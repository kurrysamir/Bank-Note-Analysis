{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mechanical-reproduction",
   "metadata": {},
   "source": [
    "<h1>Bank Note Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passing-cooling",
   "metadata": {},
   "source": [
    "<h2>Can we classify banknote as fake or genuine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "valuable-emission",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyforest import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "concerned-integrity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['from sklearn.preprocessing import StandardScaler',\n",
       " 'from sklearn.feature_extraction.text import CountVectorizer',\n",
       " 'import skimage',\n",
       " 'import sklearn',\n",
       " 'import gensim',\n",
       " 'from sklearn.impute import SimpleImputer',\n",
       " 'import bokeh',\n",
       " 'from xlrd import open_workbook',\n",
       " 'from pathlib import Path',\n",
       " 'from sklearn.ensemble import RandomForestClassifier',\n",
       " 'from sklearn.decomposition import PCA',\n",
       " 'from sklearn.model_selection import StratifiedKFold',\n",
       " 'from sklearn.linear_model import Lasso',\n",
       " 'import glob',\n",
       " 'from openpyxl import load_workbook',\n",
       " 'from sklearn.model_selection import cross_val_score',\n",
       " 'from scipy import signal as sg',\n",
       " 'from sklearn.preprocessing import PolynomialFeatures',\n",
       " 'import plotly as py',\n",
       " 'import lightgbm as lgb',\n",
       " 'import nltk',\n",
       " 'import cv2',\n",
       " 'import plotly.graph_objs as go',\n",
       " 'from sklearn import metrics',\n",
       " 'from statsmodels.tsa.arima_model import ARIMA',\n",
       " 'from pyspark import SparkContext',\n",
       " 'import dash',\n",
       " 'from sklearn.ensemble import RandomForestRegressor',\n",
       " 'from sklearn.feature_extraction.text import TfidfVectorizer',\n",
       " 'import sys',\n",
       " 'from fbprophet import Prophet',\n",
       " 'from sklearn.preprocessing import LabelEncoder',\n",
       " 'from sklearn.linear_model import ElasticNetCV',\n",
       " 'import imutils',\n",
       " 'from sklearn.preprocessing import OneHotEncoder',\n",
       " 'import torch',\n",
       " 'from sklearn.model_selection import RandomizedSearchCV',\n",
       " 'import awswrangler as wr',\n",
       " 'import keras',\n",
       " 'from sklearn.preprocessing import MinMaxScaler',\n",
       " 'from sklearn.cluster import KMeans',\n",
       " 'import tensorflow as tf',\n",
       " 'from scipy import stats',\n",
       " 'import statsmodels.api as sm',\n",
       " 'from sklearn.model_selection import train_test_split',\n",
       " 'import numpy as np',\n",
       " 'from sklearn.model_selection import KFold',\n",
       " 'import matplotlib as mpl',\n",
       " 'import datetime as dt',\n",
       " 'import spacy',\n",
       " 'import pandas as pd',\n",
       " 'from sklearn.linear_model import Ridge',\n",
       " 'import pickle',\n",
       " 'from sklearn.linear_model import LogisticRegression',\n",
       " 'import statistics',\n",
       " 'import tqdm',\n",
       " 'import pydot',\n",
       " 'from sklearn.ensemble import GradientBoostingRegressor',\n",
       " 'import re',\n",
       " 'from sklearn.linear_model import RidgeCV',\n",
       " 'from sklearn.ensemble import GradientBoostingClassifier',\n",
       " 'from sklearn.linear_model import LinearRegression',\n",
       " 'from sklearn.linear_model import ElasticNet',\n",
       " 'from sklearn.linear_model import LassoCV',\n",
       " 'import fastai',\n",
       " 'import matplotlib.pyplot as plt',\n",
       " 'import xgboost as xgb',\n",
       " 'from sklearn.manifold import TSNE',\n",
       " 'import textblob',\n",
       " 'from sklearn.preprocessing import RobustScaler',\n",
       " 'import altair as alt',\n",
       " 'from sklearn import svm',\n",
       " 'from sklearn.model_selection import GridSearchCV',\n",
       " 'import seaborn as sns',\n",
       " 'from dask import dataframe as dd',\n",
       " 'import plotly.express as px',\n",
       " 'import fbprophet',\n",
       " 'from PIL import Image',\n",
       " 'import os']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lazy_imports()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial-senegal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df=pd.read_csv('BankNote_Authentication.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "renewable-tension",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.6661</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.1674</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.6383</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.5228</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.4552</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variance  skewness  curtosis  entropy  class\n",
       "0   3.62160    8.6661   -2.8073 -0.44699      0\n",
       "1   4.54590    8.1674   -2.4586 -1.46210      0\n",
       "2   3.86600   -2.6383    1.9242  0.10645      0\n",
       "3   3.45660    9.5228   -4.0112 -3.59440      0\n",
       "4   0.32924   -4.4552    4.5718 -0.98880      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "experimental-methodology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1372, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "provincial-smith",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    762\n",
       "1    610\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "appreciated-maximum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variance    0\n",
       "skewness    0\n",
       "curtosis    0\n",
       "entropy     0\n",
       "class       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "unnecessary-manhattan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variance    float64\n",
       "skewness    float64\n",
       "curtosis    float64\n",
       "entropy     float64\n",
       "class         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "academic-paraguay",
   "metadata": {},
   "source": [
    "<h3>Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "front-leadership",
   "metadata": {},
   "source": [
    "<h4>Univariate Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "floppy-sewing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import matplotlib.pyplot as plt\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import matplotlib.pyplot as plt\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import matplotlib.pyplot as plt\\nimport pandas as pd\\nimport seaborn as sns'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\python39\\lib\\site-packages\\seaborn\\distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Distribution of \"Class\" Attribute'}, xlabel='class', ylabel='Density'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.title('Distribution of \"Class\" Attribute')\n",
    "\n",
    "sns.distplot(df['class'],color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-executive",
   "metadata": {},
   "source": [
    "<h4>Multivariate Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "touched-fluid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist(bins=20, figsize=(15,8),layout=(2,3)); #Histogram of all the attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "signed-retirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "naughty-armenia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import matplotlib.pyplot as plt\\nimport pandas as pd\\nimport seaborn as sns'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.PairGrid at 0x1f1187be340>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 762.375x720 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.pairplot(df, hue=\"class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-sperm",
   "metadata": {},
   "source": [
    "<h3>Preparing Our Data To Build Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "awful-running",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.6661</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.1674</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.6383</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.5228</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.4552</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variance  skewness  curtosis  entropy  class\n",
       "0   3.62160    8.6661   -2.8073 -0.44699      0\n",
       "1   4.54590    8.1674   -2.4586 -1.46210      0\n",
       "2   3.86600   -2.6383    1.9242  0.10645      0\n",
       "3   3.45660    9.5228   -4.0112 -3.59440      0\n",
       "4   0.32924   -4.4552    4.5718 -0.98880      0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "careful-slave",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining features and target variable\n",
    "X = df.drop(['class'],axis=1) \n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "inappropriate-coating",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-wallace",
   "metadata": {},
   "source": [
    "<h4>Scaling Our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "protecting-milton",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "technical-listing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.58438248,  0.1072115 , -0.14276339,  0.03334576],\n",
       "       [-1.08829139, -2.53123321,  2.67783284, -0.35092979],\n",
       "       [ 1.13672843, -0.15348755, -0.16820608,  0.86368769],\n",
       "       ...,\n",
       "       [-1.6900361 ,  0.72314447, -0.19588896, -2.05114485],\n",
       "       [ 0.57766241,  0.02698182,  0.1851622 ,  0.52080477],\n",
       "       [-0.9644631 ,  0.30908695, -0.49734797, -0.03521515]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "martial-length",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1226    1\n",
       "1085    1\n",
       "148     0\n",
       "1178    1\n",
       "478     0\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-divide",
   "metadata": {},
   "source": [
    "<h4>Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "proper-hartford",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies:\n",
      " [0.98181818 0.99090909 0.98181818 0.99090909 0.99090909 0.99090909\n",
      " 0.96363636 0.99082569 0.97247706 0.98165138]\n",
      "Mean Accuracy:  0.9835863219349459\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "classifier=LogisticRegression(solver='liblinear',random_state=1)\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "accuracies=cross_val_score(estimator=classifier,X=X_train,y=y_train,cv=10) # CV: Determines the cross-validation splitting strategy (How many folds, default is 5-folds) Evaluate a score by cross-validation. estimator: object to use to fit the data.\n",
    "print(\"Accuracies:\\n\",accuracies)\n",
    "\n",
    "y_test_pred=classifier.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Mean Accuracy: \",accuracies.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "generous-leadership",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9745454545454545"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "every-benjamin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix For Logistic Regression\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import matplotlib.pyplot as plt\\nimport pandas as pd\\nimport seaborn as sns'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import matplotlib.pyplot as plt\\nimport pandas as pd\\nimport seaborn as sns'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import matplotlib.pyplot as plt\\nimport pandas as pd\\nimport seaborn as sns'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(\"Confusion Matrix For Logistic Regression\")\n",
    "cm=metrics.confusion_matrix(y_test, y_test_pred, labels=[0, 1])\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index = [i for i in [0,1]],\n",
    "                  columns = [i for i in [\"Predict 0\",\"Predict 1\"]])\n",
    "plt.figure(figsize = (7,5))\n",
    "sns.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-butler",
   "metadata": {},
   "source": [
    "<h4>Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "interpreted-bottle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies:\n",
      " [0.99090909 0.99090909 0.99090909 0.99090909 0.99090909 0.99090909\n",
      " 0.96363636 0.99082569 0.97247706 0.98165138]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_classifier=SVC(kernel='linear')\n",
    "svm_classifier.fit(X_train,y_train)\n",
    "\n",
    "svm_accuracies=cross_val_score(estimator=svm_classifier,X=X_train,y=y_train,cv=10)\n",
    "print(\"Accuracies:\\n\",svm_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "environmental-spectacular",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy:  0.9854045037531277\n"
     ]
    }
   ],
   "source": [
    "svm_pred=svm_classifier.predict(X_test)\n",
    "\n",
    "print(\"Mean Accuracy: \",svm_accuracies.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "applied-blues",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9818181818181818"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,svm_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "solid-cricket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix For svm_pred\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import matplotlib.pyplot as plt\\nimport pandas as pd\\nimport seaborn as sns'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import matplotlib.pyplot as plt\\nimport pandas as pd\\nimport seaborn as sns'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import matplotlib.pyplot as plt\\nimport pandas as pd\\nimport seaborn as sns'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEvCAYAAACAFCxvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAYZ0lEQVR4nO3deZhcVbmo8fdLdzphSAgBCSFB5MgsVxGjxgEOAmoYNCheh6uSA9G+Cio4HAXxyAHFCzKoXAWeVgLBgUEGwQnBKAeQSQRECHKMUSAhEAaZM3Z954+u8LQh6e7U6krvSt5fnvVk19q79lpFiv76W2vtvSMzkSSpxLCh7oAkqfUZTCRJxQwmkqRiBhNJUjGDiSSpmMFEklSsvdkNLHtsrmuPtdaM3votQ90FrWcWLbo/Butcjf68HL75vwxaHxplZiJJKtb0zESSNEC17qHuQcMMJpJUFVkb6h40zGAiSVVRM5hIkgqlmYkkqZiZiSSpmJmJJKmYq7kkScXMTCRJxZwzkSSVcjWXJKmcmYkkqZiZiSSpmKu5JEnFzEwkScWcM5EkFWvhzMSHY0mSihlMJKkqarXGSj8iYkZELIyIu1ex77MRkRGxef11RMQZETEnIu6KiN0H0nWDiSRVRGZ3Q2UAzgOmrFwZEVsDbwMe6FW9H7B9vXQCZw2kAYOJJFVF1hor/Z028zrgiVXs+gbweSB71U0Fzs8eNwNjImJ8f204AS9JVbEWV3NFxFRgfmb+MSJ675oAPNjr9bx63YK+zmcwkaSqaHA1V0R00jMktUJXZnb1cfyGwBfpGeIaFAYTSaqKBq+ArweO1QaPVXg5sC2wIiuZCNweEa8D5gNb9zp2Yr2uTwYTSaqKtXSdSWb+CdhixeuI+DswKTMfi4grgU9ExIXA64GnMrPPIS5wAl6SqqN5S4MvAG4CdoyIeRExvY/DfwHMBeYA3wUOH0jXzUwkqSqalJlk5gf62f+yXtsJHLGmbRhMJKkqvDeXJKmYwUSSVGqAV7NXksFEkqrCzESSVKyFb0FvMJGkqjAzkSQVa+HMxIsWJUnFzEwkqSoc5pIkFWvhYS6DiSRVhZmJJKmYwUSSVMxhLklSMTMTSVIxMxNJUjEzE0lSMTMTSVIxMxNJUjGDiSSpWOZQ96BhBhNJqgozE0lSMYOJJKmYq7kkScVaODPx4ViSpGJmJpJUFa7mkiQVc5hLklSsVmus9CMiZkTEwoi4u1fdKRHx54i4KyIuj4gxvfYdExFzIuK+iHj7QLpuMJGkqshaY6V/5wFTVqq7Btg1M18J/DdwDEBE7AK8H3hF/T1nRkRbfw0YTCSpIrKWDZV+z5t5HfDESnVXZ+by+subgYn17anAhZm5JDP/BswBXtdfG86ZSFJVDN2cyWHARfXtCfQElxXm1ev6ZGYiSVXR4DBXRHRGxG29SudAm4yIY4HlwA9Lum5mIklVMYAhq1XJzC6ga03fFxH/BhwI7JP5wrrk+cDWvQ6bWK/rk5mJJFVFk1ZzrUpETAE+D7wzM5/vtetK4P0RMSIitgW2B27t73xmJpJUFU2aM4mIC4C9gM0jYh5wHD2rt0YA10QEwM2Z+bHMvCciLgZm0zP8dURmdvfXhsFkkHzpa6dz3e9uZeymY/jJD85+0f5bb7+LTx19PBPGbwnAvv/6Rj5+2AeL2ly6dCnHfOU0Zt/3F8ZsMppTTziGCePHceOtt/PNs89l2bLlDB/ezmePmM7rX7NbUVtatw0bNozf/e5nPPTQwxx88GFD3Z31V5OugM/MD6yi+pw+jj8ROHFN2nCYa5ActP9bOfv0r/Z5zO6v2pVLZ36HS2d+Z40CyfwFj/Bvn/j8i+ov+9nVjB61Mb+8eAYfft9BnH7mDAA2HTOab5/8n1z+/bM48Uuf5ZgTTl2zD6P1zic+cRj33TdnqLuhtTjMNdj6DSYRsVNEfCEizqiXL0TEzmujc61k0m7/i01Gj2rovT/91W94/0eO5OBpR3D818+gu7vfjBKA31x/E1P33xeAt+21B7f84U4yk5132I4tXrIZANttuw2Llyxh6dKlDfVN674JE7ZkypS9OffcC4e6K6plY6UC+gwmEfEF4EIg6JmAubW+fUFEHN387q1b/nj3vbx72uF87LP/wZy59wPw178/wFWz/ovvn30al878DsOGDeNnV/92QOdb+OjjbLnF5gC0t7ex8UYb8uRTT//TMddcewO77LgdHR0dg/thtM445ZTjOPbYr1GryG+467XmXQHfdP3NmUwHXpGZy3pXRsTpwD3ASc3q2Lpmlx1fzjWXzmTDDTfguhtv5VPHnMAvLjqHW267k9l/nsP7px8JwJIlSxi76RgAPnXMCcx/6BGWLV/Ggkce5eBpRwDwofdO5V0HvK3fNufMvZ/Tz5xB1zfWaOhT65H99tubhQsf54477maPPSYPdXdUkSyjEf0FkxqwFXD/SvXj6/tWqX7BTCfAmad9lY8csqq5n/XLxhtt9ML2nm98HV897Tv848mnyEzeud++fPrjh77oPWf8vy8DPXMmx554Gud9++v/tH+Ll2zGwwsfY8stXsLy5d08+9zzjNlkNAAPL3yUI7/4Fb72H5/jpRO3auInUyt7wxsmceCB+zJlyl6MGDGC0aNHMWPGNznssKOGumvrpWzh7LC/OZOjgFkR8cuI6KqXq4BZwJGre1NmdmXmpMycZCDp8djjT7DimqA/zb6PWiZjNhnN5Em7cc21N/D4P54E4Kmnn+Ghhx8Z0Dnf8ubJXPGLXwNw9bXX8/rXvIqI4OlnnuXwfz+Ooz52KLu/8hVN+TxaN3z5y19nu+0ms9NOb+aQQz7JtdfeaCBRQ/rMTDLzqojYgZ6bfK24N8t84PcDWXe8Pvn3407i93fcxZNPPs0+B32Iw6d/mOXLe+6h9r53HcDVv72Biy7/OW3tbYzs6OCU448mInj5ttvwyY8eQudRx1LLGsPb2zn2M4ez1Zbj+m3z3Qe+nWO+cgr7vfcwNhk9ilOO75nGuuDSn/LgvIc4+9wfcfa5PwKg65snsll9+ExSRbXwMFdkk5/steyxua37X0ctZ/TWbxnqLmg9s2jR/TFY53ruqx9q6OflRl/6waD1oVFetChJVdHCmYnBRJKqooUn4A0mklQVZiaSpGIVuQCxEQYTSaoKMxNJUqlWvmjRYCJJVWFmIkkqZjCRJBVzAl6SVMzMRJJUKg0mkqRiBhNJUjGXBkuSipmZSJKKtXAw6e9Ji5Ik9cvMRJIqotkPK2wmg4kkVUULD3MZTCSpKlo4mDhnIkkVkbVsqPQnImZExMKIuLtX3diIuCYi/lL/e9N6fUTEGRExJyLuiojdB9J3g4kkVUUtGyv9Ow+YslLd0cCszNwemFV/DbAfsH29dAJnDaQBg4kkVUWtwdKPzLwOeGKl6qnAzPr2TOCgXvXnZ4+bgTERMb6/NpwzkaSKWMv35hqXmQvq2w8D4+rbE4AHex03r163gD6YmUhSVTQ4zBURnRFxW6/SuSbNZs+a5KJIZmYiSVXR4K25MrML6FrDtz0SEeMzc0F9GGthvX4+sHWv4ybW6/pkZiJJFdGs1VyrcSUwrb49DbiiV/0h9VVdk4Gneg2HrZaZiSRVRZNuGhwRFwB7AZtHxDzgOOAk4OKImA7cD7y3fvgvgP2BOcDzwKEDacNgIkkV0awJ+Mz8wGp27bOKYxM4Yk3bMJhIUlW07uNMDCaSVBVpMJEkFTOYSJJKtXJm4tJgSVIxMxNJqooWzkwMJpJUEa08zGUwkaSKMJhIkooZTCRJ5TKGugcNM5hIUkWYmUiSimXNzESSVMjMRJJULJ0zkSSVMjORJBVzzkSSVCyb82ystcJgIkkVYWYiSSpmMJEkFXOYS5JUrJUzEx+OJUkqZmYiSRXhRYuSpGJetChJKlYzM5EklXKYS5JUzNVckqRimY2V/kTEpyPinoi4OyIuiIiREbFtRNwSEXMi4qKI6Cjpu8FEkioia9FQ6UtETAA+BUzKzF2BNuD9wMnANzJzO+AfwPSSvhtMJKkiahkNlQFoBzaIiHZgQ2ABsDdwSX3/TOCgkr4bTCSpIjKjodL3OXM+cCrwAD1B5CngD8CTmbm8ftg8YEJJ3w0mklQRjc6ZRERnRNzWq3SuOGdEbApMBbYFtgI2AqYMdt9dzSVJFdHodSaZ2QV0rWb3vsDfMvNRgIi4DHgTMCYi2uvZyURgfkON15mZSFJFNGOYi57hrckRsWFEBLAPMBv4LfCe+jHTgCtK+m4wkaSKaMbS4My8hZ6J9tuBP9Hzc78L+ALwmYiYA2wGnFPS96YPc22w1R7NbkJ6wdMn7T/UXZAa1qzbqWTmccBxK1XPBV43WG04ZyJJFeHtVCRJxVr5Ro/OmUiSipmZSFJFtPAj4A0mklQVrTzMZTCRpIpwAl6SVKyFn9prMJGkqkjMTCRJhWotPANvMJGkiqiZmUiSSjnMJUkq5gS8JKmYmYkkqZiZiSSpmMFEklTMYS5JUrFa68YSg4kkVYXXmUiSirXwBfA+HEuSVM7MRJIqwtVckqRitXDORJJUqJXnTAwmklQRDnNJkop5nYkkqVgrX2fi0mBJqohssAxERIyJiEsi4s8RcW9EvCEixkbENRHxl/rfmzbad4OJJFVELRorA/Qt4KrM3Al4FXAvcDQwKzO3B2bVXzfEYCJJFVFrsPQnIjYB9gTOAcjMpZn5JDAVmFk/bCZwUKN9N5hIUkU0cZhrW+BR4NyIuCMivhcRGwHjMnNB/ZiHgXGN9t1gIkkV0egwV0R0RsRtvUrnSqduB3YHzsrMVwPPsdKQVmauyRTMi7iaS5IqotHrTDKzC+jq45B5wLzMvKX++hJ6gskjETE+MxdExHhgYYNdMDORpKpo1pxJZj4MPBgRO9ar9gFmA1cC0+p104ArGu27mYkkVUQ29zKTTwI/jIgOYC5wKD0JxcURMR24H3hvoyc3mEhSRTTzdiqZeScwaRW79hmM8xtMJKkivDeXJKlYK9812Al4SVIxMxNJqgjvGixJKuaciSSpmMFEklSslSfgDSaSVBHOmUiSijnMJUkq5jCXJKlYrYXDicFEkirCYS5JUrHWzUsMJpJUGWYmkqRiLg2WJBVzAl6SVKx1Q4nBRJIqwzkTSVKxVh7m8uFYkqRiZiaSVBGtm5cYTCSpMpwzkSQVa+U5E4OJJFVE64YSg4kkVYbDXJKkYtnCuYnBRJIqopUzE68zkaSKqJENlYGIiLaIuCMiflZ/vW1E3BIRcyLioojoKOm7mUnFfLfrNA7Yf18WPvoYu716n6Hujiqq423TaPuXV5LPP8Pi8//zRfvbdno9w187BQJy6WKW/vqH5GPzyhpta6djymEMG7cNuehZlv68i3z6cYa9dGc69jgY2tqgu5ul111C7cE/l7W1nmryINeRwL3A6Prrk4FvZOaFEXE2MB04q9GTm5lUzPnnX8wBB35wqLuhilt+z40svuxbq92fTz3G4otPYfH5x7Ps5p/T8dYPD/jcMXozRvzvz72ovn3XN5OLn2fxjGNZfvuvGb7HwT1tLXqWJT/5/yw+/3iWXDWDjv0OW/MPJKB5mUlETAQOAL5Xfx3A3sAl9UNmAgeV9N3MpGKuv+EWttlm4lB3QxVXm/8XYvRmq9+/4K+9tucSozZ94XXbzq+n/dX7EMPa6X54Lstm/RCy/x9IbS/fjWU3XQlA93//gY69PwBAPvrgC8fk4w8R7R3Q1g7dy9f4c63vmjhn8k3g88Co+uvNgCczc8U/0jxgQkkDDWcmEXFoScOS1o72Xd9M7W93AxBjt6R9h9ey5MKTWfyDE6BWo22nyQM6T2w8hnzmHz0vskYuWQQjN/6nY9q2353aI/cbSBqUDf6JiM6IuK1X6Vxxzog4EFiYmX9oZt9LMpPjgXMHqyOSBt+wrXekfdc3s/iikwFoe+nOxLhtGPl/ju05oH04LHqGbqDjnYczbPTm0NZGjBrLyA99GYBld/ya7ntu7Let2Gwrhu9xMEsu/WaTPs26r9HMJDO7gK7V7H4T8M6I2B8YSc+cybeAMRHRXs9OJgLzG2we6CeYRMRdq9sFjOvjfZ1AJ0C0bcKwYRs13EFJjYnNJ9Dx1kNYctkZsPi5FbV0z76RZTdc/qLjl155Zs8Rozej4+2HsuTHp/7T/nz2SWLUpuSz/4AYRozYABY/2/OejTdlxDsPZ+lVM8inHm3q51qXNeM6k8w8BjgGICL2Aj6XmR+MiB8D7wEuBKYBV5S0098w1zjgEOAdqyiP99H5rsyclJmTDCTS2hejxvb8cP/lDPLJR16o737gXtq2fw1sUB86H7khMWrsgM7Z/dc7advljQC07fAauh+4r2fHiA0Y8a5Psuz6S6k99Nc+zqD+1BosDfoC8JmImEPPHMo5jZ+q/2GunwEbZ+adK++IiGtLGtaq/eD73+Ff93wDm28+lr/PvY3jTziVc8+7cKi7pYrp2P+jtE3cATbYmJEf/TrLbrqSGNYGwPK7/ovhkw8kRm5Exz49KwOz1s2SH51IPrGAZb/7CSMP/jREQK2bpb/5EfnME/22ufzuG+jYbzojDzuRXPwcS3/eM6rSvtvexJgtGD75HQyf/A4AFl/6DVj0TJM+/bqrNoCFECUy81rg2vr2XOB1g3XuyCZ3vr1jQuveH0At5+mT9h/qLmg9s+FnvhuDda4Pb/Puhn5efv/+ywatD41yabAkVUQr/+ZtMJGkivB5JpKkYt41WJJUrJXvGmwwkaSKcJhLklTMYS5JUjGHuSRJxZp93V8zGUwkqSKcM5EkFXOYS5JUzAl4SVIxh7kkScWcgJckFXPORJJUzDkTSVKxVp4z6e+xvZIk9cvMRJIqwgl4SVKxVh7mMphIUkU4AS9JKlZzmEuSVKp1Q4nBRJIqwzkTSVIxg4kkqZhLgyVJxVo5M/EKeEmqiGzwT38iYuuI+G1EzI6IeyLiyHr92Ii4JiL+Uv9700b7bjCRpIrIzIbKACwHPpuZuwCTgSMiYhfgaGBWZm4PzKq/bojBRJIqokY2VPqTmQsy8/b69jPAvcAEYCows37YTOCgRvvunIkkVcTamICPiJcBrwZuAcZl5oL6roeBcY2e18xEkiqi0cwkIjoj4rZepXNV54+IjYFLgaMy8+ne+7InkjUczcxMJKkiGr03V2Z2AV19HRMRw+kJJD/MzMvq1Y9ExPjMXBAR44GFDXUAMxNJqoxaZkOlPxERwDnAvZl5eq9dVwLT6tvTgCsa7buZiSSt+94EfBj4U0TcWa/7InAScHFETAfuB97baAMGE0mqiGbdgj4zbwBiNbv3GYw2DCaSVBHegl6SVMyHY0mSipmZSJKKmZlIkoqZmUiSipmZSJKKZdaGugsNM5hIUkW08sOxDCaSVBE+tleSVMzMRJJUzMxEklTMpcGSpGIuDZYkFXOYS5JUzAl4SVKxVs5MfGyvJKmYmYkkVYSruSRJxVp5mMtgIkkV4QS8JKmYmYkkqZhzJpKkYl4BL0kqZmYiSSrmnIkkqZjDXJKkYmYmkqRiBhNJUrHWDSUQrRwJ12UR0ZmZXUPdD60//M6phHcNrq7Ooe6A1jt+59Qwg4kkqZjBRJJUzGBSXY5da23zO6eGOQEvSSpmZiJJKmYwGQQR0R0Rd0bE3RHx44jYsOBc50XEe+rb34uIXfo4dq+IeONq9kVEnBERcyLirojYvdE+qXoq+p3bKSJuioglEfG5Rvuj1mQwGRyLMnO3zNwVWAp8rPfOiGjo4tDM/Ehmzu7jkL2AVf6PDewHbF8vncBZjfRBlVXF79wTwKeAUxtpW63NYDL4rge2q/8Gd31EXAnMjoi2iDglIn5fzxT+L7yQQXw7Iu6LiF8DW6w4UURcGxGT6ttTIuL2iPhjRMyKiJfR8wPk0/XfUPdYqR9TgfOzx83AmIgYvxY+v9a+SnznMnNhZv4eWLaWPrcqxNupDKL6b4P7AVfVq3YHds3Mv0VEJ/BUZr42IkYAv4uIq4FXAzsCuwDjgNnAjJXO+xLgu8Ce9XONzcwnIuJs4NnMXNVvghOAB3u9nlevWzBYn1dDr2LfOa3HDCaDY4OIuLO+fT1wDj1DAbdm5t/q9W8DXrlibBrYhJ4hqD2BCzKzG3goIn6zivNPBq5bca7MfKI5H0MtxO+cKsVgMjgWZeZuvSsiAuC53lXAJzPzVysdt3+T+jQf2LrX64n1Oq0bqvid03rMOZO151fAxyNiOEBE7BARGwHXAe+rj2+PB96yivfeDOwZEdvW3zu2Xv8MMGo17V0JHFIfH59Mz3CHQ1zrl7X9ndN6zMxk7fke8DLg9uj5FfJR4CDgcmBvesatHwBuWvmNmfloffz7sogYBiwE3gr8FLgkIqbS8xvo9b3e9gtgf2AO8DxwaHM+lipsrX7nImJL4DZgNFCLiKOAXTLz6WZ9QFWHV8BLkoo5zCVJKmYwkSQVM5hIkooZTCRJxQwmkqRiBhNJUjGDiSSpmMFEklTsfwDlzJ/lpbGgSAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 504x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Confusion Matrix For svm_pred\")\n",
    "cm=metrics.confusion_matrix(y_test,svm_pred, labels=[0, 1])\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index = [i for i in [0,1]],\n",
    "                  columns = [i for i in [\"Predict 0\",\"Predict 1\"]])\n",
    "plt.figure(figsize = (7,5))\n",
    "sns.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-lecture",
   "metadata": {},
   "source": [
    "<h4>Support Vector Machine (rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "located-difference",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies:\n",
      " [1.         0.96428571 1.         1.         1.         1.\n",
      " 0.96296296 1.         1.         1.        ]\n",
      "Mean Accuracy:  0.9927248677248677\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_rbf_classifier=SVC(kernel='rbf',gamma='auto')\n",
    "svm_rbf_classifier.fit(X_train,y_train)\n",
    "\n",
    "svm_rbf_accuracies=cross_val_score(estimator=svm_rbf_classifier,X=X_test,y=y_test,cv=10)\n",
    "print(\"Accuracies:\\n\",svm_rbf_accuracies)\n",
    "print(\"Mean Accuracy: \",svm_rbf_accuracies.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "radio-absence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_rbf_pred=svm_rbf_classifier.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test,svm_rbf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "noted-bouquet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix For svm_rbf\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import matplotlib.pyplot as plt\\nimport pandas as pd\\nimport seaborn as sns'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import matplotlib.pyplot as plt\\nimport pandas as pd\\nimport seaborn as sns'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import matplotlib.pyplot as plt\\nimport pandas as pd\\nimport seaborn as sns'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Confusion Matrix For svm_rbf\")\n",
    "cm=metrics.confusion_matrix(y_test,svm_rbf_pred, labels=[0, 1])\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index = [i for i in [0,1]],\n",
    "                  columns = [i for i in [\"Predict 0\",\"Predict 1\"]])\n",
    "plt.figure(figsize = (7,5))\n",
    "sns.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-spyware",
   "metadata": {},
   "source": [
    "<h4>RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "german-scoop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies:\n",
      " [0.96428571 1.         0.89285714 0.96428571 1.         0.96296296\n",
      " 1.         0.96296296 1.         1.        ]\n",
      "Mean Accuracy:  0.9747354497354497\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rdf_classifier=RandomForestClassifier(n_estimators=50,criterion='entropy',random_state=0)\n",
    "rdf_classifier.fit(X_train,y_train)\n",
    "rdf_accuracies=cross_val_score(estimator=rdf_classifier,X=X_test,y=y_test,cv=10)\n",
    " \n",
    "print(\"Accuracies:\\n\",rdf_accuracies)\n",
    "print(\"Mean Accuracy: \",rdf_accuracies.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "architectural-square",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9963636363636363"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf_pred=rdf_classifier.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test,rdf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "electric-preview",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix For Random Forest\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import matplotlib.pyplot as plt\\nimport pandas as pd\\nimport seaborn as sns'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import matplotlib.pyplot as plt\\nimport pandas as pd\\nimport seaborn as sns'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import matplotlib.pyplot as plt\\nimport pandas as pd\\nimport seaborn as sns'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Confusion Matrix For Random Forest\")\n",
    "cm=metrics.confusion_matrix(y_test,rdf_pred, labels=[0, 1])\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index = [i for i in [0,1]],\n",
    "                  columns = [i for i in [\"Predict 0\",\"Predict 1\"]])\n",
    "plt.figure(figsize = (7,5))\n",
    "sns.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-channels",
   "metadata": {},
   "source": [
    "<h4>KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "exempt-lightweight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=KNeighborsClassifier(),\n",
       "             param_grid={'leaf_size': [2, 5, 7, 9, 11],\n",
       "                         'n_neighbors': [2, 5, 7, 9, 11], 'p': [1, 2]})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'leaf_size' : [2,5,7,9,11],\n",
    "    'n_neighbors' : [2,5,7,9,11],\n",
    "    'p' : [1,2]    \n",
    "}\n",
    "\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid = param_grid)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "intellectual-zimbabwe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'leaf_size': 2, 'n_neighbors': 2, 'p': 1}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "spanish-courage",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_KNN_Model = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "martial-nothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier(n_neighbors=2,p=1,leaf_size=2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "recent-airport",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(leaf_size=2, n_neighbors=2, p=1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call Nearest Neighbour algorithm\n",
    "\n",
    "KNN.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "helpful-learning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_predicted = KNN.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test,KNN_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "accompanied-appendix",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix For KNN\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import matplotlib.pyplot as plt\\nimport pandas as pd\\nimport seaborn as sns'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import matplotlib.pyplot as plt\\nimport pandas as pd\\nimport seaborn as sns'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import matplotlib.pyplot as plt\\nimport pandas as pd\\nimport seaborn as sns'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Confusion Matrix For KNN\")\n",
    "cm=metrics.confusion_matrix(y_test,KNN_predicted, labels=[0, 1])\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index = [i for i in [0,1]],\n",
    "                  columns = [i for i in [\"Predict 0\",\"Predict 1\"]])\n",
    "plt.figure(figsize = (7,5))\n",
    "sns.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-practitioner",
   "metadata": {},
   "source": [
    "<h4>Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-reader",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.02065261\n",
      "Iteration 2, loss = 1.00232763\n",
      "Iteration 3, loss = 0.97715486\n",
      "Iteration 4, loss = 0.94973488\n",
      "Iteration 5, loss = 0.92231418\n",
      "Iteration 6, loss = 0.89651964\n",
      "Iteration 7, loss = 0.87283524\n",
      "Iteration 8, loss = 0.85051410\n",
      "Iteration 9, loss = 0.83056223\n",
      "Iteration 10, loss = 0.81132826\n",
      "Iteration 11, loss = 0.79467501\n",
      "Iteration 12, loss = 0.77862224\n",
      "Iteration 13, loss = 0.76455037\n",
      "Iteration 14, loss = 0.75105250\n",
      "Iteration 15, loss = 0.73882781\n",
      "Iteration 16, loss = 0.72727541\n",
      "Iteration 17, loss = 0.71657090\n",
      "Iteration 18, loss = 0.70615519\n",
      "Iteration 19, loss = 0.69650376\n",
      "Iteration 20, loss = 0.68705241\n",
      "Iteration 21, loss = 0.67795411\n",
      "Iteration 22, loss = 0.66915932\n",
      "Iteration 23, loss = 0.66056959\n",
      "Iteration 24, loss = 0.65225336\n",
      "Iteration 25, loss = 0.64391579\n",
      "Iteration 26, loss = 0.63595619\n",
      "Iteration 27, loss = 0.62803230\n",
      "Iteration 28, loss = 0.62041858\n",
      "Iteration 29, loss = 0.61270498\n",
      "Iteration 30, loss = 0.60516212\n",
      "Iteration 31, loss = 0.59779594\n",
      "Iteration 32, loss = 0.59035692\n",
      "Iteration 33, loss = 0.58320321\n",
      "Iteration 34, loss = 0.57595144\n",
      "Iteration 35, loss = 0.56900180\n",
      "Iteration 36, loss = 0.56205103\n",
      "Iteration 37, loss = 0.55529365\n",
      "Iteration 38, loss = 0.54845094\n",
      "Iteration 39, loss = 0.54178612\n",
      "Iteration 40, loss = 0.53513160\n",
      "Iteration 41, loss = 0.52864501\n",
      "Iteration 42, loss = 0.52224032\n",
      "Iteration 43, loss = 0.51578667\n",
      "Iteration 44, loss = 0.50946421\n",
      "Iteration 45, loss = 0.50308509\n",
      "Iteration 46, loss = 0.49676730\n",
      "Iteration 47, loss = 0.49048927\n",
      "Iteration 48, loss = 0.48424447\n",
      "Iteration 49, loss = 0.47795603\n",
      "Iteration 50, loss = 0.47168591\n",
      "Iteration 51, loss = 0.46554127\n",
      "Iteration 52, loss = 0.45931321\n",
      "Iteration 53, loss = 0.45311487\n",
      "Iteration 54, loss = 0.44700208\n",
      "Iteration 55, loss = 0.44078905\n",
      "Iteration 56, loss = 0.43458773\n",
      "Iteration 57, loss = 0.42855313\n",
      "Iteration 58, loss = 0.42237734\n",
      "Iteration 59, loss = 0.41626065\n",
      "Iteration 60, loss = 0.41010472\n",
      "Iteration 61, loss = 0.40404071\n",
      "Iteration 62, loss = 0.39796998\n",
      "Iteration 63, loss = 0.39184843\n",
      "Iteration 64, loss = 0.38582899\n",
      "Iteration 65, loss = 0.37982684\n",
      "Iteration 66, loss = 0.37377680\n",
      "Iteration 67, loss = 0.36774698\n",
      "Iteration 68, loss = 0.36184120\n",
      "Iteration 69, loss = 0.35589148\n",
      "Iteration 70, loss = 0.34996399\n",
      "Iteration 71, loss = 0.34405863\n",
      "Iteration 72, loss = 0.33821501\n",
      "Iteration 73, loss = 0.33238220\n",
      "Iteration 74, loss = 0.32657664\n",
      "Iteration 75, loss = 0.32080032\n",
      "Iteration 76, loss = 0.31512534\n",
      "Iteration 77, loss = 0.30945453\n",
      "Iteration 78, loss = 0.30387061\n",
      "Iteration 79, loss = 0.29833487\n",
      "Iteration 80, loss = 0.29282992\n",
      "Iteration 81, loss = 0.28743817\n",
      "Iteration 82, loss = 0.28206505\n",
      "Iteration 83, loss = 0.27679398\n",
      "Iteration 84, loss = 0.27160790\n",
      "Iteration 85, loss = 0.26648198\n",
      "Iteration 86, loss = 0.26147567\n",
      "Iteration 87, loss = 0.25648488\n",
      "Iteration 88, loss = 0.25167142\n",
      "Iteration 89, loss = 0.24685406\n",
      "Iteration 90, loss = 0.24220478\n",
      "Iteration 91, loss = 0.23763726\n",
      "Iteration 92, loss = 0.23315116\n",
      "Iteration 93, loss = 0.22880331\n",
      "Iteration 94, loss = 0.22447856\n",
      "Iteration 95, loss = 0.22029372\n",
      "Iteration 96, loss = 0.21615029\n",
      "Iteration 97, loss = 0.21213816\n",
      "Iteration 98, loss = 0.20817922\n",
      "Iteration 99, loss = 0.20428405\n",
      "Iteration 100, loss = 0.20048594\n",
      "Iteration 101, loss = 0.19679086\n",
      "Iteration 102, loss = 0.19318859\n",
      "Iteration 103, loss = 0.18964047\n",
      "Iteration 104, loss = 0.18621313\n",
      "Iteration 105, loss = 0.18281696\n",
      "Iteration 106, loss = 0.17952817\n",
      "Iteration 107, loss = 0.17630263\n",
      "Iteration 108, loss = 0.17318159\n",
      "Iteration 109, loss = 0.17011360\n",
      "Iteration 110, loss = 0.16712502\n",
      "Iteration 111, loss = 0.16421313\n",
      "Iteration 112, loss = 0.16136983\n",
      "Iteration 113, loss = 0.15859124\n",
      "Iteration 114, loss = 0.15589711\n",
      "Iteration 115, loss = 0.15325848\n",
      "Iteration 116, loss = 0.15070201\n",
      "Iteration 117, loss = 0.14820547\n",
      "Iteration 118, loss = 0.14576031\n",
      "Iteration 119, loss = 0.14339203\n",
      "Iteration 120, loss = 0.14106500\n",
      "Iteration 121, loss = 0.13881946\n",
      "Iteration 122, loss = 0.13660643\n",
      "Iteration 123, loss = 0.13446933\n",
      "Iteration 124, loss = 0.13237608\n",
      "Iteration 125, loss = 0.13033827\n",
      "Iteration 126, loss = 0.12836027\n",
      "Iteration 127, loss = 0.12642249\n",
      "Iteration 128, loss = 0.12454009\n",
      "Iteration 129, loss = 0.12268435\n",
      "Iteration 130, loss = 0.12088455\n",
      "Iteration 131, loss = 0.11915212\n",
      "Iteration 132, loss = 0.11741655\n",
      "Iteration 133, loss = 0.11574596\n",
      "Iteration 134, loss = 0.11412071\n",
      "Iteration 135, loss = 0.11252615\n",
      "Iteration 136, loss = 0.11098422\n",
      "Iteration 137, loss = 0.10946150\n",
      "Iteration 138, loss = 0.10798531\n",
      "Iteration 139, loss = 0.10653809\n",
      "Iteration 140, loss = 0.10513015\n",
      "Iteration 141, loss = 0.10375451\n",
      "Iteration 142, loss = 0.10241026\n",
      "Iteration 143, loss = 0.10109661\n",
      "Iteration 144, loss = 0.09980897\n",
      "Iteration 145, loss = 0.09855872\n",
      "Iteration 146, loss = 0.09732385\n",
      "Iteration 147, loss = 0.09614793\n",
      "Iteration 148, loss = 0.09496971\n",
      "Iteration 149, loss = 0.09384161\n",
      "Iteration 150, loss = 0.09272834\n",
      "Iteration 151, loss = 0.09161685\n",
      "Iteration 152, loss = 0.09057096\n",
      "Iteration 153, loss = 0.08952995\n",
      "Iteration 154, loss = 0.08850073\n",
      "Iteration 155, loss = 0.08750489\n",
      "Iteration 156, loss = 0.08653097\n",
      "Iteration 157, loss = 0.08557633\n",
      "Iteration 158, loss = 0.08464328\n",
      "Iteration 159, loss = 0.08373069\n",
      "Iteration 160, loss = 0.08283452\n",
      "Iteration 161, loss = 0.08196166\n",
      "Iteration 162, loss = 0.08111051\n",
      "Iteration 163, loss = 0.08026085\n",
      "Iteration 164, loss = 0.07944789\n",
      "Iteration 165, loss = 0.07864239\n",
      "Iteration 166, loss = 0.07785417\n",
      "Iteration 167, loss = 0.07708332\n",
      "Iteration 168, loss = 0.07633191\n",
      "Iteration 169, loss = 0.07559835\n",
      "Iteration 170, loss = 0.07488046\n",
      "Iteration 171, loss = 0.07417128\n",
      "Iteration 172, loss = 0.07347539\n",
      "Iteration 173, loss = 0.07279578\n",
      "Iteration 174, loss = 0.07212676\n",
      "Iteration 175, loss = 0.07147993\n",
      "Iteration 176, loss = 0.07082708\n",
      "Iteration 177, loss = 0.07019272\n",
      "Iteration 178, loss = 0.06957363\n",
      "Iteration 179, loss = 0.06896190\n",
      "Iteration 180, loss = 0.06836536\n",
      "Iteration 181, loss = 0.06778055\n",
      "Iteration 182, loss = 0.06720160\n",
      "Iteration 183, loss = 0.06663578\n",
      "Iteration 184, loss = 0.06607506\n",
      "Iteration 185, loss = 0.06554014\n",
      "Iteration 186, loss = 0.06500435\n",
      "Iteration 187, loss = 0.06447534\n",
      "Iteration 188, loss = 0.06395695\n",
      "Iteration 189, loss = 0.06344526\n",
      "Iteration 190, loss = 0.06294495\n",
      "Iteration 191, loss = 0.06245129\n",
      "Iteration 192, loss = 0.06197639\n",
      "Iteration 193, loss = 0.06149206\n",
      "Iteration 194, loss = 0.06102840\n",
      "Iteration 195, loss = 0.06057314\n",
      "Iteration 196, loss = 0.06013086\n",
      "Iteration 197, loss = 0.05968988\n",
      "Iteration 198, loss = 0.05925400\n",
      "Iteration 199, loss = 0.05883593\n",
      "Iteration 200, loss = 0.05841735\n",
      "Iteration 201, loss = 0.05800045\n",
      "Iteration 202, loss = 0.05759967\n",
      "Iteration 203, loss = 0.05720536\n",
      "Iteration 204, loss = 0.05680791\n",
      "Iteration 205, loss = 0.05642613\n",
      "Iteration 206, loss = 0.05603566\n",
      "Iteration 207, loss = 0.05566237\n",
      "Iteration 208, loss = 0.05529067\n",
      "Iteration 209, loss = 0.05493253\n",
      "Iteration 210, loss = 0.05457438\n",
      "Iteration 211, loss = 0.05421724\n",
      "Iteration 212, loss = 0.05386587\n",
      "Iteration 213, loss = 0.05352801\n",
      "Iteration 214, loss = 0.05319007\n",
      "Iteration 215, loss = 0.05285737\n",
      "Iteration 216, loss = 0.05252950\n",
      "Iteration 217, loss = 0.05220530\n",
      "Iteration 218, loss = 0.05188605\n",
      "Iteration 219, loss = 0.05157180\n",
      "Iteration 220, loss = 0.05126418\n",
      "Iteration 221, loss = 0.05096363\n",
      "Iteration 222, loss = 0.05065958\n",
      "Iteration 223, loss = 0.05036744\n",
      "Iteration 224, loss = 0.05006724\n",
      "Iteration 225, loss = 0.04977752\n",
      "Iteration 226, loss = 0.04950245\n",
      "Iteration 227, loss = 0.04921081\n",
      "Iteration 228, loss = 0.04893026\n",
      "Iteration 229, loss = 0.04866155\n",
      "Iteration 230, loss = 0.04839043\n",
      "Iteration 231, loss = 0.04812989\n",
      "Iteration 232, loss = 0.04786760\n",
      "Iteration 233, loss = 0.04760596\n",
      "Iteration 234, loss = 0.04735202\n",
      "Iteration 235, loss = 0.04710676\n",
      "Iteration 236, loss = 0.04685101\n",
      "Iteration 237, loss = 0.04660956\n",
      "Iteration 238, loss = 0.04636803\n",
      "Iteration 239, loss = 0.04612591\n",
      "Iteration 240, loss = 0.04588605\n",
      "Iteration 241, loss = 0.04564952\n",
      "Iteration 242, loss = 0.04541974\n",
      "Iteration 243, loss = 0.04519042\n",
      "Iteration 244, loss = 0.04496640\n",
      "Iteration 245, loss = 0.04474029\n",
      "Iteration 246, loss = 0.04451830\n",
      "Iteration 247, loss = 0.04429805\n",
      "Iteration 248, loss = 0.04408530\n",
      "Iteration 249, loss = 0.04387552\n",
      "Iteration 250, loss = 0.04366131\n",
      "Iteration 251, loss = 0.04345422\n",
      "Iteration 252, loss = 0.04325435\n",
      "Iteration 253, loss = 0.04305007\n",
      "Iteration 254, loss = 0.04285108\n",
      "Iteration 255, loss = 0.04265372\n",
      "Iteration 256, loss = 0.04245935\n",
      "Iteration 257, loss = 0.04226632\n",
      "Iteration 258, loss = 0.04207579\n",
      "Iteration 259, loss = 0.04188603\n",
      "Iteration 260, loss = 0.04169793\n",
      "Iteration 261, loss = 0.04151085\n",
      "Iteration 262, loss = 0.04133371\n",
      "Iteration 263, loss = 0.04114986\n",
      "Iteration 264, loss = 0.04096914\n",
      "Iteration 265, loss = 0.04078835\n",
      "Iteration 266, loss = 0.04061609\n",
      "Iteration 267, loss = 0.04044067\n",
      "Iteration 268, loss = 0.04026434\n",
      "Iteration 269, loss = 0.04009450\n",
      "Iteration 270, loss = 0.03992535\n",
      "Iteration 271, loss = 0.03976054\n",
      "Iteration 272, loss = 0.03959222\n",
      "Iteration 273, loss = 0.03942884\n",
      "Iteration 274, loss = 0.03926568\n",
      "Iteration 275, loss = 0.03910304\n",
      "Iteration 276, loss = 0.03893744\n",
      "Iteration 277, loss = 0.03878404\n",
      "Iteration 278, loss = 0.03861920\n",
      "Iteration 279, loss = 0.03846199\n",
      "Iteration 280, loss = 0.03830598\n",
      "Iteration 281, loss = 0.03815187\n",
      "Iteration 282, loss = 0.03800226\n",
      "Iteration 283, loss = 0.03785460\n",
      "Iteration 284, loss = 0.03770229\n",
      "Iteration 285, loss = 0.03756117\n",
      "Iteration 286, loss = 0.03741211\n",
      "Iteration 287, loss = 0.03726985\n",
      "Iteration 288, loss = 0.03711690\n",
      "Iteration 289, loss = 0.03697685\n",
      "Iteration 290, loss = 0.03683561\n",
      "Iteration 291, loss = 0.03670088\n",
      "Iteration 292, loss = 0.03655956\n",
      "Iteration 293, loss = 0.03642230\n",
      "Iteration 294, loss = 0.03628931\n",
      "Iteration 295, loss = 0.03615684\n",
      "Iteration 296, loss = 0.03602420\n",
      "Iteration 297, loss = 0.03589386\n",
      "Iteration 298, loss = 0.03576305\n",
      "Iteration 299, loss = 0.03563450\n",
      "Iteration 300, loss = 0.03550705\n",
      "Iteration 301, loss = 0.03537878\n",
      "Iteration 302, loss = 0.03525408\n",
      "Iteration 303, loss = 0.03513394\n",
      "Iteration 304, loss = 0.03500536\n",
      "Iteration 305, loss = 0.03488854\n",
      "Iteration 306, loss = 0.03476340\n",
      "Iteration 307, loss = 0.03464008\n",
      "Iteration 308, loss = 0.03451699\n",
      "Iteration 309, loss = 0.03439868\n",
      "Iteration 310, loss = 0.03427191\n",
      "Iteration 311, loss = 0.03415465\n",
      "Iteration 312, loss = 0.03403997\n",
      "Iteration 313, loss = 0.03392635\n",
      "Iteration 314, loss = 0.03380769\n",
      "Iteration 315, loss = 0.03369144\n",
      "Iteration 316, loss = 0.03358002\n",
      "Iteration 317, loss = 0.03347190\n",
      "Iteration 318, loss = 0.03335779\n",
      "Iteration 319, loss = 0.03324726\n",
      "Iteration 320, loss = 0.03313638\n",
      "Iteration 321, loss = 0.03302853\n",
      "Iteration 322, loss = 0.03292591\n",
      "Iteration 323, loss = 0.03282288\n",
      "Iteration 324, loss = 0.03270784\n",
      "Iteration 325, loss = 0.03260314\n",
      "Iteration 326, loss = 0.03250024\n",
      "Iteration 327, loss = 0.03239892\n",
      "Iteration 328, loss = 0.03229020\n",
      "Iteration 329, loss = 0.03219337\n",
      "Iteration 330, loss = 0.03209161\n",
      "Iteration 331, loss = 0.03199029\n",
      "Iteration 332, loss = 0.03189282\n",
      "Iteration 333, loss = 0.03179243\n",
      "Iteration 334, loss = 0.03169092\n",
      "Iteration 335, loss = 0.03159594\n",
      "Iteration 336, loss = 0.03149929\n",
      "Iteration 337, loss = 0.03139925\n",
      "Iteration 338, loss = 0.03130220\n",
      "Iteration 339, loss = 0.03121069\n",
      "Iteration 340, loss = 0.03111529\n",
      "Iteration 341, loss = 0.03101899\n",
      "Iteration 342, loss = 0.03093213\n",
      "Iteration 343, loss = 0.03083161\n",
      "Iteration 344, loss = 0.03074001\n",
      "Iteration 345, loss = 0.03064432\n",
      "Iteration 346, loss = 0.03055385\n",
      "Iteration 347, loss = 0.03046132\n",
      "Iteration 348, loss = 0.03037244\n",
      "Iteration 349, loss = 0.03027953\n",
      "Iteration 350, loss = 0.03018879\n",
      "Iteration 351, loss = 0.03010367\n",
      "Iteration 352, loss = 0.03001329\n",
      "Iteration 353, loss = 0.02992703\n",
      "Iteration 354, loss = 0.02984057\n",
      "Iteration 355, loss = 0.02975310\n",
      "Iteration 356, loss = 0.02967029\n",
      "Iteration 357, loss = 0.02958348\n",
      "Iteration 358, loss = 0.02949713\n",
      "Iteration 359, loss = 0.02941618\n",
      "Iteration 360, loss = 0.02933012\n",
      "Iteration 361, loss = 0.02924767\n",
      "Iteration 362, loss = 0.02916463\n",
      "Iteration 363, loss = 0.02908144\n",
      "Iteration 364, loss = 0.02900216\n",
      "Iteration 365, loss = 0.02892134\n",
      "Iteration 366, loss = 0.02883725\n",
      "Iteration 367, loss = 0.02875631\n",
      "Iteration 368, loss = 0.02867269\n",
      "Iteration 369, loss = 0.02859141\n",
      "Iteration 370, loss = 0.02851483\n",
      "Iteration 371, loss = 0.02843606\n",
      "Iteration 372, loss = 0.02835714\n",
      "Iteration 373, loss = 0.02828141\n",
      "Iteration 374, loss = 0.02820224\n",
      "Iteration 375, loss = 0.02812744\n",
      "Iteration 376, loss = 0.02805597\n",
      "Iteration 377, loss = 0.02797507\n",
      "Iteration 378, loss = 0.02790247\n",
      "Iteration 379, loss = 0.02782623\n",
      "Iteration 380, loss = 0.02775717\n",
      "Iteration 381, loss = 0.02767890\n",
      "Iteration 382, loss = 0.02760291\n",
      "Iteration 383, loss = 0.02753070\n",
      "Iteration 384, loss = 0.02745955\n",
      "Iteration 385, loss = 0.02738867\n",
      "Iteration 386, loss = 0.02731334\n",
      "Iteration 387, loss = 0.02724541\n",
      "Iteration 388, loss = 0.02717366\n",
      "Iteration 389, loss = 0.02710331\n",
      "Iteration 390, loss = 0.02703439\n",
      "Iteration 391, loss = 0.02696779\n",
      "Iteration 392, loss = 0.02689249\n",
      "Iteration 393, loss = 0.02682609\n",
      "Iteration 394, loss = 0.02675574\n",
      "Iteration 395, loss = 0.02668877\n",
      "Iteration 396, loss = 0.02661835\n",
      "Iteration 397, loss = 0.02655102\n",
      "Iteration 398, loss = 0.02648696\n",
      "Iteration 399, loss = 0.02641770\n",
      "Iteration 400, loss = 0.02634867\n",
      "Iteration 401, loss = 0.02627981\n",
      "Iteration 402, loss = 0.02621258\n",
      "Iteration 403, loss = 0.02615064\n",
      "Iteration 404, loss = 0.02607949\n",
      "Iteration 405, loss = 0.02601324\n",
      "Iteration 406, loss = 0.02594869\n",
      "Iteration 407, loss = 0.02588515\n",
      "Iteration 408, loss = 0.02582360\n",
      "Iteration 409, loss = 0.02575424\n",
      "Iteration 410, loss = 0.02569097\n",
      "Iteration 411, loss = 0.02562500\n",
      "Iteration 412, loss = 0.02556431\n",
      "Iteration 413, loss = 0.02549846\n",
      "Iteration 414, loss = 0.02543672\n",
      "Iteration 415, loss = 0.02537581\n",
      "Iteration 416, loss = 0.02531503\n",
      "Iteration 417, loss = 0.02525303\n",
      "Iteration 418, loss = 0.02519494\n",
      "Iteration 419, loss = 0.02513219\n",
      "Iteration 420, loss = 0.02507011\n",
      "Iteration 421, loss = 0.02500978\n",
      "Iteration 422, loss = 0.02495129\n",
      "Iteration 423, loss = 0.02489218\n",
      "Iteration 424, loss = 0.02483195\n",
      "Iteration 425, loss = 0.02477423\n",
      "Iteration 426, loss = 0.02471502\n",
      "Iteration 427, loss = 0.02465381\n",
      "Iteration 428, loss = 0.02459555\n",
      "Iteration 429, loss = 0.02453734\n",
      "Iteration 430, loss = 0.02447791\n",
      "Iteration 431, loss = 0.02442238\n",
      "Iteration 432, loss = 0.02436120\n",
      "Iteration 433, loss = 0.02430425\n",
      "Iteration 434, loss = 0.02425174\n",
      "Iteration 435, loss = 0.02419019\n",
      "Iteration 436, loss = 0.02414233\n",
      "Iteration 437, loss = 0.02408197\n",
      "Iteration 438, loss = 0.02402108\n",
      "Iteration 439, loss = 0.02396917\n",
      "Iteration 440, loss = 0.02391141\n",
      "Iteration 441, loss = 0.02385725\n",
      "Iteration 442, loss = 0.02380309\n",
      "Iteration 443, loss = 0.02374842\n",
      "Iteration 444, loss = 0.02369450\n",
      "Iteration 445, loss = 0.02364541\n",
      "Iteration 446, loss = 0.02358837\n",
      "Iteration 447, loss = 0.02353468\n",
      "Iteration 448, loss = 0.02348492\n",
      "Iteration 449, loss = 0.02343072\n",
      "Iteration 450, loss = 0.02337773\n",
      "Iteration 451, loss = 0.02332516\n",
      "Iteration 452, loss = 0.02327478\n",
      "Iteration 453, loss = 0.02322088\n",
      "Iteration 454, loss = 0.02316796\n",
      "Iteration 455, loss = 0.02311889\n",
      "Iteration 456, loss = 0.02306737\n",
      "Iteration 457, loss = 0.02301649\n",
      "Iteration 458, loss = 0.02296386\n",
      "Iteration 459, loss = 0.02291658\n",
      "Iteration 460, loss = 0.02286528\n",
      "Iteration 461, loss = 0.02281090\n",
      "Iteration 462, loss = 0.02276053\n",
      "Iteration 463, loss = 0.02270952\n",
      "Iteration 464, loss = 0.02265984\n",
      "Iteration 465, loss = 0.02260995\n",
      "Iteration 466, loss = 0.02256140\n",
      "Iteration 467, loss = 0.02251271\n",
      "Iteration 468, loss = 0.02246010\n",
      "Iteration 469, loss = 0.02241299\n",
      "Iteration 470, loss = 0.02236544\n",
      "Iteration 471, loss = 0.02231238\n",
      "Iteration 472, loss = 0.02226811\n",
      "Iteration 473, loss = 0.02221668\n",
      "Iteration 474, loss = 0.02216943\n",
      "Iteration 475, loss = 0.02212048\n",
      "Iteration 476, loss = 0.02207214\n",
      "Iteration 477, loss = 0.02202501\n",
      "Iteration 478, loss = 0.02197736\n",
      "Iteration 479, loss = 0.02193087\n",
      "Iteration 480, loss = 0.02188917\n",
      "Iteration 481, loss = 0.02183691\n",
      "Iteration 482, loss = 0.02179185\n",
      "Iteration 483, loss = 0.02174751\n",
      "Iteration 484, loss = 0.02169894\n",
      "Iteration 485, loss = 0.02165651\n",
      "Iteration 486, loss = 0.02160784\n",
      "Iteration 487, loss = 0.02155897\n",
      "Iteration 488, loss = 0.02151358\n",
      "Iteration 489, loss = 0.02146891\n",
      "Iteration 490, loss = 0.02142413\n",
      "Iteration 491, loss = 0.02138302\n",
      "Iteration 492, loss = 0.02133110\n",
      "Iteration 493, loss = 0.02128776\n",
      "Iteration 494, loss = 0.02123930\n",
      "Iteration 495, loss = 0.02119442\n",
      "Iteration 496, loss = 0.02115463\n",
      "Iteration 497, loss = 0.02110546\n",
      "Iteration 498, loss = 0.02105994\n",
      "Iteration 499, loss = 0.02101768\n",
      "Iteration 500, loss = 0.02097409\n",
      "Iteration 501, loss = 0.02092993\n",
      "Iteration 502, loss = 0.02088780\n",
      "Iteration 503, loss = 0.02084385\n",
      "Iteration 504, loss = 0.02080190\n",
      "Iteration 505, loss = 0.02076130\n",
      "Iteration 506, loss = 0.02071933\n",
      "Iteration 507, loss = 0.02067522\n",
      "Iteration 508, loss = 0.02063738\n",
      "Iteration 509, loss = 0.02059326\n",
      "Iteration 510, loss = 0.02055442\n",
      "Iteration 511, loss = 0.02050804\n",
      "Iteration 512, loss = 0.02046894\n",
      "Iteration 513, loss = 0.02042701\n",
      "Iteration 514, loss = 0.02038257\n",
      "Iteration 515, loss = 0.02034252\n",
      "Iteration 516, loss = 0.02030666\n",
      "Iteration 517, loss = 0.02026330\n",
      "Iteration 518, loss = 0.02022178\n",
      "Iteration 519, loss = 0.02018039\n",
      "Iteration 520, loss = 0.02014305\n",
      "Iteration 521, loss = 0.02010340\n",
      "Iteration 522, loss = 0.02006458\n",
      "Iteration 523, loss = 0.02002217\n",
      "Iteration 524, loss = 0.01998025\n",
      "Iteration 525, loss = 0.01994146\n",
      "Iteration 526, loss = 0.01990187\n",
      "Iteration 527, loss = 0.01986395\n",
      "Iteration 528, loss = 0.01982180\n",
      "Iteration 529, loss = 0.01978371\n",
      "Iteration 530, loss = 0.01974482\n",
      "Iteration 531, loss = 0.01970654\n",
      "Iteration 532, loss = 0.01966994\n",
      "Iteration 533, loss = 0.01962822\n",
      "Iteration 534, loss = 0.01959167\n",
      "Iteration 535, loss = 0.01955600\n",
      "Iteration 536, loss = 0.01951895\n",
      "Iteration 537, loss = 0.01947656\n",
      "Iteration 538, loss = 0.01943905\n",
      "Iteration 539, loss = 0.01940010\n",
      "Iteration 540, loss = 0.01936248\n",
      "Iteration 541, loss = 0.01932282\n",
      "Iteration 542, loss = 0.01928521\n",
      "Iteration 543, loss = 0.01924830\n",
      "Iteration 544, loss = 0.01921152\n",
      "Iteration 545, loss = 0.01917545\n",
      "Iteration 546, loss = 0.01913794\n",
      "Iteration 547, loss = 0.01910061\n",
      "Iteration 548, loss = 0.01906512\n",
      "Iteration 549, loss = 0.01902648\n",
      "Iteration 550, loss = 0.01898773\n",
      "Iteration 551, loss = 0.01895389\n",
      "Iteration 552, loss = 0.01891872\n",
      "Iteration 553, loss = 0.01887788\n",
      "Iteration 554, loss = 0.01884507\n",
      "Iteration 555, loss = 0.01880825\n",
      "Iteration 556, loss = 0.01877205\n",
      "Iteration 557, loss = 0.01873509\n",
      "Iteration 558, loss = 0.01870421\n",
      "Iteration 559, loss = 0.01866518\n",
      "Iteration 560, loss = 0.01862787\n",
      "Iteration 561, loss = 0.01859535\n",
      "Iteration 562, loss = 0.01855807\n",
      "Iteration 563, loss = 0.01852122\n",
      "Iteration 564, loss = 0.01848908\n",
      "Iteration 565, loss = 0.01845371\n",
      "Iteration 566, loss = 0.01841829\n",
      "Iteration 567, loss = 0.01838373\n",
      "Iteration 568, loss = 0.01834905\n",
      "Iteration 569, loss = 0.01831402\n",
      "Iteration 570, loss = 0.01828295\n",
      "Iteration 571, loss = 0.01824622\n",
      "Iteration 572, loss = 0.01821089\n",
      "Iteration 573, loss = 0.01817810\n",
      "Iteration 574, loss = 0.01814379\n",
      "Iteration 575, loss = 0.01810960\n",
      "Iteration 576, loss = 0.01807762\n",
      "Iteration 577, loss = 0.01804404\n",
      "Iteration 578, loss = 0.01800892\n",
      "Iteration 579, loss = 0.01797557\n",
      "Iteration 580, loss = 0.01794376\n",
      "Iteration 581, loss = 0.01790856\n",
      "Iteration 582, loss = 0.01788002\n",
      "Iteration 583, loss = 0.01784143\n",
      "Iteration 584, loss = 0.01781075\n",
      "Iteration 585, loss = 0.01777684\n",
      "Iteration 586, loss = 0.01774634\n",
      "Iteration 587, loss = 0.01771389\n",
      "Iteration 588, loss = 0.01767803\n",
      "Iteration 589, loss = 0.01764657\n",
      "Iteration 590, loss = 0.01761433\n",
      "Iteration 591, loss = 0.01758391\n",
      "Iteration 592, loss = 0.01754953\n",
      "Iteration 593, loss = 0.01751858\n",
      "Iteration 594, loss = 0.01748727\n",
      "Iteration 595, loss = 0.01745831\n",
      "Iteration 596, loss = 0.01742434\n",
      "Iteration 597, loss = 0.01739413\n",
      "Iteration 598, loss = 0.01736417\n",
      "Iteration 599, loss = 0.01733121\n",
      "Iteration 600, loss = 0.01729865\n",
      "Iteration 601, loss = 0.01726958\n",
      "Iteration 602, loss = 0.01723837\n",
      "Iteration 603, loss = 0.01720527\n",
      "Iteration 604, loss = 0.01717424\n",
      "Iteration 605, loss = 0.01714486\n",
      "Iteration 606, loss = 0.01711229\n",
      "Iteration 607, loss = 0.01708218\n",
      "Iteration 608, loss = 0.01705083\n",
      "Iteration 609, loss = 0.01702263\n",
      "Iteration 610, loss = 0.01699120\n",
      "Iteration 611, loss = 0.01695992\n",
      "Iteration 612, loss = 0.01693077\n",
      "Iteration 613, loss = 0.01690197\n",
      "Iteration 614, loss = 0.01686854\n",
      "Iteration 615, loss = 0.01684227\n",
      "Iteration 616, loss = 0.01681052\n",
      "Iteration 617, loss = 0.01678012\n",
      "Iteration 618, loss = 0.01674931\n",
      "Iteration 619, loss = 0.01671939\n",
      "Iteration 620, loss = 0.01668852\n",
      "Iteration 621, loss = 0.01666139\n",
      "Iteration 622, loss = 0.01663030\n",
      "Iteration 623, loss = 0.01660329\n",
      "Iteration 624, loss = 0.01657410\n",
      "Iteration 625, loss = 0.01654497\n",
      "Iteration 626, loss = 0.01651699\n",
      "Iteration 627, loss = 0.01648729\n",
      "Iteration 628, loss = 0.01646009\n",
      "Iteration 629, loss = 0.01643024\n",
      "Iteration 630, loss = 0.01640097\n",
      "Iteration 631, loss = 0.01637167\n",
      "Iteration 632, loss = 0.01634456\n",
      "Iteration 633, loss = 0.01631195\n",
      "Iteration 634, loss = 0.01628316\n",
      "Iteration 635, loss = 0.01625721\n",
      "Iteration 636, loss = 0.01622543\n",
      "Iteration 637, loss = 0.01619735\n",
      "Iteration 638, loss = 0.01617116\n",
      "Iteration 639, loss = 0.01614210\n",
      "Iteration 640, loss = 0.01611345\n",
      "Iteration 641, loss = 0.01608580\n",
      "Iteration 642, loss = 0.01605801\n",
      "Iteration 643, loss = 0.01602950\n",
      "Iteration 644, loss = 0.01600354\n",
      "Iteration 645, loss = 0.01597674\n",
      "Iteration 646, loss = 0.01594932\n",
      "Iteration 647, loss = 0.01592178\n",
      "Iteration 648, loss = 0.01589315\n",
      "Iteration 649, loss = 0.01586652\n",
      "Iteration 650, loss = 0.01583877\n",
      "Iteration 651, loss = 0.01581262\n",
      "Iteration 652, loss = 0.01578694\n",
      "Iteration 653, loss = 0.01576161\n",
      "Iteration 654, loss = 0.01573023\n",
      "Iteration 655, loss = 0.01570433\n",
      "Iteration 656, loss = 0.01567717\n",
      "Iteration 657, loss = 0.01565040\n",
      "Iteration 658, loss = 0.01562226\n",
      "Iteration 659, loss = 0.01559702\n",
      "Iteration 660, loss = 0.01557104\n",
      "Iteration 661, loss = 0.01554200\n",
      "Iteration 662, loss = 0.01551516\n",
      "Iteration 663, loss = 0.01548992\n",
      "Iteration 664, loss = 0.01546133\n",
      "Iteration 665, loss = 0.01543707\n",
      "Iteration 666, loss = 0.01540976\n",
      "Iteration 667, loss = 0.01538570\n",
      "Iteration 668, loss = 0.01535985\n",
      "Iteration 669, loss = 0.01533222\n",
      "Iteration 670, loss = 0.01530739\n",
      "Iteration 671, loss = 0.01528007\n",
      "Iteration 672, loss = 0.01525462\n",
      "Iteration 673, loss = 0.01522887\n",
      "Iteration 674, loss = 0.01520386\n",
      "Iteration 675, loss = 0.01517804\n",
      "Iteration 676, loss = 0.01515329\n",
      "Iteration 677, loss = 0.01512611\n",
      "Iteration 678, loss = 0.01510208\n",
      "Iteration 679, loss = 0.01507806\n",
      "Iteration 680, loss = 0.01505464\n",
      "Iteration 681, loss = 0.01502899\n",
      "Iteration 682, loss = 0.01500480\n",
      "Iteration 683, loss = 0.01497864\n",
      "Iteration 684, loss = 0.01495387\n",
      "Iteration 685, loss = 0.01492939\n",
      "Iteration 686, loss = 0.01490458\n",
      "Iteration 687, loss = 0.01488052\n",
      "Iteration 688, loss = 0.01485956\n",
      "Iteration 689, loss = 0.01483118\n",
      "Iteration 690, loss = 0.01480749\n",
      "Iteration 691, loss = 0.01478175\n",
      "Iteration 692, loss = 0.01475882\n",
      "Iteration 693, loss = 0.01473623\n",
      "Iteration 694, loss = 0.01471082\n",
      "Iteration 695, loss = 0.01468760\n",
      "Iteration 696, loss = 0.01466429\n",
      "Iteration 697, loss = 0.01463982\n",
      "Iteration 698, loss = 0.01461328\n",
      "Iteration 699, loss = 0.01458854\n",
      "Iteration 700, loss = 0.01456517\n",
      "Iteration 701, loss = 0.01454229\n",
      "Iteration 702, loss = 0.01451752\n",
      "Iteration 703, loss = 0.01449820\n",
      "Iteration 704, loss = 0.01447287\n",
      "Iteration 705, loss = 0.01444632\n",
      "Iteration 706, loss = 0.01442533\n",
      "Iteration 707, loss = 0.01439892\n",
      "Iteration 708, loss = 0.01437543\n",
      "Iteration 709, loss = 0.01435134\n",
      "Iteration 710, loss = 0.01432780\n",
      "Iteration 711, loss = 0.01430442\n",
      "Iteration 712, loss = 0.01428422\n",
      "Iteration 713, loss = 0.01425807\n",
      "Iteration 714, loss = 0.01423515\n",
      "Iteration 715, loss = 0.01421247\n",
      "Iteration 716, loss = 0.01418877\n",
      "Iteration 717, loss = 0.01416404\n",
      "Iteration 718, loss = 0.01414503\n",
      "Iteration 719, loss = 0.01412004\n",
      "Iteration 720, loss = 0.01409679\n",
      "Iteration 721, loss = 0.01407506\n",
      "Iteration 722, loss = 0.01405529\n",
      "Iteration 723, loss = 0.01402947\n",
      "Iteration 724, loss = 0.01400703\n",
      "Iteration 725, loss = 0.01398613\n",
      "Iteration 726, loss = 0.01396285\n",
      "Iteration 727, loss = 0.01394115\n",
      "Iteration 728, loss = 0.01391975\n",
      "Iteration 729, loss = 0.01389623\n",
      "Iteration 730, loss = 0.01387614\n",
      "Iteration 731, loss = 0.01385566\n",
      "Iteration 732, loss = 0.01383468\n",
      "Iteration 733, loss = 0.01380983\n",
      "Iteration 734, loss = 0.01378964\n",
      "Iteration 735, loss = 0.01376605\n",
      "Iteration 736, loss = 0.01374643\n",
      "Iteration 737, loss = 0.01372207\n",
      "Iteration 738, loss = 0.01370039\n",
      "Iteration 739, loss = 0.01367876\n",
      "Iteration 740, loss = 0.01365916\n",
      "Iteration 741, loss = 0.01363544\n",
      "Iteration 742, loss = 0.01361512\n",
      "Iteration 743, loss = 0.01359079\n",
      "Iteration 744, loss = 0.01357247\n",
      "Iteration 745, loss = 0.01354885\n",
      "Iteration 746, loss = 0.01352703\n",
      "Iteration 747, loss = 0.01350602\n",
      "Iteration 748, loss = 0.01348531\n",
      "Iteration 749, loss = 0.01346421\n",
      "Iteration 750, loss = 0.01344317\n",
      "Iteration 751, loss = 0.01342191\n",
      "Iteration 752, loss = 0.01339863\n",
      "Iteration 753, loss = 0.01337974\n",
      "Iteration 754, loss = 0.01335865\n",
      "Iteration 755, loss = 0.01333797\n",
      "Iteration 756, loss = 0.01331596\n",
      "Iteration 757, loss = 0.01329480\n",
      "Iteration 758, loss = 0.01327532\n",
      "Iteration 759, loss = 0.01325540\n",
      "Iteration 760, loss = 0.01323595\n",
      "Iteration 761, loss = 0.01321497\n",
      "Iteration 762, loss = 0.01319441\n",
      "Iteration 763, loss = 0.01317384\n",
      "Iteration 764, loss = 0.01315458\n",
      "Iteration 765, loss = 0.01313402\n",
      "Iteration 766, loss = 0.01311253\n",
      "Iteration 767, loss = 0.01309444\n",
      "Iteration 768, loss = 0.01307296\n",
      "Iteration 769, loss = 0.01305290\n",
      "Iteration 770, loss = 0.01303363\n",
      "Iteration 771, loss = 0.01301368\n",
      "Iteration 772, loss = 0.01299605\n",
      "Iteration 773, loss = 0.01297456\n",
      "Iteration 774, loss = 0.01295658\n",
      "Iteration 775, loss = 0.01293456\n",
      "Iteration 776, loss = 0.01291551\n",
      "Iteration 777, loss = 0.01289509\n",
      "Iteration 778, loss = 0.01287550\n",
      "Iteration 779, loss = 0.01285695\n",
      "Iteration 780, loss = 0.01283688\n",
      "Iteration 781, loss = 0.01281723\n",
      "Iteration 782, loss = 0.01279683\n",
      "Iteration 783, loss = 0.01277941\n",
      "Iteration 784, loss = 0.01275880\n",
      "Iteration 785, loss = 0.01273747\n",
      "Iteration 786, loss = 0.01271964\n",
      "Iteration 787, loss = 0.01269907\n",
      "Iteration 788, loss = 0.01267944\n",
      "Iteration 789, loss = 0.01266000\n",
      "Iteration 790, loss = 0.01264274\n",
      "Iteration 791, loss = 0.01262378\n",
      "Iteration 792, loss = 0.01260185\n",
      "Iteration 793, loss = 0.01258401\n",
      "Iteration 794, loss = 0.01256597\n",
      "Iteration 795, loss = 0.01254452\n",
      "Iteration 796, loss = 0.01252558\n",
      "Iteration 797, loss = 0.01251147\n",
      "Iteration 798, loss = 0.01248660\n",
      "Iteration 799, loss = 0.01246858\n",
      "Iteration 800, loss = 0.01244879\n",
      "Iteration 801, loss = 0.01243131\n",
      "Iteration 802, loss = 0.01241337\n",
      "Iteration 803, loss = 0.01239353\n",
      "Iteration 804, loss = 0.01237527\n",
      "Iteration 805, loss = 0.01235588\n",
      "Iteration 806, loss = 0.01233859\n",
      "Iteration 807, loss = 0.01232026\n",
      "Iteration 808, loss = 0.01230247\n",
      "Iteration 809, loss = 0.01228254\n",
      "Iteration 810, loss = 0.01226561\n",
      "Iteration 811, loss = 0.01224681\n",
      "Iteration 812, loss = 0.01222709\n",
      "Iteration 813, loss = 0.01220834\n",
      "Iteration 814, loss = 0.01219005\n",
      "Iteration 815, loss = 0.01217365\n",
      "Iteration 816, loss = 0.01215432\n",
      "Iteration 817, loss = 0.01213687\n",
      "Iteration 818, loss = 0.01212102\n",
      "Iteration 819, loss = 0.01210201\n",
      "Iteration 820, loss = 0.01208252\n",
      "Iteration 821, loss = 0.01206462\n",
      "Iteration 822, loss = 0.01204643\n",
      "Iteration 823, loss = 0.01202861\n",
      "Iteration 824, loss = 0.01201228\n",
      "Iteration 825, loss = 0.01199393\n",
      "Iteration 826, loss = 0.01197706\n",
      "Iteration 827, loss = 0.01195997\n",
      "Iteration 828, loss = 0.01194296\n",
      "Iteration 829, loss = 0.01192521\n",
      "Iteration 830, loss = 0.01190763\n",
      "Iteration 831, loss = 0.01188891\n",
      "Iteration 832, loss = 0.01187188\n",
      "Iteration 833, loss = 0.01185340\n",
      "Iteration 834, loss = 0.01183852\n",
      "Iteration 835, loss = 0.01182019\n",
      "Iteration 836, loss = 0.01180310\n",
      "Iteration 837, loss = 0.01178716\n",
      "Iteration 838, loss = 0.01176767\n",
      "Iteration 839, loss = 0.01175148\n",
      "Iteration 840, loss = 0.01173402\n",
      "Iteration 841, loss = 0.01171731\n",
      "Iteration 842, loss = 0.01169920\n",
      "Iteration 843, loss = 0.01168309\n",
      "Iteration 844, loss = 0.01166709\n",
      "Iteration 845, loss = 0.01164918\n",
      "Iteration 846, loss = 0.01163261\n",
      "Iteration 847, loss = 0.01161716\n",
      "Iteration 848, loss = 0.01160041\n",
      "Iteration 849, loss = 0.01158401\n",
      "Iteration 850, loss = 0.01156899\n",
      "Iteration 851, loss = 0.01155027\n",
      "Iteration 852, loss = 0.01153354\n",
      "Iteration 853, loss = 0.01152006\n",
      "Iteration 854, loss = 0.01150046\n",
      "Iteration 855, loss = 0.01148492\n",
      "Iteration 856, loss = 0.01146729\n",
      "Iteration 857, loss = 0.01145094\n",
      "Iteration 858, loss = 0.01143427\n",
      "Iteration 859, loss = 0.01141891\n",
      "Iteration 860, loss = 0.01140181\n",
      "Iteration 861, loss = 0.01138655\n",
      "Iteration 862, loss = 0.01137042\n",
      "Iteration 863, loss = 0.01135512\n",
      "Iteration 864, loss = 0.01133880\n",
      "Iteration 865, loss = 0.01132327\n",
      "Iteration 866, loss = 0.01130722\n",
      "Iteration 867, loss = 0.01129266\n",
      "Iteration 868, loss = 0.01127582\n",
      "Iteration 869, loss = 0.01125958\n",
      "Iteration 870, loss = 0.01124374\n",
      "Iteration 871, loss = 0.01122876\n",
      "Iteration 872, loss = 0.01121267\n",
      "Iteration 873, loss = 0.01119623\n",
      "Iteration 874, loss = 0.01118026\n",
      "Iteration 875, loss = 0.01116548\n",
      "Iteration 876, loss = 0.01114772\n",
      "Iteration 877, loss = 0.01113357\n",
      "Iteration 878, loss = 0.01111710\n",
      "Iteration 879, loss = 0.01110136\n",
      "Iteration 880, loss = 0.01108546\n",
      "Iteration 881, loss = 0.01106938\n",
      "Iteration 882, loss = 0.01105404\n",
      "Iteration 883, loss = 0.01103946\n",
      "Iteration 884, loss = 0.01102424\n",
      "Iteration 885, loss = 0.01100624\n",
      "Iteration 886, loss = 0.01099227\n",
      "Iteration 887, loss = 0.01097600\n",
      "Iteration 888, loss = 0.01095971\n",
      "Iteration 889, loss = 0.01094605\n",
      "Iteration 890, loss = 0.01092985\n",
      "Iteration 891, loss = 0.01091609\n",
      "Iteration 892, loss = 0.01089828\n",
      "Iteration 893, loss = 0.01088419\n",
      "Iteration 894, loss = 0.01086808\n",
      "Iteration 895, loss = 0.01085441\n",
      "Iteration 896, loss = 0.01083869\n",
      "Iteration 897, loss = 0.01082742\n",
      "Iteration 898, loss = 0.01081021\n",
      "Iteration 899, loss = 0.01079145\n",
      "Iteration 900, loss = 0.01077719\n",
      "Iteration 901, loss = 0.01076244\n",
      "Iteration 902, loss = 0.01074727\n",
      "Iteration 903, loss = 0.01073429\n",
      "Iteration 904, loss = 0.01071811\n",
      "Iteration 905, loss = 0.01070468\n",
      "Iteration 906, loss = 0.01069110\n",
      "Iteration 907, loss = 0.01067713\n",
      "Iteration 908, loss = 0.01066029\n",
      "Iteration 909, loss = 0.01064490\n",
      "Iteration 910, loss = 0.01063090\n",
      "Iteration 911, loss = 0.01061697\n",
      "Iteration 912, loss = 0.01060024\n",
      "Iteration 913, loss = 0.01058720\n",
      "Iteration 914, loss = 0.01057165\n",
      "Iteration 915, loss = 0.01055633\n",
      "Iteration 916, loss = 0.01054332\n",
      "Iteration 917, loss = 0.01052675\n",
      "Iteration 918, loss = 0.01051340\n",
      "Iteration 919, loss = 0.01049923\n",
      "Iteration 920, loss = 0.01048576\n",
      "Iteration 921, loss = 0.01046993\n",
      "Iteration 922, loss = 0.01045526\n",
      "Iteration 923, loss = 0.01044206\n",
      "Iteration 924, loss = 0.01042735\n",
      "Iteration 925, loss = 0.01041306\n",
      "Iteration 926, loss = 0.01039832\n",
      "Iteration 927, loss = 0.01038421\n",
      "Iteration 928, loss = 0.01037095\n",
      "Iteration 929, loss = 0.01035600\n",
      "Iteration 930, loss = 0.01034218\n",
      "Iteration 931, loss = 0.01033052\n",
      "Iteration 932, loss = 0.01031491\n",
      "Iteration 933, loss = 0.01030148\n",
      "Iteration 934, loss = 0.01028853\n",
      "Iteration 935, loss = 0.01027430\n",
      "Iteration 936, loss = 0.01025981\n",
      "Iteration 937, loss = 0.01024670\n",
      "Iteration 938, loss = 0.01023424\n",
      "Iteration 939, loss = 0.01021899\n",
      "Iteration 940, loss = 0.01020503\n",
      "Iteration 941, loss = 0.01019219\n",
      "Iteration 942, loss = 0.01017684\n",
      "Iteration 943, loss = 0.01016425\n",
      "Iteration 944, loss = 0.01015125\n",
      "Iteration 945, loss = 0.01013787\n",
      "Iteration 946, loss = 0.01012512\n",
      "Iteration 947, loss = 0.01011067\n",
      "Iteration 948, loss = 0.01009759\n",
      "Iteration 949, loss = 0.01008358\n",
      "Iteration 950, loss = 0.01006995\n",
      "Iteration 951, loss = 0.01005762\n",
      "Iteration 952, loss = 0.01004360\n",
      "Iteration 953, loss = 0.01003079\n",
      "Iteration 954, loss = 0.01001939\n",
      "Iteration 955, loss = 0.01000319\n",
      "Iteration 956, loss = 0.00999071\n",
      "Iteration 957, loss = 0.00997854\n",
      "Iteration 958, loss = 0.00996397\n",
      "Iteration 959, loss = 0.00994990\n",
      "Iteration 960, loss = 0.00993795\n",
      "Iteration 961, loss = 0.00992223\n",
      "Iteration 962, loss = 0.00990823\n",
      "Iteration 963, loss = 0.00989599\n",
      "Iteration 964, loss = 0.00988288\n",
      "Iteration 965, loss = 0.00986919\n",
      "Iteration 966, loss = 0.00985739\n",
      "Iteration 967, loss = 0.00984456\n",
      "Iteration 968, loss = 0.00983043\n",
      "Iteration 969, loss = 0.00982026\n",
      "Iteration 970, loss = 0.00980461\n",
      "Iteration 971, loss = 0.00979106\n",
      "Iteration 972, loss = 0.00977725\n",
      "Iteration 973, loss = 0.00976442\n",
      "Iteration 974, loss = 0.00975143\n",
      "Iteration 975, loss = 0.00973852\n",
      "Iteration 976, loss = 0.00972452\n",
      "Iteration 977, loss = 0.00971246\n",
      "Iteration 978, loss = 0.00969875\n",
      "Iteration 979, loss = 0.00968524\n",
      "Iteration 980, loss = 0.00967277\n",
      "Iteration 981, loss = 0.00966009\n",
      "Iteration 982, loss = 0.00964682\n",
      "Iteration 983, loss = 0.00963419\n",
      "Iteration 984, loss = 0.00962291\n",
      "Iteration 985, loss = 0.00960851\n",
      "Iteration 986, loss = 0.00959576\n",
      "Iteration 987, loss = 0.00958348\n",
      "Iteration 988, loss = 0.00957011\n",
      "Iteration 989, loss = 0.00955756\n",
      "Iteration 990, loss = 0.00954586\n",
      "Iteration 991, loss = 0.00953264\n",
      "Iteration 992, loss = 0.00951990\n",
      "Iteration 993, loss = 0.00950688\n",
      "Iteration 994, loss = 0.00949515\n",
      "Iteration 995, loss = 0.00948236\n",
      "Iteration 996, loss = 0.00947194\n",
      "Iteration 997, loss = 0.00945656\n",
      "Iteration 998, loss = 0.00944444\n",
      "Iteration 999, loss = 0.00943159\n",
      "Iteration 1000, loss = 0.00941938\n",
      "Iteration 1001, loss = 0.00940684\n",
      "Iteration 1002, loss = 0.00939565\n",
      "Iteration 1003, loss = 0.00938275\n",
      "Iteration 1004, loss = 0.00936938\n",
      "Iteration 1005, loss = 0.00935684\n",
      "Iteration 1006, loss = 0.00934449\n",
      "Iteration 1007, loss = 0.00933232\n",
      "Iteration 1008, loss = 0.00931933\n",
      "Iteration 1009, loss = 0.00930685\n",
      "Iteration 1010, loss = 0.00929688\n",
      "Iteration 1011, loss = 0.00928169\n",
      "Iteration 1012, loss = 0.00926959\n",
      "Iteration 1013, loss = 0.00925851\n",
      "Iteration 1014, loss = 0.00924635\n",
      "Iteration 1015, loss = 0.00923368\n",
      "Iteration 1016, loss = 0.00922008\n",
      "Iteration 1017, loss = 0.00920843\n",
      "Iteration 1018, loss = 0.00919620\n",
      "Iteration 1019, loss = 0.00918476\n",
      "Iteration 1020, loss = 0.00917194\n",
      "Iteration 1021, loss = 0.00916159\n",
      "Iteration 1022, loss = 0.00914870\n",
      "Iteration 1023, loss = 0.00913813\n",
      "Iteration 1024, loss = 0.00912483\n",
      "Iteration 1025, loss = 0.00911369\n",
      "Iteration 1026, loss = 0.00910150\n",
      "Iteration 1027, loss = 0.00909101\n",
      "Iteration 1028, loss = 0.00907898\n",
      "Iteration 1029, loss = 0.00906788\n",
      "Iteration 1030, loss = 0.00905671\n",
      "Iteration 1031, loss = 0.00904542\n",
      "Iteration 1032, loss = 0.00903270\n",
      "Iteration 1033, loss = 0.00902153\n",
      "Iteration 1034, loss = 0.00901042\n",
      "Iteration 1035, loss = 0.00899831\n",
      "Iteration 1036, loss = 0.00898697\n",
      "Iteration 1037, loss = 0.00897446\n",
      "Iteration 1038, loss = 0.00896410\n",
      "Iteration 1039, loss = 0.00895298\n",
      "Iteration 1040, loss = 0.00893981\n",
      "Iteration 1041, loss = 0.00892919\n",
      "Iteration 1042, loss = 0.00891751\n",
      "Iteration 1043, loss = 0.00890515\n",
      "Iteration 1044, loss = 0.00889374\n",
      "Iteration 1045, loss = 0.00888264\n",
      "Iteration 1046, loss = 0.00887118\n",
      "Iteration 1047, loss = 0.00885946\n",
      "Iteration 1048, loss = 0.00884788\n",
      "Iteration 1049, loss = 0.00883802\n",
      "Iteration 1050, loss = 0.00882612\n",
      "Iteration 1051, loss = 0.00881532\n",
      "Iteration 1052, loss = 0.00880394\n",
      "Iteration 1053, loss = 0.00879326\n",
      "Iteration 1054, loss = 0.00878198\n",
      "Iteration 1055, loss = 0.00877177\n",
      "Iteration 1056, loss = 0.00876227\n",
      "Iteration 1057, loss = 0.00874942\n",
      "Iteration 1058, loss = 0.00873823\n",
      "Iteration 1059, loss = 0.00872624\n",
      "Iteration 1060, loss = 0.00871575\n",
      "Iteration 1061, loss = 0.00870453\n",
      "Iteration 1062, loss = 0.00869407\n",
      "Iteration 1063, loss = 0.00868274\n",
      "Iteration 1064, loss = 0.00867285\n",
      "Iteration 1065, loss = 0.00866130\n",
      "Iteration 1066, loss = 0.00865100\n",
      "Iteration 1067, loss = 0.00864025\n",
      "Iteration 1068, loss = 0.00863028\n",
      "Iteration 1069, loss = 0.00861950\n",
      "Iteration 1070, loss = 0.00860898\n",
      "Iteration 1071, loss = 0.00859741\n",
      "Iteration 1072, loss = 0.00858985\n",
      "Iteration 1073, loss = 0.00857677\n",
      "Iteration 1074, loss = 0.00856511\n",
      "Iteration 1075, loss = 0.00855438\n",
      "Iteration 1076, loss = 0.00854569\n",
      "Iteration 1077, loss = 0.00853412\n",
      "Iteration 1078, loss = 0.00852391\n",
      "Iteration 1079, loss = 0.00851207\n",
      "Iteration 1080, loss = 0.00850090\n",
      "Iteration 1081, loss = 0.00849143\n",
      "Iteration 1082, loss = 0.00848061\n",
      "Iteration 1083, loss = 0.00847094\n",
      "Iteration 1084, loss = 0.00845987\n",
      "Iteration 1085, loss = 0.00844865\n",
      "Iteration 1086, loss = 0.00843898\n",
      "Iteration 1087, loss = 0.00842867\n",
      "Iteration 1088, loss = 0.00841726\n",
      "Iteration 1089, loss = 0.00840729\n",
      "Iteration 1090, loss = 0.00839670\n",
      "Iteration 1091, loss = 0.00838600\n",
      "Iteration 1092, loss = 0.00837630\n",
      "Iteration 1093, loss = 0.00836575\n",
      "Iteration 1094, loss = 0.00835526\n",
      "Iteration 1095, loss = 0.00834570\n",
      "Iteration 1096, loss = 0.00833597\n",
      "Iteration 1097, loss = 0.00832550\n",
      "Iteration 1098, loss = 0.00831643\n",
      "Iteration 1099, loss = 0.00830580\n",
      "Iteration 1100, loss = 0.00829507\n",
      "Iteration 1101, loss = 0.00828544\n",
      "Iteration 1102, loss = 0.00827512\n",
      "Iteration 1103, loss = 0.00826499\n",
      "Iteration 1104, loss = 0.00825397\n",
      "Iteration 1105, loss = 0.00824384\n",
      "Iteration 1106, loss = 0.00823478\n",
      "Iteration 1107, loss = 0.00822237\n",
      "Iteration 1108, loss = 0.00821295\n",
      "Iteration 1109, loss = 0.00820224\n",
      "Iteration 1110, loss = 0.00819225\n",
      "Iteration 1111, loss = 0.00818256\n",
      "Iteration 1112, loss = 0.00817304\n",
      "Iteration 1113, loss = 0.00816183\n",
      "Iteration 1114, loss = 0.00815232\n",
      "Iteration 1115, loss = 0.00814226\n",
      "Iteration 1116, loss = 0.00813231\n",
      "Iteration 1117, loss = 0.00812201\n",
      "Iteration 1118, loss = 0.00811225\n",
      "Iteration 1119, loss = 0.00810168\n",
      "Iteration 1120, loss = 0.00809255\n",
      "Iteration 1121, loss = 0.00808235\n",
      "Iteration 1122, loss = 0.00807332\n",
      "Iteration 1123, loss = 0.00806372\n",
      "Iteration 1124, loss = 0.00805375\n",
      "Iteration 1125, loss = 0.00804597\n",
      "Iteration 1126, loss = 0.00803500\n",
      "Iteration 1127, loss = 0.00802409\n",
      "Iteration 1128, loss = 0.00801534\n",
      "Iteration 1129, loss = 0.00800672\n",
      "Iteration 1130, loss = 0.00799550\n",
      "Iteration 1131, loss = 0.00798627\n",
      "Iteration 1132, loss = 0.00797773\n",
      "Iteration 1133, loss = 0.00796721\n",
      "Iteration 1134, loss = 0.00795763\n",
      "Iteration 1135, loss = 0.00794846\n",
      "Iteration 1136, loss = 0.00794020\n",
      "Iteration 1137, loss = 0.00793093\n",
      "Iteration 1138, loss = 0.00791993\n",
      "Iteration 1139, loss = 0.00791131\n",
      "Iteration 1140, loss = 0.00790067\n",
      "Iteration 1141, loss = 0.00789180\n",
      "Iteration 1142, loss = 0.00788189\n",
      "Iteration 1143, loss = 0.00787288\n",
      "Iteration 1144, loss = 0.00786309\n",
      "Iteration 1145, loss = 0.00785338\n",
      "Iteration 1146, loss = 0.00784472\n",
      "Iteration 1147, loss = 0.00783608\n",
      "Iteration 1148, loss = 0.00782631\n",
      "Iteration 1149, loss = 0.00781754\n",
      "Iteration 1150, loss = 0.00780702\n",
      "Iteration 1151, loss = 0.00779780\n",
      "Iteration 1152, loss = 0.00778913\n",
      "Iteration 1153, loss = 0.00778073\n",
      "Iteration 1154, loss = 0.00777062\n",
      "Iteration 1155, loss = 0.00776114\n",
      "Iteration 1156, loss = 0.00775104\n",
      "Iteration 1157, loss = 0.00774176\n",
      "Iteration 1158, loss = 0.00773322\n",
      "Iteration 1159, loss = 0.00772364\n",
      "Iteration 1160, loss = 0.00771461\n",
      "Iteration 1161, loss = 0.00770533\n",
      "Iteration 1162, loss = 0.00769680\n",
      "Iteration 1163, loss = 0.00768760\n",
      "Iteration 1164, loss = 0.00767855\n",
      "Iteration 1165, loss = 0.00766883\n",
      "Iteration 1166, loss = 0.00766055\n",
      "Iteration 1167, loss = 0.00765100\n",
      "Iteration 1168, loss = 0.00764173\n",
      "Iteration 1169, loss = 0.00763298\n",
      "Iteration 1170, loss = 0.00762472\n",
      "Iteration 1171, loss = 0.00761460\n",
      "Iteration 1172, loss = 0.00760638\n",
      "Iteration 1173, loss = 0.00759738\n",
      "Iteration 1174, loss = 0.00758892\n",
      "Iteration 1175, loss = 0.00757905\n",
      "Iteration 1176, loss = 0.00757159\n",
      "Iteration 1177, loss = 0.00756249\n",
      "Iteration 1178, loss = 0.00755315\n",
      "Iteration 1179, loss = 0.00754454\n",
      "Iteration 1180, loss = 0.00753645\n",
      "Iteration 1181, loss = 0.00752607\n",
      "Iteration 1182, loss = 0.00751756\n",
      "Iteration 1183, loss = 0.00750877\n",
      "Iteration 1184, loss = 0.00750019\n",
      "Iteration 1185, loss = 0.00749152\n",
      "Iteration 1186, loss = 0.00748479\n",
      "Iteration 1187, loss = 0.00747314\n",
      "Iteration 1188, loss = 0.00746783\n",
      "Iteration 1189, loss = 0.00745719\n",
      "Iteration 1190, loss = 0.00744859\n",
      "Iteration 1191, loss = 0.00743920\n",
      "Iteration 1192, loss = 0.00743161\n",
      "Iteration 1193, loss = 0.00742264\n",
      "Iteration 1194, loss = 0.00741411\n",
      "Iteration 1195, loss = 0.00740540\n",
      "Iteration 1196, loss = 0.00739731\n",
      "Iteration 1197, loss = 0.00738750\n",
      "Iteration 1198, loss = 0.00737993\n",
      "Iteration 1199, loss = 0.00737064\n",
      "Iteration 1200, loss = 0.00736294\n",
      "Iteration 1201, loss = 0.00735381\n",
      "Iteration 1202, loss = 0.00734567\n",
      "Iteration 1203, loss = 0.00733773\n",
      "Iteration 1204, loss = 0.00732710\n",
      "Iteration 1205, loss = 0.00732008\n",
      "Iteration 1206, loss = 0.00731213\n",
      "Iteration 1207, loss = 0.00730206\n",
      "Iteration 1208, loss = 0.00729446\n",
      "Iteration 1209, loss = 0.00728540\n",
      "Iteration 1210, loss = 0.00727755\n",
      "Iteration 1211, loss = 0.00726954\n",
      "Iteration 1212, loss = 0.00726017\n",
      "Iteration 1213, loss = 0.00725268\n",
      "Iteration 1214, loss = 0.00724548\n",
      "Iteration 1215, loss = 0.00723663\n",
      "Iteration 1216, loss = 0.00722869\n",
      "Iteration 1217, loss = 0.00722059\n",
      "Iteration 1218, loss = 0.00721216\n",
      "Iteration 1219, loss = 0.00720480\n",
      "Iteration 1220, loss = 0.00719600\n",
      "Iteration 1221, loss = 0.00718850\n",
      "Iteration 1222, loss = 0.00717979\n",
      "Iteration 1223, loss = 0.00717191\n",
      "Iteration 1224, loss = 0.00716334\n",
      "Iteration 1225, loss = 0.00715566\n",
      "Iteration 1226, loss = 0.00714736\n",
      "Iteration 1227, loss = 0.00713993\n",
      "Iteration 1228, loss = 0.00713200\n",
      "Iteration 1229, loss = 0.00712412\n",
      "Iteration 1230, loss = 0.00711566\n",
      "Iteration 1231, loss = 0.00710787\n",
      "Iteration 1232, loss = 0.00710083\n",
      "Iteration 1233, loss = 0.00709206\n",
      "Iteration 1234, loss = 0.00708507\n",
      "Iteration 1235, loss = 0.00707759\n",
      "Iteration 1236, loss = 0.00706905\n",
      "Iteration 1237, loss = 0.00706163\n",
      "Iteration 1238, loss = 0.00705278\n",
      "Iteration 1239, loss = 0.00704482\n",
      "Iteration 1240, loss = 0.00703753\n",
      "Iteration 1241, loss = 0.00702957\n",
      "Iteration 1242, loss = 0.00702152\n",
      "Iteration 1243, loss = 0.00701388\n",
      "Iteration 1244, loss = 0.00700680\n",
      "Iteration 1245, loss = 0.00699875\n",
      "Iteration 1246, loss = 0.00699173\n",
      "Iteration 1247, loss = 0.00698312\n",
      "Iteration 1248, loss = 0.00697504\n",
      "Iteration 1249, loss = 0.00696842\n",
      "Iteration 1250, loss = 0.00695938\n",
      "Iteration 1251, loss = 0.00695167\n",
      "Iteration 1252, loss = 0.00694503\n",
      "Iteration 1253, loss = 0.00693659\n",
      "Iteration 1254, loss = 0.00692957\n",
      "Iteration 1255, loss = 0.00692094\n",
      "Iteration 1256, loss = 0.00691305\n",
      "Iteration 1257, loss = 0.00690595\n",
      "Iteration 1258, loss = 0.00689832\n",
      "Iteration 1259, loss = 0.00689112\n",
      "Iteration 1260, loss = 0.00688330\n",
      "Iteration 1261, loss = 0.00687756\n",
      "Iteration 1262, loss = 0.00686796\n",
      "Iteration 1263, loss = 0.00686145\n",
      "Iteration 1264, loss = 0.00685443\n",
      "Iteration 1265, loss = 0.00684661\n",
      "Iteration 1266, loss = 0.00683858\n",
      "Iteration 1267, loss = 0.00683208\n",
      "Iteration 1268, loss = 0.00682468\n",
      "Iteration 1269, loss = 0.00681661\n",
      "Iteration 1270, loss = 0.00680929\n",
      "Iteration 1271, loss = 0.00680149\n",
      "Iteration 1272, loss = 0.00679341\n",
      "Iteration 1273, loss = 0.00678622\n",
      "Iteration 1274, loss = 0.00677854\n",
      "Iteration 1275, loss = 0.00677357\n",
      "Iteration 1276, loss = 0.00676377\n",
      "Iteration 1277, loss = 0.00675591\n",
      "Iteration 1278, loss = 0.00674906\n",
      "Iteration 1279, loss = 0.00674204\n",
      "Iteration 1280, loss = 0.00673405\n",
      "Iteration 1281, loss = 0.00672649\n",
      "Iteration 1282, loss = 0.00672045\n",
      "Iteration 1283, loss = 0.00671206\n",
      "Iteration 1284, loss = 0.00670529\n",
      "Iteration 1285, loss = 0.00669845\n",
      "Iteration 1286, loss = 0.00669099\n",
      "Iteration 1287, loss = 0.00668342\n",
      "Iteration 1288, loss = 0.00667742\n",
      "Iteration 1289, loss = 0.00667044\n",
      "Iteration 1290, loss = 0.00666239\n",
      "Iteration 1291, loss = 0.00665489\n",
      "Iteration 1292, loss = 0.00664811\n",
      "Iteration 1293, loss = 0.00664004\n",
      "Iteration 1294, loss = 0.00663309\n",
      "Iteration 1295, loss = 0.00662696\n",
      "Iteration 1296, loss = 0.00661874\n",
      "Iteration 1297, loss = 0.00661343\n",
      "Iteration 1298, loss = 0.00660475\n",
      "Iteration 1299, loss = 0.00659870\n",
      "Iteration 1300, loss = 0.00659054\n",
      "Iteration 1301, loss = 0.00658407\n",
      "Iteration 1302, loss = 0.00657651\n",
      "Iteration 1303, loss = 0.00656963\n",
      "Iteration 1304, loss = 0.00656319\n",
      "Iteration 1305, loss = 0.00655526\n",
      "Iteration 1306, loss = 0.00654930\n",
      "Iteration 1307, loss = 0.00654094\n",
      "Iteration 1308, loss = 0.00653391\n",
      "Iteration 1309, loss = 0.00652705\n",
      "Iteration 1310, loss = 0.00652040\n",
      "Iteration 1311, loss = 0.00651297\n",
      "Iteration 1312, loss = 0.00650560\n",
      "Iteration 1313, loss = 0.00649912\n",
      "Iteration 1314, loss = 0.00649265\n",
      "Iteration 1315, loss = 0.00648556\n",
      "Iteration 1316, loss = 0.00647924\n",
      "Iteration 1317, loss = 0.00647255\n",
      "Iteration 1318, loss = 0.00646488\n",
      "Iteration 1319, loss = 0.00645832\n",
      "Iteration 1320, loss = 0.00645139\n",
      "Iteration 1321, loss = 0.00644479\n",
      "Iteration 1322, loss = 0.00643720\n",
      "Iteration 1323, loss = 0.00643101\n",
      "Iteration 1324, loss = 0.00642397\n",
      "Iteration 1325, loss = 0.00641655\n",
      "Iteration 1326, loss = 0.00641045\n",
      "Iteration 1327, loss = 0.00640309\n",
      "Iteration 1328, loss = 0.00639641\n",
      "Iteration 1329, loss = 0.00638980\n",
      "Iteration 1330, loss = 0.00638271\n",
      "Iteration 1331, loss = 0.00637562\n",
      "Iteration 1332, loss = 0.00636921\n",
      "Iteration 1333, loss = 0.00636205\n",
      "Iteration 1334, loss = 0.00635589\n",
      "Iteration 1335, loss = 0.00634934\n",
      "Iteration 1336, loss = 0.00634234\n",
      "Iteration 1337, loss = 0.00633588\n",
      "Iteration 1338, loss = 0.00632877\n",
      "Iteration 1339, loss = 0.00632301\n",
      "Iteration 1340, loss = 0.00631623\n",
      "Iteration 1341, loss = 0.00630895\n",
      "Iteration 1342, loss = 0.00630252\n",
      "Iteration 1343, loss = 0.00629663\n",
      "Iteration 1344, loss = 0.00628980\n",
      "Iteration 1345, loss = 0.00628429\n",
      "Iteration 1346, loss = 0.00627589\n",
      "Iteration 1347, loss = 0.00626975\n",
      "Iteration 1348, loss = 0.00626445\n",
      "Iteration 1349, loss = 0.00625694\n",
      "Iteration 1350, loss = 0.00625016\n",
      "Iteration 1351, loss = 0.00624395\n",
      "Iteration 1352, loss = 0.00623759\n",
      "Iteration 1353, loss = 0.00623133\n",
      "Iteration 1354, loss = 0.00622424\n",
      "Iteration 1355, loss = 0.00621864\n",
      "Iteration 1356, loss = 0.00621162\n",
      "Iteration 1357, loss = 0.00620527\n",
      "Iteration 1358, loss = 0.00619842\n",
      "Iteration 1359, loss = 0.00619179\n",
      "Iteration 1360, loss = 0.00618501\n",
      "Iteration 1361, loss = 0.00617914\n",
      "Iteration 1362, loss = 0.00617178\n",
      "Iteration 1363, loss = 0.00616580\n",
      "Iteration 1364, loss = 0.00615909\n",
      "Iteration 1365, loss = 0.00615311\n",
      "Iteration 1366, loss = 0.00614660\n",
      "Iteration 1367, loss = 0.00614009\n",
      "Iteration 1368, loss = 0.00613397\n",
      "Iteration 1369, loss = 0.00612738\n",
      "Iteration 1370, loss = 0.00612138\n",
      "Iteration 1371, loss = 0.00611619\n",
      "Iteration 1372, loss = 0.00610945\n",
      "Iteration 1373, loss = 0.00610321\n",
      "Iteration 1374, loss = 0.00609692\n",
      "Iteration 1375, loss = 0.00609103\n",
      "Iteration 1376, loss = 0.00608443\n",
      "Iteration 1377, loss = 0.00607827\n",
      "Iteration 1378, loss = 0.00607298\n",
      "Iteration 1379, loss = 0.00606716\n",
      "Iteration 1380, loss = 0.00605998\n",
      "Iteration 1381, loss = 0.00605413\n",
      "Iteration 1382, loss = 0.00604817\n",
      "Iteration 1383, loss = 0.00604165\n",
      "Iteration 1384, loss = 0.00603505\n",
      "Iteration 1385, loss = 0.00602911\n",
      "Iteration 1386, loss = 0.00602344\n",
      "Iteration 1387, loss = 0.00601679\n",
      "Iteration 1388, loss = 0.00601072\n",
      "Iteration 1389, loss = 0.00600435\n",
      "Iteration 1390, loss = 0.00599918\n",
      "Iteration 1391, loss = 0.00599284\n",
      "Iteration 1392, loss = 0.00598714\n",
      "Iteration 1393, loss = 0.00598115\n",
      "Iteration 1394, loss = 0.00597500\n",
      "Iteration 1395, loss = 0.00596903\n",
      "Iteration 1396, loss = 0.00596267\n",
      "Iteration 1397, loss = 0.00595680\n",
      "Iteration 1398, loss = 0.00595021\n",
      "Iteration 1399, loss = 0.00594577\n",
      "Iteration 1400, loss = 0.00593956\n",
      "Iteration 1401, loss = 0.00593365\n",
      "Iteration 1402, loss = 0.00592789\n",
      "Iteration 1403, loss = 0.00592205\n",
      "Iteration 1404, loss = 0.00591623\n",
      "Iteration 1405, loss = 0.00591022\n",
      "Iteration 1406, loss = 0.00590474\n",
      "Iteration 1407, loss = 0.00589913\n",
      "Iteration 1408, loss = 0.00589387\n",
      "Iteration 1409, loss = 0.00588741\n",
      "Iteration 1410, loss = 0.00588122\n",
      "Iteration 1411, loss = 0.00587566\n",
      "Iteration 1412, loss = 0.00586993\n",
      "Iteration 1413, loss = 0.00586458\n",
      "Iteration 1414, loss = 0.00585843\n",
      "Iteration 1415, loss = 0.00585370\n",
      "Iteration 1416, loss = 0.00584683\n",
      "Iteration 1417, loss = 0.00584140\n",
      "Iteration 1418, loss = 0.00583568\n",
      "Iteration 1419, loss = 0.00582957\n",
      "Iteration 1420, loss = 0.00582431\n",
      "Iteration 1421, loss = 0.00581864\n",
      "Iteration 1422, loss = 0.00581320\n",
      "Iteration 1423, loss = 0.00580811\n",
      "Iteration 1424, loss = 0.00580204\n",
      "Iteration 1425, loss = 0.00579641\n",
      "Iteration 1426, loss = 0.00579123\n",
      "Iteration 1427, loss = 0.00578539\n",
      "Iteration 1428, loss = 0.00578030\n",
      "Iteration 1429, loss = 0.00577473\n",
      "Iteration 1430, loss = 0.00576904\n",
      "Iteration 1431, loss = 0.00576378\n",
      "Iteration 1432, loss = 0.00575723\n",
      "Iteration 1433, loss = 0.00575163\n",
      "Iteration 1434, loss = 0.00574579\n",
      "Iteration 1435, loss = 0.00574050\n",
      "Iteration 1436, loss = 0.00573590\n",
      "Iteration 1437, loss = 0.00572922\n",
      "Iteration 1438, loss = 0.00572375\n",
      "Iteration 1439, loss = 0.00571840\n",
      "Iteration 1440, loss = 0.00571297\n",
      "Iteration 1441, loss = 0.00570762\n",
      "Iteration 1442, loss = 0.00570202\n",
      "Iteration 1443, loss = 0.00569697\n",
      "Iteration 1444, loss = 0.00569210\n",
      "Iteration 1445, loss = 0.00568633\n",
      "Iteration 1446, loss = 0.00568137\n",
      "Iteration 1447, loss = 0.00567600\n",
      "Iteration 1448, loss = 0.00567077\n",
      "Iteration 1449, loss = 0.00566550\n",
      "Iteration 1450, loss = 0.00566022\n",
      "Iteration 1451, loss = 0.00565532\n",
      "Iteration 1452, loss = 0.00564980\n",
      "Iteration 1453, loss = 0.00564568\n",
      "Iteration 1454, loss = 0.00563999\n",
      "Iteration 1455, loss = 0.00563386\n",
      "Iteration 1456, loss = 0.00562860\n",
      "Iteration 1457, loss = 0.00562346\n",
      "Iteration 1458, loss = 0.00561776\n",
      "Iteration 1459, loss = 0.00561266\n",
      "Iteration 1460, loss = 0.00560708\n",
      "Iteration 1461, loss = 0.00560257\n",
      "Iteration 1462, loss = 0.00559622\n",
      "Iteration 1463, loss = 0.00559113\n",
      "Iteration 1464, loss = 0.00558570\n",
      "Iteration 1465, loss = 0.00557992\n",
      "Iteration 1466, loss = 0.00557479\n",
      "Iteration 1467, loss = 0.00557032\n",
      "Iteration 1468, loss = 0.00556432\n",
      "Iteration 1469, loss = 0.00555897\n",
      "Iteration 1470, loss = 0.00555375\n",
      "Iteration 1471, loss = 0.00554849\n",
      "Iteration 1472, loss = 0.00554328\n",
      "Iteration 1473, loss = 0.00553819\n",
      "Iteration 1474, loss = 0.00553304\n",
      "Iteration 1475, loss = 0.00552756\n",
      "Iteration 1476, loss = 0.00552434\n",
      "Iteration 1477, loss = 0.00551758\n",
      "Iteration 1478, loss = 0.00551235\n",
      "Iteration 1479, loss = 0.00550672\n",
      "Iteration 1480, loss = 0.00550213\n",
      "Iteration 1481, loss = 0.00549674\n",
      "Iteration 1482, loss = 0.00549267\n",
      "Iteration 1483, loss = 0.00548697\n",
      "Iteration 1484, loss = 0.00548141\n",
      "Iteration 1485, loss = 0.00547638\n",
      "Iteration 1486, loss = 0.00547179\n",
      "Iteration 1487, loss = 0.00546692\n",
      "Iteration 1488, loss = 0.00546180\n",
      "Iteration 1489, loss = 0.00545643\n",
      "Iteration 1490, loss = 0.00545157\n",
      "Iteration 1491, loss = 0.00544659\n",
      "Iteration 1492, loss = 0.00544136\n",
      "Iteration 1493, loss = 0.00543659\n",
      "Iteration 1494, loss = 0.00543156\n",
      "Iteration 1495, loss = 0.00542646\n",
      "Iteration 1496, loss = 0.00542145\n",
      "Iteration 1497, loss = 0.00541655\n",
      "Iteration 1498, loss = 0.00541122\n",
      "Iteration 1499, loss = 0.00540613\n",
      "Iteration 1500, loss = 0.00540151\n",
      "Iteration 1501, loss = 0.00539579\n",
      "Iteration 1502, loss = 0.00539103\n",
      "Iteration 1503, loss = 0.00538602\n",
      "Iteration 1504, loss = 0.00538141\n",
      "Iteration 1505, loss = 0.00537660\n",
      "Iteration 1506, loss = 0.00537166\n",
      "Iteration 1507, loss = 0.00536608\n",
      "Iteration 1508, loss = 0.00536153\n",
      "Iteration 1509, loss = 0.00535630\n",
      "Iteration 1510, loss = 0.00535163\n",
      "Iteration 1511, loss = 0.00534637\n",
      "Iteration 1512, loss = 0.00534163\n",
      "Iteration 1513, loss = 0.00533700\n",
      "Iteration 1514, loss = 0.00533271\n",
      "Iteration 1515, loss = 0.00532778\n",
      "Iteration 1516, loss = 0.00532246\n",
      "Iteration 1517, loss = 0.00531779\n",
      "Iteration 1518, loss = 0.00531397\n",
      "Iteration 1519, loss = 0.00530837\n",
      "Iteration 1520, loss = 0.00530417\n",
      "Iteration 1521, loss = 0.00529916\n",
      "Iteration 1522, loss = 0.00529435\n",
      "Iteration 1523, loss = 0.00528967\n",
      "Iteration 1524, loss = 0.00528488\n",
      "Iteration 1525, loss = 0.00527983\n",
      "Iteration 1526, loss = 0.00527508\n",
      "Iteration 1527, loss = 0.00527055\n",
      "Iteration 1528, loss = 0.00526663\n",
      "Iteration 1529, loss = 0.00526143\n",
      "Iteration 1530, loss = 0.00525602\n",
      "Iteration 1531, loss = 0.00525163\n",
      "Iteration 1532, loss = 0.00524760\n",
      "Iteration 1533, loss = 0.00524223\n",
      "Iteration 1534, loss = 0.00523713\n",
      "Iteration 1535, loss = 0.00523264\n",
      "Iteration 1536, loss = 0.00522786\n",
      "Iteration 1537, loss = 0.00522296\n",
      "Iteration 1538, loss = 0.00521873\n",
      "Iteration 1539, loss = 0.00521357\n",
      "Iteration 1540, loss = 0.00520894\n",
      "Iteration 1541, loss = 0.00520427\n",
      "Iteration 1542, loss = 0.00519972\n",
      "Iteration 1543, loss = 0.00519523\n",
      "Iteration 1544, loss = 0.00519008\n",
      "Iteration 1545, loss = 0.00518531\n",
      "Iteration 1546, loss = 0.00518086\n",
      "Iteration 1547, loss = 0.00517589\n",
      "Iteration 1548, loss = 0.00517123\n",
      "Iteration 1549, loss = 0.00516697\n",
      "Iteration 1550, loss = 0.00516257\n",
      "Iteration 1551, loss = 0.00515795\n",
      "Iteration 1552, loss = 0.00515303\n",
      "Iteration 1553, loss = 0.00514894\n",
      "Iteration 1554, loss = 0.00514408\n",
      "Iteration 1555, loss = 0.00513963\n",
      "Iteration 1556, loss = 0.00513566\n",
      "Iteration 1557, loss = 0.00513077\n",
      "Iteration 1558, loss = 0.00512671\n",
      "Iteration 1559, loss = 0.00512159\n",
      "Iteration 1560, loss = 0.00511727\n",
      "Iteration 1561, loss = 0.00511322\n",
      "Iteration 1562, loss = 0.00510816\n",
      "Iteration 1563, loss = 0.00510303\n",
      "Iteration 1564, loss = 0.00509898\n",
      "Iteration 1565, loss = 0.00509416\n",
      "Iteration 1566, loss = 0.00508982\n",
      "Iteration 1567, loss = 0.00508516\n",
      "Iteration 1568, loss = 0.00508053\n",
      "Iteration 1569, loss = 0.00507617\n",
      "Iteration 1570, loss = 0.00507124\n",
      "Iteration 1571, loss = 0.00506662\n",
      "Iteration 1572, loss = 0.00506276\n",
      "Iteration 1573, loss = 0.00505793\n",
      "Iteration 1574, loss = 0.00505317\n",
      "Iteration 1575, loss = 0.00504895\n",
      "Iteration 1576, loss = 0.00504449\n",
      "Iteration 1577, loss = 0.00504063\n",
      "Iteration 1578, loss = 0.00503570\n",
      "Iteration 1579, loss = 0.00503066\n",
      "Iteration 1580, loss = 0.00502786\n",
      "Iteration 1581, loss = 0.00502258\n",
      "Iteration 1582, loss = 0.00501735\n",
      "Iteration 1583, loss = 0.00501366\n",
      "Iteration 1584, loss = 0.00500851\n",
      "Iteration 1585, loss = 0.00500474\n",
      "Iteration 1586, loss = 0.00500046\n",
      "Iteration 1587, loss = 0.00499572\n",
      "Iteration 1588, loss = 0.00499163\n",
      "Iteration 1589, loss = 0.00498755\n",
      "Iteration 1590, loss = 0.00498299\n",
      "Iteration 1591, loss = 0.00497815\n",
      "Iteration 1592, loss = 0.00497371\n",
      "Iteration 1593, loss = 0.00497008\n",
      "Iteration 1594, loss = 0.00496557\n",
      "Iteration 1595, loss = 0.00496126\n",
      "Iteration 1596, loss = 0.00495671\n",
      "Iteration 1597, loss = 0.00495250\n",
      "Iteration 1598, loss = 0.00494796\n",
      "Iteration 1599, loss = 0.00494429\n",
      "Iteration 1600, loss = 0.00493995\n",
      "Iteration 1601, loss = 0.00493528\n",
      "Iteration 1602, loss = 0.00493086\n",
      "Iteration 1603, loss = 0.00492679\n",
      "Iteration 1604, loss = 0.00492265\n",
      "Iteration 1605, loss = 0.00491839\n",
      "Iteration 1606, loss = 0.00491400\n",
      "Iteration 1607, loss = 0.00490976\n",
      "Iteration 1608, loss = 0.00490570\n",
      "Iteration 1609, loss = 0.00490167\n",
      "Iteration 1610, loss = 0.00489707\n",
      "Iteration 1611, loss = 0.00489300\n",
      "Iteration 1612, loss = 0.00488905\n",
      "Iteration 1613, loss = 0.00488481\n",
      "Iteration 1614, loss = 0.00488096\n",
      "Iteration 1615, loss = 0.00487671\n",
      "Iteration 1616, loss = 0.00487215\n",
      "Iteration 1617, loss = 0.00486853\n",
      "Iteration 1618, loss = 0.00486380\n",
      "Iteration 1619, loss = 0.00486006\n",
      "Iteration 1620, loss = 0.00485555\n",
      "Iteration 1621, loss = 0.00485132\n",
      "Iteration 1622, loss = 0.00484753\n",
      "Iteration 1623, loss = 0.00484329\n",
      "Iteration 1624, loss = 0.00483892\n",
      "Iteration 1625, loss = 0.00483492\n",
      "Iteration 1626, loss = 0.00483086\n",
      "Iteration 1627, loss = 0.00482717\n",
      "Iteration 1628, loss = 0.00482298\n",
      "Iteration 1629, loss = 0.00481898\n",
      "Iteration 1630, loss = 0.00481486\n",
      "Iteration 1631, loss = 0.00481096\n",
      "Iteration 1632, loss = 0.00480681\n",
      "Iteration 1633, loss = 0.00480266\n",
      "Iteration 1634, loss = 0.00479943\n",
      "Iteration 1635, loss = 0.00479481\n",
      "Iteration 1636, loss = 0.00479096\n",
      "Iteration 1637, loss = 0.00478771\n",
      "Iteration 1638, loss = 0.00478327\n",
      "Iteration 1639, loss = 0.00477848\n",
      "Iteration 1640, loss = 0.00477442\n",
      "Iteration 1641, loss = 0.00477021\n",
      "Iteration 1642, loss = 0.00476623\n",
      "Iteration 1643, loss = 0.00476264\n",
      "Iteration 1644, loss = 0.00475864\n",
      "Iteration 1645, loss = 0.00475389\n",
      "Iteration 1646, loss = 0.00475031\n",
      "Iteration 1647, loss = 0.00474604\n",
      "Iteration 1648, loss = 0.00474275\n",
      "Iteration 1649, loss = 0.00473785\n",
      "Iteration 1650, loss = 0.00473421\n",
      "Iteration 1651, loss = 0.00473043\n",
      "Iteration 1652, loss = 0.00472668\n",
      "Iteration 1653, loss = 0.00472204\n",
      "Iteration 1654, loss = 0.00471793\n",
      "Iteration 1655, loss = 0.00471416\n",
      "Iteration 1656, loss = 0.00471031\n",
      "Iteration 1657, loss = 0.00470688\n",
      "Iteration 1658, loss = 0.00470250\n",
      "Iteration 1659, loss = 0.00469837\n",
      "Iteration 1660, loss = 0.00469453\n",
      "Iteration 1661, loss = 0.00469062\n",
      "Iteration 1662, loss = 0.00468686\n",
      "Iteration 1663, loss = 0.00468276\n",
      "Iteration 1664, loss = 0.00467897\n",
      "Iteration 1665, loss = 0.00467480\n",
      "Iteration 1666, loss = 0.00467092\n",
      "Iteration 1667, loss = 0.00466714\n",
      "Iteration 1668, loss = 0.00466324\n",
      "Iteration 1669, loss = 0.00465932\n",
      "Iteration 1670, loss = 0.00465538\n",
      "Iteration 1671, loss = 0.00465162\n",
      "Iteration 1672, loss = 0.00464796\n",
      "Iteration 1673, loss = 0.00464416\n",
      "Iteration 1674, loss = 0.00464001\n",
      "Iteration 1675, loss = 0.00463629\n",
      "Iteration 1676, loss = 0.00463277\n",
      "Iteration 1677, loss = 0.00462894\n",
      "Iteration 1678, loss = 0.00462474\n",
      "Iteration 1679, loss = 0.00462118\n",
      "Iteration 1680, loss = 0.00461748\n",
      "Iteration 1681, loss = 0.00461324\n",
      "Iteration 1682, loss = 0.00460991\n",
      "Iteration 1683, loss = 0.00460639\n",
      "Iteration 1684, loss = 0.00460245\n",
      "Iteration 1685, loss = 0.00459816\n",
      "Iteration 1686, loss = 0.00459451\n",
      "Iteration 1687, loss = 0.00459105\n",
      "Iteration 1688, loss = 0.00458702\n",
      "Iteration 1689, loss = 0.00458354\n",
      "Iteration 1690, loss = 0.00457979\n",
      "Iteration 1691, loss = 0.00457593\n",
      "Iteration 1692, loss = 0.00457208\n",
      "Iteration 1693, loss = 0.00456836\n",
      "Iteration 1694, loss = 0.00456488\n",
      "Iteration 1695, loss = 0.00456138\n",
      "Iteration 1696, loss = 0.00455789\n",
      "Iteration 1697, loss = 0.00455357\n",
      "Iteration 1698, loss = 0.00454965\n",
      "Iteration 1699, loss = 0.00454593\n",
      "Iteration 1700, loss = 0.00454276\n",
      "Iteration 1701, loss = 0.00453882\n",
      "Iteration 1702, loss = 0.00453536\n",
      "Iteration 1703, loss = 0.00453146\n",
      "Iteration 1704, loss = 0.00452786\n",
      "Iteration 1705, loss = 0.00452418\n",
      "Iteration 1706, loss = 0.00452048\n",
      "Iteration 1707, loss = 0.00451685\n",
      "Iteration 1708, loss = 0.00451307\n",
      "Iteration 1709, loss = 0.00450979\n",
      "Iteration 1710, loss = 0.00450610\n",
      "Iteration 1711, loss = 0.00450244\n",
      "Iteration 1712, loss = 0.00449870\n",
      "Iteration 1713, loss = 0.00449501\n",
      "Iteration 1714, loss = 0.00449173\n",
      "Iteration 1715, loss = 0.00448771\n",
      "Iteration 1716, loss = 0.00448406\n",
      "Iteration 1717, loss = 0.00448069\n",
      "Iteration 1718, loss = 0.00447685\n",
      "Iteration 1719, loss = 0.00447339\n",
      "Iteration 1720, loss = 0.00446952\n",
      "Iteration 1721, loss = 0.00446611\n",
      "Iteration 1722, loss = 0.00446256\n",
      "Iteration 1723, loss = 0.00445890\n",
      "Iteration 1724, loss = 0.00445513\n",
      "Iteration 1725, loss = 0.00445220\n",
      "Iteration 1726, loss = 0.00444825\n",
      "Iteration 1727, loss = 0.00444455\n",
      "Iteration 1728, loss = 0.00444125\n",
      "Iteration 1729, loss = 0.00443736\n",
      "Iteration 1730, loss = 0.00443450\n",
      "Iteration 1731, loss = 0.00443009\n",
      "Iteration 1732, loss = 0.00442657\n",
      "Iteration 1733, loss = 0.00442347\n",
      "Iteration 1734, loss = 0.00441923\n",
      "Iteration 1735, loss = 0.00441607\n",
      "Iteration 1736, loss = 0.00441261\n",
      "Iteration 1737, loss = 0.00440923\n",
      "Iteration 1738, loss = 0.00440583\n",
      "Iteration 1739, loss = 0.00440201\n",
      "Iteration 1740, loss = 0.00439877\n",
      "Iteration 1741, loss = 0.00439530\n",
      "Iteration 1742, loss = 0.00439170\n",
      "Iteration 1743, loss = 0.00438811\n",
      "Iteration 1744, loss = 0.00438467\n",
      "Iteration 1745, loss = 0.00438106\n",
      "Iteration 1746, loss = 0.00437786\n",
      "Iteration 1747, loss = 0.00437461\n",
      "Iteration 1748, loss = 0.00437121\n",
      "Iteration 1749, loss = 0.00436739\n",
      "Iteration 1750, loss = 0.00436412\n",
      "Iteration 1751, loss = 0.00436055\n",
      "Iteration 1752, loss = 0.00435746\n",
      "Iteration 1753, loss = 0.00435396\n",
      "Iteration 1754, loss = 0.00435039\n",
      "Iteration 1755, loss = 0.00434710\n",
      "Iteration 1756, loss = 0.00434320\n",
      "Iteration 1757, loss = 0.00433999\n",
      "Iteration 1758, loss = 0.00433669\n",
      "Iteration 1759, loss = 0.00433443\n",
      "Iteration 1760, loss = 0.00433011\n",
      "Iteration 1761, loss = 0.00432648\n",
      "Iteration 1762, loss = 0.00432370\n",
      "Iteration 1763, loss = 0.00431978\n",
      "Iteration 1764, loss = 0.00431650\n",
      "Iteration 1765, loss = 0.00431304\n",
      "Iteration 1766, loss = 0.00430980\n",
      "Iteration 1767, loss = 0.00430677\n",
      "Iteration 1768, loss = 0.00430366\n",
      "Iteration 1769, loss = 0.00429995\n",
      "Iteration 1770, loss = 0.00429679\n",
      "Iteration 1771, loss = 0.00429358\n",
      "Iteration 1772, loss = 0.00429037\n",
      "Iteration 1773, loss = 0.00428672\n",
      "Iteration 1774, loss = 0.00428392\n",
      "Iteration 1775, loss = 0.00428009\n",
      "Iteration 1776, loss = 0.00427690\n",
      "Iteration 1777, loss = 0.00427344\n",
      "Iteration 1778, loss = 0.00427019\n",
      "Iteration 1779, loss = 0.00426678\n",
      "Iteration 1780, loss = 0.00426361\n",
      "Iteration 1781, loss = 0.00426022\n",
      "Iteration 1782, loss = 0.00425691\n",
      "Iteration 1783, loss = 0.00425367\n",
      "Iteration 1784, loss = 0.00425025\n",
      "Iteration 1785, loss = 0.00424691\n",
      "Iteration 1786, loss = 0.00424346\n",
      "Iteration 1787, loss = 0.00424029\n",
      "Iteration 1788, loss = 0.00423694\n",
      "Iteration 1789, loss = 0.00423368\n",
      "Iteration 1790, loss = 0.00423014\n",
      "Iteration 1791, loss = 0.00422666\n",
      "Iteration 1792, loss = 0.00422322\n",
      "Iteration 1793, loss = 0.00422008\n",
      "Iteration 1794, loss = 0.00421672\n",
      "Iteration 1795, loss = 0.00421357\n",
      "Iteration 1796, loss = 0.00421057\n",
      "Iteration 1797, loss = 0.00420703\n",
      "Iteration 1798, loss = 0.00420352\n",
      "Iteration 1799, loss = 0.00420048\n",
      "Iteration 1800, loss = 0.00419769\n",
      "Iteration 1801, loss = 0.00419472\n",
      "Iteration 1802, loss = 0.00419086\n",
      "Iteration 1803, loss = 0.00418766\n",
      "Iteration 1804, loss = 0.00418484\n",
      "Iteration 1805, loss = 0.00418160\n",
      "Iteration 1806, loss = 0.00417858\n",
      "Iteration 1807, loss = 0.00417503\n",
      "Iteration 1808, loss = 0.00417187\n",
      "Iteration 1809, loss = 0.00416970\n",
      "Iteration 1810, loss = 0.00416565\n",
      "Iteration 1811, loss = 0.00416241\n",
      "Iteration 1812, loss = 0.00415962\n",
      "Iteration 1813, loss = 0.00415628\n",
      "Iteration 1814, loss = 0.00415320\n",
      "Iteration 1815, loss = 0.00415010\n",
      "Iteration 1816, loss = 0.00414694\n",
      "Iteration 1817, loss = 0.00414397\n",
      "Iteration 1818, loss = 0.00414070\n",
      "Iteration 1819, loss = 0.00413752\n",
      "Iteration 1820, loss = 0.00413448\n",
      "Iteration 1821, loss = 0.00413183\n",
      "Iteration 1822, loss = 0.00412836\n",
      "Iteration 1823, loss = 0.00412518\n",
      "Iteration 1824, loss = 0.00412218\n",
      "Iteration 1825, loss = 0.00411870\n",
      "Iteration 1826, loss = 0.00411579\n",
      "Iteration 1827, loss = 0.00411262\n",
      "Iteration 1828, loss = 0.00410958\n",
      "Iteration 1829, loss = 0.00410673\n",
      "Iteration 1830, loss = 0.00410347\n",
      "Iteration 1831, loss = 0.00410071\n",
      "Iteration 1832, loss = 0.00409719\n",
      "Iteration 1833, loss = 0.00409408\n",
      "Iteration 1834, loss = 0.00409121\n",
      "Iteration 1835, loss = 0.00408796\n",
      "Iteration 1836, loss = 0.00408482\n",
      "Iteration 1837, loss = 0.00408194\n",
      "Iteration 1838, loss = 0.00407864\n",
      "Iteration 1839, loss = 0.00407581\n",
      "Iteration 1840, loss = 0.00407245\n",
      "Iteration 1841, loss = 0.00406983\n",
      "Iteration 1842, loss = 0.00406628\n",
      "Iteration 1843, loss = 0.00406366\n",
      "Iteration 1844, loss = 0.00406050\n",
      "Iteration 1845, loss = 0.00405753\n",
      "Iteration 1846, loss = 0.00405429\n",
      "Iteration 1847, loss = 0.00405142\n",
      "Iteration 1848, loss = 0.00404890\n",
      "Iteration 1849, loss = 0.00404528\n",
      "Iteration 1850, loss = 0.00404284\n",
      "Iteration 1851, loss = 0.00403978\n",
      "Iteration 1852, loss = 0.00403654\n",
      "Iteration 1853, loss = 0.00403347\n",
      "Iteration 1854, loss = 0.00403069\n",
      "Iteration 1855, loss = 0.00402772\n",
      "Iteration 1856, loss = 0.00402475\n",
      "Iteration 1857, loss = 0.00402204\n",
      "Iteration 1858, loss = 0.00401884\n",
      "Iteration 1859, loss = 0.00401602\n",
      "Iteration 1860, loss = 0.00401313\n",
      "Iteration 1861, loss = 0.00400996\n",
      "Iteration 1862, loss = 0.00400724\n",
      "Iteration 1863, loss = 0.00400466\n",
      "Iteration 1864, loss = 0.00400119\n",
      "Iteration 1865, loss = 0.00399832\n",
      "Iteration 1866, loss = 0.00399572\n",
      "Iteration 1867, loss = 0.00399236\n",
      "Iteration 1868, loss = 0.00398942\n",
      "Iteration 1869, loss = 0.00398682\n",
      "Iteration 1870, loss = 0.00398342\n",
      "Iteration 1871, loss = 0.00398080\n",
      "Iteration 1872, loss = 0.00397852\n",
      "Iteration 1873, loss = 0.00397493\n",
      "Iteration 1874, loss = 0.00397227\n",
      "Iteration 1875, loss = 0.00396891\n",
      "Iteration 1876, loss = 0.00396609\n",
      "Iteration 1877, loss = 0.00396362\n",
      "Iteration 1878, loss = 0.00396019\n",
      "Iteration 1879, loss = 0.00395762\n",
      "Iteration 1880, loss = 0.00395452\n",
      "Iteration 1881, loss = 0.00395205\n",
      "Iteration 1882, loss = 0.00394907\n",
      "Iteration 1883, loss = 0.00394607\n",
      "Iteration 1884, loss = 0.00394344\n",
      "Iteration 1885, loss = 0.00394036\n",
      "Iteration 1886, loss = 0.00393736\n",
      "Iteration 1887, loss = 0.00393460\n",
      "Iteration 1888, loss = 0.00393178\n",
      "Iteration 1889, loss = 0.00392897\n",
      "Iteration 1890, loss = 0.00392565\n",
      "Iteration 1891, loss = 0.00392335\n",
      "Iteration 1892, loss = 0.00392025\n",
      "Iteration 1893, loss = 0.00391782\n",
      "Iteration 1894, loss = 0.00391447\n",
      "Iteration 1895, loss = 0.00391165\n",
      "Iteration 1896, loss = 0.00390885\n",
      "Iteration 1897, loss = 0.00390630\n",
      "Iteration 1898, loss = 0.00390312\n",
      "Iteration 1899, loss = 0.00390024\n",
      "Iteration 1900, loss = 0.00389765\n",
      "Iteration 1901, loss = 0.00389498\n",
      "Iteration 1902, loss = 0.00389172\n",
      "Iteration 1903, loss = 0.00388898\n",
      "Iteration 1904, loss = 0.00388618\n",
      "Iteration 1905, loss = 0.00388348\n",
      "Iteration 1906, loss = 0.00388075\n",
      "Iteration 1907, loss = 0.00387811\n",
      "Iteration 1908, loss = 0.00387549\n",
      "Iteration 1909, loss = 0.00387245\n",
      "Iteration 1910, loss = 0.00386984\n",
      "Iteration 1911, loss = 0.00386730\n",
      "Iteration 1912, loss = 0.00386425\n",
      "Iteration 1913, loss = 0.00386119\n",
      "Iteration 1914, loss = 0.00385846\n",
      "Iteration 1915, loss = 0.00385568\n",
      "Iteration 1916, loss = 0.00385303\n",
      "Iteration 1917, loss = 0.00384998\n",
      "Iteration 1918, loss = 0.00384750\n",
      "Iteration 1919, loss = 0.00384459\n",
      "Iteration 1920, loss = 0.00384218\n",
      "Iteration 1921, loss = 0.00383894\n",
      "Iteration 1922, loss = 0.00383619\n",
      "Iteration 1923, loss = 0.00383359\n",
      "Iteration 1924, loss = 0.00383080\n",
      "Iteration 1925, loss = 0.00382819\n",
      "Iteration 1926, loss = 0.00382574\n",
      "Iteration 1927, loss = 0.00382258\n",
      "Iteration 1928, loss = 0.00381966\n",
      "Iteration 1929, loss = 0.00381700\n",
      "Iteration 1930, loss = 0.00381421\n",
      "Iteration 1931, loss = 0.00381183\n",
      "Iteration 1932, loss = 0.00380891\n",
      "Iteration 1933, loss = 0.00380626\n",
      "Iteration 1934, loss = 0.00380354\n",
      "Iteration 1935, loss = 0.00380091\n",
      "Iteration 1936, loss = 0.00379825\n",
      "Iteration 1937, loss = 0.00379579\n",
      "Iteration 1938, loss = 0.00379292\n",
      "Iteration 1939, loss = 0.00379048\n",
      "Iteration 1940, loss = 0.00378758\n",
      "Iteration 1941, loss = 0.00378493\n",
      "Iteration 1942, loss = 0.00378214\n",
      "Iteration 1943, loss = 0.00377985\n",
      "Iteration 1944, loss = 0.00377676\n",
      "Iteration 1945, loss = 0.00377414\n",
      "Iteration 1946, loss = 0.00377114\n",
      "Iteration 1947, loss = 0.00376869\n",
      "Iteration 1948, loss = 0.00376593\n",
      "Iteration 1949, loss = 0.00376374\n",
      "Iteration 1950, loss = 0.00376085\n",
      "Iteration 1951, loss = 0.00375814\n",
      "Iteration 1952, loss = 0.00375555\n",
      "Iteration 1953, loss = 0.00375286\n",
      "Iteration 1954, loss = 0.00375026\n",
      "Iteration 1955, loss = 0.00374764\n",
      "Iteration 1956, loss = 0.00374533\n",
      "Iteration 1957, loss = 0.00374252\n",
      "Iteration 1958, loss = 0.00373992\n",
      "Iteration 1959, loss = 0.00373733\n",
      "Iteration 1960, loss = 0.00373462\n",
      "Iteration 1961, loss = 0.00373199\n",
      "Iteration 1962, loss = 0.00372929\n",
      "Iteration 1963, loss = 0.00372692\n",
      "Iteration 1964, loss = 0.00372422\n",
      "Iteration 1965, loss = 0.00372156\n",
      "Iteration 1966, loss = 0.00371908\n",
      "Iteration 1967, loss = 0.00371657\n",
      "Iteration 1968, loss = 0.00371405\n",
      "Iteration 1969, loss = 0.00371170\n",
      "Iteration 1970, loss = 0.00370938\n",
      "Iteration 1971, loss = 0.00370671\n",
      "Iteration 1972, loss = 0.00370388\n",
      "Iteration 1973, loss = 0.00370187\n",
      "Iteration 1974, loss = 0.00369902\n",
      "Iteration 1975, loss = 0.00369630\n",
      "Iteration 1976, loss = 0.00369354\n",
      "Iteration 1977, loss = 0.00369109\n",
      "Iteration 1978, loss = 0.00368853\n",
      "Iteration 1979, loss = 0.00368592\n",
      "Iteration 1980, loss = 0.00368307\n",
      "Iteration 1981, loss = 0.00368052\n",
      "Iteration 1982, loss = 0.00367823\n",
      "Iteration 1983, loss = 0.00367562\n",
      "Iteration 1984, loss = 0.00367307\n",
      "Iteration 1985, loss = 0.00367088\n",
      "Iteration 1986, loss = 0.00366789\n",
      "Iteration 1987, loss = 0.00366538\n",
      "Iteration 1988, loss = 0.00366265\n",
      "Iteration 1989, loss = 0.00366014\n",
      "Iteration 1990, loss = 0.00365785\n",
      "Iteration 1991, loss = 0.00365529\n",
      "Iteration 1992, loss = 0.00365258\n",
      "Iteration 1993, loss = 0.00365009\n",
      "Iteration 1994, loss = 0.00364750\n",
      "Iteration 1995, loss = 0.00364538\n",
      "Iteration 1996, loss = 0.00364269\n",
      "Iteration 1997, loss = 0.00364016\n",
      "Iteration 1998, loss = 0.00363758\n",
      "Iteration 1999, loss = 0.00363517\n",
      "Iteration 2000, loss = 0.00363303\n",
      "Iteration 2001, loss = 0.00363060\n",
      "Iteration 2002, loss = 0.00362794\n",
      "Iteration 2003, loss = 0.00362555\n",
      "Iteration 2004, loss = 0.00362256\n",
      "Iteration 2005, loss = 0.00362031\n",
      "Iteration 2006, loss = 0.00361806\n",
      "Iteration 2007, loss = 0.00361501\n",
      "Iteration 2008, loss = 0.00361275\n",
      "Iteration 2009, loss = 0.00361006\n",
      "Iteration 2010, loss = 0.00360746\n",
      "Iteration 2011, loss = 0.00360520\n",
      "Iteration 2012, loss = 0.00360276\n",
      "Iteration 2013, loss = 0.00360010\n",
      "Iteration 2014, loss = 0.00359807\n",
      "Iteration 2015, loss = 0.00359508\n",
      "Iteration 2016, loss = 0.00359234\n",
      "Iteration 2017, loss = 0.00359017\n",
      "Iteration 2018, loss = 0.00358771\n",
      "Iteration 2019, loss = 0.00358524\n",
      "Iteration 2020, loss = 0.00358296\n",
      "Iteration 2021, loss = 0.00358018\n",
      "Iteration 2022, loss = 0.00357787\n",
      "Iteration 2023, loss = 0.00357524\n",
      "Iteration 2024, loss = 0.00357298\n",
      "Iteration 2025, loss = 0.00357058\n",
      "Iteration 2026, loss = 0.00356838\n",
      "Iteration 2027, loss = 0.00356551\n",
      "Iteration 2028, loss = 0.00356326\n",
      "Iteration 2029, loss = 0.00356056\n",
      "Iteration 2030, loss = 0.00355859\n",
      "Iteration 2031, loss = 0.00355578\n",
      "Iteration 2032, loss = 0.00355354\n",
      "Iteration 2033, loss = 0.00355117\n",
      "Iteration 2034, loss = 0.00354869\n",
      "Iteration 2035, loss = 0.00354676\n",
      "Iteration 2036, loss = 0.00354408\n",
      "Iteration 2037, loss = 0.00354252\n",
      "Iteration 2038, loss = 0.00353919\n",
      "Iteration 2039, loss = 0.00353677\n",
      "Iteration 2040, loss = 0.00353486\n",
      "Iteration 2041, loss = 0.00353250\n",
      "Iteration 2042, loss = 0.00352992\n",
      "Iteration 2043, loss = 0.00352766\n",
      "Iteration 2044, loss = 0.00352540\n",
      "Iteration 2045, loss = 0.00352281\n",
      "Iteration 2046, loss = 0.00352024\n",
      "Iteration 2047, loss = 0.00351782\n",
      "Iteration 2048, loss = 0.00351554\n",
      "Iteration 2049, loss = 0.00351303\n",
      "Iteration 2050, loss = 0.00351072\n",
      "Iteration 2051, loss = 0.00350852\n",
      "Iteration 2052, loss = 0.00350584\n",
      "Iteration 2053, loss = 0.00350381\n",
      "Iteration 2054, loss = 0.00350133\n",
      "Iteration 2055, loss = 0.00349876\n",
      "Iteration 2056, loss = 0.00349678\n",
      "Iteration 2057, loss = 0.00349427\n",
      "Iteration 2058, loss = 0.00349186\n",
      "Iteration 2059, loss = 0.00348959\n",
      "Iteration 2060, loss = 0.00348734\n",
      "Iteration 2061, loss = 0.00348483\n",
      "Iteration 2062, loss = 0.00348247\n",
      "Iteration 2063, loss = 0.00348052\n",
      "Iteration 2064, loss = 0.00347806\n",
      "Iteration 2065, loss = 0.00347565\n",
      "Iteration 2066, loss = 0.00347351\n",
      "Iteration 2067, loss = 0.00347097\n",
      "Iteration 2068, loss = 0.00346859\n",
      "Iteration 2069, loss = 0.00346619\n",
      "Iteration 2070, loss = 0.00346413\n",
      "Iteration 2071, loss = 0.00346196\n",
      "Iteration 2072, loss = 0.00345958\n",
      "Iteration 2073, loss = 0.00345732\n",
      "Iteration 2074, loss = 0.00345508\n",
      "Iteration 2075, loss = 0.00345305\n",
      "Iteration 2076, loss = 0.00345069\n",
      "Iteration 2077, loss = 0.00344821\n",
      "Iteration 2078, loss = 0.00344585\n",
      "Iteration 2079, loss = 0.00344394\n",
      "Iteration 2080, loss = 0.00344150\n",
      "Iteration 2081, loss = 0.00343911\n",
      "Iteration 2082, loss = 0.00343683\n",
      "Iteration 2083, loss = 0.00343481\n",
      "Iteration 2084, loss = 0.00343254\n",
      "Iteration 2085, loss = 0.00343002\n",
      "Iteration 2086, loss = 0.00342779\n",
      "Iteration 2087, loss = 0.00342546\n",
      "Iteration 2088, loss = 0.00342347\n",
      "Iteration 2089, loss = 0.00342100\n",
      "Iteration 2090, loss = 0.00341865\n",
      "Iteration 2091, loss = 0.00341669\n",
      "Iteration 2092, loss = 0.00341437\n",
      "Iteration 2093, loss = 0.00341173\n",
      "Iteration 2094, loss = 0.00340963\n",
      "Iteration 2095, loss = 0.00340756\n",
      "Iteration 2096, loss = 0.00340516\n",
      "Iteration 2097, loss = 0.00340305\n",
      "Iteration 2098, loss = 0.00340078\n",
      "Iteration 2099, loss = 0.00339841\n",
      "Iteration 2100, loss = 0.00339639\n",
      "Iteration 2101, loss = 0.00339415\n",
      "Iteration 2102, loss = 0.00339193\n",
      "Iteration 2103, loss = 0.00338969\n",
      "Iteration 2104, loss = 0.00338737\n",
      "Iteration 2105, loss = 0.00338515\n",
      "Iteration 2106, loss = 0.00338290\n",
      "Iteration 2107, loss = 0.00338083\n",
      "Iteration 2108, loss = 0.00337872\n",
      "Iteration 2109, loss = 0.00337641\n",
      "Iteration 2110, loss = 0.00337437\n",
      "Iteration 2111, loss = 0.00337221\n",
      "Iteration 2112, loss = 0.00337010\n",
      "Iteration 2113, loss = 0.00336779\n",
      "Iteration 2114, loss = 0.00336587\n",
      "Iteration 2115, loss = 0.00336367\n",
      "Iteration 2116, loss = 0.00336151\n",
      "Iteration 2117, loss = 0.00335891\n",
      "Iteration 2118, loss = 0.00335728\n",
      "Iteration 2119, loss = 0.00335492\n",
      "Iteration 2120, loss = 0.00335239\n",
      "Iteration 2121, loss = 0.00335037\n",
      "Iteration 2122, loss = 0.00334821\n",
      "Iteration 2123, loss = 0.00334612\n",
      "Iteration 2124, loss = 0.00334397\n",
      "Iteration 2125, loss = 0.00334165\n",
      "Iteration 2126, loss = 0.00333941\n",
      "Iteration 2127, loss = 0.00333728\n",
      "Iteration 2128, loss = 0.00333515\n",
      "Iteration 2129, loss = 0.00333322\n",
      "Iteration 2130, loss = 0.00333084\n",
      "Iteration 2131, loss = 0.00332920\n",
      "Iteration 2132, loss = 0.00332650\n",
      "Iteration 2133, loss = 0.00332442\n",
      "Iteration 2134, loss = 0.00332233\n",
      "Iteration 2135, loss = 0.00332021\n",
      "Iteration 2136, loss = 0.00331791\n",
      "Iteration 2137, loss = 0.00331610\n",
      "Iteration 2138, loss = 0.00331361\n",
      "Iteration 2139, loss = 0.00331130\n",
      "Iteration 2140, loss = 0.00330910\n",
      "Iteration 2141, loss = 0.00330700\n",
      "Iteration 2142, loss = 0.00330471\n",
      "Iteration 2143, loss = 0.00330263\n",
      "Iteration 2144, loss = 0.00330105\n",
      "Iteration 2145, loss = 0.00329837\n",
      "Iteration 2146, loss = 0.00329601\n",
      "Iteration 2147, loss = 0.00329437\n",
      "Iteration 2148, loss = 0.00329197\n",
      "Iteration 2149, loss = 0.00329025\n",
      "Iteration 2150, loss = 0.00328774\n",
      "Iteration 2151, loss = 0.00328571\n",
      "Iteration 2152, loss = 0.00328362\n",
      "Iteration 2153, loss = 0.00328168\n",
      "Iteration 2154, loss = 0.00327951\n",
      "Iteration 2155, loss = 0.00327735\n",
      "Iteration 2156, loss = 0.00327542\n",
      "Iteration 2157, loss = 0.00327297\n",
      "Iteration 2158, loss = 0.00327093\n",
      "Iteration 2159, loss = 0.00326895\n",
      "Iteration 2160, loss = 0.00326688\n",
      "Iteration 2161, loss = 0.00326486\n",
      "Iteration 2162, loss = 0.00326286\n",
      "Iteration 2163, loss = 0.00326071\n",
      "Iteration 2164, loss = 0.00325867\n",
      "Iteration 2165, loss = 0.00325667\n",
      "Iteration 2166, loss = 0.00325477\n",
      "Iteration 2167, loss = 0.00325253\n",
      "Iteration 2168, loss = 0.00325045\n",
      "Iteration 2169, loss = 0.00324853\n",
      "Iteration 2170, loss = 0.00324665\n",
      "Iteration 2171, loss = 0.00324453\n",
      "Iteration 2172, loss = 0.00324245\n",
      "Iteration 2173, loss = 0.00324040\n",
      "Iteration 2174, loss = 0.00323846\n",
      "Iteration 2175, loss = 0.00323607\n",
      "Iteration 2176, loss = 0.00323434\n",
      "Iteration 2177, loss = 0.00323232\n",
      "Iteration 2178, loss = 0.00323033\n",
      "Iteration 2179, loss = 0.00322824\n",
      "Iteration 2180, loss = 0.00322610\n",
      "Iteration 2181, loss = 0.00322408\n",
      "Iteration 2182, loss = 0.00322236\n",
      "Iteration 2183, loss = 0.00322004\n",
      "Iteration 2184, loss = 0.00321819\n",
      "Iteration 2185, loss = 0.00321614\n",
      "Iteration 2186, loss = 0.00321422\n",
      "Iteration 2187, loss = 0.00321200\n",
      "Iteration 2188, loss = 0.00321000\n",
      "Iteration 2189, loss = 0.00320804\n",
      "Iteration 2190, loss = 0.00320604\n",
      "Iteration 2191, loss = 0.00320394\n",
      "Iteration 2192, loss = 0.00320232\n",
      "Iteration 2193, loss = 0.00320014\n",
      "Iteration 2194, loss = 0.00319784\n",
      "Iteration 2195, loss = 0.00319603\n",
      "Iteration 2196, loss = 0.00319396\n",
      "Iteration 2197, loss = 0.00319211\n",
      "Iteration 2198, loss = 0.00318998\n",
      "Iteration 2199, loss = 0.00318820\n",
      "Iteration 2200, loss = 0.00318643\n",
      "Iteration 2201, loss = 0.00318408\n",
      "Iteration 2202, loss = 0.00318232\n",
      "Iteration 2203, loss = 0.00318006\n",
      "Iteration 2204, loss = 0.00317791\n",
      "Iteration 2205, loss = 0.00317584\n",
      "Iteration 2206, loss = 0.00317398\n",
      "Iteration 2207, loss = 0.00317197\n",
      "Iteration 2208, loss = 0.00316978\n",
      "Iteration 2209, loss = 0.00316817\n",
      "Iteration 2210, loss = 0.00316599\n",
      "Iteration 2211, loss = 0.00316371\n",
      "Iteration 2212, loss = 0.00316179\n",
      "Iteration 2213, loss = 0.00315986\n",
      "Iteration 2214, loss = 0.00315807\n",
      "Iteration 2215, loss = 0.00315611\n",
      "Iteration 2216, loss = 0.00315400\n",
      "Iteration 2217, loss = 0.00315184\n",
      "Iteration 2218, loss = 0.00314998\n",
      "Iteration 2219, loss = 0.00314805\n",
      "Iteration 2220, loss = 0.00314597\n",
      "Iteration 2221, loss = 0.00314398\n",
      "Iteration 2222, loss = 0.00314217\n",
      "Iteration 2223, loss = 0.00314001\n",
      "Iteration 2224, loss = 0.00313811\n",
      "Iteration 2225, loss = 0.00313625\n",
      "Iteration 2226, loss = 0.00313404\n",
      "Iteration 2227, loss = 0.00313245\n",
      "Iteration 2228, loss = 0.00313029\n",
      "Iteration 2229, loss = 0.00312868\n",
      "Iteration 2230, loss = 0.00312604\n",
      "Iteration 2231, loss = 0.00312416\n",
      "Iteration 2232, loss = 0.00312241\n",
      "Iteration 2233, loss = 0.00312037\n",
      "Iteration 2234, loss = 0.00311830\n",
      "Iteration 2235, loss = 0.00311637\n",
      "Iteration 2236, loss = 0.00311442\n",
      "Iteration 2237, loss = 0.00311286\n",
      "Iteration 2238, loss = 0.00311061\n",
      "Iteration 2239, loss = 0.00310873\n",
      "Iteration 2240, loss = 0.00310674\n",
      "Iteration 2241, loss = 0.00310470\n",
      "Iteration 2242, loss = 0.00310268\n",
      "Iteration 2243, loss = 0.00310101\n",
      "Iteration 2244, loss = 0.00309896\n",
      "Iteration 2245, loss = 0.00309717\n",
      "Iteration 2246, loss = 0.00309526\n",
      "Iteration 2247, loss = 0.00309317\n",
      "Iteration 2248, loss = 0.00309121\n",
      "Iteration 2249, loss = 0.00308940\n",
      "Iteration 2250, loss = 0.00308779\n",
      "Iteration 2251, loss = 0.00308570\n",
      "Iteration 2252, loss = 0.00308383\n",
      "Iteration 2253, loss = 0.00308194\n",
      "Iteration 2254, loss = 0.00308013\n",
      "Iteration 2255, loss = 0.00307831\n",
      "Iteration 2256, loss = 0.00307636\n",
      "Iteration 2257, loss = 0.00307447\n",
      "Iteration 2258, loss = 0.00307254\n",
      "Iteration 2259, loss = 0.00307059\n",
      "Iteration 2260, loss = 0.00306879\n",
      "Iteration 2261, loss = 0.00306687\n",
      "Iteration 2262, loss = 0.00306515\n",
      "Iteration 2263, loss = 0.00306324\n",
      "Iteration 2264, loss = 0.00306134\n",
      "Iteration 2265, loss = 0.00305960\n",
      "Iteration 2266, loss = 0.00305743\n",
      "Iteration 2267, loss = 0.00305585\n",
      "Iteration 2268, loss = 0.00305385\n",
      "Iteration 2269, loss = 0.00305186\n",
      "Iteration 2270, loss = 0.00305004\n",
      "Iteration 2271, loss = 0.00304809\n",
      "Iteration 2272, loss = 0.00304622\n",
      "Iteration 2273, loss = 0.00304440\n",
      "Iteration 2274, loss = 0.00304242\n",
      "Iteration 2275, loss = 0.00304080\n",
      "Iteration 2276, loss = 0.00303920\n",
      "Iteration 2277, loss = 0.00303703\n",
      "Iteration 2278, loss = 0.00303535\n",
      "Iteration 2279, loss = 0.00303361\n",
      "Iteration 2280, loss = 0.00303176\n",
      "Iteration 2281, loss = 0.00302981\n",
      "Iteration 2282, loss = 0.00302804\n",
      "Iteration 2283, loss = 0.00302598\n",
      "Iteration 2284, loss = 0.00302441\n",
      "Iteration 2285, loss = 0.00302249\n",
      "Iteration 2286, loss = 0.00302063\n",
      "Iteration 2287, loss = 0.00301901\n",
      "Iteration 2288, loss = 0.00301726\n",
      "Iteration 2289, loss = 0.00301520\n",
      "Iteration 2290, loss = 0.00301332\n",
      "Iteration 2291, loss = 0.00301191\n",
      "Iteration 2292, loss = 0.00300974\n",
      "Iteration 2293, loss = 0.00300801\n",
      "Iteration 2294, loss = 0.00300633\n",
      "Iteration 2295, loss = 0.00300455\n",
      "Iteration 2296, loss = 0.00300263\n",
      "Iteration 2297, loss = 0.00300098\n",
      "Iteration 2298, loss = 0.00299920\n",
      "Iteration 2299, loss = 0.00299725\n",
      "Iteration 2300, loss = 0.00299561\n",
      "Iteration 2301, loss = 0.00299394\n",
      "Iteration 2302, loss = 0.00299187\n",
      "Iteration 2303, loss = 0.00299059\n",
      "Iteration 2304, loss = 0.00298833\n",
      "Iteration 2305, loss = 0.00298632\n",
      "Iteration 2306, loss = 0.00298474\n",
      "Iteration 2307, loss = 0.00298315\n",
      "Iteration 2308, loss = 0.00298122\n",
      "Iteration 2309, loss = 0.00297958\n",
      "Iteration 2310, loss = 0.00297762\n",
      "Iteration 2311, loss = 0.00297630\n",
      "Iteration 2312, loss = 0.00297419\n",
      "Iteration 2313, loss = 0.00297228\n",
      "Iteration 2314, loss = 0.00297041\n",
      "Iteration 2315, loss = 0.00296872\n",
      "Iteration 2316, loss = 0.00296702\n",
      "Iteration 2317, loss = 0.00296534\n",
      "Iteration 2318, loss = 0.00296359\n",
      "Iteration 2319, loss = 0.00296180\n",
      "Iteration 2320, loss = 0.00296004\n",
      "Iteration 2321, loss = 0.00295862\n",
      "Iteration 2322, loss = 0.00295656\n",
      "Iteration 2323, loss = 0.00295488\n",
      "Iteration 2324, loss = 0.00295325\n",
      "Iteration 2325, loss = 0.00295133\n",
      "Iteration 2326, loss = 0.00294956\n",
      "Iteration 2327, loss = 0.00294823\n",
      "Iteration 2328, loss = 0.00294612\n",
      "Iteration 2329, loss = 0.00294460\n",
      "Iteration 2330, loss = 0.00294269\n",
      "Iteration 2331, loss = 0.00294095\n",
      "Iteration 2332, loss = 0.00293937\n",
      "Iteration 2333, loss = 0.00293762\n",
      "Iteration 2334, loss = 0.00293600\n",
      "Iteration 2335, loss = 0.00293419\n",
      "Iteration 2336, loss = 0.00293246\n",
      "Iteration 2337, loss = 0.00293072\n",
      "Iteration 2338, loss = 0.00292932\n",
      "Iteration 2339, loss = 0.00292704\n",
      "Iteration 2340, loss = 0.00292549\n",
      "Iteration 2341, loss = 0.00292405\n",
      "Iteration 2342, loss = 0.00292211\n",
      "Iteration 2343, loss = 0.00292047\n",
      "Iteration 2344, loss = 0.00291879\n",
      "Iteration 2345, loss = 0.00291714\n",
      "Iteration 2346, loss = 0.00291563\n",
      "Iteration 2347, loss = 0.00291373\n",
      "Iteration 2348, loss = 0.00291188\n",
      "Iteration 2349, loss = 0.00291043\n",
      "Iteration 2350, loss = 0.00290874\n",
      "Iteration 2351, loss = 0.00290690\n",
      "Iteration 2352, loss = 0.00290524\n",
      "Iteration 2353, loss = 0.00290350\n",
      "Iteration 2354, loss = 0.00290181\n",
      "Iteration 2355, loss = 0.00290008\n",
      "Iteration 2356, loss = 0.00289838\n",
      "Iteration 2357, loss = 0.00289674\n",
      "Iteration 2358, loss = 0.00289542\n",
      "Iteration 2359, loss = 0.00289348\n",
      "Iteration 2360, loss = 0.00289204\n",
      "Iteration 2361, loss = 0.00289035\n",
      "Iteration 2362, loss = 0.00288857\n",
      "Iteration 2363, loss = 0.00288695\n",
      "Iteration 2364, loss = 0.00288528\n",
      "Iteration 2365, loss = 0.00288343\n",
      "Iteration 2366, loss = 0.00288189\n",
      "Iteration 2367, loss = 0.00288043\n",
      "Iteration 2368, loss = 0.00287901\n",
      "Iteration 2369, loss = 0.00287689\n",
      "Iteration 2370, loss = 0.00287533\n",
      "Iteration 2371, loss = 0.00287349\n",
      "Iteration 2372, loss = 0.00287177\n",
      "Iteration 2373, loss = 0.00287063\n",
      "Iteration 2374, loss = 0.00286872\n",
      "Iteration 2375, loss = 0.00286712\n",
      "Iteration 2376, loss = 0.00286532\n",
      "Iteration 2377, loss = 0.00286360\n",
      "Iteration 2378, loss = 0.00286202\n",
      "Iteration 2379, loss = 0.00286045\n",
      "Iteration 2380, loss = 0.00285880\n",
      "Iteration 2381, loss = 0.00285698\n",
      "Iteration 2382, loss = 0.00285556\n",
      "Iteration 2383, loss = 0.00285412\n",
      "Iteration 2384, loss = 0.00285216\n",
      "Iteration 2385, loss = 0.00285060\n",
      "Iteration 2386, loss = 0.00284897\n",
      "Iteration 2387, loss = 0.00284733\n",
      "Iteration 2388, loss = 0.00284579\n",
      "Iteration 2389, loss = 0.00284399\n",
      "Iteration 2390, loss = 0.00284241\n",
      "Iteration 2391, loss = 0.00284086\n",
      "Iteration 2392, loss = 0.00283947\n",
      "Iteration 2393, loss = 0.00283781\n",
      "Iteration 2394, loss = 0.00283618\n",
      "Iteration 2395, loss = 0.00283461\n",
      "Iteration 2396, loss = 0.00283314\n",
      "Iteration 2397, loss = 0.00283156\n",
      "Iteration 2398, loss = 0.00283000\n",
      "Iteration 2399, loss = 0.00282848\n",
      "Iteration 2400, loss = 0.00282683\n",
      "Iteration 2401, loss = 0.00282541\n",
      "Iteration 2402, loss = 0.00282378\n",
      "Iteration 2403, loss = 0.00282229\n",
      "Iteration 2404, loss = 0.00282088\n",
      "Iteration 2405, loss = 0.00281914\n",
      "Iteration 2406, loss = 0.00281746\n",
      "Iteration 2407, loss = 0.00281590\n",
      "Iteration 2408, loss = 0.00281465\n",
      "Iteration 2409, loss = 0.00281373\n",
      "Iteration 2410, loss = 0.00281130\n",
      "Iteration 2411, loss = 0.00280972\n",
      "Iteration 2412, loss = 0.00280837\n",
      "Iteration 2413, loss = 0.00280673\n",
      "Iteration 2414, loss = 0.00280500\n",
      "Iteration 2415, loss = 0.00280357\n",
      "Iteration 2416, loss = 0.00280185\n",
      "Iteration 2417, loss = 0.00280044\n",
      "Iteration 2418, loss = 0.00279876\n",
      "Iteration 2419, loss = 0.00279731\n",
      "Iteration 2420, loss = 0.00279587\n",
      "Iteration 2421, loss = 0.00279421\n",
      "Iteration 2422, loss = 0.00279262\n",
      "Iteration 2423, loss = 0.00279117\n",
      "Iteration 2424, loss = 0.00278963\n",
      "Iteration 2425, loss = 0.00278802\n",
      "Iteration 2426, loss = 0.00278670\n",
      "Iteration 2427, loss = 0.00278518\n",
      "Iteration 2428, loss = 0.00278358\n",
      "Iteration 2429, loss = 0.00278212\n",
      "Iteration 2430, loss = 0.00278064\n",
      "Iteration 2431, loss = 0.00277895\n",
      "Iteration 2432, loss = 0.00277753\n",
      "Iteration 2433, loss = 0.00277607\n",
      "Iteration 2434, loss = 0.00277446\n",
      "Iteration 2435, loss = 0.00277306\n",
      "Iteration 2436, loss = 0.00277142\n",
      "Iteration 2437, loss = 0.00277009\n",
      "Iteration 2438, loss = 0.00276837\n",
      "Iteration 2439, loss = 0.00276684\n",
      "Iteration 2440, loss = 0.00276567\n",
      "Iteration 2441, loss = 0.00276402\n",
      "Iteration 2442, loss = 0.00276236\n",
      "Iteration 2443, loss = 0.00276076\n",
      "Iteration 2444, loss = 0.00275930\n",
      "Iteration 2445, loss = 0.00275782\n",
      "Iteration 2446, loss = 0.00275623\n",
      "Iteration 2447, loss = 0.00275489\n",
      "Iteration 2448, loss = 0.00275320\n",
      "Iteration 2449, loss = 0.00275170\n",
      "Iteration 2450, loss = 0.00275032\n",
      "Iteration 2451, loss = 0.00274901\n",
      "Iteration 2452, loss = 0.00274734\n",
      "Iteration 2453, loss = 0.00274566\n",
      "Iteration 2454, loss = 0.00274424\n",
      "Iteration 2455, loss = 0.00274270\n",
      "Iteration 2456, loss = 0.00274138\n",
      "Iteration 2457, loss = 0.00274019\n",
      "Iteration 2458, loss = 0.00273849\n",
      "Iteration 2459, loss = 0.00273691\n",
      "Iteration 2460, loss = 0.00273552\n",
      "Iteration 2461, loss = 0.00273381\n",
      "Iteration 2462, loss = 0.00273269\n",
      "Iteration 2463, loss = 0.00273127\n",
      "Iteration 2464, loss = 0.00272936\n",
      "Iteration 2465, loss = 0.00272802\n",
      "Iteration 2466, loss = 0.00272660\n",
      "Iteration 2467, loss = 0.00272551\n",
      "Iteration 2468, loss = 0.00272352\n",
      "Iteration 2469, loss = 0.00272201\n",
      "Iteration 2470, loss = 0.00272065\n",
      "Iteration 2471, loss = 0.00271910\n",
      "Iteration 2472, loss = 0.00271767\n",
      "Iteration 2473, loss = 0.00271637\n",
      "Iteration 2474, loss = 0.00271476\n",
      "Iteration 2475, loss = 0.00271357\n",
      "Iteration 2476, loss = 0.00271180\n",
      "Iteration 2477, loss = 0.00271038\n",
      "Iteration 2478, loss = 0.00270905\n",
      "Iteration 2479, loss = 0.00270797\n",
      "Iteration 2480, loss = 0.00270605\n",
      "Iteration 2481, loss = 0.00270473\n",
      "Iteration 2482, loss = 0.00270332\n",
      "Iteration 2483, loss = 0.00270168\n",
      "Iteration 2484, loss = 0.00270059\n",
      "Iteration 2485, loss = 0.00269871\n",
      "Iteration 2486, loss = 0.00269725\n",
      "Iteration 2487, loss = 0.00269568\n",
      "Iteration 2488, loss = 0.00269442\n",
      "Iteration 2489, loss = 0.00269297\n",
      "Iteration 2490, loss = 0.00269149\n",
      "Iteration 2491, loss = 0.00269019\n",
      "Iteration 2492, loss = 0.00268887\n",
      "Iteration 2493, loss = 0.00268735\n",
      "Iteration 2494, loss = 0.00268587\n",
      "Iteration 2495, loss = 0.00268445\n",
      "Iteration 2496, loss = 0.00268313\n",
      "Iteration 2497, loss = 0.00268199\n",
      "Iteration 2498, loss = 0.00268040\n",
      "Iteration 2499, loss = 0.00267884\n",
      "Iteration 2500, loss = 0.00267750\n",
      "Iteration 2501, loss = 0.00267612\n",
      "Iteration 2502, loss = 0.00267468\n",
      "Iteration 2503, loss = 0.00267331\n",
      "Iteration 2504, loss = 0.00267212\n",
      "Iteration 2505, loss = 0.00267038\n",
      "Iteration 2506, loss = 0.00266895\n",
      "Iteration 2507, loss = 0.00266769\n",
      "Iteration 2508, loss = 0.00266628\n",
      "Iteration 2509, loss = 0.00266499\n",
      "Iteration 2510, loss = 0.00266374\n",
      "Iteration 2511, loss = 0.00266222\n",
      "Iteration 2512, loss = 0.00266109\n",
      "Iteration 2513, loss = 0.00265934\n",
      "Iteration 2514, loss = 0.00265799\n",
      "Iteration 2515, loss = 0.00265658\n",
      "Iteration 2516, loss = 0.00265563\n",
      "Iteration 2517, loss = 0.00265373\n",
      "Iteration 2518, loss = 0.00265242\n",
      "Iteration 2519, loss = 0.00265094\n",
      "Iteration 2520, loss = 0.00264980\n",
      "Iteration 2521, loss = 0.00264851\n",
      "Iteration 2522, loss = 0.00264687\n",
      "Iteration 2523, loss = 0.00264575\n",
      "Iteration 2524, loss = 0.00264412\n",
      "Iteration 2525, loss = 0.00264315\n",
      "Iteration 2526, loss = 0.00264128\n",
      "Iteration 2527, loss = 0.00263997\n",
      "Iteration 2528, loss = 0.00263881\n",
      "Iteration 2529, loss = 0.00263726\n",
      "Iteration 2530, loss = 0.00263604\n",
      "Iteration 2531, loss = 0.00263475\n",
      "Iteration 2532, loss = 0.00263333\n",
      "Iteration 2533, loss = 0.00263201\n",
      "Iteration 2534, loss = 0.00263043\n",
      "Iteration 2535, loss = 0.00262912\n",
      "Iteration 2536, loss = 0.00262777\n",
      "Iteration 2537, loss = 0.00262626\n",
      "Iteration 2538, loss = 0.00262513\n",
      "Iteration 2539, loss = 0.00262354\n",
      "Iteration 2540, loss = 0.00262204\n",
      "Iteration 2541, loss = 0.00262077\n",
      "Iteration 2542, loss = 0.00261949\n",
      "Iteration 2543, loss = 0.00261788\n",
      "Iteration 2544, loss = 0.00261678\n",
      "Iteration 2545, loss = 0.00261544\n",
      "Iteration 2546, loss = 0.00261404\n",
      "Iteration 2547, loss = 0.00261275\n",
      "Iteration 2548, loss = 0.00261141\n",
      "Iteration 2549, loss = 0.00261014\n",
      "Iteration 2550, loss = 0.00260887\n",
      "Iteration 2551, loss = 0.00260763\n",
      "Iteration 2552, loss = 0.00260622\n",
      "Iteration 2553, loss = 0.00260492\n",
      "Iteration 2554, loss = 0.00260371\n",
      "Iteration 2555, loss = 0.00260242\n",
      "Iteration 2556, loss = 0.00260110\n",
      "Iteration 2557, loss = 0.00259959\n",
      "Iteration 2558, loss = 0.00259834\n",
      "Iteration 2559, loss = 0.00259707\n",
      "Iteration 2560, loss = 0.00259566\n",
      "Iteration 2561, loss = 0.00259451\n",
      "Iteration 2562, loss = 0.00259304\n",
      "Iteration 2563, loss = 0.00259174\n",
      "Iteration 2564, loss = 0.00259055\n",
      "Iteration 2565, loss = 0.00258908\n",
      "Iteration 2566, loss = 0.00258788\n",
      "Iteration 2567, loss = 0.00258650\n",
      "Iteration 2568, loss = 0.00258528\n",
      "Iteration 2569, loss = 0.00258403\n",
      "Iteration 2570, loss = 0.00258278\n",
      "Iteration 2571, loss = 0.00258141\n",
      "Iteration 2572, loss = 0.00258008\n",
      "Iteration 2573, loss = 0.00257864\n",
      "Iteration 2574, loss = 0.00257735\n",
      "Iteration 2575, loss = 0.00257612\n",
      "Iteration 2576, loss = 0.00257506\n",
      "Iteration 2577, loss = 0.00257340\n",
      "Iteration 2578, loss = 0.00257208\n",
      "Iteration 2579, loss = 0.00257068\n",
      "Iteration 2580, loss = 0.00256946\n",
      "Iteration 2581, loss = 0.00256813\n",
      "Iteration 2582, loss = 0.00256673\n",
      "Iteration 2583, loss = 0.00256548\n",
      "Iteration 2584, loss = 0.00256437\n",
      "Iteration 2585, loss = 0.00256267\n",
      "Iteration 2586, loss = 0.00256150\n",
      "Iteration 2587, loss = 0.00256019\n",
      "Iteration 2588, loss = 0.00255898\n",
      "Iteration 2589, loss = 0.00255765\n",
      "Iteration 2590, loss = 0.00255641\n",
      "Iteration 2591, loss = 0.00255520\n",
      "Iteration 2592, loss = 0.00255391\n",
      "Iteration 2593, loss = 0.00255258\n",
      "Iteration 2594, loss = 0.00255120\n",
      "Iteration 2595, loss = 0.00254988\n",
      "Iteration 2596, loss = 0.00254869\n",
      "Iteration 2597, loss = 0.00254744\n",
      "Iteration 2598, loss = 0.00254607\n",
      "Iteration 2599, loss = 0.00254471\n",
      "Iteration 2600, loss = 0.00254356\n",
      "Iteration 2601, loss = 0.00254211\n",
      "Iteration 2602, loss = 0.00254078\n",
      "Iteration 2603, loss = 0.00253982\n",
      "Iteration 2604, loss = 0.00253829\n",
      "Iteration 2605, loss = 0.00253707\n",
      "Iteration 2606, loss = 0.00253581\n",
      "Iteration 2607, loss = 0.00253456\n",
      "Iteration 2608, loss = 0.00253334\n",
      "Iteration 2609, loss = 0.00253194\n",
      "Iteration 2610, loss = 0.00253068\n",
      "Iteration 2611, loss = 0.00252945\n",
      "Iteration 2612, loss = 0.00252831\n",
      "Iteration 2613, loss = 0.00252684\n",
      "Iteration 2614, loss = 0.00252577\n",
      "Iteration 2615, loss = 0.00252429\n",
      "Iteration 2616, loss = 0.00252298\n",
      "Iteration 2617, loss = 0.00252180\n",
      "Iteration 2618, loss = 0.00252051\n",
      "Iteration 2619, loss = 0.00251909\n",
      "Iteration 2620, loss = 0.00251806\n",
      "Iteration 2621, loss = 0.00251662\n",
      "Iteration 2622, loss = 0.00251545\n",
      "Iteration 2623, loss = 0.00251412\n",
      "Iteration 2624, loss = 0.00251286\n",
      "Iteration 2625, loss = 0.00251164\n",
      "Iteration 2626, loss = 0.00251054\n",
      "Iteration 2627, loss = 0.00250892\n",
      "Iteration 2628, loss = 0.00250765\n",
      "Iteration 2629, loss = 0.00250656\n",
      "Iteration 2630, loss = 0.00250524\n",
      "Iteration 2631, loss = 0.00250388\n",
      "Iteration 2632, loss = 0.00250284\n",
      "Iteration 2633, loss = 0.00250145\n",
      "Iteration 2634, loss = 0.00250015\n",
      "Iteration 2635, loss = 0.00249892\n",
      "Iteration 2636, loss = 0.00249766\n",
      "Iteration 2637, loss = 0.00249634\n",
      "Iteration 2638, loss = 0.00249511\n",
      "Iteration 2639, loss = 0.00249391\n",
      "Iteration 2640, loss = 0.00249256\n",
      "Iteration 2641, loss = 0.00249123\n",
      "Iteration 2642, loss = 0.00249012\n",
      "Iteration 2643, loss = 0.00248889\n",
      "Iteration 2644, loss = 0.00248757\n",
      "Iteration 2645, loss = 0.00248642\n",
      "Iteration 2646, loss = 0.00248523\n",
      "Iteration 2647, loss = 0.00248394\n",
      "Iteration 2648, loss = 0.00248298\n",
      "Iteration 2649, loss = 0.00248165\n",
      "Iteration 2650, loss = 0.00248047\n",
      "Iteration 2651, loss = 0.00247940\n",
      "Iteration 2652, loss = 0.00247837\n",
      "Iteration 2653, loss = 0.00247698\n",
      "Iteration 2654, loss = 0.00247555\n",
      "Iteration 2655, loss = 0.00247424\n",
      "Iteration 2656, loss = 0.00247296\n",
      "Iteration 2657, loss = 0.00247168\n",
      "Iteration 2658, loss = 0.00247058\n",
      "Iteration 2659, loss = 0.00246927\n",
      "Iteration 2660, loss = 0.00246808\n",
      "Iteration 2661, loss = 0.00246685\n",
      "Iteration 2662, loss = 0.00246580\n",
      "Iteration 2663, loss = 0.00246457\n",
      "Iteration 2664, loss = 0.00246337\n",
      "Iteration 2665, loss = 0.00246213\n",
      "Iteration 2666, loss = 0.00246088\n",
      "Iteration 2667, loss = 0.00245981\n",
      "Iteration 2668, loss = 0.00245845\n",
      "Iteration 2669, loss = 0.00245755\n",
      "Iteration 2670, loss = 0.00245605\n",
      "Iteration 2671, loss = 0.00245516\n",
      "Iteration 2672, loss = 0.00245392\n",
      "Iteration 2673, loss = 0.00245265\n",
      "Iteration 2674, loss = 0.00245143\n",
      "Iteration 2675, loss = 0.00245011\n",
      "Iteration 2676, loss = 0.00244883\n",
      "Iteration 2677, loss = 0.00244761\n",
      "Iteration 2678, loss = 0.00244676\n",
      "Iteration 2679, loss = 0.00244518\n",
      "Iteration 2680, loss = 0.00244402\n",
      "Iteration 2681, loss = 0.00244274\n",
      "Iteration 2682, loss = 0.00244146\n",
      "Iteration 2683, loss = 0.00244042\n",
      "Iteration 2684, loss = 0.00243912\n",
      "Iteration 2685, loss = 0.00243807\n",
      "Iteration 2686, loss = 0.00243675\n",
      "Iteration 2687, loss = 0.00243559\n",
      "Iteration 2688, loss = 0.00243438\n",
      "Iteration 2689, loss = 0.00243326\n",
      "Iteration 2690, loss = 0.00243203\n",
      "Iteration 2691, loss = 0.00243077\n",
      "Iteration 2692, loss = 0.00242945\n",
      "Iteration 2693, loss = 0.00242854\n",
      "Iteration 2694, loss = 0.00242715\n",
      "Iteration 2695, loss = 0.00242615\n",
      "Iteration 2696, loss = 0.00242472\n",
      "Iteration 2697, loss = 0.00242356\n",
      "Iteration 2698, loss = 0.00242247\n",
      "Iteration 2699, loss = 0.00242116\n",
      "Iteration 2700, loss = 0.00242025\n",
      "Iteration 2701, loss = 0.00241868\n",
      "Iteration 2702, loss = 0.00241772\n",
      "Iteration 2703, loss = 0.00241636\n",
      "Iteration 2704, loss = 0.00241529\n",
      "Iteration 2705, loss = 0.00241398\n",
      "Iteration 2706, loss = 0.00241289\n",
      "Iteration 2707, loss = 0.00241174\n",
      "Iteration 2708, loss = 0.00241052\n",
      "Iteration 2709, loss = 0.00240952\n",
      "Iteration 2710, loss = 0.00240827\n",
      "Iteration 2711, loss = 0.00240691\n",
      "Iteration 2712, loss = 0.00240567\n",
      "Iteration 2713, loss = 0.00240463\n",
      "Iteration 2714, loss = 0.00240338\n",
      "Iteration 2715, loss = 0.00240235\n",
      "Iteration 2716, loss = 0.00240113\n",
      "Iteration 2717, loss = 0.00239991\n",
      "Iteration 2718, loss = 0.00239872\n",
      "Iteration 2719, loss = 0.00239760\n",
      "Iteration 2720, loss = 0.00239646\n",
      "Iteration 2721, loss = 0.00239515\n",
      "Iteration 2722, loss = 0.00239418\n",
      "Iteration 2723, loss = 0.00239308\n",
      "Iteration 2724, loss = 0.00239176\n",
      "Iteration 2725, loss = 0.00239077\n",
      "Iteration 2726, loss = 0.00238948\n",
      "Iteration 2727, loss = 0.00238828\n",
      "Iteration 2728, loss = 0.00238718\n",
      "Iteration 2729, loss = 0.00238614\n",
      "Iteration 2730, loss = 0.00238485\n",
      "Iteration 2731, loss = 0.00238382\n",
      "Iteration 2732, loss = 0.00238284\n",
      "Iteration 2733, loss = 0.00238155\n",
      "Iteration 2734, loss = 0.00238045\n",
      "Iteration 2735, loss = 0.00237924\n",
      "Iteration 2736, loss = 0.00237815\n",
      "Iteration 2737, loss = 0.00237695\n",
      "Iteration 2738, loss = 0.00237581\n",
      "Iteration 2739, loss = 0.00237481\n",
      "Iteration 2740, loss = 0.00237370\n",
      "Iteration 2741, loss = 0.00237252\n",
      "Iteration 2742, loss = 0.00237129\n",
      "Iteration 2743, loss = 0.00237031\n",
      "Iteration 2744, loss = 0.00236927\n",
      "Iteration 2745, loss = 0.00236803\n",
      "Iteration 2746, loss = 0.00236701\n",
      "Iteration 2747, loss = 0.00236579\n",
      "Iteration 2748, loss = 0.00236466\n",
      "Iteration 2749, loss = 0.00236375\n",
      "Iteration 2750, loss = 0.00236242\n",
      "Iteration 2751, loss = 0.00236133\n",
      "Iteration 2752, loss = 0.00236024\n",
      "Iteration 2753, loss = 0.00235906\n",
      "Iteration 2754, loss = 0.00235801\n",
      "Iteration 2755, loss = 0.00235702\n",
      "Iteration 2756, loss = 0.00235577\n",
      "Iteration 2757, loss = 0.00235443\n",
      "Iteration 2758, loss = 0.00235318\n",
      "Iteration 2759, loss = 0.00235256\n",
      "Iteration 2760, loss = 0.00235109\n",
      "Iteration 2761, loss = 0.00234987\n",
      "Iteration 2762, loss = 0.00234905\n",
      "Iteration 2763, loss = 0.00234774\n",
      "Iteration 2764, loss = 0.00234657\n",
      "Iteration 2765, loss = 0.00234553\n",
      "Iteration 2766, loss = 0.00234461\n",
      "Iteration 2767, loss = 0.00234330\n",
      "Iteration 2768, loss = 0.00234205\n",
      "Iteration 2769, loss = 0.00234105\n",
      "Iteration 2770, loss = 0.00233988\n",
      "Iteration 2771, loss = 0.00233879\n",
      "Iteration 2772, loss = 0.00233770\n",
      "Iteration 2773, loss = 0.00233659\n",
      "Iteration 2774, loss = 0.00233552\n",
      "Iteration 2775, loss = 0.00233434\n",
      "Iteration 2776, loss = 0.00233320\n",
      "Iteration 2777, loss = 0.00233206\n",
      "Iteration 2778, loss = 0.00233093\n",
      "Iteration 2779, loss = 0.00233006\n",
      "Iteration 2780, loss = 0.00232889\n",
      "Iteration 2781, loss = 0.00232770\n",
      "Iteration 2782, loss = 0.00232672\n",
      "Iteration 2783, loss = 0.00232543\n",
      "Iteration 2784, loss = 0.00232434\n",
      "Iteration 2785, loss = 0.00232320\n",
      "Iteration 2786, loss = 0.00232215\n",
      "Iteration 2787, loss = 0.00232095\n",
      "Iteration 2788, loss = 0.00232000\n",
      "Iteration 2789, loss = 0.00231875\n",
      "Iteration 2790, loss = 0.00231778\n",
      "Iteration 2791, loss = 0.00231666\n",
      "Iteration 2792, loss = 0.00231545\n",
      "Iteration 2793, loss = 0.00231453\n",
      "Iteration 2794, loss = 0.00231329\n",
      "Iteration 2795, loss = 0.00231241\n",
      "Iteration 2796, loss = 0.00231102\n",
      "Iteration 2797, loss = 0.00231008\n",
      "Iteration 2798, loss = 0.00230899\n",
      "Iteration 2799, loss = 0.00230801\n",
      "Iteration 2800, loss = 0.00230686\n",
      "Iteration 2801, loss = 0.00230570\n",
      "Iteration 2802, loss = 0.00230463\n",
      "Iteration 2803, loss = 0.00230350\n",
      "Iteration 2804, loss = 0.00230244\n",
      "Iteration 2805, loss = 0.00230150\n",
      "Iteration 2806, loss = 0.00230023\n",
      "Iteration 2807, loss = 0.00229916\n",
      "Iteration 2808, loss = 0.00229810\n",
      "Iteration 2809, loss = 0.00229700\n",
      "Iteration 2810, loss = 0.00229596\n",
      "Iteration 2811, loss = 0.00229478\n",
      "Iteration 2812, loss = 0.00229372\n",
      "Iteration 2813, loss = 0.00229269\n",
      "Iteration 2814, loss = 0.00229159\n",
      "Iteration 2815, loss = 0.00229038\n",
      "Iteration 2816, loss = 0.00228951\n",
      "Iteration 2817, loss = 0.00228828\n",
      "Iteration 2818, loss = 0.00228716\n",
      "Iteration 2819, loss = 0.00228600\n",
      "Iteration 2820, loss = 0.00228491\n",
      "Iteration 2821, loss = 0.00228386\n",
      "Iteration 2822, loss = 0.00228287\n",
      "Iteration 2823, loss = 0.00228167\n",
      "Iteration 2824, loss = 0.00228062\n",
      "Iteration 2825, loss = 0.00227951\n",
      "Iteration 2826, loss = 0.00227844\n",
      "Iteration 2827, loss = 0.00227744\n",
      "Iteration 2828, loss = 0.00227630\n",
      "Iteration 2829, loss = 0.00227527\n",
      "Iteration 2830, loss = 0.00227411\n",
      "Iteration 2831, loss = 0.00227307\n",
      "Iteration 2832, loss = 0.00227221\n",
      "Iteration 2833, loss = 0.00227107\n",
      "Iteration 2834, loss = 0.00226996\n",
      "Iteration 2835, loss = 0.00226890\n",
      "Iteration 2836, loss = 0.00226795\n",
      "Iteration 2837, loss = 0.00226676\n",
      "Iteration 2838, loss = 0.00226562\n",
      "Iteration 2839, loss = 0.00226463\n",
      "Iteration 2840, loss = 0.00226387\n",
      "Iteration 2841, loss = 0.00226257\n",
      "Iteration 2842, loss = 0.00226153\n",
      "Iteration 2843, loss = 0.00226058\n",
      "Iteration 2844, loss = 0.00225957\n",
      "Iteration 2845, loss = 0.00225836\n",
      "Iteration 2846, loss = 0.00225725\n",
      "Iteration 2847, loss = 0.00225621\n",
      "Iteration 2848, loss = 0.00225526\n",
      "Iteration 2849, loss = 0.00225411\n",
      "Iteration 2850, loss = 0.00225329\n",
      "Iteration 2851, loss = 0.00225210\n",
      "Iteration 2852, loss = 0.00225113\n",
      "Iteration 2853, loss = 0.00224995\n",
      "Iteration 2854, loss = 0.00224911\n",
      "Iteration 2855, loss = 0.00224783\n",
      "Iteration 2856, loss = 0.00224692\n",
      "Iteration 2857, loss = 0.00224583\n",
      "Iteration 2858, loss = 0.00224489\n",
      "Iteration 2859, loss = 0.00224400\n",
      "Iteration 2860, loss = 0.00224303\n",
      "Iteration 2861, loss = 0.00224214\n",
      "Iteration 2862, loss = 0.00224093\n",
      "Iteration 2863, loss = 0.00223972\n",
      "Iteration 2864, loss = 0.00223870\n",
      "Iteration 2865, loss = 0.00223762\n",
      "Iteration 2866, loss = 0.00223668\n",
      "Iteration 2867, loss = 0.00223559\n",
      "Iteration 2868, loss = 0.00223448\n",
      "Iteration 2869, loss = 0.00223363\n",
      "Iteration 2870, loss = 0.00223260\n",
      "Iteration 2871, loss = 0.00223147\n",
      "Iteration 2872, loss = 0.00223039\n",
      "Iteration 2873, loss = 0.00222933\n",
      "Iteration 2874, loss = 0.00222850\n",
      "Iteration 2875, loss = 0.00222727\n",
      "Iteration 2876, loss = 0.00222634\n",
      "Iteration 2877, loss = 0.00222552\n",
      "Iteration 2878, loss = 0.00222422\n",
      "Iteration 2879, loss = 0.00222334\n",
      "Iteration 2880, loss = 0.00222226\n",
      "Iteration 2881, loss = 0.00222117\n",
      "Iteration 2882, loss = 0.00222018\n",
      "Iteration 2883, loss = 0.00221916\n",
      "Iteration 2884, loss = 0.00221808\n",
      "Iteration 2885, loss = 0.00221723\n",
      "Iteration 2886, loss = 0.00221602\n",
      "Iteration 2887, loss = 0.00221508\n",
      "Iteration 2888, loss = 0.00221406\n",
      "Iteration 2889, loss = 0.00221285\n",
      "Iteration 2890, loss = 0.00221198\n",
      "Iteration 2891, loss = 0.00221080\n",
      "Iteration 2892, loss = 0.00220992\n",
      "Iteration 2893, loss = 0.00220873\n",
      "Iteration 2894, loss = 0.00220788\n",
      "Iteration 2895, loss = 0.00220671\n",
      "Iteration 2896, loss = 0.00220566\n",
      "Iteration 2897, loss = 0.00220492\n",
      "Iteration 2898, loss = 0.00220359\n",
      "Iteration 2899, loss = 0.00220257\n",
      "Iteration 2900, loss = 0.00220168\n",
      "Iteration 2901, loss = 0.00220071\n",
      "Iteration 2902, loss = 0.00219968\n",
      "Iteration 2903, loss = 0.00219872\n",
      "Iteration 2904, loss = 0.00219760\n",
      "Iteration 2905, loss = 0.00219647\n",
      "Iteration 2906, loss = 0.00219553\n",
      "Iteration 2907, loss = 0.00219460\n",
      "Iteration 2908, loss = 0.00219352\n",
      "Iteration 2909, loss = 0.00219267\n",
      "Iteration 2910, loss = 0.00219158\n",
      "Iteration 2911, loss = 0.00219077\n",
      "Iteration 2912, loss = 0.00218959\n",
      "Iteration 2913, loss = 0.00218863\n",
      "Iteration 2914, loss = 0.00218748\n",
      "Iteration 2915, loss = 0.00218664\n",
      "Iteration 2916, loss = 0.00218570\n",
      "Iteration 2917, loss = 0.00218491\n",
      "Iteration 2918, loss = 0.00218378\n",
      "Iteration 2919, loss = 0.00218272\n",
      "Iteration 2920, loss = 0.00218167\n",
      "Iteration 2921, loss = 0.00218085\n",
      "Iteration 2922, loss = 0.00217975\n",
      "Iteration 2923, loss = 0.00217879\n",
      "Iteration 2924, loss = 0.00217785\n",
      "Iteration 2925, loss = 0.00217693\n",
      "Iteration 2926, loss = 0.00217596\n",
      "Iteration 2927, loss = 0.00217536\n",
      "Iteration 2928, loss = 0.00217391\n",
      "Iteration 2929, loss = 0.00217291\n",
      "Iteration 2930, loss = 0.00217201\n",
      "Iteration 2931, loss = 0.00217108\n",
      "Iteration 2932, loss = 0.00216999\n",
      "Iteration 2933, loss = 0.00216913\n",
      "Iteration 2934, loss = 0.00216818\n",
      "Iteration 2935, loss = 0.00216718\n",
      "Iteration 2936, loss = 0.00216615\n",
      "Iteration 2937, loss = 0.00216512\n",
      "Iteration 2938, loss = 0.00216415\n",
      "Iteration 2939, loss = 0.00216331\n",
      "Iteration 2940, loss = 0.00216216\n",
      "Iteration 2941, loss = 0.00216130\n",
      "Iteration 2942, loss = 0.00216017\n",
      "Iteration 2943, loss = 0.00215920\n",
      "Iteration 2944, loss = 0.00215821\n",
      "Iteration 2945, loss = 0.00215732\n",
      "Iteration 2946, loss = 0.00215632\n",
      "Iteration 2947, loss = 0.00215539\n",
      "Iteration 2948, loss = 0.00215448\n",
      "Iteration 2949, loss = 0.00215348\n",
      "Iteration 2950, loss = 0.00215253\n",
      "Iteration 2951, loss = 0.00215169\n",
      "Iteration 2952, loss = 0.00215064\n",
      "Iteration 2953, loss = 0.00214977\n",
      "Iteration 2954, loss = 0.00214868\n",
      "Iteration 2955, loss = 0.00214783\n",
      "Iteration 2956, loss = 0.00214689\n",
      "Iteration 2957, loss = 0.00214578\n",
      "Iteration 2958, loss = 0.00214495\n",
      "Iteration 2959, loss = 0.00214397\n",
      "Iteration 2960, loss = 0.00214291\n",
      "Iteration 2961, loss = 0.00214208\n",
      "Iteration 2962, loss = 0.00214122\n",
      "Iteration 2963, loss = 0.00214032\n",
      "Iteration 2964, loss = 0.00213929\n",
      "Iteration 2965, loss = 0.00213809\n",
      "Iteration 2966, loss = 0.00213722\n",
      "Iteration 2967, loss = 0.00213628\n",
      "Iteration 2968, loss = 0.00213527\n",
      "Iteration 2969, loss = 0.00213437\n",
      "Iteration 2970, loss = 0.00213358\n",
      "Iteration 2971, loss = 0.00213246\n",
      "Iteration 2972, loss = 0.00213153\n",
      "Iteration 2973, loss = 0.00213037\n",
      "Iteration 2974, loss = 0.00212952\n",
      "Iteration 2975, loss = 0.00212847\n",
      "Iteration 2976, loss = 0.00212764\n",
      "Iteration 2977, loss = 0.00212682\n",
      "Iteration 2978, loss = 0.00212564\n",
      "Iteration 2979, loss = 0.00212473\n",
      "Iteration 2980, loss = 0.00212391\n",
      "Iteration 2981, loss = 0.00212287\n",
      "Iteration 2982, loss = 0.00212186\n",
      "Iteration 2983, loss = 0.00212111\n",
      "Iteration 2984, loss = 0.00212001\n",
      "Iteration 2985, loss = 0.00211923\n",
      "Iteration 2986, loss = 0.00211822\n",
      "Iteration 2987, loss = 0.00211726\n",
      "Iteration 2988, loss = 0.00211639\n",
      "Iteration 2989, loss = 0.00211551\n",
      "Iteration 2990, loss = 0.00211460\n",
      "Iteration 2991, loss = 0.00211360\n",
      "Iteration 2992, loss = 0.00211271\n",
      "Iteration 2993, loss = 0.00211181\n",
      "Iteration 2994, loss = 0.00211077\n",
      "Iteration 2995, loss = 0.00210981\n",
      "Iteration 2996, loss = 0.00210888\n",
      "Iteration 2997, loss = 0.00210822\n",
      "Iteration 2998, loss = 0.00210711\n",
      "Iteration 2999, loss = 0.00210614\n",
      "Iteration 3000, loss = 0.00210523\n",
      "Iteration 3001, loss = 0.00210422\n",
      "Iteration 3002, loss = 0.00210327\n",
      "Iteration 3003, loss = 0.00210249\n",
      "Iteration 3004, loss = 0.00210162\n",
      "Iteration 3005, loss = 0.00210064\n",
      "Iteration 3006, loss = 0.00209983\n",
      "Iteration 3007, loss = 0.00209866\n",
      "Iteration 3008, loss = 0.00209775\n",
      "Iteration 3009, loss = 0.00209693\n",
      "Iteration 3010, loss = 0.00209610\n",
      "Iteration 3011, loss = 0.00209507\n",
      "Iteration 3012, loss = 0.00209421\n",
      "Iteration 3013, loss = 0.00209323\n",
      "Iteration 3014, loss = 0.00209230\n",
      "Iteration 3015, loss = 0.00209141\n",
      "Iteration 3016, loss = 0.00209054\n",
      "Iteration 3017, loss = 0.00208984\n",
      "Iteration 3018, loss = 0.00208863\n",
      "Iteration 3019, loss = 0.00208777\n",
      "Iteration 3020, loss = 0.00208675\n",
      "Iteration 3021, loss = 0.00208586\n",
      "Iteration 3022, loss = 0.00208514\n",
      "Iteration 3023, loss = 0.00208415\n",
      "Iteration 3024, loss = 0.00208311\n",
      "Iteration 3025, loss = 0.00208239\n",
      "Iteration 3026, loss = 0.00208135\n",
      "Iteration 3027, loss = 0.00208042\n",
      "Iteration 3028, loss = 0.00207952\n",
      "Iteration 3029, loss = 0.00207862\n",
      "Iteration 3030, loss = 0.00207755\n",
      "Iteration 3031, loss = 0.00207675\n",
      "Iteration 3032, loss = 0.00207590\n",
      "Iteration 3033, loss = 0.00207496\n",
      "Iteration 3034, loss = 0.00207425\n",
      "Iteration 3035, loss = 0.00207298\n",
      "Iteration 3036, loss = 0.00207211\n",
      "Iteration 3037, loss = 0.00207122\n",
      "Iteration 3038, loss = 0.00207040\n",
      "Iteration 3039, loss = 0.00206942\n",
      "Iteration 3040, loss = 0.00206858\n",
      "Iteration 3041, loss = 0.00206772\n",
      "Iteration 3042, loss = 0.00206685\n",
      "Iteration 3043, loss = 0.00206586\n",
      "Iteration 3044, loss = 0.00206493\n",
      "Iteration 3045, loss = 0.00206404\n",
      "Iteration 3046, loss = 0.00206308\n",
      "Iteration 3047, loss = 0.00206219\n",
      "Iteration 3048, loss = 0.00206132\n",
      "Iteration 3049, loss = 0.00206052\n",
      "Iteration 3050, loss = 0.00205949\n",
      "Iteration 3051, loss = 0.00205868\n",
      "Iteration 3052, loss = 0.00205767\n",
      "Iteration 3053, loss = 0.00205690\n",
      "Iteration 3054, loss = 0.00205615\n",
      "Iteration 3055, loss = 0.00205506\n",
      "Iteration 3056, loss = 0.00205423\n",
      "Iteration 3057, loss = 0.00205362\n",
      "Iteration 3058, loss = 0.00205255\n",
      "Iteration 3059, loss = 0.00205161\n",
      "Iteration 3060, loss = 0.00205077\n",
      "Iteration 3061, loss = 0.00204981\n",
      "Iteration 3062, loss = 0.00204904\n",
      "Iteration 3063, loss = 0.00204800\n",
      "Iteration 3064, loss = 0.00204712\n",
      "Iteration 3065, loss = 0.00204638\n",
      "Iteration 3066, loss = 0.00204544\n",
      "Iteration 3067, loss = 0.00204429\n",
      "Iteration 3068, loss = 0.00204354\n",
      "Iteration 3069, loss = 0.00204261\n",
      "Iteration 3070, loss = 0.00204174\n",
      "Iteration 3071, loss = 0.00204080\n",
      "Iteration 3072, loss = 0.00203988\n",
      "Iteration 3073, loss = 0.00203906\n",
      "Iteration 3074, loss = 0.00203811\n",
      "Iteration 3075, loss = 0.00203731\n",
      "Iteration 3076, loss = 0.00203638\n",
      "Iteration 3077, loss = 0.00203539\n",
      "Iteration 3078, loss = 0.00203459\n",
      "Iteration 3079, loss = 0.00203375\n",
      "Iteration 3080, loss = 0.00203286\n",
      "Iteration 3081, loss = 0.00203196\n",
      "Iteration 3082, loss = 0.00203110\n",
      "Iteration 3083, loss = 0.00203019\n",
      "Iteration 3084, loss = 0.00202943\n",
      "Iteration 3085, loss = 0.00202851\n",
      "Iteration 3086, loss = 0.00202760\n",
      "Iteration 3087, loss = 0.00202658\n",
      "Iteration 3088, loss = 0.00202600\n",
      "Iteration 3089, loss = 0.00202484\n",
      "Iteration 3090, loss = 0.00202416\n",
      "Iteration 3091, loss = 0.00202324\n",
      "Iteration 3092, loss = 0.00202225\n",
      "Iteration 3093, loss = 0.00202151\n",
      "Iteration 3094, loss = 0.00202055\n",
      "Iteration 3095, loss = 0.00201965\n",
      "Iteration 3096, loss = 0.00201883\n",
      "Iteration 3097, loss = 0.00201812\n",
      "Iteration 3098, loss = 0.00201717\n",
      "Iteration 3099, loss = 0.00201629\n",
      "Iteration 3100, loss = 0.00201553\n",
      "Iteration 3101, loss = 0.00201455\n",
      "Iteration 3102, loss = 0.00201379\n",
      "Iteration 3103, loss = 0.00201306\n",
      "Iteration 3104, loss = 0.00201205\n",
      "Iteration 3105, loss = 0.00201130\n",
      "Iteration 3106, loss = 0.00201045\n",
      "Iteration 3107, loss = 0.00200962\n",
      "Iteration 3108, loss = 0.00200867\n",
      "Iteration 3109, loss = 0.00200790\n",
      "Iteration 3110, loss = 0.00200719\n",
      "Iteration 3111, loss = 0.00200616\n",
      "Iteration 3112, loss = 0.00200545\n",
      "Iteration 3113, loss = 0.00200451\n",
      "Iteration 3114, loss = 0.00200366\n",
      "Iteration 3115, loss = 0.00200293\n",
      "Iteration 3116, loss = 0.00200202\n",
      "Iteration 3117, loss = 0.00200124\n",
      "Iteration 3118, loss = 0.00200041\n",
      "Iteration 3119, loss = 0.00199951\n",
      "Iteration 3120, loss = 0.00199873\n",
      "Iteration 3121, loss = 0.00199790\n",
      "Iteration 3122, loss = 0.00199696\n",
      "Iteration 3123, loss = 0.00199620\n",
      "Iteration 3124, loss = 0.00199549\n",
      "Iteration 3125, loss = 0.00199451\n",
      "Iteration 3126, loss = 0.00199372\n",
      "Iteration 3127, loss = 0.00199288\n",
      "Iteration 3128, loss = 0.00199204\n",
      "Iteration 3129, loss = 0.00199120\n",
      "Iteration 3130, loss = 0.00199043\n",
      "Iteration 3131, loss = 0.00198958\n",
      "Iteration 3132, loss = 0.00198882\n",
      "Iteration 3133, loss = 0.00198803\n",
      "Iteration 3134, loss = 0.00198708\n",
      "Iteration 3135, loss = 0.00198617\n",
      "Iteration 3136, loss = 0.00198535\n",
      "Iteration 3137, loss = 0.00198459\n",
      "Iteration 3138, loss = 0.00198372\n",
      "Iteration 3139, loss = 0.00198287\n",
      "Iteration 3140, loss = 0.00198198\n",
      "Iteration 3141, loss = 0.00198125\n",
      "Iteration 3142, loss = 0.00198032\n",
      "Iteration 3143, loss = 0.00197955\n",
      "Iteration 3144, loss = 0.00197862\n",
      "Iteration 3145, loss = 0.00197785\n",
      "Iteration 3146, loss = 0.00197697\n",
      "Iteration 3147, loss = 0.00197606\n",
      "Iteration 3148, loss = 0.00197523\n",
      "Iteration 3149, loss = 0.00197446\n",
      "Iteration 3150, loss = 0.00197356\n",
      "Iteration 3151, loss = 0.00197276\n",
      "Iteration 3152, loss = 0.00197185\n",
      "Iteration 3153, loss = 0.00197107\n",
      "Iteration 3154, loss = 0.00197031\n",
      "Iteration 3155, loss = 0.00196961\n",
      "Iteration 3156, loss = 0.00196881\n",
      "Iteration 3157, loss = 0.00196789\n",
      "Iteration 3158, loss = 0.00196694\n",
      "Iteration 3159, loss = 0.00196618\n",
      "Iteration 3160, loss = 0.00196536\n",
      "Iteration 3161, loss = 0.00196464\n",
      "Iteration 3162, loss = 0.00196375\n",
      "Iteration 3163, loss = 0.00196305\n",
      "Iteration 3164, loss = 0.00196222\n",
      "Iteration 3165, loss = 0.00196135\n",
      "Iteration 3166, loss = 0.00196066\n",
      "Iteration 3167, loss = 0.00195970\n",
      "Iteration 3168, loss = 0.00195899\n",
      "Iteration 3169, loss = 0.00195808\n",
      "Iteration 3170, loss = 0.00195739\n",
      "Iteration 3171, loss = 0.00195654\n",
      "Iteration 3172, loss = 0.00195571\n",
      "Iteration 3173, loss = 0.00195495\n",
      "Iteration 3174, loss = 0.00195407\n",
      "Iteration 3175, loss = 0.00195324\n",
      "Iteration 3176, loss = 0.00195240\n",
      "Iteration 3177, loss = 0.00195156\n",
      "Iteration 3178, loss = 0.00195079\n",
      "Iteration 3179, loss = 0.00194989\n",
      "Iteration 3180, loss = 0.00194911\n",
      "Iteration 3181, loss = 0.00194823\n",
      "Iteration 3182, loss = 0.00194744\n",
      "Iteration 3183, loss = 0.00194676\n",
      "Iteration 3184, loss = 0.00194587\n",
      "Iteration 3185, loss = 0.00194514\n",
      "Iteration 3186, loss = 0.00194438\n",
      "Iteration 3187, loss = 0.00194355\n",
      "Iteration 3188, loss = 0.00194275\n",
      "Iteration 3189, loss = 0.00194190\n",
      "Iteration 3190, loss = 0.00194113\n",
      "Iteration 3191, loss = 0.00194025\n",
      "Iteration 3192, loss = 0.00193950\n",
      "Iteration 3193, loss = 0.00193866\n",
      "Iteration 3194, loss = 0.00193790\n",
      "Iteration 3195, loss = 0.00193720\n",
      "Iteration 3196, loss = 0.00193631\n",
      "Iteration 3197, loss = 0.00193552\n",
      "Iteration 3198, loss = 0.00193468\n",
      "Iteration 3199, loss = 0.00193389\n",
      "Iteration 3200, loss = 0.00193321\n",
      "Iteration 3201, loss = 0.00193235\n",
      "Iteration 3202, loss = 0.00193144\n",
      "Iteration 3203, loss = 0.00193076\n",
      "Iteration 3204, loss = 0.00192985\n",
      "Iteration 3205, loss = 0.00192904\n",
      "Iteration 3206, loss = 0.00192844\n",
      "Iteration 3207, loss = 0.00192754\n",
      "Iteration 3208, loss = 0.00192663\n",
      "Iteration 3209, loss = 0.00192589\n",
      "Iteration 3210, loss = 0.00192513\n",
      "Iteration 3211, loss = 0.00192440\n",
      "Iteration 3212, loss = 0.00192354\n",
      "Iteration 3213, loss = 0.00192296\n",
      "Iteration 3214, loss = 0.00192189\n",
      "Iteration 3215, loss = 0.00192120\n",
      "Iteration 3216, loss = 0.00192031\n",
      "Iteration 3217, loss = 0.00191956\n",
      "Iteration 3218, loss = 0.00191884\n",
      "Iteration 3219, loss = 0.00191796\n",
      "Iteration 3220, loss = 0.00191724\n",
      "Iteration 3221, loss = 0.00191635\n",
      "Iteration 3222, loss = 0.00191568\n",
      "Iteration 3223, loss = 0.00191490\n",
      "Iteration 3224, loss = 0.00191400\n",
      "Iteration 3225, loss = 0.00191342\n",
      "Iteration 3226, loss = 0.00191236\n",
      "Iteration 3227, loss = 0.00191165\n",
      "Iteration 3228, loss = 0.00191084\n",
      "Iteration 3229, loss = 0.00191000\n",
      "Iteration 3230, loss = 0.00190939\n",
      "Iteration 3231, loss = 0.00190860\n",
      "Iteration 3232, loss = 0.00190764\n",
      "Iteration 3233, loss = 0.00190687\n",
      "Iteration 3234, loss = 0.00190616\n",
      "Iteration 3235, loss = 0.00190538\n",
      "Iteration 3236, loss = 0.00190461\n",
      "Iteration 3237, loss = 0.00190380\n",
      "Iteration 3238, loss = 0.00190324\n",
      "Iteration 3239, loss = 0.00190226\n",
      "Iteration 3240, loss = 0.00190145\n",
      "Iteration 3241, loss = 0.00190073\n",
      "Iteration 3242, loss = 0.00190007\n",
      "Iteration 3243, loss = 0.00189920\n",
      "Iteration 3244, loss = 0.00189857\n",
      "Iteration 3245, loss = 0.00189767\n",
      "Iteration 3246, loss = 0.00189689\n",
      "Iteration 3247, loss = 0.00189611\n",
      "Iteration 3248, loss = 0.00189533\n",
      "Iteration 3249, loss = 0.00189469\n",
      "Iteration 3250, loss = 0.00189391\n",
      "Iteration 3251, loss = 0.00189313\n",
      "Iteration 3252, loss = 0.00189261\n",
      "Iteration 3253, loss = 0.00189167\n",
      "Iteration 3254, loss = 0.00189099\n",
      "Iteration 3255, loss = 0.00189007\n",
      "Iteration 3256, loss = 0.00188936\n",
      "Iteration 3257, loss = 0.00188863\n",
      "Iteration 3258, loss = 0.00188797\n",
      "Iteration 3259, loss = 0.00188704\n",
      "Iteration 3260, loss = 0.00188636\n",
      "Iteration 3261, loss = 0.00188562\n",
      "Iteration 3262, loss = 0.00188497\n",
      "Iteration 3263, loss = 0.00188398\n",
      "Iteration 3264, loss = 0.00188327\n",
      "Iteration 3265, loss = 0.00188242\n",
      "Iteration 3266, loss = 0.00188166\n",
      "Iteration 3267, loss = 0.00188094\n",
      "Iteration 3268, loss = 0.00188032\n",
      "Iteration 3269, loss = 0.00187959\n",
      "Iteration 3270, loss = 0.00187892\n",
      "Iteration 3271, loss = 0.00187799\n",
      "Iteration 3272, loss = 0.00187717\n",
      "Iteration 3273, loss = 0.00187657\n",
      "Iteration 3274, loss = 0.00187580\n",
      "Iteration 3275, loss = 0.00187501\n",
      "Iteration 3276, loss = 0.00187419\n",
      "Iteration 3277, loss = 0.00187361\n",
      "Iteration 3278, loss = 0.00187279\n",
      "Iteration 3279, loss = 0.00187198\n",
      "Iteration 3280, loss = 0.00187121\n",
      "Iteration 3281, loss = 0.00187049\n",
      "Iteration 3282, loss = 0.00186977\n",
      "Iteration 3283, loss = 0.00186895\n",
      "Iteration 3284, loss = 0.00186823\n",
      "Iteration 3285, loss = 0.00186760\n",
      "Iteration 3286, loss = 0.00186680\n",
      "Iteration 3287, loss = 0.00186601\n",
      "Iteration 3288, loss = 0.00186523\n",
      "Iteration 3289, loss = 0.00186468\n",
      "Iteration 3290, loss = 0.00186377\n",
      "Iteration 3291, loss = 0.00186289\n",
      "Iteration 3292, loss = 0.00186221\n",
      "Iteration 3293, loss = 0.00186140\n",
      "Iteration 3294, loss = 0.00186074\n",
      "Iteration 3295, loss = 0.00186007\n",
      "Iteration 3296, loss = 0.00185917\n",
      "Iteration 3297, loss = 0.00185851\n",
      "Iteration 3298, loss = 0.00185774\n",
      "Iteration 3299, loss = 0.00185705\n",
      "Iteration 3300, loss = 0.00185630\n",
      "Iteration 3301, loss = 0.00185573\n",
      "Iteration 3302, loss = 0.00185472\n",
      "Iteration 3303, loss = 0.00185403\n",
      "Iteration 3304, loss = 0.00185337\n",
      "Iteration 3305, loss = 0.00185254\n",
      "Iteration 3306, loss = 0.00185193\n",
      "Iteration 3307, loss = 0.00185118\n",
      "Iteration 3308, loss = 0.00185039\n",
      "Iteration 3309, loss = 0.00184986\n",
      "Iteration 3310, loss = 0.00184892\n",
      "Iteration 3311, loss = 0.00184821\n",
      "Iteration 3312, loss = 0.00184753\n",
      "Iteration 3313, loss = 0.00184693\n",
      "Iteration 3314, loss = 0.00184601\n",
      "Iteration 3315, loss = 0.00184529\n",
      "Iteration 3316, loss = 0.00184452\n",
      "Iteration 3317, loss = 0.00184393\n",
      "Iteration 3318, loss = 0.00184310\n",
      "Iteration 3319, loss = 0.00184239\n",
      "Iteration 3320, loss = 0.00184151\n",
      "Iteration 3321, loss = 0.00184094\n",
      "Iteration 3322, loss = 0.00184021\n",
      "Iteration 3323, loss = 0.00183956\n",
      "Iteration 3324, loss = 0.00183871\n",
      "Iteration 3325, loss = 0.00183806\n",
      "Iteration 3326, loss = 0.00183729\n",
      "Iteration 3327, loss = 0.00183651\n",
      "Iteration 3328, loss = 0.00183577\n",
      "Iteration 3329, loss = 0.00183501\n",
      "Iteration 3330, loss = 0.00183432\n",
      "Iteration 3331, loss = 0.00183361\n",
      "Iteration 3332, loss = 0.00183297\n",
      "Iteration 3333, loss = 0.00183222\n",
      "Iteration 3334, loss = 0.00183167\n",
      "Iteration 3335, loss = 0.00183071\n",
      "Iteration 3336, loss = 0.00183013\n",
      "Iteration 3337, loss = 0.00182923\n",
      "Iteration 3338, loss = 0.00182853\n",
      "Iteration 3339, loss = 0.00182782\n",
      "Iteration 3340, loss = 0.00182709\n",
      "Iteration 3341, loss = 0.00182632\n",
      "Iteration 3342, loss = 0.00182566\n",
      "Iteration 3343, loss = 0.00182493\n",
      "Iteration 3344, loss = 0.00182441\n",
      "Iteration 3345, loss = 0.00182350\n",
      "Iteration 3346, loss = 0.00182277\n",
      "Iteration 3347, loss = 0.00182207\n",
      "Iteration 3348, loss = 0.00182129\n",
      "Iteration 3349, loss = 0.00182063\n",
      "Iteration 3350, loss = 0.00182001\n",
      "Iteration 3351, loss = 0.00181923\n",
      "Iteration 3352, loss = 0.00181842\n",
      "Iteration 3353, loss = 0.00181774\n",
      "Iteration 3354, loss = 0.00181714\n",
      "Iteration 3355, loss = 0.00181637\n",
      "Iteration 3356, loss = 0.00181575\n",
      "Iteration 3357, loss = 0.00181498\n",
      "Iteration 3358, loss = 0.00181423\n",
      "Iteration 3359, loss = 0.00181359\n",
      "Iteration 3360, loss = 0.00181280\n",
      "Iteration 3361, loss = 0.00181207\n",
      "Iteration 3362, loss = 0.00181140\n",
      "Iteration 3363, loss = 0.00181064\n",
      "Iteration 3364, loss = 0.00180998\n",
      "Iteration 3365, loss = 0.00180917\n",
      "Iteration 3366, loss = 0.00180858\n",
      "Iteration 3367, loss = 0.00180777\n",
      "Iteration 3368, loss = 0.00180714\n",
      "Iteration 3369, loss = 0.00180639\n",
      "Iteration 3370, loss = 0.00180567\n",
      "Iteration 3371, loss = 0.00180494\n",
      "Iteration 3372, loss = 0.00180430\n",
      "Iteration 3373, loss = 0.00180358\n",
      "Iteration 3374, loss = 0.00180289\n",
      "Iteration 3375, loss = 0.00180220\n",
      "Iteration 3376, loss = 0.00180165\n",
      "Iteration 3377, loss = 0.00180078\n",
      "Iteration 3378, loss = 0.00180002\n",
      "Iteration 3379, loss = 0.00179934\n",
      "Iteration 3380, loss = 0.00179873\n",
      "Iteration 3381, loss = 0.00179809\n",
      "Iteration 3382, loss = 0.00179730\n",
      "Iteration 3383, loss = 0.00179651\n",
      "Iteration 3384, loss = 0.00179598\n",
      "Iteration 3385, loss = 0.00179511\n",
      "Iteration 3386, loss = 0.00179447\n",
      "Iteration 3387, loss = 0.00179378\n",
      "Iteration 3388, loss = 0.00179297\n",
      "Iteration 3389, loss = 0.00179233\n",
      "Iteration 3390, loss = 0.00179173\n",
      "Iteration 3391, loss = 0.00179104\n",
      "Iteration 3392, loss = 0.00179023\n",
      "Iteration 3393, loss = 0.00178958\n",
      "Iteration 3394, loss = 0.00178890\n",
      "Iteration 3395, loss = 0.00178818\n",
      "Iteration 3396, loss = 0.00178754\n",
      "Iteration 3397, loss = 0.00178682\n",
      "Iteration 3398, loss = 0.00178609\n",
      "Iteration 3399, loss = 0.00178543\n",
      "Iteration 3400, loss = 0.00178470\n",
      "Iteration 3401, loss = 0.00178408\n",
      "Iteration 3402, loss = 0.00178334\n",
      "Iteration 3403, loss = 0.00178269\n",
      "Iteration 3404, loss = 0.00178198\n",
      "Iteration 3405, loss = 0.00178139\n",
      "Iteration 3406, loss = 0.00178067\n",
      "Iteration 3407, loss = 0.00178000\n",
      "Iteration 3408, loss = 0.00177929\n",
      "Iteration 3409, loss = 0.00177862\n",
      "Iteration 3410, loss = 0.00177796\n",
      "Iteration 3411, loss = 0.00177747\n",
      "Iteration 3412, loss = 0.00177655\n",
      "Iteration 3413, loss = 0.00177580\n",
      "Iteration 3414, loss = 0.00177513\n",
      "Iteration 3415, loss = 0.00177448\n",
      "Iteration 3416, loss = 0.00177377\n",
      "Iteration 3417, loss = 0.00177305\n",
      "Iteration 3418, loss = 0.00177243\n",
      "Iteration 3419, loss = 0.00177165\n",
      "Iteration 3420, loss = 0.00177099\n",
      "Iteration 3421, loss = 0.00177029\n",
      "Iteration 3422, loss = 0.00176961\n",
      "Iteration 3423, loss = 0.00176903\n",
      "Iteration 3424, loss = 0.00176829\n",
      "Iteration 3425, loss = 0.00176756\n",
      "Iteration 3426, loss = 0.00176699\n",
      "Iteration 3427, loss = 0.00176630\n",
      "Iteration 3428, loss = 0.00176575\n",
      "Iteration 3429, loss = 0.00176494\n",
      "Iteration 3430, loss = 0.00176425\n",
      "Iteration 3431, loss = 0.00176357\n",
      "Iteration 3432, loss = 0.00176292\n",
      "Iteration 3433, loss = 0.00176211\n",
      "Iteration 3434, loss = 0.00176153\n",
      "Iteration 3435, loss = 0.00176083\n",
      "Iteration 3436, loss = 0.00176021\n",
      "Iteration 3437, loss = 0.00175953\n",
      "Iteration 3438, loss = 0.00175885\n",
      "Iteration 3439, loss = 0.00175817\n",
      "Iteration 3440, loss = 0.00175761\n",
      "Iteration 3441, loss = 0.00175690\n",
      "Iteration 3442, loss = 0.00175621\n",
      "Iteration 3443, loss = 0.00175553\n",
      "Iteration 3444, loss = 0.00175508\n",
      "Iteration 3445, loss = 0.00175417\n",
      "Iteration 3446, loss = 0.00175349\n",
      "Iteration 3447, loss = 0.00175282\n",
      "Iteration 3448, loss = 0.00175214\n",
      "Iteration 3449, loss = 0.00175156\n",
      "Iteration 3450, loss = 0.00175085\n",
      "Iteration 3451, loss = 0.00175022\n",
      "Iteration 3452, loss = 0.00174961\n",
      "Iteration 3453, loss = 0.00174881\n",
      "Iteration 3454, loss = 0.00174813\n",
      "Iteration 3455, loss = 0.00174751\n",
      "Iteration 3456, loss = 0.00174684\n",
      "Iteration 3457, loss = 0.00174618\n",
      "Iteration 3458, loss = 0.00174566\n",
      "Iteration 3459, loss = 0.00174486\n",
      "Iteration 3460, loss = 0.00174426\n",
      "Iteration 3461, loss = 0.00174355\n",
      "Iteration 3462, loss = 0.00174290\n",
      "Iteration 3463, loss = 0.00174227\n",
      "Iteration 3464, loss = 0.00174155\n",
      "Iteration 3465, loss = 0.00174092\n",
      "Iteration 3466, loss = 0.00174030\n",
      "Iteration 3467, loss = 0.00173967\n",
      "Iteration 3468, loss = 0.00173896\n",
      "Iteration 3469, loss = 0.00173835\n",
      "Iteration 3470, loss = 0.00173764\n",
      "Iteration 3471, loss = 0.00173712\n",
      "Iteration 3472, loss = 0.00173633\n",
      "Iteration 3473, loss = 0.00173558\n",
      "Iteration 3474, loss = 0.00173496\n",
      "Iteration 3475, loss = 0.00173430\n",
      "Iteration 3476, loss = 0.00173359\n",
      "Iteration 3477, loss = 0.00173310\n",
      "Iteration 3478, loss = 0.00173231\n",
      "Iteration 3479, loss = 0.00173171\n",
      "Iteration 3480, loss = 0.00173109\n",
      "Iteration 3481, loss = 0.00173033\n",
      "Iteration 3482, loss = 0.00172978\n",
      "Iteration 3483, loss = 0.00172908\n",
      "Iteration 3484, loss = 0.00172842\n",
      "Iteration 3485, loss = 0.00172763\n",
      "Iteration 3486, loss = 0.00172704\n",
      "Iteration 3487, loss = 0.00172638\n",
      "Iteration 3488, loss = 0.00172579\n",
      "Iteration 3489, loss = 0.00172505\n",
      "Iteration 3490, loss = 0.00172452\n",
      "Iteration 3491, loss = 0.00172375\n",
      "Iteration 3492, loss = 0.00172320\n",
      "Iteration 3493, loss = 0.00172249\n",
      "Iteration 3494, loss = 0.00172179\n",
      "Iteration 3495, loss = 0.00172122\n",
      "Iteration 3496, loss = 0.00172055\n",
      "Iteration 3497, loss = 0.00171995\n",
      "Iteration 3498, loss = 0.00171930\n",
      "Iteration 3499, loss = 0.00171860\n",
      "Iteration 3500, loss = 0.00171802\n",
      "Iteration 3501, loss = 0.00171734\n",
      "Iteration 3502, loss = 0.00171668\n",
      "Iteration 3503, loss = 0.00171616\n",
      "Iteration 3504, loss = 0.00171540\n",
      "Iteration 3505, loss = 0.00171478\n",
      "Iteration 3506, loss = 0.00171413\n",
      "Iteration 3507, loss = 0.00171351\n",
      "Iteration 3508, loss = 0.00171282\n",
      "Iteration 3509, loss = 0.00171222\n",
      "Iteration 3510, loss = 0.00171158\n",
      "Iteration 3511, loss = 0.00171087\n",
      "Iteration 3512, loss = 0.00171040\n",
      "Iteration 3513, loss = 0.00170968\n",
      "Iteration 3514, loss = 0.00170904\n",
      "Iteration 3515, loss = 0.00170840\n",
      "Iteration 3516, loss = 0.00170776\n",
      "Iteration 3517, loss = 0.00170720\n",
      "Iteration 3518, loss = 0.00170652\n",
      "Iteration 3519, loss = 0.00170601\n",
      "Iteration 3520, loss = 0.00170519\n",
      "Iteration 3521, loss = 0.00170469\n",
      "Iteration 3522, loss = 0.00170404\n",
      "Iteration 3523, loss = 0.00170354\n",
      "Iteration 3524, loss = 0.00170271\n",
      "Iteration 3525, loss = 0.00170215\n",
      "Iteration 3526, loss = 0.00170156\n",
      "Iteration 3527, loss = 0.00170101\n",
      "Iteration 3528, loss = 0.00170025\n",
      "Iteration 3529, loss = 0.00169964\n",
      "Iteration 3530, loss = 0.00169897\n",
      "Iteration 3531, loss = 0.00169836\n",
      "Iteration 3532, loss = 0.00169782\n",
      "Iteration 3533, loss = 0.00169709\n",
      "Iteration 3534, loss = 0.00169640\n",
      "Iteration 3535, loss = 0.00169582\n",
      "Iteration 3536, loss = 0.00169521\n",
      "Iteration 3537, loss = 0.00169453\n",
      "Iteration 3538, loss = 0.00169391\n",
      "Iteration 3539, loss = 0.00169329\n",
      "Iteration 3540, loss = 0.00169264\n",
      "Iteration 3541, loss = 0.00169201\n",
      "Iteration 3542, loss = 0.00169139\n",
      "Iteration 3543, loss = 0.00169075\n",
      "Iteration 3544, loss = 0.00169014\n",
      "Iteration 3545, loss = 0.00168959\n",
      "Iteration 3546, loss = 0.00168898\n",
      "Iteration 3547, loss = 0.00168825\n",
      "Iteration 3548, loss = 0.00168808\n",
      "Iteration 3549, loss = 0.00168710\n",
      "Iteration 3550, loss = 0.00168639\n",
      "Iteration 3551, loss = 0.00168583\n",
      "Iteration 3552, loss = 0.00168524\n",
      "Iteration 3553, loss = 0.00168455\n",
      "Iteration 3554, loss = 0.00168401\n",
      "Iteration 3555, loss = 0.00168350\n",
      "Iteration 3556, loss = 0.00168274\n",
      "Iteration 3557, loss = 0.00168211\n",
      "Iteration 3558, loss = 0.00168147\n",
      "Iteration 3559, loss = 0.00168087\n",
      "Iteration 3560, loss = 0.00168025\n",
      "Iteration 3561, loss = 0.00167970\n",
      "Iteration 3562, loss = 0.00167897\n",
      "Iteration 3563, loss = 0.00167840\n",
      "Iteration 3564, loss = 0.00167786\n",
      "Iteration 3565, loss = 0.00167731\n",
      "Iteration 3566, loss = 0.00167651\n",
      "Iteration 3567, loss = 0.00167594\n",
      "Iteration 3568, loss = 0.00167529\n",
      "Iteration 3569, loss = 0.00167465\n",
      "Iteration 3570, loss = 0.00167405\n",
      "Iteration 3571, loss = 0.00167351\n",
      "Iteration 3572, loss = 0.00167277\n",
      "Iteration 3573, loss = 0.00167217\n",
      "Iteration 3574, loss = 0.00167167\n",
      "Iteration 3575, loss = 0.00167095\n",
      "Iteration 3576, loss = 0.00167037\n",
      "Iteration 3577, loss = 0.00166974\n",
      "Iteration 3578, loss = 0.00166931\n",
      "Iteration 3579, loss = 0.00166853\n",
      "Iteration 3580, loss = 0.00166799\n",
      "Iteration 3581, loss = 0.00166734\n",
      "Iteration 3582, loss = 0.00166672\n",
      "Iteration 3583, loss = 0.00166616\n",
      "Iteration 3584, loss = 0.00166571\n",
      "Iteration 3585, loss = 0.00166498\n",
      "Iteration 3586, loss = 0.00166441\n",
      "Iteration 3587, loss = 0.00166367\n",
      "Iteration 3588, loss = 0.00166300\n",
      "Iteration 3589, loss = 0.00166250\n",
      "Iteration 3590, loss = 0.00166190\n",
      "Iteration 3591, loss = 0.00166110\n",
      "Iteration 3592, loss = 0.00166068\n",
      "Iteration 3593, loss = 0.00165992\n",
      "Iteration 3594, loss = 0.00165931\n",
      "Iteration 3595, loss = 0.00165870\n",
      "Iteration 3596, loss = 0.00165806\n",
      "Iteration 3597, loss = 0.00165745\n",
      "Iteration 3598, loss = 0.00165685\n",
      "Iteration 3599, loss = 0.00165619\n",
      "Iteration 3600, loss = 0.00165568\n",
      "Iteration 3601, loss = 0.00165505\n",
      "Iteration 3602, loss = 0.00165443\n",
      "Iteration 3603, loss = 0.00165391\n",
      "Iteration 3604, loss = 0.00165325\n",
      "Iteration 3605, loss = 0.00165265\n",
      "Iteration 3606, loss = 0.00165203\n",
      "Iteration 3607, loss = 0.00165170\n",
      "Iteration 3608, loss = 0.00165084\n",
      "Iteration 3609, loss = 0.00165030\n",
      "Iteration 3610, loss = 0.00164965\n",
      "Iteration 3611, loss = 0.00164908\n",
      "Iteration 3612, loss = 0.00164854\n",
      "Iteration 3613, loss = 0.00164786\n",
      "Iteration 3614, loss = 0.00164733\n",
      "Iteration 3615, loss = 0.00164669\n",
      "Iteration 3616, loss = 0.00164609\n",
      "Iteration 3617, loss = 0.00164548\n",
      "Iteration 3618, loss = 0.00164506\n",
      "Iteration 3619, loss = 0.00164430\n",
      "Iteration 3620, loss = 0.00164371\n",
      "Iteration 3621, loss = 0.00164313\n",
      "Iteration 3622, loss = 0.00164245\n",
      "Iteration 3623, loss = 0.00164197\n",
      "Iteration 3624, loss = 0.00164134\n",
      "Iteration 3625, loss = 0.00164074\n",
      "Iteration 3626, loss = 0.00164012\n",
      "Iteration 3627, loss = 0.00163957\n",
      "Iteration 3628, loss = 0.00163906\n",
      "Iteration 3629, loss = 0.00163844\n",
      "Iteration 3630, loss = 0.00163800\n",
      "Iteration 3631, loss = 0.00163730\n",
      "Iteration 3632, loss = 0.00163665\n",
      "Iteration 3633, loss = 0.00163609\n",
      "Iteration 3634, loss = 0.00163544\n",
      "Iteration 3635, loss = 0.00163492\n",
      "Iteration 3636, loss = 0.00163425\n",
      "Iteration 3637, loss = 0.00163369\n",
      "Iteration 3638, loss = 0.00163307\n",
      "Iteration 3639, loss = 0.00163250\n",
      "Iteration 3640, loss = 0.00163189\n",
      "Iteration 3641, loss = 0.00163138\n",
      "Iteration 3642, loss = 0.00163074\n",
      "Iteration 3643, loss = 0.00163018\n",
      "Iteration 3644, loss = 0.00162952\n",
      "Iteration 3645, loss = 0.00162896\n",
      "Iteration 3646, loss = 0.00162837\n",
      "Iteration 3647, loss = 0.00162783\n",
      "Iteration 3648, loss = 0.00162732\n",
      "Iteration 3649, loss = 0.00162673\n",
      "Iteration 3650, loss = 0.00162613\n",
      "Iteration 3651, loss = 0.00162560\n",
      "Iteration 3652, loss = 0.00162496\n",
      "Iteration 3653, loss = 0.00162440\n",
      "Iteration 3654, loss = 0.00162371\n",
      "Iteration 3655, loss = 0.00162318\n",
      "Iteration 3656, loss = 0.00162262\n",
      "Iteration 3657, loss = 0.00162206\n",
      "Iteration 3658, loss = 0.00162144\n",
      "Iteration 3659, loss = 0.00162085\n",
      "Iteration 3660, loss = 0.00162027\n",
      "Iteration 3661, loss = 0.00161972\n",
      "Iteration 3662, loss = 0.00161906\n",
      "Iteration 3663, loss = 0.00161850\n",
      "Iteration 3664, loss = 0.00161799\n",
      "Iteration 3665, loss = 0.00161739\n",
      "Iteration 3666, loss = 0.00161679\n",
      "Iteration 3667, loss = 0.00161627\n",
      "Iteration 3668, loss = 0.00161564\n",
      "Iteration 3669, loss = 0.00161504\n",
      "Iteration 3670, loss = 0.00161443\n",
      "Iteration 3671, loss = 0.00161383\n",
      "Iteration 3672, loss = 0.00161321\n",
      "Iteration 3673, loss = 0.00161271\n",
      "Iteration 3674, loss = 0.00161223\n",
      "Iteration 3675, loss = 0.00161156\n",
      "Iteration 3676, loss = 0.00161103\n",
      "Iteration 3677, loss = 0.00161050\n",
      "Iteration 3678, loss = 0.00160979\n",
      "Iteration 3679, loss = 0.00160929\n",
      "Iteration 3680, loss = 0.00160868\n",
      "Iteration 3681, loss = 0.00160809\n",
      "Iteration 3682, loss = 0.00160757\n",
      "Iteration 3683, loss = 0.00160692\n",
      "Iteration 3684, loss = 0.00160636\n",
      "Iteration 3685, loss = 0.00160587\n",
      "Iteration 3686, loss = 0.00160523\n",
      "Iteration 3687, loss = 0.00160461\n",
      "Iteration 3688, loss = 0.00160411\n",
      "Iteration 3689, loss = 0.00160351\n",
      "Iteration 3690, loss = 0.00160292\n",
      "Iteration 3691, loss = 0.00160245\n",
      "Iteration 3692, loss = 0.00160175\n",
      "Iteration 3693, loss = 0.00160114\n",
      "Iteration 3694, loss = 0.00160074\n",
      "Iteration 3695, loss = 0.00160003\n",
      "Iteration 3696, loss = 0.00159952\n",
      "Iteration 3697, loss = 0.00159897\n",
      "Iteration 3698, loss = 0.00159830\n",
      "Iteration 3699, loss = 0.00159780\n",
      "Iteration 3700, loss = 0.00159721\n",
      "Iteration 3701, loss = 0.00159667\n",
      "Iteration 3702, loss = 0.00159617\n",
      "Iteration 3703, loss = 0.00159557\n",
      "Iteration 3704, loss = 0.00159495\n",
      "Iteration 3705, loss = 0.00159450\n",
      "Iteration 3706, loss = 0.00159382\n",
      "Iteration 3707, loss = 0.00159333\n",
      "Iteration 3708, loss = 0.00159272\n",
      "Iteration 3709, loss = 0.00159218\n",
      "Iteration 3710, loss = 0.00159157\n",
      "Iteration 3711, loss = 0.00159100\n",
      "Iteration 3712, loss = 0.00159044\n",
      "Iteration 3713, loss = 0.00158988\n",
      "Iteration 3714, loss = 0.00158932\n",
      "Iteration 3715, loss = 0.00158877\n",
      "Iteration 3716, loss = 0.00158857\n",
      "Iteration 3717, loss = 0.00158767\n",
      "Iteration 3718, loss = 0.00158710\n",
      "Iteration 3719, loss = 0.00158656\n",
      "Iteration 3720, loss = 0.00158599\n",
      "Iteration 3721, loss = 0.00158551\n",
      "Iteration 3722, loss = 0.00158481\n",
      "Iteration 3723, loss = 0.00158453\n",
      "Iteration 3724, loss = 0.00158372\n",
      "Iteration 3725, loss = 0.00158312\n",
      "Iteration 3726, loss = 0.00158254\n",
      "Iteration 3727, loss = 0.00158194\n",
      "Iteration 3728, loss = 0.00158147\n",
      "Iteration 3729, loss = 0.00158087\n",
      "Iteration 3730, loss = 0.00158037\n",
      "Iteration 3731, loss = 0.00157980\n",
      "Iteration 3732, loss = 0.00157920\n",
      "Iteration 3733, loss = 0.00157877\n",
      "Iteration 3734, loss = 0.00157815\n",
      "Iteration 3735, loss = 0.00157758\n",
      "Iteration 3736, loss = 0.00157710\n",
      "Iteration 3737, loss = 0.00157653\n",
      "Iteration 3738, loss = 0.00157603\n",
      "Iteration 3739, loss = 0.00157534\n",
      "Iteration 3740, loss = 0.00157492\n",
      "Iteration 3741, loss = 0.00157431\n",
      "Iteration 3742, loss = 0.00157372\n",
      "Iteration 3743, loss = 0.00157317\n",
      "Iteration 3744, loss = 0.00157265\n",
      "Iteration 3745, loss = 0.00157203\n",
      "Iteration 3746, loss = 0.00157155\n",
      "Iteration 3747, loss = 0.00157103\n",
      "Iteration 3748, loss = 0.00157058\n",
      "Iteration 3749, loss = 0.00156988\n",
      "Iteration 3750, loss = 0.00156940\n",
      "Iteration 3751, loss = 0.00156882\n",
      "Iteration 3752, loss = 0.00156825\n",
      "Iteration 3753, loss = 0.00156774\n",
      "Iteration 3754, loss = 0.00156724\n",
      "Iteration 3755, loss = 0.00156668\n",
      "Iteration 3756, loss = 0.00156620\n",
      "Iteration 3757, loss = 0.00156563\n",
      "Iteration 3758, loss = 0.00156508\n",
      "Iteration 3759, loss = 0.00156440\n",
      "Iteration 3760, loss = 0.00156393\n",
      "Iteration 3761, loss = 0.00156338\n",
      "Iteration 3762, loss = 0.00156283\n",
      "Iteration 3763, loss = 0.00156230\n",
      "Iteration 3764, loss = 0.00156173\n",
      "Iteration 3765, loss = 0.00156125\n",
      "Iteration 3766, loss = 0.00156071\n",
      "Iteration 3767, loss = 0.00156020\n",
      "Iteration 3768, loss = 0.00155966\n",
      "Iteration 3769, loss = 0.00155910\n",
      "Iteration 3770, loss = 0.00155854\n",
      "Iteration 3771, loss = 0.00155804\n",
      "Iteration 3772, loss = 0.00155745\n",
      "Iteration 3773, loss = 0.00155699\n",
      "Iteration 3774, loss = 0.00155639\n",
      "Iteration 3775, loss = 0.00155589\n",
      "Iteration 3776, loss = 0.00155534\n",
      "Iteration 3777, loss = 0.00155479\n",
      "Iteration 3778, loss = 0.00155433\n",
      "Iteration 3779, loss = 0.00155379\n",
      "Iteration 3780, loss = 0.00155329\n",
      "Iteration 3781, loss = 0.00155291\n",
      "Iteration 3782, loss = 0.00155216\n",
      "Iteration 3783, loss = 0.00155170\n",
      "Iteration 3784, loss = 0.00155120\n",
      "Iteration 3785, loss = 0.00155055\n",
      "Iteration 3786, loss = 0.00155004\n",
      "Iteration 3787, loss = 0.00154945\n",
      "Iteration 3788, loss = 0.00154899\n",
      "Iteration 3789, loss = 0.00154842\n",
      "Iteration 3790, loss = 0.00154783\n",
      "Iteration 3791, loss = 0.00154727\n",
      "Iteration 3792, loss = 0.00154684\n",
      "Iteration 3793, loss = 0.00154626\n",
      "Iteration 3794, loss = 0.00154568\n",
      "Iteration 3795, loss = 0.00154512\n",
      "Iteration 3796, loss = 0.00154457\n",
      "Iteration 3797, loss = 0.00154409\n",
      "Iteration 3798, loss = 0.00154358\n",
      "Iteration 3799, loss = 0.00154299\n",
      "Iteration 3800, loss = 0.00154252\n",
      "Iteration 3801, loss = 0.00154208\n",
      "Iteration 3802, loss = 0.00154147\n",
      "Iteration 3803, loss = 0.00154100\n",
      "Iteration 3804, loss = 0.00154041\n",
      "Iteration 3805, loss = 0.00153996\n",
      "Iteration 3806, loss = 0.00153935\n",
      "Iteration 3807, loss = 0.00153891\n",
      "Iteration 3808, loss = 0.00153837\n",
      "Iteration 3809, loss = 0.00153779\n",
      "Iteration 3810, loss = 0.00153732\n",
      "Iteration 3811, loss = 0.00153675\n",
      "Iteration 3812, loss = 0.00153621\n",
      "Iteration 3813, loss = 0.00153589\n",
      "Iteration 3814, loss = 0.00153517\n",
      "Iteration 3815, loss = 0.00153466\n",
      "Iteration 3816, loss = 0.00153420\n",
      "Iteration 3817, loss = 0.00153359\n",
      "Iteration 3818, loss = 0.00153308\n",
      "Iteration 3819, loss = 0.00153256\n",
      "Iteration 3820, loss = 0.00153201\n",
      "Iteration 3821, loss = 0.00153150\n",
      "Iteration 3822, loss = 0.00153103\n",
      "Iteration 3823, loss = 0.00153044\n",
      "Iteration 3824, loss = 0.00152997\n",
      "Iteration 3825, loss = 0.00152940\n",
      "Iteration 3826, loss = 0.00152890\n",
      "Iteration 3827, loss = 0.00152837\n",
      "Iteration 3828, loss = 0.00152783\n",
      "Iteration 3829, loss = 0.00152725\n",
      "Iteration 3830, loss = 0.00152677\n",
      "Iteration 3831, loss = 0.00152623\n",
      "Iteration 3832, loss = 0.00152572\n",
      "Iteration 3833, loss = 0.00152520\n",
      "Iteration 3834, loss = 0.00152463\n",
      "Iteration 3835, loss = 0.00152417\n",
      "Iteration 3836, loss = 0.00152359\n",
      "Iteration 3837, loss = 0.00152306\n",
      "Iteration 3838, loss = 0.00152254\n",
      "Iteration 3839, loss = 0.00152200\n",
      "Iteration 3840, loss = 0.00152156\n",
      "Iteration 3841, loss = 0.00152093\n",
      "Iteration 3842, loss = 0.00152050\n",
      "Iteration 3843, loss = 0.00151989\n",
      "Iteration 3844, loss = 0.00151942\n",
      "Iteration 3845, loss = 0.00151889\n",
      "Iteration 3846, loss = 0.00151833\n",
      "Iteration 3847, loss = 0.00151777\n",
      "Iteration 3848, loss = 0.00151725\n",
      "Iteration 3849, loss = 0.00151677\n",
      "Iteration 3850, loss = 0.00151631\n",
      "Iteration 3851, loss = 0.00151570\n",
      "Iteration 3852, loss = 0.00151523\n",
      "Iteration 3853, loss = 0.00151465\n",
      "Iteration 3854, loss = 0.00151412\n",
      "Iteration 3855, loss = 0.00151364\n",
      "Iteration 3856, loss = 0.00151309\n",
      "Iteration 3857, loss = 0.00151261\n",
      "Iteration 3858, loss = 0.00151215\n",
      "Iteration 3859, loss = 0.00151159\n",
      "Iteration 3860, loss = 0.00151106\n",
      "Iteration 3861, loss = 0.00151059\n",
      "Iteration 3862, loss = 0.00151014\n",
      "Iteration 3863, loss = 0.00150958\n",
      "Iteration 3864, loss = 0.00150902\n",
      "Iteration 3865, loss = 0.00150853\n",
      "Iteration 3866, loss = 0.00150803\n",
      "Iteration 3867, loss = 0.00150754\n",
      "Iteration 3868, loss = 0.00150700\n",
      "Iteration 3869, loss = 0.00150651\n",
      "Iteration 3870, loss = 0.00150595\n",
      "Iteration 3871, loss = 0.00150546\n",
      "Iteration 3872, loss = 0.00150503\n",
      "Iteration 3873, loss = 0.00150445\n",
      "Iteration 3874, loss = 0.00150393\n",
      "Iteration 3875, loss = 0.00150340\n",
      "Iteration 3876, loss = 0.00150292\n",
      "Iteration 3877, loss = 0.00150244\n",
      "Iteration 3878, loss = 0.00150185\n",
      "Iteration 3879, loss = 0.00150147\n",
      "Iteration 3880, loss = 0.00150097\n",
      "Iteration 3881, loss = 0.00150043\n",
      "Iteration 3882, loss = 0.00149991\n",
      "Iteration 3883, loss = 0.00149940\n",
      "Iteration 3884, loss = 0.00149895\n",
      "Iteration 3885, loss = 0.00149840\n",
      "Iteration 3886, loss = 0.00149797\n",
      "Iteration 3887, loss = 0.00149743\n",
      "Iteration 3888, loss = 0.00149690\n",
      "Iteration 3889, loss = 0.00149642\n",
      "Iteration 3890, loss = 0.00149591\n",
      "Iteration 3891, loss = 0.00149540\n",
      "Iteration 3892, loss = 0.00149494\n",
      "Iteration 3893, loss = 0.00149443\n",
      "Iteration 3894, loss = 0.00149390\n",
      "Iteration 3895, loss = 0.00149342\n",
      "Iteration 3896, loss = 0.00149290\n",
      "Iteration 3897, loss = 0.00149243\n",
      "Iteration 3898, loss = 0.00149190\n",
      "Iteration 3899, loss = 0.00149139\n",
      "Iteration 3900, loss = 0.00149087\n",
      "Iteration 3901, loss = 0.00149045\n",
      "Iteration 3902, loss = 0.00149003\n",
      "Iteration 3903, loss = 0.00148946\n",
      "Iteration 3904, loss = 0.00148896\n",
      "Iteration 3905, loss = 0.00148840\n",
      "Iteration 3906, loss = 0.00148798\n",
      "Iteration 3907, loss = 0.00148735\n",
      "Iteration 3908, loss = 0.00148696\n",
      "Iteration 3909, loss = 0.00148643\n",
      "Iteration 3910, loss = 0.00148588\n",
      "Iteration 3911, loss = 0.00148546\n",
      "Iteration 3912, loss = 0.00148490\n",
      "Iteration 3913, loss = 0.00148446\n",
      "Iteration 3914, loss = 0.00148392\n",
      "Iteration 3915, loss = 0.00148340\n",
      "Iteration 3916, loss = 0.00148289\n",
      "Iteration 3917, loss = 0.00148239\n",
      "Iteration 3918, loss = 0.00148184\n",
      "Iteration 3919, loss = 0.00148138\n",
      "Iteration 3920, loss = 0.00148085\n",
      "Iteration 3921, loss = 0.00148038\n",
      "Iteration 3922, loss = 0.00147982\n",
      "Iteration 3923, loss = 0.00147938\n",
      "Iteration 3924, loss = 0.00147888\n",
      "Iteration 3925, loss = 0.00147840\n",
      "Iteration 3926, loss = 0.00147784\n",
      "Iteration 3927, loss = 0.00147736\n",
      "Iteration 3928, loss = 0.00147687\n",
      "Iteration 3929, loss = 0.00147642\n",
      "Iteration 3930, loss = 0.00147592\n",
      "Iteration 3931, loss = 0.00147540\n",
      "Iteration 3932, loss = 0.00147498\n",
      "Iteration 3933, loss = 0.00147442\n",
      "Iteration 3934, loss = 0.00147401\n",
      "Iteration 3935, loss = 0.00147348\n",
      "Iteration 3936, loss = 0.00147308\n",
      "Iteration 3937, loss = 0.00147262\n",
      "Iteration 3938, loss = 0.00147208\n",
      "Iteration 3939, loss = 0.00147162\n",
      "Iteration 3940, loss = 0.00147108\n",
      "Iteration 3941, loss = 0.00147061\n",
      "Iteration 3942, loss = 0.00147009\n",
      "Iteration 3943, loss = 0.00146962\n",
      "Iteration 3944, loss = 0.00146917\n",
      "Iteration 3945, loss = 0.00146865\n",
      "Iteration 3946, loss = 0.00146817\n",
      "Iteration 3947, loss = 0.00146773\n",
      "Iteration 3948, loss = 0.00146715\n",
      "Iteration 3949, loss = 0.00146670\n",
      "Iteration 3950, loss = 0.00146610\n",
      "Iteration 3951, loss = 0.00146567\n",
      "Iteration 3952, loss = 0.00146516\n",
      "Iteration 3953, loss = 0.00146465\n",
      "Iteration 3954, loss = 0.00146419\n",
      "Iteration 3955, loss = 0.00146368\n",
      "Iteration 3956, loss = 0.00146321\n",
      "Iteration 3957, loss = 0.00146272\n",
      "Iteration 3958, loss = 0.00146232\n",
      "Iteration 3959, loss = 0.00146179\n",
      "Iteration 3960, loss = 0.00146125\n",
      "Iteration 3961, loss = 0.00146083\n",
      "Iteration 3962, loss = 0.00146050\n",
      "Iteration 3963, loss = 0.00145979\n",
      "Iteration 3964, loss = 0.00145936\n",
      "Iteration 3965, loss = 0.00145888\n",
      "Iteration 3966, loss = 0.00145840\n",
      "Iteration 3967, loss = 0.00145799\n",
      "Iteration 3968, loss = 0.00145757\n",
      "Iteration 3969, loss = 0.00145696\n",
      "Iteration 3970, loss = 0.00145649\n",
      "Iteration 3971, loss = 0.00145606\n",
      "Iteration 3972, loss = 0.00145559\n",
      "Iteration 3973, loss = 0.00145506\n",
      "Iteration 3974, loss = 0.00145455\n",
      "Iteration 3975, loss = 0.00145402\n",
      "Iteration 3976, loss = 0.00145369\n",
      "Iteration 3977, loss = 0.00145316\n",
      "Iteration 3978, loss = 0.00145269\n",
      "Iteration 3979, loss = 0.00145219\n",
      "Iteration 3980, loss = 0.00145163\n",
      "Iteration 3981, loss = 0.00145120\n",
      "Iteration 3982, loss = 0.00145068\n",
      "Iteration 3983, loss = 0.00145032\n",
      "Iteration 3984, loss = 0.00144979\n",
      "Iteration 3985, loss = 0.00144929\n",
      "Iteration 3986, loss = 0.00144882\n",
      "Iteration 3987, loss = 0.00144835\n",
      "Iteration 3988, loss = 0.00144781\n",
      "Iteration 3989, loss = 0.00144742\n",
      "Iteration 3990, loss = 0.00144692\n",
      "Iteration 3991, loss = 0.00144642\n",
      "Iteration 3992, loss = 0.00144590\n",
      "Iteration 3993, loss = 0.00144541\n",
      "Iteration 3994, loss = 0.00144495\n",
      "Iteration 3995, loss = 0.00144447\n",
      "Iteration 3996, loss = 0.00144402\n",
      "Iteration 3997, loss = 0.00144354\n",
      "Iteration 3998, loss = 0.00144307\n",
      "Iteration 3999, loss = 0.00144256\n",
      "Iteration 4000, loss = 0.00144211\n",
      "Iteration 4001, loss = 0.00144174\n",
      "Iteration 4002, loss = 0.00144114\n",
      "Iteration 4003, loss = 0.00144068\n",
      "Iteration 4004, loss = 0.00144017\n",
      "Iteration 4005, loss = 0.00143971\n",
      "Iteration 4006, loss = 0.00143925\n",
      "Iteration 4007, loss = 0.00143882\n",
      "Iteration 4008, loss = 0.00143829\n",
      "Iteration 4009, loss = 0.00143779\n",
      "Iteration 4010, loss = 0.00143738\n",
      "Iteration 4011, loss = 0.00143690\n",
      "Iteration 4012, loss = 0.00143650\n",
      "Iteration 4013, loss = 0.00143597\n",
      "Iteration 4014, loss = 0.00143553\n",
      "Iteration 4015, loss = 0.00143506\n",
      "Iteration 4016, loss = 0.00143465\n",
      "Iteration 4017, loss = 0.00143414\n",
      "Iteration 4018, loss = 0.00143365\n",
      "Iteration 4019, loss = 0.00143312\n",
      "Iteration 4020, loss = 0.00143269\n",
      "Iteration 4021, loss = 0.00143226\n",
      "Iteration 4022, loss = 0.00143175\n",
      "Iteration 4023, loss = 0.00143142\n",
      "Iteration 4024, loss = 0.00143087\n",
      "Iteration 4025, loss = 0.00143036\n",
      "Iteration 4026, loss = 0.00142996\n",
      "Iteration 4027, loss = 0.00142949\n",
      "Iteration 4028, loss = 0.00142900\n",
      "Iteration 4029, loss = 0.00142858\n",
      "Iteration 4030, loss = 0.00142812\n",
      "Iteration 4031, loss = 0.00142769\n",
      "Iteration 4032, loss = 0.00142720\n",
      "Iteration 4033, loss = 0.00142677\n",
      "Iteration 4034, loss = 0.00142623\n",
      "Iteration 4035, loss = 0.00142581\n",
      "Iteration 4036, loss = 0.00142531\n",
      "Iteration 4037, loss = 0.00142481\n",
      "Iteration 4038, loss = 0.00142446\n",
      "Iteration 4039, loss = 0.00142391\n",
      "Iteration 4040, loss = 0.00142349\n",
      "Iteration 4041, loss = 0.00142305\n",
      "Iteration 4042, loss = 0.00142262\n",
      "Iteration 4043, loss = 0.00142207\n",
      "Iteration 4044, loss = 0.00142159\n",
      "Iteration 4045, loss = 0.00142123\n",
      "Iteration 4046, loss = 0.00142081\n",
      "Iteration 4047, loss = 0.00142023\n",
      "Iteration 4048, loss = 0.00141979\n",
      "Iteration 4049, loss = 0.00141938\n",
      "Iteration 4050, loss = 0.00141885\n",
      "Iteration 4051, loss = 0.00141837\n",
      "Iteration 4052, loss = 0.00141795\n",
      "Iteration 4053, loss = 0.00141753\n",
      "Iteration 4054, loss = 0.00141705\n",
      "Iteration 4055, loss = 0.00141658\n",
      "Iteration 4056, loss = 0.00141620\n",
      "Iteration 4057, loss = 0.00141574\n",
      "Iteration 4058, loss = 0.00141521\n",
      "Iteration 4059, loss = 0.00141477\n",
      "Iteration 4060, loss = 0.00141434\n",
      "Iteration 4061, loss = 0.00141386\n",
      "Iteration 4062, loss = 0.00141360\n",
      "Iteration 4063, loss = 0.00141295\n",
      "Iteration 4064, loss = 0.00141246\n",
      "Iteration 4065, loss = 0.00141204\n",
      "Iteration 4066, loss = 0.00141159\n",
      "Iteration 4067, loss = 0.00141112\n",
      "Iteration 4068, loss = 0.00141060\n",
      "Iteration 4069, loss = 0.00141018\n",
      "Iteration 4070, loss = 0.00140979\n",
      "Iteration 4071, loss = 0.00140933\n",
      "Iteration 4072, loss = 0.00140879\n",
      "Iteration 4073, loss = 0.00140838\n",
      "Iteration 4074, loss = 0.00140797\n",
      "Iteration 4075, loss = 0.00140748\n",
      "Iteration 4076, loss = 0.00140701\n",
      "Iteration 4077, loss = 0.00140657\n",
      "Iteration 4078, loss = 0.00140606\n",
      "Iteration 4079, loss = 0.00140577\n",
      "Iteration 4080, loss = 0.00140521\n",
      "Iteration 4081, loss = 0.00140474\n",
      "Iteration 4082, loss = 0.00140433\n",
      "Iteration 4083, loss = 0.00140385\n",
      "Iteration 4084, loss = 0.00140338\n",
      "Iteration 4085, loss = 0.00140289\n",
      "Iteration 4086, loss = 0.00140251\n",
      "Iteration 4087, loss = 0.00140202\n",
      "Iteration 4088, loss = 0.00140160\n",
      "Iteration 4089, loss = 0.00140116\n",
      "Iteration 4090, loss = 0.00140071\n",
      "Iteration 4091, loss = 0.00140025\n",
      "Iteration 4092, loss = 0.00139977\n",
      "Iteration 4093, loss = 0.00139936\n",
      "Iteration 4094, loss = 0.00139891\n",
      "Iteration 4095, loss = 0.00139851\n",
      "Iteration 4096, loss = 0.00139809\n",
      "Iteration 4097, loss = 0.00139760\n",
      "Iteration 4098, loss = 0.00139726\n",
      "Iteration 4099, loss = 0.00139677\n",
      "Iteration 4100, loss = 0.00139629\n",
      "Iteration 4101, loss = 0.00139579\n",
      "Iteration 4102, loss = 0.00139533\n",
      "Iteration 4103, loss = 0.00139491\n",
      "Iteration 4104, loss = 0.00139442\n",
      "Iteration 4105, loss = 0.00139405\n",
      "Iteration 4106, loss = 0.00139363\n",
      "Iteration 4107, loss = 0.00139318\n",
      "Iteration 4108, loss = 0.00139257\n",
      "Iteration 4109, loss = 0.00139217\n",
      "Iteration 4110, loss = 0.00139178\n",
      "Iteration 4111, loss = 0.00139135\n",
      "Iteration 4112, loss = 0.00139086\n",
      "Iteration 4113, loss = 0.00139048\n",
      "Iteration 4114, loss = 0.00138994\n",
      "Iteration 4115, loss = 0.00138943\n",
      "Iteration 4116, loss = 0.00138908\n",
      "Iteration 4117, loss = 0.00138857\n",
      "Iteration 4118, loss = 0.00138815\n",
      "Iteration 4119, loss = 0.00138771\n",
      "Iteration 4120, loss = 0.00138738\n",
      "Iteration 4121, loss = 0.00138704\n",
      "Iteration 4122, loss = 0.00138640\n",
      "Iteration 4123, loss = 0.00138598\n",
      "Iteration 4124, loss = 0.00138558\n",
      "Iteration 4125, loss = 0.00138517\n",
      "Iteration 4126, loss = 0.00138466\n",
      "Iteration 4127, loss = 0.00138426\n",
      "Iteration 4128, loss = 0.00138387\n",
      "Iteration 4129, loss = 0.00138339\n",
      "Iteration 4130, loss = 0.00138296\n",
      "Iteration 4131, loss = 0.00138252\n",
      "Iteration 4132, loss = 0.00138229\n",
      "Iteration 4133, loss = 0.00138161\n",
      "Iteration 4134, loss = 0.00138123\n",
      "Iteration 4135, loss = 0.00138082\n",
      "Iteration 4136, loss = 0.00138032\n",
      "Iteration 4137, loss = 0.00137992\n",
      "Iteration 4138, loss = 0.00137950\n",
      "Iteration 4139, loss = 0.00137911\n",
      "Iteration 4140, loss = 0.00137863\n",
      "Iteration 4141, loss = 0.00137824\n",
      "Iteration 4142, loss = 0.00137781\n",
      "Iteration 4143, loss = 0.00137729\n",
      "Iteration 4144, loss = 0.00137687\n",
      "Iteration 4145, loss = 0.00137639\n",
      "Iteration 4146, loss = 0.00137601\n",
      "Iteration 4147, loss = 0.00137559\n",
      "Iteration 4148, loss = 0.00137514\n",
      "Iteration 4149, loss = 0.00137471\n",
      "Iteration 4150, loss = 0.00137427\n",
      "Iteration 4151, loss = 0.00137395\n",
      "Iteration 4152, loss = 0.00137334\n",
      "Iteration 4153, loss = 0.00137296\n",
      "Iteration 4154, loss = 0.00137253\n",
      "Iteration 4155, loss = 0.00137202\n",
      "Iteration 4156, loss = 0.00137162\n",
      "Iteration 4157, loss = 0.00137137\n",
      "Iteration 4158, loss = 0.00137096\n",
      "Iteration 4159, loss = 0.00137036\n",
      "Iteration 4160, loss = 0.00136992\n",
      "Iteration 4161, loss = 0.00136954\n",
      "Iteration 4162, loss = 0.00136913\n",
      "Iteration 4163, loss = 0.00136864\n",
      "Iteration 4164, loss = 0.00136822\n",
      "Iteration 4165, loss = 0.00136771\n",
      "Iteration 4166, loss = 0.00136732\n",
      "Iteration 4167, loss = 0.00136682\n",
      "Iteration 4168, loss = 0.00136639\n",
      "Iteration 4169, loss = 0.00136601\n",
      "Iteration 4170, loss = 0.00136565\n",
      "Iteration 4171, loss = 0.00136510\n",
      "Iteration 4172, loss = 0.00136468\n",
      "Iteration 4173, loss = 0.00136427\n",
      "Iteration 4174, loss = 0.00136378\n",
      "Iteration 4175, loss = 0.00136350\n",
      "Iteration 4176, loss = 0.00136293\n",
      "Iteration 4177, loss = 0.00136249\n",
      "Iteration 4178, loss = 0.00136207\n",
      "Iteration 4179, loss = 0.00136166\n",
      "Iteration 4180, loss = 0.00136119\n",
      "Iteration 4181, loss = 0.00136079\n",
      "Iteration 4182, loss = 0.00136041\n",
      "Iteration 4183, loss = 0.00135990\n",
      "Iteration 4184, loss = 0.00135948\n",
      "Iteration 4185, loss = 0.00135915\n",
      "Iteration 4186, loss = 0.00135871\n",
      "Iteration 4187, loss = 0.00135827\n",
      "Iteration 4188, loss = 0.00135776\n",
      "Iteration 4189, loss = 0.00135734\n",
      "Iteration 4190, loss = 0.00135692\n",
      "Iteration 4191, loss = 0.00135649\n",
      "Iteration 4192, loss = 0.00135605\n",
      "Iteration 4193, loss = 0.00135569\n",
      "Iteration 4194, loss = 0.00135528\n",
      "Iteration 4195, loss = 0.00135491\n",
      "Iteration 4196, loss = 0.00135448\n",
      "Iteration 4197, loss = 0.00135401\n",
      "Iteration 4198, loss = 0.00135361\n",
      "Iteration 4199, loss = 0.00135315\n",
      "Iteration 4200, loss = 0.00135283\n",
      "Iteration 4201, loss = 0.00135232\n",
      "Iteration 4202, loss = 0.00135190\n",
      "Iteration 4203, loss = 0.00135147\n",
      "Iteration 4204, loss = 0.00135115\n",
      "Iteration 4205, loss = 0.00135067\n",
      "Iteration 4206, loss = 0.00135035\n",
      "Iteration 4207, loss = 0.00134976\n",
      "Iteration 4208, loss = 0.00134956\n",
      "Iteration 4209, loss = 0.00134897\n",
      "Iteration 4210, loss = 0.00134851\n",
      "Iteration 4211, loss = 0.00134811\n",
      "Iteration 4212, loss = 0.00134771\n",
      "Iteration 4213, loss = 0.00134727\n",
      "Iteration 4214, loss = 0.00134683\n",
      "Iteration 4215, loss = 0.00134641\n",
      "Iteration 4216, loss = 0.00134602\n",
      "Iteration 4217, loss = 0.00134558\n",
      "Iteration 4218, loss = 0.00134520\n",
      "Iteration 4219, loss = 0.00134483\n",
      "Iteration 4220, loss = 0.00134437\n",
      "Iteration 4221, loss = 0.00134394\n",
      "Iteration 4222, loss = 0.00134355\n",
      "Iteration 4223, loss = 0.00134313\n",
      "Iteration 4224, loss = 0.00134275\n",
      "Iteration 4225, loss = 0.00134226\n",
      "Iteration 4226, loss = 0.00134188\n",
      "Iteration 4227, loss = 0.00134145\n",
      "Iteration 4228, loss = 0.00134102\n",
      "Iteration 4229, loss = 0.00134064\n",
      "Iteration 4230, loss = 0.00134020\n",
      "Iteration 4231, loss = 0.00133978\n",
      "Iteration 4232, loss = 0.00133934\n",
      "Iteration 4233, loss = 0.00133910\n",
      "Iteration 4234, loss = 0.00133851\n",
      "Iteration 4235, loss = 0.00133822\n",
      "Iteration 4236, loss = 0.00133775\n",
      "Iteration 4237, loss = 0.00133740\n",
      "Iteration 4238, loss = 0.00133692\n",
      "Iteration 4239, loss = 0.00133652\n",
      "Iteration 4240, loss = 0.00133608\n",
      "Iteration 4241, loss = 0.00133572\n",
      "Iteration 4242, loss = 0.00133551\n",
      "Iteration 4243, loss = 0.00133490\n",
      "Iteration 4244, loss = 0.00133449\n",
      "Iteration 4245, loss = 0.00133415\n",
      "Iteration 4246, loss = 0.00133368\n",
      "Iteration 4247, loss = 0.00133335\n",
      "Iteration 4248, loss = 0.00133290\n",
      "Iteration 4249, loss = 0.00133248\n",
      "Iteration 4250, loss = 0.00133213\n",
      "Iteration 4251, loss = 0.00133168\n",
      "Iteration 4252, loss = 0.00133129\n",
      "Iteration 4253, loss = 0.00133087\n",
      "Iteration 4254, loss = 0.00133045\n",
      "Iteration 4255, loss = 0.00133004\n",
      "Iteration 4256, loss = 0.00132969\n",
      "Iteration 4257, loss = 0.00132923\n",
      "Iteration 4258, loss = 0.00132884\n",
      "Iteration 4259, loss = 0.00132847\n",
      "Iteration 4260, loss = 0.00132797\n",
      "Iteration 4261, loss = 0.00132767\n",
      "Iteration 4262, loss = 0.00132721\n",
      "Iteration 4263, loss = 0.00132677\n",
      "Iteration 4264, loss = 0.00132637\n",
      "Iteration 4265, loss = 0.00132607\n",
      "Iteration 4266, loss = 0.00132556\n",
      "Iteration 4267, loss = 0.00132513\n",
      "Iteration 4268, loss = 0.00132473\n",
      "Iteration 4269, loss = 0.00132433\n",
      "Iteration 4270, loss = 0.00132395\n",
      "Iteration 4271, loss = 0.00132358\n",
      "Iteration 4272, loss = 0.00132316\n",
      "Iteration 4273, loss = 0.00132273\n",
      "Iteration 4274, loss = 0.00132235\n",
      "Iteration 4275, loss = 0.00132195\n",
      "Iteration 4276, loss = 0.00132161\n",
      "Iteration 4277, loss = 0.00132114\n",
      "Iteration 4278, loss = 0.00132073\n",
      "Iteration 4279, loss = 0.00132027\n",
      "Iteration 4280, loss = 0.00131990\n",
      "Iteration 4281, loss = 0.00131948\n",
      "Iteration 4282, loss = 0.00131909\n",
      "Iteration 4283, loss = 0.00131876\n",
      "Iteration 4284, loss = 0.00131826\n",
      "Iteration 4285, loss = 0.00131789\n",
      "Iteration 4286, loss = 0.00131740\n",
      "Iteration 4287, loss = 0.00131706\n",
      "Iteration 4288, loss = 0.00131666\n",
      "Iteration 4289, loss = 0.00131630\n",
      "Iteration 4290, loss = 0.00131586\n",
      "Iteration 4291, loss = 0.00131546\n",
      "Iteration 4292, loss = 0.00131508\n",
      "Iteration 4293, loss = 0.00131476\n",
      "Iteration 4294, loss = 0.00131431\n",
      "Iteration 4295, loss = 0.00131388\n",
      "Iteration 4296, loss = 0.00131348\n",
      "Iteration 4297, loss = 0.00131311\n",
      "Iteration 4298, loss = 0.00131270\n",
      "Iteration 4299, loss = 0.00131230\n",
      "Iteration 4300, loss = 0.00131190\n",
      "Iteration 4301, loss = 0.00131165\n",
      "Iteration 4302, loss = 0.00131111\n",
      "Iteration 4303, loss = 0.00131069\n",
      "Iteration 4304, loss = 0.00131043\n",
      "Iteration 4305, loss = 0.00130992\n",
      "Iteration 4306, loss = 0.00130952\n",
      "Iteration 4307, loss = 0.00130916\n",
      "Iteration 4308, loss = 0.00130863\n",
      "Iteration 4309, loss = 0.00130827\n",
      "Iteration 4310, loss = 0.00130789\n",
      "Iteration 4311, loss = 0.00130750\n",
      "Iteration 4312, loss = 0.00130704\n",
      "Iteration 4313, loss = 0.00130666\n",
      "Iteration 4314, loss = 0.00130629\n",
      "Iteration 4315, loss = 0.00130589\n",
      "Iteration 4316, loss = 0.00130559\n",
      "Iteration 4317, loss = 0.00130511\n",
      "Iteration 4318, loss = 0.00130474\n",
      "Iteration 4319, loss = 0.00130431\n",
      "Iteration 4320, loss = 0.00130386\n",
      "Iteration 4321, loss = 0.00130346\n",
      "Iteration 4322, loss = 0.00130309\n",
      "Iteration 4323, loss = 0.00130273\n",
      "Iteration 4324, loss = 0.00130233\n",
      "Iteration 4325, loss = 0.00130190\n",
      "Iteration 4326, loss = 0.00130148\n",
      "Iteration 4327, loss = 0.00130116\n",
      "Iteration 4328, loss = 0.00130073\n",
      "Iteration 4329, loss = 0.00130037\n",
      "Iteration 4330, loss = 0.00129996\n",
      "Iteration 4331, loss = 0.00129966\n",
      "Iteration 4332, loss = 0.00129918\n",
      "Iteration 4333, loss = 0.00129879\n",
      "Iteration 4334, loss = 0.00129852\n",
      "Iteration 4335, loss = 0.00129804\n",
      "Iteration 4336, loss = 0.00129768\n",
      "Iteration 4337, loss = 0.00129728\n",
      "Iteration 4338, loss = 0.00129694\n",
      "Iteration 4339, loss = 0.00129652\n",
      "Iteration 4340, loss = 0.00129616\n",
      "Iteration 4341, loss = 0.00129570\n",
      "Iteration 4342, loss = 0.00129538\n",
      "Iteration 4343, loss = 0.00129506\n",
      "Iteration 4344, loss = 0.00129456\n",
      "Iteration 4345, loss = 0.00129417\n",
      "Iteration 4346, loss = 0.00129380\n",
      "Iteration 4347, loss = 0.00129343\n",
      "Iteration 4348, loss = 0.00129301\n",
      "Iteration 4349, loss = 0.00129265\n",
      "Iteration 4350, loss = 0.00129225\n",
      "Iteration 4351, loss = 0.00129185\n",
      "Iteration 4352, loss = 0.00129150\n",
      "Iteration 4353, loss = 0.00129110\n",
      "Iteration 4354, loss = 0.00129076\n",
      "Iteration 4355, loss = 0.00129027\n",
      "Iteration 4356, loss = 0.00128994\n",
      "Iteration 4357, loss = 0.00128953\n",
      "Iteration 4358, loss = 0.00128916\n",
      "Iteration 4359, loss = 0.00128876\n",
      "Iteration 4360, loss = 0.00128833\n",
      "Iteration 4361, loss = 0.00128794\n",
      "Iteration 4362, loss = 0.00128760\n",
      "Iteration 4363, loss = 0.00128719\n",
      "Iteration 4364, loss = 0.00128684\n",
      "Iteration 4365, loss = 0.00128642\n",
      "Iteration 4366, loss = 0.00128606\n",
      "Iteration 4367, loss = 0.00128563\n",
      "Iteration 4368, loss = 0.00128528\n",
      "Iteration 4369, loss = 0.00128486\n",
      "Iteration 4370, loss = 0.00128454\n",
      "Iteration 4371, loss = 0.00128408\n",
      "Iteration 4372, loss = 0.00128381\n",
      "Iteration 4373, loss = 0.00128337\n",
      "Iteration 4374, loss = 0.00128301\n",
      "Iteration 4375, loss = 0.00128256\n",
      "Iteration 4376, loss = 0.00128213\n",
      "Iteration 4377, loss = 0.00128174\n",
      "Iteration 4378, loss = 0.00128138\n",
      "Iteration 4379, loss = 0.00128096\n",
      "Iteration 4380, loss = 0.00128059\n",
      "Iteration 4381, loss = 0.00128018\n",
      "Iteration 4382, loss = 0.00127975\n",
      "Iteration 4383, loss = 0.00127942\n",
      "Iteration 4384, loss = 0.00127900\n",
      "Iteration 4385, loss = 0.00127862\n",
      "Iteration 4386, loss = 0.00127828\n",
      "Iteration 4387, loss = 0.00127785\n",
      "Iteration 4388, loss = 0.00127751\n",
      "Iteration 4389, loss = 0.00127709\n",
      "Iteration 4390, loss = 0.00127676\n",
      "Iteration 4391, loss = 0.00127633\n",
      "Iteration 4392, loss = 0.00127597\n",
      "Iteration 4393, loss = 0.00127571\n",
      "Iteration 4394, loss = 0.00127522\n",
      "Iteration 4395, loss = 0.00127478\n",
      "Iteration 4396, loss = 0.00127445\n",
      "Iteration 4397, loss = 0.00127407\n",
      "Iteration 4398, loss = 0.00127368\n",
      "Iteration 4399, loss = 0.00127333\n",
      "Iteration 4400, loss = 0.00127292\n",
      "Iteration 4401, loss = 0.00127252\n",
      "Iteration 4402, loss = 0.00127215\n",
      "Iteration 4403, loss = 0.00127187\n",
      "Iteration 4404, loss = 0.00127153\n",
      "Iteration 4405, loss = 0.00127099\n",
      "Iteration 4406, loss = 0.00127065\n",
      "Iteration 4407, loss = 0.00127032\n",
      "Iteration 4408, loss = 0.00126986\n",
      "Iteration 4409, loss = 0.00126951\n",
      "Iteration 4410, loss = 0.00126912\n",
      "Iteration 4411, loss = 0.00126879\n",
      "Iteration 4412, loss = 0.00126833\n",
      "Iteration 4413, loss = 0.00126809\n",
      "Iteration 4414, loss = 0.00126758\n",
      "Iteration 4415, loss = 0.00126720\n",
      "Iteration 4416, loss = 0.00126684\n",
      "Iteration 4417, loss = 0.00126648\n",
      "Iteration 4418, loss = 0.00126611\n",
      "Iteration 4419, loss = 0.00126577\n",
      "Iteration 4420, loss = 0.00126525\n",
      "Iteration 4421, loss = 0.00126492\n",
      "Iteration 4422, loss = 0.00126449\n",
      "Iteration 4423, loss = 0.00126428\n",
      "Iteration 4424, loss = 0.00126385\n",
      "Iteration 4425, loss = 0.00126333\n",
      "Iteration 4426, loss = 0.00126298\n",
      "Iteration 4427, loss = 0.00126270\n",
      "Iteration 4428, loss = 0.00126222\n",
      "Iteration 4429, loss = 0.00126184\n",
      "Iteration 4430, loss = 0.00126147\n",
      "Iteration 4431, loss = 0.00126111\n",
      "Iteration 4432, loss = 0.00126067\n",
      "Iteration 4433, loss = 0.00126040\n",
      "Iteration 4434, loss = 0.00125995\n",
      "Iteration 4435, loss = 0.00125957\n",
      "Iteration 4436, loss = 0.00125922\n",
      "Iteration 4437, loss = 0.00125879\n",
      "Iteration 4438, loss = 0.00125845\n",
      "Iteration 4439, loss = 0.00125809\n",
      "Iteration 4440, loss = 0.00125778\n",
      "Iteration 4441, loss = 0.00125741\n",
      "Iteration 4442, loss = 0.00125694\n",
      "Iteration 4443, loss = 0.00125680\n",
      "Iteration 4444, loss = 0.00125621\n",
      "Iteration 4445, loss = 0.00125583\n",
      "Iteration 4446, loss = 0.00125554\n",
      "Iteration 4447, loss = 0.00125507\n",
      "Iteration 4448, loss = 0.00125469\n",
      "Iteration 4449, loss = 0.00125436\n",
      "Iteration 4450, loss = 0.00125401\n",
      "Iteration 4451, loss = 0.00125361\n",
      "Iteration 4452, loss = 0.00125321\n",
      "Iteration 4453, loss = 0.00125286\n",
      "Iteration 4454, loss = 0.00125253\n",
      "Iteration 4455, loss = 0.00125211\n",
      "Iteration 4456, loss = 0.00125175\n",
      "Iteration 4457, loss = 0.00125138\n",
      "Iteration 4458, loss = 0.00125102\n",
      "Iteration 4459, loss = 0.00125074\n",
      "Iteration 4460, loss = 0.00125027\n",
      "Iteration 4461, loss = 0.00124989\n",
      "Iteration 4462, loss = 0.00124958\n",
      "Iteration 4463, loss = 0.00124921\n",
      "Iteration 4464, loss = 0.00124891\n",
      "Iteration 4465, loss = 0.00124843\n",
      "Iteration 4466, loss = 0.00124813\n",
      "Iteration 4467, loss = 0.00124772\n",
      "Iteration 4468, loss = 0.00124739\n",
      "Iteration 4469, loss = 0.00124702\n",
      "Iteration 4470, loss = 0.00124662\n",
      "Iteration 4471, loss = 0.00124628\n",
      "Iteration 4472, loss = 0.00124594\n",
      "Iteration 4473, loss = 0.00124558\n",
      "Iteration 4474, loss = 0.00124527\n",
      "Iteration 4475, loss = 0.00124485\n",
      "Iteration 4476, loss = 0.00124449\n",
      "Iteration 4477, loss = 0.00124412\n",
      "Iteration 4478, loss = 0.00124374\n",
      "Iteration 4479, loss = 0.00124342\n",
      "Iteration 4480, loss = 0.00124302\n",
      "Iteration 4481, loss = 0.00124265\n",
      "Iteration 4482, loss = 0.00124229\n",
      "Iteration 4483, loss = 0.00124201\n",
      "Iteration 4484, loss = 0.00124156\n",
      "Iteration 4485, loss = 0.00124121\n",
      "Iteration 4486, loss = 0.00124085\n",
      "Iteration 4487, loss = 0.00124051\n",
      "Iteration 4488, loss = 0.00124017\n",
      "Iteration 4489, loss = 0.00123980\n",
      "Iteration 4490, loss = 0.00123942\n",
      "Iteration 4491, loss = 0.00123911\n",
      "Iteration 4492, loss = 0.00123874\n",
      "Iteration 4493, loss = 0.00123831\n",
      "Iteration 4494, loss = 0.00123797\n",
      "Iteration 4495, loss = 0.00123757\n",
      "Iteration 4496, loss = 0.00123721\n",
      "Iteration 4497, loss = 0.00123689\n",
      "Iteration 4498, loss = 0.00123651\n",
      "Iteration 4499, loss = 0.00123615\n",
      "Iteration 4500, loss = 0.00123580\n",
      "Iteration 4501, loss = 0.00123551\n",
      "Iteration 4502, loss = 0.00123508\n",
      "Iteration 4503, loss = 0.00123471\n",
      "Iteration 4504, loss = 0.00123435\n",
      "Iteration 4505, loss = 0.00123402\n",
      "Iteration 4506, loss = 0.00123365\n",
      "Iteration 4507, loss = 0.00123326\n",
      "Iteration 4508, loss = 0.00123295\n",
      "Iteration 4509, loss = 0.00123257\n",
      "Iteration 4510, loss = 0.00123220\n",
      "Iteration 4511, loss = 0.00123185\n",
      "Iteration 4512, loss = 0.00123147\n",
      "Iteration 4513, loss = 0.00123111\n",
      "Iteration 4514, loss = 0.00123074\n",
      "Iteration 4515, loss = 0.00123043\n",
      "Iteration 4516, loss = 0.00123005\n",
      "Iteration 4517, loss = 0.00122972\n",
      "Iteration 4518, loss = 0.00122934\n",
      "Iteration 4519, loss = 0.00122898\n",
      "Iteration 4520, loss = 0.00122865\n",
      "Iteration 4521, loss = 0.00122831\n",
      "Iteration 4522, loss = 0.00122801\n",
      "Iteration 4523, loss = 0.00122757\n",
      "Iteration 4524, loss = 0.00122731\n",
      "Iteration 4525, loss = 0.00122695\n",
      "Iteration 4526, loss = 0.00122652\n",
      "Iteration 4527, loss = 0.00122618\n",
      "Iteration 4528, loss = 0.00122584\n",
      "Iteration 4529, loss = 0.00122545\n",
      "Iteration 4530, loss = 0.00122515\n",
      "Iteration 4531, loss = 0.00122472\n",
      "Iteration 4532, loss = 0.00122435\n",
      "Iteration 4533, loss = 0.00122417\n",
      "Iteration 4534, loss = 0.00122362\n",
      "Iteration 4535, loss = 0.00122330\n",
      "Iteration 4536, loss = 0.00122289\n",
      "Iteration 4537, loss = 0.00122258\n",
      "Iteration 4538, loss = 0.00122221\n",
      "Iteration 4539, loss = 0.00122183\n",
      "Iteration 4540, loss = 0.00122153\n",
      "Iteration 4541, loss = 0.00122109\n",
      "Iteration 4542, loss = 0.00122079\n",
      "Iteration 4543, loss = 0.00122048\n",
      "Iteration 4544, loss = 0.00122009\n",
      "Iteration 4545, loss = 0.00121982\n",
      "Iteration 4546, loss = 0.00121947\n",
      "Iteration 4547, loss = 0.00121904\n",
      "Iteration 4548, loss = 0.00121867\n",
      "Iteration 4549, loss = 0.00121840\n",
      "Iteration 4550, loss = 0.00121804\n",
      "Iteration 4551, loss = 0.00121760\n",
      "Iteration 4552, loss = 0.00121729\n",
      "Iteration 4553, loss = 0.00121693\n",
      "Iteration 4554, loss = 0.00121658\n",
      "Iteration 4555, loss = 0.00121624\n",
      "Iteration 4556, loss = 0.00121591\n",
      "Iteration 4557, loss = 0.00121558\n",
      "Iteration 4558, loss = 0.00121515\n",
      "Iteration 4559, loss = 0.00121488\n",
      "Iteration 4560, loss = 0.00121448\n",
      "Iteration 4561, loss = 0.00121407\n",
      "Iteration 4562, loss = 0.00121375\n",
      "Iteration 4563, loss = 0.00121338\n",
      "Iteration 4564, loss = 0.00121304\n",
      "Iteration 4565, loss = 0.00121267\n",
      "Iteration 4566, loss = 0.00121230\n",
      "Iteration 4567, loss = 0.00121205\n",
      "Iteration 4568, loss = 0.00121159\n",
      "Iteration 4569, loss = 0.00121127\n",
      "Iteration 4570, loss = 0.00121094\n",
      "Iteration 4571, loss = 0.00121059\n",
      "Iteration 4572, loss = 0.00121030\n",
      "Iteration 4573, loss = 0.00120988\n",
      "Iteration 4574, loss = 0.00120956\n",
      "Iteration 4575, loss = 0.00120923\n",
      "Iteration 4576, loss = 0.00120894\n",
      "Iteration 4577, loss = 0.00120852\n",
      "Iteration 4578, loss = 0.00120816\n",
      "Iteration 4579, loss = 0.00120781\n",
      "Iteration 4580, loss = 0.00120748\n",
      "Iteration 4581, loss = 0.00120715\n",
      "Iteration 4582, loss = 0.00120678\n",
      "Iteration 4583, loss = 0.00120649\n",
      "Iteration 4584, loss = 0.00120609\n",
      "Iteration 4585, loss = 0.00120579\n",
      "Iteration 4586, loss = 0.00120540\n",
      "Iteration 4587, loss = 0.00120508\n",
      "Iteration 4588, loss = 0.00120476\n",
      "Iteration 4589, loss = 0.00120441\n",
      "Iteration 4590, loss = 0.00120408\n",
      "Iteration 4591, loss = 0.00120375\n",
      "Iteration 4592, loss = 0.00120338\n",
      "Iteration 4593, loss = 0.00120311\n",
      "Iteration 4594, loss = 0.00120274\n",
      "Iteration 4595, loss = 0.00120234\n",
      "Iteration 4596, loss = 0.00120203\n",
      "Iteration 4597, loss = 0.00120169\n",
      "Iteration 4598, loss = 0.00120132\n",
      "Iteration 4599, loss = 0.00120099\n",
      "Iteration 4600, loss = 0.00120063\n",
      "Iteration 4601, loss = 0.00120037\n",
      "Iteration 4602, loss = 0.00119996\n",
      "Iteration 4603, loss = 0.00119964\n",
      "Iteration 4604, loss = 0.00119935\n",
      "Iteration 4605, loss = 0.00119905\n",
      "Iteration 4606, loss = 0.00119864\n",
      "Iteration 4607, loss = 0.00119831\n",
      "Iteration 4608, loss = 0.00119798\n",
      "Iteration 4609, loss = 0.00119765\n",
      "Iteration 4610, loss = 0.00119733\n",
      "Iteration 4611, loss = 0.00119696\n",
      "Iteration 4612, loss = 0.00119659\n",
      "Iteration 4613, loss = 0.00119631\n",
      "Iteration 4614, loss = 0.00119596\n",
      "Iteration 4615, loss = 0.00119560\n",
      "Iteration 4616, loss = 0.00119522\n",
      "Iteration 4617, loss = 0.00119492\n",
      "Iteration 4618, loss = 0.00119462\n",
      "Iteration 4619, loss = 0.00119428\n",
      "Iteration 4620, loss = 0.00119386\n",
      "Iteration 4621, loss = 0.00119361\n",
      "Iteration 4622, loss = 0.00119330\n",
      "Iteration 4623, loss = 0.00119289\n",
      "Iteration 4624, loss = 0.00119257\n",
      "Iteration 4625, loss = 0.00119228\n",
      "Iteration 4626, loss = 0.00119185\n",
      "Iteration 4627, loss = 0.00119161\n",
      "Iteration 4628, loss = 0.00119123\n",
      "Iteration 4629, loss = 0.00119100\n",
      "Iteration 4630, loss = 0.00119053\n",
      "Iteration 4631, loss = 0.00119023\n",
      "Iteration 4632, loss = 0.00118986\n",
      "Iteration 4633, loss = 0.00118958\n",
      "Iteration 4634, loss = 0.00118922\n",
      "Iteration 4635, loss = 0.00118890\n",
      "Iteration 4636, loss = 0.00118855\n",
      "Iteration 4637, loss = 0.00118828\n",
      "Iteration 4638, loss = 0.00118793\n",
      "Iteration 4639, loss = 0.00118753\n",
      "Iteration 4640, loss = 0.00118725\n",
      "Iteration 4641, loss = 0.00118691\n",
      "Iteration 4642, loss = 0.00118660\n",
      "Iteration 4643, loss = 0.00118624\n",
      "Iteration 4644, loss = 0.00118590\n",
      "Iteration 4645, loss = 0.00118557\n",
      "Iteration 4646, loss = 0.00118529\n",
      "Iteration 4647, loss = 0.00118496\n",
      "Iteration 4648, loss = 0.00118459\n",
      "Iteration 4649, loss = 0.00118427\n",
      "Iteration 4650, loss = 0.00118398\n",
      "Iteration 4651, loss = 0.00118354\n",
      "Iteration 4652, loss = 0.00118325\n",
      "Iteration 4653, loss = 0.00118289\n",
      "Iteration 4654, loss = 0.00118263\n",
      "Iteration 4655, loss = 0.00118241\n",
      "Iteration 4656, loss = 0.00118189\n",
      "Iteration 4657, loss = 0.00118167\n",
      "Iteration 4658, loss = 0.00118123\n",
      "Iteration 4659, loss = 0.00118095\n",
      "Iteration 4660, loss = 0.00118057\n",
      "Iteration 4661, loss = 0.00118026\n",
      "Iteration 4662, loss = 0.00117991\n",
      "Iteration 4663, loss = 0.00117966\n",
      "Iteration 4664, loss = 0.00117926\n",
      "Iteration 4665, loss = 0.00117891\n",
      "Iteration 4666, loss = 0.00117859\n",
      "Iteration 4667, loss = 0.00117832\n",
      "Iteration 4668, loss = 0.00117802\n",
      "Iteration 4669, loss = 0.00117759\n",
      "Iteration 4670, loss = 0.00117735\n",
      "Iteration 4671, loss = 0.00117698\n",
      "Iteration 4672, loss = 0.00117668\n",
      "Iteration 4673, loss = 0.00117628\n",
      "Iteration 4674, loss = 0.00117599\n",
      "Iteration 4675, loss = 0.00117571\n",
      "Iteration 4676, loss = 0.00117532\n",
      "Iteration 4677, loss = 0.00117502\n",
      "Iteration 4678, loss = 0.00117474\n",
      "Iteration 4679, loss = 0.00117432\n",
      "Iteration 4680, loss = 0.00117399\n",
      "Iteration 4681, loss = 0.00117364\n",
      "Iteration 4682, loss = 0.00117337\n",
      "Iteration 4683, loss = 0.00117297\n",
      "Iteration 4684, loss = 0.00117272\n",
      "Iteration 4685, loss = 0.00117238\n",
      "Iteration 4686, loss = 0.00117199\n",
      "Iteration 4687, loss = 0.00117167\n",
      "Iteration 4688, loss = 0.00117143\n",
      "Iteration 4689, loss = 0.00117106\n",
      "Iteration 4690, loss = 0.00117072\n",
      "Iteration 4691, loss = 0.00117045\n",
      "Iteration 4692, loss = 0.00117008\n",
      "Iteration 4693, loss = 0.00116977\n",
      "Iteration 4694, loss = 0.00116942\n",
      "Iteration 4695, loss = 0.00116917\n",
      "Iteration 4696, loss = 0.00116883\n",
      "Iteration 4697, loss = 0.00116848\n",
      "Iteration 4698, loss = 0.00116819\n",
      "Iteration 4699, loss = 0.00116788\n",
      "Iteration 4700, loss = 0.00116755\n",
      "Iteration 4701, loss = 0.00116719\n",
      "Iteration 4702, loss = 0.00116689\n",
      "Iteration 4703, loss = 0.00116654\n",
      "Iteration 4704, loss = 0.00116623\n",
      "Iteration 4705, loss = 0.00116588\n",
      "Iteration 4706, loss = 0.00116565\n",
      "Iteration 4707, loss = 0.00116528\n",
      "Iteration 4708, loss = 0.00116496\n",
      "Iteration 4709, loss = 0.00116464\n",
      "Iteration 4710, loss = 0.00116437\n",
      "Iteration 4711, loss = 0.00116397\n",
      "Iteration 4712, loss = 0.00116367\n",
      "Iteration 4713, loss = 0.00116346\n",
      "Iteration 4714, loss = 0.00116305\n",
      "Iteration 4715, loss = 0.00116269\n",
      "Iteration 4716, loss = 0.00116239\n",
      "Iteration 4717, loss = 0.00116208\n",
      "Iteration 4718, loss = 0.00116171\n",
      "Iteration 4719, loss = 0.00116141\n",
      "Iteration 4720, loss = 0.00116110\n",
      "Iteration 4721, loss = 0.00116085\n",
      "Iteration 4722, loss = 0.00116044\n",
      "Iteration 4723, loss = 0.00116019\n",
      "Iteration 4724, loss = 0.00115981\n",
      "Iteration 4725, loss = 0.00115948\n",
      "Iteration 4726, loss = 0.00115921\n",
      "Iteration 4727, loss = 0.00115882\n",
      "Iteration 4728, loss = 0.00115849\n",
      "Iteration 4729, loss = 0.00115822\n",
      "Iteration 4730, loss = 0.00115786\n",
      "Iteration 4731, loss = 0.00115760\n",
      "Iteration 4732, loss = 0.00115723\n",
      "Iteration 4733, loss = 0.00115693\n",
      "Iteration 4734, loss = 0.00115663\n",
      "Iteration 4735, loss = 0.00115642\n",
      "Iteration 4736, loss = 0.00115595\n",
      "Iteration 4737, loss = 0.00115566\n",
      "Iteration 4738, loss = 0.00115537\n",
      "Iteration 4739, loss = 0.00115506\n",
      "Iteration 4740, loss = 0.00115476\n",
      "Iteration 4741, loss = 0.00115441\n",
      "Iteration 4742, loss = 0.00115412\n",
      "Iteration 4743, loss = 0.00115381\n",
      "Iteration 4744, loss = 0.00115350\n",
      "Iteration 4745, loss = 0.00115314\n",
      "Iteration 4746, loss = 0.00115283\n",
      "Iteration 4747, loss = 0.00115259\n",
      "Iteration 4748, loss = 0.00115223\n",
      "Iteration 4749, loss = 0.00115188\n",
      "Iteration 4750, loss = 0.00115159\n",
      "Iteration 4751, loss = 0.00115130\n",
      "Iteration 4752, loss = 0.00115097\n",
      "Iteration 4753, loss = 0.00115065\n",
      "Iteration 4754, loss = 0.00115035\n",
      "Iteration 4755, loss = 0.00114997\n",
      "Iteration 4756, loss = 0.00114966\n",
      "Iteration 4757, loss = 0.00114942\n",
      "Iteration 4758, loss = 0.00114910\n",
      "Iteration 4759, loss = 0.00114880\n",
      "Iteration 4760, loss = 0.00114851\n",
      "Iteration 4761, loss = 0.00114810\n",
      "Iteration 4762, loss = 0.00114792\n",
      "Iteration 4763, loss = 0.00114749\n",
      "Iteration 4764, loss = 0.00114719\n",
      "Iteration 4765, loss = 0.00114695\n",
      "Iteration 4766, loss = 0.00114654\n",
      "Iteration 4767, loss = 0.00114620\n",
      "Iteration 4768, loss = 0.00114594\n",
      "Iteration 4769, loss = 0.00114565\n",
      "Iteration 4770, loss = 0.00114533\n",
      "Iteration 4771, loss = 0.00114491\n",
      "Iteration 4772, loss = 0.00114461\n",
      "Iteration 4773, loss = 0.00114429\n",
      "Iteration 4774, loss = 0.00114400\n",
      "Iteration 4775, loss = 0.00114373\n",
      "Iteration 4776, loss = 0.00114342\n",
      "Iteration 4777, loss = 0.00114304\n",
      "Iteration 4778, loss = 0.00114272\n",
      "Iteration 4779, loss = 0.00114244\n",
      "Iteration 4780, loss = 0.00114219\n",
      "Iteration 4781, loss = 0.00114179\n",
      "Iteration 4782, loss = 0.00114151\n",
      "Iteration 4783, loss = 0.00114119\n",
      "Iteration 4784, loss = 0.00114089\n",
      "Iteration 4785, loss = 0.00114059\n",
      "Iteration 4786, loss = 0.00114028\n",
      "Iteration 4787, loss = 0.00113994\n",
      "Iteration 4788, loss = 0.00113968\n",
      "Iteration 4789, loss = 0.00113931\n",
      "Iteration 4790, loss = 0.00113904\n",
      "Iteration 4791, loss = 0.00113864\n",
      "Iteration 4792, loss = 0.00113835\n",
      "Iteration 4793, loss = 0.00113804\n",
      "Iteration 4794, loss = 0.00113771\n",
      "Iteration 4795, loss = 0.00113742\n",
      "Iteration 4796, loss = 0.00113716\n",
      "Iteration 4797, loss = 0.00113681\n",
      "Iteration 4798, loss = 0.00113645\n",
      "Iteration 4799, loss = 0.00113613\n",
      "Iteration 4800, loss = 0.00113582\n",
      "Iteration 4801, loss = 0.00113552\n",
      "Iteration 4802, loss = 0.00113520\n",
      "Iteration 4803, loss = 0.00113487\n",
      "Iteration 4804, loss = 0.00113459\n",
      "Iteration 4805, loss = 0.00113438\n",
      "Iteration 4806, loss = 0.00113397\n",
      "Iteration 4807, loss = 0.00113364\n",
      "Iteration 4808, loss = 0.00113335\n",
      "Iteration 4809, loss = 0.00113305\n",
      "Iteration 4810, loss = 0.00113270\n",
      "Iteration 4811, loss = 0.00113240\n",
      "Iteration 4812, loss = 0.00113214\n",
      "Iteration 4813, loss = 0.00113184\n",
      "Iteration 4814, loss = 0.00113145\n",
      "Iteration 4815, loss = 0.00113118\n",
      "Iteration 4816, loss = 0.00113082\n",
      "Iteration 4817, loss = 0.00113050\n",
      "Iteration 4818, loss = 0.00113021\n",
      "Iteration 4819, loss = 0.00112991\n",
      "Iteration 4820, loss = 0.00112962\n",
      "Iteration 4821, loss = 0.00112932\n",
      "Iteration 4822, loss = 0.00112903\n",
      "Iteration 4823, loss = 0.00112873\n",
      "Iteration 4824, loss = 0.00112844\n",
      "Iteration 4825, loss = 0.00112808\n",
      "Iteration 4826, loss = 0.00112777\n",
      "Iteration 4827, loss = 0.00112749\n",
      "Iteration 4828, loss = 0.00112723\n",
      "Iteration 4829, loss = 0.00112689\n",
      "Iteration 4830, loss = 0.00112654\n",
      "Iteration 4831, loss = 0.00112627\n",
      "Iteration 4832, loss = 0.00112601\n",
      "Iteration 4833, loss = 0.00112565\n",
      "Iteration 4834, loss = 0.00112541\n",
      "Iteration 4835, loss = 0.00112515\n",
      "Iteration 4836, loss = 0.00112480\n",
      "Iteration 4837, loss = 0.00112443\n",
      "Iteration 4838, loss = 0.00112417\n",
      "Iteration 4839, loss = 0.00112383\n",
      "Iteration 4840, loss = 0.00112355\n",
      "Iteration 4841, loss = 0.00112324\n",
      "Iteration 4842, loss = 0.00112290\n",
      "Iteration 4843, loss = 0.00112264\n",
      "Iteration 4844, loss = 0.00112240\n",
      "Iteration 4845, loss = 0.00112203\n",
      "Iteration 4846, loss = 0.00112177\n",
      "Iteration 4847, loss = 0.00112145\n",
      "Iteration 4848, loss = 0.00112115\n",
      "Iteration 4849, loss = 0.00112085\n",
      "Iteration 4850, loss = 0.00112056\n",
      "Iteration 4851, loss = 0.00112026\n",
      "Iteration 4852, loss = 0.00111998\n",
      "Iteration 4853, loss = 0.00111966\n",
      "Iteration 4854, loss = 0.00111937\n",
      "Iteration 4855, loss = 0.00111911\n",
      "Iteration 4856, loss = 0.00111879\n",
      "Iteration 4857, loss = 0.00111843\n",
      "Iteration 4858, loss = 0.00111816\n",
      "Iteration 4859, loss = 0.00111785\n",
      "Iteration 4860, loss = 0.00111753\n",
      "Iteration 4861, loss = 0.00111727\n",
      "Iteration 4862, loss = 0.00111690\n",
      "Iteration 4863, loss = 0.00111660\n",
      "Iteration 4864, loss = 0.00111634\n",
      "Iteration 4865, loss = 0.00111597\n",
      "Iteration 4866, loss = 0.00111567\n",
      "Iteration 4867, loss = 0.00111541\n",
      "Iteration 4868, loss = 0.00111504\n",
      "Iteration 4869, loss = 0.00111474\n",
      "Iteration 4870, loss = 0.00111445\n",
      "Iteration 4871, loss = 0.00111412\n",
      "Iteration 4872, loss = 0.00111388\n",
      "Iteration 4873, loss = 0.00111350\n",
      "Iteration 4874, loss = 0.00111320\n",
      "Iteration 4875, loss = 0.00111289\n",
      "Iteration 4876, loss = 0.00111261\n",
      "Iteration 4877, loss = 0.00111233\n",
      "Iteration 4878, loss = 0.00111200\n",
      "Iteration 4879, loss = 0.00111173\n",
      "Iteration 4880, loss = 0.00111146\n",
      "Iteration 4881, loss = 0.00111113\n",
      "Iteration 4882, loss = 0.00111081\n",
      "Iteration 4883, loss = 0.00111048\n",
      "Iteration 4884, loss = 0.00111017\n",
      "Iteration 4885, loss = 0.00111002\n",
      "Iteration 4886, loss = 0.00110962\n",
      "Iteration 4887, loss = 0.00110932\n",
      "Iteration 4888, loss = 0.00110907\n",
      "Iteration 4889, loss = 0.00110873\n",
      "Iteration 4890, loss = 0.00110843\n",
      "Iteration 4891, loss = 0.00110810\n",
      "Iteration 4892, loss = 0.00110785\n",
      "Iteration 4893, loss = 0.00110750\n",
      "Iteration 4894, loss = 0.00110726\n",
      "Iteration 4895, loss = 0.00110693\n",
      "Iteration 4896, loss = 0.00110666\n",
      "Iteration 4897, loss = 0.00110635\n",
      "Iteration 4898, loss = 0.00110602\n",
      "Iteration 4899, loss = 0.00110571\n",
      "Iteration 4900, loss = 0.00110544\n",
      "Iteration 4901, loss = 0.00110507\n",
      "Iteration 4902, loss = 0.00110479\n",
      "Iteration 4903, loss = 0.00110455\n",
      "Iteration 4904, loss = 0.00110422\n",
      "Iteration 4905, loss = 0.00110394\n",
      "Iteration 4906, loss = 0.00110366\n",
      "Iteration 4907, loss = 0.00110340\n",
      "Iteration 4908, loss = 0.00110315\n",
      "Iteration 4909, loss = 0.00110274\n",
      "Iteration 4910, loss = 0.00110243\n",
      "Iteration 4911, loss = 0.00110214\n",
      "Iteration 4912, loss = 0.00110190\n",
      "Iteration 4913, loss = 0.00110156\n",
      "Iteration 4914, loss = 0.00110133\n",
      "Iteration 4915, loss = 0.00110104\n",
      "Iteration 4916, loss = 0.00110077\n",
      "Iteration 4917, loss = 0.00110046\n",
      "Iteration 4918, loss = 0.00110019\n",
      "Iteration 4919, loss = 0.00109988\n",
      "Iteration 4920, loss = 0.00109956\n",
      "Iteration 4921, loss = 0.00109927\n",
      "Iteration 4922, loss = 0.00109904\n",
      "Iteration 4923, loss = 0.00109867\n",
      "Iteration 4924, loss = 0.00109839\n",
      "Iteration 4925, loss = 0.00109809\n",
      "Iteration 4926, loss = 0.00109783\n",
      "Iteration 4927, loss = 0.00109753\n",
      "Iteration 4928, loss = 0.00109729\n",
      "Iteration 4929, loss = 0.00109695\n",
      "Iteration 4930, loss = 0.00109666\n",
      "Iteration 4931, loss = 0.00109637\n",
      "Iteration 4932, loss = 0.00109608\n",
      "Iteration 4933, loss = 0.00109579\n",
      "Iteration 4934, loss = 0.00109550\n",
      "Iteration 4935, loss = 0.00109526\n",
      "Iteration 4936, loss = 0.00109492\n",
      "Iteration 4937, loss = 0.00109467\n",
      "Iteration 4938, loss = 0.00109437\n",
      "Iteration 4939, loss = 0.00109404\n",
      "Iteration 4940, loss = 0.00109386\n",
      "Iteration 4941, loss = 0.00109350\n",
      "Iteration 4942, loss = 0.00109321\n",
      "Iteration 4943, loss = 0.00109292\n",
      "Iteration 4944, loss = 0.00109262\n",
      "Iteration 4945, loss = 0.00109230\n",
      "Iteration 4946, loss = 0.00109196\n",
      "Iteration 4947, loss = 0.00109170\n",
      "Iteration 4948, loss = 0.00109155\n",
      "Iteration 4949, loss = 0.00109111\n",
      "Iteration 4950, loss = 0.00109083\n",
      "Iteration 4951, loss = 0.00109058\n",
      "Iteration 4952, loss = 0.00109027\n",
      "Iteration 4953, loss = 0.00108999\n",
      "Iteration 4954, loss = 0.00108969\n",
      "Iteration 4955, loss = 0.00108941\n",
      "Iteration 4956, loss = 0.00108916\n",
      "Iteration 4957, loss = 0.00108881\n",
      "Iteration 4958, loss = 0.00108856\n",
      "Iteration 4959, loss = 0.00108826\n",
      "Iteration 4960, loss = 0.00108797\n",
      "Iteration 4961, loss = 0.00108767\n",
      "Iteration 4962, loss = 0.00108741\n",
      "Iteration 4963, loss = 0.00108707\n",
      "Iteration 4964, loss = 0.00108685\n",
      "Iteration 4965, loss = 0.00108657\n",
      "Iteration 4966, loss = 0.00108623\n",
      "Iteration 4967, loss = 0.00108593\n",
      "Iteration 4968, loss = 0.00108572\n",
      "Iteration 4969, loss = 0.00108537\n",
      "Iteration 4970, loss = 0.00108511\n",
      "Iteration 4971, loss = 0.00108481\n",
      "Iteration 4972, loss = 0.00108462\n",
      "Iteration 4973, loss = 0.00108426\n",
      "Iteration 4974, loss = 0.00108399\n",
      "Iteration 4975, loss = 0.00108373\n",
      "Iteration 4976, loss = 0.00108341\n",
      "Iteration 4977, loss = 0.00108315\n",
      "Iteration 4978, loss = 0.00108288\n",
      "Iteration 4979, loss = 0.00108259\n",
      "Iteration 4980, loss = 0.00108228\n",
      "Iteration 4981, loss = 0.00108202\n",
      "Iteration 4982, loss = 0.00108172\n",
      "Iteration 4983, loss = 0.00108148\n",
      "Iteration 4984, loss = 0.00108114\n",
      "Iteration 4985, loss = 0.00108095\n",
      "Iteration 4986, loss = 0.00108058\n",
      "Iteration 4987, loss = 0.00108032\n",
      "Iteration 4988, loss = 0.00108003\n",
      "Iteration 4989, loss = 0.00107973\n",
      "Iteration 4990, loss = 0.00107952\n",
      "Iteration 4991, loss = 0.00107917\n",
      "Iteration 4992, loss = 0.00107889\n",
      "Iteration 4993, loss = 0.00107863\n",
      "Iteration 4994, loss = 0.00107832\n",
      "Iteration 4995, loss = 0.00107803\n",
      "Iteration 4996, loss = 0.00107778\n",
      "Iteration 4997, loss = 0.00107749\n",
      "Iteration 4998, loss = 0.00107721\n",
      "Iteration 4999, loss = 0.00107695\n",
      "Iteration 5000, loss = 0.00107666\n",
      "Iteration 5001, loss = 0.00107639\n",
      "Iteration 5002, loss = 0.00107609\n",
      "Iteration 5003, loss = 0.00107579\n",
      "Iteration 5004, loss = 0.00107553\n",
      "Iteration 5005, loss = 0.00107522\n",
      "Iteration 5006, loss = 0.00107497\n",
      "Iteration 5007, loss = 0.00107464\n",
      "Iteration 5008, loss = 0.00107438\n",
      "Iteration 5009, loss = 0.00107414\n",
      "Iteration 5010, loss = 0.00107382\n",
      "Iteration 5011, loss = 0.00107355\n",
      "Iteration 5012, loss = 0.00107328\n",
      "Iteration 5013, loss = 0.00107299\n",
      "Iteration 5014, loss = 0.00107273\n",
      "Iteration 5015, loss = 0.00107244\n",
      "Iteration 5016, loss = 0.00107219\n",
      "Iteration 5017, loss = 0.00107190\n",
      "Iteration 5018, loss = 0.00107168\n",
      "Iteration 5019, loss = 0.00107135\n",
      "Iteration 5020, loss = 0.00107104\n",
      "Iteration 5021, loss = 0.00107079\n",
      "Iteration 5022, loss = 0.00107055\n",
      "Iteration 5023, loss = 0.00107026\n",
      "Iteration 5024, loss = 0.00106996\n",
      "Iteration 5025, loss = 0.00106968\n",
      "Iteration 5026, loss = 0.00106939\n",
      "Iteration 5027, loss = 0.00106912\n",
      "Iteration 5028, loss = 0.00106887\n",
      "Iteration 5029, loss = 0.00106858\n",
      "Iteration 5030, loss = 0.00106829\n",
      "Iteration 5031, loss = 0.00106800\n",
      "Iteration 5032, loss = 0.00106772\n",
      "Iteration 5033, loss = 0.00106748\n",
      "Iteration 5034, loss = 0.00106719\n",
      "Iteration 5035, loss = 0.00106697\n",
      "Iteration 5036, loss = 0.00106671\n",
      "Iteration 5037, loss = 0.00106641\n",
      "Iteration 5038, loss = 0.00106613\n",
      "Iteration 5039, loss = 0.00106586\n",
      "Iteration 5040, loss = 0.00106561\n",
      "Iteration 5041, loss = 0.00106531\n",
      "Iteration 5042, loss = 0.00106504\n",
      "Iteration 5043, loss = 0.00106477\n",
      "Iteration 5044, loss = 0.00106451\n",
      "Iteration 5045, loss = 0.00106426\n",
      "Iteration 5046, loss = 0.00106398\n",
      "Iteration 5047, loss = 0.00106367\n",
      "Iteration 5048, loss = 0.00106343\n",
      "Iteration 5049, loss = 0.00106312\n",
      "Iteration 5050, loss = 0.00106288\n",
      "Iteration 5051, loss = 0.00106261\n",
      "Iteration 5052, loss = 0.00106231\n",
      "Iteration 5053, loss = 0.00106207\n",
      "Iteration 5054, loss = 0.00106175\n",
      "Iteration 5055, loss = 0.00106153\n",
      "Iteration 5056, loss = 0.00106118\n",
      "Iteration 5057, loss = 0.00106100\n",
      "Iteration 5058, loss = 0.00106063\n",
      "Iteration 5059, loss = 0.00106037\n",
      "Iteration 5060, loss = 0.00106014\n",
      "Iteration 5061, loss = 0.00105982\n",
      "Iteration 5062, loss = 0.00105954\n",
      "Iteration 5063, loss = 0.00105927\n",
      "Iteration 5064, loss = 0.00105899\n",
      "Iteration 5065, loss = 0.00105870\n",
      "Iteration 5066, loss = 0.00105843\n",
      "Iteration 5067, loss = 0.00105816\n",
      "Iteration 5068, loss = 0.00105788\n",
      "Iteration 5069, loss = 0.00105763\n",
      "Iteration 5070, loss = 0.00105737\n",
      "Iteration 5071, loss = 0.00105709\n",
      "Iteration 5072, loss = 0.00105676\n",
      "Iteration 5073, loss = 0.00105656\n",
      "Iteration 5074, loss = 0.00105627\n",
      "Iteration 5075, loss = 0.00105601\n",
      "Iteration 5076, loss = 0.00105571\n",
      "Iteration 5077, loss = 0.00105544\n",
      "Iteration 5078, loss = 0.00105519\n",
      "Iteration 5079, loss = 0.00105488\n",
      "Iteration 5080, loss = 0.00105463\n",
      "Iteration 5081, loss = 0.00105436\n",
      "Iteration 5082, loss = 0.00105407\n",
      "Iteration 5083, loss = 0.00105386\n",
      "Iteration 5084, loss = 0.00105363\n",
      "Iteration 5085, loss = 0.00105330\n",
      "Iteration 5086, loss = 0.00105303\n",
      "Iteration 5087, loss = 0.00105273\n",
      "Iteration 5088, loss = 0.00105247\n",
      "Iteration 5089, loss = 0.00105224\n",
      "Iteration 5090, loss = 0.00105194\n",
      "Iteration 5091, loss = 0.00105176\n",
      "Iteration 5092, loss = 0.00105144\n",
      "Iteration 5093, loss = 0.00105110\n",
      "Iteration 5094, loss = 0.00105086\n",
      "Iteration 5095, loss = 0.00105057\n",
      "Iteration 5096, loss = 0.00105033\n",
      "Iteration 5097, loss = 0.00105002\n",
      "Iteration 5098, loss = 0.00104973\n",
      "Iteration 5099, loss = 0.00104950\n",
      "Iteration 5100, loss = 0.00104925\n",
      "Iteration 5101, loss = 0.00104894\n",
      "Iteration 5102, loss = 0.00104871\n",
      "Iteration 5103, loss = 0.00104843\n",
      "Iteration 5104, loss = 0.00104813\n",
      "Iteration 5105, loss = 0.00104784\n",
      "Iteration 5106, loss = 0.00104755\n",
      "Iteration 5107, loss = 0.00104739\n",
      "Iteration 5108, loss = 0.00104710\n",
      "Iteration 5109, loss = 0.00104677\n",
      "Iteration 5110, loss = 0.00104652\n",
      "Iteration 5111, loss = 0.00104629\n",
      "Iteration 5112, loss = 0.00104603\n",
      "Iteration 5113, loss = 0.00104573\n",
      "Iteration 5114, loss = 0.00104546\n",
      "Iteration 5115, loss = 0.00104519\n",
      "Iteration 5116, loss = 0.00104497\n",
      "Iteration 5117, loss = 0.00104465\n",
      "Iteration 5118, loss = 0.00104440\n",
      "Iteration 5119, loss = 0.00104417\n",
      "Iteration 5120, loss = 0.00104393\n",
      "Iteration 5121, loss = 0.00104364\n",
      "Iteration 5122, loss = 0.00104339\n",
      "Iteration 5123, loss = 0.00104312\n",
      "Iteration 5124, loss = 0.00104286\n",
      "Iteration 5125, loss = 0.00104257\n",
      "Iteration 5126, loss = 0.00104234\n",
      "Iteration 5127, loss = 0.00104208\n",
      "Iteration 5128, loss = 0.00104185\n",
      "Iteration 5129, loss = 0.00104154\n",
      "Iteration 5130, loss = 0.00104125\n",
      "Iteration 5131, loss = 0.00104102\n",
      "Iteration 5132, loss = 0.00104077\n",
      "Iteration 5133, loss = 0.00104048\n",
      "Iteration 5134, loss = 0.00104025\n",
      "Iteration 5135, loss = 0.00103993\n",
      "Iteration 5136, loss = 0.00103967\n",
      "Iteration 5137, loss = 0.00103942\n",
      "Iteration 5138, loss = 0.00103916\n",
      "Iteration 5139, loss = 0.00103885\n",
      "Iteration 5140, loss = 0.00103868\n",
      "Iteration 5141, loss = 0.00103837\n",
      "Iteration 5142, loss = 0.00103811\n",
      "Iteration 5143, loss = 0.00103786\n",
      "Iteration 5144, loss = 0.00103764\n",
      "Iteration 5145, loss = 0.00103731\n",
      "Iteration 5146, loss = 0.00103706\n",
      "Iteration 5147, loss = 0.00103679\n",
      "Iteration 5148, loss = 0.00103654\n",
      "Iteration 5149, loss = 0.00103629\n",
      "Iteration 5150, loss = 0.00103608\n",
      "Iteration 5151, loss = 0.00103579\n",
      "Iteration 5152, loss = 0.00103548\n",
      "Iteration 5153, loss = 0.00103522\n",
      "Iteration 5154, loss = 0.00103496\n",
      "Iteration 5155, loss = 0.00103472\n",
      "Iteration 5156, loss = 0.00103445\n",
      "Iteration 5157, loss = 0.00103417\n",
      "Iteration 5158, loss = 0.00103398\n",
      "Iteration 5159, loss = 0.00103374\n",
      "Iteration 5160, loss = 0.00103346\n",
      "Iteration 5161, loss = 0.00103316\n",
      "Iteration 5162, loss = 0.00103288\n",
      "Iteration 5163, loss = 0.00103267\n",
      "Iteration 5164, loss = 0.00103239\n",
      "Iteration 5165, loss = 0.00103222\n",
      "Iteration 5166, loss = 0.00103187\n",
      "Iteration 5167, loss = 0.00103157\n",
      "Iteration 5168, loss = 0.00103131\n",
      "Iteration 5169, loss = 0.00103106\n",
      "Iteration 5170, loss = 0.00103079\n",
      "Iteration 5171, loss = 0.00103054\n",
      "Iteration 5172, loss = 0.00103030\n",
      "Iteration 5173, loss = 0.00103003\n",
      "Iteration 5174, loss = 0.00102979\n",
      "Iteration 5175, loss = 0.00102953\n",
      "Iteration 5176, loss = 0.00102924\n",
      "Iteration 5177, loss = 0.00102904\n",
      "Iteration 5178, loss = 0.00102874\n",
      "Iteration 5179, loss = 0.00102846\n",
      "Iteration 5180, loss = 0.00102819\n",
      "Iteration 5181, loss = 0.00102798\n",
      "Iteration 5182, loss = 0.00102769\n",
      "Iteration 5183, loss = 0.00102745\n",
      "Iteration 5184, loss = 0.00102720\n",
      "Iteration 5185, loss = 0.00102700\n",
      "Iteration 5186, loss = 0.00102666\n",
      "Iteration 5187, loss = 0.00102638\n",
      "Iteration 5188, loss = 0.00102608\n",
      "Iteration 5189, loss = 0.00102586\n",
      "Iteration 5190, loss = 0.00102555\n",
      "Iteration 5191, loss = 0.00102524\n",
      "Iteration 5192, loss = 0.00102500\n",
      "Iteration 5193, loss = 0.00102470\n",
      "Iteration 5194, loss = 0.00102442\n",
      "Iteration 5195, loss = 0.00102413\n",
      "Iteration 5196, loss = 0.00102387\n",
      "Iteration 5197, loss = 0.00102361\n",
      "Iteration 5198, loss = 0.00102337\n",
      "Iteration 5199, loss = 0.00102311\n",
      "Iteration 5200, loss = 0.00102279\n",
      "Iteration 5201, loss = 0.00102254\n",
      "Iteration 5202, loss = 0.00102223\n",
      "Iteration 5203, loss = 0.00102194\n",
      "Iteration 5204, loss = 0.00102170\n",
      "Iteration 5205, loss = 0.00102146\n",
      "Iteration 5206, loss = 0.00102118\n",
      "Iteration 5207, loss = 0.00102085\n",
      "Iteration 5208, loss = 0.00102059\n",
      "Iteration 5209, loss = 0.00102031\n",
      "Iteration 5210, loss = 0.00102010\n",
      "Iteration 5211, loss = 0.00101981\n",
      "Iteration 5212, loss = 0.00101954\n",
      "Iteration 5213, loss = 0.00101932\n",
      "Iteration 5214, loss = 0.00101899\n",
      "Iteration 5215, loss = 0.00101872\n",
      "Iteration 5216, loss = 0.00101849\n",
      "Iteration 5217, loss = 0.00101820\n",
      "Iteration 5218, loss = 0.00101797\n",
      "Iteration 5219, loss = 0.00101767\n",
      "Iteration 5220, loss = 0.00101738\n",
      "Iteration 5221, loss = 0.00101712\n",
      "Iteration 5222, loss = 0.00101686\n",
      "Iteration 5223, loss = 0.00101659\n",
      "Iteration 5224, loss = 0.00101631\n",
      "Iteration 5225, loss = 0.00101599\n",
      "Iteration 5226, loss = 0.00101572\n",
      "Iteration 5227, loss = 0.00101542\n",
      "Iteration 5228, loss = 0.00101520\n",
      "Iteration 5229, loss = 0.00101495\n",
      "Iteration 5230, loss = 0.00101467\n",
      "Iteration 5231, loss = 0.00101435\n",
      "Iteration 5232, loss = 0.00101410\n",
      "Iteration 5233, loss = 0.00101379\n",
      "Iteration 5234, loss = 0.00101360\n",
      "Iteration 5235, loss = 0.00101324\n",
      "Iteration 5236, loss = 0.00101296\n",
      "Iteration 5237, loss = 0.00101272\n",
      "Iteration 5238, loss = 0.00101244\n",
      "Iteration 5239, loss = 0.00101220\n",
      "Iteration 5240, loss = 0.00101192\n",
      "Iteration 5241, loss = 0.00101160\n",
      "Iteration 5242, loss = 0.00101133\n",
      "Iteration 5243, loss = 0.00101108\n",
      "Iteration 5244, loss = 0.00101077\n",
      "Iteration 5245, loss = 0.00101049\n",
      "Iteration 5246, loss = 0.00101024\n",
      "Iteration 5247, loss = 0.00100995\n",
      "Iteration 5248, loss = 0.00100967\n",
      "Iteration 5249, loss = 0.00100943\n",
      "Iteration 5250, loss = 0.00100913\n",
      "Iteration 5251, loss = 0.00100884\n",
      "Iteration 5252, loss = 0.00100861\n",
      "Iteration 5253, loss = 0.00100836\n",
      "Iteration 5254, loss = 0.00100805\n",
      "Iteration 5255, loss = 0.00100780\n",
      "Iteration 5256, loss = 0.00100750\n",
      "Iteration 5257, loss = 0.00100723\n",
      "Iteration 5258, loss = 0.00100698\n",
      "Iteration 5259, loss = 0.00100671\n",
      "Iteration 5260, loss = 0.00100653\n",
      "Iteration 5261, loss = 0.00100621\n",
      "Iteration 5262, loss = 0.00100589\n",
      "Iteration 5263, loss = 0.00100567\n",
      "Iteration 5264, loss = 0.00100538\n",
      "Iteration 5265, loss = 0.00100515\n",
      "Iteration 5266, loss = 0.00100486\n",
      "Iteration 5267, loss = 0.00100459\n",
      "Iteration 5268, loss = 0.00100437\n",
      "Iteration 5269, loss = 0.00100407\n",
      "Iteration 5270, loss = 0.00100378\n",
      "Iteration 5271, loss = 0.00100355\n",
      "Iteration 5272, loss = 0.00100332\n",
      "Iteration 5273, loss = 0.00100308\n",
      "Iteration 5274, loss = 0.00100282\n",
      "Iteration 5275, loss = 0.00100253\n",
      "Iteration 5276, loss = 0.00100230\n",
      "Iteration 5277, loss = 0.00100199\n",
      "Iteration 5278, loss = 0.00100171\n",
      "Iteration 5279, loss = 0.00100141\n",
      "Iteration 5280, loss = 0.00100122\n",
      "Iteration 5281, loss = 0.00100094\n",
      "Iteration 5282, loss = 0.00100062\n",
      "Iteration 5283, loss = 0.00100038\n",
      "Iteration 5284, loss = 0.00100009\n",
      "Iteration 5285, loss = 0.00099984\n",
      "Iteration 5286, loss = 0.00099961\n",
      "Iteration 5287, loss = 0.00099936\n",
      "Iteration 5288, loss = 0.00099907\n",
      "Iteration 5289, loss = 0.00099883\n",
      "Iteration 5290, loss = 0.00099856\n",
      "Iteration 5291, loss = 0.00099826\n",
      "Iteration 5292, loss = 0.00099808\n",
      "Iteration 5293, loss = 0.00099776\n",
      "Iteration 5294, loss = 0.00099749\n",
      "Iteration 5295, loss = 0.00099723\n",
      "Iteration 5296, loss = 0.00099701\n",
      "Iteration 5297, loss = 0.00099677\n",
      "Iteration 5298, loss = 0.00099646\n",
      "Iteration 5299, loss = 0.00099620\n",
      "Iteration 5300, loss = 0.00099596\n",
      "Iteration 5301, loss = 0.00099569\n",
      "Iteration 5302, loss = 0.00099544\n",
      "Iteration 5303, loss = 0.00099518\n",
      "Iteration 5304, loss = 0.00099495\n",
      "Iteration 5305, loss = 0.00099472\n",
      "Iteration 5306, loss = 0.00099447\n",
      "Iteration 5307, loss = 0.00099419\n",
      "Iteration 5308, loss = 0.00099396\n",
      "Iteration 5309, loss = 0.00099368\n",
      "Iteration 5310, loss = 0.00099344\n",
      "Iteration 5311, loss = 0.00099318\n",
      "Iteration 5312, loss = 0.00099293\n",
      "Iteration 5313, loss = 0.00099267\n",
      "Iteration 5314, loss = 0.00099240\n",
      "Iteration 5315, loss = 0.00099216\n",
      "Iteration 5316, loss = 0.00099189\n",
      "Iteration 5317, loss = 0.00099165\n",
      "Iteration 5318, loss = 0.00099137\n",
      "Iteration 5319, loss = 0.00099112\n",
      "Iteration 5320, loss = 0.00099091\n",
      "Iteration 5321, loss = 0.00099062\n",
      "Iteration 5322, loss = 0.00099037\n",
      "Iteration 5323, loss = 0.00099012\n",
      "Iteration 5324, loss = 0.00098987\n",
      "Iteration 5325, loss = 0.00098964\n",
      "Iteration 5326, loss = 0.00098937\n",
      "Iteration 5327, loss = 0.00098911\n",
      "Iteration 5328, loss = 0.00098888\n",
      "Iteration 5329, loss = 0.00098856\n",
      "Iteration 5330, loss = 0.00098833\n",
      "Iteration 5331, loss = 0.00098807\n",
      "Iteration 5332, loss = 0.00098788\n",
      "Iteration 5333, loss = 0.00098756\n",
      "Iteration 5334, loss = 0.00098736\n",
      "Iteration 5335, loss = 0.00098712\n",
      "Iteration 5336, loss = 0.00098686\n",
      "Iteration 5337, loss = 0.00098664\n",
      "Iteration 5338, loss = 0.00098635\n",
      "Iteration 5339, loss = 0.00098611\n",
      "Iteration 5340, loss = 0.00098586\n",
      "Iteration 5341, loss = 0.00098558\n",
      "Iteration 5342, loss = 0.00098533\n",
      "Iteration 5343, loss = 0.00098509\n",
      "Iteration 5344, loss = 0.00098482\n",
      "Iteration 5345, loss = 0.00098459\n",
      "Iteration 5346, loss = 0.00098432\n",
      "Iteration 5347, loss = 0.00098409\n",
      "Iteration 5348, loss = 0.00098385\n",
      "Iteration 5349, loss = 0.00098361\n",
      "Iteration 5350, loss = 0.00098334\n",
      "Iteration 5351, loss = 0.00098313\n",
      "Iteration 5352, loss = 0.00098285\n",
      "Iteration 5353, loss = 0.00098256\n",
      "Iteration 5354, loss = 0.00098226\n",
      "Iteration 5355, loss = 0.00098206\n",
      "Iteration 5356, loss = 0.00098178\n",
      "Iteration 5357, loss = 0.00098154\n",
      "Iteration 5358, loss = 0.00098129\n",
      "Iteration 5359, loss = 0.00098101\n",
      "Iteration 5360, loss = 0.00098073\n",
      "Iteration 5361, loss = 0.00098055\n",
      "Iteration 5362, loss = 0.00098028\n",
      "Iteration 5363, loss = 0.00098002\n",
      "Iteration 5364, loss = 0.00097975\n",
      "Iteration 5365, loss = 0.00097954\n",
      "Iteration 5366, loss = 0.00097926\n",
      "Iteration 5367, loss = 0.00097904\n",
      "Iteration 5368, loss = 0.00097881\n",
      "Iteration 5369, loss = 0.00097856\n",
      "Iteration 5370, loss = 0.00097826\n",
      "Iteration 5371, loss = 0.00097807\n",
      "Iteration 5372, loss = 0.00097780\n",
      "Iteration 5373, loss = 0.00097759\n",
      "Iteration 5374, loss = 0.00097732\n",
      "Iteration 5375, loss = 0.00097707\n",
      "Iteration 5376, loss = 0.00097680\n",
      "Iteration 5377, loss = 0.00097662\n",
      "Iteration 5378, loss = 0.00097634\n",
      "Iteration 5379, loss = 0.00097608\n",
      "Iteration 5380, loss = 0.00097589\n",
      "Iteration 5381, loss = 0.00097561\n",
      "Iteration 5382, loss = 0.00097542\n",
      "Iteration 5383, loss = 0.00097510\n",
      "Iteration 5384, loss = 0.00097487\n",
      "Iteration 5385, loss = 0.00097461\n",
      "Iteration 5386, loss = 0.00097440\n",
      "Iteration 5387, loss = 0.00097414\n",
      "Iteration 5388, loss = 0.00097389\n",
      "Iteration 5389, loss = 0.00097368\n",
      "Iteration 5390, loss = 0.00097342\n",
      "Iteration 5391, loss = 0.00097321\n",
      "Iteration 5392, loss = 0.00097294\n",
      "Iteration 5393, loss = 0.00097272\n",
      "Iteration 5394, loss = 0.00097250\n",
      "Iteration 5395, loss = 0.00097217\n",
      "Iteration 5396, loss = 0.00097197\n",
      "Iteration 5397, loss = 0.00097170\n",
      "Iteration 5398, loss = 0.00097142\n",
      "Iteration 5399, loss = 0.00097121\n",
      "Iteration 5400, loss = 0.00097096\n",
      "Iteration 5401, loss = 0.00097070\n",
      "Iteration 5402, loss = 0.00097051\n",
      "Iteration 5403, loss = 0.00097028\n",
      "Iteration 5404, loss = 0.00097000\n",
      "Iteration 5405, loss = 0.00096973\n",
      "Iteration 5406, loss = 0.00096950\n",
      "Iteration 5407, loss = 0.00096927\n",
      "Iteration 5408, loss = 0.00096904\n",
      "Iteration 5409, loss = 0.00096882\n",
      "Iteration 5410, loss = 0.00096852\n",
      "Iteration 5411, loss = 0.00096829\n",
      "Iteration 5412, loss = 0.00096804\n",
      "Iteration 5413, loss = 0.00096784\n",
      "Iteration 5414, loss = 0.00096755\n",
      "Iteration 5415, loss = 0.00096734\n",
      "Iteration 5416, loss = 0.00096707\n",
      "Iteration 5417, loss = 0.00096689\n",
      "Iteration 5418, loss = 0.00096664\n",
      "Iteration 5419, loss = 0.00096638\n",
      "Iteration 5420, loss = 0.00096618\n",
      "Iteration 5421, loss = 0.00096591\n",
      "Iteration 5422, loss = 0.00096564\n",
      "Iteration 5423, loss = 0.00096540\n",
      "Iteration 5424, loss = 0.00096517\n",
      "Iteration 5425, loss = 0.00096496\n",
      "Iteration 5426, loss = 0.00096468\n",
      "Iteration 5427, loss = 0.00096445\n",
      "Iteration 5428, loss = 0.00096424\n",
      "Iteration 5429, loss = 0.00096398\n",
      "Iteration 5430, loss = 0.00096369\n",
      "Iteration 5431, loss = 0.00096353\n",
      "Iteration 5432, loss = 0.00096326\n",
      "Iteration 5433, loss = 0.00096300\n",
      "Iteration 5434, loss = 0.00096280\n",
      "Iteration 5435, loss = 0.00096252\n",
      "Iteration 5436, loss = 0.00096229\n",
      "Iteration 5437, loss = 0.00096202\n",
      "Iteration 5438, loss = 0.00096177\n",
      "Iteration 5439, loss = 0.00096156\n",
      "Iteration 5440, loss = 0.00096130\n",
      "Iteration 5441, loss = 0.00096105\n",
      "Iteration 5442, loss = 0.00096081\n",
      "Iteration 5443, loss = 0.00096058\n",
      "Iteration 5444, loss = 0.00096033\n",
      "Iteration 5445, loss = 0.00096016\n",
      "Iteration 5446, loss = 0.00095984\n",
      "Iteration 5447, loss = 0.00095960\n",
      "Iteration 5448, loss = 0.00095938\n",
      "Iteration 5449, loss = 0.00095913\n",
      "Iteration 5450, loss = 0.00095889\n",
      "Iteration 5451, loss = 0.00095862\n",
      "Iteration 5452, loss = 0.00095844\n",
      "Iteration 5453, loss = 0.00095817\n",
      "Iteration 5454, loss = 0.00095789\n",
      "Iteration 5455, loss = 0.00095768\n",
      "Iteration 5456, loss = 0.00095742\n",
      "Iteration 5457, loss = 0.00095721\n",
      "Iteration 5458, loss = 0.00095699\n",
      "Iteration 5459, loss = 0.00095678\n",
      "Iteration 5460, loss = 0.00095651\n",
      "Iteration 5461, loss = 0.00095624\n",
      "Iteration 5462, loss = 0.00095605\n",
      "Iteration 5463, loss = 0.00095576\n",
      "Iteration 5464, loss = 0.00095552\n",
      "Iteration 5465, loss = 0.00095536\n",
      "Iteration 5466, loss = 0.00095510\n",
      "Iteration 5467, loss = 0.00095482\n",
      "Iteration 5468, loss = 0.00095462\n",
      "Iteration 5469, loss = 0.00095440\n",
      "Iteration 5470, loss = 0.00095413\n",
      "Iteration 5471, loss = 0.00095388\n",
      "Iteration 5472, loss = 0.00095367\n",
      "Iteration 5473, loss = 0.00095339\n",
      "Iteration 5474, loss = 0.00095317\n",
      "Iteration 5475, loss = 0.00095292\n",
      "Iteration 5476, loss = 0.00095271\n",
      "Iteration 5477, loss = 0.00095244\n",
      "Iteration 5478, loss = 0.00095219\n",
      "Iteration 5479, loss = 0.00095195\n",
      "Iteration 5480, loss = 0.00095169\n",
      "Iteration 5481, loss = 0.00095144\n",
      "Iteration 5482, loss = 0.00095123\n",
      "Iteration 5483, loss = 0.00095094\n",
      "Iteration 5484, loss = 0.00095074\n",
      "Iteration 5485, loss = 0.00095047\n",
      "Iteration 5486, loss = 0.00095026\n",
      "Iteration 5487, loss = 0.00095001\n",
      "Iteration 5488, loss = 0.00094975\n",
      "Iteration 5489, loss = 0.00094958\n",
      "Iteration 5490, loss = 0.00094932\n",
      "Iteration 5491, loss = 0.00094909\n",
      "Iteration 5492, loss = 0.00094902\n",
      "Iteration 5493, loss = 0.00094862\n",
      "Iteration 5494, loss = 0.00094841\n",
      "Iteration 5495, loss = 0.00094814\n",
      "Iteration 5496, loss = 0.00094793\n",
      "Iteration 5497, loss = 0.00094775\n",
      "Iteration 5498, loss = 0.00094747\n",
      "Iteration 5499, loss = 0.00094724\n",
      "Iteration 5500, loss = 0.00094701\n",
      "Iteration 5501, loss = 0.00094681\n",
      "Iteration 5502, loss = 0.00094655\n",
      "Iteration 5503, loss = 0.00094630\n",
      "Iteration 5504, loss = 0.00094608\n",
      "Iteration 5505, loss = 0.00094588\n",
      "Iteration 5506, loss = 0.00094566\n",
      "Iteration 5507, loss = 0.00094541\n",
      "Iteration 5508, loss = 0.00094517\n",
      "Iteration 5509, loss = 0.00094489\n",
      "Iteration 5510, loss = 0.00094469\n",
      "Iteration 5511, loss = 0.00094449\n",
      "Iteration 5512, loss = 0.00094427\n",
      "Iteration 5513, loss = 0.00094404\n",
      "Iteration 5514, loss = 0.00094379\n",
      "Iteration 5515, loss = 0.00094353\n",
      "Iteration 5516, loss = 0.00094334\n",
      "Iteration 5517, loss = 0.00094308\n",
      "Iteration 5518, loss = 0.00094288\n",
      "Iteration 5519, loss = 0.00094262\n",
      "Iteration 5520, loss = 0.00094244\n",
      "Iteration 5521, loss = 0.00094216\n",
      "Iteration 5522, loss = 0.00094195\n",
      "Iteration 5523, loss = 0.00094169\n",
      "Iteration 5524, loss = 0.00094143\n",
      "Iteration 5525, loss = 0.00094124\n",
      "Iteration 5526, loss = 0.00094102\n",
      "Iteration 5527, loss = 0.00094076\n",
      "Iteration 5528, loss = 0.00094057\n",
      "Iteration 5529, loss = 0.00094036\n",
      "Iteration 5530, loss = 0.00094009\n",
      "Iteration 5531, loss = 0.00093984\n",
      "Iteration 5532, loss = 0.00093965\n",
      "Iteration 5533, loss = 0.00093941\n",
      "Iteration 5534, loss = 0.00093923\n",
      "Iteration 5535, loss = 0.00093899\n",
      "Iteration 5536, loss = 0.00093870\n",
      "Iteration 5537, loss = 0.00093847\n",
      "Iteration 5538, loss = 0.00093825\n",
      "Iteration 5539, loss = 0.00093802\n",
      "Iteration 5540, loss = 0.00093777\n",
      "Iteration 5541, loss = 0.00093753\n",
      "Iteration 5542, loss = 0.00093730\n",
      "Iteration 5543, loss = 0.00093709\n",
      "Iteration 5544, loss = 0.00093683\n",
      "Iteration 5545, loss = 0.00093661\n",
      "Iteration 5546, loss = 0.00093638\n",
      "Iteration 5547, loss = 0.00093616\n",
      "Iteration 5548, loss = 0.00093592\n",
      "Iteration 5549, loss = 0.00093572\n",
      "Iteration 5550, loss = 0.00093548\n",
      "Iteration 5551, loss = 0.00093527\n",
      "Iteration 5552, loss = 0.00093503\n",
      "Iteration 5553, loss = 0.00093478\n",
      "Iteration 5554, loss = 0.00093458\n",
      "Iteration 5555, loss = 0.00093439\n",
      "Iteration 5556, loss = 0.00093417\n",
      "Iteration 5557, loss = 0.00093389\n",
      "Iteration 5558, loss = 0.00093366\n",
      "Iteration 5559, loss = 0.00093347\n",
      "Iteration 5560, loss = 0.00093321\n",
      "Iteration 5561, loss = 0.00093297\n",
      "Iteration 5562, loss = 0.00093276\n",
      "Iteration 5563, loss = 0.00093252\n",
      "Iteration 5564, loss = 0.00093236\n",
      "Iteration 5565, loss = 0.00093214\n",
      "Iteration 5566, loss = 0.00093185\n",
      "Iteration 5567, loss = 0.00093167\n",
      "Iteration 5568, loss = 0.00093141\n",
      "Iteration 5569, loss = 0.00093120\n",
      "Iteration 5570, loss = 0.00093097\n",
      "Iteration 5571, loss = 0.00093073\n",
      "Iteration 5572, loss = 0.00093053\n",
      "Iteration 5573, loss = 0.00093033\n",
      "Iteration 5574, loss = 0.00093007\n",
      "Iteration 5575, loss = 0.00092985\n",
      "Iteration 5576, loss = 0.00092964\n",
      "Iteration 5577, loss = 0.00092939\n",
      "Iteration 5578, loss = 0.00092923\n",
      "Iteration 5579, loss = 0.00092897\n",
      "Iteration 5580, loss = 0.00092873\n",
      "Iteration 5581, loss = 0.00092852\n",
      "Iteration 5582, loss = 0.00092833\n",
      "Iteration 5583, loss = 0.00092807\n",
      "Iteration 5584, loss = 0.00092783\n",
      "Iteration 5585, loss = 0.00092764\n",
      "Iteration 5586, loss = 0.00092742\n",
      "Iteration 5587, loss = 0.00092719\n",
      "Iteration 5588, loss = 0.00092695\n",
      "Iteration 5589, loss = 0.00092671\n",
      "Iteration 5590, loss = 0.00092650\n",
      "Iteration 5591, loss = 0.00092626\n",
      "Iteration 5592, loss = 0.00092604\n",
      "Iteration 5593, loss = 0.00092583\n",
      "Iteration 5594, loss = 0.00092562\n",
      "Iteration 5595, loss = 0.00092542\n",
      "Iteration 5596, loss = 0.00092516\n",
      "Iteration 5597, loss = 0.00092495\n",
      "Iteration 5598, loss = 0.00092471\n",
      "Iteration 5599, loss = 0.00092449\n",
      "Iteration 5600, loss = 0.00092431\n",
      "Iteration 5601, loss = 0.00092407\n",
      "Iteration 5602, loss = 0.00092385\n",
      "Iteration 5603, loss = 0.00092364\n",
      "Iteration 5604, loss = 0.00092341\n",
      "Iteration 5605, loss = 0.00092321\n",
      "Iteration 5606, loss = 0.00092297\n",
      "Iteration 5607, loss = 0.00092278\n",
      "Iteration 5608, loss = 0.00092254\n",
      "Iteration 5609, loss = 0.00092232\n",
      "Iteration 5610, loss = 0.00092210\n",
      "Iteration 5611, loss = 0.00092187\n",
      "Iteration 5612, loss = 0.00092166\n",
      "Iteration 5613, loss = 0.00092144\n",
      "Iteration 5614, loss = 0.00092121\n",
      "Iteration 5615, loss = 0.00092098\n",
      "Iteration 5616, loss = 0.00092077\n",
      "Iteration 5617, loss = 0.00092054\n",
      "Iteration 5618, loss = 0.00092031\n",
      "Iteration 5619, loss = 0.00092006\n",
      "Iteration 5620, loss = 0.00091982\n",
      "Iteration 5621, loss = 0.00091962\n",
      "Iteration 5622, loss = 0.00091942\n",
      "Iteration 5623, loss = 0.00091917\n",
      "Iteration 5624, loss = 0.00091895\n",
      "Iteration 5625, loss = 0.00091874\n",
      "Iteration 5626, loss = 0.00091854\n",
      "Iteration 5627, loss = 0.00091831\n",
      "Iteration 5628, loss = 0.00091803\n",
      "Iteration 5629, loss = 0.00091781\n",
      "Iteration 5630, loss = 0.00091760\n",
      "Iteration 5631, loss = 0.00091741\n",
      "Iteration 5632, loss = 0.00091717\n",
      "Iteration 5633, loss = 0.00091696\n",
      "Iteration 5634, loss = 0.00091682\n",
      "Iteration 5635, loss = 0.00091655\n",
      "Iteration 5636, loss = 0.00091627\n",
      "Iteration 5637, loss = 0.00091614\n",
      "Iteration 5638, loss = 0.00091584\n",
      "Iteration 5639, loss = 0.00091561\n",
      "Iteration 5640, loss = 0.00091539\n",
      "Iteration 5641, loss = 0.00091517\n",
      "Iteration 5642, loss = 0.00091495\n",
      "Iteration 5643, loss = 0.00091473\n",
      "Iteration 5644, loss = 0.00091459\n",
      "Iteration 5645, loss = 0.00091432\n",
      "Iteration 5646, loss = 0.00091401\n",
      "Iteration 5647, loss = 0.00091384\n",
      "Iteration 5648, loss = 0.00091363\n",
      "Iteration 5649, loss = 0.00091343\n",
      "Iteration 5650, loss = 0.00091317\n",
      "Iteration 5651, loss = 0.00091294\n",
      "Iteration 5652, loss = 0.00091274\n",
      "Iteration 5653, loss = 0.00091251\n",
      "Iteration 5654, loss = 0.00091230\n",
      "Iteration 5655, loss = 0.00091207\n",
      "Iteration 5656, loss = 0.00091185\n",
      "Iteration 5657, loss = 0.00091166\n",
      "Iteration 5658, loss = 0.00091140\n",
      "Iteration 5659, loss = 0.00091125\n",
      "Iteration 5660, loss = 0.00091099\n",
      "Iteration 5661, loss = 0.00091077\n",
      "Iteration 5662, loss = 0.00091059\n",
      "Iteration 5663, loss = 0.00091035\n",
      "Iteration 5664, loss = 0.00091016\n",
      "Iteration 5665, loss = 0.00090992\n",
      "Iteration 5666, loss = 0.00090971\n",
      "Iteration 5667, loss = 0.00090950\n",
      "Iteration 5668, loss = 0.00090931\n",
      "Iteration 5669, loss = 0.00090908\n",
      "Iteration 5670, loss = 0.00090889\n",
      "Iteration 5671, loss = 0.00090864\n",
      "Iteration 5672, loss = 0.00090844\n",
      "Iteration 5673, loss = 0.00090822\n",
      "Iteration 5674, loss = 0.00090801\n",
      "Iteration 5675, loss = 0.00090777\n",
      "Iteration 5676, loss = 0.00090754\n",
      "Iteration 5677, loss = 0.00090733\n",
      "Iteration 5678, loss = 0.00090714\n",
      "Iteration 5679, loss = 0.00090693\n",
      "Iteration 5680, loss = 0.00090670\n",
      "Iteration 5681, loss = 0.00090653\n",
      "Iteration 5682, loss = 0.00090629\n",
      "Iteration 5683, loss = 0.00090608\n",
      "Iteration 5684, loss = 0.00090587\n",
      "Iteration 5685, loss = 0.00090570\n",
      "Iteration 5686, loss = 0.00090542\n",
      "Iteration 5687, loss = 0.00090522\n",
      "Iteration 5688, loss = 0.00090500\n",
      "Iteration 5689, loss = 0.00090480\n",
      "Iteration 5690, loss = 0.00090456\n",
      "Iteration 5691, loss = 0.00090436\n",
      "Iteration 5692, loss = 0.00090416\n",
      "Iteration 5693, loss = 0.00090395\n",
      "Iteration 5694, loss = 0.00090372\n",
      "Iteration 5695, loss = 0.00090356\n",
      "Iteration 5696, loss = 0.00090333\n",
      "Iteration 5697, loss = 0.00090310\n",
      "Iteration 5698, loss = 0.00090288\n",
      "Iteration 5699, loss = 0.00090268\n",
      "Iteration 5700, loss = 0.00090247\n",
      "Iteration 5701, loss = 0.00090229\n",
      "Iteration 5702, loss = 0.00090204\n",
      "Iteration 5703, loss = 0.00090183\n",
      "Iteration 5704, loss = 0.00090164\n",
      "Iteration 5705, loss = 0.00090143\n",
      "Iteration 5706, loss = 0.00090120\n",
      "Iteration 5707, loss = 0.00090098\n",
      "Iteration 5708, loss = 0.00090077\n",
      "Iteration 5709, loss = 0.00090055\n",
      "Iteration 5710, loss = 0.00090037\n",
      "Iteration 5711, loss = 0.00090016\n",
      "Iteration 5712, loss = 0.00089995\n",
      "Iteration 5713, loss = 0.00089968\n",
      "Iteration 5714, loss = 0.00089954\n",
      "Iteration 5715, loss = 0.00089933\n",
      "Iteration 5716, loss = 0.00089907\n",
      "Iteration 5717, loss = 0.00089885\n",
      "Iteration 5718, loss = 0.00089863\n",
      "Iteration 5719, loss = 0.00089842\n",
      "Iteration 5720, loss = 0.00089821\n",
      "Iteration 5721, loss = 0.00089800\n",
      "Iteration 5722, loss = 0.00089777\n",
      "Iteration 5723, loss = 0.00089758\n",
      "Iteration 5724, loss = 0.00089739\n",
      "Iteration 5725, loss = 0.00089718\n",
      "Iteration 5726, loss = 0.00089695\n",
      "Iteration 5727, loss = 0.00089675\n",
      "Iteration 5728, loss = 0.00089653\n",
      "Iteration 5729, loss = 0.00089634\n",
      "Iteration 5730, loss = 0.00089610\n",
      "Iteration 5731, loss = 0.00089594\n",
      "Iteration 5732, loss = 0.00089574\n",
      "Iteration 5733, loss = 0.00089546\n",
      "Iteration 5734, loss = 0.00089534\n",
      "Iteration 5735, loss = 0.00089509\n",
      "Iteration 5736, loss = 0.00089487\n",
      "Iteration 5737, loss = 0.00089470\n",
      "Iteration 5738, loss = 0.00089443\n",
      "Iteration 5739, loss = 0.00089425\n",
      "Iteration 5740, loss = 0.00089404\n",
      "Iteration 5741, loss = 0.00089380\n",
      "Iteration 5742, loss = 0.00089359\n",
      "Iteration 5743, loss = 0.00089342\n",
      "Iteration 5744, loss = 0.00089319\n",
      "Iteration 5745, loss = 0.00089301\n",
      "Iteration 5746, loss = 0.00089276\n",
      "Iteration 5747, loss = 0.00089255\n",
      "Iteration 5748, loss = 0.00089232\n",
      "Iteration 5749, loss = 0.00089216\n",
      "Iteration 5750, loss = 0.00089193\n",
      "Iteration 5751, loss = 0.00089171\n",
      "Iteration 5752, loss = 0.00089156\n",
      "Iteration 5753, loss = 0.00089130\n",
      "Iteration 5754, loss = 0.00089109\n",
      "Iteration 5755, loss = 0.00089092\n",
      "Iteration 5756, loss = 0.00089069\n",
      "Iteration 5757, loss = 0.00089047\n",
      "Iteration 5758, loss = 0.00089027\n",
      "Iteration 5759, loss = 0.00089005\n",
      "Iteration 5760, loss = 0.00088984\n",
      "Iteration 5761, loss = 0.00088959\n",
      "Iteration 5762, loss = 0.00088943\n",
      "Iteration 5763, loss = 0.00088917\n",
      "Iteration 5764, loss = 0.00088899\n",
      "Iteration 5765, loss = 0.00088877\n",
      "Iteration 5766, loss = 0.00088855\n",
      "Iteration 5767, loss = 0.00088834\n",
      "Iteration 5768, loss = 0.00088816\n",
      "Iteration 5769, loss = 0.00088794\n",
      "Iteration 5770, loss = 0.00088772\n",
      "Iteration 5771, loss = 0.00088752\n",
      "Iteration 5772, loss = 0.00088732\n",
      "Iteration 5773, loss = 0.00088711\n",
      "Iteration 5774, loss = 0.00088689\n",
      "Iteration 5775, loss = 0.00088671\n",
      "Iteration 5776, loss = 0.00088652\n",
      "Iteration 5777, loss = 0.00088633\n",
      "Iteration 5778, loss = 0.00088608\n",
      "Iteration 5779, loss = 0.00088589\n",
      "Iteration 5780, loss = 0.00088567\n",
      "Iteration 5781, loss = 0.00088545\n",
      "Iteration 5782, loss = 0.00088526\n",
      "Iteration 5783, loss = 0.00088502\n",
      "Iteration 5784, loss = 0.00088486\n",
      "Iteration 5785, loss = 0.00088464\n",
      "Iteration 5786, loss = 0.00088447\n",
      "Iteration 5787, loss = 0.00088424\n",
      "Iteration 5788, loss = 0.00088402\n",
      "Iteration 5789, loss = 0.00088380\n",
      "Iteration 5790, loss = 0.00088359\n",
      "Iteration 5791, loss = 0.00088342\n",
      "Iteration 5792, loss = 0.00088321\n",
      "Iteration 5793, loss = 0.00088297\n",
      "Iteration 5794, loss = 0.00088280\n",
      "Iteration 5795, loss = 0.00088261\n",
      "Iteration 5796, loss = 0.00088242\n",
      "Iteration 5797, loss = 0.00088223\n",
      "Iteration 5798, loss = 0.00088204\n",
      "Iteration 5799, loss = 0.00088180\n",
      "Iteration 5800, loss = 0.00088160\n",
      "Iteration 5801, loss = 0.00088137\n",
      "Iteration 5802, loss = 0.00088122\n",
      "Iteration 5803, loss = 0.00088100\n",
      "Iteration 5804, loss = 0.00088079\n",
      "Iteration 5805, loss = 0.00088061\n",
      "Iteration 5806, loss = 0.00088040\n",
      "Iteration 5807, loss = 0.00088017\n",
      "Iteration 5808, loss = 0.00087998\n",
      "Iteration 5809, loss = 0.00087980\n",
      "Iteration 5810, loss = 0.00087963\n",
      "Iteration 5811, loss = 0.00087939\n",
      "Iteration 5812, loss = 0.00087916\n",
      "Iteration 5813, loss = 0.00087900\n",
      "Iteration 5814, loss = 0.00087880\n",
      "Iteration 5815, loss = 0.00087862\n",
      "Iteration 5816, loss = 0.00087838\n",
      "Iteration 5817, loss = 0.00087819\n",
      "Iteration 5818, loss = 0.00087798\n",
      "Iteration 5819, loss = 0.00087779\n",
      "Iteration 5820, loss = 0.00087759\n",
      "Iteration 5821, loss = 0.00087738\n",
      "Iteration 5822, loss = 0.00087719\n",
      "Iteration 5823, loss = 0.00087703\n",
      "Iteration 5824, loss = 0.00087679\n",
      "Iteration 5825, loss = 0.00087662\n",
      "Iteration 5826, loss = 0.00087641\n",
      "Iteration 5827, loss = 0.00087618\n",
      "Iteration 5828, loss = 0.00087597\n",
      "Iteration 5829, loss = 0.00087578\n",
      "Iteration 5830, loss = 0.00087556\n",
      "Iteration 5831, loss = 0.00087542\n",
      "Iteration 5832, loss = 0.00087518\n",
      "Iteration 5833, loss = 0.00087497\n",
      "Iteration 5834, loss = 0.00087479\n",
      "Iteration 5835, loss = 0.00087458\n",
      "Iteration 5836, loss = 0.00087438\n",
      "Iteration 5837, loss = 0.00087417\n",
      "Iteration 5838, loss = 0.00087401\n",
      "Iteration 5839, loss = 0.00087382\n",
      "Iteration 5840, loss = 0.00087361\n",
      "Iteration 5841, loss = 0.00087341\n",
      "Iteration 5842, loss = 0.00087319\n",
      "Iteration 5843, loss = 0.00087300\n",
      "Iteration 5844, loss = 0.00087282\n",
      "Iteration 5845, loss = 0.00087259\n",
      "Iteration 5846, loss = 0.00087239\n",
      "Iteration 5847, loss = 0.00087218\n",
      "Iteration 5848, loss = 0.00087199\n",
      "Iteration 5849, loss = 0.00087178\n",
      "Iteration 5850, loss = 0.00087160\n",
      "Iteration 5851, loss = 0.00087139\n",
      "Iteration 5852, loss = 0.00087120\n",
      "Iteration 5853, loss = 0.00087103\n",
      "Iteration 5854, loss = 0.00087082\n",
      "Iteration 5855, loss = 0.00087060\n",
      "Iteration 5856, loss = 0.00087041\n",
      "Iteration 5857, loss = 0.00087019\n",
      "Iteration 5858, loss = 0.00087002\n",
      "Iteration 5859, loss = 0.00086982\n",
      "Iteration 5860, loss = 0.00086963\n",
      "Iteration 5861, loss = 0.00086943\n",
      "Iteration 5862, loss = 0.00086924\n",
      "Iteration 5863, loss = 0.00086903\n",
      "Iteration 5864, loss = 0.00086889\n",
      "Iteration 5865, loss = 0.00086867\n",
      "Iteration 5866, loss = 0.00086846\n",
      "Iteration 5867, loss = 0.00086829\n",
      "Iteration 5868, loss = 0.00086806\n",
      "Iteration 5869, loss = 0.00086785\n",
      "Iteration 5870, loss = 0.00086768\n",
      "Iteration 5871, loss = 0.00086747\n",
      "Iteration 5872, loss = 0.00086727\n",
      "Iteration 5873, loss = 0.00086707\n",
      "Iteration 5874, loss = 0.00086689\n",
      "Iteration 5875, loss = 0.00086671\n",
      "Iteration 5876, loss = 0.00086649\n",
      "Iteration 5877, loss = 0.00086629\n",
      "Iteration 5878, loss = 0.00086609\n",
      "Iteration 5879, loss = 0.00086593\n",
      "Iteration 5880, loss = 0.00086570\n",
      "Iteration 5881, loss = 0.00086550\n",
      "Iteration 5882, loss = 0.00086527\n",
      "Iteration 5883, loss = 0.00086508\n",
      "Iteration 5884, loss = 0.00086490\n",
      "Iteration 5885, loss = 0.00086470\n",
      "Iteration 5886, loss = 0.00086450\n",
      "Iteration 5887, loss = 0.00086434\n",
      "Iteration 5888, loss = 0.00086412\n",
      "Iteration 5889, loss = 0.00086393\n",
      "Iteration 5890, loss = 0.00086376\n",
      "Iteration 5891, loss = 0.00086352\n",
      "Iteration 5892, loss = 0.00086331\n",
      "Iteration 5893, loss = 0.00086320\n",
      "Iteration 5894, loss = 0.00086300\n",
      "Iteration 5895, loss = 0.00086283\n",
      "Iteration 5896, loss = 0.00086254\n",
      "Iteration 5897, loss = 0.00086236\n",
      "Iteration 5898, loss = 0.00086225\n",
      "Iteration 5899, loss = 0.00086196\n",
      "Iteration 5900, loss = 0.00086178\n",
      "Iteration 5901, loss = 0.00086157\n",
      "Iteration 5902, loss = 0.00086135\n",
      "Iteration 5903, loss = 0.00086116\n",
      "Iteration 5904, loss = 0.00086097\n",
      "Iteration 5905, loss = 0.00086079\n",
      "Iteration 5906, loss = 0.00086061\n",
      "Iteration 5907, loss = 0.00086041\n",
      "Iteration 5908, loss = 0.00086022\n",
      "Iteration 5909, loss = 0.00086005\n",
      "Iteration 5910, loss = 0.00085986\n",
      "Iteration 5911, loss = 0.00085963\n",
      "Iteration 5912, loss = 0.00085947\n",
      "Iteration 5913, loss = 0.00085925\n",
      "Iteration 5914, loss = 0.00085908\n",
      "Iteration 5915, loss = 0.00085887\n",
      "Iteration 5916, loss = 0.00085868\n",
      "Iteration 5917, loss = 0.00085854\n",
      "Iteration 5918, loss = 0.00085831\n",
      "Iteration 5919, loss = 0.00085812\n",
      "Iteration 5920, loss = 0.00085793\n",
      "Iteration 5921, loss = 0.00085775\n",
      "Iteration 5922, loss = 0.00085754\n",
      "Iteration 5923, loss = 0.00085738\n",
      "Iteration 5924, loss = 0.00085720\n",
      "Iteration 5925, loss = 0.00085698\n",
      "Iteration 5926, loss = 0.00085680\n",
      "Iteration 5927, loss = 0.00085663\n",
      "Iteration 5928, loss = 0.00085640\n",
      "Iteration 5929, loss = 0.00085625\n",
      "Iteration 5930, loss = 0.00085602\n",
      "Iteration 5931, loss = 0.00085587\n",
      "Iteration 5932, loss = 0.00085567\n",
      "Iteration 5933, loss = 0.00085549\n",
      "Iteration 5934, loss = 0.00085529\n",
      "Iteration 5935, loss = 0.00085517\n",
      "Iteration 5936, loss = 0.00085491\n",
      "Iteration 5937, loss = 0.00085474\n",
      "Iteration 5938, loss = 0.00085455\n",
      "Iteration 5939, loss = 0.00085436\n",
      "Iteration 5940, loss = 0.00085417\n",
      "Iteration 5941, loss = 0.00085397\n",
      "Iteration 5942, loss = 0.00085382\n",
      "Iteration 5943, loss = 0.00085363\n",
      "Iteration 5944, loss = 0.00085340\n",
      "Iteration 5945, loss = 0.00085321\n",
      "Iteration 5946, loss = 0.00085305\n",
      "Iteration 5947, loss = 0.00085288\n",
      "Iteration 5948, loss = 0.00085265\n",
      "Iteration 5949, loss = 0.00085248\n",
      "Iteration 5950, loss = 0.00085230\n",
      "Iteration 5951, loss = 0.00085211\n",
      "Iteration 5952, loss = 0.00085193\n",
      "Iteration 5953, loss = 0.00085170\n",
      "Iteration 5954, loss = 0.00085155\n",
      "Iteration 5955, loss = 0.00085137\n",
      "Iteration 5956, loss = 0.00085119\n",
      "Iteration 5957, loss = 0.00085099\n",
      "Iteration 5958, loss = 0.00085080\n",
      "Iteration 5959, loss = 0.00085067\n",
      "Iteration 5960, loss = 0.00085045\n",
      "Iteration 5961, loss = 0.00085025\n",
      "Iteration 5962, loss = 0.00085003\n",
      "Iteration 5963, loss = 0.00084986\n",
      "Iteration 5964, loss = 0.00084970\n",
      "Iteration 5965, loss = 0.00084947\n",
      "Iteration 5966, loss = 0.00084930\n",
      "Iteration 5967, loss = 0.00084909\n",
      "Iteration 5968, loss = 0.00084892\n",
      "Iteration 5969, loss = 0.00084873\n",
      "Iteration 5970, loss = 0.00084856\n",
      "Iteration 5971, loss = 0.00084836\n",
      "Iteration 5972, loss = 0.00084818\n",
      "Iteration 5973, loss = 0.00084801\n",
      "Iteration 5974, loss = 0.00084784\n",
      "Iteration 5975, loss = 0.00084764\n",
      "Iteration 5976, loss = 0.00084748\n",
      "Iteration 5977, loss = 0.00084728\n",
      "Iteration 5978, loss = 0.00084709\n",
      "Iteration 5979, loss = 0.00084689\n",
      "Iteration 5980, loss = 0.00084672\n",
      "Iteration 5981, loss = 0.00084655\n",
      "Iteration 5982, loss = 0.00084633\n",
      "Iteration 5983, loss = 0.00084625\n",
      "Iteration 5984, loss = 0.00084597\n",
      "Iteration 5985, loss = 0.00084581\n",
      "Iteration 5986, loss = 0.00084559\n",
      "Iteration 5987, loss = 0.00084547\n",
      "Iteration 5988, loss = 0.00084526\n",
      "Iteration 5989, loss = 0.00084507\n",
      "Iteration 5990, loss = 0.00084487\n",
      "Iteration 5991, loss = 0.00084468\n",
      "Iteration 5992, loss = 0.00084453\n",
      "Iteration 5993, loss = 0.00084433\n",
      "Iteration 5994, loss = 0.00084413\n",
      "Iteration 5995, loss = 0.00084398\n",
      "Iteration 5996, loss = 0.00084373\n",
      "Iteration 5997, loss = 0.00084357\n",
      "Iteration 5998, loss = 0.00084337\n",
      "Iteration 5999, loss = 0.00084321\n",
      "Iteration 6000, loss = 0.00084301\n",
      "Iteration 6001, loss = 0.00084281\n",
      "Iteration 6002, loss = 0.00084264\n",
      "Iteration 6003, loss = 0.00084243\n",
      "Iteration 6004, loss = 0.00084226\n",
      "Iteration 6005, loss = 0.00084206\n",
      "Iteration 6006, loss = 0.00084187\n",
      "Iteration 6007, loss = 0.00084170\n",
      "Iteration 6008, loss = 0.00084153\n",
      "Iteration 6009, loss = 0.00084137\n",
      "Iteration 6010, loss = 0.00084115\n",
      "Iteration 6011, loss = 0.00084097\n",
      "Iteration 6012, loss = 0.00084077\n",
      "Iteration 6013, loss = 0.00084058\n",
      "Iteration 6014, loss = 0.00084039\n",
      "Iteration 6015, loss = 0.00084019\n",
      "Iteration 6016, loss = 0.00084000\n",
      "Iteration 6017, loss = 0.00083983\n",
      "Iteration 6018, loss = 0.00083969\n",
      "Iteration 6019, loss = 0.00083948\n",
      "Iteration 6020, loss = 0.00083931\n",
      "Iteration 6021, loss = 0.00083913\n",
      "Iteration 6022, loss = 0.00083892\n",
      "Iteration 6023, loss = 0.00083871\n",
      "Iteration 6024, loss = 0.00083853\n",
      "Iteration 6025, loss = 0.00083838\n",
      "Iteration 6026, loss = 0.00083817\n",
      "Iteration 6027, loss = 0.00083798\n",
      "Iteration 6028, loss = 0.00083782\n",
      "Iteration 6029, loss = 0.00083765\n",
      "Iteration 6030, loss = 0.00083746\n",
      "Iteration 6031, loss = 0.00083728\n",
      "Iteration 6032, loss = 0.00083709\n",
      "Iteration 6033, loss = 0.00083689\n",
      "Iteration 6034, loss = 0.00083676\n",
      "Iteration 6035, loss = 0.00083653\n",
      "Iteration 6036, loss = 0.00083636\n",
      "Iteration 6037, loss = 0.00083618\n",
      "Iteration 6038, loss = 0.00083606\n",
      "Iteration 6039, loss = 0.00083584\n",
      "Iteration 6040, loss = 0.00083568\n",
      "Iteration 6041, loss = 0.00083546\n",
      "Iteration 6042, loss = 0.00083528\n",
      "Iteration 6043, loss = 0.00083511\n",
      "Iteration 6044, loss = 0.00083491\n",
      "Iteration 6045, loss = 0.00083472\n",
      "Iteration 6046, loss = 0.00083458\n",
      "Iteration 6047, loss = 0.00083438\n",
      "Iteration 6048, loss = 0.00083421\n",
      "Iteration 6049, loss = 0.00083402\n",
      "Iteration 6050, loss = 0.00083382\n",
      "Iteration 6051, loss = 0.00083365\n",
      "Iteration 6052, loss = 0.00083345\n",
      "Iteration 6053, loss = 0.00083328\n",
      "Iteration 6054, loss = 0.00083311\n",
      "Iteration 6055, loss = 0.00083293\n",
      "Iteration 6056, loss = 0.00083283\n",
      "Iteration 6057, loss = 0.00083257\n",
      "Iteration 6058, loss = 0.00083234\n",
      "Iteration 6059, loss = 0.00083218\n",
      "Iteration 6060, loss = 0.00083199\n",
      "Iteration 6061, loss = 0.00083179\n",
      "Iteration 6062, loss = 0.00083159\n",
      "Iteration 6063, loss = 0.00083143\n",
      "Iteration 6064, loss = 0.00083125\n",
      "Iteration 6065, loss = 0.00083106\n",
      "Iteration 6066, loss = 0.00083092\n",
      "Iteration 6067, loss = 0.00083071\n",
      "Iteration 6068, loss = 0.00083054\n",
      "Iteration 6069, loss = 0.00083037\n",
      "Iteration 6070, loss = 0.00083021\n",
      "Iteration 6071, loss = 0.00083003\n",
      "Iteration 6072, loss = 0.00082980\n",
      "Iteration 6073, loss = 0.00082969\n",
      "Iteration 6074, loss = 0.00082946\n",
      "Iteration 6075, loss = 0.00082928\n",
      "Iteration 6076, loss = 0.00082912\n",
      "Iteration 6077, loss = 0.00082892\n",
      "Iteration 6078, loss = 0.00082874\n",
      "Iteration 6079, loss = 0.00082853\n",
      "Iteration 6080, loss = 0.00082841\n",
      "Iteration 6081, loss = 0.00082822\n",
      "Iteration 6082, loss = 0.00082803\n",
      "Iteration 6083, loss = 0.00082788\n",
      "Iteration 6084, loss = 0.00082768\n",
      "Iteration 6085, loss = 0.00082752\n",
      "Iteration 6086, loss = 0.00082734\n",
      "Iteration 6087, loss = 0.00082717\n",
      "Iteration 6088, loss = 0.00082699\n",
      "Iteration 6089, loss = 0.00082679\n",
      "Iteration 6090, loss = 0.00082664\n",
      "Iteration 6091, loss = 0.00082647\n",
      "Iteration 6092, loss = 0.00082628\n",
      "Iteration 6093, loss = 0.00082611\n",
      "Iteration 6094, loss = 0.00082593\n",
      "Iteration 6095, loss = 0.00082575\n",
      "Iteration 6096, loss = 0.00082555\n",
      "Iteration 6097, loss = 0.00082539\n",
      "Iteration 6098, loss = 0.00082520\n",
      "Iteration 6099, loss = 0.00082503\n",
      "Iteration 6100, loss = 0.00082484\n",
      "Iteration 6101, loss = 0.00082468\n",
      "Iteration 6102, loss = 0.00082448\n",
      "Iteration 6103, loss = 0.00082432\n",
      "Iteration 6104, loss = 0.00082416\n",
      "Iteration 6105, loss = 0.00082394\n",
      "Iteration 6106, loss = 0.00082379\n",
      "Iteration 6107, loss = 0.00082363\n",
      "Iteration 6108, loss = 0.00082343\n",
      "Iteration 6109, loss = 0.00082324\n",
      "Iteration 6110, loss = 0.00082305\n",
      "Iteration 6111, loss = 0.00082289\n",
      "Iteration 6112, loss = 0.00082272\n",
      "Iteration 6113, loss = 0.00082258\n",
      "Iteration 6114, loss = 0.00082238\n",
      "Iteration 6115, loss = 0.00082220\n",
      "Iteration 6116, loss = 0.00082201\n",
      "Iteration 6117, loss = 0.00082179\n",
      "Iteration 6118, loss = 0.00082166\n",
      "Iteration 6119, loss = 0.00082145\n",
      "Iteration 6120, loss = 0.00082129\n",
      "Iteration 6121, loss = 0.00082110\n",
      "Iteration 6122, loss = 0.00082093\n",
      "Iteration 6123, loss = 0.00082075\n",
      "Iteration 6124, loss = 0.00082057\n",
      "Iteration 6125, loss = 0.00082040\n",
      "Iteration 6126, loss = 0.00082023\n",
      "Iteration 6127, loss = 0.00082005\n",
      "Iteration 6128, loss = 0.00081987\n",
      "Iteration 6129, loss = 0.00081970\n",
      "Iteration 6130, loss = 0.00081949\n",
      "Iteration 6131, loss = 0.00081931\n",
      "Iteration 6132, loss = 0.00081913\n",
      "Iteration 6133, loss = 0.00081900\n",
      "Iteration 6134, loss = 0.00081881\n",
      "Iteration 6135, loss = 0.00081862\n",
      "Iteration 6136, loss = 0.00081844\n",
      "Iteration 6137, loss = 0.00081828\n",
      "Iteration 6138, loss = 0.00081814\n",
      "Iteration 6139, loss = 0.00081796\n",
      "Iteration 6140, loss = 0.00081773\n",
      "Iteration 6141, loss = 0.00081759\n",
      "Iteration 6142, loss = 0.00081738\n",
      "Iteration 6143, loss = 0.00081720\n",
      "Iteration 6144, loss = 0.00081702\n",
      "Iteration 6145, loss = 0.00081687\n",
      "Iteration 6146, loss = 0.00081666\n",
      "Iteration 6147, loss = 0.00081649\n",
      "Iteration 6148, loss = 0.00081633\n",
      "Iteration 6149, loss = 0.00081614\n",
      "Iteration 6150, loss = 0.00081598\n",
      "Iteration 6151, loss = 0.00081580\n",
      "Iteration 6152, loss = 0.00081560\n",
      "Iteration 6153, loss = 0.00081542\n",
      "Iteration 6154, loss = 0.00081526\n",
      "Iteration 6155, loss = 0.00081510\n",
      "Iteration 6156, loss = 0.00081491\n",
      "Iteration 6157, loss = 0.00081473\n",
      "Iteration 6158, loss = 0.00081457\n",
      "Iteration 6159, loss = 0.00081436\n",
      "Iteration 6160, loss = 0.00081419\n",
      "Iteration 6161, loss = 0.00081403\n",
      "Iteration 6162, loss = 0.00081385\n",
      "Iteration 6163, loss = 0.00081369\n",
      "Iteration 6164, loss = 0.00081345\n",
      "Iteration 6165, loss = 0.00081330\n",
      "Iteration 6166, loss = 0.00081312\n",
      "Iteration 6167, loss = 0.00081297\n",
      "Iteration 6168, loss = 0.00081279\n",
      "Iteration 6169, loss = 0.00081259\n",
      "Iteration 6170, loss = 0.00081247\n",
      "Iteration 6171, loss = 0.00081228\n",
      "Iteration 6172, loss = 0.00081212\n",
      "Iteration 6173, loss = 0.00081193\n",
      "Iteration 6174, loss = 0.00081176\n",
      "Iteration 6175, loss = 0.00081157\n",
      "Iteration 6176, loss = 0.00081140\n",
      "Iteration 6177, loss = 0.00081123\n",
      "Iteration 6178, loss = 0.00081102\n",
      "Iteration 6179, loss = 0.00081089\n",
      "Iteration 6180, loss = 0.00081068\n",
      "Iteration 6181, loss = 0.00081051\n",
      "Iteration 6182, loss = 0.00081035\n",
      "Iteration 6183, loss = 0.00081016\n",
      "Iteration 6184, loss = 0.00080998\n",
      "Iteration 6185, loss = 0.00080982\n",
      "Iteration 6186, loss = 0.00080961\n",
      "Iteration 6187, loss = 0.00080946\n",
      "Iteration 6188, loss = 0.00080930\n",
      "Iteration 6189, loss = 0.00080911\n",
      "Iteration 6190, loss = 0.00080893\n",
      "Iteration 6191, loss = 0.00080886\n",
      "Iteration 6192, loss = 0.00080859\n",
      "Iteration 6193, loss = 0.00080843\n",
      "Iteration 6194, loss = 0.00080829\n",
      "Iteration 6195, loss = 0.00080811\n",
      "Iteration 6196, loss = 0.00080793\n",
      "Iteration 6197, loss = 0.00080777\n",
      "Iteration 6198, loss = 0.00080761\n",
      "Iteration 6199, loss = 0.00080740\n",
      "Iteration 6200, loss = 0.00080728\n",
      "Iteration 6201, loss = 0.00080708\n",
      "Iteration 6202, loss = 0.00080691\n",
      "Iteration 6203, loss = 0.00080677\n",
      "Iteration 6204, loss = 0.00080656\n",
      "Iteration 6205, loss = 0.00080641\n",
      "Iteration 6206, loss = 0.00080625\n",
      "Iteration 6207, loss = 0.00080607\n",
      "Iteration 6208, loss = 0.00080589\n",
      "Iteration 6209, loss = 0.00080573\n",
      "Iteration 6210, loss = 0.00080556\n",
      "Iteration 6211, loss = 0.00080542\n",
      "Iteration 6212, loss = 0.00080525\n",
      "Iteration 6213, loss = 0.00080506\n",
      "Iteration 6214, loss = 0.00080496\n",
      "Iteration 6215, loss = 0.00080474\n",
      "Iteration 6216, loss = 0.00080459\n",
      "Iteration 6217, loss = 0.00080443\n",
      "Iteration 6218, loss = 0.00080421\n",
      "Iteration 6219, loss = 0.00080405\n",
      "Iteration 6220, loss = 0.00080385\n",
      "Iteration 6221, loss = 0.00080371\n",
      "Iteration 6222, loss = 0.00080355\n",
      "Iteration 6223, loss = 0.00080335\n",
      "Iteration 6224, loss = 0.00080321\n",
      "Iteration 6225, loss = 0.00080303\n",
      "Iteration 6226, loss = 0.00080284\n",
      "Iteration 6227, loss = 0.00080270\n",
      "Iteration 6228, loss = 0.00080252\n",
      "Iteration 6229, loss = 0.00080237\n",
      "Iteration 6230, loss = 0.00080221\n",
      "Iteration 6231, loss = 0.00080203\n",
      "Iteration 6232, loss = 0.00080185\n",
      "Iteration 6233, loss = 0.00080167\n",
      "Iteration 6234, loss = 0.00080149\n",
      "Iteration 6235, loss = 0.00080133\n",
      "Iteration 6236, loss = 0.00080112\n",
      "Iteration 6237, loss = 0.00080099\n",
      "Iteration 6238, loss = 0.00080081\n",
      "Iteration 6239, loss = 0.00080062\n",
      "Iteration 6240, loss = 0.00080045\n",
      "Iteration 6241, loss = 0.00080036\n",
      "Iteration 6242, loss = 0.00080013\n",
      "Iteration 6243, loss = 0.00079995\n",
      "Iteration 6244, loss = 0.00079980\n",
      "Iteration 6245, loss = 0.00079965\n",
      "Iteration 6246, loss = 0.00079944\n",
      "Iteration 6247, loss = 0.00079931\n",
      "Iteration 6248, loss = 0.00079916\n",
      "Iteration 6249, loss = 0.00079894\n",
      "Iteration 6250, loss = 0.00079880\n",
      "Iteration 6251, loss = 0.00079862\n",
      "Iteration 6252, loss = 0.00079845\n",
      "Iteration 6253, loss = 0.00079832\n",
      "Iteration 6254, loss = 0.00079811\n",
      "Iteration 6255, loss = 0.00079794\n",
      "Iteration 6256, loss = 0.00079779\n",
      "Iteration 6257, loss = 0.00079762\n",
      "Iteration 6258, loss = 0.00079745\n",
      "Iteration 6259, loss = 0.00079726\n",
      "Iteration 6260, loss = 0.00079709\n",
      "Iteration 6261, loss = 0.00079696\n",
      "Iteration 6262, loss = 0.00079679\n",
      "Iteration 6263, loss = 0.00079662\n",
      "Iteration 6264, loss = 0.00079643\n",
      "Iteration 6265, loss = 0.00079628\n",
      "Iteration 6266, loss = 0.00079609\n",
      "Iteration 6267, loss = 0.00079592\n",
      "Iteration 6268, loss = 0.00079575\n",
      "Iteration 6269, loss = 0.00079562\n",
      "Iteration 6270, loss = 0.00079544\n",
      "Iteration 6271, loss = 0.00079532\n",
      "Iteration 6272, loss = 0.00079510\n",
      "Iteration 6273, loss = 0.00079491\n",
      "Iteration 6274, loss = 0.00079474\n",
      "Iteration 6275, loss = 0.00079459\n",
      "Iteration 6276, loss = 0.00079444\n",
      "Iteration 6277, loss = 0.00079428\n",
      "Iteration 6278, loss = 0.00079408\n",
      "Iteration 6279, loss = 0.00079395\n",
      "Iteration 6280, loss = 0.00079376\n",
      "Iteration 6281, loss = 0.00079362\n",
      "Iteration 6282, loss = 0.00079344\n",
      "Iteration 6283, loss = 0.00079328\n",
      "Iteration 6284, loss = 0.00079313\n",
      "Iteration 6285, loss = 0.00079294\n",
      "Iteration 6286, loss = 0.00079280\n",
      "Iteration 6287, loss = 0.00079260\n",
      "Iteration 6288, loss = 0.00079246\n",
      "Iteration 6289, loss = 0.00079230\n",
      "Iteration 6290, loss = 0.00079213\n",
      "Iteration 6291, loss = 0.00079194\n",
      "Iteration 6292, loss = 0.00079178\n",
      "Iteration 6293, loss = 0.00079164\n",
      "Iteration 6294, loss = 0.00079146\n",
      "Iteration 6295, loss = 0.00079130\n",
      "Iteration 6296, loss = 0.00079116\n",
      "Iteration 6297, loss = 0.00079100\n",
      "Iteration 6298, loss = 0.00079082\n",
      "Iteration 6299, loss = 0.00079064\n",
      "Iteration 6300, loss = 0.00079048\n",
      "Iteration 6301, loss = 0.00079033\n",
      "Iteration 6302, loss = 0.00079017\n",
      "Iteration 6303, loss = 0.00079001\n",
      "Iteration 6304, loss = 0.00078988\n",
      "Iteration 6305, loss = 0.00078967\n",
      "Iteration 6306, loss = 0.00078951\n",
      "Iteration 6307, loss = 0.00078934\n",
      "Iteration 6308, loss = 0.00078918\n",
      "Iteration 6309, loss = 0.00078900\n",
      "Iteration 6310, loss = 0.00078885\n",
      "Iteration 6311, loss = 0.00078868\n",
      "Iteration 6312, loss = 0.00078851\n",
      "Iteration 6313, loss = 0.00078834\n",
      "Iteration 6314, loss = 0.00078820\n",
      "Iteration 6315, loss = 0.00078804\n",
      "Iteration 6316, loss = 0.00078784\n",
      "Iteration 6317, loss = 0.00078769\n",
      "Iteration 6318, loss = 0.00078750\n",
      "Iteration 6319, loss = 0.00078734\n",
      "Iteration 6320, loss = 0.00078718\n",
      "Iteration 6321, loss = 0.00078703\n",
      "Iteration 6322, loss = 0.00078685\n",
      "Iteration 6323, loss = 0.00078667\n",
      "Iteration 6324, loss = 0.00078654\n",
      "Iteration 6325, loss = 0.00078636\n",
      "Iteration 6326, loss = 0.00078617\n",
      "Iteration 6327, loss = 0.00078602\n",
      "Iteration 6328, loss = 0.00078584\n",
      "Iteration 6329, loss = 0.00078568\n",
      "Iteration 6330, loss = 0.00078554\n",
      "Iteration 6331, loss = 0.00078533\n",
      "Iteration 6332, loss = 0.00078522\n",
      "Iteration 6333, loss = 0.00078500\n",
      "Iteration 6334, loss = 0.00078482\n",
      "Iteration 6335, loss = 0.00078466\n",
      "Iteration 6336, loss = 0.00078450\n",
      "Iteration 6337, loss = 0.00078436\n",
      "Iteration 6338, loss = 0.00078419\n",
      "Iteration 6339, loss = 0.00078401\n",
      "Iteration 6340, loss = 0.00078385\n",
      "Iteration 6341, loss = 0.00078369\n",
      "Iteration 6342, loss = 0.00078355\n",
      "Iteration 6343, loss = 0.00078341\n",
      "Iteration 6344, loss = 0.00078325\n",
      "Iteration 6345, loss = 0.00078308\n",
      "Iteration 6346, loss = 0.00078293\n",
      "Iteration 6347, loss = 0.00078277\n",
      "Iteration 6348, loss = 0.00078258\n",
      "Iteration 6349, loss = 0.00078242\n",
      "Iteration 6350, loss = 0.00078227\n",
      "Iteration 6351, loss = 0.00078213\n",
      "Iteration 6352, loss = 0.00078195\n",
      "Iteration 6353, loss = 0.00078186\n",
      "Iteration 6354, loss = 0.00078165\n",
      "Iteration 6355, loss = 0.00078148\n",
      "Iteration 6356, loss = 0.00078132\n",
      "Iteration 6357, loss = 0.00078116\n",
      "Iteration 6358, loss = 0.00078097\n",
      "Iteration 6359, loss = 0.00078081\n",
      "Iteration 6360, loss = 0.00078065\n",
      "Iteration 6361, loss = 0.00078048\n",
      "Iteration 6362, loss = 0.00078031\n",
      "Iteration 6363, loss = 0.00078015\n",
      "Iteration 6364, loss = 0.00077999\n",
      "Iteration 6365, loss = 0.00077981\n",
      "Iteration 6366, loss = 0.00077967\n",
      "Iteration 6367, loss = 0.00077955\n",
      "Iteration 6368, loss = 0.00077934\n",
      "Iteration 6369, loss = 0.00077918\n",
      "Iteration 6370, loss = 0.00077902\n",
      "Iteration 6371, loss = 0.00077887\n",
      "Iteration 6372, loss = 0.00077868\n",
      "Iteration 6373, loss = 0.00077854\n",
      "Iteration 6374, loss = 0.00077842\n",
      "Iteration 6375, loss = 0.00077822\n",
      "Iteration 6376, loss = 0.00077808\n",
      "Iteration 6377, loss = 0.00077790\n",
      "Iteration 6378, loss = 0.00077777\n",
      "Iteration 6379, loss = 0.00077759\n",
      "Iteration 6380, loss = 0.00077742\n",
      "Iteration 6381, loss = 0.00077730\n",
      "Iteration 6382, loss = 0.00077713\n",
      "Iteration 6383, loss = 0.00077697\n",
      "Iteration 6384, loss = 0.00077681\n",
      "Iteration 6385, loss = 0.00077662\n",
      "Iteration 6386, loss = 0.00077650\n",
      "Iteration 6387, loss = 0.00077631\n",
      "Iteration 6388, loss = 0.00077615\n",
      "Iteration 6389, loss = 0.00077600\n",
      "Iteration 6390, loss = 0.00077585\n",
      "Iteration 6391, loss = 0.00077568\n",
      "Iteration 6392, loss = 0.00077558\n",
      "Iteration 6393, loss = 0.00077537\n",
      "Iteration 6394, loss = 0.00077522\n",
      "Iteration 6395, loss = 0.00077506\n",
      "Iteration 6396, loss = 0.00077491\n",
      "Iteration 6397, loss = 0.00077476\n",
      "Iteration 6398, loss = 0.00077459\n",
      "Iteration 6399, loss = 0.00077448\n",
      "Iteration 6400, loss = 0.00077427\n",
      "Iteration 6401, loss = 0.00077412\n",
      "Iteration 6402, loss = 0.00077398\n",
      "Iteration 6403, loss = 0.00077380\n",
      "Iteration 6404, loss = 0.00077364\n",
      "Iteration 6405, loss = 0.00077348\n",
      "Iteration 6406, loss = 0.00077334\n",
      "Iteration 6407, loss = 0.00077317\n",
      "Iteration 6408, loss = 0.00077300\n",
      "Iteration 6409, loss = 0.00077285\n",
      "Iteration 6410, loss = 0.00077266\n",
      "Iteration 6411, loss = 0.00077257\n",
      "Iteration 6412, loss = 0.00077234\n",
      "Iteration 6413, loss = 0.00077219\n",
      "Iteration 6414, loss = 0.00077200\n",
      "Iteration 6415, loss = 0.00077186\n",
      "Iteration 6416, loss = 0.00077171\n",
      "Iteration 6417, loss = 0.00077152\n",
      "Iteration 6418, loss = 0.00077138\n",
      "Iteration 6419, loss = 0.00077121\n",
      "Iteration 6420, loss = 0.00077104\n",
      "Iteration 6421, loss = 0.00077091\n",
      "Iteration 6422, loss = 0.00077077\n",
      "Iteration 6423, loss = 0.00077059\n",
      "Iteration 6424, loss = 0.00077043\n",
      "Iteration 6425, loss = 0.00077028\n",
      "Iteration 6426, loss = 0.00077011\n",
      "Iteration 6427, loss = 0.00076993\n",
      "Iteration 6428, loss = 0.00076981\n",
      "Iteration 6429, loss = 0.00076960\n",
      "Iteration 6430, loss = 0.00076948\n",
      "Iteration 6431, loss = 0.00076931\n",
      "Iteration 6432, loss = 0.00076915\n",
      "Iteration 6433, loss = 0.00076899\n",
      "Iteration 6434, loss = 0.00076885\n",
      "Iteration 6435, loss = 0.00076869\n",
      "Iteration 6436, loss = 0.00076851\n",
      "Iteration 6437, loss = 0.00076834\n",
      "Iteration 6438, loss = 0.00076821\n",
      "Iteration 6439, loss = 0.00076801\n",
      "Iteration 6440, loss = 0.00076789\n",
      "Iteration 6441, loss = 0.00076771\n",
      "Iteration 6442, loss = 0.00076755\n",
      "Iteration 6443, loss = 0.00076740\n",
      "Iteration 6444, loss = 0.00076722\n",
      "Iteration 6445, loss = 0.00076710\n",
      "Iteration 6446, loss = 0.00076690\n",
      "Iteration 6447, loss = 0.00076675\n",
      "Iteration 6448, loss = 0.00076659\n",
      "Iteration 6449, loss = 0.00076644\n",
      "Iteration 6450, loss = 0.00076625\n",
      "Iteration 6451, loss = 0.00076609\n",
      "Iteration 6452, loss = 0.00076595\n",
      "Iteration 6453, loss = 0.00076576\n",
      "Iteration 6454, loss = 0.00076562\n",
      "Iteration 6455, loss = 0.00076545\n",
      "Iteration 6456, loss = 0.00076531\n",
      "Iteration 6457, loss = 0.00076514\n",
      "Iteration 6458, loss = 0.00076497\n",
      "Iteration 6459, loss = 0.00076481\n",
      "Iteration 6460, loss = 0.00076466\n",
      "Iteration 6461, loss = 0.00076451\n",
      "Iteration 6462, loss = 0.00076433\n",
      "Iteration 6463, loss = 0.00076418\n",
      "Iteration 6464, loss = 0.00076403\n",
      "Iteration 6465, loss = 0.00076386\n",
      "Iteration 6466, loss = 0.00076374\n",
      "Iteration 6467, loss = 0.00076354\n",
      "Iteration 6468, loss = 0.00076337\n",
      "Iteration 6469, loss = 0.00076321\n",
      "Iteration 6470, loss = 0.00076304\n",
      "Iteration 6471, loss = 0.00076288\n",
      "Iteration 6472, loss = 0.00076277\n",
      "Iteration 6473, loss = 0.00076256\n",
      "Iteration 6474, loss = 0.00076242\n",
      "Iteration 6475, loss = 0.00076225\n",
      "Iteration 6476, loss = 0.00076209\n",
      "Iteration 6477, loss = 0.00076194\n",
      "Iteration 6478, loss = 0.00076181\n",
      "Iteration 6479, loss = 0.00076162\n",
      "Iteration 6480, loss = 0.00076148\n",
      "Iteration 6481, loss = 0.00076136\n",
      "Iteration 6482, loss = 0.00076118\n",
      "Iteration 6483, loss = 0.00076103\n",
      "Iteration 6484, loss = 0.00076088\n",
      "Iteration 6485, loss = 0.00076071\n",
      "Iteration 6486, loss = 0.00076055\n",
      "Iteration 6487, loss = 0.00076039\n",
      "Iteration 6488, loss = 0.00076028\n",
      "Iteration 6489, loss = 0.00076012\n",
      "Iteration 6490, loss = 0.00075994\n",
      "Iteration 6491, loss = 0.00075984\n",
      "Iteration 6492, loss = 0.00075966\n",
      "Iteration 6493, loss = 0.00075952\n",
      "Iteration 6494, loss = 0.00075932\n",
      "Iteration 6495, loss = 0.00075919\n",
      "Iteration 6496, loss = 0.00075903\n",
      "Iteration 6497, loss = 0.00075886\n",
      "Iteration 6498, loss = 0.00075872\n",
      "Iteration 6499, loss = 0.00075858\n",
      "Iteration 6500, loss = 0.00075840\n",
      "Iteration 6501, loss = 0.00075827\n",
      "Iteration 6502, loss = 0.00075810\n",
      "Iteration 6503, loss = 0.00075792\n",
      "Iteration 6504, loss = 0.00075779\n",
      "Iteration 6505, loss = 0.00075765\n",
      "Iteration 6506, loss = 0.00075744\n",
      "Iteration 6507, loss = 0.00075730\n",
      "Iteration 6508, loss = 0.00075714\n",
      "Iteration 6509, loss = 0.00075699\n",
      "Iteration 6510, loss = 0.00075684\n",
      "Iteration 6511, loss = 0.00075670\n",
      "Iteration 6512, loss = 0.00075651\n",
      "Iteration 6513, loss = 0.00075636\n",
      "Iteration 6514, loss = 0.00075622\n",
      "Iteration 6515, loss = 0.00075607\n",
      "Iteration 6516, loss = 0.00075596\n",
      "Iteration 6517, loss = 0.00075580\n",
      "Iteration 6518, loss = 0.00075562\n",
      "Iteration 6519, loss = 0.00075545\n",
      "Iteration 6520, loss = 0.00075533\n",
      "Iteration 6521, loss = 0.00075518\n",
      "Iteration 6522, loss = 0.00075500\n",
      "Iteration 6523, loss = 0.00075489\n",
      "Iteration 6524, loss = 0.00075468\n",
      "Iteration 6525, loss = 0.00075455\n",
      "Iteration 6526, loss = 0.00075441\n",
      "Iteration 6527, loss = 0.00075424\n",
      "Iteration 6528, loss = 0.00075409\n",
      "Iteration 6529, loss = 0.00075396\n",
      "Iteration 6530, loss = 0.00075380\n",
      "Iteration 6531, loss = 0.00075363\n",
      "Iteration 6532, loss = 0.00075350\n",
      "Iteration 6533, loss = 0.00075340\n",
      "Iteration 6534, loss = 0.00075318\n",
      "Iteration 6535, loss = 0.00075302\n",
      "Iteration 6536, loss = 0.00075289\n",
      "Iteration 6537, loss = 0.00075273\n",
      "Iteration 6538, loss = 0.00075256\n",
      "Iteration 6539, loss = 0.00075242\n",
      "Iteration 6540, loss = 0.00075226\n",
      "Iteration 6541, loss = 0.00075213\n",
      "Iteration 6542, loss = 0.00075196\n",
      "Iteration 6543, loss = 0.00075183\n",
      "Iteration 6544, loss = 0.00075167\n",
      "Iteration 6545, loss = 0.00075156\n",
      "Iteration 6546, loss = 0.00075135\n",
      "Iteration 6547, loss = 0.00075119\n",
      "Iteration 6548, loss = 0.00075103\n",
      "Iteration 6549, loss = 0.00075089\n",
      "Iteration 6550, loss = 0.00075078\n",
      "Iteration 6551, loss = 0.00075059\n",
      "Iteration 6552, loss = 0.00075045\n",
      "Iteration 6553, loss = 0.00075028\n",
      "Iteration 6554, loss = 0.00075014\n",
      "Iteration 6555, loss = 0.00074998\n",
      "Iteration 6556, loss = 0.00074981\n",
      "Iteration 6557, loss = 0.00074971\n",
      "Iteration 6558, loss = 0.00074954\n",
      "Iteration 6559, loss = 0.00074937\n",
      "Iteration 6560, loss = 0.00074926\n",
      "Iteration 6561, loss = 0.00074911\n",
      "Iteration 6562, loss = 0.00074891\n",
      "Iteration 6563, loss = 0.00074879\n",
      "Iteration 6564, loss = 0.00074864\n",
      "Iteration 6565, loss = 0.00074848\n",
      "Iteration 6566, loss = 0.00074831\n",
      "Iteration 6567, loss = 0.00074820\n",
      "Iteration 6568, loss = 0.00074801\n",
      "Iteration 6569, loss = 0.00074786\n",
      "Iteration 6570, loss = 0.00074771\n",
      "Iteration 6571, loss = 0.00074757\n",
      "Iteration 6572, loss = 0.00074740\n",
      "Iteration 6573, loss = 0.00074725\n",
      "Iteration 6574, loss = 0.00074714\n",
      "Iteration 6575, loss = 0.00074697\n",
      "Iteration 6576, loss = 0.00074682\n",
      "Iteration 6577, loss = 0.00074666\n",
      "Iteration 6578, loss = 0.00074650\n",
      "Iteration 6579, loss = 0.00074635\n",
      "Iteration 6580, loss = 0.00074622\n",
      "Iteration 6581, loss = 0.00074604\n",
      "Iteration 6582, loss = 0.00074590\n",
      "Iteration 6583, loss = 0.00074575\n",
      "Iteration 6584, loss = 0.00074561\n",
      "Iteration 6585, loss = 0.00074544\n",
      "Iteration 6586, loss = 0.00074530\n",
      "Iteration 6587, loss = 0.00074515\n",
      "Iteration 6588, loss = 0.00074500\n",
      "Iteration 6589, loss = 0.00074485\n",
      "Iteration 6590, loss = 0.00074470\n",
      "Iteration 6591, loss = 0.00074454\n",
      "Iteration 6592, loss = 0.00074437\n",
      "Iteration 6593, loss = 0.00074425\n",
      "Iteration 6594, loss = 0.00074414\n",
      "Iteration 6595, loss = 0.00074395\n",
      "Iteration 6596, loss = 0.00074377\n",
      "Iteration 6597, loss = 0.00074363\n",
      "Iteration 6598, loss = 0.00074346\n",
      "Iteration 6599, loss = 0.00074329\n",
      "Iteration 6600, loss = 0.00074315\n",
      "Iteration 6601, loss = 0.00074299\n",
      "Iteration 6602, loss = 0.00074286\n",
      "Iteration 6603, loss = 0.00074267\n",
      "Iteration 6604, loss = 0.00074253\n",
      "Iteration 6605, loss = 0.00074237\n",
      "Iteration 6606, loss = 0.00074226\n",
      "Iteration 6607, loss = 0.00074209\n",
      "Iteration 6608, loss = 0.00074194\n",
      "Iteration 6609, loss = 0.00074179\n",
      "Iteration 6610, loss = 0.00074166\n",
      "Iteration 6611, loss = 0.00074150\n",
      "Iteration 6612, loss = 0.00074136\n",
      "Iteration 6613, loss = 0.00074121\n",
      "Iteration 6614, loss = 0.00074110\n",
      "Iteration 6615, loss = 0.00074091\n",
      "Iteration 6616, loss = 0.00074078\n",
      "Iteration 6617, loss = 0.00074061\n",
      "Iteration 6618, loss = 0.00074048\n",
      "Iteration 6619, loss = 0.00074031\n",
      "Iteration 6620, loss = 0.00074017\n",
      "Iteration 6621, loss = 0.00074001\n",
      "Iteration 6622, loss = 0.00073987\n",
      "Iteration 6623, loss = 0.00073972\n",
      "Iteration 6624, loss = 0.00073963\n",
      "Iteration 6625, loss = 0.00073943\n",
      "Iteration 6626, loss = 0.00073930\n",
      "Iteration 6627, loss = 0.00073914\n",
      "Iteration 6628, loss = 0.00073900\n",
      "Iteration 6629, loss = 0.00073886\n",
      "Iteration 6630, loss = 0.00073870\n",
      "Iteration 6631, loss = 0.00073855\n",
      "Iteration 6632, loss = 0.00073842\n",
      "Iteration 6633, loss = 0.00073826\n",
      "Iteration 6634, loss = 0.00073812\n",
      "Iteration 6635, loss = 0.00073798\n",
      "Iteration 6636, loss = 0.00073780\n",
      "Iteration 6637, loss = 0.00073766\n",
      "Iteration 6638, loss = 0.00073754\n",
      "Iteration 6639, loss = 0.00073739\n",
      "Iteration 6640, loss = 0.00073725\n",
      "Iteration 6641, loss = 0.00073708\n",
      "Iteration 6642, loss = 0.00073693\n",
      "Iteration 6643, loss = 0.00073679\n",
      "Iteration 6644, loss = 0.00073665\n",
      "Iteration 6645, loss = 0.00073650\n",
      "Iteration 6646, loss = 0.00073634\n",
      "Iteration 6647, loss = 0.00073623\n",
      "Iteration 6648, loss = 0.00073604\n",
      "Iteration 6649, loss = 0.00073592\n",
      "Iteration 6650, loss = 0.00073578\n",
      "Iteration 6651, loss = 0.00073563\n",
      "Iteration 6652, loss = 0.00073546\n",
      "Iteration 6653, loss = 0.00073532\n",
      "Iteration 6654, loss = 0.00073518\n",
      "Iteration 6655, loss = 0.00073503\n",
      "Iteration 6656, loss = 0.00073487\n",
      "Iteration 6657, loss = 0.00073472\n",
      "Iteration 6658, loss = 0.00073458\n",
      "Iteration 6659, loss = 0.00073443\n",
      "Iteration 6660, loss = 0.00073428\n",
      "Iteration 6661, loss = 0.00073411\n",
      "Iteration 6662, loss = 0.00073398\n",
      "Iteration 6663, loss = 0.00073384\n",
      "Iteration 6664, loss = 0.00073371\n",
      "Iteration 6665, loss = 0.00073354\n",
      "Iteration 6666, loss = 0.00073342\n",
      "Iteration 6667, loss = 0.00073338\n",
      "Iteration 6668, loss = 0.00073312\n",
      "Iteration 6669, loss = 0.00073297\n",
      "Iteration 6670, loss = 0.00073282\n",
      "Iteration 6671, loss = 0.00073272\n",
      "Iteration 6672, loss = 0.00073257\n",
      "Iteration 6673, loss = 0.00073240\n",
      "Iteration 6674, loss = 0.00073229\n",
      "Iteration 6675, loss = 0.00073213\n",
      "Iteration 6676, loss = 0.00073198\n",
      "Iteration 6677, loss = 0.00073185\n",
      "Iteration 6678, loss = 0.00073170\n",
      "Iteration 6679, loss = 0.00073155\n",
      "Iteration 6680, loss = 0.00073140\n",
      "Iteration 6681, loss = 0.00073128\n",
      "Iteration 6682, loss = 0.00073113\n",
      "Iteration 6683, loss = 0.00073098\n",
      "Iteration 6684, loss = 0.00073083\n",
      "Iteration 6685, loss = 0.00073068\n",
      "Iteration 6686, loss = 0.00073055\n",
      "Iteration 6687, loss = 0.00073040\n",
      "Iteration 6688, loss = 0.00073026\n",
      "Iteration 6689, loss = 0.00073014\n",
      "Iteration 6690, loss = 0.00072996\n",
      "Iteration 6691, loss = 0.00072984\n",
      "Iteration 6692, loss = 0.00072972\n",
      "Iteration 6693, loss = 0.00072951\n",
      "Iteration 6694, loss = 0.00072934\n",
      "Iteration 6695, loss = 0.00072924\n",
      "Iteration 6696, loss = 0.00072906\n",
      "Iteration 6697, loss = 0.00072892\n",
      "Iteration 6698, loss = 0.00072879\n",
      "Iteration 6699, loss = 0.00072862\n",
      "Iteration 6700, loss = 0.00072851\n",
      "Iteration 6701, loss = 0.00072834\n",
      "Iteration 6702, loss = 0.00072822\n",
      "Iteration 6703, loss = 0.00072806\n",
      "Iteration 6704, loss = 0.00072792\n",
      "Iteration 6705, loss = 0.00072780\n",
      "Iteration 6706, loss = 0.00072766\n",
      "Iteration 6707, loss = 0.00072753\n",
      "Iteration 6708, loss = 0.00072737\n",
      "Iteration 6709, loss = 0.00072726\n",
      "Iteration 6710, loss = 0.00072710\n",
      "Iteration 6711, loss = 0.00072696\n",
      "Iteration 6712, loss = 0.00072682\n",
      "Iteration 6713, loss = 0.00072667\n",
      "Iteration 6714, loss = 0.00072656\n",
      "Iteration 6715, loss = 0.00072639\n",
      "Iteration 6716, loss = 0.00072627\n",
      "Iteration 6717, loss = 0.00072611\n",
      "Iteration 6718, loss = 0.00072597\n",
      "Iteration 6719, loss = 0.00072582\n",
      "Iteration 6720, loss = 0.00072569\n",
      "Iteration 6721, loss = 0.00072558\n",
      "Iteration 6722, loss = 0.00072542\n",
      "Iteration 6723, loss = 0.00072528\n",
      "Iteration 6724, loss = 0.00072515\n",
      "Iteration 6725, loss = 0.00072500\n",
      "Iteration 6726, loss = 0.00072484\n",
      "Iteration 6727, loss = 0.00072472\n",
      "Iteration 6728, loss = 0.00072457\n",
      "Iteration 6729, loss = 0.00072445\n",
      "Iteration 6730, loss = 0.00072428\n",
      "Iteration 6731, loss = 0.00072414\n",
      "Iteration 6732, loss = 0.00072398\n",
      "Iteration 6733, loss = 0.00072385\n",
      "Iteration 6734, loss = 0.00072376\n",
      "Iteration 6735, loss = 0.00072358\n",
      "Iteration 6736, loss = 0.00072347\n",
      "Iteration 6737, loss = 0.00072328\n",
      "Iteration 6738, loss = 0.00072314\n",
      "Iteration 6739, loss = 0.00072305\n",
      "Iteration 6740, loss = 0.00072291\n",
      "Iteration 6741, loss = 0.00072273\n",
      "Iteration 6742, loss = 0.00072260\n",
      "Iteration 6743, loss = 0.00072248\n",
      "Iteration 6744, loss = 0.00072232\n",
      "Iteration 6745, loss = 0.00072217\n",
      "Iteration 6746, loss = 0.00072200\n",
      "Iteration 6747, loss = 0.00072189\n",
      "Iteration 6748, loss = 0.00072174\n",
      "Iteration 6749, loss = 0.00072159\n",
      "Iteration 6750, loss = 0.00072147\n",
      "Iteration 6751, loss = 0.00072132\n",
      "Iteration 6752, loss = 0.00072115\n",
      "Iteration 6753, loss = 0.00072100\n",
      "Iteration 6754, loss = 0.00072086\n",
      "Iteration 6755, loss = 0.00072074\n",
      "Iteration 6756, loss = 0.00072061\n",
      "Iteration 6757, loss = 0.00072046\n",
      "Iteration 6758, loss = 0.00072032\n",
      "Iteration 6759, loss = 0.00072017\n",
      "Iteration 6760, loss = 0.00072002\n",
      "Iteration 6761, loss = 0.00071989\n",
      "Iteration 6762, loss = 0.00071975\n",
      "Iteration 6763, loss = 0.00071960\n",
      "Iteration 6764, loss = 0.00071945\n",
      "Iteration 6765, loss = 0.00071935\n",
      "Iteration 6766, loss = 0.00071919\n",
      "Iteration 6767, loss = 0.00071905\n",
      "Iteration 6768, loss = 0.00071891\n",
      "Iteration 6769, loss = 0.00071882\n",
      "Iteration 6770, loss = 0.00071866\n",
      "Iteration 6771, loss = 0.00071853\n",
      "Iteration 6772, loss = 0.00071840\n",
      "Iteration 6773, loss = 0.00071824\n",
      "Iteration 6774, loss = 0.00071817\n",
      "Iteration 6775, loss = 0.00071796\n",
      "Iteration 6776, loss = 0.00071781\n",
      "Iteration 6777, loss = 0.00071767\n",
      "Iteration 6778, loss = 0.00071759\n",
      "Iteration 6779, loss = 0.00071741\n",
      "Iteration 6780, loss = 0.00071728\n",
      "Iteration 6781, loss = 0.00071710\n",
      "Iteration 6782, loss = 0.00071700\n",
      "Iteration 6783, loss = 0.00071689\n",
      "Iteration 6784, loss = 0.00071668\n",
      "Iteration 6785, loss = 0.00071654\n",
      "Iteration 6786, loss = 0.00071641\n",
      "Iteration 6787, loss = 0.00071627\n",
      "Iteration 6788, loss = 0.00071614\n",
      "Iteration 6789, loss = 0.00071598\n",
      "Iteration 6790, loss = 0.00071584\n",
      "Iteration 6791, loss = 0.00071570\n",
      "Iteration 6792, loss = 0.00071561\n",
      "Iteration 6793, loss = 0.00071544\n",
      "Iteration 6794, loss = 0.00071529\n",
      "Iteration 6795, loss = 0.00071514\n",
      "Iteration 6796, loss = 0.00071505\n",
      "Iteration 6797, loss = 0.00071492\n",
      "Iteration 6798, loss = 0.00071473\n",
      "Iteration 6799, loss = 0.00071461\n",
      "Iteration 6800, loss = 0.00071446\n",
      "Iteration 6801, loss = 0.00071435\n",
      "Iteration 6802, loss = 0.00071419\n",
      "Iteration 6803, loss = 0.00071406\n",
      "Iteration 6804, loss = 0.00071394\n",
      "Iteration 6805, loss = 0.00071380\n",
      "Iteration 6806, loss = 0.00071366\n",
      "Iteration 6807, loss = 0.00071357\n",
      "Iteration 6808, loss = 0.00071338\n",
      "Iteration 6809, loss = 0.00071322\n",
      "Iteration 6810, loss = 0.00071308\n",
      "Iteration 6811, loss = 0.00071296\n",
      "Iteration 6812, loss = 0.00071281\n",
      "Iteration 6813, loss = 0.00071267\n",
      "Iteration 6814, loss = 0.00071254\n",
      "Iteration 6815, loss = 0.00071242\n",
      "Iteration 6816, loss = 0.00071224\n",
      "Iteration 6817, loss = 0.00071210\n",
      "Iteration 6818, loss = 0.00071198\n",
      "Iteration 6819, loss = 0.00071183\n",
      "Iteration 6820, loss = 0.00071172\n",
      "Iteration 6821, loss = 0.00071155\n",
      "Iteration 6822, loss = 0.00071142\n",
      "Iteration 6823, loss = 0.00071131\n",
      "Iteration 6824, loss = 0.00071121\n",
      "Iteration 6825, loss = 0.00071102\n",
      "Iteration 6826, loss = 0.00071088\n",
      "Iteration 6827, loss = 0.00071075\n",
      "Iteration 6828, loss = 0.00071063\n",
      "Iteration 6829, loss = 0.00071049\n",
      "Iteration 6830, loss = 0.00071037\n",
      "Iteration 6831, loss = 0.00071020\n",
      "Iteration 6832, loss = 0.00071009\n",
      "Iteration 6833, loss = 0.00070992\n",
      "Iteration 6834, loss = 0.00070979\n",
      "Iteration 6835, loss = 0.00070968\n",
      "Iteration 6836, loss = 0.00070952\n",
      "Iteration 6837, loss = 0.00070938\n",
      "Iteration 6838, loss = 0.00070926\n",
      "Iteration 6839, loss = 0.00070909\n",
      "Iteration 6840, loss = 0.00070898\n",
      "Iteration 6841, loss = 0.00070884\n",
      "Iteration 6842, loss = 0.00070868\n",
      "Iteration 6843, loss = 0.00070855\n",
      "Iteration 6844, loss = 0.00070840\n",
      "Iteration 6845, loss = 0.00070830\n",
      "Iteration 6846, loss = 0.00070815\n",
      "Iteration 6847, loss = 0.00070802\n",
      "Iteration 6848, loss = 0.00070787\n",
      "Iteration 6849, loss = 0.00070773\n",
      "Iteration 6850, loss = 0.00070759\n",
      "Iteration 6851, loss = 0.00070746\n",
      "Iteration 6852, loss = 0.00070733\n",
      "Iteration 6853, loss = 0.00070720\n",
      "Iteration 6854, loss = 0.00070704\n",
      "Iteration 6855, loss = 0.00070691\n",
      "Iteration 6856, loss = 0.00070675\n",
      "Iteration 6857, loss = 0.00070662\n",
      "Iteration 6858, loss = 0.00070648\n",
      "Iteration 6859, loss = 0.00070636\n",
      "Iteration 6860, loss = 0.00070619\n",
      "Iteration 6861, loss = 0.00070606\n",
      "Iteration 6862, loss = 0.00070591\n",
      "Iteration 6863, loss = 0.00070581\n",
      "Iteration 6864, loss = 0.00070566\n",
      "Iteration 6865, loss = 0.00070551\n",
      "Iteration 6866, loss = 0.00070538\n",
      "Iteration 6867, loss = 0.00070523\n",
      "Iteration 6868, loss = 0.00070511\n",
      "Iteration 6869, loss = 0.00070496\n",
      "Iteration 6870, loss = 0.00070485\n",
      "Iteration 6871, loss = 0.00070470\n",
      "Iteration 6872, loss = 0.00070456\n",
      "Iteration 6873, loss = 0.00070442\n",
      "Iteration 6874, loss = 0.00070428\n",
      "Iteration 6875, loss = 0.00070414\n",
      "Iteration 6876, loss = 0.00070403\n",
      "Iteration 6877, loss = 0.00070389\n",
      "Iteration 6878, loss = 0.00070373\n",
      "Iteration 6879, loss = 0.00070361\n",
      "Iteration 6880, loss = 0.00070346\n",
      "Iteration 6881, loss = 0.00070333\n",
      "Iteration 6882, loss = 0.00070317\n",
      "Iteration 6883, loss = 0.00070306\n",
      "Iteration 6884, loss = 0.00070289\n",
      "Iteration 6885, loss = 0.00070276\n",
      "Iteration 6886, loss = 0.00070262\n",
      "Iteration 6887, loss = 0.00070248\n",
      "Iteration 6888, loss = 0.00070240\n",
      "Iteration 6889, loss = 0.00070222\n",
      "Iteration 6890, loss = 0.00070208\n",
      "Iteration 6891, loss = 0.00070195\n",
      "Iteration 6892, loss = 0.00070182\n",
      "Iteration 6893, loss = 0.00070168\n",
      "Iteration 6894, loss = 0.00070156\n",
      "Iteration 6895, loss = 0.00070143\n",
      "Iteration 6896, loss = 0.00070128\n",
      "Iteration 6897, loss = 0.00070116\n",
      "Iteration 6898, loss = 0.00070101\n",
      "Iteration 6899, loss = 0.00070088\n",
      "Iteration 6900, loss = 0.00070074\n",
      "Iteration 6901, loss = 0.00070061\n",
      "Iteration 6902, loss = 0.00070044\n",
      "Iteration 6903, loss = 0.00070030\n",
      "Iteration 6904, loss = 0.00070017\n",
      "Iteration 6905, loss = 0.00070006\n",
      "Iteration 6906, loss = 0.00069991\n",
      "Iteration 6907, loss = 0.00069978\n",
      "Iteration 6908, loss = 0.00069966\n",
      "Iteration 6909, loss = 0.00069952\n",
      "Iteration 6910, loss = 0.00069942\n",
      "Iteration 6911, loss = 0.00069923\n",
      "Iteration 6912, loss = 0.00069909\n",
      "Iteration 6913, loss = 0.00069894\n",
      "Iteration 6914, loss = 0.00069881\n",
      "Iteration 6915, loss = 0.00069869\n",
      "Iteration 6916, loss = 0.00069857\n",
      "Iteration 6917, loss = 0.00069843\n",
      "Iteration 6918, loss = 0.00069827\n",
      "Iteration 6919, loss = 0.00069816\n",
      "Iteration 6920, loss = 0.00069803\n",
      "Iteration 6921, loss = 0.00069786\n",
      "Iteration 6922, loss = 0.00069778\n",
      "Iteration 6923, loss = 0.00069763\n",
      "Iteration 6924, loss = 0.00069746\n",
      "Iteration 6925, loss = 0.00069733\n",
      "Iteration 6926, loss = 0.00069720\n",
      "Iteration 6927, loss = 0.00069706\n",
      "Iteration 6928, loss = 0.00069696\n",
      "Iteration 6929, loss = 0.00069678\n",
      "Iteration 6930, loss = 0.00069668\n",
      "Iteration 6931, loss = 0.00069654\n",
      "Iteration 6932, loss = 0.00069638\n",
      "Iteration 6933, loss = 0.00069626\n",
      "Iteration 6934, loss = 0.00069615\n",
      "Iteration 6935, loss = 0.00069601\n",
      "Iteration 6936, loss = 0.00069586\n",
      "Iteration 6937, loss = 0.00069572\n",
      "Iteration 6938, loss = 0.00069559\n",
      "Iteration 6939, loss = 0.00069549\n",
      "Iteration 6940, loss = 0.00069534\n",
      "Iteration 6941, loss = 0.00069522\n",
      "Iteration 6942, loss = 0.00069511\n",
      "Iteration 6943, loss = 0.00069495\n",
      "Iteration 6944, loss = 0.00069483\n",
      "Iteration 6945, loss = 0.00069469\n",
      "Iteration 6946, loss = 0.00069457\n",
      "Iteration 6947, loss = 0.00069444\n",
      "Iteration 6948, loss = 0.00069433\n",
      "Iteration 6949, loss = 0.00069417\n",
      "Iteration 6950, loss = 0.00069406\n",
      "Iteration 6951, loss = 0.00069394\n",
      "Iteration 6952, loss = 0.00069380\n",
      "Iteration 6953, loss = 0.00069368\n",
      "Iteration 6954, loss = 0.00069355\n",
      "Iteration 6955, loss = 0.00069340\n",
      "Iteration 6956, loss = 0.00069329\n",
      "Iteration 6957, loss = 0.00069316\n",
      "Iteration 6958, loss = 0.00069302\n",
      "Iteration 6959, loss = 0.00069290\n",
      "Iteration 6960, loss = 0.00069277\n",
      "Iteration 6961, loss = 0.00069263\n",
      "Iteration 6962, loss = 0.00069247\n",
      "Iteration 6963, loss = 0.00069236\n",
      "Iteration 6964, loss = 0.00069223\n",
      "Iteration 6965, loss = 0.00069211\n",
      "Iteration 6966, loss = 0.00069197\n",
      "Iteration 6967, loss = 0.00069183\n",
      "Iteration 6968, loss = 0.00069171\n",
      "Iteration 6969, loss = 0.00069162\n",
      "Iteration 6970, loss = 0.00069144\n",
      "Iteration 6971, loss = 0.00069131\n",
      "Iteration 6972, loss = 0.00069121\n",
      "Iteration 6973, loss = 0.00069103\n",
      "Iteration 6974, loss = 0.00069090\n",
      "Iteration 6975, loss = 0.00069077\n",
      "Iteration 6976, loss = 0.00069063\n",
      "Iteration 6977, loss = 0.00069054\n",
      "Iteration 6978, loss = 0.00069039\n",
      "Iteration 6979, loss = 0.00069027\n",
      "Iteration 6980, loss = 0.00069014\n",
      "Iteration 6981, loss = 0.00069001\n",
      "Iteration 6982, loss = 0.00068989\n",
      "Iteration 6983, loss = 0.00068978\n",
      "Iteration 6984, loss = 0.00068959\n",
      "Iteration 6985, loss = 0.00068948\n",
      "Iteration 6986, loss = 0.00068935\n",
      "Iteration 6987, loss = 0.00068921\n",
      "Iteration 6988, loss = 0.00068907\n",
      "Iteration 6989, loss = 0.00068897\n",
      "Iteration 6990, loss = 0.00068885\n",
      "Iteration 6991, loss = 0.00068868\n",
      "Iteration 6992, loss = 0.00068855\n",
      "Iteration 6993, loss = 0.00068843\n",
      "Iteration 6994, loss = 0.00068829\n",
      "Iteration 6995, loss = 0.00068815\n",
      "Iteration 6996, loss = 0.00068805\n",
      "Iteration 6997, loss = 0.00068791\n",
      "Iteration 6998, loss = 0.00068776\n",
      "Iteration 6999, loss = 0.00068762\n",
      "Iteration 7000, loss = 0.00068749\n",
      "Iteration 7001, loss = 0.00068737\n",
      "Iteration 7002, loss = 0.00068724\n",
      "Iteration 7003, loss = 0.00068711\n",
      "Iteration 7004, loss = 0.00068698\n",
      "Iteration 7005, loss = 0.00068685\n",
      "Iteration 7006, loss = 0.00068673\n",
      "Iteration 7007, loss = 0.00068659\n",
      "Iteration 7008, loss = 0.00068644\n",
      "Iteration 7009, loss = 0.00068632\n",
      "Iteration 7010, loss = 0.00068619\n",
      "Iteration 7011, loss = 0.00068604\n",
      "Iteration 7012, loss = 0.00068592\n",
      "Iteration 7013, loss = 0.00068581\n",
      "Iteration 7014, loss = 0.00068566\n",
      "Iteration 7015, loss = 0.00068555\n",
      "Iteration 7016, loss = 0.00068538\n",
      "Iteration 7017, loss = 0.00068526\n",
      "Iteration 7018, loss = 0.00068515\n",
      "Iteration 7019, loss = 0.00068500\n",
      "Iteration 7020, loss = 0.00068488\n",
      "Iteration 7021, loss = 0.00068473\n",
      "Iteration 7022, loss = 0.00068460\n",
      "Iteration 7023, loss = 0.00068448\n",
      "Iteration 7024, loss = 0.00068433\n",
      "Iteration 7025, loss = 0.00068421\n",
      "Iteration 7026, loss = 0.00068408\n",
      "Iteration 7027, loss = 0.00068393\n",
      "Iteration 7028, loss = 0.00068383\n",
      "Iteration 7029, loss = 0.00068369\n",
      "Iteration 7030, loss = 0.00068356\n",
      "Iteration 7031, loss = 0.00068342\n",
      "Iteration 7032, loss = 0.00068331\n",
      "Iteration 7033, loss = 0.00068317\n",
      "Iteration 7034, loss = 0.00068306\n",
      "Iteration 7035, loss = 0.00068290\n",
      "Iteration 7036, loss = 0.00068279\n",
      "Iteration 7037, loss = 0.00068265\n",
      "Iteration 7038, loss = 0.00068253\n",
      "Iteration 7039, loss = 0.00068239\n",
      "Iteration 7040, loss = 0.00068228\n",
      "Iteration 7041, loss = 0.00068217\n",
      "Iteration 7042, loss = 0.00068204\n",
      "Iteration 7043, loss = 0.00068189\n",
      "Iteration 7044, loss = 0.00068175\n",
      "Iteration 7045, loss = 0.00068162\n",
      "Iteration 7046, loss = 0.00068151\n",
      "Iteration 7047, loss = 0.00068136\n",
      "Iteration 7048, loss = 0.00068123\n",
      "Iteration 7049, loss = 0.00068110\n",
      "Iteration 7050, loss = 0.00068098\n",
      "Iteration 7051, loss = 0.00068084\n",
      "Iteration 7052, loss = 0.00068071\n",
      "Iteration 7053, loss = 0.00068060\n",
      "Iteration 7054, loss = 0.00068048\n",
      "Iteration 7055, loss = 0.00068033\n",
      "Iteration 7056, loss = 0.00068021\n",
      "Iteration 7057, loss = 0.00068009\n",
      "Iteration 7058, loss = 0.00067998\n",
      "Iteration 7059, loss = 0.00067984\n",
      "Iteration 7060, loss = 0.00067973\n",
      "Iteration 7061, loss = 0.00067959\n",
      "Iteration 7062, loss = 0.00067944\n",
      "Iteration 7063, loss = 0.00067933\n",
      "Iteration 7064, loss = 0.00067916\n",
      "Iteration 7065, loss = 0.00067908\n",
      "Iteration 7066, loss = 0.00067891\n",
      "Iteration 7067, loss = 0.00067878\n",
      "Iteration 7068, loss = 0.00067867\n",
      "Iteration 7069, loss = 0.00067853\n",
      "Iteration 7070, loss = 0.00067839\n",
      "Iteration 7071, loss = 0.00067827\n",
      "Iteration 7072, loss = 0.00067813\n",
      "Iteration 7073, loss = 0.00067801\n",
      "Iteration 7074, loss = 0.00067788\n",
      "Iteration 7075, loss = 0.00067776\n",
      "Iteration 7076, loss = 0.00067762\n",
      "Iteration 7077, loss = 0.00067749\n",
      "Iteration 7078, loss = 0.00067735\n",
      "Iteration 7079, loss = 0.00067722\n",
      "Iteration 7080, loss = 0.00067709\n",
      "Iteration 7081, loss = 0.00067696\n",
      "Iteration 7082, loss = 0.00067683\n",
      "Iteration 7083, loss = 0.00067670\n",
      "Iteration 7084, loss = 0.00067657\n",
      "Iteration 7085, loss = 0.00067645\n",
      "Iteration 7086, loss = 0.00067635\n",
      "Iteration 7087, loss = 0.00067617\n",
      "Iteration 7088, loss = 0.00067605\n",
      "Iteration 7089, loss = 0.00067594\n",
      "Iteration 7090, loss = 0.00067582\n",
      "Iteration 7091, loss = 0.00067568\n",
      "Iteration 7092, loss = 0.00067557\n",
      "Iteration 7093, loss = 0.00067543\n",
      "Iteration 7094, loss = 0.00067534\n",
      "Iteration 7095, loss = 0.00067516\n",
      "Iteration 7096, loss = 0.00067504\n",
      "Iteration 7097, loss = 0.00067493\n",
      "Iteration 7098, loss = 0.00067480\n",
      "Iteration 7099, loss = 0.00067465\n",
      "Iteration 7100, loss = 0.00067453\n",
      "Iteration 7101, loss = 0.00067442\n",
      "Iteration 7102, loss = 0.00067427\n",
      "Iteration 7103, loss = 0.00067415\n",
      "Iteration 7104, loss = 0.00067402\n",
      "Iteration 7105, loss = 0.00067390\n",
      "Iteration 7106, loss = 0.00067376\n",
      "Iteration 7107, loss = 0.00067365\n",
      "Iteration 7108, loss = 0.00067353\n",
      "Iteration 7109, loss = 0.00067340\n",
      "Iteration 7110, loss = 0.00067327\n",
      "Iteration 7111, loss = 0.00067314\n",
      "Iteration 7112, loss = 0.00067305\n",
      "Iteration 7113, loss = 0.00067289\n",
      "Iteration 7114, loss = 0.00067281\n",
      "Iteration 7115, loss = 0.00067265\n",
      "Iteration 7116, loss = 0.00067251\n",
      "Iteration 7117, loss = 0.00067241\n",
      "Iteration 7118, loss = 0.00067227\n",
      "Iteration 7119, loss = 0.00067214\n",
      "Iteration 7120, loss = 0.00067203\n",
      "Iteration 7121, loss = 0.00067189\n",
      "Iteration 7122, loss = 0.00067179\n",
      "Iteration 7123, loss = 0.00067165\n",
      "Iteration 7124, loss = 0.00067150\n",
      "Iteration 7125, loss = 0.00067143\n",
      "Iteration 7126, loss = 0.00067127\n",
      "Iteration 7127, loss = 0.00067113\n",
      "Iteration 7128, loss = 0.00067099\n",
      "Iteration 7129, loss = 0.00067088\n",
      "Iteration 7130, loss = 0.00067075\n",
      "Iteration 7131, loss = 0.00067061\n",
      "Iteration 7132, loss = 0.00067049\n",
      "Iteration 7133, loss = 0.00067037\n",
      "Iteration 7134, loss = 0.00067024\n",
      "Iteration 7135, loss = 0.00067014\n",
      "Iteration 7136, loss = 0.00067000\n",
      "Iteration 7137, loss = 0.00066986\n",
      "Iteration 7138, loss = 0.00066976\n",
      "Iteration 7139, loss = 0.00066964\n",
      "Iteration 7140, loss = 0.00066952\n",
      "Iteration 7141, loss = 0.00066939\n",
      "Iteration 7142, loss = 0.00066927\n",
      "Iteration 7143, loss = 0.00066910\n",
      "Iteration 7144, loss = 0.00066896\n",
      "Iteration 7145, loss = 0.00066884\n",
      "Iteration 7146, loss = 0.00066871\n",
      "Iteration 7147, loss = 0.00066859\n",
      "Iteration 7148, loss = 0.00066848\n",
      "Iteration 7149, loss = 0.00066835\n",
      "Iteration 7150, loss = 0.00066825\n",
      "Iteration 7151, loss = 0.00066810\n",
      "Iteration 7152, loss = 0.00066799\n",
      "Iteration 7153, loss = 0.00066785\n",
      "Iteration 7154, loss = 0.00066773\n",
      "Iteration 7155, loss = 0.00066761\n",
      "Iteration 7156, loss = 0.00066749\n",
      "Iteration 7157, loss = 0.00066737\n",
      "Iteration 7158, loss = 0.00066721\n",
      "Iteration 7159, loss = 0.00066714\n",
      "Iteration 7160, loss = 0.00066702\n",
      "Iteration 7161, loss = 0.00066683\n",
      "Iteration 7162, loss = 0.00066673\n",
      "Iteration 7163, loss = 0.00066659\n",
      "Iteration 7164, loss = 0.00066648\n",
      "Iteration 7165, loss = 0.00066635\n",
      "Iteration 7166, loss = 0.00066622\n",
      "Iteration 7167, loss = 0.00066609\n",
      "Iteration 7168, loss = 0.00066598\n",
      "Iteration 7169, loss = 0.00066586\n",
      "Iteration 7170, loss = 0.00066572\n",
      "Iteration 7171, loss = 0.00066560\n",
      "Iteration 7172, loss = 0.00066548\n",
      "Iteration 7173, loss = 0.00066536\n",
      "Iteration 7174, loss = 0.00066524\n",
      "Iteration 7175, loss = 0.00066511\n",
      "Iteration 7176, loss = 0.00066498\n",
      "Iteration 7177, loss = 0.00066485\n",
      "Iteration 7178, loss = 0.00066474\n",
      "Iteration 7179, loss = 0.00066465\n",
      "Iteration 7180, loss = 0.00066450\n",
      "Iteration 7181, loss = 0.00066436\n",
      "Iteration 7182, loss = 0.00066425\n",
      "Iteration 7183, loss = 0.00066412\n",
      "Iteration 7184, loss = 0.00066400\n",
      "Iteration 7185, loss = 0.00066389\n",
      "Iteration 7186, loss = 0.00066373\n",
      "Iteration 7187, loss = 0.00066362\n",
      "Iteration 7188, loss = 0.00066348\n",
      "Iteration 7189, loss = 0.00066335\n",
      "Iteration 7190, loss = 0.00066326\n",
      "Iteration 7191, loss = 0.00066311\n",
      "Iteration 7192, loss = 0.00066298\n",
      "Iteration 7193, loss = 0.00066288\n",
      "Iteration 7194, loss = 0.00066275\n",
      "Iteration 7195, loss = 0.00066262\n",
      "Iteration 7196, loss = 0.00066250\n",
      "Iteration 7197, loss = 0.00066237\n",
      "Iteration 7198, loss = 0.00066226\n",
      "Iteration 7199, loss = 0.00066212\n",
      "Iteration 7200, loss = 0.00066199\n",
      "Iteration 7201, loss = 0.00066190\n",
      "Iteration 7202, loss = 0.00066174\n",
      "Iteration 7203, loss = 0.00066163\n",
      "Iteration 7204, loss = 0.00066151\n",
      "Iteration 7205, loss = 0.00066137\n",
      "Iteration 7206, loss = 0.00066129\n",
      "Iteration 7207, loss = 0.00066116\n",
      "Iteration 7208, loss = 0.00066103\n",
      "Iteration 7209, loss = 0.00066087\n",
      "Iteration 7210, loss = 0.00066077\n",
      "Iteration 7211, loss = 0.00066066\n",
      "Iteration 7212, loss = 0.00066052\n",
      "Iteration 7213, loss = 0.00066040\n",
      "Iteration 7214, loss = 0.00066028\n",
      "Iteration 7215, loss = 0.00066016\n",
      "Iteration 7216, loss = 0.00066003\n",
      "Iteration 7217, loss = 0.00065992\n",
      "Iteration 7218, loss = 0.00065980\n",
      "Iteration 7219, loss = 0.00065968\n",
      "Iteration 7220, loss = 0.00065955\n",
      "Iteration 7221, loss = 0.00065941\n",
      "Iteration 7222, loss = 0.00065928\n",
      "Iteration 7223, loss = 0.00065916\n",
      "Iteration 7224, loss = 0.00065903\n",
      "Iteration 7225, loss = 0.00065891\n",
      "Iteration 7226, loss = 0.00065880\n",
      "Iteration 7227, loss = 0.00065867\n",
      "Iteration 7228, loss = 0.00065854\n",
      "Iteration 7229, loss = 0.00065844\n",
      "Iteration 7230, loss = 0.00065831\n",
      "Iteration 7231, loss = 0.00065819\n",
      "Iteration 7232, loss = 0.00065809\n",
      "Iteration 7233, loss = 0.00065794\n",
      "Iteration 7234, loss = 0.00065784\n",
      "Iteration 7235, loss = 0.00065770\n",
      "Iteration 7236, loss = 0.00065759\n",
      "Iteration 7237, loss = 0.00065746\n",
      "Iteration 7238, loss = 0.00065732\n",
      "Iteration 7239, loss = 0.00065727\n",
      "Iteration 7240, loss = 0.00065708\n",
      "Iteration 7241, loss = 0.00065699\n",
      "Iteration 7242, loss = 0.00065684\n",
      "Iteration 7243, loss = 0.00065672\n",
      "Iteration 7244, loss = 0.00065661\n",
      "Iteration 7245, loss = 0.00065646\n",
      "Iteration 7246, loss = 0.00065636\n",
      "Iteration 7247, loss = 0.00065625\n",
      "Iteration 7248, loss = 0.00065611\n",
      "Iteration 7249, loss = 0.00065601\n",
      "Iteration 7250, loss = 0.00065586\n",
      "Iteration 7251, loss = 0.00065575\n",
      "Iteration 7252, loss = 0.00065564\n",
      "Iteration 7253, loss = 0.00065552\n",
      "Iteration 7254, loss = 0.00065541\n",
      "Iteration 7255, loss = 0.00065527\n",
      "Iteration 7256, loss = 0.00065515\n",
      "Iteration 7257, loss = 0.00065503\n",
      "Iteration 7258, loss = 0.00065492\n",
      "Iteration 7259, loss = 0.00065479\n",
      "Iteration 7260, loss = 0.00065470\n",
      "Iteration 7261, loss = 0.00065457\n",
      "Iteration 7262, loss = 0.00065446\n",
      "Iteration 7263, loss = 0.00065431\n",
      "Iteration 7264, loss = 0.00065419\n",
      "Iteration 7265, loss = 0.00065408\n",
      "Iteration 7266, loss = 0.00065396\n",
      "Iteration 7267, loss = 0.00065383\n",
      "Iteration 7268, loss = 0.00065373\n",
      "Iteration 7269, loss = 0.00065361\n",
      "Iteration 7270, loss = 0.00065347\n",
      "Iteration 7271, loss = 0.00065334\n",
      "Iteration 7272, loss = 0.00065324\n",
      "Iteration 7273, loss = 0.00065313\n",
      "Iteration 7274, loss = 0.00065299\n",
      "Iteration 7275, loss = 0.00065287\n",
      "Iteration 7276, loss = 0.00065274\n",
      "Iteration 7277, loss = 0.00065264\n",
      "Iteration 7278, loss = 0.00065252\n",
      "Iteration 7279, loss = 0.00065242\n",
      "Iteration 7280, loss = 0.00065230\n",
      "Iteration 7281, loss = 0.00065216\n",
      "Iteration 7282, loss = 0.00065208\n",
      "Iteration 7283, loss = 0.00065193\n",
      "Iteration 7284, loss = 0.00065181\n",
      "Iteration 7285, loss = 0.00065169\n",
      "Iteration 7286, loss = 0.00065159\n",
      "Iteration 7287, loss = 0.00065148\n",
      "Iteration 7288, loss = 0.00065133\n",
      "Iteration 7289, loss = 0.00065121\n",
      "Iteration 7290, loss = 0.00065111\n",
      "Iteration 7291, loss = 0.00065099\n",
      "Iteration 7292, loss = 0.00065092\n",
      "Iteration 7293, loss = 0.00065073\n",
      "Iteration 7294, loss = 0.00065065\n",
      "Iteration 7295, loss = 0.00065052\n",
      "Iteration 7296, loss = 0.00065039\n",
      "Iteration 7297, loss = 0.00065028\n",
      "Iteration 7298, loss = 0.00065017\n",
      "Iteration 7299, loss = 0.00065007\n",
      "Iteration 7300, loss = 0.00064996\n",
      "Iteration 7301, loss = 0.00064983\n",
      "Iteration 7302, loss = 0.00064972\n",
      "Iteration 7303, loss = 0.00064958\n",
      "Iteration 7304, loss = 0.00064948\n",
      "Iteration 7305, loss = 0.00064936\n",
      "Iteration 7306, loss = 0.00064925\n",
      "Iteration 7307, loss = 0.00064913\n",
      "Iteration 7308, loss = 0.00064899\n",
      "Iteration 7309, loss = 0.00064889\n",
      "Iteration 7310, loss = 0.00064876\n",
      "Iteration 7311, loss = 0.00064865\n",
      "Iteration 7312, loss = 0.00064852\n",
      "Iteration 7313, loss = 0.00064839\n",
      "Iteration 7314, loss = 0.00064828\n",
      "Iteration 7315, loss = 0.00064818\n",
      "Iteration 7316, loss = 0.00064807\n",
      "Iteration 7317, loss = 0.00064792\n",
      "Iteration 7318, loss = 0.00064780\n",
      "Iteration 7319, loss = 0.00064768\n",
      "Iteration 7320, loss = 0.00064755\n",
      "Iteration 7321, loss = 0.00064745\n",
      "Iteration 7322, loss = 0.00064734\n",
      "Iteration 7323, loss = 0.00064720\n",
      "Iteration 7324, loss = 0.00064709\n",
      "Iteration 7325, loss = 0.00064696\n",
      "Iteration 7326, loss = 0.00064686\n",
      "Iteration 7327, loss = 0.00064672\n",
      "Iteration 7328, loss = 0.00064664\n",
      "Iteration 7329, loss = 0.00064648\n",
      "Iteration 7330, loss = 0.00064638\n",
      "Iteration 7331, loss = 0.00064625\n",
      "Iteration 7332, loss = 0.00064613\n",
      "Iteration 7333, loss = 0.00064603\n",
      "Iteration 7334, loss = 0.00064589\n",
      "Iteration 7335, loss = 0.00064579\n",
      "Iteration 7336, loss = 0.00064568\n",
      "Iteration 7337, loss = 0.00064555\n",
      "Iteration 7338, loss = 0.00064544\n",
      "Iteration 7339, loss = 0.00064533\n",
      "Iteration 7340, loss = 0.00064519\n",
      "Iteration 7341, loss = 0.00064509\n",
      "Iteration 7342, loss = 0.00064496\n",
      "Iteration 7343, loss = 0.00064487\n",
      "Iteration 7344, loss = 0.00064473\n",
      "Iteration 7345, loss = 0.00064463\n",
      "Iteration 7346, loss = 0.00064450\n",
      "Iteration 7347, loss = 0.00064439\n",
      "Iteration 7348, loss = 0.00064430\n",
      "Iteration 7349, loss = 0.00064416\n",
      "Iteration 7350, loss = 0.00064403\n",
      "Iteration 7351, loss = 0.00064391\n",
      "Iteration 7352, loss = 0.00064381\n",
      "Iteration 7353, loss = 0.00064369\n",
      "Iteration 7354, loss = 0.00064358\n",
      "Iteration 7355, loss = 0.00064348\n",
      "Iteration 7356, loss = 0.00064338\n",
      "Iteration 7357, loss = 0.00064323\n",
      "Iteration 7358, loss = 0.00064314\n",
      "Iteration 7359, loss = 0.00064301\n",
      "Iteration 7360, loss = 0.00064288\n",
      "Iteration 7361, loss = 0.00064277\n",
      "Iteration 7362, loss = 0.00064265\n",
      "Iteration 7363, loss = 0.00064253\n",
      "Iteration 7364, loss = 0.00064242\n",
      "Iteration 7365, loss = 0.00064228\n",
      "Iteration 7366, loss = 0.00064216\n",
      "Iteration 7367, loss = 0.00064207\n",
      "Iteration 7368, loss = 0.00064195\n",
      "Iteration 7369, loss = 0.00064183\n",
      "Iteration 7370, loss = 0.00064172\n",
      "Iteration 7371, loss = 0.00064160\n",
      "Iteration 7372, loss = 0.00064147\n",
      "Iteration 7373, loss = 0.00064135\n",
      "Iteration 7374, loss = 0.00064123\n",
      "Iteration 7375, loss = 0.00064113\n",
      "Iteration 7376, loss = 0.00064100\n",
      "Iteration 7377, loss = 0.00064088\n",
      "Iteration 7378, loss = 0.00064079\n",
      "Iteration 7379, loss = 0.00064067\n",
      "Iteration 7380, loss = 0.00064052\n",
      "Iteration 7381, loss = 0.00064041\n",
      "Iteration 7382, loss = 0.00064030\n",
      "Iteration 7383, loss = 0.00064019\n",
      "Iteration 7384, loss = 0.00064007\n",
      "Iteration 7385, loss = 0.00063994\n",
      "Iteration 7386, loss = 0.00063985\n",
      "Iteration 7387, loss = 0.00063975\n",
      "Iteration 7388, loss = 0.00063961\n",
      "Iteration 7389, loss = 0.00063949\n",
      "Iteration 7390, loss = 0.00063938\n",
      "Iteration 7391, loss = 0.00063928\n",
      "Iteration 7392, loss = 0.00063918\n",
      "Iteration 7393, loss = 0.00063905\n",
      "Iteration 7394, loss = 0.00063895\n",
      "Iteration 7395, loss = 0.00063884\n",
      "Iteration 7396, loss = 0.00063871\n",
      "Iteration 7397, loss = 0.00063859\n",
      "Iteration 7398, loss = 0.00063849\n",
      "Iteration 7399, loss = 0.00063836\n",
      "Iteration 7400, loss = 0.00063825\n",
      "Iteration 7401, loss = 0.00063814\n",
      "Iteration 7402, loss = 0.00063800\n",
      "Iteration 7403, loss = 0.00063791\n",
      "Iteration 7404, loss = 0.00063777\n",
      "Iteration 7405, loss = 0.00063769\n",
      "Iteration 7406, loss = 0.00063755\n",
      "Iteration 7407, loss = 0.00063745\n",
      "Iteration 7408, loss = 0.00063735\n",
      "Iteration 7409, loss = 0.00063721\n",
      "Iteration 7410, loss = 0.00063711\n",
      "Iteration 7411, loss = 0.00063700\n",
      "Iteration 7412, loss = 0.00063691\n",
      "Iteration 7413, loss = 0.00063676\n",
      "Iteration 7414, loss = 0.00063665\n",
      "Iteration 7415, loss = 0.00063655\n",
      "Iteration 7416, loss = 0.00063643\n",
      "Iteration 7417, loss = 0.00063631\n",
      "Iteration 7418, loss = 0.00063620\n",
      "Iteration 7419, loss = 0.00063612\n",
      "Iteration 7420, loss = 0.00063601\n",
      "Iteration 7421, loss = 0.00063589\n",
      "Iteration 7422, loss = 0.00063577\n",
      "Iteration 7423, loss = 0.00063565\n",
      "Iteration 7424, loss = 0.00063554\n",
      "Iteration 7425, loss = 0.00063543\n",
      "Iteration 7426, loss = 0.00063531\n",
      "Iteration 7427, loss = 0.00063520\n",
      "Iteration 7428, loss = 0.00063508\n",
      "Iteration 7429, loss = 0.00063496\n",
      "Iteration 7430, loss = 0.00063485\n",
      "Iteration 7431, loss = 0.00063474\n",
      "Iteration 7432, loss = 0.00063465\n",
      "Iteration 7433, loss = 0.00063453\n",
      "Iteration 7434, loss = 0.00063441\n",
      "Iteration 7435, loss = 0.00063431\n",
      "Iteration 7436, loss = 0.00063421\n",
      "Iteration 7437, loss = 0.00063409\n",
      "Iteration 7438, loss = 0.00063398\n",
      "Iteration 7439, loss = 0.00063387\n",
      "Iteration 7440, loss = 0.00063375\n",
      "Iteration 7441, loss = 0.00063364\n",
      "Iteration 7442, loss = 0.00063355\n",
      "Iteration 7443, loss = 0.00063342\n",
      "Iteration 7444, loss = 0.00063332\n",
      "Iteration 7445, loss = 0.00063322\n",
      "Iteration 7446, loss = 0.00063309\n",
      "Iteration 7447, loss = 0.00063297\n",
      "Iteration 7448, loss = 0.00063285\n",
      "Iteration 7449, loss = 0.00063280\n",
      "Iteration 7450, loss = 0.00063262\n",
      "Iteration 7451, loss = 0.00063255\n",
      "Iteration 7452, loss = 0.00063241\n",
      "Iteration 7453, loss = 0.00063228\n",
      "Iteration 7454, loss = 0.00063218\n",
      "Iteration 7455, loss = 0.00063206\n",
      "Iteration 7456, loss = 0.00063198\n",
      "Iteration 7457, loss = 0.00063185\n",
      "Iteration 7458, loss = 0.00063175\n",
      "Iteration 7459, loss = 0.00063162\n",
      "Iteration 7460, loss = 0.00063153\n",
      "Iteration 7461, loss = 0.00063142\n",
      "Iteration 7462, loss = 0.00063128\n",
      "Iteration 7463, loss = 0.00063119\n",
      "Iteration 7464, loss = 0.00063106\n",
      "Iteration 7465, loss = 0.00063094\n",
      "Iteration 7466, loss = 0.00063084\n",
      "Iteration 7467, loss = 0.00063075\n",
      "Iteration 7468, loss = 0.00063061\n",
      "Iteration 7469, loss = 0.00063052\n",
      "Iteration 7470, loss = 0.00063042\n",
      "Iteration 7471, loss = 0.00063030\n",
      "Iteration 7472, loss = 0.00063016\n",
      "Iteration 7473, loss = 0.00063007\n",
      "Iteration 7474, loss = 0.00062995\n",
      "Iteration 7475, loss = 0.00062984\n",
      "Iteration 7476, loss = 0.00062975\n",
      "Iteration 7477, loss = 0.00062961\n",
      "Iteration 7478, loss = 0.00062951\n",
      "Iteration 7479, loss = 0.00062941\n",
      "Iteration 7480, loss = 0.00062929\n",
      "Iteration 7481, loss = 0.00062916\n",
      "Iteration 7482, loss = 0.00062907\n",
      "Iteration 7483, loss = 0.00062893\n",
      "Iteration 7484, loss = 0.00062883\n",
      "Iteration 7485, loss = 0.00062872\n",
      "Iteration 7486, loss = 0.00062863\n",
      "Iteration 7487, loss = 0.00062850\n",
      "Iteration 7488, loss = 0.00062838\n",
      "Iteration 7489, loss = 0.00062827\n",
      "Iteration 7490, loss = 0.00062818\n",
      "Iteration 7491, loss = 0.00062807\n",
      "Iteration 7492, loss = 0.00062795\n",
      "Iteration 7493, loss = 0.00062783\n",
      "Iteration 7494, loss = 0.00062775\n",
      "Iteration 7495, loss = 0.00062761\n",
      "Iteration 7496, loss = 0.00062758\n",
      "Iteration 7497, loss = 0.00062738\n",
      "Iteration 7498, loss = 0.00062728\n",
      "Iteration 7499, loss = 0.00062716\n",
      "Iteration 7500, loss = 0.00062707\n",
      "Iteration 7501, loss = 0.00062696\n",
      "Iteration 7502, loss = 0.00062685\n",
      "Iteration 7503, loss = 0.00062682\n",
      "Iteration 7504, loss = 0.00062662\n",
      "Iteration 7505, loss = 0.00062651\n",
      "Iteration 7506, loss = 0.00062639\n",
      "Iteration 7507, loss = 0.00062630\n",
      "Iteration 7508, loss = 0.00062619\n",
      "Iteration 7509, loss = 0.00062610\n",
      "Iteration 7510, loss = 0.00062597\n",
      "Iteration 7511, loss = 0.00062588\n",
      "Iteration 7512, loss = 0.00062575\n",
      "Iteration 7513, loss = 0.00062565\n",
      "Iteration 7514, loss = 0.00062554\n",
      "Iteration 7515, loss = 0.00062542\n",
      "Iteration 7516, loss = 0.00062533\n",
      "Iteration 7517, loss = 0.00062522\n",
      "Iteration 7518, loss = 0.00062510\n",
      "Iteration 7519, loss = 0.00062499\n",
      "Iteration 7520, loss = 0.00062487\n",
      "Iteration 7521, loss = 0.00062476\n",
      "Iteration 7522, loss = 0.00062465\n",
      "Iteration 7523, loss = 0.00062455\n",
      "Iteration 7524, loss = 0.00062446\n",
      "Iteration 7525, loss = 0.00062432\n",
      "Iteration 7526, loss = 0.00062422\n",
      "Iteration 7527, loss = 0.00062412\n",
      "Iteration 7528, loss = 0.00062400\n",
      "Iteration 7529, loss = 0.00062389\n",
      "Iteration 7530, loss = 0.00062378\n",
      "Iteration 7531, loss = 0.00062366\n",
      "Iteration 7532, loss = 0.00062357\n",
      "Iteration 7533, loss = 0.00062346\n",
      "Iteration 7534, loss = 0.00062336\n",
      "Iteration 7535, loss = 0.00062325\n",
      "Iteration 7536, loss = 0.00062315\n",
      "Iteration 7537, loss = 0.00062302\n",
      "Iteration 7538, loss = 0.00062293\n",
      "Iteration 7539, loss = 0.00062281\n",
      "Iteration 7540, loss = 0.00062271\n",
      "Iteration 7541, loss = 0.00062260\n",
      "Iteration 7542, loss = 0.00062248\n",
      "Iteration 7543, loss = 0.00062240\n",
      "Iteration 7544, loss = 0.00062230\n",
      "Iteration 7545, loss = 0.00062218\n",
      "Iteration 7546, loss = 0.00062208\n",
      "Iteration 7547, loss = 0.00062197\n",
      "Iteration 7548, loss = 0.00062184\n",
      "Iteration 7549, loss = 0.00062182\n",
      "Iteration 7550, loss = 0.00062163\n",
      "Iteration 7551, loss = 0.00062153\n",
      "Iteration 7552, loss = 0.00062143\n",
      "Iteration 7553, loss = 0.00062131\n",
      "Iteration 7554, loss = 0.00062123\n",
      "Iteration 7555, loss = 0.00062110\n",
      "Iteration 7556, loss = 0.00062101\n",
      "Iteration 7557, loss = 0.00062089\n",
      "Iteration 7558, loss = 0.00062079\n",
      "Iteration 7559, loss = 0.00062067\n",
      "Iteration 7560, loss = 0.00062056\n",
      "Iteration 7561, loss = 0.00062045\n",
      "Iteration 7562, loss = 0.00062035\n",
      "Iteration 7563, loss = 0.00062024\n",
      "Iteration 7564, loss = 0.00062015\n",
      "Iteration 7565, loss = 0.00062005\n",
      "Iteration 7566, loss = 0.00061992\n",
      "Iteration 7567, loss = 0.00061982\n",
      "Iteration 7568, loss = 0.00061970\n",
      "Iteration 7569, loss = 0.00061962\n",
      "Iteration 7570, loss = 0.00061949\n",
      "Iteration 7571, loss = 0.00061937\n",
      "Iteration 7572, loss = 0.00061926\n",
      "Iteration 7573, loss = 0.00061915\n",
      "Iteration 7574, loss = 0.00061905\n",
      "Iteration 7575, loss = 0.00061893\n",
      "Iteration 7576, loss = 0.00061882\n",
      "Iteration 7577, loss = 0.00061871\n",
      "Iteration 7578, loss = 0.00061859\n",
      "Iteration 7579, loss = 0.00061850\n",
      "Iteration 7580, loss = 0.00061837\n",
      "Iteration 7581, loss = 0.00061828\n",
      "Iteration 7582, loss = 0.00061824\n",
      "Iteration 7583, loss = 0.00061808\n",
      "Iteration 7584, loss = 0.00061794\n",
      "Iteration 7585, loss = 0.00061782\n",
      "Iteration 7586, loss = 0.00061773\n",
      "Iteration 7587, loss = 0.00061760\n",
      "Iteration 7588, loss = 0.00061750\n",
      "Iteration 7589, loss = 0.00061738\n",
      "Iteration 7590, loss = 0.00061729\n",
      "Iteration 7591, loss = 0.00061719\n",
      "Iteration 7592, loss = 0.00061709\n",
      "Iteration 7593, loss = 0.00061697\n",
      "Iteration 7594, loss = 0.00061689\n",
      "Iteration 7595, loss = 0.00061676\n",
      "Iteration 7596, loss = 0.00061666\n",
      "Iteration 7597, loss = 0.00061655\n",
      "Iteration 7598, loss = 0.00061645\n",
      "Iteration 7599, loss = 0.00061634\n",
      "Iteration 7600, loss = 0.00061625\n",
      "Iteration 7601, loss = 0.00061616\n",
      "Iteration 7602, loss = 0.00061606\n",
      "Iteration 7603, loss = 0.00061593\n",
      "Iteration 7604, loss = 0.00061581\n",
      "Iteration 7605, loss = 0.00061572\n",
      "Iteration 7606, loss = 0.00061560\n",
      "Iteration 7607, loss = 0.00061550\n",
      "Iteration 7608, loss = 0.00061540\n",
      "Iteration 7609, loss = 0.00061530\n",
      "Iteration 7610, loss = 0.00061518\n",
      "Iteration 7611, loss = 0.00061508\n",
      "Iteration 7612, loss = 0.00061496\n",
      "Iteration 7613, loss = 0.00061486\n",
      "Iteration 7614, loss = 0.00061474\n",
      "Iteration 7615, loss = 0.00061464\n",
      "Iteration 7616, loss = 0.00061455\n",
      "Iteration 7617, loss = 0.00061444\n",
      "Iteration 7618, loss = 0.00061433\n",
      "Iteration 7619, loss = 0.00061423\n",
      "Iteration 7620, loss = 0.00061412\n",
      "Iteration 7621, loss = 0.00061402\n",
      "Iteration 7622, loss = 0.00061393\n",
      "Iteration 7623, loss = 0.00061379\n",
      "Iteration 7624, loss = 0.00061371\n",
      "Iteration 7625, loss = 0.00061361\n",
      "Iteration 7626, loss = 0.00061350\n",
      "Iteration 7627, loss = 0.00061339\n",
      "Iteration 7628, loss = 0.00061328\n",
      "Iteration 7629, loss = 0.00061318\n",
      "Iteration 7630, loss = 0.00061306\n",
      "Iteration 7631, loss = 0.00061295\n",
      "Iteration 7632, loss = 0.00061283\n",
      "Iteration 7633, loss = 0.00061274\n",
      "Iteration 7634, loss = 0.00061264\n",
      "Iteration 7635, loss = 0.00061252\n",
      "Iteration 7636, loss = 0.00061243\n",
      "Iteration 7637, loss = 0.00061234\n",
      "Iteration 7638, loss = 0.00061222\n",
      "Iteration 7639, loss = 0.00061212\n",
      "Iteration 7640, loss = 0.00061200\n",
      "Iteration 7641, loss = 0.00061191\n",
      "Iteration 7642, loss = 0.00061180\n",
      "Iteration 7643, loss = 0.00061169\n",
      "Iteration 7644, loss = 0.00061158\n",
      "Iteration 7645, loss = 0.00061151\n",
      "Iteration 7646, loss = 0.00061138\n",
      "Iteration 7647, loss = 0.00061130\n",
      "Iteration 7648, loss = 0.00061117\n",
      "Iteration 7649, loss = 0.00061108\n",
      "Iteration 7650, loss = 0.00061098\n",
      "Iteration 7651, loss = 0.00061090\n",
      "Iteration 7652, loss = 0.00061076\n",
      "Iteration 7653, loss = 0.00061066\n",
      "Iteration 7654, loss = 0.00061060\n",
      "Iteration 7655, loss = 0.00061045\n",
      "Iteration 7656, loss = 0.00061033\n",
      "Iteration 7657, loss = 0.00061029\n",
      "Iteration 7658, loss = 0.00061013\n",
      "Iteration 7659, loss = 0.00061004\n",
      "Iteration 7660, loss = 0.00060994\n",
      "Iteration 7661, loss = 0.00060982\n",
      "Iteration 7662, loss = 0.00060973\n",
      "Iteration 7663, loss = 0.00060961\n",
      "Iteration 7664, loss = 0.00060950\n",
      "Iteration 7665, loss = 0.00060942\n",
      "Iteration 7666, loss = 0.00060930\n",
      "Iteration 7667, loss = 0.00060920\n",
      "Iteration 7668, loss = 0.00060909\n",
      "Iteration 7669, loss = 0.00060898\n",
      "Iteration 7670, loss = 0.00060889\n",
      "Iteration 7671, loss = 0.00060878\n",
      "Iteration 7672, loss = 0.00060868\n",
      "Iteration 7673, loss = 0.00060858\n",
      "Iteration 7674, loss = 0.00060848\n",
      "Iteration 7675, loss = 0.00060838\n",
      "Iteration 7676, loss = 0.00060826\n",
      "Iteration 7677, loss = 0.00060814\n",
      "Iteration 7678, loss = 0.00060804\n",
      "Iteration 7679, loss = 0.00060797\n",
      "Iteration 7680, loss = 0.00060784\n",
      "Iteration 7681, loss = 0.00060774\n",
      "Iteration 7682, loss = 0.00060764\n",
      "Iteration 7683, loss = 0.00060753\n",
      "Iteration 7684, loss = 0.00060743\n",
      "Iteration 7685, loss = 0.00060733\n",
      "Iteration 7686, loss = 0.00060724\n",
      "Iteration 7687, loss = 0.00060714\n",
      "Iteration 7688, loss = 0.00060703\n",
      "Iteration 7689, loss = 0.00060692\n",
      "Iteration 7690, loss = 0.00060683\n",
      "Iteration 7691, loss = 0.00060672\n",
      "Iteration 7692, loss = 0.00060665\n",
      "Iteration 7693, loss = 0.00060654\n",
      "Iteration 7694, loss = 0.00060640\n",
      "Iteration 7695, loss = 0.00060631\n",
      "Iteration 7696, loss = 0.00060620\n",
      "Iteration 7697, loss = 0.00060609\n",
      "Iteration 7698, loss = 0.00060600\n",
      "Iteration 7699, loss = 0.00060591\n",
      "Iteration 7700, loss = 0.00060581\n",
      "Iteration 7701, loss = 0.00060570\n",
      "Iteration 7702, loss = 0.00060558\n",
      "Iteration 7703, loss = 0.00060550\n",
      "Iteration 7704, loss = 0.00060540\n",
      "Iteration 7705, loss = 0.00060528\n",
      "Iteration 7706, loss = 0.00060520\n",
      "Iteration 7707, loss = 0.00060508\n",
      "Iteration 7708, loss = 0.00060499\n",
      "Iteration 7709, loss = 0.00060488\n",
      "Iteration 7710, loss = 0.00060477\n",
      "Iteration 7711, loss = 0.00060468\n",
      "Iteration 7712, loss = 0.00060458\n",
      "Iteration 7713, loss = 0.00060448\n",
      "Iteration 7714, loss = 0.00060440\n",
      "Iteration 7715, loss = 0.00060429\n",
      "Iteration 7716, loss = 0.00060417\n",
      "Iteration 7717, loss = 0.00060408\n",
      "Iteration 7718, loss = 0.00060397\n",
      "Iteration 7719, loss = 0.00060386\n",
      "Iteration 7720, loss = 0.00060376\n",
      "Iteration 7721, loss = 0.00060366\n",
      "Iteration 7722, loss = 0.00060356\n",
      "Iteration 7723, loss = 0.00060345\n",
      "Iteration 7724, loss = 0.00060337\n",
      "Iteration 7725, loss = 0.00060325\n",
      "Iteration 7726, loss = 0.00060317\n",
      "Iteration 7727, loss = 0.00060303\n",
      "Iteration 7728, loss = 0.00060297\n",
      "Iteration 7729, loss = 0.00060284\n",
      "Iteration 7730, loss = 0.00060274\n",
      "Iteration 7731, loss = 0.00060264\n",
      "Iteration 7732, loss = 0.00060253\n",
      "Iteration 7733, loss = 0.00060243\n",
      "Iteration 7734, loss = 0.00060232\n",
      "Iteration 7735, loss = 0.00060221\n",
      "Iteration 7736, loss = 0.00060212\n",
      "Iteration 7737, loss = 0.00060203\n",
      "Iteration 7738, loss = 0.00060190\n",
      "Iteration 7739, loss = 0.00060181\n",
      "Iteration 7740, loss = 0.00060169\n",
      "Iteration 7741, loss = 0.00060161\n",
      "Iteration 7742, loss = 0.00060150\n",
      "Iteration 7743, loss = 0.00060140\n",
      "Iteration 7744, loss = 0.00060129\n",
      "Iteration 7745, loss = 0.00060119\n",
      "Iteration 7746, loss = 0.00060109\n",
      "Iteration 7747, loss = 0.00060099\n",
      "Iteration 7748, loss = 0.00060089\n",
      "Iteration 7749, loss = 0.00060078\n",
      "Iteration 7750, loss = 0.00060068\n",
      "Iteration 7751, loss = 0.00060058\n",
      "Iteration 7752, loss = 0.00060048\n",
      "Iteration 7753, loss = 0.00060038\n",
      "Iteration 7754, loss = 0.00060028\n",
      "Iteration 7755, loss = 0.00060018\n",
      "Iteration 7756, loss = 0.00060007\n",
      "Iteration 7757, loss = 0.00059998\n",
      "Iteration 7758, loss = 0.00059989\n",
      "Iteration 7759, loss = 0.00059978\n",
      "Iteration 7760, loss = 0.00059968\n",
      "Iteration 7761, loss = 0.00059958\n",
      "Iteration 7762, loss = 0.00059948\n",
      "Iteration 7763, loss = 0.00059939\n",
      "Iteration 7764, loss = 0.00059927\n",
      "Iteration 7765, loss = 0.00059918\n",
      "Iteration 7766, loss = 0.00059908\n",
      "Iteration 7767, loss = 0.00059898\n",
      "Iteration 7768, loss = 0.00059886\n",
      "Iteration 7769, loss = 0.00059876\n",
      "Iteration 7770, loss = 0.00059867\n",
      "Iteration 7771, loss = 0.00059855\n",
      "Iteration 7772, loss = 0.00059847\n",
      "Iteration 7773, loss = 0.00059840\n",
      "Iteration 7774, loss = 0.00059825\n",
      "Iteration 7775, loss = 0.00059814\n",
      "Iteration 7776, loss = 0.00059806\n",
      "Iteration 7777, loss = 0.00059795\n",
      "Iteration 7778, loss = 0.00059788\n",
      "Iteration 7779, loss = 0.00059776\n",
      "Iteration 7780, loss = 0.00059766\n",
      "Iteration 7781, loss = 0.00059755\n",
      "Iteration 7782, loss = 0.00059743\n",
      "Iteration 7783, loss = 0.00059733\n",
      "Iteration 7784, loss = 0.00059724\n",
      "Iteration 7785, loss = 0.00059716\n",
      "Iteration 7786, loss = 0.00059703\n",
      "Iteration 7787, loss = 0.00059693\n",
      "Iteration 7788, loss = 0.00059681\n",
      "Iteration 7789, loss = 0.00059671\n",
      "Iteration 7790, loss = 0.00059662\n",
      "Iteration 7791, loss = 0.00059650\n",
      "Iteration 7792, loss = 0.00059641\n",
      "Iteration 7793, loss = 0.00059634\n",
      "Iteration 7794, loss = 0.00059621\n",
      "Iteration 7795, loss = 0.00059611\n",
      "Iteration 7796, loss = 0.00059600\n",
      "Iteration 7797, loss = 0.00059590\n",
      "Iteration 7798, loss = 0.00059584\n",
      "Iteration 7799, loss = 0.00059571\n",
      "Iteration 7800, loss = 0.00059563\n",
      "Iteration 7801, loss = 0.00059550\n",
      "Iteration 7802, loss = 0.00059540\n",
      "Iteration 7803, loss = 0.00059532\n",
      "Iteration 7804, loss = 0.00059522\n",
      "Iteration 7805, loss = 0.00059511\n",
      "Iteration 7806, loss = 0.00059501\n",
      "Iteration 7807, loss = 0.00059492\n",
      "Iteration 7808, loss = 0.00059484\n",
      "Iteration 7809, loss = 0.00059472\n",
      "Iteration 7810, loss = 0.00059462\n",
      "Iteration 7811, loss = 0.00059451\n",
      "Iteration 7812, loss = 0.00059444\n",
      "Iteration 7813, loss = 0.00059432\n",
      "Iteration 7814, loss = 0.00059424\n",
      "Iteration 7815, loss = 0.00059413\n",
      "Iteration 7816, loss = 0.00059403\n",
      "Iteration 7817, loss = 0.00059393\n",
      "Iteration 7818, loss = 0.00059382\n",
      "Iteration 7819, loss = 0.00059373\n",
      "Iteration 7820, loss = 0.00059362\n",
      "Iteration 7821, loss = 0.00059352\n",
      "Iteration 7822, loss = 0.00059343\n",
      "Iteration 7823, loss = 0.00059334\n",
      "Iteration 7824, loss = 0.00059322\n",
      "Iteration 7825, loss = 0.00059312\n",
      "Iteration 7826, loss = 0.00059302\n",
      "Iteration 7827, loss = 0.00059292\n",
      "Iteration 7828, loss = 0.00059283\n",
      "Iteration 7829, loss = 0.00059272\n",
      "Iteration 7830, loss = 0.00059263\n",
      "Iteration 7831, loss = 0.00059253\n",
      "Iteration 7832, loss = 0.00059243\n",
      "Iteration 7833, loss = 0.00059233\n",
      "Iteration 7834, loss = 0.00059225\n",
      "Iteration 7835, loss = 0.00059216\n",
      "Iteration 7836, loss = 0.00059204\n",
      "Iteration 7837, loss = 0.00059195\n",
      "Iteration 7838, loss = 0.00059184\n",
      "Iteration 7839, loss = 0.00059173\n",
      "Iteration 7840, loss = 0.00059163\n",
      "Iteration 7841, loss = 0.00059156\n",
      "Iteration 7842, loss = 0.00059146\n",
      "Iteration 7843, loss = 0.00059133\n",
      "Iteration 7844, loss = 0.00059123\n",
      "Iteration 7845, loss = 0.00059114\n",
      "Iteration 7846, loss = 0.00059103\n",
      "Iteration 7847, loss = 0.00059097\n",
      "Iteration 7848, loss = 0.00059083\n",
      "Iteration 7849, loss = 0.00059075\n",
      "Iteration 7850, loss = 0.00059065\n",
      "Iteration 7851, loss = 0.00059054\n",
      "Iteration 7852, loss = 0.00059044\n",
      "Iteration 7853, loss = 0.00059032\n",
      "Iteration 7854, loss = 0.00059025\n",
      "Iteration 7855, loss = 0.00059014\n",
      "Iteration 7856, loss = 0.00059003\n",
      "Iteration 7857, loss = 0.00058995\n",
      "Iteration 7858, loss = 0.00058984\n",
      "Iteration 7859, loss = 0.00058974\n",
      "Iteration 7860, loss = 0.00058963\n",
      "Iteration 7861, loss = 0.00058956\n",
      "Iteration 7862, loss = 0.00058945\n",
      "Iteration 7863, loss = 0.00058936\n",
      "Iteration 7864, loss = 0.00058925\n",
      "Iteration 7865, loss = 0.00058916\n",
      "Iteration 7866, loss = 0.00058907\n",
      "Iteration 7867, loss = 0.00058895\n",
      "Iteration 7868, loss = 0.00058885\n",
      "Iteration 7869, loss = 0.00058876\n",
      "Iteration 7870, loss = 0.00058865\n",
      "Iteration 7871, loss = 0.00058854\n",
      "Iteration 7872, loss = 0.00058845\n",
      "Iteration 7873, loss = 0.00058836\n",
      "Iteration 7874, loss = 0.00058826\n",
      "Iteration 7875, loss = 0.00058816\n",
      "Iteration 7876, loss = 0.00058805\n",
      "Iteration 7877, loss = 0.00058795\n",
      "Iteration 7878, loss = 0.00058789\n",
      "Iteration 7879, loss = 0.00058777\n",
      "Iteration 7880, loss = 0.00058767\n",
      "Iteration 7881, loss = 0.00058756\n",
      "Iteration 7882, loss = 0.00058746\n",
      "Iteration 7883, loss = 0.00058736\n",
      "Iteration 7884, loss = 0.00058727\n",
      "Iteration 7885, loss = 0.00058717\n",
      "Iteration 7886, loss = 0.00058708\n",
      "Iteration 7887, loss = 0.00058701\n",
      "Iteration 7888, loss = 0.00058689\n",
      "Iteration 7889, loss = 0.00058678\n",
      "Iteration 7890, loss = 0.00058669\n",
      "Iteration 7891, loss = 0.00058659\n",
      "Iteration 7892, loss = 0.00058648\n",
      "Iteration 7893, loss = 0.00058642\n",
      "Iteration 7894, loss = 0.00058628\n",
      "Iteration 7895, loss = 0.00058622\n",
      "Iteration 7896, loss = 0.00058611\n",
      "Iteration 7897, loss = 0.00058598\n",
      "Iteration 7898, loss = 0.00058589\n",
      "Iteration 7899, loss = 0.00058579\n",
      "Iteration 7900, loss = 0.00058570\n",
      "Iteration 7901, loss = 0.00058559\n",
      "Iteration 7902, loss = 0.00058549\n",
      "Iteration 7903, loss = 0.00058539\n",
      "Iteration 7904, loss = 0.00058527\n",
      "Iteration 7905, loss = 0.00058519\n",
      "Iteration 7906, loss = 0.00058508\n",
      "Iteration 7907, loss = 0.00058500\n",
      "Iteration 7908, loss = 0.00058489\n",
      "Iteration 7909, loss = 0.00058480\n",
      "Iteration 7910, loss = 0.00058471\n",
      "Iteration 7911, loss = 0.00058459\n",
      "Iteration 7912, loss = 0.00058449\n",
      "Iteration 7913, loss = 0.00058439\n",
      "Iteration 7914, loss = 0.00058432\n",
      "Iteration 7915, loss = 0.00058420\n",
      "Iteration 7916, loss = 0.00058411\n",
      "Iteration 7917, loss = 0.00058402\n",
      "Iteration 7918, loss = 0.00058393\n",
      "Iteration 7919, loss = 0.00058382\n",
      "Iteration 7920, loss = 0.00058378\n",
      "Iteration 7921, loss = 0.00058363\n",
      "Iteration 7922, loss = 0.00058353\n",
      "Iteration 7923, loss = 0.00058346\n",
      "Iteration 7924, loss = 0.00058336\n",
      "Iteration 7925, loss = 0.00058326\n",
      "Iteration 7926, loss = 0.00058315\n",
      "Iteration 7927, loss = 0.00058306\n",
      "Iteration 7928, loss = 0.00058298\n",
      "Iteration 7929, loss = 0.00058289\n",
      "Iteration 7930, loss = 0.00058277\n",
      "Iteration 7931, loss = 0.00058268\n",
      "Iteration 7932, loss = 0.00058258\n",
      "Iteration 7933, loss = 0.00058249\n",
      "Iteration 7934, loss = 0.00058241\n",
      "Iteration 7935, loss = 0.00058229\n",
      "Iteration 7936, loss = 0.00058218\n",
      "Iteration 7937, loss = 0.00058213\n",
      "Iteration 7938, loss = 0.00058200\n",
      "Iteration 7939, loss = 0.00058189\n",
      "Iteration 7940, loss = 0.00058179\n",
      "Iteration 7941, loss = 0.00058170\n",
      "Iteration 7942, loss = 0.00058159\n",
      "Iteration 7943, loss = 0.00058152\n",
      "Iteration 7944, loss = 0.00058140\n",
      "Iteration 7945, loss = 0.00058130\n",
      "Iteration 7946, loss = 0.00058120\n",
      "Iteration 7947, loss = 0.00058111\n",
      "Iteration 7948, loss = 0.00058101\n",
      "Iteration 7949, loss = 0.00058090\n",
      "Iteration 7950, loss = 0.00058080\n",
      "Iteration 7951, loss = 0.00058074\n",
      "Iteration 7952, loss = 0.00058061\n",
      "Iteration 7953, loss = 0.00058052\n",
      "Iteration 7954, loss = 0.00058043\n",
      "Iteration 7955, loss = 0.00058035\n",
      "Iteration 7956, loss = 0.00058024\n",
      "Iteration 7957, loss = 0.00058015\n",
      "Iteration 7958, loss = 0.00058005\n",
      "Iteration 7959, loss = 0.00058001\n",
      "Iteration 7960, loss = 0.00057988\n",
      "Iteration 7961, loss = 0.00057977\n",
      "Iteration 7962, loss = 0.00057967\n",
      "Iteration 7963, loss = 0.00057958\n",
      "Iteration 7964, loss = 0.00057948\n",
      "Iteration 7965, loss = 0.00057939\n",
      "Iteration 7966, loss = 0.00057930\n",
      "Iteration 7967, loss = 0.00057920\n",
      "Iteration 7968, loss = 0.00057911\n",
      "Iteration 7969, loss = 0.00057906\n",
      "Iteration 7970, loss = 0.00057891\n",
      "Iteration 7971, loss = 0.00057882\n",
      "Iteration 7972, loss = 0.00057874\n",
      "Iteration 7973, loss = 0.00057864\n",
      "Iteration 7974, loss = 0.00057854\n",
      "Iteration 7975, loss = 0.00057843\n",
      "Iteration 7976, loss = 0.00057834\n",
      "Iteration 7977, loss = 0.00057826\n",
      "Iteration 7978, loss = 0.00057816\n",
      "Iteration 7979, loss = 0.00057807\n",
      "Iteration 7980, loss = 0.00057797\n",
      "Iteration 7981, loss = 0.00057788\n",
      "Iteration 7982, loss = 0.00057778\n",
      "Iteration 7983, loss = 0.00057768\n",
      "Iteration 7984, loss = 0.00057760\n",
      "Iteration 7985, loss = 0.00057752\n",
      "Iteration 7986, loss = 0.00057741\n",
      "Iteration 7987, loss = 0.00057730\n",
      "Iteration 7988, loss = 0.00057722\n",
      "Iteration 7989, loss = 0.00057711\n",
      "Iteration 7990, loss = 0.00057704\n",
      "Iteration 7991, loss = 0.00057694\n",
      "Iteration 7992, loss = 0.00057684\n",
      "Iteration 7993, loss = 0.00057673\n",
      "Iteration 7994, loss = 0.00057665\n",
      "Iteration 7995, loss = 0.00057655\n",
      "Iteration 7996, loss = 0.00057644\n",
      "Iteration 7997, loss = 0.00057636\n",
      "Iteration 7998, loss = 0.00057628\n",
      "Iteration 7999, loss = 0.00057617\n",
      "Iteration 8000, loss = 0.00057608\n",
      "Iteration 1, loss = 1.04307925\n",
      "Iteration 2, loss = 1.03999583\n",
      "Iteration 3, loss = 1.03502421\n",
      "Iteration 4, loss = 1.02882570\n",
      "Iteration 5, loss = 1.02161886\n",
      "Iteration 6, loss = 1.01353814\n",
      "Iteration 7, loss = 1.00518033\n",
      "Iteration 8, loss = 0.99629146\n",
      "Iteration 9, loss = 0.98695016\n",
      "Iteration 10, loss = 0.97780271\n",
      "Iteration 11, loss = 0.96816411\n",
      "Iteration 12, loss = 0.95885851\n",
      "Iteration 13, loss = 0.94941970\n",
      "Iteration 14, loss = 0.94031499\n",
      "Iteration 15, loss = 0.93114893\n",
      "Iteration 16, loss = 0.92247714\n",
      "Iteration 17, loss = 0.91363217\n",
      "Iteration 18, loss = 0.90530126\n",
      "Iteration 19, loss = 0.89702973\n",
      "Iteration 20, loss = 0.88896846\n",
      "Iteration 21, loss = 0.88104884\n",
      "Iteration 22, loss = 0.87349587\n",
      "Iteration 23, loss = 0.86599414\n",
      "Iteration 24, loss = 0.85846749\n",
      "Iteration 25, loss = 0.85146273\n",
      "Iteration 26, loss = 0.84443121\n",
      "Iteration 27, loss = 0.83752044\n",
      "Iteration 28, loss = 0.83091368\n",
      "Iteration 29, loss = 0.82450974\n",
      "Iteration 30, loss = 0.81823020\n",
      "Iteration 31, loss = 0.81226947\n",
      "Iteration 32, loss = 0.80641652\n",
      "Iteration 33, loss = 0.80072972\n",
      "Iteration 34, loss = 0.79533738\n",
      "Iteration 35, loss = 0.78993272\n",
      "Iteration 36, loss = 0.78466502\n",
      "Iteration 37, loss = 0.77968623\n",
      "Iteration 38, loss = 0.77465106\n",
      "Iteration 39, loss = 0.76992409\n",
      "Iteration 40, loss = 0.76532213\n",
      "Iteration 41, loss = 0.76086048\n",
      "Iteration 42, loss = 0.75667133\n",
      "Iteration 43, loss = 0.75255111\n",
      "Iteration 44, loss = 0.74860564\n",
      "Iteration 45, loss = 0.74469058\n",
      "Iteration 46, loss = 0.74091573\n",
      "Iteration 47, loss = 0.73721243\n",
      "Iteration 48, loss = 0.73349362\n",
      "Iteration 49, loss = 0.72993439\n",
      "Iteration 50, loss = 0.72628398\n",
      "Iteration 51, loss = 0.72288935\n",
      "Iteration 52, loss = 0.71937042\n",
      "Iteration 53, loss = 0.71601488\n",
      "Iteration 54, loss = 0.71259752\n",
      "Iteration 55, loss = 0.70924144\n",
      "Iteration 56, loss = 0.70593159\n",
      "Iteration 57, loss = 0.70244926\n",
      "Iteration 58, loss = 0.69918587\n",
      "Iteration 59, loss = 0.69575496\n",
      "Iteration 60, loss = 0.69240938\n",
      "Iteration 61, loss = 0.68913388\n",
      "Iteration 62, loss = 0.68589264\n",
      "Iteration 63, loss = 0.68279815\n",
      "Iteration 64, loss = 0.67959593\n",
      "Iteration 65, loss = 0.67665969\n",
      "Iteration 66, loss = 0.67369869\n",
      "Iteration 67, loss = 0.67074037\n",
      "Iteration 68, loss = 0.66793161\n",
      "Iteration 69, loss = 0.66502675\n",
      "Iteration 70, loss = 0.66227768\n",
      "Iteration 71, loss = 0.65943683\n",
      "Iteration 72, loss = 0.65671200\n",
      "Iteration 73, loss = 0.65390359\n",
      "Iteration 74, loss = 0.65117480\n",
      "Iteration 75, loss = 0.64845979\n",
      "Iteration 76, loss = 0.64573897\n",
      "Iteration 77, loss = 0.64303636\n",
      "Iteration 78, loss = 0.64035811\n",
      "Iteration 79, loss = 0.63772134\n",
      "Iteration 80, loss = 0.63510050\n",
      "Iteration 81, loss = 0.63245408\n",
      "Iteration 82, loss = 0.62989902\n",
      "Iteration 83, loss = 0.62729651\n",
      "Iteration 84, loss = 0.62468519\n",
      "Iteration 85, loss = 0.62213611\n",
      "Iteration 86, loss = 0.61953900\n",
      "Iteration 87, loss = 0.61695991\n",
      "Iteration 88, loss = 0.61441320\n",
      "Iteration 89, loss = 0.61186128\n",
      "Iteration 90, loss = 0.60933388\n",
      "Iteration 91, loss = 0.60679272\n",
      "Iteration 92, loss = 0.60431857\n",
      "Iteration 93, loss = 0.60181055\n",
      "Iteration 94, loss = 0.59932571\n",
      "Iteration 95, loss = 0.59688260\n",
      "Iteration 96, loss = 0.59442144\n",
      "Iteration 97, loss = 0.59198855\n",
      "Iteration 98, loss = 0.58958768\n",
      "Iteration 99, loss = 0.58715291\n",
      "Iteration 100, loss = 0.58477687\n",
      "Iteration 101, loss = 0.58241489\n",
      "Iteration 102, loss = 0.58000810\n",
      "Iteration 103, loss = 0.57765496\n",
      "Iteration 104, loss = 0.57530083\n",
      "Iteration 105, loss = 0.57293686\n",
      "Iteration 106, loss = 0.57063601\n",
      "Iteration 107, loss = 0.56829556\n",
      "Iteration 108, loss = 0.56602202\n",
      "Iteration 109, loss = 0.56368847\n",
      "Iteration 110, loss = 0.56141310\n",
      "Iteration 111, loss = 0.55913684\n",
      "Iteration 112, loss = 0.55684848\n",
      "Iteration 113, loss = 0.55459141\n",
      "Iteration 114, loss = 0.55226887\n",
      "Iteration 115, loss = 0.55003086\n",
      "Iteration 116, loss = 0.54777725\n",
      "Iteration 117, loss = 0.54546740\n",
      "Iteration 118, loss = 0.54325394\n",
      "Iteration 119, loss = 0.54095827\n",
      "Iteration 120, loss = 0.53872130\n",
      "Iteration 121, loss = 0.53648561\n",
      "Iteration 122, loss = 0.53426424\n",
      "Iteration 123, loss = 0.53206056\n",
      "Iteration 124, loss = 0.52986355\n",
      "Iteration 125, loss = 0.52769955\n",
      "Iteration 126, loss = 0.52553574\n",
      "Iteration 127, loss = 0.52336834\n",
      "Iteration 128, loss = 0.52123012\n",
      "Iteration 129, loss = 0.51909027\n",
      "Iteration 130, loss = 0.51699458\n",
      "Iteration 131, loss = 0.51491887\n",
      "Iteration 132, loss = 0.51285055\n",
      "Iteration 133, loss = 0.51081903\n",
      "Iteration 134, loss = 0.50877880\n",
      "Iteration 135, loss = 0.50672233\n",
      "Iteration 136, loss = 0.50468449\n",
      "Iteration 137, loss = 0.50262792\n",
      "Iteration 138, loss = 0.50056786\n",
      "Iteration 139, loss = 0.49851399\n",
      "Iteration 140, loss = 0.49642186\n",
      "Iteration 141, loss = 0.49433977\n",
      "Iteration 142, loss = 0.49227020\n",
      "Iteration 143, loss = 0.49022006\n",
      "Iteration 144, loss = 0.48813905\n",
      "Iteration 145, loss = 0.48608720\n",
      "Iteration 146, loss = 0.48403280\n",
      "Iteration 147, loss = 0.48198720\n",
      "Iteration 148, loss = 0.47996485\n",
      "Iteration 149, loss = 0.47787730\n",
      "Iteration 150, loss = 0.47583025\n",
      "Iteration 151, loss = 0.47378219\n",
      "Iteration 152, loss = 0.47172546\n",
      "Iteration 153, loss = 0.46964821\n",
      "Iteration 154, loss = 0.46761760\n",
      "Iteration 155, loss = 0.46561831\n",
      "Iteration 156, loss = 0.46354855\n",
      "Iteration 157, loss = 0.46154501\n",
      "Iteration 158, loss = 0.45951984\n",
      "Iteration 159, loss = 0.45746532\n",
      "Iteration 160, loss = 0.45542399\n",
      "Iteration 161, loss = 0.45335974\n",
      "Iteration 162, loss = 0.45128371\n",
      "Iteration 163, loss = 0.44919683\n",
      "Iteration 164, loss = 0.44710284\n",
      "Iteration 165, loss = 0.44501159\n",
      "Iteration 166, loss = 0.44289170\n",
      "Iteration 167, loss = 0.44078787\n",
      "Iteration 168, loss = 0.43869240\n",
      "Iteration 169, loss = 0.43657617\n",
      "Iteration 170, loss = 0.43450220\n",
      "Iteration 171, loss = 0.43242008\n",
      "Iteration 172, loss = 0.43033843\n",
      "Iteration 173, loss = 0.42827048\n",
      "Iteration 174, loss = 0.42622477\n",
      "Iteration 175, loss = 0.42413930\n",
      "Iteration 176, loss = 0.42211244\n",
      "Iteration 177, loss = 0.42003580\n",
      "Iteration 178, loss = 0.41799993\n",
      "Iteration 179, loss = 0.41592504\n",
      "Iteration 180, loss = 0.41389436\n",
      "Iteration 181, loss = 0.41181702\n",
      "Iteration 182, loss = 0.40977596\n",
      "Iteration 183, loss = 0.40774588\n",
      "Iteration 184, loss = 0.40567300\n",
      "Iteration 185, loss = 0.40360979\n",
      "Iteration 186, loss = 0.40156639\n",
      "Iteration 187, loss = 0.39946802\n",
      "Iteration 188, loss = 0.39740670\n",
      "Iteration 189, loss = 0.39534885\n",
      "Iteration 190, loss = 0.39326367\n",
      "Iteration 191, loss = 0.39123002\n",
      "Iteration 192, loss = 0.38918587\n",
      "Iteration 193, loss = 0.38716371\n",
      "Iteration 194, loss = 0.38513573\n",
      "Iteration 195, loss = 0.38314985\n",
      "Iteration 196, loss = 0.38111977\n",
      "Iteration 197, loss = 0.37916040\n",
      "Iteration 198, loss = 0.37716055\n",
      "Iteration 199, loss = 0.37518481\n",
      "Iteration 200, loss = 0.37320718\n",
      "Iteration 201, loss = 0.37122136\n",
      "Iteration 202, loss = 0.36925976\n",
      "Iteration 203, loss = 0.36729194\n",
      "Iteration 204, loss = 0.36531081\n",
      "Iteration 205, loss = 0.36335089\n",
      "Iteration 206, loss = 0.36137313\n",
      "Iteration 207, loss = 0.35939495\n",
      "Iteration 208, loss = 0.35740039\n",
      "Iteration 209, loss = 0.35542377\n",
      "Iteration 210, loss = 0.35342066\n",
      "Iteration 211, loss = 0.35145078\n",
      "Iteration 212, loss = 0.34942133\n",
      "Iteration 213, loss = 0.34745443\n",
      "Iteration 214, loss = 0.34545884\n",
      "Iteration 215, loss = 0.34347444\n",
      "Iteration 216, loss = 0.34149032\n",
      "Iteration 217, loss = 0.33954129\n",
      "Iteration 218, loss = 0.33758305\n",
      "Iteration 219, loss = 0.33566055\n",
      "Iteration 220, loss = 0.33374479\n",
      "Iteration 221, loss = 0.33183759\n",
      "Iteration 222, loss = 0.32995910\n",
      "Iteration 223, loss = 0.32807133\n",
      "Iteration 224, loss = 0.32617934\n",
      "Iteration 225, loss = 0.32432901\n",
      "Iteration 226, loss = 0.32243652\n",
      "Iteration 227, loss = 0.32057577\n",
      "Iteration 228, loss = 0.31869195\n",
      "Iteration 229, loss = 0.31681752\n",
      "Iteration 230, loss = 0.31496279\n",
      "Iteration 231, loss = 0.31309415\n",
      "Iteration 232, loss = 0.31124509\n",
      "Iteration 233, loss = 0.30938812\n",
      "Iteration 234, loss = 0.30754594\n",
      "Iteration 235, loss = 0.30570288\n",
      "Iteration 236, loss = 0.30387288\n",
      "Iteration 237, loss = 0.30202179\n",
      "Iteration 238, loss = 0.30022142\n",
      "Iteration 239, loss = 0.29839110\n",
      "Iteration 240, loss = 0.29659061\n",
      "Iteration 241, loss = 0.29480913\n",
      "Iteration 242, loss = 0.29301025\n",
      "Iteration 243, loss = 0.29123295\n",
      "Iteration 244, loss = 0.28945826\n",
      "Iteration 245, loss = 0.28770300\n",
      "Iteration 246, loss = 0.28593297\n",
      "Iteration 247, loss = 0.28421070\n",
      "Iteration 248, loss = 0.28247010\n",
      "Iteration 249, loss = 0.28074992\n",
      "Iteration 250, loss = 0.27907135\n",
      "Iteration 251, loss = 0.27737733\n",
      "Iteration 252, loss = 0.27569533\n",
      "Iteration 253, loss = 0.27404131\n",
      "Iteration 254, loss = 0.27239762\n",
      "Iteration 255, loss = 0.27074550\n",
      "Iteration 256, loss = 0.26912618\n",
      "Iteration 257, loss = 0.26748297\n",
      "Iteration 258, loss = 0.26588633\n",
      "Iteration 259, loss = 0.26427334\n",
      "Iteration 260, loss = 0.26266983\n",
      "Iteration 261, loss = 0.26108493\n",
      "Iteration 262, loss = 0.25951048\n",
      "Iteration 263, loss = 0.25791507\n",
      "Iteration 264, loss = 0.25633611\n",
      "Iteration 265, loss = 0.25476976\n",
      "Iteration 266, loss = 0.25321638\n",
      "Iteration 267, loss = 0.25167653\n",
      "Iteration 268, loss = 0.25014839\n",
      "Iteration 269, loss = 0.24864041\n",
      "Iteration 270, loss = 0.24714655\n",
      "Iteration 271, loss = 0.24566191\n",
      "Iteration 272, loss = 0.24418844\n",
      "Iteration 273, loss = 0.24271198\n",
      "Iteration 274, loss = 0.24127417\n",
      "Iteration 275, loss = 0.23981910\n",
      "Iteration 276, loss = 0.23839435\n",
      "Iteration 277, loss = 0.23697222\n",
      "Iteration 278, loss = 0.23556227\n",
      "Iteration 279, loss = 0.23417880\n",
      "Iteration 280, loss = 0.23279703\n",
      "Iteration 281, loss = 0.23141961\n",
      "Iteration 282, loss = 0.23003965\n",
      "Iteration 283, loss = 0.22867924\n",
      "Iteration 284, loss = 0.22731074\n",
      "Iteration 285, loss = 0.22595030\n",
      "Iteration 286, loss = 0.22460640\n",
      "Iteration 287, loss = 0.22327046\n",
      "Iteration 288, loss = 0.22195568\n",
      "Iteration 289, loss = 0.22064423\n",
      "Iteration 290, loss = 0.21934793\n",
      "Iteration 291, loss = 0.21806279\n",
      "Iteration 292, loss = 0.21679215\n",
      "Iteration 293, loss = 0.21552655\n",
      "Iteration 294, loss = 0.21426762\n",
      "Iteration 295, loss = 0.21302444\n",
      "Iteration 296, loss = 0.21178478\n",
      "Iteration 297, loss = 0.21056291\n",
      "Iteration 298, loss = 0.20932827\n",
      "Iteration 299, loss = 0.20812384\n",
      "Iteration 300, loss = 0.20692294\n",
      "Iteration 301, loss = 0.20572171\n",
      "Iteration 302, loss = 0.20453463\n",
      "Iteration 303, loss = 0.20336623\n",
      "Iteration 304, loss = 0.20219884\n",
      "Iteration 305, loss = 0.20104435\n",
      "Iteration 306, loss = 0.19989006\n",
      "Iteration 307, loss = 0.19875539\n",
      "Iteration 308, loss = 0.19763488\n",
      "Iteration 309, loss = 0.19651452\n",
      "Iteration 310, loss = 0.19541456\n",
      "Iteration 311, loss = 0.19432513\n",
      "Iteration 312, loss = 0.19324489\n",
      "Iteration 313, loss = 0.19218307\n",
      "Iteration 314, loss = 0.19111764\n",
      "Iteration 315, loss = 0.19006489\n",
      "Iteration 316, loss = 0.18901884\n",
      "Iteration 317, loss = 0.18798074\n",
      "Iteration 318, loss = 0.18695758\n",
      "Iteration 319, loss = 0.18592982\n",
      "Iteration 320, loss = 0.18491732\n",
      "Iteration 321, loss = 0.18391244\n",
      "Iteration 322, loss = 0.18290912\n",
      "Iteration 323, loss = 0.18193561\n",
      "Iteration 324, loss = 0.18095504\n",
      "Iteration 325, loss = 0.17997647\n",
      "Iteration 326, loss = 0.17901808\n",
      "Iteration 327, loss = 0.17807094\n",
      "Iteration 328, loss = 0.17712189\n",
      "Iteration 329, loss = 0.17618393\n",
      "Iteration 330, loss = 0.17525036\n",
      "Iteration 331, loss = 0.17431764\n",
      "Iteration 332, loss = 0.17340402\n",
      "Iteration 333, loss = 0.17248794\n",
      "Iteration 334, loss = 0.17158075\n",
      "Iteration 335, loss = 0.17068278\n",
      "Iteration 336, loss = 0.16978617\n",
      "Iteration 337, loss = 0.16888619\n",
      "Iteration 338, loss = 0.16800143\n",
      "Iteration 339, loss = 0.16711847\n",
      "Iteration 340, loss = 0.16624430\n",
      "Iteration 341, loss = 0.16538058\n",
      "Iteration 342, loss = 0.16451672\n",
      "Iteration 343, loss = 0.16367973\n",
      "Iteration 344, loss = 0.16282328\n",
      "Iteration 345, loss = 0.16199828\n",
      "Iteration 346, loss = 0.16117565\n",
      "Iteration 347, loss = 0.16034228\n",
      "Iteration 348, loss = 0.15953723\n",
      "Iteration 349, loss = 0.15871250\n",
      "Iteration 350, loss = 0.15789987\n",
      "Iteration 351, loss = 0.15710334\n",
      "Iteration 352, loss = 0.15630633\n",
      "Iteration 353, loss = 0.15552530\n",
      "Iteration 354, loss = 0.15475562\n",
      "Iteration 355, loss = 0.15398879\n",
      "Iteration 356, loss = 0.15323914\n",
      "Iteration 357, loss = 0.15248459\n",
      "Iteration 358, loss = 0.15173951\n",
      "Iteration 359, loss = 0.15099669\n",
      "Iteration 360, loss = 0.15026169\n",
      "Iteration 361, loss = 0.14953353\n",
      "Iteration 362, loss = 0.14880375\n",
      "Iteration 363, loss = 0.14808107\n",
      "Iteration 364, loss = 0.14736878\n",
      "Iteration 365, loss = 0.14666962\n",
      "Iteration 366, loss = 0.14595827\n",
      "Iteration 367, loss = 0.14526731\n",
      "Iteration 368, loss = 0.14458408\n",
      "Iteration 369, loss = 0.14390698\n",
      "Iteration 370, loss = 0.14323139\n",
      "Iteration 371, loss = 0.14257827\n",
      "Iteration 372, loss = 0.14190820\n",
      "Iteration 373, loss = 0.14126011\n",
      "Iteration 374, loss = 0.14059744\n",
      "Iteration 375, loss = 0.13994959\n",
      "Iteration 376, loss = 0.13930117\n",
      "Iteration 377, loss = 0.13866319\n",
      "Iteration 378, loss = 0.13803389\n",
      "Iteration 379, loss = 0.13739647\n",
      "Iteration 380, loss = 0.13677701\n",
      "Iteration 381, loss = 0.13615950\n",
      "Iteration 382, loss = 0.13554596\n",
      "Iteration 383, loss = 0.13494024\n",
      "Iteration 384, loss = 0.13433267\n",
      "Iteration 385, loss = 0.13373739\n",
      "Iteration 386, loss = 0.13313569\n",
      "Iteration 387, loss = 0.13254415\n",
      "Iteration 388, loss = 0.13195306\n",
      "Iteration 389, loss = 0.13137545\n",
      "Iteration 390, loss = 0.13079789\n",
      "Iteration 391, loss = 0.13022925\n",
      "Iteration 392, loss = 0.12965555\n",
      "Iteration 393, loss = 0.12909943\n",
      "Iteration 394, loss = 0.12854505\n",
      "Iteration 395, loss = 0.12799619\n",
      "Iteration 396, loss = 0.12744768\n",
      "Iteration 397, loss = 0.12691285\n",
      "Iteration 398, loss = 0.12637566\n",
      "Iteration 399, loss = 0.12583385\n",
      "Iteration 400, loss = 0.12530248\n",
      "Iteration 401, loss = 0.12477453\n",
      "Iteration 402, loss = 0.12425450\n",
      "Iteration 403, loss = 0.12373895\n",
      "Iteration 404, loss = 0.12322720\n",
      "Iteration 405, loss = 0.12271754\n",
      "Iteration 406, loss = 0.12220976\n",
      "Iteration 407, loss = 0.12171283\n",
      "Iteration 408, loss = 0.12121465\n",
      "Iteration 409, loss = 0.12071863\n",
      "Iteration 410, loss = 0.12022876\n",
      "Iteration 411, loss = 0.11974569\n",
      "Iteration 412, loss = 0.11926392\n",
      "Iteration 413, loss = 0.11878708\n",
      "Iteration 414, loss = 0.11831351\n",
      "Iteration 415, loss = 0.11783844\n",
      "Iteration 416, loss = 0.11737401\n",
      "Iteration 417, loss = 0.11690068\n",
      "Iteration 418, loss = 0.11643744\n",
      "Iteration 419, loss = 0.11597359\n",
      "Iteration 420, loss = 0.11551722\n",
      "Iteration 421, loss = 0.11505658\n",
      "Iteration 422, loss = 0.11461234\n",
      "Iteration 423, loss = 0.11416397\n",
      "Iteration 424, loss = 0.11372443\n",
      "Iteration 425, loss = 0.11328239\n",
      "Iteration 426, loss = 0.11285571\n",
      "Iteration 427, loss = 0.11242491\n",
      "Iteration 428, loss = 0.11200538\n",
      "Iteration 429, loss = 0.11158169\n",
      "Iteration 430, loss = 0.11116815\n",
      "Iteration 431, loss = 0.11075861\n",
      "Iteration 432, loss = 0.11034766\n",
      "Iteration 433, loss = 0.10992752\n",
      "Iteration 434, loss = 0.10951661\n",
      "Iteration 435, loss = 0.10911506\n",
      "Iteration 436, loss = 0.10870667\n",
      "Iteration 437, loss = 0.10830406\n",
      "Iteration 438, loss = 0.10790136\n",
      "Iteration 439, loss = 0.10751179\n",
      "Iteration 440, loss = 0.10711374\n",
      "Iteration 441, loss = 0.10672641\n",
      "Iteration 442, loss = 0.10633666\n",
      "Iteration 443, loss = 0.10596099\n",
      "Iteration 444, loss = 0.10557841\n",
      "Iteration 445, loss = 0.10520618\n",
      "Iteration 446, loss = 0.10483513\n",
      "Iteration 447, loss = 0.10446043\n",
      "Iteration 448, loss = 0.10408579\n",
      "Iteration 449, loss = 0.10370768\n",
      "Iteration 450, loss = 0.10334467\n",
      "Iteration 451, loss = 0.10297035\n",
      "Iteration 452, loss = 0.10261371\n",
      "Iteration 453, loss = 0.10225377\n",
      "Iteration 454, loss = 0.10190277\n",
      "Iteration 455, loss = 0.10156222\n",
      "Iteration 456, loss = 0.10120511\n",
      "Iteration 457, loss = 0.10085715\n",
      "Iteration 458, loss = 0.10051421\n",
      "Iteration 459, loss = 0.10016481\n",
      "Iteration 460, loss = 0.09982839\n",
      "Iteration 461, loss = 0.09948636\n",
      "Iteration 462, loss = 0.09915331\n",
      "Iteration 463, loss = 0.09882079\n",
      "Iteration 464, loss = 0.09849379\n",
      "Iteration 465, loss = 0.09816883\n",
      "Iteration 466, loss = 0.09784982\n",
      "Iteration 467, loss = 0.09753644\n",
      "Iteration 468, loss = 0.09721503\n",
      "Iteration 469, loss = 0.09689917\n",
      "Iteration 470, loss = 0.09658038\n",
      "Iteration 471, loss = 0.09627910\n",
      "Iteration 472, loss = 0.09596833\n",
      "Iteration 473, loss = 0.09565642\n",
      "Iteration 474, loss = 0.09535292\n",
      "Iteration 475, loss = 0.09504549\n",
      "Iteration 476, loss = 0.09474972\n",
      "Iteration 477, loss = 0.09444849\n",
      "Iteration 478, loss = 0.09415067\n",
      "Iteration 479, loss = 0.09385454\n",
      "Iteration 480, loss = 0.09356640\n",
      "Iteration 481, loss = 0.09327672\n",
      "Iteration 482, loss = 0.09298090\n",
      "Iteration 483, loss = 0.09269893\n",
      "Iteration 484, loss = 0.09240847\n",
      "Iteration 485, loss = 0.09212093\n",
      "Iteration 486, loss = 0.09183333\n",
      "Iteration 487, loss = 0.09154477\n",
      "Iteration 488, loss = 0.09126854\n",
      "Iteration 489, loss = 0.09098954\n",
      "Iteration 490, loss = 0.09070588\n",
      "Iteration 491, loss = 0.09043449\n",
      "Iteration 492, loss = 0.09015569\n",
      "Iteration 493, loss = 0.08988000\n",
      "Iteration 494, loss = 0.08960489\n",
      "Iteration 495, loss = 0.08933198\n",
      "Iteration 496, loss = 0.08906492\n",
      "Iteration 497, loss = 0.08879630\n",
      "Iteration 498, loss = 0.08854458\n",
      "Iteration 499, loss = 0.08826668\n",
      "Iteration 500, loss = 0.08800176\n",
      "Iteration 501, loss = 0.08774522\n",
      "Iteration 502, loss = 0.08747920\n",
      "Iteration 503, loss = 0.08722209\n",
      "Iteration 504, loss = 0.08696110\n",
      "Iteration 505, loss = 0.08670934\n",
      "Iteration 506, loss = 0.08645193\n",
      "Iteration 507, loss = 0.08619863\n",
      "Iteration 508, loss = 0.08595299\n",
      "Iteration 509, loss = 0.08570242\n",
      "Iteration 510, loss = 0.08545522\n",
      "Iteration 511, loss = 0.08521165\n",
      "Iteration 512, loss = 0.08496437\n",
      "Iteration 513, loss = 0.08473287\n",
      "Iteration 514, loss = 0.08449186\n",
      "Iteration 515, loss = 0.08424581\n",
      "Iteration 516, loss = 0.08400855\n",
      "Iteration 517, loss = 0.08376910\n",
      "Iteration 518, loss = 0.08353224\n",
      "Iteration 519, loss = 0.08329269\n",
      "Iteration 520, loss = 0.08306176\n",
      "Iteration 521, loss = 0.08283082\n",
      "Iteration 522, loss = 0.08259260\n",
      "Iteration 523, loss = 0.08236612\n",
      "Iteration 524, loss = 0.08213440\n",
      "Iteration 525, loss = 0.08190909\n",
      "Iteration 526, loss = 0.08168522\n",
      "Iteration 527, loss = 0.08146482\n",
      "Iteration 528, loss = 0.08124222\n",
      "Iteration 529, loss = 0.08102486\n",
      "Iteration 530, loss = 0.08080203\n",
      "Iteration 531, loss = 0.08058633\n",
      "Iteration 532, loss = 0.08036845\n",
      "Iteration 533, loss = 0.08015290\n",
      "Iteration 534, loss = 0.07994062\n",
      "Iteration 535, loss = 0.07973324\n",
      "Iteration 536, loss = 0.07952150\n",
      "Iteration 537, loss = 0.07931713\n",
      "Iteration 538, loss = 0.07911204\n",
      "Iteration 539, loss = 0.07890893\n",
      "Iteration 540, loss = 0.07870854\n",
      "Iteration 541, loss = 0.07850800\n",
      "Iteration 542, loss = 0.07830766\n",
      "Iteration 543, loss = 0.07810968\n",
      "Iteration 544, loss = 0.07791586\n",
      "Iteration 545, loss = 0.07771893\n",
      "Iteration 546, loss = 0.07751833\n",
      "Iteration 547, loss = 0.07732108\n",
      "Iteration 548, loss = 0.07712864\n",
      "Iteration 549, loss = 0.07693332\n",
      "Iteration 550, loss = 0.07674115\n",
      "Iteration 551, loss = 0.07654665\n",
      "Iteration 552, loss = 0.07636140\n",
      "Iteration 553, loss = 0.07617045\n",
      "Iteration 554, loss = 0.07598365\n",
      "Iteration 555, loss = 0.07580108\n",
      "Iteration 556, loss = 0.07562001\n",
      "Iteration 557, loss = 0.07543959\n",
      "Iteration 558, loss = 0.07526702\n",
      "Iteration 559, loss = 0.07508105\n",
      "Iteration 560, loss = 0.07490580\n",
      "Iteration 561, loss = 0.07472594\n",
      "Iteration 562, loss = 0.07454972\n",
      "Iteration 563, loss = 0.07437347\n",
      "Iteration 564, loss = 0.07419464\n",
      "Iteration 565, loss = 0.07402481\n",
      "Iteration 566, loss = 0.07384622\n",
      "Iteration 567, loss = 0.07367124\n",
      "Iteration 568, loss = 0.07349977\n",
      "Iteration 569, loss = 0.07333160\n",
      "Iteration 570, loss = 0.07316297\n",
      "Iteration 571, loss = 0.07299255\n",
      "Iteration 572, loss = 0.07282303\n",
      "Iteration 573, loss = 0.07265763\n",
      "Iteration 574, loss = 0.07248711\n",
      "Iteration 575, loss = 0.07231770\n",
      "Iteration 576, loss = 0.07214809\n",
      "Iteration 577, loss = 0.07198412\n",
      "Iteration 578, loss = 0.07181731\n",
      "Iteration 579, loss = 0.07165398\n",
      "Iteration 580, loss = 0.07148805\n",
      "Iteration 581, loss = 0.07132903\n",
      "Iteration 582, loss = 0.07116557\n",
      "Iteration 583, loss = 0.07100703\n",
      "Iteration 584, loss = 0.07084793\n",
      "Iteration 585, loss = 0.07069924\n",
      "Iteration 586, loss = 0.07053895\n",
      "Iteration 587, loss = 0.07037917\n",
      "Iteration 588, loss = 0.07022305\n",
      "Iteration 589, loss = 0.07006739\n",
      "Iteration 590, loss = 0.06991468\n",
      "Iteration 591, loss = 0.06975896\n",
      "Iteration 592, loss = 0.06960239\n",
      "Iteration 593, loss = 0.06945601\n",
      "Iteration 594, loss = 0.06929882\n",
      "Iteration 595, loss = 0.06914494\n",
      "Iteration 596, loss = 0.06899132\n",
      "Iteration 597, loss = 0.06883850\n",
      "Iteration 598, loss = 0.06868865\n",
      "Iteration 599, loss = 0.06853699\n",
      "Iteration 600, loss = 0.06838803\n",
      "Iteration 601, loss = 0.06823719\n",
      "Iteration 602, loss = 0.06808957\n",
      "Iteration 603, loss = 0.06794112\n",
      "Iteration 604, loss = 0.06779251\n",
      "Iteration 605, loss = 0.06764292\n",
      "Iteration 606, loss = 0.06749597\n",
      "Iteration 607, loss = 0.06734800\n",
      "Iteration 608, loss = 0.06721185\n",
      "Iteration 609, loss = 0.06706294\n",
      "Iteration 610, loss = 0.06692258\n",
      "Iteration 611, loss = 0.06677555\n",
      "Iteration 612, loss = 0.06663330\n",
      "Iteration 613, loss = 0.06649217\n",
      "Iteration 614, loss = 0.06635140\n",
      "Iteration 615, loss = 0.06620730\n",
      "Iteration 616, loss = 0.06606452\n",
      "Iteration 617, loss = 0.06593024\n",
      "Iteration 618, loss = 0.06579702\n",
      "Iteration 619, loss = 0.06565487\n",
      "Iteration 620, loss = 0.06551732\n",
      "Iteration 621, loss = 0.06538504\n",
      "Iteration 622, loss = 0.06525307\n",
      "Iteration 623, loss = 0.06512367\n",
      "Iteration 624, loss = 0.06499391\n",
      "Iteration 625, loss = 0.06485991\n",
      "Iteration 626, loss = 0.06472956\n",
      "Iteration 627, loss = 0.06459625\n",
      "Iteration 628, loss = 0.06446353\n",
      "Iteration 629, loss = 0.06433604\n",
      "Iteration 630, loss = 0.06420383\n",
      "Iteration 631, loss = 0.06407502\n",
      "Iteration 632, loss = 0.06394778\n",
      "Iteration 633, loss = 0.06381995\n",
      "Iteration 634, loss = 0.06369335\n",
      "Iteration 635, loss = 0.06356780\n",
      "Iteration 636, loss = 0.06344358\n",
      "Iteration 637, loss = 0.06331255\n",
      "Iteration 638, loss = 0.06318858\n",
      "Iteration 639, loss = 0.06306120\n",
      "Iteration 640, loss = 0.06293488\n",
      "Iteration 641, loss = 0.06280748\n",
      "Iteration 642, loss = 0.06268417\n",
      "Iteration 643, loss = 0.06255394\n",
      "Iteration 644, loss = 0.06243234\n",
      "Iteration 645, loss = 0.06230888\n",
      "Iteration 646, loss = 0.06218362\n",
      "Iteration 647, loss = 0.06205848\n",
      "Iteration 648, loss = 0.06193735\n",
      "Iteration 649, loss = 0.06181867\n",
      "Iteration 650, loss = 0.06169871\n",
      "Iteration 651, loss = 0.06159025\n",
      "Iteration 652, loss = 0.06146793\n",
      "Iteration 653, loss = 0.06135282\n",
      "Iteration 654, loss = 0.06123578\n",
      "Iteration 655, loss = 0.06112367\n",
      "Iteration 656, loss = 0.06101051\n",
      "Iteration 657, loss = 0.06089137\n",
      "Iteration 658, loss = 0.06077632\n",
      "Iteration 659, loss = 0.06066478\n",
      "Iteration 660, loss = 0.06054894\n",
      "Iteration 661, loss = 0.06043891\n",
      "Iteration 662, loss = 0.06032615\n",
      "Iteration 663, loss = 0.06021891\n",
      "Iteration 664, loss = 0.06010596\n",
      "Iteration 665, loss = 0.05999879\n",
      "Iteration 666, loss = 0.05988927\n",
      "Iteration 667, loss = 0.05978317\n",
      "Iteration 668, loss = 0.05967394\n",
      "Iteration 669, loss = 0.05956667\n",
      "Iteration 670, loss = 0.05945933\n",
      "Iteration 671, loss = 0.05935577\n",
      "Iteration 672, loss = 0.05924445\n",
      "Iteration 673, loss = 0.05913761\n",
      "Iteration 674, loss = 0.05902984\n",
      "Iteration 675, loss = 0.05892293\n",
      "Iteration 676, loss = 0.05881607\n",
      "Iteration 677, loss = 0.05871022\n",
      "Iteration 678, loss = 0.05859920\n",
      "Iteration 679, loss = 0.05849942\n",
      "Iteration 680, loss = 0.05838975\n",
      "Iteration 681, loss = 0.05828350\n",
      "Iteration 682, loss = 0.05817606\n",
      "Iteration 683, loss = 0.05806947\n",
      "Iteration 684, loss = 0.05796354\n",
      "Iteration 685, loss = 0.05785923\n",
      "Iteration 686, loss = 0.05774957\n",
      "Iteration 687, loss = 0.05765320\n",
      "Iteration 688, loss = 0.05754137\n",
      "Iteration 689, loss = 0.05743778\n",
      "Iteration 690, loss = 0.05733911\n",
      "Iteration 691, loss = 0.05723154\n",
      "Iteration 692, loss = 0.05713179\n",
      "Iteration 693, loss = 0.05702705\n",
      "Iteration 694, loss = 0.05693087\n",
      "Iteration 695, loss = 0.05682528\n",
      "Iteration 696, loss = 0.05672558\n",
      "Iteration 697, loss = 0.05662598\n",
      "Iteration 698, loss = 0.05652687\n",
      "Iteration 699, loss = 0.05643206\n",
      "Iteration 700, loss = 0.05633313\n",
      "Iteration 701, loss = 0.05623778\n",
      "Iteration 702, loss = 0.05614234\n",
      "Iteration 703, loss = 0.05604994\n",
      "Iteration 704, loss = 0.05594717\n",
      "Iteration 705, loss = 0.05585117\n",
      "Iteration 706, loss = 0.05576421\n",
      "Iteration 707, loss = 0.05566685\n",
      "Iteration 708, loss = 0.05557228\n",
      "Iteration 709, loss = 0.05547990\n",
      "Iteration 710, loss = 0.05538740\n",
      "Iteration 711, loss = 0.05529696\n",
      "Iteration 712, loss = 0.05520711\n",
      "Iteration 713, loss = 0.05511017\n",
      "Iteration 714, loss = 0.05502062\n",
      "Iteration 715, loss = 0.05492386\n",
      "Iteration 716, loss = 0.05483538\n",
      "Iteration 717, loss = 0.05473718\n",
      "Iteration 718, loss = 0.05464448\n",
      "Iteration 719, loss = 0.05456137\n",
      "Iteration 720, loss = 0.05446666\n",
      "Iteration 721, loss = 0.05437296\n",
      "Iteration 722, loss = 0.05428137\n",
      "Iteration 723, loss = 0.05418819\n",
      "Iteration 724, loss = 0.05410062\n",
      "Iteration 725, loss = 0.05401128\n",
      "Iteration 726, loss = 0.05391810\n",
      "Iteration 727, loss = 0.05383195\n",
      "Iteration 728, loss = 0.05374942\n",
      "Iteration 729, loss = 0.05365858\n",
      "Iteration 730, loss = 0.05357128\n",
      "Iteration 731, loss = 0.05348427\n",
      "Iteration 732, loss = 0.05339542\n",
      "Iteration 733, loss = 0.05331078\n",
      "Iteration 734, loss = 0.05322348\n",
      "Iteration 735, loss = 0.05313895\n",
      "Iteration 736, loss = 0.05305995\n",
      "Iteration 737, loss = 0.05297755\n",
      "Iteration 738, loss = 0.05288957\n",
      "Iteration 739, loss = 0.05280680\n",
      "Iteration 740, loss = 0.05272463\n",
      "Iteration 741, loss = 0.05263685\n",
      "Iteration 742, loss = 0.05254794\n",
      "Iteration 743, loss = 0.05246703\n",
      "Iteration 744, loss = 0.05238037\n",
      "Iteration 745, loss = 0.05229739\n",
      "Iteration 746, loss = 0.05221555\n",
      "Iteration 747, loss = 0.05212853\n",
      "Iteration 748, loss = 0.05204854\n",
      "Iteration 749, loss = 0.05195666\n",
      "Iteration 750, loss = 0.05187264\n",
      "Iteration 751, loss = 0.05179335\n",
      "Iteration 752, loss = 0.05170427\n",
      "Iteration 753, loss = 0.05162398\n",
      "Iteration 754, loss = 0.05154455\n",
      "Iteration 755, loss = 0.05146430\n",
      "Iteration 756, loss = 0.05138375\n",
      "Iteration 757, loss = 0.05130162\n",
      "Iteration 758, loss = 0.05122712\n",
      "Iteration 759, loss = 0.05114701\n",
      "Iteration 760, loss = 0.05107798\n",
      "Iteration 761, loss = 0.05099793\n",
      "Iteration 762, loss = 0.05092657\n",
      "Iteration 763, loss = 0.05084281\n",
      "Iteration 764, loss = 0.05076793\n",
      "Iteration 765, loss = 0.05069301\n",
      "Iteration 766, loss = 0.05061596\n",
      "Iteration 767, loss = 0.05053826\n",
      "Iteration 768, loss = 0.05046393\n",
      "Iteration 769, loss = 0.05038844\n",
      "Iteration 770, loss = 0.05030947\n",
      "Iteration 771, loss = 0.05023540\n",
      "Iteration 772, loss = 0.05015914\n",
      "Iteration 773, loss = 0.05008456\n",
      "Iteration 774, loss = 0.05000850\n",
      "Iteration 775, loss = 0.04992996\n",
      "Iteration 776, loss = 0.04985635\n",
      "Iteration 777, loss = 0.04978395\n",
      "Iteration 778, loss = 0.04970714\n",
      "Iteration 779, loss = 0.04963465\n",
      "Iteration 780, loss = 0.04955778\n",
      "Iteration 781, loss = 0.04948051\n",
      "Iteration 782, loss = 0.04940798\n",
      "Iteration 783, loss = 0.04933010\n",
      "Iteration 784, loss = 0.04925753\n",
      "Iteration 785, loss = 0.04917930\n",
      "Iteration 786, loss = 0.04910582\n",
      "Iteration 787, loss = 0.04903241\n",
      "Iteration 788, loss = 0.04895950\n",
      "Iteration 789, loss = 0.04888354\n",
      "Iteration 790, loss = 0.04881546\n",
      "Iteration 791, loss = 0.04874223\n",
      "Iteration 792, loss = 0.04867154\n",
      "Iteration 793, loss = 0.04860025\n",
      "Iteration 794, loss = 0.04853022\n",
      "Iteration 795, loss = 0.04846010\n",
      "Iteration 796, loss = 0.04839213\n",
      "Iteration 797, loss = 0.04832695\n",
      "Iteration 798, loss = 0.04825356\n",
      "Iteration 799, loss = 0.04818443\n",
      "Iteration 800, loss = 0.04812290\n",
      "Iteration 801, loss = 0.04804814\n",
      "Iteration 802, loss = 0.04798154\n",
      "Iteration 803, loss = 0.04791244\n",
      "Iteration 804, loss = 0.04784266\n",
      "Iteration 805, loss = 0.04777598\n",
      "Iteration 806, loss = 0.04770899\n",
      "Iteration 807, loss = 0.04764354\n",
      "Iteration 808, loss = 0.04757738\n",
      "Iteration 809, loss = 0.04751181\n",
      "Iteration 810, loss = 0.04744719\n",
      "Iteration 811, loss = 0.04738237\n",
      "Iteration 812, loss = 0.04731421\n",
      "Iteration 813, loss = 0.04724960\n",
      "Iteration 814, loss = 0.04718020\n",
      "Iteration 815, loss = 0.04711121\n",
      "Iteration 816, loss = 0.04704296\n",
      "Iteration 817, loss = 0.04697541\n",
      "Iteration 818, loss = 0.04691123\n",
      "Iteration 819, loss = 0.04683842\n",
      "Iteration 820, loss = 0.04677233\n",
      "Iteration 821, loss = 0.04670505\n",
      "Iteration 822, loss = 0.04663619\n",
      "Iteration 823, loss = 0.04657063\n",
      "Iteration 824, loss = 0.04650228\n",
      "Iteration 825, loss = 0.04643420\n",
      "Iteration 826, loss = 0.04636966\n",
      "Iteration 827, loss = 0.04630865\n",
      "Iteration 828, loss = 0.04623531\n",
      "Iteration 829, loss = 0.04617351\n",
      "Iteration 830, loss = 0.04610814\n",
      "Iteration 831, loss = 0.04604391\n",
      "Iteration 832, loss = 0.04598028\n",
      "Iteration 833, loss = 0.04591904\n",
      "Iteration 834, loss = 0.04585406\n",
      "Iteration 835, loss = 0.04579086\n",
      "Iteration 836, loss = 0.04572993\n",
      "Iteration 837, loss = 0.04566738\n",
      "Iteration 838, loss = 0.04560394\n",
      "Iteration 839, loss = 0.04554216\n",
      "Iteration 840, loss = 0.04548063\n",
      "Iteration 841, loss = 0.04542031\n",
      "Iteration 842, loss = 0.04535771\n",
      "Iteration 843, loss = 0.04529724\n",
      "Iteration 844, loss = 0.04523858\n",
      "Iteration 845, loss = 0.04517870\n",
      "Iteration 846, loss = 0.04511742\n",
      "Iteration 847, loss = 0.04505805\n",
      "Iteration 848, loss = 0.04500044\n",
      "Iteration 849, loss = 0.04493701\n",
      "Iteration 850, loss = 0.04488132\n",
      "Iteration 851, loss = 0.04481854\n",
      "Iteration 852, loss = 0.04475890\n",
      "Iteration 853, loss = 0.04470189\n",
      "Iteration 854, loss = 0.04464039\n",
      "Iteration 855, loss = 0.04458128\n",
      "Iteration 856, loss = 0.04452087\n",
      "Iteration 857, loss = 0.04446648\n",
      "Iteration 858, loss = 0.04440651\n",
      "Iteration 859, loss = 0.04434829\n",
      "Iteration 860, loss = 0.04428885\n",
      "Iteration 861, loss = 0.04423220\n",
      "Iteration 862, loss = 0.04417186\n",
      "Iteration 863, loss = 0.04411363\n",
      "Iteration 864, loss = 0.04405330\n",
      "Iteration 865, loss = 0.04399210\n",
      "Iteration 866, loss = 0.04393519\n",
      "Iteration 867, loss = 0.04387609\n",
      "Iteration 868, loss = 0.04381938\n",
      "Iteration 869, loss = 0.04376184\n",
      "Iteration 870, loss = 0.04370801\n",
      "Iteration 871, loss = 0.04365393\n",
      "Iteration 872, loss = 0.04359773\n",
      "Iteration 873, loss = 0.04353826\n",
      "Iteration 874, loss = 0.04348271\n",
      "Iteration 875, loss = 0.04342597\n",
      "Iteration 876, loss = 0.04336835\n",
      "Iteration 877, loss = 0.04332120\n",
      "Iteration 878, loss = 0.04325838\n",
      "Iteration 879, loss = 0.04320118\n",
      "Iteration 880, loss = 0.04314360\n",
      "Iteration 881, loss = 0.04309054\n",
      "Iteration 882, loss = 0.04303055\n",
      "Iteration 883, loss = 0.04297707\n",
      "Iteration 884, loss = 0.04291810\n",
      "Iteration 885, loss = 0.04286227\n",
      "Iteration 886, loss = 0.04280741\n",
      "Iteration 887, loss = 0.04275268\n",
      "Iteration 888, loss = 0.04270094\n",
      "Iteration 889, loss = 0.04264225\n",
      "Iteration 890, loss = 0.04258814\n",
      "Iteration 891, loss = 0.04253313\n",
      "Iteration 892, loss = 0.04247630\n",
      "Iteration 893, loss = 0.04242117\n",
      "Iteration 894, loss = 0.04236841\n",
      "Iteration 895, loss = 0.04231103\n",
      "Iteration 896, loss = 0.04225761\n",
      "Iteration 897, loss = 0.04220598\n",
      "Iteration 898, loss = 0.04215035\n",
      "Iteration 899, loss = 0.04209604\n",
      "Iteration 900, loss = 0.04204304\n",
      "Iteration 901, loss = 0.04199138\n",
      "Iteration 902, loss = 0.04193890\n",
      "Iteration 903, loss = 0.04188453\n",
      "Iteration 904, loss = 0.04183729\n",
      "Iteration 905, loss = 0.04177740\n",
      "Iteration 906, loss = 0.04172482\n",
      "Iteration 907, loss = 0.04166877\n",
      "Iteration 908, loss = 0.04161672\n",
      "Iteration 909, loss = 0.04156407\n",
      "Iteration 910, loss = 0.04151009\n",
      "Iteration 911, loss = 0.04145765\n",
      "Iteration 912, loss = 0.04140689\n",
      "Iteration 913, loss = 0.04135558\n",
      "Iteration 914, loss = 0.04130390\n",
      "Iteration 915, loss = 0.04125445\n",
      "Iteration 916, loss = 0.04120020\n",
      "Iteration 917, loss = 0.04114809\n",
      "Iteration 918, loss = 0.04109837\n",
      "Iteration 919, loss = 0.04104394\n",
      "Iteration 920, loss = 0.04099727\n",
      "Iteration 921, loss = 0.04094462\n",
      "Iteration 922, loss = 0.04089155\n",
      "Iteration 923, loss = 0.04084031\n",
      "Iteration 924, loss = 0.04078971\n",
      "Iteration 925, loss = 0.04073852\n",
      "Iteration 926, loss = 0.04068862\n",
      "Iteration 927, loss = 0.04063522\n",
      "Iteration 928, loss = 0.04058458\n",
      "Iteration 929, loss = 0.04053948\n",
      "Iteration 930, loss = 0.04048611\n",
      "Iteration 931, loss = 0.04043547\n",
      "Iteration 932, loss = 0.04038419\n",
      "Iteration 933, loss = 0.04033569\n",
      "Iteration 934, loss = 0.04028912\n",
      "Iteration 935, loss = 0.04024148\n",
      "Iteration 936, loss = 0.04019277\n",
      "Iteration 937, loss = 0.04015031\n",
      "Iteration 938, loss = 0.04010045\n",
      "Iteration 939, loss = 0.04005781\n",
      "Iteration 940, loss = 0.04000586\n",
      "Iteration 941, loss = 0.03995411\n",
      "Iteration 942, loss = 0.03990900\n",
      "Iteration 943, loss = 0.03985821\n",
      "Iteration 944, loss = 0.03981483\n",
      "Iteration 945, loss = 0.03976231\n",
      "Iteration 946, loss = 0.03971609\n",
      "Iteration 947, loss = 0.03966990\n",
      "Iteration 948, loss = 0.03962019\n",
      "Iteration 949, loss = 0.03957325\n",
      "Iteration 950, loss = 0.03952428\n",
      "Iteration 951, loss = 0.03947453\n",
      "Iteration 952, loss = 0.03942406\n",
      "Iteration 953, loss = 0.03937634\n",
      "Iteration 954, loss = 0.03932831\n",
      "Iteration 955, loss = 0.03927948\n",
      "Iteration 956, loss = 0.03923361\n",
      "Iteration 957, loss = 0.03918586\n",
      "Iteration 958, loss = 0.03913770\n",
      "Iteration 959, loss = 0.03909198\n",
      "Iteration 960, loss = 0.03904668\n",
      "Iteration 961, loss = 0.03899732\n",
      "Iteration 962, loss = 0.03895071\n",
      "Iteration 963, loss = 0.03890413\n",
      "Iteration 964, loss = 0.03885872\n",
      "Iteration 965, loss = 0.03881297\n",
      "Iteration 966, loss = 0.03876749\n",
      "Iteration 967, loss = 0.03872410\n",
      "Iteration 968, loss = 0.03867786\n",
      "Iteration 969, loss = 0.03863145\n",
      "Iteration 970, loss = 0.03858563\n",
      "Iteration 971, loss = 0.03854109\n",
      "Iteration 972, loss = 0.03849364\n",
      "Iteration 973, loss = 0.03844662\n",
      "Iteration 974, loss = 0.03840453\n",
      "Iteration 975, loss = 0.03835890\n",
      "Iteration 976, loss = 0.03831654\n",
      "Iteration 977, loss = 0.03826794\n",
      "Iteration 978, loss = 0.03822224\n",
      "Iteration 979, loss = 0.03817781\n",
      "Iteration 980, loss = 0.03813384\n",
      "Iteration 981, loss = 0.03808834\n",
      "Iteration 982, loss = 0.03804277\n",
      "Iteration 983, loss = 0.03800081\n",
      "Iteration 984, loss = 0.03795587\n",
      "Iteration 985, loss = 0.03791341\n",
      "Iteration 986, loss = 0.03786945\n",
      "Iteration 987, loss = 0.03782650\n",
      "Iteration 988, loss = 0.03778984\n",
      "Iteration 989, loss = 0.03774435\n",
      "Iteration 990, loss = 0.03770843\n",
      "Iteration 991, loss = 0.03766380\n",
      "Iteration 992, loss = 0.03762151\n",
      "Iteration 993, loss = 0.03757997\n",
      "Iteration 994, loss = 0.03753888\n",
      "Iteration 995, loss = 0.03749600\n",
      "Iteration 996, loss = 0.03745658\n",
      "Iteration 997, loss = 0.03741588\n",
      "Iteration 998, loss = 0.03737505\n",
      "Iteration 999, loss = 0.03733351\n",
      "Iteration 1000, loss = 0.03729334\n",
      "Iteration 1001, loss = 0.03725455\n",
      "Iteration 1002, loss = 0.03721160\n",
      "Iteration 1003, loss = 0.03716994\n",
      "Iteration 1004, loss = 0.03712945\n",
      "Iteration 1005, loss = 0.03708957\n",
      "Iteration 1006, loss = 0.03704921\n",
      "Iteration 1007, loss = 0.03701107\n",
      "Iteration 1008, loss = 0.03696979\n",
      "Iteration 1009, loss = 0.03692899\n",
      "Iteration 1010, loss = 0.03688826\n",
      "Iteration 1011, loss = 0.03684796\n",
      "Iteration 1012, loss = 0.03680935\n",
      "Iteration 1013, loss = 0.03676934\n",
      "Iteration 1014, loss = 0.03672928\n",
      "Iteration 1015, loss = 0.03669178\n",
      "Iteration 1016, loss = 0.03665343\n",
      "Iteration 1017, loss = 0.03661374\n",
      "Iteration 1018, loss = 0.03657610\n",
      "Iteration 1019, loss = 0.03653781\n",
      "Iteration 1020, loss = 0.03649872\n",
      "Iteration 1021, loss = 0.03646051\n",
      "Iteration 1022, loss = 0.03642517\n",
      "Iteration 1023, loss = 0.03638352\n",
      "Iteration 1024, loss = 0.03634326\n",
      "Iteration 1025, loss = 0.03630253\n",
      "Iteration 1026, loss = 0.03626376\n",
      "Iteration 1027, loss = 0.03622463\n",
      "Iteration 1028, loss = 0.03618957\n",
      "Iteration 1029, loss = 0.03615161\n",
      "Iteration 1030, loss = 0.03610983\n",
      "Iteration 1031, loss = 0.03607188\n",
      "Iteration 1032, loss = 0.03603331\n",
      "Iteration 1033, loss = 0.03599673\n",
      "Iteration 1034, loss = 0.03595770\n",
      "Iteration 1035, loss = 0.03591911\n",
      "Iteration 1036, loss = 0.03588025\n",
      "Iteration 1037, loss = 0.03584296\n",
      "Iteration 1038, loss = 0.03580350\n",
      "Iteration 1039, loss = 0.03576957\n",
      "Iteration 1040, loss = 0.03572776\n",
      "Iteration 1041, loss = 0.03569220\n",
      "Iteration 1042, loss = 0.03565050\n",
      "Iteration 1043, loss = 0.03561483\n",
      "Iteration 1044, loss = 0.03557772\n",
      "Iteration 1045, loss = 0.03554027\n",
      "Iteration 1046, loss = 0.03550515\n",
      "Iteration 1047, loss = 0.03546839\n",
      "Iteration 1048, loss = 0.03543312\n",
      "Iteration 1049, loss = 0.03539491\n",
      "Iteration 1050, loss = 0.03535824\n",
      "Iteration 1051, loss = 0.03532072\n",
      "Iteration 1052, loss = 0.03528373\n",
      "Iteration 1053, loss = 0.03524988\n",
      "Iteration 1054, loss = 0.03521235\n",
      "Iteration 1055, loss = 0.03517530\n",
      "Iteration 1056, loss = 0.03513892\n",
      "Iteration 1057, loss = 0.03510339\n",
      "Iteration 1058, loss = 0.03506664\n",
      "Iteration 1059, loss = 0.03503164\n",
      "Iteration 1060, loss = 0.03499357\n",
      "Iteration 1061, loss = 0.03495739\n",
      "Iteration 1062, loss = 0.03492007\n",
      "Iteration 1063, loss = 0.03488385\n",
      "Iteration 1064, loss = 0.03484834\n",
      "Iteration 1065, loss = 0.03481378\n",
      "Iteration 1066, loss = 0.03477839\n",
      "Iteration 1067, loss = 0.03474095\n",
      "Iteration 1068, loss = 0.03470824\n",
      "Iteration 1069, loss = 0.03467406\n",
      "Iteration 1070, loss = 0.03464096\n",
      "Iteration 1071, loss = 0.03460649\n",
      "Iteration 1072, loss = 0.03457107\n",
      "Iteration 1073, loss = 0.03453532\n",
      "Iteration 1074, loss = 0.03450242\n",
      "Iteration 1075, loss = 0.03446591\n",
      "Iteration 1076, loss = 0.03443163\n",
      "Iteration 1077, loss = 0.03440097\n",
      "Iteration 1078, loss = 0.03436105\n",
      "Iteration 1079, loss = 0.03432622\n",
      "Iteration 1080, loss = 0.03429204\n",
      "Iteration 1081, loss = 0.03425766\n",
      "Iteration 1082, loss = 0.03421823\n",
      "Iteration 1083, loss = 0.03418216\n",
      "Iteration 1084, loss = 0.03414549\n",
      "Iteration 1085, loss = 0.03411075\n",
      "Iteration 1086, loss = 0.03407528\n",
      "Iteration 1087, loss = 0.03404180\n",
      "Iteration 1088, loss = 0.03400754\n",
      "Iteration 1089, loss = 0.03397321\n",
      "Iteration 1090, loss = 0.03393830\n",
      "Iteration 1091, loss = 0.03390725\n",
      "Iteration 1092, loss = 0.03386986\n",
      "Iteration 1093, loss = 0.03383669\n",
      "Iteration 1094, loss = 0.03380189\n",
      "Iteration 1095, loss = 0.03376550\n",
      "Iteration 1096, loss = 0.03373512\n",
      "Iteration 1097, loss = 0.03370062\n",
      "Iteration 1098, loss = 0.03366304\n",
      "Iteration 1099, loss = 0.03362513\n",
      "Iteration 1100, loss = 0.03359362\n",
      "Iteration 1101, loss = 0.03355635\n",
      "Iteration 1102, loss = 0.03352508\n",
      "Iteration 1103, loss = 0.03349204\n",
      "Iteration 1104, loss = 0.03345800\n",
      "Iteration 1105, loss = 0.03342763\n",
      "Iteration 1106, loss = 0.03339614\n",
      "Iteration 1107, loss = 0.03336304\n",
      "Iteration 1108, loss = 0.03332877\n",
      "Iteration 1109, loss = 0.03329981\n",
      "Iteration 1110, loss = 0.03327051\n",
      "Iteration 1111, loss = 0.03323651\n",
      "Iteration 1112, loss = 0.03320145\n",
      "Iteration 1113, loss = 0.03316980\n",
      "Iteration 1114, loss = 0.03313356\n",
      "Iteration 1115, loss = 0.03309971\n",
      "Iteration 1116, loss = 0.03306794\n",
      "Iteration 1117, loss = 0.03303103\n",
      "Iteration 1118, loss = 0.03300159\n",
      "Iteration 1119, loss = 0.03296650\n",
      "Iteration 1120, loss = 0.03293649\n",
      "Iteration 1121, loss = 0.03290297\n",
      "Iteration 1122, loss = 0.03287328\n",
      "Iteration 1123, loss = 0.03283923\n",
      "Iteration 1124, loss = 0.03280800\n",
      "Iteration 1125, loss = 0.03277918\n",
      "Iteration 1126, loss = 0.03274416\n",
      "Iteration 1127, loss = 0.03271303\n",
      "Iteration 1128, loss = 0.03268062\n",
      "Iteration 1129, loss = 0.03264834\n",
      "Iteration 1130, loss = 0.03261739\n",
      "Iteration 1131, loss = 0.03258629\n",
      "Iteration 1132, loss = 0.03255662\n",
      "Iteration 1133, loss = 0.03252530\n",
      "Iteration 1134, loss = 0.03249353\n",
      "Iteration 1135, loss = 0.03246285\n",
      "Iteration 1136, loss = 0.03243038\n",
      "Iteration 1137, loss = 0.03239960\n",
      "Iteration 1138, loss = 0.03236962\n",
      "Iteration 1139, loss = 0.03234141\n",
      "Iteration 1140, loss = 0.03231005\n",
      "Iteration 1141, loss = 0.03228068\n",
      "Iteration 1142, loss = 0.03224780\n",
      "Iteration 1143, loss = 0.03221516\n",
      "Iteration 1144, loss = 0.03218374\n",
      "Iteration 1145, loss = 0.03215110\n",
      "Iteration 1146, loss = 0.03212572\n",
      "Iteration 1147, loss = 0.03209458\n",
      "Iteration 1148, loss = 0.03206280\n",
      "Iteration 1149, loss = 0.03203058\n",
      "Iteration 1150, loss = 0.03200001\n",
      "Iteration 1151, loss = 0.03197113\n",
      "Iteration 1152, loss = 0.03193997\n",
      "Iteration 1153, loss = 0.03190990\n",
      "Iteration 1154, loss = 0.03188166\n",
      "Iteration 1155, loss = 0.03185261\n",
      "Iteration 1156, loss = 0.03182365\n",
      "Iteration 1157, loss = 0.03179559\n",
      "Iteration 1158, loss = 0.03176612\n",
      "Iteration 1159, loss = 0.03174057\n",
      "Iteration 1160, loss = 0.03171053\n",
      "Iteration 1161, loss = 0.03168136\n",
      "Iteration 1162, loss = 0.03165356\n",
      "Iteration 1163, loss = 0.03162459\n",
      "Iteration 1164, loss = 0.03159632\n",
      "Iteration 1165, loss = 0.03156883\n",
      "Iteration 1166, loss = 0.03153894\n",
      "Iteration 1167, loss = 0.03151154\n",
      "Iteration 1168, loss = 0.03148047\n",
      "Iteration 1169, loss = 0.03145353\n",
      "Iteration 1170, loss = 0.03142171\n",
      "Iteration 1171, loss = 0.03139340\n",
      "Iteration 1172, loss = 0.03136256\n",
      "Iteration 1173, loss = 0.03132827\n",
      "Iteration 1174, loss = 0.03129980\n",
      "Iteration 1175, loss = 0.03127027\n",
      "Iteration 1176, loss = 0.03123780\n",
      "Iteration 1177, loss = 0.03120790\n",
      "Iteration 1178, loss = 0.03117811\n",
      "Iteration 1179, loss = 0.03114798\n",
      "Iteration 1180, loss = 0.03111837\n",
      "Iteration 1181, loss = 0.03108959\n",
      "Iteration 1182, loss = 0.03105899\n",
      "Iteration 1183, loss = 0.03103059\n",
      "Iteration 1184, loss = 0.03100125\n",
      "Iteration 1185, loss = 0.03097218\n",
      "Iteration 1186, loss = 0.03094478\n",
      "Iteration 1187, loss = 0.03091493\n",
      "Iteration 1188, loss = 0.03088596\n",
      "Iteration 1189, loss = 0.03085720\n",
      "Iteration 1190, loss = 0.03082839\n",
      "Iteration 1191, loss = 0.03080496\n",
      "Iteration 1192, loss = 0.03077858\n",
      "Iteration 1193, loss = 0.03074934\n",
      "Iteration 1194, loss = 0.03072173\n",
      "Iteration 1195, loss = 0.03069363\n",
      "Iteration 1196, loss = 0.03066815\n",
      "Iteration 1197, loss = 0.03063929\n",
      "Iteration 1198, loss = 0.03061042\n",
      "Iteration 1199, loss = 0.03058320\n",
      "Iteration 1200, loss = 0.03055537\n",
      "Iteration 1201, loss = 0.03052755\n",
      "Iteration 1202, loss = 0.03050033\n",
      "Iteration 1203, loss = 0.03047340\n",
      "Iteration 1204, loss = 0.03044568\n",
      "Iteration 1205, loss = 0.03041542\n",
      "Iteration 1206, loss = 0.03038672\n",
      "Iteration 1207, loss = 0.03035589\n",
      "Iteration 1208, loss = 0.03032795\n",
      "Iteration 1209, loss = 0.03030258\n",
      "Iteration 1210, loss = 0.03027542\n",
      "Iteration 1211, loss = 0.03024356\n",
      "Iteration 1212, loss = 0.03021665\n",
      "Iteration 1213, loss = 0.03018657\n",
      "Iteration 1214, loss = 0.03016051\n",
      "Iteration 1215, loss = 0.03013262\n",
      "Iteration 1216, loss = 0.03010390\n",
      "Iteration 1217, loss = 0.03007247\n",
      "Iteration 1218, loss = 0.03004432\n",
      "Iteration 1219, loss = 0.03001571\n",
      "Iteration 1220, loss = 0.02998822\n",
      "Iteration 1221, loss = 0.02996167\n",
      "Iteration 1222, loss = 0.02993386\n",
      "Iteration 1223, loss = 0.02990528\n",
      "Iteration 1224, loss = 0.02987839\n",
      "Iteration 1225, loss = 0.02984589\n",
      "Iteration 1226, loss = 0.02982567\n",
      "Iteration 1227, loss = 0.02979708\n",
      "Iteration 1228, loss = 0.02976555\n",
      "Iteration 1229, loss = 0.02973660\n",
      "Iteration 1230, loss = 0.02971011\n",
      "Iteration 1231, loss = 0.02968285\n",
      "Iteration 1232, loss = 0.02965299\n",
      "Iteration 1233, loss = 0.02962599\n",
      "Iteration 1234, loss = 0.02959949\n",
      "Iteration 1235, loss = 0.02957096\n",
      "Iteration 1236, loss = 0.02954524\n",
      "Iteration 1237, loss = 0.02952209\n",
      "Iteration 1238, loss = 0.02949249\n",
      "Iteration 1239, loss = 0.02946501\n",
      "Iteration 1240, loss = 0.02944148\n",
      "Iteration 1241, loss = 0.02941989\n",
      "Iteration 1242, loss = 0.02938556\n",
      "Iteration 1243, loss = 0.02936233\n",
      "Iteration 1244, loss = 0.02934319\n",
      "Iteration 1245, loss = 0.02931195\n",
      "Iteration 1246, loss = 0.02928944\n",
      "Iteration 1247, loss = 0.02926139\n",
      "Iteration 1248, loss = 0.02923438\n",
      "Iteration 1249, loss = 0.02920839\n",
      "Iteration 1250, loss = 0.02918625\n",
      "Iteration 1251, loss = 0.02915757\n",
      "Iteration 1252, loss = 0.02913149\n",
      "Iteration 1253, loss = 0.02910467\n",
      "Iteration 1254, loss = 0.02907921\n",
      "Iteration 1255, loss = 0.02905710\n",
      "Iteration 1256, loss = 0.02903263\n",
      "Iteration 1257, loss = 0.02900119\n",
      "Iteration 1258, loss = 0.02897497\n",
      "Iteration 1259, loss = 0.02895300\n",
      "Iteration 1260, loss = 0.02892356\n",
      "Iteration 1261, loss = 0.02889915\n",
      "Iteration 1262, loss = 0.02887275\n",
      "Iteration 1263, loss = 0.02884817\n",
      "Iteration 1264, loss = 0.02882323\n",
      "Iteration 1265, loss = 0.02879789\n",
      "Iteration 1266, loss = 0.02877302\n",
      "Iteration 1267, loss = 0.02874945\n",
      "Iteration 1268, loss = 0.02872188\n",
      "Iteration 1269, loss = 0.02869931\n",
      "Iteration 1270, loss = 0.02867201\n",
      "Iteration 1271, loss = 0.02864556\n",
      "Iteration 1272, loss = 0.02862030\n",
      "Iteration 1273, loss = 0.02859787\n",
      "Iteration 1274, loss = 0.02857187\n",
      "Iteration 1275, loss = 0.02854694\n",
      "Iteration 1276, loss = 0.02852148\n",
      "Iteration 1277, loss = 0.02849730\n",
      "Iteration 1278, loss = 0.02847724\n",
      "Iteration 1279, loss = 0.02845126\n",
      "Iteration 1280, loss = 0.02842747\n",
      "Iteration 1281, loss = 0.02840368\n",
      "Iteration 1282, loss = 0.02837928\n",
      "Iteration 1283, loss = 0.02835442\n",
      "Iteration 1284, loss = 0.02832980\n",
      "Iteration 1285, loss = 0.02830665\n",
      "Iteration 1286, loss = 0.02828284\n",
      "Iteration 1287, loss = 0.02825888\n",
      "Iteration 1288, loss = 0.02823421\n",
      "Iteration 1289, loss = 0.02821273\n",
      "Iteration 1290, loss = 0.02818613\n",
      "Iteration 1291, loss = 0.02816443\n",
      "Iteration 1292, loss = 0.02813995\n",
      "Iteration 1293, loss = 0.02811312\n",
      "Iteration 1294, loss = 0.02809105\n",
      "Iteration 1295, loss = 0.02806332\n",
      "Iteration 1296, loss = 0.02804132\n",
      "Iteration 1297, loss = 0.02801125\n",
      "Iteration 1298, loss = 0.02798560\n",
      "Iteration 1299, loss = 0.02796251\n",
      "Iteration 1300, loss = 0.02793544\n",
      "Iteration 1301, loss = 0.02790946\n",
      "Iteration 1302, loss = 0.02788472\n",
      "Iteration 1303, loss = 0.02786278\n",
      "Iteration 1304, loss = 0.02783722\n",
      "Iteration 1305, loss = 0.02781112\n",
      "Iteration 1306, loss = 0.02778577\n",
      "Iteration 1307, loss = 0.02776193\n",
      "Iteration 1308, loss = 0.02773646\n",
      "Iteration 1309, loss = 0.02771333\n",
      "Iteration 1310, loss = 0.02768845\n",
      "Iteration 1311, loss = 0.02766310\n",
      "Iteration 1312, loss = 0.02764022\n",
      "Iteration 1313, loss = 0.02761438\n",
      "Iteration 1314, loss = 0.02759035\n",
      "Iteration 1315, loss = 0.02756675\n",
      "Iteration 1316, loss = 0.02754252\n",
      "Iteration 1317, loss = 0.02751847\n",
      "Iteration 1318, loss = 0.02749627\n",
      "Iteration 1319, loss = 0.02747466\n",
      "Iteration 1320, loss = 0.02744691\n",
      "Iteration 1321, loss = 0.02742224\n",
      "Iteration 1322, loss = 0.02739809\n",
      "Iteration 1323, loss = 0.02737662\n",
      "Iteration 1324, loss = 0.02735204\n",
      "Iteration 1325, loss = 0.02732962\n",
      "Iteration 1326, loss = 0.02730720\n",
      "Iteration 1327, loss = 0.02729077\n",
      "Iteration 1328, loss = 0.02725907\n",
      "Iteration 1329, loss = 0.02723693\n",
      "Iteration 1330, loss = 0.02721074\n",
      "Iteration 1331, loss = 0.02719343\n",
      "Iteration 1332, loss = 0.02716691\n",
      "Iteration 1333, loss = 0.02714087\n",
      "Iteration 1334, loss = 0.02711712\n",
      "Iteration 1335, loss = 0.02709578\n",
      "Iteration 1336, loss = 0.02707078\n",
      "Iteration 1337, loss = 0.02705224\n",
      "Iteration 1338, loss = 0.02702593\n",
      "Iteration 1339, loss = 0.02700361\n",
      "Iteration 1340, loss = 0.02698311\n",
      "Iteration 1341, loss = 0.02695845\n",
      "Iteration 1342, loss = 0.02693554\n",
      "Iteration 1343, loss = 0.02691273\n",
      "Iteration 1344, loss = 0.02689437\n",
      "Iteration 1345, loss = 0.02687062\n",
      "Iteration 1346, loss = 0.02684715\n",
      "Iteration 1347, loss = 0.02682563\n",
      "Iteration 1348, loss = 0.02680416\n",
      "Iteration 1349, loss = 0.02678347\n",
      "Iteration 1350, loss = 0.02675867\n",
      "Iteration 1351, loss = 0.02673705\n",
      "Iteration 1352, loss = 0.02671237\n",
      "Iteration 1353, loss = 0.02669035\n",
      "Iteration 1354, loss = 0.02666710\n",
      "Iteration 1355, loss = 0.02664393\n",
      "Iteration 1356, loss = 0.02662400\n",
      "Iteration 1357, loss = 0.02659989\n",
      "Iteration 1358, loss = 0.02657896\n",
      "Iteration 1359, loss = 0.02656136\n",
      "Iteration 1360, loss = 0.02653365\n",
      "Iteration 1361, loss = 0.02651420\n",
      "Iteration 1362, loss = 0.02649394\n",
      "Iteration 1363, loss = 0.02646939\n",
      "Iteration 1364, loss = 0.02644719\n",
      "Iteration 1365, loss = 0.02642458\n",
      "Iteration 1366, loss = 0.02640275\n",
      "Iteration 1367, loss = 0.02638053\n",
      "Iteration 1368, loss = 0.02635879\n",
      "Iteration 1369, loss = 0.02633688\n",
      "Iteration 1370, loss = 0.02631681\n",
      "Iteration 1371, loss = 0.02629407\n",
      "Iteration 1372, loss = 0.02627179\n",
      "Iteration 1373, loss = 0.02625047\n",
      "Iteration 1374, loss = 0.02622844\n",
      "Iteration 1375, loss = 0.02620757\n",
      "Iteration 1376, loss = 0.02618710\n",
      "Iteration 1377, loss = 0.02616588\n",
      "Iteration 1378, loss = 0.02614600\n",
      "Iteration 1379, loss = 0.02612488\n",
      "Iteration 1380, loss = 0.02610425\n",
      "Iteration 1381, loss = 0.02608338\n",
      "Iteration 1382, loss = 0.02606237\n",
      "Iteration 1383, loss = 0.02604179\n",
      "Iteration 1384, loss = 0.02602133\n",
      "Iteration 1385, loss = 0.02599843\n",
      "Iteration 1386, loss = 0.02597503\n",
      "Iteration 1387, loss = 0.02595509\n",
      "Iteration 1388, loss = 0.02593345\n",
      "Iteration 1389, loss = 0.02591118\n",
      "Iteration 1390, loss = 0.02589061\n",
      "Iteration 1391, loss = 0.02586867\n",
      "Iteration 1392, loss = 0.02584651\n",
      "Iteration 1393, loss = 0.02582527\n",
      "Iteration 1394, loss = 0.02580767\n",
      "Iteration 1395, loss = 0.02578680\n",
      "Iteration 1396, loss = 0.02576816\n",
      "Iteration 1397, loss = 0.02574567\n",
      "Iteration 1398, loss = 0.02572492\n",
      "Iteration 1399, loss = 0.02570431\n",
      "Iteration 1400, loss = 0.02568443\n",
      "Iteration 1401, loss = 0.02566336\n",
      "Iteration 1402, loss = 0.02564103\n",
      "Iteration 1403, loss = 0.02562017\n",
      "Iteration 1404, loss = 0.02559955\n",
      "Iteration 1405, loss = 0.02558040\n",
      "Iteration 1406, loss = 0.02555917\n",
      "Iteration 1407, loss = 0.02553838\n",
      "Iteration 1408, loss = 0.02551920\n",
      "Iteration 1409, loss = 0.02550027\n",
      "Iteration 1410, loss = 0.02547770\n",
      "Iteration 1411, loss = 0.02545813\n",
      "Iteration 1412, loss = 0.02543910\n",
      "Iteration 1413, loss = 0.02542207\n",
      "Iteration 1414, loss = 0.02539935\n",
      "Iteration 1415, loss = 0.02537968\n",
      "Iteration 1416, loss = 0.02536059\n",
      "Iteration 1417, loss = 0.02534154\n",
      "Iteration 1418, loss = 0.02532181\n",
      "Iteration 1419, loss = 0.02530550\n",
      "Iteration 1420, loss = 0.02528668\n",
      "Iteration 1421, loss = 0.02526393\n",
      "Iteration 1422, loss = 0.02524344\n",
      "Iteration 1423, loss = 0.02522399\n",
      "Iteration 1424, loss = 0.02520290\n",
      "Iteration 1425, loss = 0.02518324\n",
      "Iteration 1426, loss = 0.02516412\n",
      "Iteration 1427, loss = 0.02514494\n",
      "Iteration 1428, loss = 0.02512967\n",
      "Iteration 1429, loss = 0.02510570\n",
      "Iteration 1430, loss = 0.02508379\n",
      "Iteration 1431, loss = 0.02506273\n",
      "Iteration 1432, loss = 0.02504379\n",
      "Iteration 1433, loss = 0.02502137\n",
      "Iteration 1434, loss = 0.02500010\n",
      "Iteration 1435, loss = 0.02498606\n",
      "Iteration 1436, loss = 0.02496185\n",
      "Iteration 1437, loss = 0.02494128\n",
      "Iteration 1438, loss = 0.02492393\n",
      "Iteration 1439, loss = 0.02490271\n",
      "Iteration 1440, loss = 0.02488684\n",
      "Iteration 1441, loss = 0.02486422\n",
      "Iteration 1442, loss = 0.02484321\n",
      "Iteration 1443, loss = 0.02482344\n",
      "Iteration 1444, loss = 0.02480517\n",
      "Iteration 1445, loss = 0.02478599\n",
      "Iteration 1446, loss = 0.02476732\n",
      "Iteration 1447, loss = 0.02474446\n",
      "Iteration 1448, loss = 0.02472477\n",
      "Iteration 1449, loss = 0.02470455\n",
      "Iteration 1450, loss = 0.02468777\n",
      "Iteration 1451, loss = 0.02466838\n",
      "Iteration 1452, loss = 0.02465023\n",
      "Iteration 1453, loss = 0.02462955\n",
      "Iteration 1454, loss = 0.02461313\n",
      "Iteration 1455, loss = 0.02459120\n",
      "Iteration 1456, loss = 0.02457268\n",
      "Iteration 1457, loss = 0.02455413\n",
      "Iteration 1458, loss = 0.02453474\n",
      "Iteration 1459, loss = 0.02451671\n",
      "Iteration 1460, loss = 0.02449652\n",
      "Iteration 1461, loss = 0.02447680\n",
      "Iteration 1462, loss = 0.02446112\n",
      "Iteration 1463, loss = 0.02444134\n",
      "Iteration 1464, loss = 0.02442061\n",
      "Iteration 1465, loss = 0.02440032\n",
      "Iteration 1466, loss = 0.02438088\n",
      "Iteration 1467, loss = 0.02436105\n",
      "Iteration 1468, loss = 0.02434294\n",
      "Iteration 1469, loss = 0.02432386\n",
      "Iteration 1470, loss = 0.02430423\n",
      "Iteration 1471, loss = 0.02428502\n",
      "Iteration 1472, loss = 0.02426238\n",
      "Iteration 1473, loss = 0.02424531\n",
      "Iteration 1474, loss = 0.02422836\n",
      "Iteration 1475, loss = 0.02421608\n",
      "Iteration 1476, loss = 0.02419358\n",
      "Iteration 1477, loss = 0.02417549\n",
      "Iteration 1478, loss = 0.02415888\n",
      "Iteration 1479, loss = 0.02414012\n",
      "Iteration 1480, loss = 0.02412696\n",
      "Iteration 1481, loss = 0.02410591\n",
      "Iteration 1482, loss = 0.02408788\n",
      "Iteration 1483, loss = 0.02406834\n",
      "Iteration 1484, loss = 0.02404913\n",
      "Iteration 1485, loss = 0.02403035\n",
      "Iteration 1486, loss = 0.02401141\n",
      "Iteration 1487, loss = 0.02399294\n",
      "Iteration 1488, loss = 0.02397346\n",
      "Iteration 1489, loss = 0.02395569\n",
      "Iteration 1490, loss = 0.02393698\n",
      "Iteration 1491, loss = 0.02392014\n",
      "Iteration 1492, loss = 0.02390065\n",
      "Iteration 1493, loss = 0.02388324\n",
      "Iteration 1494, loss = 0.02386505\n",
      "Iteration 1495, loss = 0.02384823\n",
      "Iteration 1496, loss = 0.02383056\n",
      "Iteration 1497, loss = 0.02381349\n",
      "Iteration 1498, loss = 0.02379499\n",
      "Iteration 1499, loss = 0.02377589\n",
      "Iteration 1500, loss = 0.02375623\n",
      "Iteration 1501, loss = 0.02373954\n",
      "Iteration 1502, loss = 0.02372046\n",
      "Iteration 1503, loss = 0.02370244\n",
      "Iteration 1504, loss = 0.02368317\n",
      "Iteration 1505, loss = 0.02366442\n",
      "Iteration 1506, loss = 0.02364609\n",
      "Iteration 1507, loss = 0.02362551\n",
      "Iteration 1508, loss = 0.02360408\n",
      "Iteration 1509, loss = 0.02358651\n",
      "Iteration 1510, loss = 0.02357148\n",
      "Iteration 1511, loss = 0.02354810\n",
      "Iteration 1512, loss = 0.02353240\n",
      "Iteration 1513, loss = 0.02351253\n",
      "Iteration 1514, loss = 0.02349515\n",
      "Iteration 1515, loss = 0.02347916\n",
      "Iteration 1516, loss = 0.02346036\n",
      "Iteration 1517, loss = 0.02344387\n",
      "Iteration 1518, loss = 0.02342525\n",
      "Iteration 1519, loss = 0.02341169\n",
      "Iteration 1520, loss = 0.02339144\n",
      "Iteration 1521, loss = 0.02337491\n",
      "Iteration 1522, loss = 0.02335669\n",
      "Iteration 1523, loss = 0.02334024\n",
      "Iteration 1524, loss = 0.02332359\n",
      "Iteration 1525, loss = 0.02330542\n",
      "Iteration 1526, loss = 0.02328640\n",
      "Iteration 1527, loss = 0.02326835\n",
      "Iteration 1528, loss = 0.02324999\n",
      "Iteration 1529, loss = 0.02323202\n",
      "Iteration 1530, loss = 0.02321565\n",
      "Iteration 1531, loss = 0.02319723\n",
      "Iteration 1532, loss = 0.02318137\n",
      "Iteration 1533, loss = 0.02316440\n",
      "Iteration 1534, loss = 0.02314655\n",
      "Iteration 1535, loss = 0.02312928\n",
      "Iteration 1536, loss = 0.02311217\n",
      "Iteration 1537, loss = 0.02309548\n",
      "Iteration 1538, loss = 0.02308009\n",
      "Iteration 1539, loss = 0.02306368\n",
      "Iteration 1540, loss = 0.02304712\n",
      "Iteration 1541, loss = 0.02303068\n",
      "Iteration 1542, loss = 0.02301398\n",
      "Iteration 1543, loss = 0.02299778\n",
      "Iteration 1544, loss = 0.02298110\n",
      "Iteration 1545, loss = 0.02296480\n",
      "Iteration 1546, loss = 0.02294833\n",
      "Iteration 1547, loss = 0.02293405\n",
      "Iteration 1548, loss = 0.02291610\n",
      "Iteration 1549, loss = 0.02289893\n",
      "Iteration 1550, loss = 0.02288270\n",
      "Iteration 1551, loss = 0.02286645\n",
      "Iteration 1552, loss = 0.02285009\n",
      "Iteration 1553, loss = 0.02283504\n",
      "Iteration 1554, loss = 0.02281743\n",
      "Iteration 1555, loss = 0.02280246\n",
      "Iteration 1556, loss = 0.02278531\n",
      "Iteration 1557, loss = 0.02276911\n",
      "Iteration 1558, loss = 0.02275196\n",
      "Iteration 1559, loss = 0.02273585\n",
      "Iteration 1560, loss = 0.02272032\n",
      "Iteration 1561, loss = 0.02270077\n",
      "Iteration 1562, loss = 0.02268369\n",
      "Iteration 1563, loss = 0.02266577\n",
      "Iteration 1564, loss = 0.02264839\n",
      "Iteration 1565, loss = 0.02263177\n",
      "Iteration 1566, loss = 0.02261622\n",
      "Iteration 1567, loss = 0.02259922\n",
      "Iteration 1568, loss = 0.02258365\n",
      "Iteration 1569, loss = 0.02256712\n",
      "Iteration 1570, loss = 0.02255173\n",
      "Iteration 1571, loss = 0.02253517\n",
      "Iteration 1572, loss = 0.02251823\n",
      "Iteration 1573, loss = 0.02250243\n",
      "Iteration 1574, loss = 0.02248318\n",
      "Iteration 1575, loss = 0.02246956\n",
      "Iteration 1576, loss = 0.02245056\n",
      "Iteration 1577, loss = 0.02243689\n",
      "Iteration 1578, loss = 0.02241925\n",
      "Iteration 1579, loss = 0.02240382\n",
      "Iteration 1580, loss = 0.02238767\n",
      "Iteration 1581, loss = 0.02237231\n",
      "Iteration 1582, loss = 0.02235644\n",
      "Iteration 1583, loss = 0.02233944\n",
      "Iteration 1584, loss = 0.02232459\n",
      "Iteration 1585, loss = 0.02230903\n",
      "Iteration 1586, loss = 0.02229393\n",
      "Iteration 1587, loss = 0.02227924\n",
      "Iteration 1588, loss = 0.02226159\n",
      "Iteration 1589, loss = 0.02224592\n",
      "Iteration 1590, loss = 0.02223114\n",
      "Iteration 1591, loss = 0.02221682\n",
      "Iteration 1592, loss = 0.02219767\n",
      "Iteration 1593, loss = 0.02218411\n",
      "Iteration 1594, loss = 0.02216717\n",
      "Iteration 1595, loss = 0.02215341\n",
      "Iteration 1596, loss = 0.02213721\n",
      "Iteration 1597, loss = 0.02212066\n",
      "Iteration 1598, loss = 0.02210384\n",
      "Iteration 1599, loss = 0.02208585\n",
      "Iteration 1600, loss = 0.02207288\n",
      "Iteration 1601, loss = 0.02205379\n",
      "Iteration 1602, loss = 0.02203760\n",
      "Iteration 1603, loss = 0.02202124\n",
      "Iteration 1604, loss = 0.02200425\n",
      "Iteration 1605, loss = 0.02198735\n",
      "Iteration 1606, loss = 0.02197344\n",
      "Iteration 1607, loss = 0.02195467\n",
      "Iteration 1608, loss = 0.02193734\n",
      "Iteration 1609, loss = 0.02192122\n",
      "Iteration 1610, loss = 0.02190579\n",
      "Iteration 1611, loss = 0.02189187\n",
      "Iteration 1612, loss = 0.02187462\n",
      "Iteration 1613, loss = 0.02186007\n",
      "Iteration 1614, loss = 0.02184508\n",
      "Iteration 1615, loss = 0.02182944\n",
      "Iteration 1616, loss = 0.02181327\n",
      "Iteration 1617, loss = 0.02180201\n",
      "Iteration 1618, loss = 0.02178278\n",
      "Iteration 1619, loss = 0.02176617\n",
      "Iteration 1620, loss = 0.02175225\n",
      "Iteration 1621, loss = 0.02173573\n",
      "Iteration 1622, loss = 0.02171923\n",
      "Iteration 1623, loss = 0.02170551\n",
      "Iteration 1624, loss = 0.02168783\n",
      "Iteration 1625, loss = 0.02167294\n",
      "Iteration 1626, loss = 0.02165629\n",
      "Iteration 1627, loss = 0.02164016\n",
      "Iteration 1628, loss = 0.02162483\n",
      "Iteration 1629, loss = 0.02160777\n",
      "Iteration 1630, loss = 0.02159273\n",
      "Iteration 1631, loss = 0.02157446\n",
      "Iteration 1632, loss = 0.02155839\n",
      "Iteration 1633, loss = 0.02154300\n",
      "Iteration 1634, loss = 0.02152546\n",
      "Iteration 1635, loss = 0.02151071\n",
      "Iteration 1636, loss = 0.02149227\n",
      "Iteration 1637, loss = 0.02147690\n",
      "Iteration 1638, loss = 0.02146177\n",
      "Iteration 1639, loss = 0.02144506\n",
      "Iteration 1640, loss = 0.02142896\n",
      "Iteration 1641, loss = 0.02141293\n",
      "Iteration 1642, loss = 0.02139784\n",
      "Iteration 1643, loss = 0.02138197\n",
      "Iteration 1644, loss = 0.02136665\n",
      "Iteration 1645, loss = 0.02135303\n",
      "Iteration 1646, loss = 0.02133792\n",
      "Iteration 1647, loss = 0.02132189\n",
      "Iteration 1648, loss = 0.02131073\n",
      "Iteration 1649, loss = 0.02129249\n",
      "Iteration 1650, loss = 0.02127841\n",
      "Iteration 1651, loss = 0.02126471\n",
      "Iteration 1652, loss = 0.02124903\n",
      "Iteration 1653, loss = 0.02123569\n",
      "Iteration 1654, loss = 0.02122119\n",
      "Iteration 1655, loss = 0.02120672\n",
      "Iteration 1656, loss = 0.02119117\n",
      "Iteration 1657, loss = 0.02117618\n",
      "Iteration 1658, loss = 0.02116046\n",
      "Iteration 1659, loss = 0.02114392\n",
      "Iteration 1660, loss = 0.02113126\n",
      "Iteration 1661, loss = 0.02111538\n",
      "Iteration 1662, loss = 0.02109832\n",
      "Iteration 1663, loss = 0.02108416\n",
      "Iteration 1664, loss = 0.02107024\n",
      "Iteration 1665, loss = 0.02105486\n",
      "Iteration 1666, loss = 0.02103979\n",
      "Iteration 1667, loss = 0.02102583\n",
      "Iteration 1668, loss = 0.02101298\n",
      "Iteration 1669, loss = 0.02099723\n",
      "Iteration 1670, loss = 0.02098321\n",
      "Iteration 1671, loss = 0.02096861\n",
      "Iteration 1672, loss = 0.02095414\n",
      "Iteration 1673, loss = 0.02094022\n",
      "Iteration 1674, loss = 0.02092674\n",
      "Iteration 1675, loss = 0.02091579\n",
      "Iteration 1676, loss = 0.02089936\n",
      "Iteration 1677, loss = 0.02088720\n",
      "Iteration 1678, loss = 0.02087038\n",
      "Iteration 1679, loss = 0.02085559\n",
      "Iteration 1680, loss = 0.02084285\n",
      "Iteration 1681, loss = 0.02082503\n",
      "Iteration 1682, loss = 0.02081117\n",
      "Iteration 1683, loss = 0.02079576\n",
      "Iteration 1684, loss = 0.02078332\n",
      "Iteration 1685, loss = 0.02076983\n",
      "Iteration 1686, loss = 0.02075518\n",
      "Iteration 1687, loss = 0.02073884\n",
      "Iteration 1688, loss = 0.02072408\n",
      "Iteration 1689, loss = 0.02071033\n",
      "Iteration 1690, loss = 0.02069768\n",
      "Iteration 1691, loss = 0.02068212\n",
      "Iteration 1692, loss = 0.02066835\n",
      "Iteration 1693, loss = 0.02065450\n",
      "Iteration 1694, loss = 0.02064031\n",
      "Iteration 1695, loss = 0.02062658\n",
      "Iteration 1696, loss = 0.02061273\n",
      "Iteration 1697, loss = 0.02059736\n",
      "Iteration 1698, loss = 0.02058436\n",
      "Iteration 1699, loss = 0.02057161\n",
      "Iteration 1700, loss = 0.02055747\n",
      "Iteration 1701, loss = 0.02054386\n",
      "Iteration 1702, loss = 0.02053034\n",
      "Iteration 1703, loss = 0.02051598\n",
      "Iteration 1704, loss = 0.02050557\n",
      "Iteration 1705, loss = 0.02048920\n",
      "Iteration 1706, loss = 0.02047533\n",
      "Iteration 1707, loss = 0.02046251\n",
      "Iteration 1708, loss = 0.02044826\n",
      "Iteration 1709, loss = 0.02043430\n",
      "Iteration 1710, loss = 0.02042124\n",
      "Iteration 1711, loss = 0.02040672\n",
      "Iteration 1712, loss = 0.02039955\n",
      "Iteration 1713, loss = 0.02038214\n",
      "Iteration 1714, loss = 0.02036747\n",
      "Iteration 1715, loss = 0.02035458\n",
      "Iteration 1716, loss = 0.02034061\n",
      "Iteration 1717, loss = 0.02032431\n",
      "Iteration 1718, loss = 0.02031179\n",
      "Iteration 1719, loss = 0.02029404\n",
      "Iteration 1720, loss = 0.02028010\n",
      "Iteration 1721, loss = 0.02026530\n",
      "Iteration 1722, loss = 0.02024998\n",
      "Iteration 1723, loss = 0.02023566\n",
      "Iteration 1724, loss = 0.02022153\n",
      "Iteration 1725, loss = 0.02020791\n",
      "Iteration 1726, loss = 0.02019503\n",
      "Iteration 1727, loss = 0.02018094\n",
      "Iteration 1728, loss = 0.02016886\n",
      "Iteration 1729, loss = 0.02015320\n",
      "Iteration 1730, loss = 0.02013793\n",
      "Iteration 1731, loss = 0.02012394\n",
      "Iteration 1732, loss = 0.02010929\n",
      "Iteration 1733, loss = 0.02009833\n",
      "Iteration 1734, loss = 0.02008084\n",
      "Iteration 1735, loss = 0.02006639\n",
      "Iteration 1736, loss = 0.02005245\n",
      "Iteration 1737, loss = 0.02003637\n",
      "Iteration 1738, loss = 0.02002189\n",
      "Iteration 1739, loss = 0.02000897\n",
      "Iteration 1740, loss = 0.01999363\n",
      "Iteration 1741, loss = 0.01997829\n",
      "Iteration 1742, loss = 0.01996439\n",
      "Iteration 1743, loss = 0.01995013\n",
      "Iteration 1744, loss = 0.01993722\n",
      "Iteration 1745, loss = 0.01992253\n",
      "Iteration 1746, loss = 0.01990790\n",
      "Iteration 1747, loss = 0.01989574\n",
      "Iteration 1748, loss = 0.01988280\n",
      "Iteration 1749, loss = 0.01986970\n",
      "Iteration 1750, loss = 0.01986008\n",
      "Iteration 1751, loss = 0.01984474\n",
      "Iteration 1752, loss = 0.01983113\n",
      "Iteration 1753, loss = 0.01981756\n",
      "Iteration 1754, loss = 0.01980498\n",
      "Iteration 1755, loss = 0.01979209\n",
      "Iteration 1756, loss = 0.01978145\n",
      "Iteration 1757, loss = 0.01976781\n",
      "Iteration 1758, loss = 0.01975578\n",
      "Iteration 1759, loss = 0.01974411\n",
      "Iteration 1760, loss = 0.01973016\n",
      "Iteration 1761, loss = 0.01971840\n",
      "Iteration 1762, loss = 0.01970628\n",
      "Iteration 1763, loss = 0.01969422\n",
      "Iteration 1764, loss = 0.01968230\n",
      "Iteration 1765, loss = 0.01967170\n",
      "Iteration 1766, loss = 0.01965873\n",
      "Iteration 1767, loss = 0.01964692\n",
      "Iteration 1768, loss = 0.01963537\n",
      "Iteration 1769, loss = 0.01962109\n",
      "Iteration 1770, loss = 0.01960924\n",
      "Iteration 1771, loss = 0.01959608\n",
      "Iteration 1772, loss = 0.01958516\n",
      "Iteration 1773, loss = 0.01957229\n",
      "Iteration 1774, loss = 0.01955985\n",
      "Iteration 1775, loss = 0.01954676\n",
      "Iteration 1776, loss = 0.01953357\n",
      "Iteration 1777, loss = 0.01952057\n",
      "Iteration 1778, loss = 0.01950897\n",
      "Iteration 1779, loss = 0.01949757\n",
      "Iteration 1780, loss = 0.01948259\n",
      "Iteration 1781, loss = 0.01946829\n",
      "Iteration 1782, loss = 0.01945429\n",
      "Iteration 1783, loss = 0.01944031\n",
      "Iteration 1784, loss = 0.01942936\n",
      "Iteration 1785, loss = 0.01941325\n",
      "Iteration 1786, loss = 0.01940257\n",
      "Iteration 1787, loss = 0.01938725\n",
      "Iteration 1788, loss = 0.01937370\n",
      "Iteration 1789, loss = 0.01936365\n",
      "Iteration 1790, loss = 0.01935212\n",
      "Iteration 1791, loss = 0.01933756\n",
      "Iteration 1792, loss = 0.01932614\n",
      "Iteration 1793, loss = 0.01931473\n",
      "Iteration 1794, loss = 0.01930341\n",
      "Iteration 1795, loss = 0.01929282\n",
      "Iteration 1796, loss = 0.01928216\n",
      "Iteration 1797, loss = 0.01926899\n",
      "Iteration 1798, loss = 0.01925611\n",
      "Iteration 1799, loss = 0.01924309\n",
      "Iteration 1800, loss = 0.01923116\n",
      "Iteration 1801, loss = 0.01921860\n",
      "Iteration 1802, loss = 0.01920715\n",
      "Iteration 1803, loss = 0.01919586\n",
      "Iteration 1804, loss = 0.01918333\n",
      "Iteration 1805, loss = 0.01917299\n",
      "Iteration 1806, loss = 0.01916030\n",
      "Iteration 1807, loss = 0.01914721\n",
      "Iteration 1808, loss = 0.01913487\n",
      "Iteration 1809, loss = 0.01912543\n",
      "Iteration 1810, loss = 0.01911088\n",
      "Iteration 1811, loss = 0.01909876\n",
      "Iteration 1812, loss = 0.01908720\n",
      "Iteration 1813, loss = 0.01907491\n",
      "Iteration 1814, loss = 0.01906316\n",
      "Iteration 1815, loss = 0.01905216\n",
      "Iteration 1816, loss = 0.01903888\n",
      "Iteration 1817, loss = 0.01902827\n",
      "Iteration 1818, loss = 0.01901383\n",
      "Iteration 1819, loss = 0.01900222\n",
      "Iteration 1820, loss = 0.01898854\n",
      "Iteration 1821, loss = 0.01897727\n",
      "Iteration 1822, loss = 0.01896534\n",
      "Iteration 1823, loss = 0.01895242\n",
      "Iteration 1824, loss = 0.01894044\n",
      "Iteration 1825, loss = 0.01892832\n",
      "Iteration 1826, loss = 0.01891777\n",
      "Iteration 1827, loss = 0.01890636\n",
      "Iteration 1828, loss = 0.01889355\n",
      "Iteration 1829, loss = 0.01888254\n",
      "Iteration 1830, loss = 0.01887120\n",
      "Iteration 1831, loss = 0.01886099\n",
      "Iteration 1832, loss = 0.01885147\n",
      "Iteration 1833, loss = 0.01884158\n",
      "Iteration 1834, loss = 0.01882983\n",
      "Iteration 1835, loss = 0.01881880\n",
      "Iteration 1836, loss = 0.01880691\n",
      "Iteration 1837, loss = 0.01879790\n",
      "Iteration 1838, loss = 0.01878573\n",
      "Iteration 1839, loss = 0.01877605\n",
      "Iteration 1840, loss = 0.01876860\n",
      "Iteration 1841, loss = 0.01875129\n",
      "Iteration 1842, loss = 0.01874080\n",
      "Iteration 1843, loss = 0.01872786\n",
      "Iteration 1844, loss = 0.01871493\n",
      "Iteration 1845, loss = 0.01870334\n",
      "Iteration 1846, loss = 0.01869341\n",
      "Iteration 1847, loss = 0.01868195\n",
      "Iteration 1848, loss = 0.01867030\n",
      "Iteration 1849, loss = 0.01865990\n",
      "Iteration 1850, loss = 0.01864866\n",
      "Iteration 1851, loss = 0.01863824\n",
      "Iteration 1852, loss = 0.01862661\n",
      "Iteration 1853, loss = 0.01861746\n",
      "Iteration 1854, loss = 0.01860587\n",
      "Iteration 1855, loss = 0.01859319\n",
      "Iteration 1856, loss = 0.01858112\n",
      "Iteration 1857, loss = 0.01856924\n",
      "Iteration 1858, loss = 0.01855810\n",
      "Iteration 1859, loss = 0.01854577\n",
      "Iteration 1860, loss = 0.01853624\n",
      "Iteration 1861, loss = 0.01852661\n",
      "Iteration 1862, loss = 0.01851709\n",
      "Iteration 1863, loss = 0.01850449\n",
      "Iteration 1864, loss = 0.01849307\n",
      "Iteration 1865, loss = 0.01848177\n",
      "Iteration 1866, loss = 0.01846842\n",
      "Iteration 1867, loss = 0.01845513\n",
      "Iteration 1868, loss = 0.01844079\n",
      "Iteration 1869, loss = 0.01842859\n",
      "Iteration 1870, loss = 0.01841270\n",
      "Iteration 1871, loss = 0.01840423\n",
      "Iteration 1872, loss = 0.01838937\n",
      "Iteration 1873, loss = 0.01837471\n",
      "Iteration 1874, loss = 0.01836285\n",
      "Iteration 1875, loss = 0.01835175\n",
      "Iteration 1876, loss = 0.01833933\n",
      "Iteration 1877, loss = 0.01832736\n",
      "Iteration 1878, loss = 0.01831525\n",
      "Iteration 1879, loss = 0.01830407\n",
      "Iteration 1880, loss = 0.01829181\n",
      "Iteration 1881, loss = 0.01828110\n",
      "Iteration 1882, loss = 0.01827260\n",
      "Iteration 1883, loss = 0.01825996\n",
      "Iteration 1884, loss = 0.01824733\n",
      "Iteration 1885, loss = 0.01823659\n",
      "Iteration 1886, loss = 0.01822350\n",
      "Iteration 1887, loss = 0.01821112\n",
      "Iteration 1888, loss = 0.01819993\n",
      "Iteration 1889, loss = 0.01818745\n",
      "Iteration 1890, loss = 0.01817399\n",
      "Iteration 1891, loss = 0.01816780\n",
      "Iteration 1892, loss = 0.01815306\n",
      "Iteration 1893, loss = 0.01814133\n",
      "Iteration 1894, loss = 0.01813325\n",
      "Iteration 1895, loss = 0.01811997\n",
      "Iteration 1896, loss = 0.01810899\n",
      "Iteration 1897, loss = 0.01809809\n",
      "Iteration 1898, loss = 0.01808706\n",
      "Iteration 1899, loss = 0.01807653\n",
      "Iteration 1900, loss = 0.01806557\n",
      "Iteration 1901, loss = 0.01805442\n",
      "Iteration 1902, loss = 0.01804472\n",
      "Iteration 1903, loss = 0.01803318\n",
      "Iteration 1904, loss = 0.01802202\n",
      "Iteration 1905, loss = 0.01801068\n",
      "Iteration 1906, loss = 0.01799945\n",
      "Iteration 1907, loss = 0.01798820\n",
      "Iteration 1908, loss = 0.01797868\n",
      "Iteration 1909, loss = 0.01796607\n",
      "Iteration 1910, loss = 0.01795419\n",
      "Iteration 1911, loss = 0.01794235\n",
      "Iteration 1912, loss = 0.01793199\n",
      "Iteration 1913, loss = 0.01791870\n",
      "Iteration 1914, loss = 0.01790871\n",
      "Iteration 1915, loss = 0.01789737\n",
      "Iteration 1916, loss = 0.01788908\n",
      "Iteration 1917, loss = 0.01787742\n",
      "Iteration 1918, loss = 0.01786489\n",
      "Iteration 1919, loss = 0.01785418\n",
      "Iteration 1920, loss = 0.01784455\n",
      "Iteration 1921, loss = 0.01783151\n",
      "Iteration 1922, loss = 0.01782017\n",
      "Iteration 1923, loss = 0.01781077\n",
      "Iteration 1924, loss = 0.01779754\n",
      "Iteration 1925, loss = 0.01778749\n",
      "Iteration 1926, loss = 0.01777592\n",
      "Iteration 1927, loss = 0.01776498\n",
      "Iteration 1928, loss = 0.01775455\n",
      "Iteration 1929, loss = 0.01774284\n",
      "Iteration 1930, loss = 0.01773358\n",
      "Iteration 1931, loss = 0.01772087\n",
      "Iteration 1932, loss = 0.01771016\n",
      "Iteration 1933, loss = 0.01769832\n",
      "Iteration 1934, loss = 0.01768841\n",
      "Iteration 1935, loss = 0.01767714\n",
      "Iteration 1936, loss = 0.01766717\n",
      "Iteration 1937, loss = 0.01766240\n",
      "Iteration 1938, loss = 0.01764849\n",
      "Iteration 1939, loss = 0.01763656\n",
      "Iteration 1940, loss = 0.01762591\n",
      "Iteration 1941, loss = 0.01761532\n",
      "Iteration 1942, loss = 0.01760401\n",
      "Iteration 1943, loss = 0.01759442\n",
      "Iteration 1944, loss = 0.01758448\n",
      "Iteration 1945, loss = 0.01757198\n",
      "Iteration 1946, loss = 0.01756164\n",
      "Iteration 1947, loss = 0.01754924\n",
      "Iteration 1948, loss = 0.01753979\n",
      "Iteration 1949, loss = 0.01752644\n",
      "Iteration 1950, loss = 0.01751495\n",
      "Iteration 1951, loss = 0.01750534\n",
      "Iteration 1952, loss = 0.01749573\n",
      "Iteration 1953, loss = 0.01748464\n",
      "Iteration 1954, loss = 0.01747325\n",
      "Iteration 1955, loss = 0.01746322\n",
      "Iteration 1956, loss = 0.01745288\n",
      "Iteration 1957, loss = 0.01744352\n",
      "Iteration 1958, loss = 0.01743310\n",
      "Iteration 1959, loss = 0.01742227\n",
      "Iteration 1960, loss = 0.01741128\n",
      "Iteration 1961, loss = 0.01740102\n",
      "Iteration 1962, loss = 0.01739038\n",
      "Iteration 1963, loss = 0.01737952\n",
      "Iteration 1964, loss = 0.01736887\n",
      "Iteration 1965, loss = 0.01736092\n",
      "Iteration 1966, loss = 0.01734981\n",
      "Iteration 1967, loss = 0.01733842\n",
      "Iteration 1968, loss = 0.01732839\n",
      "Iteration 1969, loss = 0.01731911\n",
      "Iteration 1970, loss = 0.01730731\n",
      "Iteration 1971, loss = 0.01729835\n",
      "Iteration 1972, loss = 0.01728774\n",
      "Iteration 1973, loss = 0.01727742\n",
      "Iteration 1974, loss = 0.01727350\n",
      "Iteration 1975, loss = 0.01725401\n",
      "Iteration 1976, loss = 0.01724693\n",
      "Iteration 1977, loss = 0.01723309\n",
      "Iteration 1978, loss = 0.01722217\n",
      "Iteration 1979, loss = 0.01721385\n",
      "Iteration 1980, loss = 0.01720130\n",
      "Iteration 1981, loss = 0.01719052\n",
      "Iteration 1982, loss = 0.01717982\n",
      "Iteration 1983, loss = 0.01716804\n",
      "Iteration 1984, loss = 0.01715698\n",
      "Iteration 1985, loss = 0.01714640\n",
      "Iteration 1986, loss = 0.01713858\n",
      "Iteration 1987, loss = 0.01712661\n",
      "Iteration 1988, loss = 0.01711633\n",
      "Iteration 1989, loss = 0.01710661\n",
      "Iteration 1990, loss = 0.01709664\n",
      "Iteration 1991, loss = 0.01708583\n",
      "Iteration 1992, loss = 0.01707628\n",
      "Iteration 1993, loss = 0.01706545\n",
      "Iteration 1994, loss = 0.01705546\n",
      "Iteration 1995, loss = 0.01704539\n",
      "Iteration 1996, loss = 0.01703472\n",
      "Iteration 1997, loss = 0.01702422\n",
      "Iteration 1998, loss = 0.01701396\n",
      "Iteration 1999, loss = 0.01700355\n",
      "Iteration 2000, loss = 0.01699285\n",
      "Iteration 2001, loss = 0.01698204\n",
      "Iteration 2002, loss = 0.01697286\n",
      "Iteration 2003, loss = 0.01696087\n",
      "Iteration 2004, loss = 0.01695087\n",
      "Iteration 2005, loss = 0.01694211\n",
      "Iteration 2006, loss = 0.01693071\n",
      "Iteration 2007, loss = 0.01692046\n",
      "Iteration 2008, loss = 0.01691060\n",
      "Iteration 2009, loss = 0.01690080\n",
      "Iteration 2010, loss = 0.01689078\n",
      "Iteration 2011, loss = 0.01688186\n",
      "Iteration 2012, loss = 0.01687107\n",
      "Iteration 2013, loss = 0.01686053\n",
      "Iteration 2014, loss = 0.01685083\n",
      "Iteration 2015, loss = 0.01684094\n",
      "Iteration 2016, loss = 0.01683013\n",
      "Iteration 2017, loss = 0.01682209\n",
      "Iteration 2018, loss = 0.01681092\n",
      "Iteration 2019, loss = 0.01679969\n",
      "Iteration 2020, loss = 0.01679076\n",
      "Iteration 2021, loss = 0.01678076\n",
      "Iteration 2022, loss = 0.01676956\n",
      "Iteration 2023, loss = 0.01676046\n",
      "Iteration 2024, loss = 0.01675050\n",
      "Iteration 2025, loss = 0.01674154\n",
      "Iteration 2026, loss = 0.01673320\n",
      "Iteration 2027, loss = 0.01672318\n",
      "Iteration 2028, loss = 0.01671248\n",
      "Iteration 2029, loss = 0.01670483\n",
      "Iteration 2030, loss = 0.01669444\n",
      "Iteration 2031, loss = 0.01668471\n",
      "Iteration 2032, loss = 0.01667499\n",
      "Iteration 2033, loss = 0.01666520\n",
      "Iteration 2034, loss = 0.01665552\n",
      "Iteration 2035, loss = 0.01664598\n",
      "Iteration 2036, loss = 0.01663695\n",
      "Iteration 2037, loss = 0.01662829\n",
      "Iteration 2038, loss = 0.01661821\n",
      "Iteration 2039, loss = 0.01660849\n",
      "Iteration 2040, loss = 0.01659956\n",
      "Iteration 2041, loss = 0.01658936\n",
      "Iteration 2042, loss = 0.01658099\n",
      "Iteration 2043, loss = 0.01657226\n",
      "Iteration 2044, loss = 0.01656237\n",
      "Iteration 2045, loss = 0.01655344\n",
      "Iteration 2046, loss = 0.01654420\n",
      "Iteration 2047, loss = 0.01653519\n",
      "Iteration 2048, loss = 0.01652686\n",
      "Iteration 2049, loss = 0.01651504\n",
      "Iteration 2050, loss = 0.01650503\n",
      "Iteration 2051, loss = 0.01649506\n",
      "Iteration 2052, loss = 0.01648759\n",
      "Iteration 2053, loss = 0.01647640\n",
      "Iteration 2054, loss = 0.01646739\n",
      "Iteration 2055, loss = 0.01645790\n",
      "Iteration 2056, loss = 0.01644784\n",
      "Iteration 2057, loss = 0.01643869\n",
      "Iteration 2058, loss = 0.01643082\n",
      "Iteration 2059, loss = 0.01641938\n",
      "Iteration 2060, loss = 0.01640945\n",
      "Iteration 2061, loss = 0.01640003\n",
      "Iteration 2062, loss = 0.01639058\n",
      "Iteration 2063, loss = 0.01637970\n",
      "Iteration 2064, loss = 0.01636912\n",
      "Iteration 2065, loss = 0.01635953\n",
      "Iteration 2066, loss = 0.01634928\n",
      "Iteration 2067, loss = 0.01633953\n",
      "Iteration 2068, loss = 0.01633238\n",
      "Iteration 2069, loss = 0.01631987\n",
      "Iteration 2070, loss = 0.01631233\n",
      "Iteration 2071, loss = 0.01630049\n",
      "Iteration 2072, loss = 0.01629077\n",
      "Iteration 2073, loss = 0.01628110\n",
      "Iteration 2074, loss = 0.01627111\n",
      "Iteration 2075, loss = 0.01626088\n",
      "Iteration 2076, loss = 0.01625115\n",
      "Iteration 2077, loss = 0.01624093\n",
      "Iteration 2078, loss = 0.01623129\n",
      "Iteration 2079, loss = 0.01622362\n",
      "Iteration 2080, loss = 0.01621343\n",
      "Iteration 2081, loss = 0.01620476\n",
      "Iteration 2082, loss = 0.01619449\n",
      "Iteration 2083, loss = 0.01618580\n",
      "Iteration 2084, loss = 0.01617777\n",
      "Iteration 2085, loss = 0.01616727\n",
      "Iteration 2086, loss = 0.01615842\n",
      "Iteration 2087, loss = 0.01614692\n",
      "Iteration 2088, loss = 0.01613765\n",
      "Iteration 2089, loss = 0.01612778\n",
      "Iteration 2090, loss = 0.01611873\n",
      "Iteration 2091, loss = 0.01610758\n",
      "Iteration 2092, loss = 0.01609904\n",
      "Iteration 2093, loss = 0.01608953\n",
      "Iteration 2094, loss = 0.01607987\n",
      "Iteration 2095, loss = 0.01607121\n",
      "Iteration 2096, loss = 0.01606292\n",
      "Iteration 2097, loss = 0.01605265\n",
      "Iteration 2098, loss = 0.01604294\n",
      "Iteration 2099, loss = 0.01603292\n",
      "Iteration 2100, loss = 0.01602317\n",
      "Iteration 2101, loss = 0.01601623\n",
      "Iteration 2102, loss = 0.01600468\n",
      "Iteration 2103, loss = 0.01599493\n",
      "Iteration 2104, loss = 0.01598677\n",
      "Iteration 2105, loss = 0.01597833\n",
      "Iteration 2106, loss = 0.01596797\n",
      "Iteration 2107, loss = 0.01595781\n",
      "Iteration 2108, loss = 0.01594801\n",
      "Iteration 2109, loss = 0.01593844\n",
      "Iteration 2110, loss = 0.01592910\n",
      "Iteration 2111, loss = 0.01591831\n",
      "Iteration 2112, loss = 0.01590865\n",
      "Iteration 2113, loss = 0.01589834\n",
      "Iteration 2114, loss = 0.01588893\n",
      "Iteration 2115, loss = 0.01587837\n",
      "Iteration 2116, loss = 0.01587003\n",
      "Iteration 2117, loss = 0.01586034\n",
      "Iteration 2118, loss = 0.01585016\n",
      "Iteration 2119, loss = 0.01584292\n",
      "Iteration 2120, loss = 0.01583207\n",
      "Iteration 2121, loss = 0.01582237\n",
      "Iteration 2122, loss = 0.01581371\n",
      "Iteration 2123, loss = 0.01580419\n",
      "Iteration 2124, loss = 0.01579457\n",
      "Iteration 2125, loss = 0.01578687\n",
      "Iteration 2126, loss = 0.01577842\n",
      "Iteration 2127, loss = 0.01576813\n",
      "Iteration 2128, loss = 0.01575852\n",
      "Iteration 2129, loss = 0.01574962\n",
      "Iteration 2130, loss = 0.01574047\n",
      "Iteration 2131, loss = 0.01573200\n",
      "Iteration 2132, loss = 0.01572353\n",
      "Iteration 2133, loss = 0.01571397\n",
      "Iteration 2134, loss = 0.01570564\n",
      "Iteration 2135, loss = 0.01569623\n",
      "Iteration 2136, loss = 0.01568775\n",
      "Iteration 2137, loss = 0.01567885\n",
      "Iteration 2138, loss = 0.01567027\n",
      "Iteration 2139, loss = 0.01566231\n",
      "Iteration 2140, loss = 0.01565252\n",
      "Iteration 2141, loss = 0.01564309\n",
      "Iteration 2142, loss = 0.01563399\n",
      "Iteration 2143, loss = 0.01562541\n",
      "Iteration 2144, loss = 0.01561681\n",
      "Iteration 2145, loss = 0.01560695\n",
      "Iteration 2146, loss = 0.01559734\n",
      "Iteration 2147, loss = 0.01558896\n",
      "Iteration 2148, loss = 0.01558023\n",
      "Iteration 2149, loss = 0.01557131\n",
      "Iteration 2150, loss = 0.01556213\n",
      "Iteration 2151, loss = 0.01555363\n",
      "Iteration 2152, loss = 0.01554529\n",
      "Iteration 2153, loss = 0.01553521\n",
      "Iteration 2154, loss = 0.01552655\n",
      "Iteration 2155, loss = 0.01551742\n",
      "Iteration 2156, loss = 0.01550880\n",
      "Iteration 2157, loss = 0.01550007\n",
      "Iteration 2158, loss = 0.01549115\n",
      "Iteration 2159, loss = 0.01548284\n",
      "Iteration 2160, loss = 0.01547498\n",
      "Iteration 2161, loss = 0.01546567\n",
      "Iteration 2162, loss = 0.01545664\n",
      "Iteration 2163, loss = 0.01544808\n",
      "Iteration 2164, loss = 0.01544067\n",
      "Iteration 2165, loss = 0.01543465\n",
      "Iteration 2166, loss = 0.01542436\n",
      "Iteration 2167, loss = 0.01541594\n",
      "Iteration 2168, loss = 0.01540786\n",
      "Iteration 2169, loss = 0.01539876\n",
      "Iteration 2170, loss = 0.01539286\n",
      "Iteration 2171, loss = 0.01538281\n",
      "Iteration 2172, loss = 0.01537485\n",
      "Iteration 2173, loss = 0.01536677\n",
      "Iteration 2174, loss = 0.01535875\n",
      "Iteration 2175, loss = 0.01535156\n",
      "Iteration 2176, loss = 0.01534273\n",
      "Iteration 2177, loss = 0.01533543\n",
      "Iteration 2178, loss = 0.01532618\n",
      "Iteration 2179, loss = 0.01531753\n",
      "Iteration 2180, loss = 0.01530968\n",
      "Iteration 2181, loss = 0.01530095\n",
      "Iteration 2182, loss = 0.01529200\n",
      "Iteration 2183, loss = 0.01528359\n",
      "Iteration 2184, loss = 0.01527535\n",
      "Iteration 2185, loss = 0.01526727\n",
      "Iteration 2186, loss = 0.01525980\n",
      "Iteration 2187, loss = 0.01525034\n",
      "Iteration 2188, loss = 0.01524365\n",
      "Iteration 2189, loss = 0.01523464\n",
      "Iteration 2190, loss = 0.01522468\n",
      "Iteration 2191, loss = 0.01521614\n",
      "Iteration 2192, loss = 0.01520663\n",
      "Iteration 2193, loss = 0.01519848\n",
      "Iteration 2194, loss = 0.01518859\n",
      "Iteration 2195, loss = 0.01518300\n",
      "Iteration 2196, loss = 0.01517199\n",
      "Iteration 2197, loss = 0.01516404\n",
      "Iteration 2198, loss = 0.01515506\n",
      "Iteration 2199, loss = 0.01514692\n",
      "Iteration 2200, loss = 0.01513936\n",
      "Iteration 2201, loss = 0.01513087\n",
      "Iteration 2202, loss = 0.01512215\n",
      "Iteration 2203, loss = 0.01511404\n",
      "Iteration 2204, loss = 0.01510589\n",
      "Iteration 2205, loss = 0.01510078\n",
      "Iteration 2206, loss = 0.01509011\n",
      "Iteration 2207, loss = 0.01508132\n",
      "Iteration 2208, loss = 0.01507436\n",
      "Iteration 2209, loss = 0.01506801\n",
      "Iteration 2210, loss = 0.01505988\n",
      "Iteration 2211, loss = 0.01505041\n",
      "Iteration 2212, loss = 0.01504205\n",
      "Iteration 2213, loss = 0.01503237\n",
      "Iteration 2214, loss = 0.01502336\n",
      "Iteration 2215, loss = 0.01501443\n",
      "Iteration 2216, loss = 0.01500566\n",
      "Iteration 2217, loss = 0.01499478\n",
      "Iteration 2218, loss = 0.01498594\n",
      "Iteration 2219, loss = 0.01497785\n",
      "Iteration 2220, loss = 0.01497064\n",
      "Iteration 2221, loss = 0.01496042\n",
      "Iteration 2222, loss = 0.01495288\n",
      "Iteration 2223, loss = 0.01494369\n",
      "Iteration 2224, loss = 0.01493654\n",
      "Iteration 2225, loss = 0.01492815\n",
      "Iteration 2226, loss = 0.01492060\n",
      "Iteration 2227, loss = 0.01491334\n",
      "Iteration 2228, loss = 0.01490316\n",
      "Iteration 2229, loss = 0.01489528\n",
      "Iteration 2230, loss = 0.01488693\n",
      "Iteration 2231, loss = 0.01487862\n",
      "Iteration 2232, loss = 0.01487086\n",
      "Iteration 2233, loss = 0.01486218\n",
      "Iteration 2234, loss = 0.01485465\n",
      "Iteration 2235, loss = 0.01484598\n",
      "Iteration 2236, loss = 0.01483800\n",
      "Iteration 2237, loss = 0.01483138\n",
      "Iteration 2238, loss = 0.01482140\n",
      "Iteration 2239, loss = 0.01481310\n",
      "Iteration 2240, loss = 0.01480587\n",
      "Iteration 2241, loss = 0.01479796\n",
      "Iteration 2242, loss = 0.01478822\n",
      "Iteration 2243, loss = 0.01477968\n",
      "Iteration 2244, loss = 0.01477240\n",
      "Iteration 2245, loss = 0.01476313\n",
      "Iteration 2246, loss = 0.01475555\n",
      "Iteration 2247, loss = 0.01474696\n",
      "Iteration 2248, loss = 0.01473892\n",
      "Iteration 2249, loss = 0.01473241\n",
      "Iteration 2250, loss = 0.01472352\n",
      "Iteration 2251, loss = 0.01471573\n",
      "Iteration 2252, loss = 0.01470842\n",
      "Iteration 2253, loss = 0.01470161\n",
      "Iteration 2254, loss = 0.01469262\n",
      "Iteration 2255, loss = 0.01468490\n",
      "Iteration 2256, loss = 0.01467741\n",
      "Iteration 2257, loss = 0.01466952\n",
      "Iteration 2258, loss = 0.01466221\n",
      "Iteration 2259, loss = 0.01465391\n",
      "Iteration 2260, loss = 0.01464662\n",
      "Iteration 2261, loss = 0.01463848\n",
      "Iteration 2262, loss = 0.01463107\n",
      "Iteration 2263, loss = 0.01462428\n",
      "Iteration 2264, loss = 0.01461640\n",
      "Iteration 2265, loss = 0.01460872\n",
      "Iteration 2266, loss = 0.01460082\n",
      "Iteration 2267, loss = 0.01459541\n",
      "Iteration 2268, loss = 0.01458653\n",
      "Iteration 2269, loss = 0.01457791\n",
      "Iteration 2270, loss = 0.01456993\n",
      "Iteration 2271, loss = 0.01456286\n",
      "Iteration 2272, loss = 0.01455405\n",
      "Iteration 2273, loss = 0.01454636\n",
      "Iteration 2274, loss = 0.01453828\n",
      "Iteration 2275, loss = 0.01453089\n",
      "Iteration 2276, loss = 0.01452225\n",
      "Iteration 2277, loss = 0.01451268\n",
      "Iteration 2278, loss = 0.01450347\n",
      "Iteration 2279, loss = 0.01449627\n",
      "Iteration 2280, loss = 0.01448683\n",
      "Iteration 2281, loss = 0.01447895\n",
      "Iteration 2282, loss = 0.01446967\n",
      "Iteration 2283, loss = 0.01446058\n",
      "Iteration 2284, loss = 0.01445431\n",
      "Iteration 2285, loss = 0.01444359\n",
      "Iteration 2286, loss = 0.01443704\n",
      "Iteration 2287, loss = 0.01442666\n",
      "Iteration 2288, loss = 0.01441804\n",
      "Iteration 2289, loss = 0.01441349\n",
      "Iteration 2290, loss = 0.01440545\n",
      "Iteration 2291, loss = 0.01439739\n",
      "Iteration 2292, loss = 0.01438947\n",
      "Iteration 2293, loss = 0.01438192\n",
      "Iteration 2294, loss = 0.01437369\n",
      "Iteration 2295, loss = 0.01436582\n",
      "Iteration 2296, loss = 0.01435654\n",
      "Iteration 2297, loss = 0.01435025\n",
      "Iteration 2298, loss = 0.01434021\n",
      "Iteration 2299, loss = 0.01433327\n",
      "Iteration 2300, loss = 0.01432417\n",
      "Iteration 2301, loss = 0.01431636\n",
      "Iteration 2302, loss = 0.01430842\n",
      "Iteration 2303, loss = 0.01430123\n",
      "Iteration 2304, loss = 0.01429262\n",
      "Iteration 2305, loss = 0.01428507\n",
      "Iteration 2306, loss = 0.01427761\n",
      "Iteration 2307, loss = 0.01426945\n",
      "Iteration 2308, loss = 0.01426197\n",
      "Iteration 2309, loss = 0.01425307\n",
      "Iteration 2310, loss = 0.01424775\n",
      "Iteration 2311, loss = 0.01423850\n",
      "Iteration 2312, loss = 0.01423100\n",
      "Iteration 2313, loss = 0.01422431\n",
      "Iteration 2314, loss = 0.01421572\n",
      "Iteration 2315, loss = 0.01420804\n",
      "Iteration 2316, loss = 0.01419943\n",
      "Iteration 2317, loss = 0.01419187\n",
      "Iteration 2318, loss = 0.01418385\n",
      "Iteration 2319, loss = 0.01417640\n",
      "Iteration 2320, loss = 0.01416906\n",
      "Iteration 2321, loss = 0.01416337\n",
      "Iteration 2322, loss = 0.01415451\n",
      "Iteration 2323, loss = 0.01414636\n",
      "Iteration 2324, loss = 0.01413963\n",
      "Iteration 2325, loss = 0.01413233\n",
      "Iteration 2326, loss = 0.01412511\n",
      "Iteration 2327, loss = 0.01411831\n",
      "Iteration 2328, loss = 0.01411147\n",
      "Iteration 2329, loss = 0.01410377\n",
      "Iteration 2330, loss = 0.01409675\n",
      "Iteration 2331, loss = 0.01408971\n",
      "Iteration 2332, loss = 0.01408445\n",
      "Iteration 2333, loss = 0.01407660\n",
      "Iteration 2334, loss = 0.01407020\n",
      "Iteration 2335, loss = 0.01406480\n",
      "Iteration 2336, loss = 0.01405506\n",
      "Iteration 2337, loss = 0.01404960\n",
      "Iteration 2338, loss = 0.01404005\n",
      "Iteration 2339, loss = 0.01403378\n",
      "Iteration 2340, loss = 0.01402543\n",
      "Iteration 2341, loss = 0.01401830\n",
      "Iteration 2342, loss = 0.01401048\n",
      "Iteration 2343, loss = 0.01400296\n",
      "Iteration 2344, loss = 0.01399608\n",
      "Iteration 2345, loss = 0.01398931\n",
      "Iteration 2346, loss = 0.01398036\n",
      "Iteration 2347, loss = 0.01397371\n",
      "Iteration 2348, loss = 0.01396534\n",
      "Iteration 2349, loss = 0.01395872\n",
      "Iteration 2350, loss = 0.01395119\n",
      "Iteration 2351, loss = 0.01394409\n",
      "Iteration 2352, loss = 0.01393739\n",
      "Iteration 2353, loss = 0.01393070\n",
      "Iteration 2354, loss = 0.01392359\n",
      "Iteration 2355, loss = 0.01391656\n",
      "Iteration 2356, loss = 0.01390895\n",
      "Iteration 2357, loss = 0.01390224\n",
      "Iteration 2358, loss = 0.01389506\n",
      "Iteration 2359, loss = 0.01388866\n",
      "Iteration 2360, loss = 0.01387937\n",
      "Iteration 2361, loss = 0.01387045\n",
      "Iteration 2362, loss = 0.01386177\n",
      "Iteration 2363, loss = 0.01385539\n",
      "Iteration 2364, loss = 0.01384777\n",
      "Iteration 2365, loss = 0.01384027\n",
      "Iteration 2366, loss = 0.01383224\n",
      "Iteration 2367, loss = 0.01382560\n",
      "Iteration 2368, loss = 0.01381935\n",
      "Iteration 2369, loss = 0.01381208\n",
      "Iteration 2370, loss = 0.01380463\n",
      "Iteration 2371, loss = 0.01380032\n",
      "Iteration 2372, loss = 0.01379243\n",
      "Iteration 2373, loss = 0.01378301\n",
      "Iteration 2374, loss = 0.01377555\n",
      "Iteration 2375, loss = 0.01376775\n",
      "Iteration 2376, loss = 0.01376113\n",
      "Iteration 2377, loss = 0.01375248\n",
      "Iteration 2378, loss = 0.01374605\n",
      "Iteration 2379, loss = 0.01374013\n",
      "Iteration 2380, loss = 0.01373219\n",
      "Iteration 2381, loss = 0.01372301\n",
      "Iteration 2382, loss = 0.01371625\n",
      "Iteration 2383, loss = 0.01370877\n",
      "Iteration 2384, loss = 0.01370089\n",
      "Iteration 2385, loss = 0.01369387\n",
      "Iteration 2386, loss = 0.01368757\n",
      "Iteration 2387, loss = 0.01367914\n",
      "Iteration 2388, loss = 0.01367513\n",
      "Iteration 2389, loss = 0.01366656\n",
      "Iteration 2390, loss = 0.01365926\n",
      "Iteration 2391, loss = 0.01365173\n",
      "Iteration 2392, loss = 0.01364454\n",
      "Iteration 2393, loss = 0.01363813\n",
      "Iteration 2394, loss = 0.01363213\n",
      "Iteration 2395, loss = 0.01362367\n",
      "Iteration 2396, loss = 0.01361649\n",
      "Iteration 2397, loss = 0.01360797\n",
      "Iteration 2398, loss = 0.01360167\n",
      "Iteration 2399, loss = 0.01359410\n",
      "Iteration 2400, loss = 0.01358680\n",
      "Iteration 2401, loss = 0.01357923\n",
      "Iteration 2402, loss = 0.01357225\n",
      "Iteration 2403, loss = 0.01356483\n",
      "Iteration 2404, loss = 0.01355916\n",
      "Iteration 2405, loss = 0.01354998\n",
      "Iteration 2406, loss = 0.01354257\n",
      "Iteration 2407, loss = 0.01353510\n",
      "Iteration 2408, loss = 0.01352897\n",
      "Iteration 2409, loss = 0.01352187\n",
      "Iteration 2410, loss = 0.01351442\n",
      "Iteration 2411, loss = 0.01350835\n",
      "Iteration 2412, loss = 0.01350151\n",
      "Iteration 2413, loss = 0.01349521\n",
      "Iteration 2414, loss = 0.01348907\n",
      "Iteration 2415, loss = 0.01348281\n",
      "Iteration 2416, loss = 0.01347780\n",
      "Iteration 2417, loss = 0.01346975\n",
      "Iteration 2418, loss = 0.01346298\n",
      "Iteration 2419, loss = 0.01345592\n",
      "Iteration 2420, loss = 0.01344875\n",
      "Iteration 2421, loss = 0.01344220\n",
      "Iteration 2422, loss = 0.01343663\n",
      "Iteration 2423, loss = 0.01342835\n",
      "Iteration 2424, loss = 0.01342100\n",
      "Iteration 2425, loss = 0.01341423\n",
      "Iteration 2426, loss = 0.01340741\n",
      "Iteration 2427, loss = 0.01340146\n",
      "Iteration 2428, loss = 0.01339485\n",
      "Iteration 2429, loss = 0.01339165\n",
      "Iteration 2430, loss = 0.01338170\n",
      "Iteration 2431, loss = 0.01337451\n",
      "Iteration 2432, loss = 0.01336799\n",
      "Iteration 2433, loss = 0.01336120\n",
      "Iteration 2434, loss = 0.01335281\n",
      "Iteration 2435, loss = 0.01334536\n",
      "Iteration 2436, loss = 0.01333772\n",
      "Iteration 2437, loss = 0.01333157\n",
      "Iteration 2438, loss = 0.01332506\n",
      "Iteration 2439, loss = 0.01331664\n",
      "Iteration 2440, loss = 0.01330988\n",
      "Iteration 2441, loss = 0.01330405\n",
      "Iteration 2442, loss = 0.01329700\n",
      "Iteration 2443, loss = 0.01328981\n",
      "Iteration 2444, loss = 0.01328361\n",
      "Iteration 2445, loss = 0.01327701\n",
      "Iteration 2446, loss = 0.01327014\n",
      "Iteration 2447, loss = 0.01326329\n",
      "Iteration 2448, loss = 0.01325666\n",
      "Iteration 2449, loss = 0.01324883\n",
      "Iteration 2450, loss = 0.01324289\n",
      "Iteration 2451, loss = 0.01323558\n",
      "Iteration 2452, loss = 0.01322873\n",
      "Iteration 2453, loss = 0.01322167\n",
      "Iteration 2454, loss = 0.01321518\n",
      "Iteration 2455, loss = 0.01320836\n",
      "Iteration 2456, loss = 0.01320162\n",
      "Iteration 2457, loss = 0.01319524\n",
      "Iteration 2458, loss = 0.01319015\n",
      "Iteration 2459, loss = 0.01318309\n",
      "Iteration 2460, loss = 0.01317649\n",
      "Iteration 2461, loss = 0.01317005\n",
      "Iteration 2462, loss = 0.01316407\n",
      "Iteration 2463, loss = 0.01315717\n",
      "Iteration 2464, loss = 0.01315040\n",
      "Iteration 2465, loss = 0.01314328\n",
      "Iteration 2466, loss = 0.01313586\n",
      "Iteration 2467, loss = 0.01312944\n",
      "Iteration 2468, loss = 0.01312432\n",
      "Iteration 2469, loss = 0.01311623\n",
      "Iteration 2470, loss = 0.01311020\n",
      "Iteration 2471, loss = 0.01310405\n",
      "Iteration 2472, loss = 0.01309766\n",
      "Iteration 2473, loss = 0.01309193\n",
      "Iteration 2474, loss = 0.01308626\n",
      "Iteration 2475, loss = 0.01307977\n",
      "Iteration 2476, loss = 0.01307369\n",
      "Iteration 2477, loss = 0.01306822\n",
      "Iteration 2478, loss = 0.01306093\n",
      "Iteration 2479, loss = 0.01305506\n",
      "Iteration 2480, loss = 0.01304805\n",
      "Iteration 2481, loss = 0.01304053\n",
      "Iteration 2482, loss = 0.01303348\n",
      "Iteration 2483, loss = 0.01302735\n",
      "Iteration 2484, loss = 0.01302036\n",
      "Iteration 2485, loss = 0.01301266\n",
      "Iteration 2486, loss = 0.01300556\n",
      "Iteration 2487, loss = 0.01300043\n",
      "Iteration 2488, loss = 0.01299327\n",
      "Iteration 2489, loss = 0.01298457\n",
      "Iteration 2490, loss = 0.01297763\n",
      "Iteration 2491, loss = 0.01297197\n",
      "Iteration 2492, loss = 0.01296378\n",
      "Iteration 2493, loss = 0.01295700\n",
      "Iteration 2494, loss = 0.01294985\n",
      "Iteration 2495, loss = 0.01294356\n",
      "Iteration 2496, loss = 0.01293659\n",
      "Iteration 2497, loss = 0.01292899\n",
      "Iteration 2498, loss = 0.01292263\n",
      "Iteration 2499, loss = 0.01291607\n",
      "Iteration 2500, loss = 0.01290946\n",
      "Iteration 2501, loss = 0.01290308\n",
      "Iteration 2502, loss = 0.01289573\n",
      "Iteration 2503, loss = 0.01289036\n",
      "Iteration 2504, loss = 0.01288224\n",
      "Iteration 2505, loss = 0.01287734\n",
      "Iteration 2506, loss = 0.01286947\n",
      "Iteration 2507, loss = 0.01286417\n",
      "Iteration 2508, loss = 0.01285620\n",
      "Iteration 2509, loss = 0.01284831\n",
      "Iteration 2510, loss = 0.01284112\n",
      "Iteration 2511, loss = 0.01283551\n",
      "Iteration 2512, loss = 0.01282726\n",
      "Iteration 2513, loss = 0.01281944\n",
      "Iteration 2514, loss = 0.01281313\n",
      "Iteration 2515, loss = 0.01280815\n",
      "Iteration 2516, loss = 0.01279919\n",
      "Iteration 2517, loss = 0.01279205\n",
      "Iteration 2518, loss = 0.01278539\n",
      "Iteration 2519, loss = 0.01277816\n",
      "Iteration 2520, loss = 0.01277222\n",
      "Iteration 2521, loss = 0.01276554\n",
      "Iteration 2522, loss = 0.01275809\n",
      "Iteration 2523, loss = 0.01275251\n",
      "Iteration 2524, loss = 0.01274495\n",
      "Iteration 2525, loss = 0.01273831\n",
      "Iteration 2526, loss = 0.01273450\n",
      "Iteration 2527, loss = 0.01272569\n",
      "Iteration 2528, loss = 0.01271877\n",
      "Iteration 2529, loss = 0.01271161\n",
      "Iteration 2530, loss = 0.01270447\n",
      "Iteration 2531, loss = 0.01269722\n",
      "Iteration 2532, loss = 0.01269362\n",
      "Iteration 2533, loss = 0.01268564\n",
      "Iteration 2534, loss = 0.01267931\n",
      "Iteration 2535, loss = 0.01267337\n",
      "Iteration 2536, loss = 0.01266744\n",
      "Iteration 2537, loss = 0.01266171\n",
      "Iteration 2538, loss = 0.01265592\n",
      "Iteration 2539, loss = 0.01265028\n",
      "Iteration 2540, loss = 0.01264423\n",
      "Iteration 2541, loss = 0.01263812\n",
      "Iteration 2542, loss = 0.01263242\n",
      "Iteration 2543, loss = 0.01262656\n",
      "Iteration 2544, loss = 0.01262095\n",
      "Iteration 2545, loss = 0.01261614\n",
      "Iteration 2546, loss = 0.01260974\n",
      "Iteration 2547, loss = 0.01260451\n",
      "Iteration 2548, loss = 0.01259866\n",
      "Iteration 2549, loss = 0.01259306\n",
      "Iteration 2550, loss = 0.01258751\n",
      "Iteration 2551, loss = 0.01258131\n",
      "Iteration 2552, loss = 0.01257630\n",
      "Iteration 2553, loss = 0.01257037\n",
      "Iteration 2554, loss = 0.01256410\n",
      "Iteration 2555, loss = 0.01255860\n",
      "Iteration 2556, loss = 0.01255199\n",
      "Iteration 2557, loss = 0.01254593\n",
      "Iteration 2558, loss = 0.01253984\n",
      "Iteration 2559, loss = 0.01253360\n",
      "Iteration 2560, loss = 0.01252771\n",
      "Iteration 2561, loss = 0.01252186\n",
      "Iteration 2562, loss = 0.01251608\n",
      "Iteration 2563, loss = 0.01251107\n",
      "Iteration 2564, loss = 0.01250454\n",
      "Iteration 2565, loss = 0.01249931\n",
      "Iteration 2566, loss = 0.01249240\n",
      "Iteration 2567, loss = 0.01248868\n",
      "Iteration 2568, loss = 0.01247978\n",
      "Iteration 2569, loss = 0.01247491\n",
      "Iteration 2570, loss = 0.01246885\n",
      "Iteration 2571, loss = 0.01246137\n",
      "Iteration 2572, loss = 0.01245464\n",
      "Iteration 2573, loss = 0.01244896\n",
      "Iteration 2574, loss = 0.01244254\n",
      "Iteration 2575, loss = 0.01243651\n",
      "Iteration 2576, loss = 0.01243093\n",
      "Iteration 2577, loss = 0.01242400\n",
      "Iteration 2578, loss = 0.01241768\n",
      "Iteration 2579, loss = 0.01241346\n",
      "Iteration 2580, loss = 0.01240546\n",
      "Iteration 2581, loss = 0.01239785\n",
      "Iteration 2582, loss = 0.01239300\n",
      "Iteration 2583, loss = 0.01238535\n",
      "Iteration 2584, loss = 0.01237993\n",
      "Iteration 2585, loss = 0.01237386\n",
      "Iteration 2586, loss = 0.01236736\n",
      "Iteration 2587, loss = 0.01236137\n",
      "Iteration 2588, loss = 0.01235547\n",
      "Iteration 2589, loss = 0.01234906\n",
      "Iteration 2590, loss = 0.01234321\n",
      "Iteration 2591, loss = 0.01233726\n",
      "Iteration 2592, loss = 0.01233084\n",
      "Iteration 2593, loss = 0.01232609\n",
      "Iteration 2594, loss = 0.01232059\n",
      "Iteration 2595, loss = 0.01231416\n",
      "Iteration 2596, loss = 0.01230847\n",
      "Iteration 2597, loss = 0.01230278\n",
      "Iteration 2598, loss = 0.01229777\n",
      "Iteration 2599, loss = 0.01229153\n",
      "Iteration 2600, loss = 0.01228581\n",
      "Iteration 2601, loss = 0.01227963\n",
      "Iteration 2602, loss = 0.01227346\n",
      "Iteration 2603, loss = 0.01226769\n",
      "Iteration 2604, loss = 0.01226261\n",
      "Iteration 2605, loss = 0.01225616\n",
      "Iteration 2606, loss = 0.01224991\n",
      "Iteration 2607, loss = 0.01224423\n",
      "Iteration 2608, loss = 0.01223901\n",
      "Iteration 2609, loss = 0.01223320\n",
      "Iteration 2610, loss = 0.01222747\n",
      "Iteration 2611, loss = 0.01222261\n",
      "Iteration 2612, loss = 0.01221637\n",
      "Iteration 2613, loss = 0.01221064\n",
      "Iteration 2614, loss = 0.01220466\n",
      "Iteration 2615, loss = 0.01219934\n",
      "Iteration 2616, loss = 0.01219345\n",
      "Iteration 2617, loss = 0.01218799\n",
      "Iteration 2618, loss = 0.01218022\n",
      "Iteration 2619, loss = 0.01217334\n",
      "Iteration 2620, loss = 0.01216621\n",
      "Iteration 2621, loss = 0.01216010\n",
      "Iteration 2622, loss = 0.01215428\n",
      "Iteration 2623, loss = 0.01214679\n",
      "Iteration 2624, loss = 0.01214053\n",
      "Iteration 2625, loss = 0.01213376\n",
      "Iteration 2626, loss = 0.01212774\n",
      "Iteration 2627, loss = 0.01212149\n",
      "Iteration 2628, loss = 0.01211605\n",
      "Iteration 2629, loss = 0.01210925\n",
      "Iteration 2630, loss = 0.01210340\n",
      "Iteration 2631, loss = 0.01209735\n",
      "Iteration 2632, loss = 0.01209137\n",
      "Iteration 2633, loss = 0.01208619\n",
      "Iteration 2634, loss = 0.01208002\n",
      "Iteration 2635, loss = 0.01207364\n",
      "Iteration 2636, loss = 0.01206924\n",
      "Iteration 2637, loss = 0.01206299\n",
      "Iteration 2638, loss = 0.01206202\n",
      "Iteration 2639, loss = 0.01205249\n",
      "Iteration 2640, loss = 0.01204770\n",
      "Iteration 2641, loss = 0.01204266\n",
      "Iteration 2642, loss = 0.01203648\n",
      "Iteration 2643, loss = 0.01203078\n",
      "Iteration 2644, loss = 0.01202573\n",
      "Iteration 2645, loss = 0.01202008\n",
      "Iteration 2646, loss = 0.01201707\n",
      "Iteration 2647, loss = 0.01201202\n",
      "Iteration 2648, loss = 0.01200578\n",
      "Iteration 2649, loss = 0.01199933\n",
      "Iteration 2650, loss = 0.01199423\n",
      "Iteration 2651, loss = 0.01198741\n",
      "Iteration 2652, loss = 0.01198187\n",
      "Iteration 2653, loss = 0.01197612\n",
      "Iteration 2654, loss = 0.01196912\n",
      "Iteration 2655, loss = 0.01196334\n",
      "Iteration 2656, loss = 0.01195884\n",
      "Iteration 2657, loss = 0.01195195\n",
      "Iteration 2658, loss = 0.01194554\n",
      "Iteration 2659, loss = 0.01193953\n",
      "Iteration 2660, loss = 0.01193306\n",
      "Iteration 2661, loss = 0.01192793\n",
      "Iteration 2662, loss = 0.01192200\n",
      "Iteration 2663, loss = 0.01191541\n",
      "Iteration 2664, loss = 0.01190930\n",
      "Iteration 2665, loss = 0.01190368\n",
      "Iteration 2666, loss = 0.01189842\n",
      "Iteration 2667, loss = 0.01189257\n",
      "Iteration 2668, loss = 0.01188734\n",
      "Iteration 2669, loss = 0.01188143\n",
      "Iteration 2670, loss = 0.01187607\n",
      "Iteration 2671, loss = 0.01187031\n",
      "Iteration 2672, loss = 0.01186794\n",
      "Iteration 2673, loss = 0.01186139\n",
      "Iteration 2674, loss = 0.01185471\n",
      "Iteration 2675, loss = 0.01184851\n",
      "Iteration 2676, loss = 0.01184290\n",
      "Iteration 2677, loss = 0.01183736\n",
      "Iteration 2678, loss = 0.01183231\n",
      "Iteration 2679, loss = 0.01182638\n",
      "Iteration 2680, loss = 0.01182044\n",
      "Iteration 2681, loss = 0.01181554\n",
      "Iteration 2682, loss = 0.01180951\n",
      "Iteration 2683, loss = 0.01180479\n",
      "Iteration 2684, loss = 0.01179867\n",
      "Iteration 2685, loss = 0.01179357\n",
      "Iteration 2686, loss = 0.01178826\n",
      "Iteration 2687, loss = 0.01178260\n",
      "Iteration 2688, loss = 0.01177794\n",
      "Iteration 2689, loss = 0.01177227\n",
      "Iteration 2690, loss = 0.01176706\n",
      "Iteration 2691, loss = 0.01176207\n",
      "Iteration 2692, loss = 0.01175715\n",
      "Iteration 2693, loss = 0.01175177\n",
      "Iteration 2694, loss = 0.01174837\n",
      "Iteration 2695, loss = 0.01174155\n",
      "Iteration 2696, loss = 0.01173636\n",
      "Iteration 2697, loss = 0.01173085\n",
      "Iteration 2698, loss = 0.01172565\n",
      "Iteration 2699, loss = 0.01172071\n",
      "Iteration 2700, loss = 0.01171523\n",
      "Iteration 2701, loss = 0.01171083\n",
      "Iteration 2702, loss = 0.01170563\n",
      "Iteration 2703, loss = 0.01169987\n",
      "Iteration 2704, loss = 0.01169454\n",
      "Iteration 2705, loss = 0.01168991\n",
      "Iteration 2706, loss = 0.01168493\n",
      "Iteration 2707, loss = 0.01167970\n",
      "Iteration 2708, loss = 0.01167570\n",
      "Iteration 2709, loss = 0.01167041\n",
      "Iteration 2710, loss = 0.01166785\n",
      "Iteration 2711, loss = 0.01166147\n",
      "Iteration 2712, loss = 0.01165769\n",
      "Iteration 2713, loss = 0.01165263\n",
      "Iteration 2714, loss = 0.01164896\n",
      "Iteration 2715, loss = 0.01164378\n",
      "Iteration 2716, loss = 0.01163715\n",
      "Iteration 2717, loss = 0.01163164\n",
      "Iteration 2718, loss = 0.01162595\n",
      "Iteration 2719, loss = 0.01161996\n",
      "Iteration 2720, loss = 0.01161499\n",
      "Iteration 2721, loss = 0.01160787\n",
      "Iteration 2722, loss = 0.01160169\n",
      "Iteration 2723, loss = 0.01159572\n",
      "Iteration 2724, loss = 0.01158779\n",
      "Iteration 2725, loss = 0.01158348\n",
      "Iteration 2726, loss = 0.01157592\n",
      "Iteration 2727, loss = 0.01157232\n",
      "Iteration 2728, loss = 0.01156437\n",
      "Iteration 2729, loss = 0.01155789\n",
      "Iteration 2730, loss = 0.01155324\n",
      "Iteration 2731, loss = 0.01154726\n",
      "Iteration 2732, loss = 0.01154082\n",
      "Iteration 2733, loss = 0.01153397\n",
      "Iteration 2734, loss = 0.01152806\n",
      "Iteration 2735, loss = 0.01152244\n",
      "Iteration 2736, loss = 0.01151728\n",
      "Iteration 2737, loss = 0.01151040\n",
      "Iteration 2738, loss = 0.01150613\n",
      "Iteration 2739, loss = 0.01150134\n",
      "Iteration 2740, loss = 0.01149461\n",
      "Iteration 2741, loss = 0.01148908\n",
      "Iteration 2742, loss = 0.01148415\n",
      "Iteration 2743, loss = 0.01147832\n",
      "Iteration 2744, loss = 0.01147260\n",
      "Iteration 2745, loss = 0.01146783\n",
      "Iteration 2746, loss = 0.01146139\n",
      "Iteration 2747, loss = 0.01145746\n",
      "Iteration 2748, loss = 0.01145121\n",
      "Iteration 2749, loss = 0.01144467\n",
      "Iteration 2750, loss = 0.01143868\n",
      "Iteration 2751, loss = 0.01143634\n",
      "Iteration 2752, loss = 0.01142826\n",
      "Iteration 2753, loss = 0.01142341\n",
      "Iteration 2754, loss = 0.01141826\n",
      "Iteration 2755, loss = 0.01141272\n",
      "Iteration 2756, loss = 0.01140769\n",
      "Iteration 2757, loss = 0.01140241\n",
      "Iteration 2758, loss = 0.01139733\n",
      "Iteration 2759, loss = 0.01139192\n",
      "Iteration 2760, loss = 0.01138839\n",
      "Iteration 2761, loss = 0.01138233\n",
      "Iteration 2762, loss = 0.01137767\n",
      "Iteration 2763, loss = 0.01137141\n",
      "Iteration 2764, loss = 0.01136632\n",
      "Iteration 2765, loss = 0.01136115\n",
      "Iteration 2766, loss = 0.01135568\n",
      "Iteration 2767, loss = 0.01135023\n",
      "Iteration 2768, loss = 0.01134535\n",
      "Iteration 2769, loss = 0.01134094\n",
      "Iteration 2770, loss = 0.01133523\n",
      "Iteration 2771, loss = 0.01133047\n",
      "Iteration 2772, loss = 0.01132598\n",
      "Iteration 2773, loss = 0.01132044\n",
      "Iteration 2774, loss = 0.01131616\n",
      "Iteration 2775, loss = 0.01131075\n",
      "Iteration 2776, loss = 0.01130555\n",
      "Iteration 2777, loss = 0.01130047\n",
      "Iteration 2778, loss = 0.01129601\n",
      "Iteration 2779, loss = 0.01129148\n",
      "Iteration 2780, loss = 0.01128703\n",
      "Iteration 2781, loss = 0.01128310\n",
      "Iteration 2782, loss = 0.01127713\n",
      "Iteration 2783, loss = 0.01127219\n",
      "Iteration 2784, loss = 0.01126829\n",
      "Iteration 2785, loss = 0.01126304\n",
      "Iteration 2786, loss = 0.01125779\n",
      "Iteration 2787, loss = 0.01125265\n",
      "Iteration 2788, loss = 0.01124704\n",
      "Iteration 2789, loss = 0.01124192\n",
      "Iteration 2790, loss = 0.01123645\n",
      "Iteration 2791, loss = 0.01123162\n",
      "Iteration 2792, loss = 0.01122512\n",
      "Iteration 2793, loss = 0.01122035\n",
      "Iteration 2794, loss = 0.01121383\n",
      "Iteration 2795, loss = 0.01120942\n",
      "Iteration 2796, loss = 0.01120421\n",
      "Iteration 2797, loss = 0.01119782\n",
      "Iteration 2798, loss = 0.01119250\n",
      "Iteration 2799, loss = 0.01118738\n",
      "Iteration 2800, loss = 0.01118181\n",
      "Iteration 2801, loss = 0.01117701\n",
      "Iteration 2802, loss = 0.01117167\n",
      "Iteration 2803, loss = 0.01116636\n",
      "Iteration 2804, loss = 0.01116179\n",
      "Iteration 2805, loss = 0.01115626\n",
      "Iteration 2806, loss = 0.01115134\n",
      "Iteration 2807, loss = 0.01114528\n",
      "Iteration 2808, loss = 0.01114013\n",
      "Iteration 2809, loss = 0.01113585\n",
      "Iteration 2810, loss = 0.01112914\n",
      "Iteration 2811, loss = 0.01112428\n",
      "Iteration 2812, loss = 0.01111939\n",
      "Iteration 2813, loss = 0.01111448\n",
      "Iteration 2814, loss = 0.01110946\n",
      "Iteration 2815, loss = 0.01110460\n",
      "Iteration 2816, loss = 0.01110177\n",
      "Iteration 2817, loss = 0.01109569\n",
      "Iteration 2818, loss = 0.01109063\n",
      "Iteration 2819, loss = 0.01108544\n",
      "Iteration 2820, loss = 0.01108018\n",
      "Iteration 2821, loss = 0.01107509\n",
      "Iteration 2822, loss = 0.01107031\n",
      "Iteration 2823, loss = 0.01106479\n",
      "Iteration 2824, loss = 0.01105983\n",
      "Iteration 2825, loss = 0.01105577\n",
      "Iteration 2826, loss = 0.01105215\n",
      "Iteration 2827, loss = 0.01104633\n",
      "Iteration 2828, loss = 0.01104112\n",
      "Iteration 2829, loss = 0.01103565\n",
      "Iteration 2830, loss = 0.01103168\n",
      "Iteration 2831, loss = 0.01102612\n",
      "Iteration 2832, loss = 0.01102396\n",
      "Iteration 2833, loss = 0.01101720\n",
      "Iteration 2834, loss = 0.01101393\n",
      "Iteration 2835, loss = 0.01100839\n",
      "Iteration 2836, loss = 0.01100374\n",
      "Iteration 2837, loss = 0.01099953\n",
      "Iteration 2838, loss = 0.01099490\n",
      "Iteration 2839, loss = 0.01099123\n",
      "Iteration 2840, loss = 0.01098751\n",
      "Iteration 2841, loss = 0.01098189\n",
      "Iteration 2842, loss = 0.01097803\n",
      "Iteration 2843, loss = 0.01097214\n",
      "Iteration 2844, loss = 0.01096770\n",
      "Iteration 2845, loss = 0.01096344\n",
      "Iteration 2846, loss = 0.01095801\n",
      "Iteration 2847, loss = 0.01095272\n",
      "Iteration 2848, loss = 0.01094761\n",
      "Iteration 2849, loss = 0.01094257\n",
      "Iteration 2850, loss = 0.01093821\n",
      "Iteration 2851, loss = 0.01093271\n",
      "Iteration 2852, loss = 0.01092680\n",
      "Iteration 2853, loss = 0.01092179\n",
      "Iteration 2854, loss = 0.01091711\n",
      "Iteration 2855, loss = 0.01091164\n",
      "Iteration 2856, loss = 0.01090692\n",
      "Iteration 2857, loss = 0.01090197\n",
      "Iteration 2858, loss = 0.01089738\n",
      "Iteration 2859, loss = 0.01089238\n",
      "Iteration 2860, loss = 0.01088790\n",
      "Iteration 2861, loss = 0.01088307\n",
      "Iteration 2862, loss = 0.01087870\n",
      "Iteration 2863, loss = 0.01087468\n",
      "Iteration 2864, loss = 0.01086967\n",
      "Iteration 2865, loss = 0.01086564\n",
      "Iteration 2866, loss = 0.01086087\n",
      "Iteration 2867, loss = 0.01085599\n",
      "Iteration 2868, loss = 0.01085212\n",
      "Iteration 2869, loss = 0.01084644\n",
      "Iteration 2870, loss = 0.01084165\n",
      "Iteration 2871, loss = 0.01083659\n",
      "Iteration 2872, loss = 0.01083214\n",
      "Iteration 2873, loss = 0.01082795\n",
      "Iteration 2874, loss = 0.01082212\n",
      "Iteration 2875, loss = 0.01081797\n",
      "Iteration 2876, loss = 0.01081323\n",
      "Iteration 2877, loss = 0.01080907\n",
      "Iteration 2878, loss = 0.01080352\n",
      "Iteration 2879, loss = 0.01079780\n",
      "Iteration 2880, loss = 0.01079297\n",
      "Iteration 2881, loss = 0.01078699\n",
      "Iteration 2882, loss = 0.01078314\n",
      "Iteration 2883, loss = 0.01077665\n",
      "Iteration 2884, loss = 0.01077270\n",
      "Iteration 2885, loss = 0.01076809\n",
      "Iteration 2886, loss = 0.01076255\n",
      "Iteration 2887, loss = 0.01075785\n",
      "Iteration 2888, loss = 0.01075314\n",
      "Iteration 2889, loss = 0.01074963\n",
      "Iteration 2890, loss = 0.01074432\n",
      "Iteration 2891, loss = 0.01074012\n",
      "Iteration 2892, loss = 0.01073464\n",
      "Iteration 2893, loss = 0.01073052\n",
      "Iteration 2894, loss = 0.01072563\n",
      "Iteration 2895, loss = 0.01072099\n",
      "Iteration 2896, loss = 0.01071562\n",
      "Iteration 2897, loss = 0.01071058\n",
      "Iteration 2898, loss = 0.01070536\n",
      "Iteration 2899, loss = 0.01070031\n",
      "Iteration 2900, loss = 0.01069545\n",
      "Iteration 2901, loss = 0.01069049\n",
      "Iteration 2902, loss = 0.01068629\n",
      "Iteration 2903, loss = 0.01068155\n",
      "Iteration 2904, loss = 0.01067660\n",
      "Iteration 2905, loss = 0.01067183\n",
      "Iteration 2906, loss = 0.01066706\n",
      "Iteration 2907, loss = 0.01066233\n",
      "Iteration 2908, loss = 0.01065733\n",
      "Iteration 2909, loss = 0.01065284\n",
      "Iteration 2910, loss = 0.01064955\n",
      "Iteration 2911, loss = 0.01064361\n",
      "Iteration 2912, loss = 0.01063914\n",
      "Iteration 2913, loss = 0.01063465\n",
      "Iteration 2914, loss = 0.01063045\n",
      "Iteration 2915, loss = 0.01062596\n",
      "Iteration 2916, loss = 0.01062140\n",
      "Iteration 2917, loss = 0.01061688\n",
      "Iteration 2918, loss = 0.01061322\n",
      "Iteration 2919, loss = 0.01060837\n",
      "Iteration 2920, loss = 0.01060514\n",
      "Iteration 2921, loss = 0.01060004\n",
      "Iteration 2922, loss = 0.01059647\n",
      "Iteration 2923, loss = 0.01059231\n",
      "Iteration 2924, loss = 0.01058702\n",
      "Iteration 2925, loss = 0.01058308\n",
      "Iteration 2926, loss = 0.01057864\n",
      "Iteration 2927, loss = 0.01057427\n",
      "Iteration 2928, loss = 0.01056981\n",
      "Iteration 2929, loss = 0.01056532\n",
      "Iteration 2930, loss = 0.01055942\n",
      "Iteration 2931, loss = 0.01055425\n",
      "Iteration 2932, loss = 0.01055024\n",
      "Iteration 2933, loss = 0.01054493\n",
      "Iteration 2934, loss = 0.01054041\n",
      "Iteration 2935, loss = 0.01053652\n",
      "Iteration 2936, loss = 0.01053057\n",
      "Iteration 2937, loss = 0.01052738\n",
      "Iteration 2938, loss = 0.01052080\n",
      "Iteration 2939, loss = 0.01051665\n",
      "Iteration 2940, loss = 0.01051188\n",
      "Iteration 2941, loss = 0.01050739\n",
      "Iteration 2942, loss = 0.01050238\n",
      "Iteration 2943, loss = 0.01049797\n",
      "Iteration 2944, loss = 0.01049330\n",
      "Iteration 2945, loss = 0.01048906\n",
      "Iteration 2946, loss = 0.01048596\n",
      "Iteration 2947, loss = 0.01048142\n",
      "Iteration 2948, loss = 0.01047808\n",
      "Iteration 2949, loss = 0.01047609\n",
      "Iteration 2950, loss = 0.01047030\n",
      "Iteration 2951, loss = 0.01046574\n",
      "Iteration 2952, loss = 0.01046155\n",
      "Iteration 2953, loss = 0.01045641\n",
      "Iteration 2954, loss = 0.01045117\n",
      "Iteration 2955, loss = 0.01044744\n",
      "Iteration 2956, loss = 0.01044354\n",
      "Iteration 2957, loss = 0.01043738\n",
      "Iteration 2958, loss = 0.01043292\n",
      "Iteration 2959, loss = 0.01042799\n",
      "Iteration 2960, loss = 0.01042285\n",
      "Iteration 2961, loss = 0.01041807\n",
      "Iteration 2962, loss = 0.01041449\n",
      "Iteration 2963, loss = 0.01040879\n",
      "Iteration 2964, loss = 0.01040325\n",
      "Iteration 2965, loss = 0.01039903\n",
      "Iteration 2966, loss = 0.01039431\n",
      "Iteration 2967, loss = 0.01039095\n",
      "Iteration 2968, loss = 0.01038541\n",
      "Iteration 2969, loss = 0.01038274\n",
      "Iteration 2970, loss = 0.01037562\n",
      "Iteration 2971, loss = 0.01037060\n",
      "Iteration 2972, loss = 0.01036619\n",
      "Iteration 2973, loss = 0.01036171\n",
      "Iteration 2974, loss = 0.01035691\n",
      "Iteration 2975, loss = 0.01035276\n",
      "Iteration 2976, loss = 0.01034852\n",
      "Iteration 2977, loss = 0.01034384\n",
      "Iteration 2978, loss = 0.01033967\n",
      "Iteration 2979, loss = 0.01033553\n",
      "Iteration 2980, loss = 0.01033113\n",
      "Iteration 2981, loss = 0.01032737\n",
      "Iteration 2982, loss = 0.01032371\n",
      "Iteration 2983, loss = 0.01031956\n",
      "Iteration 2984, loss = 0.01031591\n",
      "Iteration 2985, loss = 0.01031057\n",
      "Iteration 2986, loss = 0.01030662\n",
      "Iteration 2987, loss = 0.01030249\n",
      "Iteration 2988, loss = 0.01029853\n",
      "Iteration 2989, loss = 0.01029442\n",
      "Iteration 2990, loss = 0.01029123\n",
      "Iteration 2991, loss = 0.01028648\n",
      "Iteration 2992, loss = 0.01028237\n",
      "Iteration 2993, loss = 0.01027816\n",
      "Iteration 2994, loss = 0.01027376\n",
      "Iteration 2995, loss = 0.01026977\n",
      "Iteration 2996, loss = 0.01026546\n",
      "Iteration 2997, loss = 0.01026110\n",
      "Iteration 2998, loss = 0.01025618\n",
      "Iteration 2999, loss = 0.01025197\n",
      "Iteration 3000, loss = 0.01024730\n",
      "Iteration 3001, loss = 0.01024405\n",
      "Iteration 3002, loss = 0.01023926\n",
      "Iteration 3003, loss = 0.01023461\n",
      "Iteration 3004, loss = 0.01023004\n",
      "Iteration 3005, loss = 0.01022590\n",
      "Iteration 3006, loss = 0.01022162\n",
      "Iteration 3007, loss = 0.01021804\n",
      "Iteration 3008, loss = 0.01021363\n",
      "Iteration 3009, loss = 0.01020962\n",
      "Iteration 3010, loss = 0.01020522\n",
      "Iteration 3011, loss = 0.01020120\n",
      "Iteration 3012, loss = 0.01019631\n",
      "Iteration 3013, loss = 0.01019173\n",
      "Iteration 3014, loss = 0.01018726\n",
      "Iteration 3015, loss = 0.01018308\n",
      "Iteration 3016, loss = 0.01017844\n",
      "Iteration 3017, loss = 0.01017423\n",
      "Iteration 3018, loss = 0.01016914\n",
      "Iteration 3019, loss = 0.01016527\n",
      "Iteration 3020, loss = 0.01015981\n",
      "Iteration 3021, loss = 0.01015479\n",
      "Iteration 3022, loss = 0.01014917\n",
      "Iteration 3023, loss = 0.01014480\n",
      "Iteration 3024, loss = 0.01014040\n",
      "Iteration 3025, loss = 0.01013780\n",
      "Iteration 3026, loss = 0.01013175\n",
      "Iteration 3027, loss = 0.01012868\n",
      "Iteration 3028, loss = 0.01012353\n",
      "Iteration 3029, loss = 0.01011940\n",
      "Iteration 3030, loss = 0.01011564\n",
      "Iteration 3031, loss = 0.01011192\n",
      "Iteration 3032, loss = 0.01010644\n",
      "Iteration 3033, loss = 0.01010199\n",
      "Iteration 3034, loss = 0.01009786\n",
      "Iteration 3035, loss = 0.01009266\n",
      "Iteration 3036, loss = 0.01008708\n",
      "Iteration 3037, loss = 0.01008221\n",
      "Iteration 3038, loss = 0.01007742\n",
      "Iteration 3039, loss = 0.01007474\n",
      "Iteration 3040, loss = 0.01006838\n",
      "Iteration 3041, loss = 0.01006463\n",
      "Iteration 3042, loss = 0.01006197\n",
      "Iteration 3043, loss = 0.01005594\n",
      "Iteration 3044, loss = 0.01005212\n",
      "Iteration 3045, loss = 0.01004935\n",
      "Iteration 3046, loss = 0.01004549\n",
      "Iteration 3047, loss = 0.01004047\n",
      "Iteration 3048, loss = 0.01003753\n",
      "Iteration 3049, loss = 0.01003300\n",
      "Iteration 3050, loss = 0.01002926\n",
      "Iteration 3051, loss = 0.01002464\n",
      "Iteration 3052, loss = 0.01002007\n",
      "Iteration 3053, loss = 0.01001505\n",
      "Iteration 3054, loss = 0.01001085\n",
      "Iteration 3055, loss = 0.01000697\n",
      "Iteration 3056, loss = 0.01000236\n",
      "Iteration 3057, loss = 0.00999778\n",
      "Iteration 3058, loss = 0.00999322\n",
      "Iteration 3059, loss = 0.00998880\n",
      "Iteration 3060, loss = 0.00998557\n",
      "Iteration 3061, loss = 0.00998090\n",
      "Iteration 3062, loss = 0.00997606\n",
      "Iteration 3063, loss = 0.00997150\n",
      "Iteration 3064, loss = 0.00996701\n",
      "Iteration 3065, loss = 0.00996194\n",
      "Iteration 3066, loss = 0.00995776\n",
      "Iteration 3067, loss = 0.00995385\n",
      "Iteration 3068, loss = 0.00994942\n",
      "Iteration 3069, loss = 0.00994558\n",
      "Iteration 3070, loss = 0.00994241\n",
      "Iteration 3071, loss = 0.00993794\n",
      "Iteration 3072, loss = 0.00993298\n",
      "Iteration 3073, loss = 0.00992874\n",
      "Iteration 3074, loss = 0.00992467\n",
      "Iteration 3075, loss = 0.00992037\n",
      "Iteration 3076, loss = 0.00991580\n",
      "Iteration 3077, loss = 0.00991166\n",
      "Iteration 3078, loss = 0.00990685\n",
      "Iteration 3079, loss = 0.00990263\n",
      "Iteration 3080, loss = 0.00989988\n",
      "Iteration 3081, loss = 0.00989454\n",
      "Iteration 3082, loss = 0.00989111\n",
      "Iteration 3083, loss = 0.00988641\n",
      "Iteration 3084, loss = 0.00988217\n",
      "Iteration 3085, loss = 0.00987796\n",
      "Iteration 3086, loss = 0.00987520\n",
      "Iteration 3087, loss = 0.00987036\n",
      "Iteration 3088, loss = 0.00986656\n",
      "Iteration 3089, loss = 0.00986199\n",
      "Iteration 3090, loss = 0.00985782\n",
      "Iteration 3091, loss = 0.00985336\n",
      "Iteration 3092, loss = 0.00984881\n",
      "Iteration 3093, loss = 0.00984464\n",
      "Iteration 3094, loss = 0.00984123\n",
      "Iteration 3095, loss = 0.00983679\n",
      "Iteration 3096, loss = 0.00983238\n",
      "Iteration 3097, loss = 0.00982802\n",
      "Iteration 3098, loss = 0.00982342\n",
      "Iteration 3099, loss = 0.00981895\n",
      "Iteration 3100, loss = 0.00981601\n",
      "Iteration 3101, loss = 0.00981049\n",
      "Iteration 3102, loss = 0.00980627\n",
      "Iteration 3103, loss = 0.00980183\n",
      "Iteration 3104, loss = 0.00979907\n",
      "Iteration 3105, loss = 0.00979362\n",
      "Iteration 3106, loss = 0.00979084\n",
      "Iteration 3107, loss = 0.00978653\n",
      "Iteration 3108, loss = 0.00978227\n",
      "Iteration 3109, loss = 0.00977852\n",
      "Iteration 3110, loss = 0.00977472\n",
      "Iteration 3111, loss = 0.00977188\n",
      "Iteration 3112, loss = 0.00976726\n",
      "Iteration 3113, loss = 0.00976328\n",
      "Iteration 3114, loss = 0.00975961\n",
      "Iteration 3115, loss = 0.00975536\n",
      "Iteration 3116, loss = 0.00975198\n",
      "Iteration 3117, loss = 0.00974706\n",
      "Iteration 3118, loss = 0.00974280\n",
      "Iteration 3119, loss = 0.00973907\n",
      "Iteration 3120, loss = 0.00973466\n",
      "Iteration 3121, loss = 0.00972992\n",
      "Iteration 3122, loss = 0.00972632\n",
      "Iteration 3123, loss = 0.00972213\n",
      "Iteration 3124, loss = 0.00971823\n",
      "Iteration 3125, loss = 0.00971408\n",
      "Iteration 3126, loss = 0.00971008\n",
      "Iteration 3127, loss = 0.00970661\n",
      "Iteration 3128, loss = 0.00970167\n",
      "Iteration 3129, loss = 0.00969730\n",
      "Iteration 3130, loss = 0.00969350\n",
      "Iteration 3131, loss = 0.00968960\n",
      "Iteration 3132, loss = 0.00968523\n",
      "Iteration 3133, loss = 0.00968084\n",
      "Iteration 3134, loss = 0.00967690\n",
      "Iteration 3135, loss = 0.00967384\n",
      "Iteration 3136, loss = 0.00966903\n",
      "Iteration 3137, loss = 0.00966528\n",
      "Iteration 3138, loss = 0.00966222\n",
      "Iteration 3139, loss = 0.00965771\n",
      "Iteration 3140, loss = 0.00965352\n",
      "Iteration 3141, loss = 0.00964923\n",
      "Iteration 3142, loss = 0.00964526\n",
      "Iteration 3143, loss = 0.00964094\n",
      "Iteration 3144, loss = 0.00963905\n",
      "Iteration 3145, loss = 0.00963243\n",
      "Iteration 3146, loss = 0.00962852\n",
      "Iteration 3147, loss = 0.00962381\n",
      "Iteration 3148, loss = 0.00961980\n",
      "Iteration 3149, loss = 0.00961620\n",
      "Iteration 3150, loss = 0.00961136\n",
      "Iteration 3151, loss = 0.00961018\n",
      "Iteration 3152, loss = 0.00960425\n",
      "Iteration 3153, loss = 0.00959974\n",
      "Iteration 3154, loss = 0.00959573\n",
      "Iteration 3155, loss = 0.00959228\n",
      "Iteration 3156, loss = 0.00958808\n",
      "Iteration 3157, loss = 0.00958522\n",
      "Iteration 3158, loss = 0.00958117\n",
      "Iteration 3159, loss = 0.00957659\n",
      "Iteration 3160, loss = 0.00957240\n",
      "Iteration 3161, loss = 0.00956796\n",
      "Iteration 3162, loss = 0.00956423\n",
      "Iteration 3163, loss = 0.00955962\n",
      "Iteration 3164, loss = 0.00955494\n",
      "Iteration 3165, loss = 0.00955044\n",
      "Iteration 3166, loss = 0.00954814\n",
      "Iteration 3167, loss = 0.00954193\n",
      "Iteration 3168, loss = 0.00953815\n",
      "Iteration 3169, loss = 0.00953390\n",
      "Iteration 3170, loss = 0.00953213\n",
      "Iteration 3171, loss = 0.00952661\n",
      "Iteration 3172, loss = 0.00952099\n",
      "Iteration 3173, loss = 0.00951744\n",
      "Iteration 3174, loss = 0.00951392\n",
      "Iteration 3175, loss = 0.00950892\n",
      "Iteration 3176, loss = 0.00950489\n",
      "Iteration 3177, loss = 0.00950084\n",
      "Iteration 3178, loss = 0.00949757\n",
      "Iteration 3179, loss = 0.00949340\n",
      "Iteration 3180, loss = 0.00948909\n",
      "Iteration 3181, loss = 0.00948576\n",
      "Iteration 3182, loss = 0.00948097\n",
      "Iteration 3183, loss = 0.00947759\n",
      "Iteration 3184, loss = 0.00947346\n",
      "Iteration 3185, loss = 0.00946975\n",
      "Iteration 3186, loss = 0.00946550\n",
      "Iteration 3187, loss = 0.00946231\n",
      "Iteration 3188, loss = 0.00945826\n",
      "Iteration 3189, loss = 0.00945413\n",
      "Iteration 3190, loss = 0.00945041\n",
      "Iteration 3191, loss = 0.00944648\n",
      "Iteration 3192, loss = 0.00944197\n",
      "Iteration 3193, loss = 0.00943826\n",
      "Iteration 3194, loss = 0.00943419\n",
      "Iteration 3195, loss = 0.00943119\n",
      "Iteration 3196, loss = 0.00942727\n",
      "Iteration 3197, loss = 0.00942373\n",
      "Iteration 3198, loss = 0.00941869\n",
      "Iteration 3199, loss = 0.00941461\n",
      "Iteration 3200, loss = 0.00941118\n",
      "Iteration 3201, loss = 0.00940754\n",
      "Iteration 3202, loss = 0.00940361\n",
      "Iteration 3203, loss = 0.00939907\n",
      "Iteration 3204, loss = 0.00939570\n",
      "Iteration 3205, loss = 0.00939234\n",
      "Iteration 3206, loss = 0.00938773\n",
      "Iteration 3207, loss = 0.00938359\n",
      "Iteration 3208, loss = 0.00937959\n",
      "Iteration 3209, loss = 0.00937663\n",
      "Iteration 3210, loss = 0.00937232\n",
      "Iteration 3211, loss = 0.00936766\n",
      "Iteration 3212, loss = 0.00936372\n",
      "Iteration 3213, loss = 0.00936024\n",
      "Iteration 3214, loss = 0.00935597\n",
      "Iteration 3215, loss = 0.00935241\n",
      "Iteration 3216, loss = 0.00934970\n",
      "Iteration 3217, loss = 0.00934585\n",
      "Iteration 3218, loss = 0.00934086\n",
      "Iteration 3219, loss = 0.00933733\n",
      "Iteration 3220, loss = 0.00933386\n",
      "Iteration 3221, loss = 0.00933009\n",
      "Iteration 3222, loss = 0.00932648\n",
      "Iteration 3223, loss = 0.00932368\n",
      "Iteration 3224, loss = 0.00931966\n",
      "Iteration 3225, loss = 0.00931626\n",
      "Iteration 3226, loss = 0.00931258\n",
      "Iteration 3227, loss = 0.00930878\n",
      "Iteration 3228, loss = 0.00930600\n",
      "Iteration 3229, loss = 0.00930199\n",
      "Iteration 3230, loss = 0.00929810\n",
      "Iteration 3231, loss = 0.00929427\n",
      "Iteration 3232, loss = 0.00929060\n",
      "Iteration 3233, loss = 0.00928655\n",
      "Iteration 3234, loss = 0.00928284\n",
      "Iteration 3235, loss = 0.00928022\n",
      "Iteration 3236, loss = 0.00927553\n",
      "Iteration 3237, loss = 0.00927120\n",
      "Iteration 3238, loss = 0.00926860\n",
      "Iteration 3239, loss = 0.00926465\n",
      "Iteration 3240, loss = 0.00926077\n",
      "Iteration 3241, loss = 0.00925719\n",
      "Iteration 3242, loss = 0.00925361\n",
      "Iteration 3243, loss = 0.00924990\n",
      "Iteration 3244, loss = 0.00924626\n",
      "Iteration 3245, loss = 0.00924259\n",
      "Iteration 3246, loss = 0.00923853\n",
      "Iteration 3247, loss = 0.00923474\n",
      "Iteration 3248, loss = 0.00923036\n",
      "Iteration 3249, loss = 0.00922625\n",
      "Iteration 3250, loss = 0.00922249\n",
      "Iteration 3251, loss = 0.00921840\n",
      "Iteration 3252, loss = 0.00921525\n",
      "Iteration 3253, loss = 0.00921141\n",
      "Iteration 3254, loss = 0.00920869\n",
      "Iteration 3255, loss = 0.00920407\n",
      "Iteration 3256, loss = 0.00919988\n",
      "Iteration 3257, loss = 0.00919562\n",
      "Iteration 3258, loss = 0.00919139\n",
      "Iteration 3259, loss = 0.00918758\n",
      "Iteration 3260, loss = 0.00918358\n",
      "Iteration 3261, loss = 0.00917952\n",
      "Iteration 3262, loss = 0.00917645\n",
      "Iteration 3263, loss = 0.00917143\n",
      "Iteration 3264, loss = 0.00916761\n",
      "Iteration 3265, loss = 0.00916394\n",
      "Iteration 3266, loss = 0.00915951\n",
      "Iteration 3267, loss = 0.00915628\n",
      "Iteration 3268, loss = 0.00915256\n",
      "Iteration 3269, loss = 0.00914975\n",
      "Iteration 3270, loss = 0.00914620\n",
      "Iteration 3271, loss = 0.00914246\n",
      "Iteration 3272, loss = 0.00913825\n",
      "Iteration 3273, loss = 0.00913513\n",
      "Iteration 3274, loss = 0.00913092\n",
      "Iteration 3275, loss = 0.00912631\n",
      "Iteration 3276, loss = 0.00912243\n",
      "Iteration 3277, loss = 0.00911996\n",
      "Iteration 3278, loss = 0.00911523\n",
      "Iteration 3279, loss = 0.00911114\n",
      "Iteration 3280, loss = 0.00910716\n",
      "Iteration 3281, loss = 0.00910397\n",
      "Iteration 3282, loss = 0.00909908\n",
      "Iteration 3283, loss = 0.00909664\n",
      "Iteration 3284, loss = 0.00909173\n",
      "Iteration 3285, loss = 0.00908775\n",
      "Iteration 3286, loss = 0.00908328\n",
      "Iteration 3287, loss = 0.00907949\n",
      "Iteration 3288, loss = 0.00907609\n",
      "Iteration 3289, loss = 0.00907184\n",
      "Iteration 3290, loss = 0.00906802\n",
      "Iteration 3291, loss = 0.00906441\n",
      "Iteration 3292, loss = 0.00906063\n",
      "Iteration 3293, loss = 0.00905699\n",
      "Iteration 3294, loss = 0.00905431\n",
      "Iteration 3295, loss = 0.00905025\n",
      "Iteration 3296, loss = 0.00904727\n",
      "Iteration 3297, loss = 0.00904256\n",
      "Iteration 3298, loss = 0.00903865\n",
      "Iteration 3299, loss = 0.00903553\n",
      "Iteration 3300, loss = 0.00903188\n",
      "Iteration 3301, loss = 0.00903029\n",
      "Iteration 3302, loss = 0.00902549\n",
      "Iteration 3303, loss = 0.00902178\n",
      "Iteration 3304, loss = 0.00901860\n",
      "Iteration 3305, loss = 0.00901580\n",
      "Iteration 3306, loss = 0.00901157\n",
      "Iteration 3307, loss = 0.00900778\n",
      "Iteration 3308, loss = 0.00900426\n",
      "Iteration 3309, loss = 0.00900073\n",
      "Iteration 3310, loss = 0.00899744\n",
      "Iteration 3311, loss = 0.00899316\n",
      "Iteration 3312, loss = 0.00898947\n",
      "Iteration 3313, loss = 0.00898560\n",
      "Iteration 3314, loss = 0.00898224\n",
      "Iteration 3315, loss = 0.00897907\n",
      "Iteration 3316, loss = 0.00897474\n",
      "Iteration 3317, loss = 0.00897100\n",
      "Iteration 3318, loss = 0.00896789\n",
      "Iteration 3319, loss = 0.00896418\n",
      "Iteration 3320, loss = 0.00896068\n",
      "Iteration 3321, loss = 0.00895677\n",
      "Iteration 3322, loss = 0.00895379\n",
      "Iteration 3323, loss = 0.00894956\n",
      "Iteration 3324, loss = 0.00894650\n",
      "Iteration 3325, loss = 0.00894315\n",
      "Iteration 3326, loss = 0.00893971\n",
      "Iteration 3327, loss = 0.00893607\n",
      "Iteration 3328, loss = 0.00893295\n",
      "Iteration 3329, loss = 0.00892953\n",
      "Iteration 3330, loss = 0.00892594\n",
      "Iteration 3331, loss = 0.00892219\n",
      "Iteration 3332, loss = 0.00891896\n",
      "Iteration 3333, loss = 0.00891561\n",
      "Iteration 3334, loss = 0.00891193\n",
      "Iteration 3335, loss = 0.00890863\n",
      "Iteration 3336, loss = 0.00890560\n",
      "Iteration 3337, loss = 0.00890205\n",
      "Iteration 3338, loss = 0.00889902\n",
      "Iteration 3339, loss = 0.00889744\n",
      "Iteration 3340, loss = 0.00889255\n",
      "Iteration 3341, loss = 0.00888893\n",
      "Iteration 3342, loss = 0.00888595\n",
      "Iteration 3343, loss = 0.00888221\n",
      "Iteration 3344, loss = 0.00887967\n",
      "Iteration 3345, loss = 0.00887599\n",
      "Iteration 3346, loss = 0.00887284\n",
      "Iteration 3347, loss = 0.00886865\n",
      "Iteration 3348, loss = 0.00886576\n",
      "Iteration 3349, loss = 0.00886195\n",
      "Iteration 3350, loss = 0.00885870\n",
      "Iteration 3351, loss = 0.00885525\n",
      "Iteration 3352, loss = 0.00885157\n",
      "Iteration 3353, loss = 0.00884837\n",
      "Iteration 3354, loss = 0.00884516\n",
      "Iteration 3355, loss = 0.00884171\n",
      "Iteration 3356, loss = 0.00883843\n",
      "Iteration 3357, loss = 0.00883530\n",
      "Iteration 3358, loss = 0.00883141\n",
      "Iteration 3359, loss = 0.00882732\n",
      "Iteration 3360, loss = 0.00882491\n",
      "Iteration 3361, loss = 0.00882064\n",
      "Iteration 3362, loss = 0.00881749\n",
      "Iteration 3363, loss = 0.00881370\n",
      "Iteration 3364, loss = 0.00881049\n",
      "Iteration 3365, loss = 0.00880654\n",
      "Iteration 3366, loss = 0.00880269\n",
      "Iteration 3367, loss = 0.00879880\n",
      "Iteration 3368, loss = 0.00879543\n",
      "Iteration 3369, loss = 0.00879147\n",
      "Iteration 3370, loss = 0.00878842\n",
      "Iteration 3371, loss = 0.00878431\n",
      "Iteration 3372, loss = 0.00878219\n",
      "Iteration 3373, loss = 0.00877835\n",
      "Iteration 3374, loss = 0.00877451\n",
      "Iteration 3375, loss = 0.00877170\n",
      "Iteration 3376, loss = 0.00876785\n",
      "Iteration 3377, loss = 0.00876549\n",
      "Iteration 3378, loss = 0.00876167\n",
      "Iteration 3379, loss = 0.00875843\n",
      "Iteration 3380, loss = 0.00875524\n",
      "Iteration 3381, loss = 0.00875229\n",
      "Iteration 3382, loss = 0.00874892\n",
      "Iteration 3383, loss = 0.00874578\n",
      "Iteration 3384, loss = 0.00874223\n",
      "Iteration 3385, loss = 0.00874041\n",
      "Iteration 3386, loss = 0.00873637\n",
      "Iteration 3387, loss = 0.00873338\n",
      "Iteration 3388, loss = 0.00872985\n",
      "Iteration 3389, loss = 0.00872705\n",
      "Iteration 3390, loss = 0.00872388\n",
      "Iteration 3391, loss = 0.00871999\n",
      "Iteration 3392, loss = 0.00871695\n",
      "Iteration 3393, loss = 0.00871334\n",
      "Iteration 3394, loss = 0.00871004\n",
      "Iteration 3395, loss = 0.00870658\n",
      "Iteration 3396, loss = 0.00870342\n",
      "Iteration 3397, loss = 0.00870114\n",
      "Iteration 3398, loss = 0.00869720\n",
      "Iteration 3399, loss = 0.00869400\n",
      "Iteration 3400, loss = 0.00869015\n",
      "Iteration 3401, loss = 0.00868684\n",
      "Iteration 3402, loss = 0.00868252\n",
      "Iteration 3403, loss = 0.00867976\n",
      "Iteration 3404, loss = 0.00867588\n",
      "Iteration 3405, loss = 0.00867242\n",
      "Iteration 3406, loss = 0.00866924\n",
      "Iteration 3407, loss = 0.00866510\n",
      "Iteration 3408, loss = 0.00866173\n",
      "Iteration 3409, loss = 0.00865825\n",
      "Iteration 3410, loss = 0.00865495\n",
      "Iteration 3411, loss = 0.00865171\n",
      "Iteration 3412, loss = 0.00864818\n",
      "Iteration 3413, loss = 0.00864439\n",
      "Iteration 3414, loss = 0.00864183\n",
      "Iteration 3415, loss = 0.00863838\n",
      "Iteration 3416, loss = 0.00863495\n",
      "Iteration 3417, loss = 0.00863229\n",
      "Iteration 3418, loss = 0.00862825\n",
      "Iteration 3419, loss = 0.00862503\n",
      "Iteration 3420, loss = 0.00862188\n",
      "Iteration 3421, loss = 0.00861862\n",
      "Iteration 3422, loss = 0.00861538\n",
      "Iteration 3423, loss = 0.00861241\n",
      "Iteration 3424, loss = 0.00860885\n",
      "Iteration 3425, loss = 0.00860539\n",
      "Iteration 3426, loss = 0.00860230\n",
      "Iteration 3427, loss = 0.00860016\n",
      "Iteration 3428, loss = 0.00859629\n",
      "Iteration 3429, loss = 0.00859304\n",
      "Iteration 3430, loss = 0.00859156\n",
      "Iteration 3431, loss = 0.00858768\n",
      "Iteration 3432, loss = 0.00858457\n",
      "Iteration 3433, loss = 0.00858118\n",
      "Iteration 3434, loss = 0.00857780\n",
      "Iteration 3435, loss = 0.00857506\n",
      "Iteration 3436, loss = 0.00857161\n",
      "Iteration 3437, loss = 0.00856704\n",
      "Iteration 3438, loss = 0.00856378\n",
      "Iteration 3439, loss = 0.00856048\n",
      "Iteration 3440, loss = 0.00855685\n",
      "Iteration 3441, loss = 0.00855388\n",
      "Iteration 3442, loss = 0.00854970\n",
      "Iteration 3443, loss = 0.00854647\n",
      "Iteration 3444, loss = 0.00854363\n",
      "Iteration 3445, loss = 0.00854029\n",
      "Iteration 3446, loss = 0.00853632\n",
      "Iteration 3447, loss = 0.00853284\n",
      "Iteration 3448, loss = 0.00853030\n",
      "Iteration 3449, loss = 0.00852621\n",
      "Iteration 3450, loss = 0.00852268\n",
      "Iteration 3451, loss = 0.00851921\n",
      "Iteration 3452, loss = 0.00851616\n",
      "Iteration 3453, loss = 0.00851300\n",
      "Iteration 3454, loss = 0.00851001\n",
      "Iteration 3455, loss = 0.00850673\n",
      "Iteration 3456, loss = 0.00850363\n",
      "Iteration 3457, loss = 0.00850274\n",
      "Iteration 3458, loss = 0.00849734\n",
      "Iteration 3459, loss = 0.00849359\n",
      "Iteration 3460, loss = 0.00849062\n",
      "Iteration 3461, loss = 0.00848680\n",
      "Iteration 3462, loss = 0.00848332\n",
      "Iteration 3463, loss = 0.00848013\n",
      "Iteration 3464, loss = 0.00847625\n",
      "Iteration 3465, loss = 0.00847363\n",
      "Iteration 3466, loss = 0.00846972\n",
      "Iteration 3467, loss = 0.00846692\n",
      "Iteration 3468, loss = 0.00846349\n",
      "Iteration 3469, loss = 0.00846043\n",
      "Iteration 3470, loss = 0.00845833\n",
      "Iteration 3471, loss = 0.00845484\n",
      "Iteration 3472, loss = 0.00845088\n",
      "Iteration 3473, loss = 0.00844763\n",
      "Iteration 3474, loss = 0.00844405\n",
      "Iteration 3475, loss = 0.00844101\n",
      "Iteration 3476, loss = 0.00843813\n",
      "Iteration 3477, loss = 0.00843536\n",
      "Iteration 3478, loss = 0.00843206\n",
      "Iteration 3479, loss = 0.00842942\n",
      "Iteration 3480, loss = 0.00842603\n",
      "Iteration 3481, loss = 0.00842322\n",
      "Iteration 3482, loss = 0.00842164\n",
      "Iteration 3483, loss = 0.00841953\n",
      "Iteration 3484, loss = 0.00841567\n",
      "Iteration 3485, loss = 0.00841273\n",
      "Iteration 3486, loss = 0.00840975\n",
      "Iteration 3487, loss = 0.00840697\n",
      "Iteration 3488, loss = 0.00840416\n",
      "Iteration 3489, loss = 0.00840115\n",
      "Iteration 3490, loss = 0.00839821\n",
      "Iteration 3491, loss = 0.00839562\n",
      "Iteration 3492, loss = 0.00839305\n",
      "Iteration 3493, loss = 0.00838968\n",
      "Iteration 3494, loss = 0.00838636\n",
      "Iteration 3495, loss = 0.00838281\n",
      "Iteration 3496, loss = 0.00838101\n",
      "Iteration 3497, loss = 0.00837661\n",
      "Iteration 3498, loss = 0.00837391\n",
      "Iteration 3499, loss = 0.00837126\n",
      "Iteration 3500, loss = 0.00836716\n",
      "Iteration 3501, loss = 0.00836338\n",
      "Iteration 3502, loss = 0.00835939\n",
      "Iteration 3503, loss = 0.00835638\n",
      "Iteration 3504, loss = 0.00835265\n",
      "Iteration 3505, loss = 0.00834974\n",
      "Iteration 3506, loss = 0.00834588\n",
      "Iteration 3507, loss = 0.00834263\n",
      "Iteration 3508, loss = 0.00833956\n",
      "Iteration 3509, loss = 0.00833548\n",
      "Iteration 3510, loss = 0.00833308\n",
      "Iteration 3511, loss = 0.00832920\n",
      "Iteration 3512, loss = 0.00832564\n",
      "Iteration 3513, loss = 0.00832273\n",
      "Iteration 3514, loss = 0.00831909\n",
      "Iteration 3515, loss = 0.00831596\n",
      "Iteration 3516, loss = 0.00831274\n",
      "Iteration 3517, loss = 0.00830991\n",
      "Iteration 3518, loss = 0.00830663\n",
      "Iteration 3519, loss = 0.00830373\n",
      "Iteration 3520, loss = 0.00830064\n",
      "Iteration 3521, loss = 0.00829763\n",
      "Iteration 3522, loss = 0.00829484\n",
      "Iteration 3523, loss = 0.00829173\n",
      "Iteration 3524, loss = 0.00828937\n",
      "Iteration 3525, loss = 0.00828594\n",
      "Iteration 3526, loss = 0.00828379\n",
      "Iteration 3527, loss = 0.00828138\n",
      "Iteration 3528, loss = 0.00827853\n",
      "Iteration 3529, loss = 0.00827479\n",
      "Iteration 3530, loss = 0.00827273\n",
      "Iteration 3531, loss = 0.00826831\n",
      "Iteration 3532, loss = 0.00826659\n",
      "Iteration 3533, loss = 0.00826277\n",
      "Iteration 3534, loss = 0.00826004\n",
      "Iteration 3535, loss = 0.00825713\n",
      "Iteration 3536, loss = 0.00825392\n",
      "Iteration 3537, loss = 0.00825129\n",
      "Iteration 3538, loss = 0.00824862\n",
      "Iteration 3539, loss = 0.00824546\n",
      "Iteration 3540, loss = 0.00824204\n",
      "Iteration 3541, loss = 0.00823904\n",
      "Iteration 3542, loss = 0.00823642\n",
      "Iteration 3543, loss = 0.00823346\n",
      "Iteration 3544, loss = 0.00823033\n",
      "Iteration 3545, loss = 0.00822700\n",
      "Iteration 3546, loss = 0.00822399\n",
      "Iteration 3547, loss = 0.00822075\n",
      "Iteration 3548, loss = 0.00821816\n",
      "Iteration 3549, loss = 0.00821521\n",
      "Iteration 3550, loss = 0.00821246\n",
      "Iteration 3551, loss = 0.00820984\n",
      "Iteration 3552, loss = 0.00820631\n",
      "Iteration 3553, loss = 0.00820347\n",
      "Iteration 3554, loss = 0.00819977\n",
      "Iteration 3555, loss = 0.00819597\n",
      "Iteration 3556, loss = 0.00819229\n",
      "Iteration 3557, loss = 0.00818948\n",
      "Iteration 3558, loss = 0.00818637\n",
      "Iteration 3559, loss = 0.00818288\n",
      "Iteration 3560, loss = 0.00817987\n",
      "Iteration 3561, loss = 0.00817656\n",
      "Iteration 3562, loss = 0.00817378\n",
      "Iteration 3563, loss = 0.00817006\n",
      "Iteration 3564, loss = 0.00816687\n",
      "Iteration 3565, loss = 0.00816335\n",
      "Iteration 3566, loss = 0.00816014\n",
      "Iteration 3567, loss = 0.00815712\n",
      "Iteration 3568, loss = 0.00815401\n",
      "Iteration 3569, loss = 0.00815054\n",
      "Iteration 3570, loss = 0.00814677\n",
      "Iteration 3571, loss = 0.00814420\n",
      "Iteration 3572, loss = 0.00814048\n",
      "Iteration 3573, loss = 0.00813713\n",
      "Iteration 3574, loss = 0.00813492\n",
      "Iteration 3575, loss = 0.00813142\n",
      "Iteration 3576, loss = 0.00812837\n",
      "Iteration 3577, loss = 0.00812496\n",
      "Iteration 3578, loss = 0.00812197\n",
      "Iteration 3579, loss = 0.00811901\n",
      "Iteration 3580, loss = 0.00811625\n",
      "Iteration 3581, loss = 0.00811363\n",
      "Iteration 3582, loss = 0.00811066\n",
      "Iteration 3583, loss = 0.00810753\n",
      "Iteration 3584, loss = 0.00810457\n",
      "Iteration 3585, loss = 0.00810204\n",
      "Iteration 3586, loss = 0.00809967\n",
      "Iteration 3587, loss = 0.00809726\n",
      "Iteration 3588, loss = 0.00809356\n",
      "Iteration 3589, loss = 0.00809109\n",
      "Iteration 3590, loss = 0.00808943\n",
      "Iteration 3591, loss = 0.00808699\n",
      "Iteration 3592, loss = 0.00808327\n",
      "Iteration 3593, loss = 0.00808058\n",
      "Iteration 3594, loss = 0.00807810\n",
      "Iteration 3595, loss = 0.00807441\n",
      "Iteration 3596, loss = 0.00807123\n",
      "Iteration 3597, loss = 0.00806941\n",
      "Iteration 3598, loss = 0.00806579\n",
      "Iteration 3599, loss = 0.00806261\n",
      "Iteration 3600, loss = 0.00805982\n",
      "Iteration 3601, loss = 0.00805716\n",
      "Iteration 3602, loss = 0.00805412\n",
      "Iteration 3603, loss = 0.00805150\n",
      "Iteration 3604, loss = 0.00804879\n",
      "Iteration 3605, loss = 0.00804578\n",
      "Iteration 3606, loss = 0.00804388\n",
      "Iteration 3607, loss = 0.00804039\n",
      "Iteration 3608, loss = 0.00803779\n",
      "Iteration 3609, loss = 0.00803428\n",
      "Iteration 3610, loss = 0.00803135\n",
      "Iteration 3611, loss = 0.00802809\n",
      "Iteration 3612, loss = 0.00802523\n",
      "Iteration 3613, loss = 0.00802306\n",
      "Iteration 3614, loss = 0.00801992\n",
      "Iteration 3615, loss = 0.00801730\n",
      "Iteration 3616, loss = 0.00801493\n",
      "Iteration 3617, loss = 0.00801108\n",
      "Iteration 3618, loss = 0.00800776\n",
      "Iteration 3619, loss = 0.00800481\n",
      "Iteration 3620, loss = 0.00800131\n",
      "Iteration 3621, loss = 0.00799782\n",
      "Iteration 3622, loss = 0.00799509\n",
      "Iteration 3623, loss = 0.00799205\n",
      "Iteration 3624, loss = 0.00798869\n",
      "Iteration 3625, loss = 0.00798560\n",
      "Iteration 3626, loss = 0.00798293\n",
      "Iteration 3627, loss = 0.00798018\n",
      "Iteration 3628, loss = 0.00797761\n",
      "Iteration 3629, loss = 0.00797469\n",
      "Iteration 3630, loss = 0.00797195\n",
      "Iteration 3631, loss = 0.00797052\n",
      "Iteration 3632, loss = 0.00796655\n",
      "Iteration 3633, loss = 0.00796401\n",
      "Iteration 3634, loss = 0.00796119\n",
      "Iteration 3635, loss = 0.00795858\n",
      "Iteration 3636, loss = 0.00795612\n",
      "Iteration 3637, loss = 0.00795282\n",
      "Iteration 3638, loss = 0.00795030\n",
      "Iteration 3639, loss = 0.00794700\n",
      "Iteration 3640, loss = 0.00794445\n",
      "Iteration 3641, loss = 0.00794137\n",
      "Iteration 3642, loss = 0.00793844\n",
      "Iteration 3643, loss = 0.00793556\n",
      "Iteration 3644, loss = 0.00793270\n",
      "Iteration 3645, loss = 0.00793017\n",
      "Iteration 3646, loss = 0.00792683\n",
      "Iteration 3647, loss = 0.00792401\n",
      "Iteration 3648, loss = 0.00792146\n",
      "Iteration 3649, loss = 0.00791870\n",
      "Iteration 3650, loss = 0.00791585\n",
      "Iteration 3651, loss = 0.00791305\n",
      "Iteration 3652, loss = 0.00791003\n",
      "Iteration 3653, loss = 0.00790811\n",
      "Iteration 3654, loss = 0.00790429\n",
      "Iteration 3655, loss = 0.00790024\n",
      "Iteration 3656, loss = 0.00789920\n",
      "Iteration 3657, loss = 0.00789382\n",
      "Iteration 3658, loss = 0.00789092\n",
      "Iteration 3659, loss = 0.00788796\n",
      "Iteration 3660, loss = 0.00788485\n",
      "Iteration 3661, loss = 0.00788215\n",
      "Iteration 3662, loss = 0.00787904\n",
      "Iteration 3663, loss = 0.00787610\n",
      "Iteration 3664, loss = 0.00787306\n",
      "Iteration 3665, loss = 0.00787012\n",
      "Iteration 3666, loss = 0.00786769\n",
      "Iteration 3667, loss = 0.00786469\n",
      "Iteration 3668, loss = 0.00786136\n",
      "Iteration 3669, loss = 0.00785829\n",
      "Iteration 3670, loss = 0.00785550\n",
      "Iteration 3671, loss = 0.00785306\n",
      "Iteration 3672, loss = 0.00784976\n",
      "Iteration 3673, loss = 0.00784680\n",
      "Iteration 3674, loss = 0.00784426\n",
      "Iteration 3675, loss = 0.00784171\n",
      "Iteration 3676, loss = 0.00783961\n",
      "Iteration 3677, loss = 0.00783690\n",
      "Iteration 3678, loss = 0.00783482\n",
      "Iteration 3679, loss = 0.00783154\n",
      "Iteration 3680, loss = 0.00782927\n",
      "Iteration 3681, loss = 0.00782694\n",
      "Iteration 3682, loss = 0.00782383\n",
      "Iteration 3683, loss = 0.00782145\n",
      "Iteration 3684, loss = 0.00781842\n",
      "Iteration 3685, loss = 0.00781639\n",
      "Iteration 3686, loss = 0.00781318\n",
      "Iteration 3687, loss = 0.00781062\n",
      "Iteration 3688, loss = 0.00780779\n",
      "Iteration 3689, loss = 0.00780476\n",
      "Iteration 3690, loss = 0.00780257\n",
      "Iteration 3691, loss = 0.00780088\n",
      "Iteration 3692, loss = 0.00779811\n",
      "Iteration 3693, loss = 0.00779505\n",
      "Iteration 3694, loss = 0.00779273\n",
      "Iteration 3695, loss = 0.00779026\n",
      "Iteration 3696, loss = 0.00778714\n",
      "Iteration 3697, loss = 0.00778407\n",
      "Iteration 3698, loss = 0.00778047\n",
      "Iteration 3699, loss = 0.00777827\n",
      "Iteration 3700, loss = 0.00777466\n",
      "Iteration 3701, loss = 0.00777220\n",
      "Iteration 3702, loss = 0.00776915\n",
      "Iteration 3703, loss = 0.00776578\n",
      "Iteration 3704, loss = 0.00776257\n",
      "Iteration 3705, loss = 0.00775923\n",
      "Iteration 3706, loss = 0.00775620\n",
      "Iteration 3707, loss = 0.00775293\n",
      "Iteration 3708, loss = 0.00774987\n",
      "Iteration 3709, loss = 0.00774662\n",
      "Iteration 3710, loss = 0.00774359\n",
      "Iteration 3711, loss = 0.00774192\n",
      "Iteration 3712, loss = 0.00773892\n",
      "Iteration 3713, loss = 0.00773597\n",
      "Iteration 3714, loss = 0.00773323\n",
      "Iteration 3715, loss = 0.00773035\n",
      "Iteration 3716, loss = 0.00772795\n",
      "Iteration 3717, loss = 0.00772404\n",
      "Iteration 3718, loss = 0.00772149\n",
      "Iteration 3719, loss = 0.00771836\n",
      "Iteration 3720, loss = 0.00771552\n",
      "Iteration 3721, loss = 0.00771282\n",
      "Iteration 3722, loss = 0.00770910\n",
      "Iteration 3723, loss = 0.00770623\n",
      "Iteration 3724, loss = 0.00770305\n",
      "Iteration 3725, loss = 0.00769961\n",
      "Iteration 3726, loss = 0.00769677\n",
      "Iteration 3727, loss = 0.00769325\n",
      "Iteration 3728, loss = 0.00769083\n",
      "Iteration 3729, loss = 0.00768813\n",
      "Iteration 3730, loss = 0.00768510\n",
      "Iteration 3731, loss = 0.00768189\n",
      "Iteration 3732, loss = 0.00767958\n",
      "Iteration 3733, loss = 0.00767665\n",
      "Iteration 3734, loss = 0.00767426\n",
      "Iteration 3735, loss = 0.00767091\n",
      "Iteration 3736, loss = 0.00766885\n",
      "Iteration 3737, loss = 0.00766546\n",
      "Iteration 3738, loss = 0.00766302\n",
      "Iteration 3739, loss = 0.00766018\n",
      "Iteration 3740, loss = 0.00765751\n",
      "Iteration 3741, loss = 0.00765455\n",
      "Iteration 3742, loss = 0.00765146\n",
      "Iteration 3743, loss = 0.00764940\n",
      "Iteration 3744, loss = 0.00764561\n",
      "Iteration 3745, loss = 0.00764283\n",
      "Iteration 3746, loss = 0.00764007\n",
      "Iteration 3747, loss = 0.00763735\n",
      "Iteration 3748, loss = 0.00763460\n",
      "Iteration 3749, loss = 0.00763220\n",
      "Iteration 3750, loss = 0.00762884\n",
      "Iteration 3751, loss = 0.00762587\n",
      "Iteration 3752, loss = 0.00762403\n",
      "Iteration 3753, loss = 0.00762051\n",
      "Iteration 3754, loss = 0.00761809\n",
      "Iteration 3755, loss = 0.00761532\n",
      "Iteration 3756, loss = 0.00761279\n",
      "Iteration 3757, loss = 0.00760914\n",
      "Iteration 3758, loss = 0.00760636\n",
      "Iteration 3759, loss = 0.00760349\n",
      "Iteration 3760, loss = 0.00760130\n",
      "Iteration 3761, loss = 0.00759772\n",
      "Iteration 3762, loss = 0.00759502\n",
      "Iteration 3763, loss = 0.00759225\n",
      "Iteration 3764, loss = 0.00758948\n",
      "Iteration 3765, loss = 0.00758678\n",
      "Iteration 3766, loss = 0.00758414\n",
      "Iteration 3767, loss = 0.00758074\n",
      "Iteration 3768, loss = 0.00757793\n",
      "Iteration 3769, loss = 0.00757499\n",
      "Iteration 3770, loss = 0.00757259\n",
      "Iteration 3771, loss = 0.00756960\n",
      "Iteration 3772, loss = 0.00756670\n",
      "Iteration 3773, loss = 0.00756342\n",
      "Iteration 3774, loss = 0.00756088\n",
      "Iteration 3775, loss = 0.00755821\n",
      "Iteration 3776, loss = 0.00755518\n",
      "Iteration 3777, loss = 0.00755237\n",
      "Iteration 3778, loss = 0.00754916\n",
      "Iteration 3779, loss = 0.00754739\n",
      "Iteration 3780, loss = 0.00754416\n",
      "Iteration 3781, loss = 0.00754241\n",
      "Iteration 3782, loss = 0.00754020\n",
      "Iteration 3783, loss = 0.00753684\n",
      "Iteration 3784, loss = 0.00753485\n",
      "Iteration 3785, loss = 0.00753255\n",
      "Iteration 3786, loss = 0.00752994\n",
      "Iteration 3787, loss = 0.00752685\n",
      "Iteration 3788, loss = 0.00752372\n",
      "Iteration 3789, loss = 0.00752130\n",
      "Iteration 3790, loss = 0.00751863\n",
      "Iteration 3791, loss = 0.00751565\n",
      "Iteration 3792, loss = 0.00751304\n",
      "Iteration 3793, loss = 0.00751072\n",
      "Iteration 3794, loss = 0.00750774\n",
      "Iteration 3795, loss = 0.00750546\n",
      "Iteration 3796, loss = 0.00750247\n",
      "Iteration 3797, loss = 0.00750011\n",
      "Iteration 3798, loss = 0.00749744\n",
      "Iteration 3799, loss = 0.00749510\n",
      "Iteration 3800, loss = 0.00749272\n",
      "Iteration 3801, loss = 0.00749042\n",
      "Iteration 3802, loss = 0.00748803\n",
      "Iteration 3803, loss = 0.00748564\n",
      "Iteration 3804, loss = 0.00748351\n",
      "Iteration 3805, loss = 0.00748141\n",
      "Iteration 3806, loss = 0.00747778\n",
      "Iteration 3807, loss = 0.00747535\n",
      "Iteration 3808, loss = 0.00747296\n",
      "Iteration 3809, loss = 0.00747030\n",
      "Iteration 3810, loss = 0.00746755\n",
      "Iteration 3811, loss = 0.00746507\n",
      "Iteration 3812, loss = 0.00746227\n",
      "Iteration 3813, loss = 0.00745983\n",
      "Iteration 3814, loss = 0.00745744\n",
      "Iteration 3815, loss = 0.00745434\n",
      "Iteration 3816, loss = 0.00745291\n",
      "Iteration 3817, loss = 0.00744925\n",
      "Iteration 3818, loss = 0.00744624\n",
      "Iteration 3819, loss = 0.00744337\n",
      "Iteration 3820, loss = 0.00744056\n",
      "Iteration 3821, loss = 0.00743728\n",
      "Iteration 3822, loss = 0.00743555\n",
      "Iteration 3823, loss = 0.00743217\n",
      "Iteration 3824, loss = 0.00742960\n",
      "Iteration 3825, loss = 0.00742684\n",
      "Iteration 3826, loss = 0.00742450\n",
      "Iteration 3827, loss = 0.00742187\n",
      "Iteration 3828, loss = 0.00741917\n",
      "Iteration 3829, loss = 0.00741631\n",
      "Iteration 3830, loss = 0.00741390\n",
      "Iteration 3831, loss = 0.00741091\n",
      "Iteration 3832, loss = 0.00740850\n",
      "Iteration 3833, loss = 0.00740552\n",
      "Iteration 3834, loss = 0.00740321\n",
      "Iteration 3835, loss = 0.00740034\n",
      "Iteration 3836, loss = 0.00739806\n",
      "Iteration 3837, loss = 0.00739684\n",
      "Iteration 3838, loss = 0.00739291\n",
      "Iteration 3839, loss = 0.00739007\n",
      "Iteration 3840, loss = 0.00738776\n",
      "Iteration 3841, loss = 0.00738511\n",
      "Iteration 3842, loss = 0.00738308\n",
      "Iteration 3843, loss = 0.00737957\n",
      "Iteration 3844, loss = 0.00737647\n",
      "Iteration 3845, loss = 0.00737422\n",
      "Iteration 3846, loss = 0.00737097\n",
      "Iteration 3847, loss = 0.00736925\n",
      "Iteration 3848, loss = 0.00736569\n",
      "Iteration 3849, loss = 0.00736333\n",
      "Iteration 3850, loss = 0.00736024\n",
      "Iteration 3851, loss = 0.00735803\n",
      "Iteration 3852, loss = 0.00735533\n",
      "Iteration 3853, loss = 0.00735282\n",
      "Iteration 3854, loss = 0.00735013\n",
      "Iteration 3855, loss = 0.00734737\n",
      "Iteration 3856, loss = 0.00734487\n",
      "Iteration 3857, loss = 0.00734265\n",
      "Iteration 3858, loss = 0.00734039\n",
      "Iteration 3859, loss = 0.00733799\n",
      "Iteration 3860, loss = 0.00733538\n",
      "Iteration 3861, loss = 0.00733250\n",
      "Iteration 3862, loss = 0.00733098\n",
      "Iteration 3863, loss = 0.00732817\n",
      "Iteration 3864, loss = 0.00732544\n",
      "Iteration 3865, loss = 0.00732285\n",
      "Iteration 3866, loss = 0.00732079\n",
      "Iteration 3867, loss = 0.00731854\n",
      "Iteration 3868, loss = 0.00731517\n",
      "Iteration 3869, loss = 0.00731278\n",
      "Iteration 3870, loss = 0.00730973\n",
      "Iteration 3871, loss = 0.00730758\n",
      "Iteration 3872, loss = 0.00730448\n",
      "Iteration 3873, loss = 0.00730231\n",
      "Iteration 3874, loss = 0.00729974\n",
      "Iteration 3875, loss = 0.00729683\n",
      "Iteration 3876, loss = 0.00729456\n",
      "Iteration 3877, loss = 0.00729182\n",
      "Iteration 3878, loss = 0.00728907\n",
      "Iteration 3879, loss = 0.00728647\n",
      "Iteration 3880, loss = 0.00728408\n",
      "Iteration 3881, loss = 0.00728113\n",
      "Iteration 3882, loss = 0.00727863\n",
      "Iteration 3883, loss = 0.00727594\n",
      "Iteration 3884, loss = 0.00727335\n",
      "Iteration 3885, loss = 0.00727057\n",
      "Iteration 3886, loss = 0.00726810\n",
      "Iteration 3887, loss = 0.00726571\n",
      "Iteration 3888, loss = 0.00726308\n",
      "Iteration 3889, loss = 0.00726044\n",
      "Iteration 3890, loss = 0.00725887\n",
      "Iteration 3891, loss = 0.00725570\n",
      "Iteration 3892, loss = 0.00725313\n",
      "Iteration 3893, loss = 0.00725066\n",
      "Iteration 3894, loss = 0.00724855\n",
      "Iteration 3895, loss = 0.00724562\n",
      "Iteration 3896, loss = 0.00724348\n",
      "Iteration 3897, loss = 0.00724037\n",
      "Iteration 3898, loss = 0.00723799\n",
      "Iteration 3899, loss = 0.00723551\n",
      "Iteration 3900, loss = 0.00723298\n",
      "Iteration 3901, loss = 0.00723071\n",
      "Iteration 3902, loss = 0.00722838\n",
      "Iteration 3903, loss = 0.00722545\n",
      "Iteration 3904, loss = 0.00722321\n",
      "Iteration 3905, loss = 0.00722045\n",
      "Iteration 3906, loss = 0.00721792\n",
      "Iteration 3907, loss = 0.00721548\n",
      "Iteration 3908, loss = 0.00721305\n",
      "Iteration 3909, loss = 0.00721039\n",
      "Iteration 3910, loss = 0.00720830\n",
      "Iteration 3911, loss = 0.00720612\n",
      "Iteration 3912, loss = 0.00720304\n",
      "Iteration 3913, loss = 0.00720060\n",
      "Iteration 3914, loss = 0.00719822\n",
      "Iteration 3915, loss = 0.00719563\n",
      "Iteration 3916, loss = 0.00719334\n",
      "Iteration 3917, loss = 0.00719050\n",
      "Iteration 3918, loss = 0.00718838\n",
      "Iteration 3919, loss = 0.00718589\n",
      "Iteration 3920, loss = 0.00718337\n",
      "Iteration 3921, loss = 0.00718157\n",
      "Iteration 3922, loss = 0.00717871\n",
      "Iteration 3923, loss = 0.00717646\n",
      "Iteration 3924, loss = 0.00717406\n",
      "Iteration 3925, loss = 0.00717156\n",
      "Iteration 3926, loss = 0.00716936\n",
      "Iteration 3927, loss = 0.00716681\n",
      "Iteration 3928, loss = 0.00716482\n",
      "Iteration 3929, loss = 0.00716212\n",
      "Iteration 3930, loss = 0.00715923\n",
      "Iteration 3931, loss = 0.00715690\n",
      "Iteration 3932, loss = 0.00715447\n",
      "Iteration 3933, loss = 0.00715158\n",
      "Iteration 3934, loss = 0.00714927\n",
      "Iteration 3935, loss = 0.00714668\n",
      "Iteration 3936, loss = 0.00714437\n",
      "Iteration 3937, loss = 0.00714175\n",
      "Iteration 3938, loss = 0.00713884\n",
      "Iteration 3939, loss = 0.00713711\n",
      "Iteration 3940, loss = 0.00713381\n",
      "Iteration 3941, loss = 0.00713170\n",
      "Iteration 3942, loss = 0.00712902\n",
      "Iteration 3943, loss = 0.00712640\n",
      "Iteration 3944, loss = 0.00712380\n",
      "Iteration 3945, loss = 0.00712141\n",
      "Iteration 3946, loss = 0.00711912\n",
      "Iteration 3947, loss = 0.00711725\n",
      "Iteration 3948, loss = 0.00711508\n",
      "Iteration 3949, loss = 0.00711199\n",
      "Iteration 3950, loss = 0.00710987\n",
      "Iteration 3951, loss = 0.00710733\n",
      "Iteration 3952, loss = 0.00710501\n",
      "Iteration 3953, loss = 0.00710295\n",
      "Iteration 3954, loss = 0.00710082\n",
      "Iteration 3955, loss = 0.00709832\n",
      "Iteration 3956, loss = 0.00709609\n",
      "Iteration 3957, loss = 0.00709428\n",
      "Iteration 3958, loss = 0.00709211\n",
      "Iteration 3959, loss = 0.00709002\n",
      "Iteration 3960, loss = 0.00708750\n",
      "Iteration 3961, loss = 0.00708489\n",
      "Iteration 3962, loss = 0.00708244\n",
      "Iteration 3963, loss = 0.00708019\n",
      "Iteration 3964, loss = 0.00707766\n",
      "Iteration 3965, loss = 0.00707446\n",
      "Iteration 3966, loss = 0.00707263\n",
      "Iteration 3967, loss = 0.00706944\n",
      "Iteration 3968, loss = 0.00706703\n",
      "Iteration 3969, loss = 0.00706437\n",
      "Iteration 3970, loss = 0.00706187\n",
      "Iteration 3971, loss = 0.00705966\n",
      "Iteration 3972, loss = 0.00705686\n",
      "Iteration 3973, loss = 0.00705436\n",
      "Iteration 3974, loss = 0.00705250\n",
      "Iteration 3975, loss = 0.00704936\n",
      "Iteration 3976, loss = 0.00704770\n",
      "Iteration 3977, loss = 0.00704482\n",
      "Iteration 3978, loss = 0.00704294\n",
      "Iteration 3979, loss = 0.00704013\n",
      "Iteration 3980, loss = 0.00703788\n",
      "Iteration 3981, loss = 0.00703587\n",
      "Iteration 3982, loss = 0.00703313\n",
      "Iteration 3983, loss = 0.00703081\n",
      "Iteration 3984, loss = 0.00702992\n",
      "Iteration 3985, loss = 0.00702633\n",
      "Iteration 3986, loss = 0.00702385\n",
      "Iteration 3987, loss = 0.00702153\n",
      "Iteration 3988, loss = 0.00701920\n",
      "Iteration 3989, loss = 0.00701666\n",
      "Iteration 3990, loss = 0.00701429\n",
      "Iteration 3991, loss = 0.00701203\n",
      "Iteration 3992, loss = 0.00700920\n",
      "Iteration 3993, loss = 0.00700694\n",
      "Iteration 3994, loss = 0.00700481\n",
      "Iteration 3995, loss = 0.00700251\n",
      "Iteration 3996, loss = 0.00700052\n",
      "Iteration 3997, loss = 0.00699886\n",
      "Iteration 3998, loss = 0.00699640\n",
      "Iteration 3999, loss = 0.00699413\n",
      "Iteration 4000, loss = 0.00699188\n",
      "Iteration 4001, loss = 0.00698972\n",
      "Iteration 4002, loss = 0.00698777\n",
      "Iteration 4003, loss = 0.00698535\n",
      "Iteration 4004, loss = 0.00698310\n",
      "Iteration 4005, loss = 0.00698093\n",
      "Iteration 4006, loss = 0.00697850\n",
      "Iteration 4007, loss = 0.00697615\n",
      "Iteration 4008, loss = 0.00697398\n",
      "Iteration 4009, loss = 0.00697143\n",
      "Iteration 4010, loss = 0.00696887\n",
      "Iteration 4011, loss = 0.00696630\n",
      "Iteration 4012, loss = 0.00696508\n",
      "Iteration 4013, loss = 0.00696198\n",
      "Iteration 4014, loss = 0.00696020\n",
      "Iteration 4015, loss = 0.00695743\n",
      "Iteration 4016, loss = 0.00695542\n",
      "Iteration 4017, loss = 0.00695331\n",
      "Iteration 4018, loss = 0.00695055\n",
      "Iteration 4019, loss = 0.00694805\n",
      "Iteration 4020, loss = 0.00694567\n",
      "Iteration 4021, loss = 0.00694359\n",
      "Iteration 4022, loss = 0.00694136\n",
      "Iteration 4023, loss = 0.00693896\n",
      "Iteration 4024, loss = 0.00693656\n",
      "Iteration 4025, loss = 0.00693562\n",
      "Iteration 4026, loss = 0.00693233\n",
      "Iteration 4027, loss = 0.00693077\n",
      "Iteration 4028, loss = 0.00692795\n",
      "Iteration 4029, loss = 0.00692591\n",
      "Iteration 4030, loss = 0.00692368\n",
      "Iteration 4031, loss = 0.00692175\n",
      "Iteration 4032, loss = 0.00691952\n",
      "Iteration 4033, loss = 0.00691729\n",
      "Iteration 4034, loss = 0.00691621\n",
      "Iteration 4035, loss = 0.00691337\n",
      "Iteration 4036, loss = 0.00691206\n",
      "Iteration 4037, loss = 0.00690913\n",
      "Iteration 4038, loss = 0.00690687\n",
      "Iteration 4039, loss = 0.00690410\n",
      "Iteration 4040, loss = 0.00690130\n",
      "Iteration 4041, loss = 0.00689932\n",
      "Iteration 4042, loss = 0.00689634\n",
      "Iteration 4043, loss = 0.00689410\n",
      "Iteration 4044, loss = 0.00689163\n",
      "Iteration 4045, loss = 0.00688907\n",
      "Iteration 4046, loss = 0.00688681\n",
      "Iteration 4047, loss = 0.00688433\n",
      "Iteration 4048, loss = 0.00688252\n",
      "Iteration 4049, loss = 0.00687989\n",
      "Iteration 4050, loss = 0.00687770\n",
      "Iteration 4051, loss = 0.00687542\n",
      "Iteration 4052, loss = 0.00687340\n",
      "Iteration 4053, loss = 0.00687110\n",
      "Iteration 4054, loss = 0.00686867\n",
      "Iteration 4055, loss = 0.00686714\n",
      "Iteration 4056, loss = 0.00686404\n",
      "Iteration 4057, loss = 0.00686224\n",
      "Iteration 4058, loss = 0.00685939\n",
      "Iteration 4059, loss = 0.00685749\n",
      "Iteration 4060, loss = 0.00685477\n",
      "Iteration 4061, loss = 0.00685285\n",
      "Iteration 4062, loss = 0.00685053\n",
      "Iteration 4063, loss = 0.00684796\n",
      "Iteration 4064, loss = 0.00684547\n",
      "Iteration 4065, loss = 0.00684304\n",
      "Iteration 4066, loss = 0.00684079\n",
      "Iteration 4067, loss = 0.00683873\n",
      "Iteration 4068, loss = 0.00683714\n",
      "Iteration 4069, loss = 0.00683436\n",
      "Iteration 4070, loss = 0.00683251\n",
      "Iteration 4071, loss = 0.00683015\n",
      "Iteration 4072, loss = 0.00682795\n",
      "Iteration 4073, loss = 0.00682639\n",
      "Iteration 4074, loss = 0.00682417\n",
      "Iteration 4075, loss = 0.00682186\n",
      "Iteration 4076, loss = 0.00681880\n",
      "Iteration 4077, loss = 0.00681596\n",
      "Iteration 4078, loss = 0.00681363\n",
      "Iteration 4079, loss = 0.00681129\n",
      "Iteration 4080, loss = 0.00680866\n",
      "Iteration 4081, loss = 0.00680641\n",
      "Iteration 4082, loss = 0.00680377\n",
      "Iteration 4083, loss = 0.00680093\n",
      "Iteration 4084, loss = 0.00679899\n",
      "Iteration 4085, loss = 0.00679577\n",
      "Iteration 4086, loss = 0.00679399\n",
      "Iteration 4087, loss = 0.00679119\n",
      "Iteration 4088, loss = 0.00678913\n",
      "Iteration 4089, loss = 0.00678695\n",
      "Iteration 4090, loss = 0.00678458\n",
      "Iteration 4091, loss = 0.00678233\n",
      "Iteration 4092, loss = 0.00678030\n",
      "Iteration 4093, loss = 0.00677821\n",
      "Iteration 4094, loss = 0.00677613\n",
      "Iteration 4095, loss = 0.00677416\n",
      "Iteration 4096, loss = 0.00677211\n",
      "Iteration 4097, loss = 0.00677172\n",
      "Iteration 4098, loss = 0.00676903\n",
      "Iteration 4099, loss = 0.00676649\n",
      "Iteration 4100, loss = 0.00676451\n",
      "Iteration 4101, loss = 0.00676252\n",
      "Iteration 4102, loss = 0.00676030\n",
      "Iteration 4103, loss = 0.00675831\n",
      "Iteration 4104, loss = 0.00675624\n",
      "Iteration 4105, loss = 0.00675424\n",
      "Iteration 4106, loss = 0.00675314\n",
      "Iteration 4107, loss = 0.00675011\n",
      "Iteration 4108, loss = 0.00674778\n",
      "Iteration 4109, loss = 0.00674565\n",
      "Iteration 4110, loss = 0.00674320\n",
      "Iteration 4111, loss = 0.00674059\n",
      "Iteration 4112, loss = 0.00673840\n",
      "Iteration 4113, loss = 0.00673689\n",
      "Iteration 4114, loss = 0.00673401\n",
      "Iteration 4115, loss = 0.00673178\n",
      "Iteration 4116, loss = 0.00672873\n",
      "Iteration 4117, loss = 0.00672630\n",
      "Iteration 4118, loss = 0.00672504\n",
      "Iteration 4119, loss = 0.00672176\n",
      "Iteration 4120, loss = 0.00671898\n",
      "Iteration 4121, loss = 0.00671667\n",
      "Iteration 4122, loss = 0.00671433\n",
      "Iteration 4123, loss = 0.00671268\n",
      "Iteration 4124, loss = 0.00671003\n",
      "Iteration 4125, loss = 0.00670753\n",
      "Iteration 4126, loss = 0.00670537\n",
      "Iteration 4127, loss = 0.00670286\n",
      "Iteration 4128, loss = 0.00670044\n",
      "Iteration 4129, loss = 0.00669822\n",
      "Iteration 4130, loss = 0.00669580\n",
      "Iteration 4131, loss = 0.00669371\n",
      "Iteration 4132, loss = 0.00669129\n",
      "Iteration 4133, loss = 0.00668978\n",
      "Iteration 4134, loss = 0.00668719\n",
      "Iteration 4135, loss = 0.00668551\n",
      "Iteration 4136, loss = 0.00668378\n",
      "Iteration 4137, loss = 0.00668143\n",
      "Iteration 4138, loss = 0.00667929\n",
      "Iteration 4139, loss = 0.00667731\n",
      "Iteration 4140, loss = 0.00667496\n",
      "Iteration 4141, loss = 0.00667308\n",
      "Iteration 4142, loss = 0.00667062\n",
      "Iteration 4143, loss = 0.00666831\n",
      "Iteration 4144, loss = 0.00666594\n",
      "Iteration 4145, loss = 0.00666340\n",
      "Iteration 4146, loss = 0.00666096\n",
      "Iteration 4147, loss = 0.00665833\n",
      "Iteration 4148, loss = 0.00665621\n",
      "Iteration 4149, loss = 0.00665402\n",
      "Iteration 4150, loss = 0.00665191\n",
      "Iteration 4151, loss = 0.00664960\n",
      "Iteration 4152, loss = 0.00664724\n",
      "Iteration 4153, loss = 0.00664511\n",
      "Iteration 4154, loss = 0.00664290\n",
      "Iteration 4155, loss = 0.00664079\n",
      "Iteration 4156, loss = 0.00663861\n",
      "Iteration 4157, loss = 0.00663669\n",
      "Iteration 4158, loss = 0.00663452\n",
      "Iteration 4159, loss = 0.00663272\n",
      "Iteration 4160, loss = 0.00663066\n",
      "Iteration 4161, loss = 0.00662877\n",
      "Iteration 4162, loss = 0.00662658\n",
      "Iteration 4163, loss = 0.00662473\n",
      "Iteration 4164, loss = 0.00662279\n",
      "Iteration 4165, loss = 0.00662126\n",
      "Iteration 4166, loss = 0.00661874\n",
      "Iteration 4167, loss = 0.00661703\n",
      "Iteration 4168, loss = 0.00661483\n",
      "Iteration 4169, loss = 0.00661312\n",
      "Iteration 4170, loss = 0.00661089\n",
      "Iteration 4171, loss = 0.00660896\n",
      "Iteration 4172, loss = 0.00660751\n",
      "Iteration 4173, loss = 0.00660551\n",
      "Iteration 4174, loss = 0.00660283\n",
      "Iteration 4175, loss = 0.00660059\n",
      "Iteration 4176, loss = 0.00659810\n",
      "Iteration 4177, loss = 0.00659547\n",
      "Iteration 4178, loss = 0.00659410\n",
      "Iteration 4179, loss = 0.00659139\n",
      "Iteration 4180, loss = 0.00658948\n",
      "Iteration 4181, loss = 0.00658703\n",
      "Iteration 4182, loss = 0.00658480\n",
      "Iteration 4183, loss = 0.00658297\n",
      "Iteration 4184, loss = 0.00658053\n",
      "Iteration 4185, loss = 0.00657837\n",
      "Iteration 4186, loss = 0.00657604\n",
      "Iteration 4187, loss = 0.00657386\n",
      "Iteration 4188, loss = 0.00657156\n",
      "Iteration 4189, loss = 0.00656921\n",
      "Iteration 4190, loss = 0.00656719\n",
      "Iteration 4191, loss = 0.00656549\n",
      "Iteration 4192, loss = 0.00656324\n",
      "Iteration 4193, loss = 0.00656167\n",
      "Iteration 4194, loss = 0.00655929\n",
      "Iteration 4195, loss = 0.00655778\n",
      "Iteration 4196, loss = 0.00655560\n",
      "Iteration 4197, loss = 0.00655281\n",
      "Iteration 4198, loss = 0.00655106\n",
      "Iteration 4199, loss = 0.00654834\n",
      "Iteration 4200, loss = 0.00654624\n",
      "Iteration 4201, loss = 0.00654390\n",
      "Iteration 4202, loss = 0.00654192\n",
      "Iteration 4203, loss = 0.00653966\n",
      "Iteration 4204, loss = 0.00653772\n",
      "Iteration 4205, loss = 0.00653558\n",
      "Iteration 4206, loss = 0.00653334\n",
      "Iteration 4207, loss = 0.00653140\n",
      "Iteration 4208, loss = 0.00652962\n",
      "Iteration 4209, loss = 0.00652785\n",
      "Iteration 4210, loss = 0.00652593\n",
      "Iteration 4211, loss = 0.00652464\n",
      "Iteration 4212, loss = 0.00652269\n",
      "Iteration 4213, loss = 0.00652045\n",
      "Iteration 4214, loss = 0.00651857\n",
      "Iteration 4215, loss = 0.00651632\n",
      "Iteration 4216, loss = 0.00651383\n",
      "Iteration 4217, loss = 0.00651158\n",
      "Iteration 4218, loss = 0.00650913\n",
      "Iteration 4219, loss = 0.00650796\n",
      "Iteration 4220, loss = 0.00650509\n",
      "Iteration 4221, loss = 0.00650408\n",
      "Iteration 4222, loss = 0.00650185\n",
      "Iteration 4223, loss = 0.00649962\n",
      "Iteration 4224, loss = 0.00649751\n",
      "Iteration 4225, loss = 0.00649531\n",
      "Iteration 4226, loss = 0.00649301\n",
      "Iteration 4227, loss = 0.00649258\n",
      "Iteration 4228, loss = 0.00648951\n",
      "Iteration 4229, loss = 0.00648710\n",
      "Iteration 4230, loss = 0.00648531\n",
      "Iteration 4231, loss = 0.00648372\n",
      "Iteration 4232, loss = 0.00648113\n",
      "Iteration 4233, loss = 0.00647898\n",
      "Iteration 4234, loss = 0.00647727\n",
      "Iteration 4235, loss = 0.00647518\n",
      "Iteration 4236, loss = 0.00647319\n",
      "Iteration 4237, loss = 0.00647140\n",
      "Iteration 4238, loss = 0.00646918\n",
      "Iteration 4239, loss = 0.00646722\n",
      "Iteration 4240, loss = 0.00646509\n",
      "Iteration 4241, loss = 0.00646321\n",
      "Iteration 4242, loss = 0.00646150\n",
      "Iteration 4243, loss = 0.00645915\n",
      "Iteration 4244, loss = 0.00645724\n",
      "Iteration 4245, loss = 0.00645503\n",
      "Iteration 4246, loss = 0.00645294\n",
      "Iteration 4247, loss = 0.00645153\n",
      "Iteration 4248, loss = 0.00644894\n",
      "Iteration 4249, loss = 0.00644817\n",
      "Iteration 4250, loss = 0.00644473\n",
      "Iteration 4251, loss = 0.00644258\n",
      "Iteration 4252, loss = 0.00644022\n",
      "Iteration 4253, loss = 0.00643834\n",
      "Iteration 4254, loss = 0.00643586\n",
      "Iteration 4255, loss = 0.00643349\n",
      "Iteration 4256, loss = 0.00643099\n",
      "Iteration 4257, loss = 0.00642923\n",
      "Iteration 4258, loss = 0.00642670\n",
      "Iteration 4259, loss = 0.00642462\n",
      "Iteration 4260, loss = 0.00642237\n",
      "Iteration 4261, loss = 0.00642012\n",
      "Iteration 4262, loss = 0.00641862\n",
      "Iteration 4263, loss = 0.00641591\n",
      "Iteration 4264, loss = 0.00641383\n",
      "Iteration 4265, loss = 0.00641164\n",
      "Iteration 4266, loss = 0.00640960\n",
      "Iteration 4267, loss = 0.00640770\n",
      "Iteration 4268, loss = 0.00640539\n",
      "Iteration 4269, loss = 0.00640320\n",
      "Iteration 4270, loss = 0.00640099\n",
      "Iteration 4271, loss = 0.00639891\n",
      "Iteration 4272, loss = 0.00639661\n",
      "Iteration 4273, loss = 0.00639473\n",
      "Iteration 4274, loss = 0.00639259\n",
      "Iteration 4275, loss = 0.00639042\n",
      "Iteration 4276, loss = 0.00638891\n",
      "Iteration 4277, loss = 0.00638633\n",
      "Iteration 4278, loss = 0.00638411\n",
      "Iteration 4279, loss = 0.00638204\n",
      "Iteration 4280, loss = 0.00637998\n",
      "Iteration 4281, loss = 0.00637800\n",
      "Iteration 4282, loss = 0.00637588\n",
      "Iteration 4283, loss = 0.00637389\n",
      "Iteration 4284, loss = 0.00637228\n",
      "Iteration 4285, loss = 0.00637022\n",
      "Iteration 4286, loss = 0.00636850\n",
      "Iteration 4287, loss = 0.00636648\n",
      "Iteration 4288, loss = 0.00636468\n",
      "Iteration 4289, loss = 0.00636286\n",
      "Iteration 4290, loss = 0.00636084\n",
      "Iteration 4291, loss = 0.00635878\n",
      "Iteration 4292, loss = 0.00635739\n",
      "Iteration 4293, loss = 0.00635527\n",
      "Iteration 4294, loss = 0.00635379\n",
      "Iteration 4295, loss = 0.00635194\n",
      "Iteration 4296, loss = 0.00635023\n",
      "Iteration 4297, loss = 0.00634815\n",
      "Iteration 4298, loss = 0.00634603\n",
      "Iteration 4299, loss = 0.00634455\n",
      "Iteration 4300, loss = 0.00634239\n",
      "Iteration 4301, loss = 0.00634016\n",
      "Iteration 4302, loss = 0.00633830\n",
      "Iteration 4303, loss = 0.00633635\n",
      "Iteration 4304, loss = 0.00633452\n",
      "Iteration 4305, loss = 0.00633266\n",
      "Iteration 4306, loss = 0.00633105\n",
      "Iteration 4307, loss = 0.00632909\n",
      "Iteration 4308, loss = 0.00632776\n",
      "Iteration 4309, loss = 0.00632591\n",
      "Iteration 4310, loss = 0.00632416\n",
      "Iteration 4311, loss = 0.00632220\n",
      "Iteration 4312, loss = 0.00631996\n",
      "Iteration 4313, loss = 0.00631775\n",
      "Iteration 4314, loss = 0.00631554\n",
      "Iteration 4315, loss = 0.00631370\n",
      "Iteration 4316, loss = 0.00631169\n",
      "Iteration 4317, loss = 0.00630946\n",
      "Iteration 4318, loss = 0.00630732\n",
      "Iteration 4319, loss = 0.00630529\n",
      "Iteration 4320, loss = 0.00630357\n",
      "Iteration 4321, loss = 0.00630156\n",
      "Iteration 4322, loss = 0.00629960\n",
      "Iteration 4323, loss = 0.00629778\n",
      "Iteration 4324, loss = 0.00629604\n",
      "Iteration 4325, loss = 0.00629428\n",
      "Iteration 4326, loss = 0.00629248\n",
      "Iteration 4327, loss = 0.00629071\n",
      "Iteration 4328, loss = 0.00628905\n",
      "Iteration 4329, loss = 0.00628711\n",
      "Iteration 4330, loss = 0.00628543\n",
      "Iteration 4331, loss = 0.00628337\n",
      "Iteration 4332, loss = 0.00628227\n",
      "Iteration 4333, loss = 0.00627924\n",
      "Iteration 4334, loss = 0.00627703\n",
      "Iteration 4335, loss = 0.00627560\n",
      "Iteration 4336, loss = 0.00627314\n",
      "Iteration 4337, loss = 0.00627105\n",
      "Iteration 4338, loss = 0.00626924\n",
      "Iteration 4339, loss = 0.00626718\n",
      "Iteration 4340, loss = 0.00626526\n",
      "Iteration 4341, loss = 0.00626271\n",
      "Iteration 4342, loss = 0.00626119\n",
      "Iteration 4343, loss = 0.00625843\n",
      "Iteration 4344, loss = 0.00625685\n",
      "Iteration 4345, loss = 0.00625516\n",
      "Iteration 4346, loss = 0.00625277\n",
      "Iteration 4347, loss = 0.00624998\n",
      "Iteration 4348, loss = 0.00624760\n",
      "Iteration 4349, loss = 0.00624598\n",
      "Iteration 4350, loss = 0.00624379\n",
      "Iteration 4351, loss = 0.00624140\n",
      "Iteration 4352, loss = 0.00623924\n",
      "Iteration 4353, loss = 0.00623791\n",
      "Iteration 4354, loss = 0.00623548\n",
      "Iteration 4355, loss = 0.00623378\n",
      "Iteration 4356, loss = 0.00623192\n",
      "Iteration 4357, loss = 0.00623004\n",
      "Iteration 4358, loss = 0.00622819\n",
      "Iteration 4359, loss = 0.00622629\n",
      "Iteration 4360, loss = 0.00622429\n",
      "Iteration 4361, loss = 0.00622261\n",
      "Iteration 4362, loss = 0.00622051\n",
      "Iteration 4363, loss = 0.00621874\n",
      "Iteration 4364, loss = 0.00621666\n",
      "Iteration 4365, loss = 0.00621489\n",
      "Iteration 4366, loss = 0.00621314\n",
      "Iteration 4367, loss = 0.00621098\n",
      "Iteration 4368, loss = 0.00620949\n",
      "Iteration 4369, loss = 0.00620742\n",
      "Iteration 4370, loss = 0.00620531\n",
      "Iteration 4371, loss = 0.00620338\n",
      "Iteration 4372, loss = 0.00620122\n",
      "Iteration 4373, loss = 0.00620053\n",
      "Iteration 4374, loss = 0.00619811\n",
      "Iteration 4375, loss = 0.00619605\n",
      "Iteration 4376, loss = 0.00619463\n",
      "Iteration 4377, loss = 0.00619252\n",
      "Iteration 4378, loss = 0.00619031\n",
      "Iteration 4379, loss = 0.00618858\n",
      "Iteration 4380, loss = 0.00618668\n",
      "Iteration 4381, loss = 0.00618487\n",
      "Iteration 4382, loss = 0.00618306\n",
      "Iteration 4383, loss = 0.00618120\n",
      "Iteration 4384, loss = 0.00617966\n",
      "Iteration 4385, loss = 0.00617788\n",
      "Iteration 4386, loss = 0.00617581\n",
      "Iteration 4387, loss = 0.00617402\n",
      "Iteration 4388, loss = 0.00617212\n",
      "Iteration 4389, loss = 0.00617009\n",
      "Iteration 4390, loss = 0.00616950\n",
      "Iteration 4391, loss = 0.00616635\n",
      "Iteration 4392, loss = 0.00616433\n",
      "Iteration 4393, loss = 0.00616207\n",
      "Iteration 4394, loss = 0.00616047\n",
      "Iteration 4395, loss = 0.00615820\n",
      "Iteration 4396, loss = 0.00615636\n",
      "Iteration 4397, loss = 0.00615431\n",
      "Iteration 4398, loss = 0.00615222\n",
      "Iteration 4399, loss = 0.00615057\n",
      "Iteration 4400, loss = 0.00614872\n",
      "Iteration 4401, loss = 0.00614651\n",
      "Iteration 4402, loss = 0.00614487\n",
      "Iteration 4403, loss = 0.00614257\n",
      "Iteration 4404, loss = 0.00614064\n",
      "Iteration 4405, loss = 0.00613863\n",
      "Iteration 4406, loss = 0.00613657\n",
      "Iteration 4407, loss = 0.00613486\n",
      "Iteration 4408, loss = 0.00613256\n",
      "Iteration 4409, loss = 0.00613056\n",
      "Iteration 4410, loss = 0.00612864\n",
      "Iteration 4411, loss = 0.00612658\n",
      "Iteration 4412, loss = 0.00612488\n",
      "Iteration 4413, loss = 0.00612352\n",
      "Iteration 4414, loss = 0.00612148\n",
      "Iteration 4415, loss = 0.00611973\n",
      "Iteration 4416, loss = 0.00611817\n",
      "Iteration 4417, loss = 0.00611626\n",
      "Iteration 4418, loss = 0.00611446\n",
      "Iteration 4419, loss = 0.00611268\n",
      "Iteration 4420, loss = 0.00611092\n",
      "Iteration 4421, loss = 0.00610905\n",
      "Iteration 4422, loss = 0.00610742\n",
      "Iteration 4423, loss = 0.00610588\n",
      "Iteration 4424, loss = 0.00610337\n",
      "Iteration 4425, loss = 0.00610166\n",
      "Iteration 4426, loss = 0.00610034\n",
      "Iteration 4427, loss = 0.00609803\n",
      "Iteration 4428, loss = 0.00609600\n",
      "Iteration 4429, loss = 0.00609424\n",
      "Iteration 4430, loss = 0.00609211\n",
      "Iteration 4431, loss = 0.00609013\n",
      "Iteration 4432, loss = 0.00608834\n",
      "Iteration 4433, loss = 0.00608631\n",
      "Iteration 4434, loss = 0.00608444\n",
      "Iteration 4435, loss = 0.00608282\n",
      "Iteration 4436, loss = 0.00608128\n",
      "Iteration 4437, loss = 0.00607924\n",
      "Iteration 4438, loss = 0.00607713\n",
      "Iteration 4439, loss = 0.00607545\n",
      "Iteration 4440, loss = 0.00607374\n",
      "Iteration 4441, loss = 0.00607157\n",
      "Iteration 4442, loss = 0.00606963\n",
      "Iteration 4443, loss = 0.00606821\n",
      "Iteration 4444, loss = 0.00606644\n",
      "Iteration 4445, loss = 0.00606439\n",
      "Iteration 4446, loss = 0.00606293\n",
      "Iteration 4447, loss = 0.00606080\n",
      "Iteration 4448, loss = 0.00605923\n",
      "Iteration 4449, loss = 0.00605742\n",
      "Iteration 4450, loss = 0.00605557\n",
      "Iteration 4451, loss = 0.00605390\n",
      "Iteration 4452, loss = 0.00605208\n",
      "Iteration 4453, loss = 0.00605035\n",
      "Iteration 4454, loss = 0.00604842\n",
      "Iteration 4455, loss = 0.00604659\n",
      "Iteration 4456, loss = 0.00604471\n",
      "Iteration 4457, loss = 0.00604292\n",
      "Iteration 4458, loss = 0.00604127\n",
      "Iteration 4459, loss = 0.00603951\n",
      "Iteration 4460, loss = 0.00603728\n",
      "Iteration 4461, loss = 0.00603539\n",
      "Iteration 4462, loss = 0.00603340\n",
      "Iteration 4463, loss = 0.00603147\n",
      "Iteration 4464, loss = 0.00602944\n",
      "Iteration 4465, loss = 0.00602846\n",
      "Iteration 4466, loss = 0.00602641\n",
      "Iteration 4467, loss = 0.00602458\n",
      "Iteration 4468, loss = 0.00602266\n",
      "Iteration 4469, loss = 0.00602123\n",
      "Iteration 4470, loss = 0.00601937\n",
      "Iteration 4471, loss = 0.00601756\n",
      "Iteration 4472, loss = 0.00601551\n",
      "Iteration 4473, loss = 0.00601369\n",
      "Iteration 4474, loss = 0.00601197\n",
      "Iteration 4475, loss = 0.00601032\n",
      "Iteration 4476, loss = 0.00600829\n",
      "Iteration 4477, loss = 0.00600679\n",
      "Iteration 4478, loss = 0.00600532\n",
      "Iteration 4479, loss = 0.00600336\n",
      "Iteration 4480, loss = 0.00600185\n",
      "Iteration 4481, loss = 0.00599985\n",
      "Iteration 4482, loss = 0.00599811\n",
      "Iteration 4483, loss = 0.00599646\n",
      "Iteration 4484, loss = 0.00599459\n",
      "Iteration 4485, loss = 0.00599285\n",
      "Iteration 4486, loss = 0.00599162\n",
      "Iteration 4487, loss = 0.00598930\n",
      "Iteration 4488, loss = 0.00598771\n",
      "Iteration 4489, loss = 0.00598548\n",
      "Iteration 4490, loss = 0.00598417\n",
      "Iteration 4491, loss = 0.00598165\n",
      "Iteration 4492, loss = 0.00598032\n",
      "Iteration 4493, loss = 0.00597815\n",
      "Iteration 4494, loss = 0.00597652\n",
      "Iteration 4495, loss = 0.00597470\n",
      "Iteration 4496, loss = 0.00597280\n",
      "Iteration 4497, loss = 0.00597123\n",
      "Iteration 4498, loss = 0.00596952\n",
      "Iteration 4499, loss = 0.00596757\n",
      "Iteration 4500, loss = 0.00596637\n",
      "Iteration 4501, loss = 0.00596426\n",
      "Iteration 4502, loss = 0.00596187\n",
      "Iteration 4503, loss = 0.00596033\n",
      "Iteration 4504, loss = 0.00595772\n",
      "Iteration 4505, loss = 0.00595564\n",
      "Iteration 4506, loss = 0.00595357\n",
      "Iteration 4507, loss = 0.00595190\n",
      "Iteration 4508, loss = 0.00594971\n",
      "Iteration 4509, loss = 0.00594777\n",
      "Iteration 4510, loss = 0.00594518\n",
      "Iteration 4511, loss = 0.00594344\n",
      "Iteration 4512, loss = 0.00594102\n",
      "Iteration 4513, loss = 0.00593943\n",
      "Iteration 4514, loss = 0.00593819\n",
      "Iteration 4515, loss = 0.00593658\n",
      "Iteration 4516, loss = 0.00593476\n",
      "Iteration 4517, loss = 0.00593302\n",
      "Iteration 4518, loss = 0.00593100\n",
      "Iteration 4519, loss = 0.00592938\n",
      "Iteration 4520, loss = 0.00592801\n",
      "Iteration 4521, loss = 0.00592594\n",
      "Iteration 4522, loss = 0.00592417\n",
      "Iteration 4523, loss = 0.00592218\n",
      "Iteration 4524, loss = 0.00592012\n",
      "Iteration 4525, loss = 0.00591810\n",
      "Iteration 4526, loss = 0.00591711\n",
      "Iteration 4527, loss = 0.00591453\n",
      "Iteration 4528, loss = 0.00591276\n",
      "Iteration 4529, loss = 0.00591075\n",
      "Iteration 4530, loss = 0.00590870\n",
      "Iteration 4531, loss = 0.00590683\n",
      "Iteration 4532, loss = 0.00590489\n",
      "Iteration 4533, loss = 0.00590299\n",
      "Iteration 4534, loss = 0.00590091\n",
      "Iteration 4535, loss = 0.00589854\n",
      "Iteration 4536, loss = 0.00589650\n",
      "Iteration 4537, loss = 0.00589524\n",
      "Iteration 4538, loss = 0.00589278\n",
      "Iteration 4539, loss = 0.00589069\n",
      "Iteration 4540, loss = 0.00588872\n",
      "Iteration 4541, loss = 0.00588751\n",
      "Iteration 4542, loss = 0.00588515\n",
      "Iteration 4543, loss = 0.00588325\n",
      "Iteration 4544, loss = 0.00588145\n",
      "Iteration 4545, loss = 0.00587957\n",
      "Iteration 4546, loss = 0.00587785\n",
      "Iteration 4547, loss = 0.00587608\n",
      "Iteration 4548, loss = 0.00587416\n",
      "Iteration 4549, loss = 0.00587223\n",
      "Iteration 4550, loss = 0.00587038\n",
      "Iteration 4551, loss = 0.00586890\n",
      "Iteration 4552, loss = 0.00586661\n",
      "Iteration 4553, loss = 0.00586501\n",
      "Iteration 4554, loss = 0.00586306\n",
      "Iteration 4555, loss = 0.00586123\n",
      "Iteration 4556, loss = 0.00585954\n",
      "Iteration 4557, loss = 0.00585800\n",
      "Iteration 4558, loss = 0.00585606\n",
      "Iteration 4559, loss = 0.00585445\n",
      "Iteration 4560, loss = 0.00585253\n",
      "Iteration 4561, loss = 0.00585077\n",
      "Iteration 4562, loss = 0.00584893\n",
      "Iteration 4563, loss = 0.00584718\n",
      "Iteration 4564, loss = 0.00584581\n",
      "Iteration 4565, loss = 0.00584375\n",
      "Iteration 4566, loss = 0.00584244\n",
      "Iteration 4567, loss = 0.00584068\n",
      "Iteration 4568, loss = 0.00583866\n",
      "Iteration 4569, loss = 0.00583762\n",
      "Iteration 4570, loss = 0.00583527\n",
      "Iteration 4571, loss = 0.00583344\n",
      "Iteration 4572, loss = 0.00583186\n",
      "Iteration 4573, loss = 0.00582975\n",
      "Iteration 4574, loss = 0.00582782\n",
      "Iteration 4575, loss = 0.00582604\n",
      "Iteration 4576, loss = 0.00582400\n",
      "Iteration 4577, loss = 0.00582212\n",
      "Iteration 4578, loss = 0.00582107\n",
      "Iteration 4579, loss = 0.00581939\n",
      "Iteration 4580, loss = 0.00581700\n",
      "Iteration 4581, loss = 0.00581569\n",
      "Iteration 4582, loss = 0.00581328\n",
      "Iteration 4583, loss = 0.00581135\n",
      "Iteration 4584, loss = 0.00580966\n",
      "Iteration 4585, loss = 0.00580774\n",
      "Iteration 4586, loss = 0.00580557\n",
      "Iteration 4587, loss = 0.00580376\n",
      "Iteration 4588, loss = 0.00580222\n",
      "Iteration 4589, loss = 0.00580095\n",
      "Iteration 4590, loss = 0.00579822\n",
      "Iteration 4591, loss = 0.00579619\n",
      "Iteration 4592, loss = 0.00579431\n",
      "Iteration 4593, loss = 0.00579331\n",
      "Iteration 4594, loss = 0.00579094\n",
      "Iteration 4595, loss = 0.00578938\n",
      "Iteration 4596, loss = 0.00578797\n",
      "Iteration 4597, loss = 0.00578551\n",
      "Iteration 4598, loss = 0.00578435\n",
      "Iteration 4599, loss = 0.00578214\n",
      "Iteration 4600, loss = 0.00578067\n",
      "Iteration 4601, loss = 0.00577870\n",
      "Iteration 4602, loss = 0.00577700\n",
      "Iteration 4603, loss = 0.00577518\n",
      "Iteration 4604, loss = 0.00577345\n",
      "Iteration 4605, loss = 0.00577184\n",
      "Iteration 4606, loss = 0.00577020\n",
      "Iteration 4607, loss = 0.00576860\n",
      "Iteration 4608, loss = 0.00576644\n",
      "Iteration 4609, loss = 0.00576482\n",
      "Iteration 4610, loss = 0.00576319\n",
      "Iteration 4611, loss = 0.00576167\n",
      "Iteration 4612, loss = 0.00576035\n",
      "Iteration 4613, loss = 0.00575831\n",
      "Iteration 4614, loss = 0.00575690\n",
      "Iteration 4615, loss = 0.00575517\n",
      "Iteration 4616, loss = 0.00575380\n",
      "Iteration 4617, loss = 0.00575179\n",
      "Iteration 4618, loss = 0.00574992\n",
      "Iteration 4619, loss = 0.00574853\n",
      "Iteration 4620, loss = 0.00574685\n",
      "Iteration 4621, loss = 0.00574514\n",
      "Iteration 4622, loss = 0.00574332\n",
      "Iteration 4623, loss = 0.00574178\n",
      "Iteration 4624, loss = 0.00574008\n",
      "Iteration 4625, loss = 0.00573840\n",
      "Iteration 4626, loss = 0.00573721\n",
      "Iteration 4627, loss = 0.00573514\n",
      "Iteration 4628, loss = 0.00573366\n",
      "Iteration 4629, loss = 0.00573165\n",
      "Iteration 4630, loss = 0.00572983\n",
      "Iteration 4631, loss = 0.00572797\n",
      "Iteration 4632, loss = 0.00572636\n",
      "Iteration 4633, loss = 0.00572440\n",
      "Iteration 4634, loss = 0.00572320\n",
      "Iteration 4635, loss = 0.00572109\n",
      "Iteration 4636, loss = 0.00571959\n",
      "Iteration 4637, loss = 0.00571832\n",
      "Iteration 4638, loss = 0.00571587\n",
      "Iteration 4639, loss = 0.00571421\n",
      "Iteration 4640, loss = 0.00571249\n",
      "Iteration 4641, loss = 0.00571070\n",
      "Iteration 4642, loss = 0.00570911\n",
      "Iteration 4643, loss = 0.00570745\n",
      "Iteration 4644, loss = 0.00570574\n",
      "Iteration 4645, loss = 0.00570419\n",
      "Iteration 4646, loss = 0.00570247\n",
      "Iteration 4647, loss = 0.00570074\n",
      "Iteration 4648, loss = 0.00569933\n",
      "Iteration 4649, loss = 0.00569772\n",
      "Iteration 4650, loss = 0.00569604\n",
      "Iteration 4651, loss = 0.00569451\n",
      "Iteration 4652, loss = 0.00569297\n",
      "Iteration 4653, loss = 0.00569203\n",
      "Iteration 4654, loss = 0.00569009\n",
      "Iteration 4655, loss = 0.00568840\n",
      "Iteration 4656, loss = 0.00568691\n",
      "Iteration 4657, loss = 0.00568523\n",
      "Iteration 4658, loss = 0.00568369\n",
      "Iteration 4659, loss = 0.00568211\n",
      "Iteration 4660, loss = 0.00568024\n",
      "Iteration 4661, loss = 0.00567852\n",
      "Iteration 4662, loss = 0.00567699\n",
      "Iteration 4663, loss = 0.00567534\n",
      "Iteration 4664, loss = 0.00567368\n",
      "Iteration 4665, loss = 0.00567261\n",
      "Iteration 4666, loss = 0.00567108\n",
      "Iteration 4667, loss = 0.00566927\n",
      "Iteration 4668, loss = 0.00566809\n",
      "Iteration 4669, loss = 0.00566650\n",
      "Iteration 4670, loss = 0.00566523\n",
      "Iteration 4671, loss = 0.00566314\n",
      "Iteration 4672, loss = 0.00566131\n",
      "Iteration 4673, loss = 0.00565944\n",
      "Iteration 4674, loss = 0.00565782\n",
      "Iteration 4675, loss = 0.00565596\n",
      "Iteration 4676, loss = 0.00565449\n",
      "Iteration 4677, loss = 0.00565274\n",
      "Iteration 4678, loss = 0.00565097\n",
      "Iteration 4679, loss = 0.00564927\n",
      "Iteration 4680, loss = 0.00564749\n",
      "Iteration 4681, loss = 0.00564607\n",
      "Iteration 4682, loss = 0.00564421\n",
      "Iteration 4683, loss = 0.00564271\n",
      "Iteration 4684, loss = 0.00564137\n",
      "Iteration 4685, loss = 0.00563930\n",
      "Iteration 4686, loss = 0.00563765\n",
      "Iteration 4687, loss = 0.00563624\n",
      "Iteration 4688, loss = 0.00563434\n",
      "Iteration 4689, loss = 0.00563276\n",
      "Iteration 4690, loss = 0.00563109\n",
      "Iteration 4691, loss = 0.00562981\n",
      "Iteration 4692, loss = 0.00562812\n",
      "Iteration 4693, loss = 0.00562682\n",
      "Iteration 4694, loss = 0.00562484\n",
      "Iteration 4695, loss = 0.00562338\n",
      "Iteration 4696, loss = 0.00562149\n",
      "Iteration 4697, loss = 0.00561986\n",
      "Iteration 4698, loss = 0.00561847\n",
      "Iteration 4699, loss = 0.00561639\n",
      "Iteration 4700, loss = 0.00561465\n",
      "Iteration 4701, loss = 0.00561304\n",
      "Iteration 4702, loss = 0.00561132\n",
      "Iteration 4703, loss = 0.00560934\n",
      "Iteration 4704, loss = 0.00560739\n",
      "Iteration 4705, loss = 0.00560585\n",
      "Iteration 4706, loss = 0.00560454\n",
      "Iteration 4707, loss = 0.00560246\n",
      "Iteration 4708, loss = 0.00560061\n",
      "Iteration 4709, loss = 0.00559940\n",
      "Iteration 4710, loss = 0.00559757\n",
      "Iteration 4711, loss = 0.00559630\n",
      "Iteration 4712, loss = 0.00559423\n",
      "Iteration 4713, loss = 0.00559262\n",
      "Iteration 4714, loss = 0.00559098\n",
      "Iteration 4715, loss = 0.00559024\n",
      "Iteration 4716, loss = 0.00558807\n",
      "Iteration 4717, loss = 0.00558656\n",
      "Iteration 4718, loss = 0.00558492\n",
      "Iteration 4719, loss = 0.00558350\n",
      "Iteration 4720, loss = 0.00558184\n",
      "Iteration 4721, loss = 0.00558059\n",
      "Iteration 4722, loss = 0.00557892\n",
      "Iteration 4723, loss = 0.00557753\n",
      "Iteration 4724, loss = 0.00557604\n",
      "Iteration 4725, loss = 0.00557477\n",
      "Iteration 4726, loss = 0.00557299\n",
      "Iteration 4727, loss = 0.00557151\n",
      "Iteration 4728, loss = 0.00556962\n",
      "Iteration 4729, loss = 0.00556821\n",
      "Iteration 4730, loss = 0.00556663\n",
      "Iteration 4731, loss = 0.00556520\n",
      "Iteration 4732, loss = 0.00556381\n",
      "Iteration 4733, loss = 0.00556205\n",
      "Iteration 4734, loss = 0.00556049\n",
      "Iteration 4735, loss = 0.00555897\n",
      "Iteration 4736, loss = 0.00555730\n",
      "Iteration 4737, loss = 0.00555571\n",
      "Iteration 4738, loss = 0.00555441\n",
      "Iteration 4739, loss = 0.00555285\n",
      "Iteration 4740, loss = 0.00555116\n",
      "Iteration 4741, loss = 0.00554926\n",
      "Iteration 4742, loss = 0.00554758\n",
      "Iteration 4743, loss = 0.00554637\n",
      "Iteration 4744, loss = 0.00554420\n",
      "Iteration 4745, loss = 0.00554242\n",
      "Iteration 4746, loss = 0.00554066\n",
      "Iteration 4747, loss = 0.00553929\n",
      "Iteration 4748, loss = 0.00553831\n",
      "Iteration 4749, loss = 0.00553624\n",
      "Iteration 4750, loss = 0.00553463\n",
      "Iteration 4751, loss = 0.00553292\n",
      "Iteration 4752, loss = 0.00553166\n",
      "Iteration 4753, loss = 0.00553000\n",
      "Iteration 4754, loss = 0.00552839\n",
      "Iteration 4755, loss = 0.00552690\n",
      "Iteration 4756, loss = 0.00552551\n",
      "Iteration 4757, loss = 0.00552367\n",
      "Iteration 4758, loss = 0.00552217\n",
      "Iteration 4759, loss = 0.00552049\n",
      "Iteration 4760, loss = 0.00551872\n",
      "Iteration 4761, loss = 0.00551708\n",
      "Iteration 4762, loss = 0.00551535\n",
      "Iteration 4763, loss = 0.00551387\n",
      "Iteration 4764, loss = 0.00551210\n",
      "Iteration 4765, loss = 0.00551018\n",
      "Iteration 4766, loss = 0.00550930\n",
      "Iteration 4767, loss = 0.00550763\n",
      "Iteration 4768, loss = 0.00550596\n",
      "Iteration 4769, loss = 0.00550414\n",
      "Iteration 4770, loss = 0.00550242\n",
      "Iteration 4771, loss = 0.00550079\n",
      "Iteration 4772, loss = 0.00549912\n",
      "Iteration 4773, loss = 0.00549796\n",
      "Iteration 4774, loss = 0.00549596\n",
      "Iteration 4775, loss = 0.00549447\n",
      "Iteration 4776, loss = 0.00549273\n",
      "Iteration 4777, loss = 0.00549077\n",
      "Iteration 4778, loss = 0.00548910\n",
      "Iteration 4779, loss = 0.00548806\n",
      "Iteration 4780, loss = 0.00548591\n",
      "Iteration 4781, loss = 0.00548456\n",
      "Iteration 4782, loss = 0.00548283\n",
      "Iteration 4783, loss = 0.00548097\n",
      "Iteration 4784, loss = 0.00547936\n",
      "Iteration 4785, loss = 0.00547767\n",
      "Iteration 4786, loss = 0.00547628\n",
      "Iteration 4787, loss = 0.00547486\n",
      "Iteration 4788, loss = 0.00547230\n",
      "Iteration 4789, loss = 0.00547076\n",
      "Iteration 4790, loss = 0.00547118\n",
      "Iteration 4791, loss = 0.00546795\n",
      "Iteration 4792, loss = 0.00546626\n",
      "Iteration 4793, loss = 0.00546445\n",
      "Iteration 4794, loss = 0.00546298\n",
      "Iteration 4795, loss = 0.00546100\n",
      "Iteration 4796, loss = 0.00545925\n",
      "Iteration 4797, loss = 0.00545763\n",
      "Iteration 4798, loss = 0.00545597\n",
      "Iteration 4799, loss = 0.00545450\n",
      "Iteration 4800, loss = 0.00545246\n",
      "Iteration 4801, loss = 0.00545118\n",
      "Iteration 4802, loss = 0.00544923\n",
      "Iteration 4803, loss = 0.00544753\n",
      "Iteration 4804, loss = 0.00544590\n",
      "Iteration 4805, loss = 0.00544453\n",
      "Iteration 4806, loss = 0.00544270\n",
      "Iteration 4807, loss = 0.00544169\n",
      "Iteration 4808, loss = 0.00543980\n",
      "Iteration 4809, loss = 0.00543832\n",
      "Iteration 4810, loss = 0.00543699\n",
      "Iteration 4811, loss = 0.00543605\n",
      "Iteration 4812, loss = 0.00543458\n",
      "Iteration 4813, loss = 0.00543274\n",
      "Iteration 4814, loss = 0.00543129\n",
      "Iteration 4815, loss = 0.00542897\n",
      "Iteration 4816, loss = 0.00542741\n",
      "Iteration 4817, loss = 0.00542621\n",
      "Iteration 4818, loss = 0.00542473\n",
      "Iteration 4819, loss = 0.00542330\n",
      "Iteration 4820, loss = 0.00542182\n",
      "Iteration 4821, loss = 0.00542042\n",
      "Iteration 4822, loss = 0.00541902\n",
      "Iteration 4823, loss = 0.00541762\n",
      "Iteration 4824, loss = 0.00541605\n",
      "Iteration 4825, loss = 0.00541494\n",
      "Iteration 4826, loss = 0.00541346\n",
      "Iteration 4827, loss = 0.00541207\n",
      "Iteration 4828, loss = 0.00541101\n",
      "Iteration 4829, loss = 0.00540931\n",
      "Iteration 4830, loss = 0.00540811\n",
      "Iteration 4831, loss = 0.00540655\n",
      "Iteration 4832, loss = 0.00540507\n",
      "Iteration 4833, loss = 0.00540339\n",
      "Iteration 4834, loss = 0.00540186\n",
      "Iteration 4835, loss = 0.00540027\n",
      "Iteration 4836, loss = 0.00539952\n",
      "Iteration 4837, loss = 0.00539731\n",
      "Iteration 4838, loss = 0.00539608\n",
      "Iteration 4839, loss = 0.00539422\n",
      "Iteration 4840, loss = 0.00539272\n",
      "Iteration 4841, loss = 0.00539182\n",
      "Iteration 4842, loss = 0.00539048\n",
      "Iteration 4843, loss = 0.00538919\n",
      "Iteration 4844, loss = 0.00538718\n",
      "Iteration 4845, loss = 0.00538574\n",
      "Iteration 4846, loss = 0.00538406\n",
      "Iteration 4847, loss = 0.00538232\n",
      "Iteration 4848, loss = 0.00538071\n",
      "Iteration 4849, loss = 0.00537927\n",
      "Iteration 4850, loss = 0.00537796\n",
      "Iteration 4851, loss = 0.00537606\n",
      "Iteration 4852, loss = 0.00537431\n",
      "Iteration 4853, loss = 0.00537281\n",
      "Iteration 4854, loss = 0.00537140\n",
      "Iteration 4855, loss = 0.00536988\n",
      "Iteration 4856, loss = 0.00536828\n",
      "Iteration 4857, loss = 0.00536692\n",
      "Iteration 4858, loss = 0.00536502\n",
      "Iteration 4859, loss = 0.00536394\n",
      "Iteration 4860, loss = 0.00536216\n",
      "Iteration 4861, loss = 0.00536027\n",
      "Iteration 4862, loss = 0.00535882\n",
      "Iteration 4863, loss = 0.00535721\n",
      "Iteration 4864, loss = 0.00535580\n",
      "Iteration 4865, loss = 0.00535394\n",
      "Iteration 4866, loss = 0.00535229\n",
      "Iteration 4867, loss = 0.00535065\n",
      "Iteration 4868, loss = 0.00534904\n",
      "Iteration 4869, loss = 0.00534735\n",
      "Iteration 4870, loss = 0.00534562\n",
      "Iteration 4871, loss = 0.00534399\n",
      "Iteration 4872, loss = 0.00534272\n",
      "Iteration 4873, loss = 0.00534077\n",
      "Iteration 4874, loss = 0.00533933\n",
      "Iteration 4875, loss = 0.00533770\n",
      "Iteration 4876, loss = 0.00533588\n",
      "Iteration 4877, loss = 0.00533439\n",
      "Iteration 4878, loss = 0.00533367\n",
      "Iteration 4879, loss = 0.00533139\n",
      "Iteration 4880, loss = 0.00532998\n",
      "Iteration 4881, loss = 0.00532836\n",
      "Iteration 4882, loss = 0.00532715\n",
      "Iteration 4883, loss = 0.00532573\n",
      "Iteration 4884, loss = 0.00532413\n",
      "Iteration 4885, loss = 0.00532259\n",
      "Iteration 4886, loss = 0.00532122\n",
      "Iteration 4887, loss = 0.00531980\n",
      "Iteration 4888, loss = 0.00531841\n",
      "Iteration 4889, loss = 0.00531707\n",
      "Iteration 4890, loss = 0.00531582\n",
      "Iteration 4891, loss = 0.00531423\n",
      "Iteration 4892, loss = 0.00531268\n",
      "Iteration 4893, loss = 0.00531136\n",
      "Iteration 4894, loss = 0.00531040\n",
      "Iteration 4895, loss = 0.00530901\n",
      "Iteration 4896, loss = 0.00530734\n",
      "Iteration 4897, loss = 0.00530587\n",
      "Iteration 4898, loss = 0.00530406\n",
      "Iteration 4899, loss = 0.00530269\n",
      "Iteration 4900, loss = 0.00530100\n",
      "Iteration 4901, loss = 0.00529972\n",
      "Iteration 4902, loss = 0.00529809\n",
      "Iteration 4903, loss = 0.00529657\n",
      "Iteration 4904, loss = 0.00529513\n",
      "Iteration 4905, loss = 0.00529390\n",
      "Iteration 4906, loss = 0.00529223\n",
      "Iteration 4907, loss = 0.00529065\n",
      "Iteration 4908, loss = 0.00528917\n",
      "Iteration 4909, loss = 0.00528784\n",
      "Iteration 4910, loss = 0.00528628\n",
      "Iteration 4911, loss = 0.00528497\n",
      "Iteration 4912, loss = 0.00528354\n",
      "Iteration 4913, loss = 0.00528206\n",
      "Iteration 4914, loss = 0.00528076\n",
      "Iteration 4915, loss = 0.00527971\n",
      "Iteration 4916, loss = 0.00527783\n",
      "Iteration 4917, loss = 0.00527639\n",
      "Iteration 4918, loss = 0.00527526\n",
      "Iteration 4919, loss = 0.00527350\n",
      "Iteration 4920, loss = 0.00527243\n",
      "Iteration 4921, loss = 0.00527064\n",
      "Iteration 4922, loss = 0.00526946\n",
      "Iteration 4923, loss = 0.00526793\n",
      "Iteration 4924, loss = 0.00526645\n",
      "Iteration 4925, loss = 0.00526498\n",
      "Iteration 4926, loss = 0.00526387\n",
      "Iteration 4927, loss = 0.00526218\n",
      "Iteration 4928, loss = 0.00526037\n",
      "Iteration 4929, loss = 0.00525948\n",
      "Iteration 4930, loss = 0.00525778\n",
      "Iteration 4931, loss = 0.00525575\n",
      "Iteration 4932, loss = 0.00525444\n",
      "Iteration 4933, loss = 0.00525273\n",
      "Iteration 4934, loss = 0.00525110\n",
      "Iteration 4935, loss = 0.00525027\n",
      "Iteration 4936, loss = 0.00524849\n",
      "Iteration 4937, loss = 0.00524694\n",
      "Iteration 4938, loss = 0.00524535\n",
      "Iteration 4939, loss = 0.00524431\n",
      "Iteration 4940, loss = 0.00524366\n",
      "Iteration 4941, loss = 0.00524149\n",
      "Iteration 4942, loss = 0.00524010\n",
      "Iteration 4943, loss = 0.00523857\n",
      "Iteration 4944, loss = 0.00523736\n",
      "Iteration 4945, loss = 0.00523562\n",
      "Iteration 4946, loss = 0.00523414\n",
      "Iteration 4947, loss = 0.00523266\n",
      "Iteration 4948, loss = 0.00523139\n",
      "Iteration 4949, loss = 0.00522977\n",
      "Iteration 4950, loss = 0.00522818\n",
      "Iteration 4951, loss = 0.00522671\n",
      "Iteration 4952, loss = 0.00522544\n",
      "Iteration 4953, loss = 0.00522383\n",
      "Iteration 4954, loss = 0.00522238\n",
      "Iteration 4955, loss = 0.00522090\n",
      "Iteration 4956, loss = 0.00521947\n",
      "Iteration 4957, loss = 0.00521804\n",
      "Iteration 4958, loss = 0.00521673\n",
      "Iteration 4959, loss = 0.00521551\n",
      "Iteration 4960, loss = 0.00521412\n",
      "Iteration 4961, loss = 0.00521281\n",
      "Iteration 4962, loss = 0.00521144\n",
      "Iteration 4963, loss = 0.00521018\n",
      "Iteration 4964, loss = 0.00520906\n",
      "Iteration 4965, loss = 0.00520747\n",
      "Iteration 4966, loss = 0.00520601\n",
      "Iteration 4967, loss = 0.00520479\n",
      "Iteration 4968, loss = 0.00520354\n",
      "Iteration 4969, loss = 0.00520253\n",
      "Iteration 4970, loss = 0.00520053\n",
      "Iteration 4971, loss = 0.00519915\n",
      "Iteration 4972, loss = 0.00519810\n",
      "Iteration 4973, loss = 0.00519635\n",
      "Iteration 4974, loss = 0.00519458\n",
      "Iteration 4975, loss = 0.00519318\n",
      "Iteration 4976, loss = 0.00519171\n",
      "Iteration 4977, loss = 0.00519025\n",
      "Iteration 4978, loss = 0.00518875\n",
      "Iteration 4979, loss = 0.00518745\n",
      "Iteration 4980, loss = 0.00518623\n",
      "Iteration 4981, loss = 0.00518479\n",
      "Iteration 4982, loss = 0.00518362\n",
      "Iteration 4983, loss = 0.00518185\n",
      "Iteration 4984, loss = 0.00518093\n",
      "Iteration 4985, loss = 0.00517918\n",
      "Iteration 4986, loss = 0.00517782\n",
      "Iteration 4987, loss = 0.00517618\n",
      "Iteration 4988, loss = 0.00517454\n",
      "Iteration 4989, loss = 0.00517354\n",
      "Iteration 4990, loss = 0.00517167\n",
      "Iteration 4991, loss = 0.00517023\n",
      "Iteration 4992, loss = 0.00516926\n",
      "Iteration 4993, loss = 0.00516745\n",
      "Iteration 4994, loss = 0.00516594\n",
      "Iteration 4995, loss = 0.00516421\n",
      "Iteration 4996, loss = 0.00516270\n",
      "Iteration 4997, loss = 0.00516166\n",
      "Iteration 4998, loss = 0.00516028\n",
      "Iteration 4999, loss = 0.00515793\n",
      "Iteration 5000, loss = 0.00515650\n",
      "Iteration 5001, loss = 0.00515487\n",
      "Iteration 5002, loss = 0.00515320\n",
      "Iteration 5003, loss = 0.00515167\n",
      "Iteration 5004, loss = 0.00515031\n",
      "Iteration 5005, loss = 0.00514892\n",
      "Iteration 5006, loss = 0.00514731\n",
      "Iteration 5007, loss = 0.00514587\n",
      "Iteration 5008, loss = 0.00514458\n",
      "Iteration 5009, loss = 0.00514318\n",
      "Iteration 5010, loss = 0.00514248\n",
      "Iteration 5011, loss = 0.00514025\n",
      "Iteration 5012, loss = 0.00513903\n",
      "Iteration 5013, loss = 0.00513738\n",
      "Iteration 5014, loss = 0.00513595\n",
      "Iteration 5015, loss = 0.00513436\n",
      "Iteration 5016, loss = 0.00513303\n",
      "Iteration 5017, loss = 0.00513177\n",
      "Iteration 5018, loss = 0.00513025\n",
      "Iteration 5019, loss = 0.00512938\n",
      "Iteration 5020, loss = 0.00512748\n",
      "Iteration 5021, loss = 0.00512625\n",
      "Iteration 5022, loss = 0.00512451\n",
      "Iteration 5023, loss = 0.00512367\n",
      "Iteration 5024, loss = 0.00512188\n",
      "Iteration 5025, loss = 0.00512043\n",
      "Iteration 5026, loss = 0.00511902\n",
      "Iteration 5027, loss = 0.00511798\n",
      "Iteration 5028, loss = 0.00511607\n",
      "Iteration 5029, loss = 0.00511485\n",
      "Iteration 5030, loss = 0.00511318\n",
      "Iteration 5031, loss = 0.00511160\n",
      "Iteration 5032, loss = 0.00511023\n",
      "Iteration 5033, loss = 0.00510882\n",
      "Iteration 5034, loss = 0.00510719\n",
      "Iteration 5035, loss = 0.00510581\n",
      "Iteration 5036, loss = 0.00510431\n",
      "Iteration 5037, loss = 0.00510351\n",
      "Iteration 5038, loss = 0.00510174\n",
      "Iteration 5039, loss = 0.00510064\n",
      "Iteration 5040, loss = 0.00509887\n",
      "Iteration 5041, loss = 0.00509761\n",
      "Iteration 5042, loss = 0.00509608\n",
      "Iteration 5043, loss = 0.00509456\n",
      "Iteration 5044, loss = 0.00509342\n",
      "Iteration 5045, loss = 0.00509250\n",
      "Iteration 5046, loss = 0.00509060\n",
      "Iteration 5047, loss = 0.00508924\n",
      "Iteration 5048, loss = 0.00508774\n",
      "Iteration 5049, loss = 0.00508640\n",
      "Iteration 5050, loss = 0.00508526\n",
      "Iteration 5051, loss = 0.00508401\n",
      "Iteration 5052, loss = 0.00508235\n",
      "Iteration 5053, loss = 0.00508219\n",
      "Iteration 5054, loss = 0.00507986\n",
      "Iteration 5055, loss = 0.00507837\n",
      "Iteration 5056, loss = 0.00507770\n",
      "Iteration 5057, loss = 0.00507599\n",
      "Iteration 5058, loss = 0.00507457\n",
      "Iteration 5059, loss = 0.00507307\n",
      "Iteration 5060, loss = 0.00507169\n",
      "Iteration 5061, loss = 0.00507036\n",
      "Iteration 5062, loss = 0.00506908\n",
      "Iteration 5063, loss = 0.00506772\n",
      "Iteration 5064, loss = 0.00506700\n",
      "Iteration 5065, loss = 0.00506520\n",
      "Iteration 5066, loss = 0.00506370\n",
      "Iteration 5067, loss = 0.00506218\n",
      "Iteration 5068, loss = 0.00506059\n",
      "Iteration 5069, loss = 0.00505930\n",
      "Iteration 5070, loss = 0.00505839\n",
      "Iteration 5071, loss = 0.00505665\n",
      "Iteration 5072, loss = 0.00505545\n",
      "Iteration 5073, loss = 0.00505433\n",
      "Iteration 5074, loss = 0.00505264\n",
      "Iteration 5075, loss = 0.00505149\n",
      "Iteration 5076, loss = 0.00505000\n",
      "Iteration 5077, loss = 0.00504886\n",
      "Iteration 5078, loss = 0.00504750\n",
      "Iteration 5079, loss = 0.00504613\n",
      "Iteration 5080, loss = 0.00504478\n",
      "Iteration 5081, loss = 0.00504353\n",
      "Iteration 5082, loss = 0.00504242\n",
      "Iteration 5083, loss = 0.00504094\n",
      "Iteration 5084, loss = 0.00503952\n",
      "Iteration 5085, loss = 0.00503800\n",
      "Iteration 5086, loss = 0.00503686\n",
      "Iteration 5087, loss = 0.00503501\n",
      "Iteration 5088, loss = 0.00503356\n",
      "Iteration 5089, loss = 0.00503260\n",
      "Iteration 5090, loss = 0.00503100\n",
      "Iteration 5091, loss = 0.00502983\n",
      "Iteration 5092, loss = 0.00502840\n",
      "Iteration 5093, loss = 0.00502719\n",
      "Iteration 5094, loss = 0.00502585\n",
      "Iteration 5095, loss = 0.00502472\n",
      "Iteration 5096, loss = 0.00502349\n",
      "Iteration 5097, loss = 0.00502227\n",
      "Iteration 5098, loss = 0.00502080\n",
      "Iteration 5099, loss = 0.00501938\n",
      "Iteration 5100, loss = 0.00501884\n",
      "Iteration 5101, loss = 0.00501686\n",
      "Iteration 5102, loss = 0.00501561\n",
      "Iteration 5103, loss = 0.00501410\n",
      "Iteration 5104, loss = 0.00501264\n",
      "Iteration 5105, loss = 0.00501123\n",
      "Iteration 5106, loss = 0.00500987\n",
      "Iteration 5107, loss = 0.00500858\n",
      "Iteration 5108, loss = 0.00500728\n",
      "Iteration 5109, loss = 0.00500717\n",
      "Iteration 5110, loss = 0.00500512\n",
      "Iteration 5111, loss = 0.00500331\n",
      "Iteration 5112, loss = 0.00500208\n",
      "Iteration 5113, loss = 0.00500068\n",
      "Iteration 5114, loss = 0.00499927\n",
      "Iteration 5115, loss = 0.00499781\n",
      "Iteration 5116, loss = 0.00499650\n",
      "Iteration 5117, loss = 0.00499542\n",
      "Iteration 5118, loss = 0.00499437\n",
      "Iteration 5119, loss = 0.00499268\n",
      "Iteration 5120, loss = 0.00499136\n",
      "Iteration 5121, loss = 0.00499005\n",
      "Iteration 5122, loss = 0.00498893\n",
      "Iteration 5123, loss = 0.00498738\n",
      "Iteration 5124, loss = 0.00498602\n",
      "Iteration 5125, loss = 0.00498474\n",
      "Iteration 5126, loss = 0.00498337\n",
      "Iteration 5127, loss = 0.00498204\n",
      "Iteration 5128, loss = 0.00498059\n",
      "Iteration 5129, loss = 0.00497922\n",
      "Iteration 5130, loss = 0.00497782\n",
      "Iteration 5131, loss = 0.00497648\n",
      "Iteration 5132, loss = 0.00497529\n",
      "Iteration 5133, loss = 0.00497490\n",
      "Iteration 5134, loss = 0.00497265\n",
      "Iteration 5135, loss = 0.00497137\n",
      "Iteration 5136, loss = 0.00496985\n",
      "Iteration 5137, loss = 0.00496857\n",
      "Iteration 5138, loss = 0.00496735\n",
      "Iteration 5139, loss = 0.00496590\n",
      "Iteration 5140, loss = 0.00496438\n",
      "Iteration 5141, loss = 0.00496307\n",
      "Iteration 5142, loss = 0.00496162\n",
      "Iteration 5143, loss = 0.00496072\n",
      "Iteration 5144, loss = 0.00495881\n",
      "Iteration 5145, loss = 0.00495756\n",
      "Iteration 5146, loss = 0.00495642\n",
      "Iteration 5147, loss = 0.00495509\n",
      "Iteration 5148, loss = 0.00495359\n",
      "Iteration 5149, loss = 0.00495254\n",
      "Iteration 5150, loss = 0.00495110\n",
      "Iteration 5151, loss = 0.00494973\n",
      "Iteration 5152, loss = 0.00494831\n",
      "Iteration 5153, loss = 0.00494701\n",
      "Iteration 5154, loss = 0.00494556\n",
      "Iteration 5155, loss = 0.00494433\n",
      "Iteration 5156, loss = 0.00494284\n",
      "Iteration 5157, loss = 0.00494145\n",
      "Iteration 5158, loss = 0.00494041\n",
      "Iteration 5159, loss = 0.00493901\n",
      "Iteration 5160, loss = 0.00493763\n",
      "Iteration 5161, loss = 0.00493630\n",
      "Iteration 5162, loss = 0.00493536\n",
      "Iteration 5163, loss = 0.00493368\n",
      "Iteration 5164, loss = 0.00493228\n",
      "Iteration 5165, loss = 0.00493105\n",
      "Iteration 5166, loss = 0.00492979\n",
      "Iteration 5167, loss = 0.00492852\n",
      "Iteration 5168, loss = 0.00492718\n",
      "Iteration 5169, loss = 0.00492609\n",
      "Iteration 5170, loss = 0.00492478\n",
      "Iteration 5171, loss = 0.00492333\n",
      "Iteration 5172, loss = 0.00492254\n",
      "Iteration 5173, loss = 0.00492129\n",
      "Iteration 5174, loss = 0.00491977\n",
      "Iteration 5175, loss = 0.00491856\n",
      "Iteration 5176, loss = 0.00491777\n",
      "Iteration 5177, loss = 0.00491632\n",
      "Iteration 5178, loss = 0.00491500\n",
      "Iteration 5179, loss = 0.00491371\n",
      "Iteration 5180, loss = 0.00491302\n",
      "Iteration 5181, loss = 0.00491138\n",
      "Iteration 5182, loss = 0.00491022\n",
      "Iteration 5183, loss = 0.00490896\n",
      "Iteration 5184, loss = 0.00490753\n",
      "Iteration 5185, loss = 0.00490627\n",
      "Iteration 5186, loss = 0.00490465\n",
      "Iteration 5187, loss = 0.00490341\n",
      "Iteration 5188, loss = 0.00490225\n",
      "Iteration 5189, loss = 0.00490083\n",
      "Iteration 5190, loss = 0.00489951\n",
      "Iteration 5191, loss = 0.00489817\n",
      "Iteration 5192, loss = 0.00489684\n",
      "Iteration 5193, loss = 0.00489540\n",
      "Iteration 5194, loss = 0.00489424\n",
      "Iteration 5195, loss = 0.00489293\n",
      "Iteration 5196, loss = 0.00489173\n",
      "Iteration 5197, loss = 0.00489040\n",
      "Iteration 5198, loss = 0.00488899\n",
      "Iteration 5199, loss = 0.00488768\n",
      "Iteration 5200, loss = 0.00488652\n",
      "Iteration 5201, loss = 0.00488489\n",
      "Iteration 5202, loss = 0.00488391\n",
      "Iteration 5203, loss = 0.00488236\n",
      "Iteration 5204, loss = 0.00488093\n",
      "Iteration 5205, loss = 0.00487990\n",
      "Iteration 5206, loss = 0.00487826\n",
      "Iteration 5207, loss = 0.00487699\n",
      "Iteration 5208, loss = 0.00487544\n",
      "Iteration 5209, loss = 0.00487420\n",
      "Iteration 5210, loss = 0.00487280\n",
      "Iteration 5211, loss = 0.00487152\n",
      "Iteration 5212, loss = 0.00487011\n",
      "Iteration 5213, loss = 0.00486873\n",
      "Iteration 5214, loss = 0.00486745\n",
      "Iteration 5215, loss = 0.00486621\n",
      "Iteration 5216, loss = 0.00486492\n",
      "Iteration 5217, loss = 0.00486371\n",
      "Iteration 5218, loss = 0.00486249\n",
      "Iteration 5219, loss = 0.00486148\n",
      "Iteration 5220, loss = 0.00486002\n",
      "Iteration 5221, loss = 0.00485880\n",
      "Iteration 5222, loss = 0.00485833\n",
      "Iteration 5223, loss = 0.00485611\n",
      "Iteration 5224, loss = 0.00485492\n",
      "Iteration 5225, loss = 0.00485366\n",
      "Iteration 5226, loss = 0.00485232\n",
      "Iteration 5227, loss = 0.00485152\n",
      "Iteration 5228, loss = 0.00485031\n",
      "Iteration 5229, loss = 0.00484873\n",
      "Iteration 5230, loss = 0.00484780\n",
      "Iteration 5231, loss = 0.00484625\n",
      "Iteration 5232, loss = 0.00484504\n",
      "Iteration 5233, loss = 0.00484369\n",
      "Iteration 5234, loss = 0.00484283\n",
      "Iteration 5235, loss = 0.00484134\n",
      "Iteration 5236, loss = 0.00483939\n",
      "Iteration 5237, loss = 0.00483854\n",
      "Iteration 5238, loss = 0.00483709\n",
      "Iteration 5239, loss = 0.00483541\n",
      "Iteration 5240, loss = 0.00483427\n",
      "Iteration 5241, loss = 0.00483274\n",
      "Iteration 5242, loss = 0.00483157\n",
      "Iteration 5243, loss = 0.00483017\n",
      "Iteration 5244, loss = 0.00482883\n",
      "Iteration 5245, loss = 0.00482818\n",
      "Iteration 5246, loss = 0.00482641\n",
      "Iteration 5247, loss = 0.00482502\n",
      "Iteration 5248, loss = 0.00482417\n",
      "Iteration 5249, loss = 0.00482250\n",
      "Iteration 5250, loss = 0.00482131\n",
      "Iteration 5251, loss = 0.00482068\n",
      "Iteration 5252, loss = 0.00481888\n",
      "Iteration 5253, loss = 0.00481765\n",
      "Iteration 5254, loss = 0.00481639\n",
      "Iteration 5255, loss = 0.00481520\n",
      "Iteration 5256, loss = 0.00481426\n",
      "Iteration 5257, loss = 0.00481269\n",
      "Iteration 5258, loss = 0.00481140\n",
      "Iteration 5259, loss = 0.00481011\n",
      "Iteration 5260, loss = 0.00480886\n",
      "Iteration 5261, loss = 0.00480720\n",
      "Iteration 5262, loss = 0.00480584\n",
      "Iteration 5263, loss = 0.00480475\n",
      "Iteration 5264, loss = 0.00480328\n",
      "Iteration 5265, loss = 0.00480237\n",
      "Iteration 5266, loss = 0.00480072\n",
      "Iteration 5267, loss = 0.00479971\n",
      "Iteration 5268, loss = 0.00479816\n",
      "Iteration 5269, loss = 0.00479712\n",
      "Iteration 5270, loss = 0.00479649\n",
      "Iteration 5271, loss = 0.00479519\n",
      "Iteration 5272, loss = 0.00479360\n",
      "Iteration 5273, loss = 0.00479234\n",
      "Iteration 5274, loss = 0.00479101\n",
      "Iteration 5275, loss = 0.00478979\n",
      "Iteration 5276, loss = 0.00478901\n",
      "Iteration 5277, loss = 0.00478744\n",
      "Iteration 5278, loss = 0.00478587\n",
      "Iteration 5279, loss = 0.00478463\n",
      "Iteration 5280, loss = 0.00478345\n",
      "Iteration 5281, loss = 0.00478203\n",
      "Iteration 5282, loss = 0.00478067\n",
      "Iteration 5283, loss = 0.00477962\n",
      "Iteration 5284, loss = 0.00477816\n",
      "Iteration 5285, loss = 0.00477688\n",
      "Iteration 5286, loss = 0.00477604\n",
      "Iteration 5287, loss = 0.00477510\n",
      "Iteration 5288, loss = 0.00477359\n",
      "Iteration 5289, loss = 0.00477219\n",
      "Iteration 5290, loss = 0.00477081\n",
      "Iteration 5291, loss = 0.00476965\n",
      "Iteration 5292, loss = 0.00476843\n",
      "Iteration 5293, loss = 0.00476703\n",
      "Iteration 5294, loss = 0.00476587\n",
      "Iteration 5295, loss = 0.00476451\n",
      "Iteration 5296, loss = 0.00476353\n",
      "Iteration 5297, loss = 0.00476198\n",
      "Iteration 5298, loss = 0.00476086\n",
      "Iteration 5299, loss = 0.00475972\n",
      "Iteration 5300, loss = 0.00475845\n",
      "Iteration 5301, loss = 0.00475731\n",
      "Iteration 5302, loss = 0.00475582\n",
      "Iteration 5303, loss = 0.00475470\n",
      "Iteration 5304, loss = 0.00475350\n",
      "Iteration 5305, loss = 0.00475250\n",
      "Iteration 5306, loss = 0.00475099\n",
      "Iteration 5307, loss = 0.00474959\n",
      "Iteration 5308, loss = 0.00474826\n",
      "Iteration 5309, loss = 0.00474716\n",
      "Iteration 5310, loss = 0.00474585\n",
      "Iteration 5311, loss = 0.00474444\n",
      "Iteration 5312, loss = 0.00474302\n",
      "Iteration 5313, loss = 0.00474181\n",
      "Iteration 5314, loss = 0.00474054\n",
      "Iteration 5315, loss = 0.00473939\n",
      "Iteration 5316, loss = 0.00473793\n",
      "Iteration 5317, loss = 0.00473680\n",
      "Iteration 5318, loss = 0.00473673\n",
      "Iteration 5319, loss = 0.00473403\n",
      "Iteration 5320, loss = 0.00473273\n",
      "Iteration 5321, loss = 0.00473134\n",
      "Iteration 5322, loss = 0.00473009\n",
      "Iteration 5323, loss = 0.00472880\n",
      "Iteration 5324, loss = 0.00472781\n",
      "Iteration 5325, loss = 0.00472638\n",
      "Iteration 5326, loss = 0.00472550\n",
      "Iteration 5327, loss = 0.00472382\n",
      "Iteration 5328, loss = 0.00472298\n",
      "Iteration 5329, loss = 0.00472148\n",
      "Iteration 5330, loss = 0.00472042\n",
      "Iteration 5331, loss = 0.00471904\n",
      "Iteration 5332, loss = 0.00471758\n",
      "Iteration 5333, loss = 0.00471650\n",
      "Iteration 5334, loss = 0.00471517\n",
      "Iteration 5335, loss = 0.00471395\n",
      "Iteration 5336, loss = 0.00471259\n",
      "Iteration 5337, loss = 0.00471134\n",
      "Iteration 5338, loss = 0.00471017\n",
      "Iteration 5339, loss = 0.00470907\n",
      "Iteration 5340, loss = 0.00470775\n",
      "Iteration 5341, loss = 0.00470649\n",
      "Iteration 5342, loss = 0.00470543\n",
      "Iteration 5343, loss = 0.00470424\n",
      "Iteration 5344, loss = 0.00470289\n",
      "Iteration 5345, loss = 0.00470210\n",
      "Iteration 5346, loss = 0.00470047\n",
      "Iteration 5347, loss = 0.00469950\n",
      "Iteration 5348, loss = 0.00469838\n",
      "Iteration 5349, loss = 0.00469684\n",
      "Iteration 5350, loss = 0.00469603\n",
      "Iteration 5351, loss = 0.00469455\n",
      "Iteration 5352, loss = 0.00469367\n",
      "Iteration 5353, loss = 0.00469207\n",
      "Iteration 5354, loss = 0.00469095\n",
      "Iteration 5355, loss = 0.00469027\n",
      "Iteration 5356, loss = 0.00468863\n",
      "Iteration 5357, loss = 0.00468746\n",
      "Iteration 5358, loss = 0.00468612\n",
      "Iteration 5359, loss = 0.00468540\n",
      "Iteration 5360, loss = 0.00468373\n",
      "Iteration 5361, loss = 0.00468279\n",
      "Iteration 5362, loss = 0.00468154\n",
      "Iteration 5363, loss = 0.00468011\n",
      "Iteration 5364, loss = 0.00467903\n",
      "Iteration 5365, loss = 0.00467772\n",
      "Iteration 5366, loss = 0.00467663\n",
      "Iteration 5367, loss = 0.00467532\n",
      "Iteration 5368, loss = 0.00467412\n",
      "Iteration 5369, loss = 0.00467304\n",
      "Iteration 5370, loss = 0.00467186\n",
      "Iteration 5371, loss = 0.00467103\n",
      "Iteration 5372, loss = 0.00466959\n",
      "Iteration 5373, loss = 0.00466871\n",
      "Iteration 5374, loss = 0.00466770\n",
      "Iteration 5375, loss = 0.00466607\n",
      "Iteration 5376, loss = 0.00466514\n",
      "Iteration 5377, loss = 0.00466370\n",
      "Iteration 5378, loss = 0.00466282\n",
      "Iteration 5379, loss = 0.00466125\n",
      "Iteration 5380, loss = 0.00466022\n",
      "Iteration 5381, loss = 0.00465893\n",
      "Iteration 5382, loss = 0.00465734\n",
      "Iteration 5383, loss = 0.00465624\n",
      "Iteration 5384, loss = 0.00465500\n",
      "Iteration 5385, loss = 0.00465397\n",
      "Iteration 5386, loss = 0.00465272\n",
      "Iteration 5387, loss = 0.00465159\n",
      "Iteration 5388, loss = 0.00465043\n",
      "Iteration 5389, loss = 0.00464894\n",
      "Iteration 5390, loss = 0.00464773\n",
      "Iteration 5391, loss = 0.00464674\n",
      "Iteration 5392, loss = 0.00464561\n",
      "Iteration 5393, loss = 0.00464450\n",
      "Iteration 5394, loss = 0.00464334\n",
      "Iteration 5395, loss = 0.00464224\n",
      "Iteration 5396, loss = 0.00464106\n",
      "Iteration 5397, loss = 0.00464000\n",
      "Iteration 5398, loss = 0.00463901\n",
      "Iteration 5399, loss = 0.00463812\n",
      "Iteration 5400, loss = 0.00463689\n",
      "Iteration 5401, loss = 0.00463594\n",
      "Iteration 5402, loss = 0.00463453\n",
      "Iteration 5403, loss = 0.00463349\n",
      "Iteration 5404, loss = 0.00463250\n",
      "Iteration 5405, loss = 0.00463159\n",
      "Iteration 5406, loss = 0.00463002\n",
      "Iteration 5407, loss = 0.00462901\n",
      "Iteration 5408, loss = 0.00462775\n",
      "Iteration 5409, loss = 0.00462666\n",
      "Iteration 5410, loss = 0.00462567\n",
      "Iteration 5411, loss = 0.00462444\n",
      "Iteration 5412, loss = 0.00462339\n",
      "Iteration 5413, loss = 0.00462258\n",
      "Iteration 5414, loss = 0.00462120\n",
      "Iteration 5415, loss = 0.00462003\n",
      "Iteration 5416, loss = 0.00461886\n",
      "Iteration 5417, loss = 0.00461814\n",
      "Iteration 5418, loss = 0.00461683\n",
      "Iteration 5419, loss = 0.00461567\n",
      "Iteration 5420, loss = 0.00461465\n",
      "Iteration 5421, loss = 0.00461350\n",
      "Iteration 5422, loss = 0.00461254\n",
      "Iteration 5423, loss = 0.00461142\n",
      "Iteration 5424, loss = 0.00461036\n",
      "Iteration 5425, loss = 0.00460897\n",
      "Iteration 5426, loss = 0.00460770\n",
      "Iteration 5427, loss = 0.00460655\n",
      "Iteration 5428, loss = 0.00460539\n",
      "Iteration 5429, loss = 0.00460422\n",
      "Iteration 5430, loss = 0.00460321\n",
      "Iteration 5431, loss = 0.00460184\n",
      "Iteration 5432, loss = 0.00460069\n",
      "Iteration 5433, loss = 0.00459956\n",
      "Iteration 5434, loss = 0.00459827\n",
      "Iteration 5435, loss = 0.00459733\n",
      "Iteration 5436, loss = 0.00459660\n",
      "Iteration 5437, loss = 0.00459520\n",
      "Iteration 5438, loss = 0.00459416\n",
      "Iteration 5439, loss = 0.00459302\n",
      "Iteration 5440, loss = 0.00459185\n",
      "Iteration 5441, loss = 0.00459150\n",
      "Iteration 5442, loss = 0.00458959\n",
      "Iteration 5443, loss = 0.00458862\n",
      "Iteration 5444, loss = 0.00458772\n",
      "Iteration 5445, loss = 0.00458617\n",
      "Iteration 5446, loss = 0.00458465\n",
      "Iteration 5447, loss = 0.00458376\n",
      "Iteration 5448, loss = 0.00458236\n",
      "Iteration 5449, loss = 0.00458117\n",
      "Iteration 5450, loss = 0.00457988\n",
      "Iteration 5451, loss = 0.00457881\n",
      "Iteration 5452, loss = 0.00457781\n",
      "Iteration 5453, loss = 0.00457635\n",
      "Iteration 5454, loss = 0.00457548\n",
      "Iteration 5455, loss = 0.00457420\n",
      "Iteration 5456, loss = 0.00457297\n",
      "Iteration 5457, loss = 0.00457175\n",
      "Iteration 5458, loss = 0.00457063\n",
      "Iteration 5459, loss = 0.00456952\n",
      "Iteration 5460, loss = 0.00456847\n",
      "Iteration 5461, loss = 0.00456733\n",
      "Iteration 5462, loss = 0.00456640\n",
      "Iteration 5463, loss = 0.00456531\n",
      "Iteration 5464, loss = 0.00456427\n",
      "Iteration 5465, loss = 0.00456297\n",
      "Iteration 5466, loss = 0.00456192\n",
      "Iteration 5467, loss = 0.00456074\n",
      "Iteration 5468, loss = 0.00455974\n",
      "Iteration 5469, loss = 0.00455870\n",
      "Iteration 5470, loss = 0.00455751\n",
      "Iteration 5471, loss = 0.00455632\n",
      "Iteration 5472, loss = 0.00455521\n",
      "Iteration 5473, loss = 0.00455404\n",
      "Iteration 5474, loss = 0.00455295\n",
      "Iteration 5475, loss = 0.00455173\n",
      "Iteration 5476, loss = 0.00455060\n",
      "Iteration 5477, loss = 0.00454957\n",
      "Iteration 5478, loss = 0.00454841\n",
      "Iteration 5479, loss = 0.00454742\n",
      "Iteration 5480, loss = 0.00454623\n",
      "Iteration 5481, loss = 0.00454522\n",
      "Iteration 5482, loss = 0.00454425\n",
      "Iteration 5483, loss = 0.00454311\n",
      "Iteration 5484, loss = 0.00454213\n",
      "Iteration 5485, loss = 0.00454103\n",
      "Iteration 5486, loss = 0.00454010\n",
      "Iteration 5487, loss = 0.00453878\n",
      "Iteration 5488, loss = 0.00453855\n",
      "Iteration 5489, loss = 0.00453710\n",
      "Iteration 5490, loss = 0.00453588\n",
      "Iteration 5491, loss = 0.00453474\n",
      "Iteration 5492, loss = 0.00453362\n",
      "Iteration 5493, loss = 0.00453255\n",
      "Iteration 5494, loss = 0.00453138\n",
      "Iteration 5495, loss = 0.00453019\n",
      "Iteration 5496, loss = 0.00452904\n",
      "Iteration 5497, loss = 0.00452796\n",
      "Iteration 5498, loss = 0.00452719\n",
      "Iteration 5499, loss = 0.00452561\n",
      "Iteration 5500, loss = 0.00452407\n",
      "Iteration 5501, loss = 0.00452303\n",
      "Iteration 5502, loss = 0.00452174\n",
      "Iteration 5503, loss = 0.00452055\n",
      "Iteration 5504, loss = 0.00451938\n",
      "Iteration 5505, loss = 0.00451818\n",
      "Iteration 5506, loss = 0.00451700\n",
      "Iteration 5507, loss = 0.00451579\n",
      "Iteration 5508, loss = 0.00451445\n",
      "Iteration 5509, loss = 0.00451341\n",
      "Iteration 5510, loss = 0.00451210\n",
      "Iteration 5511, loss = 0.00451103\n",
      "Iteration 5512, loss = 0.00450991\n",
      "Iteration 5513, loss = 0.00450874\n",
      "Iteration 5514, loss = 0.00450762\n",
      "Iteration 5515, loss = 0.00450657\n",
      "Iteration 5516, loss = 0.00450553\n",
      "Iteration 5517, loss = 0.00450442\n",
      "Iteration 5518, loss = 0.00450339\n",
      "Iteration 5519, loss = 0.00450239\n",
      "Iteration 5520, loss = 0.00450173\n",
      "Iteration 5521, loss = 0.00450006\n",
      "Iteration 5522, loss = 0.00449891\n",
      "Iteration 5523, loss = 0.00449762\n",
      "Iteration 5524, loss = 0.00449636\n",
      "Iteration 5525, loss = 0.00449514\n",
      "Iteration 5526, loss = 0.00449398\n",
      "Iteration 5527, loss = 0.00449292\n",
      "Iteration 5528, loss = 0.00449198\n",
      "Iteration 5529, loss = 0.00449060\n",
      "Iteration 5530, loss = 0.00448961\n",
      "Iteration 5531, loss = 0.00448829\n",
      "Iteration 5532, loss = 0.00448754\n",
      "Iteration 5533, loss = 0.00448575\n",
      "Iteration 5534, loss = 0.00448461\n",
      "Iteration 5535, loss = 0.00448323\n",
      "Iteration 5536, loss = 0.00448213\n",
      "Iteration 5537, loss = 0.00448113\n",
      "Iteration 5538, loss = 0.00447969\n",
      "Iteration 5539, loss = 0.00447892\n",
      "Iteration 5540, loss = 0.00447782\n",
      "Iteration 5541, loss = 0.00447649\n",
      "Iteration 5542, loss = 0.00447540\n",
      "Iteration 5543, loss = 0.00447450\n",
      "Iteration 5544, loss = 0.00447334\n",
      "Iteration 5545, loss = 0.00447197\n",
      "Iteration 5546, loss = 0.00447137\n",
      "Iteration 5547, loss = 0.00447003\n",
      "Iteration 5548, loss = 0.00446896\n",
      "Iteration 5549, loss = 0.00446780\n",
      "Iteration 5550, loss = 0.00446676\n",
      "Iteration 5551, loss = 0.00446613\n",
      "Iteration 5552, loss = 0.00446497\n",
      "Iteration 5553, loss = 0.00446372\n",
      "Iteration 5554, loss = 0.00446231\n",
      "Iteration 5555, loss = 0.00446115\n",
      "Iteration 5556, loss = 0.00446006\n",
      "Iteration 5557, loss = 0.00445897\n",
      "Iteration 5558, loss = 0.00445802\n",
      "Iteration 5559, loss = 0.00445680\n",
      "Iteration 5560, loss = 0.00445609\n",
      "Iteration 5561, loss = 0.00445486\n",
      "Iteration 5562, loss = 0.00445393\n",
      "Iteration 5563, loss = 0.00445276\n",
      "Iteration 5564, loss = 0.00445165\n",
      "Iteration 5565, loss = 0.00445064\n",
      "Iteration 5566, loss = 0.00444985\n",
      "Iteration 5567, loss = 0.00444827\n",
      "Iteration 5568, loss = 0.00444700\n",
      "Iteration 5569, loss = 0.00444604\n",
      "Iteration 5570, loss = 0.00444482\n",
      "Iteration 5571, loss = 0.00444347\n",
      "Iteration 5572, loss = 0.00444219\n",
      "Iteration 5573, loss = 0.00444102\n",
      "Iteration 5574, loss = 0.00443960\n",
      "Iteration 5575, loss = 0.00443847\n",
      "Iteration 5576, loss = 0.00443730\n",
      "Iteration 5577, loss = 0.00443589\n",
      "Iteration 5578, loss = 0.00443501\n",
      "Iteration 5579, loss = 0.00443427\n",
      "Iteration 5580, loss = 0.00443297\n",
      "Iteration 5581, loss = 0.00443217\n",
      "Iteration 5582, loss = 0.00443101\n",
      "Iteration 5583, loss = 0.00443009\n",
      "Iteration 5584, loss = 0.00442901\n",
      "Iteration 5585, loss = 0.00442806\n",
      "Iteration 5586, loss = 0.00442711\n",
      "Iteration 5587, loss = 0.00442628\n",
      "Iteration 5588, loss = 0.00442578\n",
      "Iteration 5589, loss = 0.00442435\n",
      "Iteration 5590, loss = 0.00442314\n",
      "Iteration 5591, loss = 0.00442178\n",
      "Iteration 5592, loss = 0.00442156\n",
      "Iteration 5593, loss = 0.00441986\n",
      "Iteration 5594, loss = 0.00441868\n",
      "Iteration 5595, loss = 0.00441717\n",
      "Iteration 5596, loss = 0.00441649\n",
      "Iteration 5597, loss = 0.00441491\n",
      "Iteration 5598, loss = 0.00441383\n",
      "Iteration 5599, loss = 0.00441269\n",
      "Iteration 5600, loss = 0.00441180\n",
      "Iteration 5601, loss = 0.00441025\n",
      "Iteration 5602, loss = 0.00440951\n",
      "Iteration 5603, loss = 0.00440808\n",
      "Iteration 5604, loss = 0.00440674\n",
      "Iteration 5605, loss = 0.00440550\n",
      "Iteration 5606, loss = 0.00440447\n",
      "Iteration 5607, loss = 0.00440326\n",
      "Iteration 5608, loss = 0.00440233\n",
      "Iteration 5609, loss = 0.00440128\n",
      "Iteration 5610, loss = 0.00439987\n",
      "Iteration 5611, loss = 0.00439888\n",
      "Iteration 5612, loss = 0.00439786\n",
      "Iteration 5613, loss = 0.00439666\n",
      "Iteration 5614, loss = 0.00439577\n",
      "Iteration 5615, loss = 0.00439463\n",
      "Iteration 5616, loss = 0.00439350\n",
      "Iteration 5617, loss = 0.00439232\n",
      "Iteration 5618, loss = 0.00439129\n",
      "Iteration 5619, loss = 0.00438984\n",
      "Iteration 5620, loss = 0.00438873\n",
      "Iteration 5621, loss = 0.00438736\n",
      "Iteration 5622, loss = 0.00438623\n",
      "Iteration 5623, loss = 0.00438542\n",
      "Iteration 5624, loss = 0.00438389\n",
      "Iteration 5625, loss = 0.00438273\n",
      "Iteration 5626, loss = 0.00438168\n",
      "Iteration 5627, loss = 0.00438047\n",
      "Iteration 5628, loss = 0.00437942\n",
      "Iteration 5629, loss = 0.00437856\n",
      "Iteration 5630, loss = 0.00437737\n",
      "Iteration 5631, loss = 0.00437660\n",
      "Iteration 5632, loss = 0.00437504\n",
      "Iteration 5633, loss = 0.00437385\n",
      "Iteration 5634, loss = 0.00437278\n",
      "Iteration 5635, loss = 0.00437185\n",
      "Iteration 5636, loss = 0.00437056\n",
      "Iteration 5637, loss = 0.00436944\n",
      "Iteration 5638, loss = 0.00436866\n",
      "Iteration 5639, loss = 0.00436743\n",
      "Iteration 5640, loss = 0.00436623\n",
      "Iteration 5641, loss = 0.00436500\n",
      "Iteration 5642, loss = 0.00436416\n",
      "Iteration 5643, loss = 0.00436306\n",
      "Iteration 5644, loss = 0.00436218\n",
      "Iteration 5645, loss = 0.00436107\n",
      "Iteration 5646, loss = 0.00435991\n",
      "Iteration 5647, loss = 0.00435876\n",
      "Iteration 5648, loss = 0.00435779\n",
      "Iteration 5649, loss = 0.00435674\n",
      "Iteration 5650, loss = 0.00435556\n",
      "Iteration 5651, loss = 0.00435454\n",
      "Iteration 5652, loss = 0.00435331\n",
      "Iteration 5653, loss = 0.00435234\n",
      "Iteration 5654, loss = 0.00435119\n",
      "Iteration 5655, loss = 0.00435023\n",
      "Iteration 5656, loss = 0.00434912\n",
      "Iteration 5657, loss = 0.00434813\n",
      "Iteration 5658, loss = 0.00434716\n",
      "Iteration 5659, loss = 0.00434686\n",
      "Iteration 5660, loss = 0.00434512\n",
      "Iteration 5661, loss = 0.00434405\n",
      "Iteration 5662, loss = 0.00434322\n",
      "Iteration 5663, loss = 0.00434218\n",
      "Iteration 5664, loss = 0.00434111\n",
      "Iteration 5665, loss = 0.00433990\n",
      "Iteration 5666, loss = 0.00433870\n",
      "Iteration 5667, loss = 0.00433754\n",
      "Iteration 5668, loss = 0.00433663\n",
      "Iteration 5669, loss = 0.00433571\n",
      "Iteration 5670, loss = 0.00433448\n",
      "Iteration 5671, loss = 0.00433346\n",
      "Iteration 5672, loss = 0.00433248\n",
      "Iteration 5673, loss = 0.00433155\n",
      "Iteration 5674, loss = 0.00433036\n",
      "Iteration 5675, loss = 0.00432985\n",
      "Iteration 5676, loss = 0.00432885\n",
      "Iteration 5677, loss = 0.00432768\n",
      "Iteration 5678, loss = 0.00432670\n",
      "Iteration 5679, loss = 0.00432525\n",
      "Iteration 5680, loss = 0.00432424\n",
      "Iteration 5681, loss = 0.00432307\n",
      "Iteration 5682, loss = 0.00432185\n",
      "Iteration 5683, loss = 0.00432067\n",
      "Iteration 5684, loss = 0.00431954\n",
      "Iteration 5685, loss = 0.00431841\n",
      "Iteration 5686, loss = 0.00431712\n",
      "Iteration 5687, loss = 0.00431600\n",
      "Iteration 5688, loss = 0.00431498\n",
      "Iteration 5689, loss = 0.00431385\n",
      "Iteration 5690, loss = 0.00431274\n",
      "Iteration 5691, loss = 0.00431164\n",
      "Iteration 5692, loss = 0.00431053\n",
      "Iteration 5693, loss = 0.00430926\n",
      "Iteration 5694, loss = 0.00430829\n",
      "Iteration 5695, loss = 0.00430704\n",
      "Iteration 5696, loss = 0.00430569\n",
      "Iteration 5697, loss = 0.00430427\n",
      "Iteration 5698, loss = 0.00430383\n",
      "Iteration 5699, loss = 0.00430280\n",
      "Iteration 5700, loss = 0.00430119\n",
      "Iteration 5701, loss = 0.00430005\n",
      "Iteration 5702, loss = 0.00429911\n",
      "Iteration 5703, loss = 0.00429790\n",
      "Iteration 5704, loss = 0.00429661\n",
      "Iteration 5705, loss = 0.00429529\n",
      "Iteration 5706, loss = 0.00429406\n",
      "Iteration 5707, loss = 0.00429331\n",
      "Iteration 5708, loss = 0.00429225\n",
      "Iteration 5709, loss = 0.00429070\n",
      "Iteration 5710, loss = 0.00428988\n",
      "Iteration 5711, loss = 0.00428865\n",
      "Iteration 5712, loss = 0.00428766\n",
      "Iteration 5713, loss = 0.00428632\n",
      "Iteration 5714, loss = 0.00428551\n",
      "Iteration 5715, loss = 0.00428424\n",
      "Iteration 5716, loss = 0.00428299\n",
      "Iteration 5717, loss = 0.00428188\n",
      "Iteration 5718, loss = 0.00428073\n",
      "Iteration 5719, loss = 0.00427971\n",
      "Iteration 5720, loss = 0.00427860\n",
      "Iteration 5721, loss = 0.00427787\n",
      "Iteration 5722, loss = 0.00427666\n",
      "Iteration 5723, loss = 0.00427640\n",
      "Iteration 5724, loss = 0.00427483\n",
      "Iteration 5725, loss = 0.00427370\n",
      "Iteration 5726, loss = 0.00427234\n",
      "Iteration 5727, loss = 0.00427125\n",
      "Iteration 5728, loss = 0.00427086\n",
      "Iteration 5729, loss = 0.00426921\n",
      "Iteration 5730, loss = 0.00426814\n",
      "Iteration 5731, loss = 0.00426709\n",
      "Iteration 5732, loss = 0.00426586\n",
      "Iteration 5733, loss = 0.00426478\n",
      "Iteration 5734, loss = 0.00426372\n",
      "Iteration 5735, loss = 0.00426297\n",
      "Iteration 5736, loss = 0.00426185\n",
      "Iteration 5737, loss = 0.00426088\n",
      "Iteration 5738, loss = 0.00425990\n",
      "Iteration 5739, loss = 0.00425914\n",
      "Iteration 5740, loss = 0.00425816\n",
      "Iteration 5741, loss = 0.00425720\n",
      "Iteration 5742, loss = 0.00425686\n",
      "Iteration 5743, loss = 0.00425556\n",
      "Iteration 5744, loss = 0.00425438\n",
      "Iteration 5745, loss = 0.00425325\n",
      "Iteration 5746, loss = 0.00425234\n",
      "Iteration 5747, loss = 0.00425131\n",
      "Iteration 5748, loss = 0.00425025\n",
      "Iteration 5749, loss = 0.00424937\n",
      "Iteration 5750, loss = 0.00424864\n",
      "Iteration 5751, loss = 0.00424753\n",
      "Iteration 5752, loss = 0.00424656\n",
      "Iteration 5753, loss = 0.00424556\n",
      "Iteration 5754, loss = 0.00424445\n",
      "Iteration 5755, loss = 0.00424351\n",
      "Iteration 5756, loss = 0.00424225\n",
      "Iteration 5757, loss = 0.00424140\n",
      "Iteration 5758, loss = 0.00424055\n",
      "Iteration 5759, loss = 0.00423962\n",
      "Iteration 5760, loss = 0.00423931\n",
      "Iteration 5761, loss = 0.00423770\n",
      "Iteration 5762, loss = 0.00423635\n",
      "Iteration 5763, loss = 0.00423534\n",
      "Iteration 5764, loss = 0.00423449\n",
      "Iteration 5765, loss = 0.00423347\n",
      "Iteration 5766, loss = 0.00423253\n",
      "Iteration 5767, loss = 0.00423156\n",
      "Iteration 5768, loss = 0.00423033\n",
      "Iteration 5769, loss = 0.00422950\n",
      "Iteration 5770, loss = 0.00422833\n",
      "Iteration 5771, loss = 0.00422742\n",
      "Iteration 5772, loss = 0.00422649\n",
      "Iteration 5773, loss = 0.00422629\n",
      "Iteration 5774, loss = 0.00422431\n",
      "Iteration 5775, loss = 0.00422343\n",
      "Iteration 5776, loss = 0.00422209\n",
      "Iteration 5777, loss = 0.00422089\n",
      "Iteration 5778, loss = 0.00421983\n",
      "Iteration 5779, loss = 0.00421871\n",
      "Iteration 5780, loss = 0.00421747\n",
      "Iteration 5781, loss = 0.00421656\n",
      "Iteration 5782, loss = 0.00421540\n",
      "Iteration 5783, loss = 0.00421427\n",
      "Iteration 5784, loss = 0.00421338\n",
      "Iteration 5785, loss = 0.00421231\n",
      "Iteration 5786, loss = 0.00421125\n",
      "Iteration 5787, loss = 0.00421027\n",
      "Iteration 5788, loss = 0.00420940\n",
      "Iteration 5789, loss = 0.00420848\n",
      "Iteration 5790, loss = 0.00420758\n",
      "Iteration 5791, loss = 0.00420652\n",
      "Iteration 5792, loss = 0.00420612\n",
      "Iteration 5793, loss = 0.00420473\n",
      "Iteration 5794, loss = 0.00420369\n",
      "Iteration 5795, loss = 0.00420266\n",
      "Iteration 5796, loss = 0.00420162\n",
      "Iteration 5797, loss = 0.00420078\n",
      "Iteration 5798, loss = 0.00419934\n",
      "Iteration 5799, loss = 0.00419814\n",
      "Iteration 5800, loss = 0.00419708\n",
      "Iteration 5801, loss = 0.00419593\n",
      "Iteration 5802, loss = 0.00419495\n",
      "Iteration 5803, loss = 0.00419425\n",
      "Iteration 5804, loss = 0.00419290\n",
      "Iteration 5805, loss = 0.00419196\n",
      "Iteration 5806, loss = 0.00419094\n",
      "Iteration 5807, loss = 0.00419037\n",
      "Iteration 5808, loss = 0.00418921\n",
      "Iteration 5809, loss = 0.00418835\n",
      "Iteration 5810, loss = 0.00418735\n",
      "Iteration 5811, loss = 0.00418630\n",
      "Iteration 5812, loss = 0.00418531\n",
      "Iteration 5813, loss = 0.00418437\n",
      "Iteration 5814, loss = 0.00418347\n",
      "Iteration 5815, loss = 0.00418297\n",
      "Iteration 5816, loss = 0.00418165\n",
      "Iteration 5817, loss = 0.00418064\n",
      "Iteration 5818, loss = 0.00417968\n",
      "Iteration 5819, loss = 0.00417876\n",
      "Iteration 5820, loss = 0.00417790\n",
      "Iteration 5821, loss = 0.00417688\n",
      "Iteration 5822, loss = 0.00417576\n",
      "Iteration 5823, loss = 0.00417480\n",
      "Iteration 5824, loss = 0.00417381\n",
      "Iteration 5825, loss = 0.00417303\n",
      "Iteration 5826, loss = 0.00417174\n",
      "Iteration 5827, loss = 0.00417088\n",
      "Iteration 5828, loss = 0.00416979\n",
      "Iteration 5829, loss = 0.00416909\n",
      "Iteration 5830, loss = 0.00416744\n",
      "Iteration 5831, loss = 0.00416650\n",
      "Iteration 5832, loss = 0.00416535\n",
      "Iteration 5833, loss = 0.00416424\n",
      "Iteration 5834, loss = 0.00416329\n",
      "Iteration 5835, loss = 0.00416236\n",
      "Iteration 5836, loss = 0.00416133\n",
      "Iteration 5837, loss = 0.00416017\n",
      "Iteration 5838, loss = 0.00415910\n",
      "Iteration 5839, loss = 0.00415820\n",
      "Iteration 5840, loss = 0.00415729\n",
      "Iteration 5841, loss = 0.00415601\n",
      "Iteration 5842, loss = 0.00415514\n",
      "Iteration 5843, loss = 0.00415394\n",
      "Iteration 5844, loss = 0.00415313\n",
      "Iteration 5845, loss = 0.00415242\n",
      "Iteration 5846, loss = 0.00415113\n",
      "Iteration 5847, loss = 0.00415009\n",
      "Iteration 5848, loss = 0.00414910\n",
      "Iteration 5849, loss = 0.00414813\n",
      "Iteration 5850, loss = 0.00414702\n",
      "Iteration 5851, loss = 0.00414586\n",
      "Iteration 5852, loss = 0.00414518\n",
      "Iteration 5853, loss = 0.00414398\n",
      "Iteration 5854, loss = 0.00414282\n",
      "Iteration 5855, loss = 0.00414160\n",
      "Iteration 5856, loss = 0.00414086\n",
      "Iteration 5857, loss = 0.00413965\n",
      "Iteration 5858, loss = 0.00413880\n",
      "Iteration 5859, loss = 0.00413773\n",
      "Iteration 5860, loss = 0.00413642\n",
      "Iteration 5861, loss = 0.00413548\n",
      "Iteration 5862, loss = 0.00413433\n",
      "Iteration 5863, loss = 0.00413345\n",
      "Iteration 5864, loss = 0.00413249\n",
      "Iteration 5865, loss = 0.00413141\n",
      "Iteration 5866, loss = 0.00413071\n",
      "Iteration 5867, loss = 0.00412956\n",
      "Iteration 5868, loss = 0.00412863\n",
      "Iteration 5869, loss = 0.00412763\n",
      "Iteration 5870, loss = 0.00412664\n",
      "Iteration 5871, loss = 0.00412561\n",
      "Iteration 5872, loss = 0.00412464\n",
      "Iteration 5873, loss = 0.00412358\n",
      "Iteration 5874, loss = 0.00412265\n",
      "Iteration 5875, loss = 0.00412157\n",
      "Iteration 5876, loss = 0.00412039\n",
      "Iteration 5877, loss = 0.00411922\n",
      "Iteration 5878, loss = 0.00411809\n",
      "Iteration 5879, loss = 0.00411722\n",
      "Iteration 5880, loss = 0.00411654\n",
      "Iteration 5881, loss = 0.00411519\n",
      "Iteration 5882, loss = 0.00411425\n",
      "Iteration 5883, loss = 0.00411320\n",
      "Iteration 5884, loss = 0.00411233\n",
      "Iteration 5885, loss = 0.00411118\n",
      "Iteration 5886, loss = 0.00411061\n",
      "Iteration 5887, loss = 0.00410933\n",
      "Iteration 5888, loss = 0.00410835\n",
      "Iteration 5889, loss = 0.00410732\n",
      "Iteration 5890, loss = 0.00410659\n",
      "Iteration 5891, loss = 0.00410536\n",
      "Iteration 5892, loss = 0.00410468\n",
      "Iteration 5893, loss = 0.00410356\n",
      "Iteration 5894, loss = 0.00410256\n",
      "Iteration 5895, loss = 0.00410172\n",
      "Iteration 5896, loss = 0.00410066\n",
      "Iteration 5897, loss = 0.00409941\n",
      "Iteration 5898, loss = 0.00409865\n",
      "Iteration 5899, loss = 0.00409763\n",
      "Iteration 5900, loss = 0.00409655\n",
      "Iteration 5901, loss = 0.00409565\n",
      "Iteration 5902, loss = 0.00409475\n",
      "Iteration 5903, loss = 0.00409382\n",
      "Iteration 5904, loss = 0.00409295\n",
      "Iteration 5905, loss = 0.00409202\n",
      "Iteration 5906, loss = 0.00409171\n",
      "Iteration 5907, loss = 0.00409027\n",
      "Iteration 5908, loss = 0.00408943\n",
      "Iteration 5909, loss = 0.00408857\n",
      "Iteration 5910, loss = 0.00408752\n",
      "Iteration 5911, loss = 0.00408672\n",
      "Iteration 5912, loss = 0.00408563\n",
      "Iteration 5913, loss = 0.00408480\n",
      "Iteration 5914, loss = 0.00408392\n",
      "Iteration 5915, loss = 0.00408308\n",
      "Iteration 5916, loss = 0.00408208\n",
      "Iteration 5917, loss = 0.00408117\n",
      "Iteration 5918, loss = 0.00408020\n",
      "Iteration 5919, loss = 0.00407957\n",
      "Iteration 5920, loss = 0.00407849\n",
      "Iteration 5921, loss = 0.00407737\n",
      "Iteration 5922, loss = 0.00407634\n",
      "Iteration 5923, loss = 0.00407562\n",
      "Iteration 5924, loss = 0.00407446\n",
      "Iteration 5925, loss = 0.00407343\n",
      "Iteration 5926, loss = 0.00407240\n",
      "Iteration 5927, loss = 0.00407149\n",
      "Iteration 5928, loss = 0.00407044\n",
      "Iteration 5929, loss = 0.00406938\n",
      "Iteration 5930, loss = 0.00406836\n",
      "Iteration 5931, loss = 0.00406738\n",
      "Iteration 5932, loss = 0.00406636\n",
      "Iteration 5933, loss = 0.00406521\n",
      "Iteration 5934, loss = 0.00406402\n",
      "Iteration 5935, loss = 0.00406282\n",
      "Iteration 5936, loss = 0.00406163\n",
      "Iteration 5937, loss = 0.00406128\n",
      "Iteration 5938, loss = 0.00406029\n",
      "Iteration 5939, loss = 0.00405959\n",
      "Iteration 5940, loss = 0.00405818\n",
      "Iteration 5941, loss = 0.00405715\n",
      "Iteration 5942, loss = 0.00405631\n",
      "Iteration 5943, loss = 0.00405571\n",
      "Iteration 5944, loss = 0.00405453\n",
      "Iteration 5945, loss = 0.00405365\n",
      "Iteration 5946, loss = 0.00405273\n",
      "Iteration 5947, loss = 0.00405184\n",
      "Iteration 5948, loss = 0.00405085\n",
      "Iteration 5949, loss = 0.00404998\n",
      "Iteration 5950, loss = 0.00404907\n",
      "Iteration 5951, loss = 0.00404825\n",
      "Iteration 5952, loss = 0.00404722\n",
      "Iteration 5953, loss = 0.00404627\n",
      "Iteration 5954, loss = 0.00404544\n",
      "Iteration 5955, loss = 0.00404445\n",
      "Iteration 5956, loss = 0.00404353\n",
      "Iteration 5957, loss = 0.00404249\n",
      "Iteration 5958, loss = 0.00404151\n",
      "Iteration 5959, loss = 0.00404051\n",
      "Iteration 5960, loss = 0.00403958\n",
      "Iteration 5961, loss = 0.00403877\n",
      "Iteration 5962, loss = 0.00403802\n",
      "Iteration 5963, loss = 0.00403735\n",
      "Iteration 5964, loss = 0.00403613\n",
      "Iteration 5965, loss = 0.00403517\n",
      "Iteration 5966, loss = 0.00403405\n",
      "Iteration 5967, loss = 0.00403329\n",
      "Iteration 5968, loss = 0.00403213\n",
      "Iteration 5969, loss = 0.00403110\n",
      "Iteration 5970, loss = 0.00403022\n",
      "Iteration 5971, loss = 0.00402948\n",
      "Iteration 5972, loss = 0.00402819\n",
      "Iteration 5973, loss = 0.00402741\n",
      "Iteration 5974, loss = 0.00402663\n",
      "Iteration 5975, loss = 0.00402555\n",
      "Iteration 5976, loss = 0.00402461\n",
      "Iteration 5977, loss = 0.00402369\n",
      "Iteration 5978, loss = 0.00402275\n",
      "Iteration 5979, loss = 0.00402167\n",
      "Iteration 5980, loss = 0.00402106\n",
      "Iteration 5981, loss = 0.00401994\n",
      "Iteration 5982, loss = 0.00401872\n",
      "Iteration 5983, loss = 0.00401785\n",
      "Iteration 5984, loss = 0.00401678\n",
      "Iteration 5985, loss = 0.00401613\n",
      "Iteration 5986, loss = 0.00401479\n",
      "Iteration 5987, loss = 0.00401406\n",
      "Iteration 5988, loss = 0.00401279\n",
      "Iteration 5989, loss = 0.00401189\n",
      "Iteration 5990, loss = 0.00401104\n",
      "Iteration 5991, loss = 0.00401005\n",
      "Iteration 5992, loss = 0.00400895\n",
      "Iteration 5993, loss = 0.00400808\n",
      "Iteration 5994, loss = 0.00400707\n",
      "Iteration 5995, loss = 0.00400598\n",
      "Iteration 5996, loss = 0.00400505\n",
      "Iteration 5997, loss = 0.00400413\n",
      "Iteration 5998, loss = 0.00400302\n",
      "Iteration 5999, loss = 0.00400231\n",
      "Iteration 6000, loss = 0.00400134\n",
      "Iteration 6001, loss = 0.00400032\n",
      "Iteration 6002, loss = 0.00399936\n",
      "Iteration 6003, loss = 0.00399844\n",
      "Iteration 6004, loss = 0.00399748\n",
      "Iteration 6005, loss = 0.00399669\n",
      "Iteration 6006, loss = 0.00399583\n",
      "Iteration 6007, loss = 0.00399497\n",
      "Iteration 6008, loss = 0.00399410\n",
      "Iteration 6009, loss = 0.00399329\n",
      "Iteration 6010, loss = 0.00399249\n",
      "Iteration 6011, loss = 0.00399157\n",
      "Iteration 6012, loss = 0.00399121\n",
      "Iteration 6013, loss = 0.00398988\n",
      "Iteration 6014, loss = 0.00398895\n",
      "Iteration 6015, loss = 0.00398808\n",
      "Iteration 6016, loss = 0.00398715\n",
      "Iteration 6017, loss = 0.00398621\n",
      "Iteration 6018, loss = 0.00398544\n",
      "Iteration 6019, loss = 0.00398437\n",
      "Iteration 6020, loss = 0.00398336\n",
      "Iteration 6021, loss = 0.00398247\n",
      "Iteration 6022, loss = 0.00398152\n",
      "Iteration 6023, loss = 0.00398061\n",
      "Iteration 6024, loss = 0.00398028\n",
      "Iteration 6025, loss = 0.00397921\n",
      "Iteration 6026, loss = 0.00397837\n",
      "Iteration 6027, loss = 0.00397755\n",
      "Iteration 6028, loss = 0.00397661\n",
      "Iteration 6029, loss = 0.00397585\n",
      "Iteration 6030, loss = 0.00397524\n",
      "Iteration 6031, loss = 0.00397412\n",
      "Iteration 6032, loss = 0.00397330\n",
      "Iteration 6033, loss = 0.00397243\n",
      "Iteration 6034, loss = 0.00397172\n",
      "Iteration 6035, loss = 0.00397067\n",
      "Iteration 6036, loss = 0.00396976\n",
      "Iteration 6037, loss = 0.00396878\n",
      "Iteration 6038, loss = 0.00396810\n",
      "Iteration 6039, loss = 0.00396709\n",
      "Iteration 6040, loss = 0.00396641\n",
      "Iteration 6041, loss = 0.00396565\n",
      "Iteration 6042, loss = 0.00396452\n",
      "Iteration 6043, loss = 0.00396361\n",
      "Iteration 6044, loss = 0.00396257\n",
      "Iteration 6045, loss = 0.00396186\n",
      "Iteration 6046, loss = 0.00396078\n",
      "Iteration 6047, loss = 0.00395967\n",
      "Iteration 6048, loss = 0.00395871\n",
      "Iteration 6049, loss = 0.00395761\n",
      "Iteration 6050, loss = 0.00395672\n",
      "Iteration 6051, loss = 0.00395590\n",
      "Iteration 6052, loss = 0.00395488\n",
      "Iteration 6053, loss = 0.00395390\n",
      "Iteration 6054, loss = 0.00395285\n",
      "Iteration 6055, loss = 0.00395213\n",
      "Iteration 6056, loss = 0.00395093\n",
      "Iteration 6057, loss = 0.00395010\n",
      "Iteration 6058, loss = 0.00394938\n",
      "Iteration 6059, loss = 0.00394877\n",
      "Iteration 6060, loss = 0.00394732\n",
      "Iteration 6061, loss = 0.00394645\n",
      "Iteration 6062, loss = 0.00394560\n",
      "Iteration 6063, loss = 0.00394503\n",
      "Iteration 6064, loss = 0.00394373\n",
      "Iteration 6065, loss = 0.00394311\n",
      "Iteration 6066, loss = 0.00394226\n",
      "Iteration 6067, loss = 0.00394129\n",
      "Iteration 6068, loss = 0.00394036\n",
      "Iteration 6069, loss = 0.00393948\n",
      "Iteration 6070, loss = 0.00393899\n",
      "Iteration 6071, loss = 0.00393784\n",
      "Iteration 6072, loss = 0.00393690\n",
      "Iteration 6073, loss = 0.00393635\n",
      "Iteration 6074, loss = 0.00393523\n",
      "Iteration 6075, loss = 0.00393429\n",
      "Iteration 6076, loss = 0.00393333\n",
      "Iteration 6077, loss = 0.00393246\n",
      "Iteration 6078, loss = 0.00393171\n",
      "Iteration 6079, loss = 0.00393070\n",
      "Iteration 6080, loss = 0.00392951\n",
      "Iteration 6081, loss = 0.00392853\n",
      "Iteration 6082, loss = 0.00392756\n",
      "Iteration 6083, loss = 0.00392644\n",
      "Iteration 6084, loss = 0.00392562\n",
      "Iteration 6085, loss = 0.00392443\n",
      "Iteration 6086, loss = 0.00392348\n",
      "Iteration 6087, loss = 0.00392277\n",
      "Iteration 6088, loss = 0.00392190\n",
      "Iteration 6089, loss = 0.00392089\n",
      "Iteration 6090, loss = 0.00391987\n",
      "Iteration 6091, loss = 0.00391921\n",
      "Iteration 6092, loss = 0.00391805\n",
      "Iteration 6093, loss = 0.00391717\n",
      "Iteration 6094, loss = 0.00391624\n",
      "Iteration 6095, loss = 0.00391555\n",
      "Iteration 6096, loss = 0.00391465\n",
      "Iteration 6097, loss = 0.00391360\n",
      "Iteration 6098, loss = 0.00391245\n",
      "Iteration 6099, loss = 0.00391182\n",
      "Iteration 6100, loss = 0.00391066\n",
      "Iteration 6101, loss = 0.00390992\n",
      "Iteration 6102, loss = 0.00390902\n",
      "Iteration 6103, loss = 0.00390816\n",
      "Iteration 6104, loss = 0.00390713\n",
      "Iteration 6105, loss = 0.00390629\n",
      "Iteration 6106, loss = 0.00390546\n",
      "Iteration 6107, loss = 0.00390450\n",
      "Iteration 6108, loss = 0.00390371\n",
      "Iteration 6109, loss = 0.00390273\n",
      "Iteration 6110, loss = 0.00390207\n",
      "Iteration 6111, loss = 0.00390116\n",
      "Iteration 6112, loss = 0.00390017\n",
      "Iteration 6113, loss = 0.00389948\n",
      "Iteration 6114, loss = 0.00389850\n",
      "Iteration 6115, loss = 0.00389767\n",
      "Iteration 6116, loss = 0.00389692\n",
      "Iteration 6117, loss = 0.00389604\n",
      "Iteration 6118, loss = 0.00389511\n",
      "Iteration 6119, loss = 0.00389432\n",
      "Iteration 6120, loss = 0.00389342\n",
      "Iteration 6121, loss = 0.00389318\n",
      "Iteration 6122, loss = 0.00389199\n",
      "Iteration 6123, loss = 0.00389139\n",
      "Iteration 6124, loss = 0.00389039\n",
      "Iteration 6125, loss = 0.00388960\n",
      "Iteration 6126, loss = 0.00388868\n",
      "Iteration 6127, loss = 0.00388781\n",
      "Iteration 6128, loss = 0.00388696\n",
      "Iteration 6129, loss = 0.00388598\n",
      "Iteration 6130, loss = 0.00388559\n",
      "Iteration 6131, loss = 0.00388440\n",
      "Iteration 6132, loss = 0.00388331\n",
      "Iteration 6133, loss = 0.00388230\n",
      "Iteration 6134, loss = 0.00388152\n",
      "Iteration 6135, loss = 0.00388030\n",
      "Iteration 6136, loss = 0.00387956\n",
      "Iteration 6137, loss = 0.00387861\n",
      "Iteration 6138, loss = 0.00387760\n",
      "Iteration 6139, loss = 0.00387683\n",
      "Iteration 6140, loss = 0.00387598\n",
      "Iteration 6141, loss = 0.00387497\n",
      "Iteration 6142, loss = 0.00387401\n",
      "Iteration 6143, loss = 0.00387337\n",
      "Iteration 6144, loss = 0.00387213\n",
      "Iteration 6145, loss = 0.00387142\n",
      "Iteration 6146, loss = 0.00387069\n",
      "Iteration 6147, loss = 0.00386964\n",
      "Iteration 6148, loss = 0.00386873\n",
      "Iteration 6149, loss = 0.00386784\n",
      "Iteration 6150, loss = 0.00386700\n",
      "Iteration 6151, loss = 0.00386618\n",
      "Iteration 6152, loss = 0.00386540\n",
      "Iteration 6153, loss = 0.00386455\n",
      "Iteration 6154, loss = 0.00386372\n",
      "Iteration 6155, loss = 0.00386296\n",
      "Iteration 6156, loss = 0.00386201\n",
      "Iteration 6157, loss = 0.00386114\n",
      "Iteration 6158, loss = 0.00386025\n",
      "Iteration 6159, loss = 0.00385944\n",
      "Iteration 6160, loss = 0.00385857\n",
      "Iteration 6161, loss = 0.00385738\n",
      "Iteration 6162, loss = 0.00385641\n",
      "Iteration 6163, loss = 0.00385542\n",
      "Iteration 6164, loss = 0.00385527\n",
      "Iteration 6165, loss = 0.00385360\n",
      "Iteration 6166, loss = 0.00385275\n",
      "Iteration 6167, loss = 0.00385208\n",
      "Iteration 6168, loss = 0.00385131\n",
      "Iteration 6169, loss = 0.00385036\n",
      "Iteration 6170, loss = 0.00384925\n",
      "Iteration 6171, loss = 0.00384829\n",
      "Iteration 6172, loss = 0.00384764\n",
      "Iteration 6173, loss = 0.00384649\n",
      "Iteration 6174, loss = 0.00384578\n",
      "Iteration 6175, loss = 0.00384462\n",
      "Iteration 6176, loss = 0.00384395\n",
      "Iteration 6177, loss = 0.00384288\n",
      "Iteration 6178, loss = 0.00384198\n",
      "Iteration 6179, loss = 0.00384101\n",
      "Iteration 6180, loss = 0.00384026\n",
      "Iteration 6181, loss = 0.00383939\n",
      "Iteration 6182, loss = 0.00383835\n",
      "Iteration 6183, loss = 0.00383761\n",
      "Iteration 6184, loss = 0.00383667\n",
      "Iteration 6185, loss = 0.00383568\n",
      "Iteration 6186, loss = 0.00383488\n",
      "Iteration 6187, loss = 0.00383411\n",
      "Iteration 6188, loss = 0.00383356\n",
      "Iteration 6189, loss = 0.00383257\n",
      "Iteration 6190, loss = 0.00383182\n",
      "Iteration 6191, loss = 0.00383097\n",
      "Iteration 6192, loss = 0.00383040\n",
      "Iteration 6193, loss = 0.00382954\n",
      "Iteration 6194, loss = 0.00382867\n",
      "Iteration 6195, loss = 0.00382781\n",
      "Iteration 6196, loss = 0.00382712\n",
      "Iteration 6197, loss = 0.00382619\n",
      "Iteration 6198, loss = 0.00382540\n",
      "Iteration 6199, loss = 0.00382464\n",
      "Iteration 6200, loss = 0.00382413\n",
      "Iteration 6201, loss = 0.00382333\n",
      "Iteration 6202, loss = 0.00382246\n",
      "Iteration 6203, loss = 0.00382151\n",
      "Iteration 6204, loss = 0.00382075\n",
      "Iteration 6205, loss = 0.00381998\n",
      "Iteration 6206, loss = 0.00381904\n",
      "Iteration 6207, loss = 0.00381821\n",
      "Iteration 6208, loss = 0.00381754\n",
      "Iteration 6209, loss = 0.00381659\n",
      "Iteration 6210, loss = 0.00381594\n",
      "Iteration 6211, loss = 0.00381507\n",
      "Iteration 6212, loss = 0.00381433\n",
      "Iteration 6213, loss = 0.00381356\n",
      "Iteration 6214, loss = 0.00381290\n",
      "Iteration 6215, loss = 0.00381201\n",
      "Iteration 6216, loss = 0.00381112\n",
      "Iteration 6217, loss = 0.00381023\n",
      "Iteration 6218, loss = 0.00380959\n",
      "Iteration 6219, loss = 0.00380853\n",
      "Iteration 6220, loss = 0.00380800\n",
      "Iteration 6221, loss = 0.00380720\n",
      "Iteration 6222, loss = 0.00380654\n",
      "Iteration 6223, loss = 0.00380534\n",
      "Iteration 6224, loss = 0.00380454\n",
      "Iteration 6225, loss = 0.00380351\n",
      "Iteration 6226, loss = 0.00380232\n",
      "Iteration 6227, loss = 0.00380192\n",
      "Iteration 6228, loss = 0.00380035\n",
      "Iteration 6229, loss = 0.00379995\n",
      "Iteration 6230, loss = 0.00379868\n",
      "Iteration 6231, loss = 0.00379777\n",
      "Iteration 6232, loss = 0.00379675\n",
      "Iteration 6233, loss = 0.00379579\n",
      "Iteration 6234, loss = 0.00379482\n",
      "Iteration 6235, loss = 0.00379388\n",
      "Iteration 6236, loss = 0.00379324\n",
      "Iteration 6237, loss = 0.00379216\n",
      "Iteration 6238, loss = 0.00379121\n",
      "Iteration 6239, loss = 0.00379044\n",
      "Iteration 6240, loss = 0.00378953\n",
      "Iteration 6241, loss = 0.00378875\n",
      "Iteration 6242, loss = 0.00378798\n",
      "Iteration 6243, loss = 0.00378723\n",
      "Iteration 6244, loss = 0.00378647\n",
      "Iteration 6245, loss = 0.00378574\n",
      "Iteration 6246, loss = 0.00378494\n",
      "Iteration 6247, loss = 0.00378419\n",
      "Iteration 6248, loss = 0.00378353\n",
      "Iteration 6249, loss = 0.00378270\n",
      "Iteration 6250, loss = 0.00378182\n",
      "Iteration 6251, loss = 0.00378101\n",
      "Iteration 6252, loss = 0.00378025\n",
      "Iteration 6253, loss = 0.00377924\n",
      "Iteration 6254, loss = 0.00377840\n",
      "Iteration 6255, loss = 0.00377765\n",
      "Iteration 6256, loss = 0.00377664\n",
      "Iteration 6257, loss = 0.00377634\n",
      "Iteration 6258, loss = 0.00377507\n",
      "Iteration 6259, loss = 0.00377415\n",
      "Iteration 6260, loss = 0.00377330\n",
      "Iteration 6261, loss = 0.00377240\n",
      "Iteration 6262, loss = 0.00377147\n",
      "Iteration 6263, loss = 0.00377052\n",
      "Iteration 6264, loss = 0.00376981\n",
      "Iteration 6265, loss = 0.00376877\n",
      "Iteration 6266, loss = 0.00376808\n",
      "Iteration 6267, loss = 0.00376698\n",
      "Iteration 6268, loss = 0.00376612\n",
      "Iteration 6269, loss = 0.00376526\n",
      "Iteration 6270, loss = 0.00376432\n",
      "Iteration 6271, loss = 0.00376353\n",
      "Iteration 6272, loss = 0.00376265\n",
      "Iteration 6273, loss = 0.00376191\n",
      "Iteration 6274, loss = 0.00376084\n",
      "Iteration 6275, loss = 0.00375996\n",
      "Iteration 6276, loss = 0.00375909\n",
      "Iteration 6277, loss = 0.00375804\n",
      "Iteration 6278, loss = 0.00375721\n",
      "Iteration 6279, loss = 0.00375649\n",
      "Iteration 6280, loss = 0.00375548\n",
      "Iteration 6281, loss = 0.00375478\n",
      "Iteration 6282, loss = 0.00375397\n",
      "Iteration 6283, loss = 0.00375316\n",
      "Iteration 6284, loss = 0.00375246\n",
      "Iteration 6285, loss = 0.00375163\n",
      "Iteration 6286, loss = 0.00375086\n",
      "Iteration 6287, loss = 0.00375044\n",
      "Iteration 6288, loss = 0.00374948\n",
      "Iteration 6289, loss = 0.00374868\n",
      "Iteration 6290, loss = 0.00374771\n",
      "Iteration 6291, loss = 0.00374675\n",
      "Iteration 6292, loss = 0.00374596\n",
      "Iteration 6293, loss = 0.00374517\n",
      "Iteration 6294, loss = 0.00374442\n",
      "Iteration 6295, loss = 0.00374340\n",
      "Iteration 6296, loss = 0.00374243\n",
      "Iteration 6297, loss = 0.00374185\n",
      "Iteration 6298, loss = 0.00374065\n",
      "Iteration 6299, loss = 0.00374046\n",
      "Iteration 6300, loss = 0.00373920\n",
      "Iteration 6301, loss = 0.00373821\n",
      "Iteration 6302, loss = 0.00373755\n",
      "Iteration 6303, loss = 0.00373668\n",
      "Iteration 6304, loss = 0.00373555\n",
      "Iteration 6305, loss = 0.00373494\n",
      "Iteration 6306, loss = 0.00373378\n",
      "Iteration 6307, loss = 0.00373327\n",
      "Iteration 6308, loss = 0.00373209\n",
      "Iteration 6309, loss = 0.00373124\n",
      "Iteration 6310, loss = 0.00373059\n",
      "Iteration 6311, loss = 0.00372972\n",
      "Iteration 6312, loss = 0.00372884\n",
      "Iteration 6313, loss = 0.00372848\n",
      "Iteration 6314, loss = 0.00372720\n",
      "Iteration 6315, loss = 0.00372652\n",
      "Iteration 6316, loss = 0.00372551\n",
      "Iteration 6317, loss = 0.00372470\n",
      "Iteration 6318, loss = 0.00372385\n",
      "Iteration 6319, loss = 0.00372327\n",
      "Iteration 6320, loss = 0.00372223\n",
      "Iteration 6321, loss = 0.00372138\n",
      "Iteration 6322, loss = 0.00372049\n",
      "Iteration 6323, loss = 0.00371972\n",
      "Iteration 6324, loss = 0.00371871\n",
      "Iteration 6325, loss = 0.00371826\n",
      "Iteration 6326, loss = 0.00371710\n",
      "Iteration 6327, loss = 0.00371629\n",
      "Iteration 6328, loss = 0.00371544\n",
      "Iteration 6329, loss = 0.00371462\n",
      "Iteration 6330, loss = 0.00371421\n",
      "Iteration 6331, loss = 0.00371304\n",
      "Iteration 6332, loss = 0.00371226\n",
      "Iteration 6333, loss = 0.00371147\n",
      "Iteration 6334, loss = 0.00371068\n",
      "Iteration 6335, loss = 0.00370995\n",
      "Iteration 6336, loss = 0.00370919\n",
      "Iteration 6337, loss = 0.00370839\n",
      "Iteration 6338, loss = 0.00370765\n",
      "Iteration 6339, loss = 0.00370704\n",
      "Iteration 6340, loss = 0.00370608\n",
      "Iteration 6341, loss = 0.00370521\n",
      "Iteration 6342, loss = 0.00370448\n",
      "Iteration 6343, loss = 0.00370381\n",
      "Iteration 6344, loss = 0.00370297\n",
      "Iteration 6345, loss = 0.00370196\n",
      "Iteration 6346, loss = 0.00370131\n",
      "Iteration 6347, loss = 0.00370047\n",
      "Iteration 6348, loss = 0.00369959\n",
      "Iteration 6349, loss = 0.00369895\n",
      "Iteration 6350, loss = 0.00369814\n",
      "Iteration 6351, loss = 0.00369726\n",
      "Iteration 6352, loss = 0.00369657\n",
      "Iteration 6353, loss = 0.00369572\n",
      "Iteration 6354, loss = 0.00369496\n",
      "Iteration 6355, loss = 0.00369425\n",
      "Iteration 6356, loss = 0.00369341\n",
      "Iteration 6357, loss = 0.00369269\n",
      "Iteration 6358, loss = 0.00369176\n",
      "Iteration 6359, loss = 0.00369105\n",
      "Iteration 6360, loss = 0.00369015\n",
      "Iteration 6361, loss = 0.00368941\n",
      "Iteration 6362, loss = 0.00368870\n",
      "Iteration 6363, loss = 0.00368780\n",
      "Iteration 6364, loss = 0.00368698\n",
      "Iteration 6365, loss = 0.00368682\n",
      "Iteration 6366, loss = 0.00368527\n",
      "Iteration 6367, loss = 0.00368458\n",
      "Iteration 6368, loss = 0.00368361\n",
      "Iteration 6369, loss = 0.00368281\n",
      "Iteration 6370, loss = 0.00368239\n",
      "Iteration 6371, loss = 0.00368187\n",
      "Iteration 6372, loss = 0.00368076\n",
      "Iteration 6373, loss = 0.00368001\n",
      "Iteration 6374, loss = 0.00367944\n",
      "Iteration 6375, loss = 0.00367886\n",
      "Iteration 6376, loss = 0.00367790\n",
      "Iteration 6377, loss = 0.00367728\n",
      "Iteration 6378, loss = 0.00367628\n",
      "Iteration 6379, loss = 0.00367540\n",
      "Iteration 6380, loss = 0.00367448\n",
      "Iteration 6381, loss = 0.00367392\n",
      "Iteration 6382, loss = 0.00367289\n",
      "Iteration 6383, loss = 0.00367209\n",
      "Iteration 6384, loss = 0.00367138\n",
      "Iteration 6385, loss = 0.00367063\n",
      "Iteration 6386, loss = 0.00366999\n",
      "Iteration 6387, loss = 0.00366903\n",
      "Iteration 6388, loss = 0.00366818\n",
      "Iteration 6389, loss = 0.00366731\n",
      "Iteration 6390, loss = 0.00366663\n",
      "Iteration 6391, loss = 0.00366583\n",
      "Iteration 6392, loss = 0.00366484\n",
      "Iteration 6393, loss = 0.00366389\n",
      "Iteration 6394, loss = 0.00366297\n",
      "Iteration 6395, loss = 0.00366219\n",
      "Iteration 6396, loss = 0.00366137\n",
      "Iteration 6397, loss = 0.00366048\n",
      "Iteration 6398, loss = 0.00365990\n",
      "Iteration 6399, loss = 0.00365909\n",
      "Iteration 6400, loss = 0.00365838\n",
      "Iteration 6401, loss = 0.00365787\n",
      "Iteration 6402, loss = 0.00365701\n",
      "Iteration 6403, loss = 0.00365608\n",
      "Iteration 6404, loss = 0.00365537\n",
      "Iteration 6405, loss = 0.00365483\n",
      "Iteration 6406, loss = 0.00365410\n",
      "Iteration 6407, loss = 0.00365342\n",
      "Iteration 6408, loss = 0.00365273\n",
      "Iteration 6409, loss = 0.00365214\n",
      "Iteration 6410, loss = 0.00365185\n",
      "Iteration 6411, loss = 0.00365074\n",
      "Iteration 6412, loss = 0.00365000\n",
      "Iteration 6413, loss = 0.00364923\n",
      "Iteration 6414, loss = 0.00364846\n",
      "Iteration 6415, loss = 0.00364778\n",
      "Iteration 6416, loss = 0.00364697\n",
      "Iteration 6417, loss = 0.00364642\n",
      "Iteration 6418, loss = 0.00364530\n",
      "Iteration 6419, loss = 0.00364475\n",
      "Iteration 6420, loss = 0.00364384\n",
      "Iteration 6421, loss = 0.00364274\n",
      "Iteration 6422, loss = 0.00364199\n",
      "Iteration 6423, loss = 0.00364085\n",
      "Iteration 6424, loss = 0.00364018\n",
      "Iteration 6425, loss = 0.00363911\n",
      "Iteration 6426, loss = 0.00363818\n",
      "Iteration 6427, loss = 0.00363736\n",
      "Iteration 6428, loss = 0.00363642\n",
      "Iteration 6429, loss = 0.00363594\n",
      "Iteration 6430, loss = 0.00363496\n",
      "Iteration 6431, loss = 0.00363419\n",
      "Iteration 6432, loss = 0.00363334\n",
      "Iteration 6433, loss = 0.00363243\n",
      "Iteration 6434, loss = 0.00363184\n",
      "Iteration 6435, loss = 0.00363099\n",
      "Iteration 6436, loss = 0.00363045\n",
      "Iteration 6437, loss = 0.00362911\n",
      "Iteration 6438, loss = 0.00362818\n",
      "Iteration 6439, loss = 0.00362715\n",
      "Iteration 6440, loss = 0.00362642\n",
      "Iteration 6441, loss = 0.00362540\n",
      "Iteration 6442, loss = 0.00362447\n",
      "Iteration 6443, loss = 0.00362348\n",
      "Iteration 6444, loss = 0.00362258\n",
      "Iteration 6445, loss = 0.00362155\n",
      "Iteration 6446, loss = 0.00362133\n",
      "Iteration 6447, loss = 0.00361990\n",
      "Iteration 6448, loss = 0.00361894\n",
      "Iteration 6449, loss = 0.00361837\n",
      "Iteration 6450, loss = 0.00361757\n",
      "Iteration 6451, loss = 0.00361650\n",
      "Iteration 6452, loss = 0.00361579\n",
      "Iteration 6453, loss = 0.00361501\n",
      "Iteration 6454, loss = 0.00361428\n",
      "Iteration 6455, loss = 0.00361354\n",
      "Iteration 6456, loss = 0.00361298\n",
      "Iteration 6457, loss = 0.00361217\n",
      "Iteration 6458, loss = 0.00361150\n",
      "Iteration 6459, loss = 0.00361082\n",
      "Iteration 6460, loss = 0.00361003\n",
      "Iteration 6461, loss = 0.00360947\n",
      "Iteration 6462, loss = 0.00360861\n",
      "Iteration 6463, loss = 0.00360795\n",
      "Iteration 6464, loss = 0.00360707\n",
      "Iteration 6465, loss = 0.00360626\n",
      "Iteration 6466, loss = 0.00360550\n",
      "Iteration 6467, loss = 0.00360572\n",
      "Iteration 6468, loss = 0.00360418\n",
      "Iteration 6469, loss = 0.00360347\n",
      "Iteration 6470, loss = 0.00360271\n",
      "Iteration 6471, loss = 0.00360217\n",
      "Iteration 6472, loss = 0.00360112\n",
      "Iteration 6473, loss = 0.00360085\n",
      "Iteration 6474, loss = 0.00359948\n",
      "Iteration 6475, loss = 0.00359886\n",
      "Iteration 6476, loss = 0.00359844\n",
      "Iteration 6477, loss = 0.00359727\n",
      "Iteration 6478, loss = 0.00359653\n",
      "Iteration 6479, loss = 0.00359573\n",
      "Iteration 6480, loss = 0.00359493\n",
      "Iteration 6481, loss = 0.00359406\n",
      "Iteration 6482, loss = 0.00359343\n",
      "Iteration 6483, loss = 0.00359279\n",
      "Iteration 6484, loss = 0.00359228\n",
      "Iteration 6485, loss = 0.00359126\n",
      "Iteration 6486, loss = 0.00359054\n",
      "Iteration 6487, loss = 0.00358970\n",
      "Iteration 6488, loss = 0.00358903\n",
      "Iteration 6489, loss = 0.00358816\n",
      "Iteration 6490, loss = 0.00358729\n",
      "Iteration 6491, loss = 0.00358629\n",
      "Iteration 6492, loss = 0.00358532\n",
      "Iteration 6493, loss = 0.00358446\n",
      "Iteration 6494, loss = 0.00358398\n",
      "Iteration 6495, loss = 0.00358292\n",
      "Iteration 6496, loss = 0.00358206\n",
      "Iteration 6497, loss = 0.00358159\n",
      "Iteration 6498, loss = 0.00358058\n",
      "Iteration 6499, loss = 0.00357977\n",
      "Iteration 6500, loss = 0.00357876\n",
      "Iteration 6501, loss = 0.00357849\n",
      "Iteration 6502, loss = 0.00357732\n",
      "Iteration 6503, loss = 0.00357667\n",
      "Iteration 6504, loss = 0.00357581\n",
      "Iteration 6505, loss = 0.00357513\n",
      "Iteration 6506, loss = 0.00357438\n",
      "Iteration 6507, loss = 0.00357377\n",
      "Iteration 6508, loss = 0.00357306\n",
      "Iteration 6509, loss = 0.00357226\n",
      "Iteration 6510, loss = 0.00357157\n",
      "Iteration 6511, loss = 0.00357086\n",
      "Iteration 6512, loss = 0.00357010\n",
      "Iteration 6513, loss = 0.00356946\n",
      "Iteration 6514, loss = 0.00356865\n",
      "Iteration 6515, loss = 0.00356791\n",
      "Iteration 6516, loss = 0.00356723\n",
      "Iteration 6517, loss = 0.00356684\n",
      "Iteration 6518, loss = 0.00356586\n",
      "Iteration 6519, loss = 0.00356513\n",
      "Iteration 6520, loss = 0.00356430\n",
      "Iteration 6521, loss = 0.00356345\n",
      "Iteration 6522, loss = 0.00356295\n",
      "Iteration 6523, loss = 0.00356218\n",
      "Iteration 6524, loss = 0.00356117\n",
      "Iteration 6525, loss = 0.00356039\n",
      "Iteration 6526, loss = 0.00355970\n",
      "Iteration 6527, loss = 0.00355889\n",
      "Iteration 6528, loss = 0.00355828\n",
      "Iteration 6529, loss = 0.00355739\n",
      "Iteration 6530, loss = 0.00355694\n",
      "Iteration 6531, loss = 0.00355584\n",
      "Iteration 6532, loss = 0.00355499\n",
      "Iteration 6533, loss = 0.00355428\n",
      "Iteration 6534, loss = 0.00355344\n",
      "Iteration 6535, loss = 0.00355267\n",
      "Iteration 6536, loss = 0.00355196\n",
      "Iteration 6537, loss = 0.00355106\n",
      "Iteration 6538, loss = 0.00355034\n",
      "Iteration 6539, loss = 0.00354950\n",
      "Iteration 6540, loss = 0.00354875\n",
      "Iteration 6541, loss = 0.00354810\n",
      "Iteration 6542, loss = 0.00354729\n",
      "Iteration 6543, loss = 0.00354642\n",
      "Iteration 6544, loss = 0.00354567\n",
      "Iteration 6545, loss = 0.00354499\n",
      "Iteration 6546, loss = 0.00354435\n",
      "Iteration 6547, loss = 0.00354345\n",
      "Iteration 6548, loss = 0.00354272\n",
      "Iteration 6549, loss = 0.00354192\n",
      "Iteration 6550, loss = 0.00354119\n",
      "Iteration 6551, loss = 0.00354047\n",
      "Iteration 6552, loss = 0.00353975\n",
      "Iteration 6553, loss = 0.00353892\n",
      "Iteration 6554, loss = 0.00353812\n",
      "Iteration 6555, loss = 0.00353732\n",
      "Iteration 6556, loss = 0.00353660\n",
      "Iteration 6557, loss = 0.00353579\n",
      "Iteration 6558, loss = 0.00353502\n",
      "Iteration 6559, loss = 0.00353444\n",
      "Iteration 6560, loss = 0.00353358\n",
      "Iteration 6561, loss = 0.00353254\n",
      "Iteration 6562, loss = 0.00353192\n",
      "Iteration 6563, loss = 0.00353098\n",
      "Iteration 6564, loss = 0.00353057\n",
      "Iteration 6565, loss = 0.00352949\n",
      "Iteration 6566, loss = 0.00352868\n",
      "Iteration 6567, loss = 0.00352794\n",
      "Iteration 6568, loss = 0.00352721\n",
      "Iteration 6569, loss = 0.00352650\n",
      "Iteration 6570, loss = 0.00352572\n",
      "Iteration 6571, loss = 0.00352503\n",
      "Iteration 6572, loss = 0.00352443\n",
      "Iteration 6573, loss = 0.00352363\n",
      "Iteration 6574, loss = 0.00352292\n",
      "Iteration 6575, loss = 0.00352207\n",
      "Iteration 6576, loss = 0.00352148\n",
      "Iteration 6577, loss = 0.00352070\n",
      "Iteration 6578, loss = 0.00351986\n",
      "Iteration 6579, loss = 0.00351907\n",
      "Iteration 6580, loss = 0.00351835\n",
      "Iteration 6581, loss = 0.00351761\n",
      "Iteration 6582, loss = 0.00351689\n",
      "Iteration 6583, loss = 0.00351629\n",
      "Iteration 6584, loss = 0.00351550\n",
      "Iteration 6585, loss = 0.00351472\n",
      "Iteration 6586, loss = 0.00351384\n",
      "Iteration 6587, loss = 0.00351307\n",
      "Iteration 6588, loss = 0.00351266\n",
      "Iteration 6589, loss = 0.00351178\n",
      "Iteration 6590, loss = 0.00351102\n",
      "Iteration 6591, loss = 0.00351041\n",
      "Iteration 6592, loss = 0.00350960\n",
      "Iteration 6593, loss = 0.00350921\n",
      "Iteration 6594, loss = 0.00350834\n",
      "Iteration 6595, loss = 0.00350755\n",
      "Iteration 6596, loss = 0.00350694\n",
      "Iteration 6597, loss = 0.00350628\n",
      "Iteration 6598, loss = 0.00350563\n",
      "Iteration 6599, loss = 0.00350471\n",
      "Iteration 6600, loss = 0.00350384\n",
      "Iteration 6601, loss = 0.00350306\n",
      "Iteration 6602, loss = 0.00350228\n",
      "Iteration 6603, loss = 0.00350135\n",
      "Iteration 6604, loss = 0.00350058\n",
      "Iteration 6605, loss = 0.00349980\n",
      "Iteration 6606, loss = 0.00349903\n",
      "Iteration 6607, loss = 0.00349842\n",
      "Iteration 6608, loss = 0.00349763\n",
      "Iteration 6609, loss = 0.00349709\n",
      "Iteration 6610, loss = 0.00349625\n",
      "Iteration 6611, loss = 0.00349563\n",
      "Iteration 6612, loss = 0.00349516\n",
      "Iteration 6613, loss = 0.00349430\n",
      "Iteration 6614, loss = 0.00349353\n",
      "Iteration 6615, loss = 0.00349273\n",
      "Iteration 6616, loss = 0.00349194\n",
      "Iteration 6617, loss = 0.00349126\n",
      "Iteration 6618, loss = 0.00349060\n",
      "Iteration 6619, loss = 0.00348998\n",
      "Iteration 6620, loss = 0.00348914\n",
      "Iteration 6621, loss = 0.00348840\n",
      "Iteration 6622, loss = 0.00348767\n",
      "Iteration 6623, loss = 0.00348683\n",
      "Iteration 6624, loss = 0.00348613\n",
      "Iteration 6625, loss = 0.00348536\n",
      "Iteration 6626, loss = 0.00348481\n",
      "Iteration 6627, loss = 0.00348399\n",
      "Iteration 6628, loss = 0.00348299\n",
      "Iteration 6629, loss = 0.00348214\n",
      "Iteration 6630, loss = 0.00348157\n",
      "Iteration 6631, loss = 0.00348108\n",
      "Iteration 6632, loss = 0.00348010\n",
      "Iteration 6633, loss = 0.00347915\n",
      "Iteration 6634, loss = 0.00347833\n",
      "Iteration 6635, loss = 0.00347763\n",
      "Iteration 6636, loss = 0.00347675\n",
      "Iteration 6637, loss = 0.00347617\n",
      "Iteration 6638, loss = 0.00347528\n",
      "Iteration 6639, loss = 0.00347445\n",
      "Iteration 6640, loss = 0.00347370\n",
      "Iteration 6641, loss = 0.00347303\n",
      "Iteration 6642, loss = 0.00347240\n",
      "Iteration 6643, loss = 0.00347155\n",
      "Iteration 6644, loss = 0.00347104\n",
      "Iteration 6645, loss = 0.00347039\n",
      "Iteration 6646, loss = 0.00346957\n",
      "Iteration 6647, loss = 0.00346891\n",
      "Iteration 6648, loss = 0.00346825\n",
      "Iteration 6649, loss = 0.00346749\n",
      "Iteration 6650, loss = 0.00346681\n",
      "Iteration 6651, loss = 0.00346626\n",
      "Iteration 6652, loss = 0.00346544\n",
      "Iteration 6653, loss = 0.00346479\n",
      "Iteration 6654, loss = 0.00346433\n",
      "Iteration 6655, loss = 0.00346341\n",
      "Iteration 6656, loss = 0.00346265\n",
      "Iteration 6657, loss = 0.00346201\n",
      "Iteration 6658, loss = 0.00346136\n",
      "Iteration 6659, loss = 0.00346049\n",
      "Iteration 6660, loss = 0.00345978\n",
      "Iteration 6661, loss = 0.00345906\n",
      "Iteration 6662, loss = 0.00345830\n",
      "Iteration 6663, loss = 0.00345757\n",
      "Iteration 6664, loss = 0.00345681\n",
      "Iteration 6665, loss = 0.00345619\n",
      "Iteration 6666, loss = 0.00345526\n",
      "Iteration 6667, loss = 0.00345470\n",
      "Iteration 6668, loss = 0.00345396\n",
      "Iteration 6669, loss = 0.00345310\n",
      "Iteration 6670, loss = 0.00345237\n",
      "Iteration 6671, loss = 0.00345166\n",
      "Iteration 6672, loss = 0.00345095\n",
      "Iteration 6673, loss = 0.00345017\n",
      "Iteration 6674, loss = 0.00344950\n",
      "Iteration 6675, loss = 0.00344880\n",
      "Iteration 6676, loss = 0.00344799\n",
      "Iteration 6677, loss = 0.00344727\n",
      "Iteration 6678, loss = 0.00344663\n",
      "Iteration 6679, loss = 0.00344578\n",
      "Iteration 6680, loss = 0.00344504\n",
      "Iteration 6681, loss = 0.00344451\n",
      "Iteration 6682, loss = 0.00344358\n",
      "Iteration 6683, loss = 0.00344289\n",
      "Iteration 6684, loss = 0.00344221\n",
      "Iteration 6685, loss = 0.00344147\n",
      "Iteration 6686, loss = 0.00344081\n",
      "Iteration 6687, loss = 0.00344028\n",
      "Iteration 6688, loss = 0.00343945\n",
      "Iteration 6689, loss = 0.00343894\n",
      "Iteration 6690, loss = 0.00343823\n",
      "Iteration 6691, loss = 0.00343752\n",
      "Iteration 6692, loss = 0.00343696\n",
      "Iteration 6693, loss = 0.00343630\n",
      "Iteration 6694, loss = 0.00343571\n",
      "Iteration 6695, loss = 0.00343493\n",
      "Iteration 6696, loss = 0.00343434\n",
      "Iteration 6697, loss = 0.00343376\n",
      "Iteration 6698, loss = 0.00343303\n",
      "Iteration 6699, loss = 0.00343251\n",
      "Iteration 6700, loss = 0.00343159\n",
      "Iteration 6701, loss = 0.00343090\n",
      "Iteration 6702, loss = 0.00343005\n",
      "Iteration 6703, loss = 0.00342939\n",
      "Iteration 6704, loss = 0.00342874\n",
      "Iteration 6705, loss = 0.00342788\n",
      "Iteration 6706, loss = 0.00342720\n",
      "Iteration 6707, loss = 0.00342643\n",
      "Iteration 6708, loss = 0.00342570\n",
      "Iteration 6709, loss = 0.00342499\n",
      "Iteration 6710, loss = 0.00342426\n",
      "Iteration 6711, loss = 0.00342388\n",
      "Iteration 6712, loss = 0.00342275\n",
      "Iteration 6713, loss = 0.00342199\n",
      "Iteration 6714, loss = 0.00342128\n",
      "Iteration 6715, loss = 0.00342055\n",
      "Iteration 6716, loss = 0.00342006\n",
      "Iteration 6717, loss = 0.00341913\n",
      "Iteration 6718, loss = 0.00341859\n",
      "Iteration 6719, loss = 0.00341773\n",
      "Iteration 6720, loss = 0.00341696\n",
      "Iteration 6721, loss = 0.00341620\n",
      "Iteration 6722, loss = 0.00341552\n",
      "Iteration 6723, loss = 0.00341480\n",
      "Iteration 6724, loss = 0.00341396\n",
      "Iteration 6725, loss = 0.00341327\n",
      "Iteration 6726, loss = 0.00341256\n",
      "Iteration 6727, loss = 0.00341200\n",
      "Iteration 6728, loss = 0.00341110\n",
      "Iteration 6729, loss = 0.00341060\n",
      "Iteration 6730, loss = 0.00340976\n",
      "Iteration 6731, loss = 0.00340926\n",
      "Iteration 6732, loss = 0.00340840\n",
      "Iteration 6733, loss = 0.00340754\n",
      "Iteration 6734, loss = 0.00340672\n",
      "Iteration 6735, loss = 0.00340602\n",
      "Iteration 6736, loss = 0.00340519\n",
      "Iteration 6737, loss = 0.00340460\n",
      "Iteration 6738, loss = 0.00340373\n",
      "Iteration 6739, loss = 0.00340296\n",
      "Iteration 6740, loss = 0.00340230\n",
      "Iteration 6741, loss = 0.00340155\n",
      "Iteration 6742, loss = 0.00340085\n",
      "Iteration 6743, loss = 0.00340029\n",
      "Iteration 6744, loss = 0.00339956\n",
      "Iteration 6745, loss = 0.00339873\n",
      "Iteration 6746, loss = 0.00339813\n",
      "Iteration 6747, loss = 0.00339728\n",
      "Iteration 6748, loss = 0.00339664\n",
      "Iteration 6749, loss = 0.00339643\n",
      "Iteration 6750, loss = 0.00339508\n",
      "Iteration 6751, loss = 0.00339420\n",
      "Iteration 6752, loss = 0.00339371\n",
      "Iteration 6753, loss = 0.00339285\n",
      "Iteration 6754, loss = 0.00339204\n",
      "Iteration 6755, loss = 0.00339137\n",
      "Iteration 6756, loss = 0.00339070\n",
      "Iteration 6757, loss = 0.00339003\n",
      "Iteration 6758, loss = 0.00338934\n",
      "Iteration 6759, loss = 0.00338867\n",
      "Iteration 6760, loss = 0.00338800\n",
      "Iteration 6761, loss = 0.00338746\n",
      "Iteration 6762, loss = 0.00338681\n",
      "Iteration 6763, loss = 0.00338632\n",
      "Iteration 6764, loss = 0.00338531\n",
      "Iteration 6765, loss = 0.00338470\n",
      "Iteration 6766, loss = 0.00338396\n",
      "Iteration 6767, loss = 0.00338334\n",
      "Iteration 6768, loss = 0.00338255\n",
      "Iteration 6769, loss = 0.00338205\n",
      "Iteration 6770, loss = 0.00338134\n",
      "Iteration 6771, loss = 0.00338077\n",
      "Iteration 6772, loss = 0.00337997\n",
      "Iteration 6773, loss = 0.00337931\n",
      "Iteration 6774, loss = 0.00337862\n",
      "Iteration 6775, loss = 0.00337809\n",
      "Iteration 6776, loss = 0.00337749\n",
      "Iteration 6777, loss = 0.00337660\n",
      "Iteration 6778, loss = 0.00337605\n",
      "Iteration 6779, loss = 0.00337520\n",
      "Iteration 6780, loss = 0.00337450\n",
      "Iteration 6781, loss = 0.00337391\n",
      "Iteration 6782, loss = 0.00337309\n",
      "Iteration 6783, loss = 0.00337251\n",
      "Iteration 6784, loss = 0.00337175\n",
      "Iteration 6785, loss = 0.00337117\n",
      "Iteration 6786, loss = 0.00337037\n",
      "Iteration 6787, loss = 0.00336953\n",
      "Iteration 6788, loss = 0.00336916\n",
      "Iteration 6789, loss = 0.00336826\n",
      "Iteration 6790, loss = 0.00336774\n",
      "Iteration 6791, loss = 0.00336674\n",
      "Iteration 6792, loss = 0.00336611\n",
      "Iteration 6793, loss = 0.00336555\n",
      "Iteration 6794, loss = 0.00336487\n",
      "Iteration 6795, loss = 0.00336412\n",
      "Iteration 6796, loss = 0.00336345\n",
      "Iteration 6797, loss = 0.00336266\n",
      "Iteration 6798, loss = 0.00336201\n",
      "Iteration 6799, loss = 0.00336122\n",
      "Iteration 6800, loss = 0.00336071\n",
      "Iteration 6801, loss = 0.00335999\n",
      "Iteration 6802, loss = 0.00335936\n",
      "Iteration 6803, loss = 0.00335855\n",
      "Iteration 6804, loss = 0.00335789\n",
      "Iteration 6805, loss = 0.00335731\n",
      "Iteration 6806, loss = 0.00335689\n",
      "Iteration 6807, loss = 0.00335603\n",
      "Iteration 6808, loss = 0.00335550\n",
      "Iteration 6809, loss = 0.00335485\n",
      "Iteration 6810, loss = 0.00335401\n",
      "Iteration 6811, loss = 0.00335331\n",
      "Iteration 6812, loss = 0.00335273\n",
      "Iteration 6813, loss = 0.00335194\n",
      "Iteration 6814, loss = 0.00335116\n",
      "Iteration 6815, loss = 0.00335043\n",
      "Iteration 6816, loss = 0.00334973\n",
      "Iteration 6817, loss = 0.00334910\n",
      "Iteration 6818, loss = 0.00334830\n",
      "Iteration 6819, loss = 0.00334751\n",
      "Iteration 6820, loss = 0.00334680\n",
      "Iteration 6821, loss = 0.00334597\n",
      "Iteration 6822, loss = 0.00334512\n",
      "Iteration 6823, loss = 0.00334443\n",
      "Iteration 6824, loss = 0.00334381\n",
      "Iteration 6825, loss = 0.00334323\n",
      "Iteration 6826, loss = 0.00334243\n",
      "Iteration 6827, loss = 0.00334159\n",
      "Iteration 6828, loss = 0.00334112\n",
      "Iteration 6829, loss = 0.00334021\n",
      "Iteration 6830, loss = 0.00333959\n",
      "Iteration 6831, loss = 0.00333886\n",
      "Iteration 6832, loss = 0.00333816\n",
      "Iteration 6833, loss = 0.00333712\n",
      "Iteration 6834, loss = 0.00333636\n",
      "Iteration 6835, loss = 0.00333542\n",
      "Iteration 6836, loss = 0.00333464\n",
      "Iteration 6837, loss = 0.00333376\n",
      "Iteration 6838, loss = 0.00333290\n",
      "Iteration 6839, loss = 0.00333244\n",
      "Iteration 6840, loss = 0.00333151\n",
      "Iteration 6841, loss = 0.00333091\n",
      "Iteration 6842, loss = 0.00332999\n",
      "Iteration 6843, loss = 0.00332930\n",
      "Iteration 6844, loss = 0.00332858\n",
      "Iteration 6845, loss = 0.00332778\n",
      "Iteration 6846, loss = 0.00332700\n",
      "Iteration 6847, loss = 0.00332598\n",
      "Iteration 6848, loss = 0.00332567\n",
      "Iteration 6849, loss = 0.00332444\n",
      "Iteration 6850, loss = 0.00332370\n",
      "Iteration 6851, loss = 0.00332292\n",
      "Iteration 6852, loss = 0.00332212\n",
      "Iteration 6853, loss = 0.00332144\n",
      "Iteration 6854, loss = 0.00332072\n",
      "Iteration 6855, loss = 0.00331994\n",
      "Iteration 6856, loss = 0.00331924\n",
      "Iteration 6857, loss = 0.00331847\n",
      "Iteration 6858, loss = 0.00331776\n",
      "Iteration 6859, loss = 0.00331709\n",
      "Iteration 6860, loss = 0.00331639\n",
      "Iteration 6861, loss = 0.00331579\n",
      "Iteration 6862, loss = 0.00331525\n",
      "Iteration 6863, loss = 0.00331440\n",
      "Iteration 6864, loss = 0.00331355\n",
      "Iteration 6865, loss = 0.00331286\n",
      "Iteration 6866, loss = 0.00331222\n",
      "Iteration 6867, loss = 0.00331149\n",
      "Iteration 6868, loss = 0.00331087\n",
      "Iteration 6869, loss = 0.00331029\n",
      "Iteration 6870, loss = 0.00330956\n",
      "Iteration 6871, loss = 0.00330892\n",
      "Iteration 6872, loss = 0.00330851\n",
      "Iteration 6873, loss = 0.00330760\n",
      "Iteration 6874, loss = 0.00330694\n",
      "Iteration 6875, loss = 0.00330636\n",
      "Iteration 6876, loss = 0.00330579\n",
      "Iteration 6877, loss = 0.00330514\n",
      "Iteration 6878, loss = 0.00330453\n",
      "Iteration 6879, loss = 0.00330396\n",
      "Iteration 6880, loss = 0.00330346\n",
      "Iteration 6881, loss = 0.00330290\n",
      "Iteration 6882, loss = 0.00330218\n",
      "Iteration 6883, loss = 0.00330166\n",
      "Iteration 6884, loss = 0.00330095\n",
      "Iteration 6885, loss = 0.00330042\n",
      "Iteration 6886, loss = 0.00329983\n",
      "Iteration 6887, loss = 0.00329926\n",
      "Iteration 6888, loss = 0.00329843\n",
      "Iteration 6889, loss = 0.00329779\n",
      "Iteration 6890, loss = 0.00329722\n",
      "Iteration 6891, loss = 0.00329651\n",
      "Iteration 6892, loss = 0.00329572\n",
      "Iteration 6893, loss = 0.00329529\n",
      "Iteration 6894, loss = 0.00329458\n",
      "Iteration 6895, loss = 0.00329388\n",
      "Iteration 6896, loss = 0.00329327\n",
      "Iteration 6897, loss = 0.00329282\n",
      "Iteration 6898, loss = 0.00329190\n",
      "Iteration 6899, loss = 0.00329126\n",
      "Iteration 6900, loss = 0.00329052\n",
      "Iteration 6901, loss = 0.00328992\n",
      "Iteration 6902, loss = 0.00328942\n",
      "Iteration 6903, loss = 0.00328885\n",
      "Iteration 6904, loss = 0.00328795\n",
      "Iteration 6905, loss = 0.00328735\n",
      "Iteration 6906, loss = 0.00328658\n",
      "Iteration 6907, loss = 0.00328608\n",
      "Iteration 6908, loss = 0.00328522\n",
      "Iteration 6909, loss = 0.00328461\n",
      "Iteration 6910, loss = 0.00328415\n",
      "Iteration 6911, loss = 0.00328325\n",
      "Iteration 6912, loss = 0.00328241\n",
      "Iteration 6913, loss = 0.00328183\n",
      "Iteration 6914, loss = 0.00328125\n",
      "Iteration 6915, loss = 0.00328054\n",
      "Iteration 6916, loss = 0.00327969\n",
      "Iteration 6917, loss = 0.00327915\n",
      "Iteration 6918, loss = 0.00327838\n",
      "Iteration 6919, loss = 0.00327760\n",
      "Iteration 6920, loss = 0.00327692\n",
      "Iteration 6921, loss = 0.00327621\n",
      "Iteration 6922, loss = 0.00327547\n",
      "Iteration 6923, loss = 0.00327484\n",
      "Iteration 6924, loss = 0.00327412\n",
      "Iteration 6925, loss = 0.00327374\n",
      "Iteration 6926, loss = 0.00327271\n",
      "Iteration 6927, loss = 0.00327203\n",
      "Iteration 6928, loss = 0.00327153\n",
      "Iteration 6929, loss = 0.00327041\n",
      "Iteration 6930, loss = 0.00326977\n",
      "Iteration 6931, loss = 0.00326896\n",
      "Iteration 6932, loss = 0.00326832\n",
      "Iteration 6933, loss = 0.00326765\n",
      "Iteration 6934, loss = 0.00326700\n",
      "Iteration 6935, loss = 0.00326637\n",
      "Iteration 6936, loss = 0.00326569\n",
      "Iteration 6937, loss = 0.00326507\n",
      "Iteration 6938, loss = 0.00326444\n",
      "Iteration 6939, loss = 0.00326376\n",
      "Iteration 6940, loss = 0.00326303\n",
      "Iteration 6941, loss = 0.00326256\n",
      "Iteration 6942, loss = 0.00326186\n",
      "Iteration 6943, loss = 0.00326140\n",
      "Iteration 6944, loss = 0.00326105\n",
      "Iteration 6945, loss = 0.00326018\n",
      "Iteration 6946, loss = 0.00325972\n",
      "Iteration 6947, loss = 0.00325893\n",
      "Iteration 6948, loss = 0.00325824\n",
      "Iteration 6949, loss = 0.00325756\n",
      "Iteration 6950, loss = 0.00325701\n",
      "Iteration 6951, loss = 0.00325625\n",
      "Iteration 6952, loss = 0.00325571\n",
      "Iteration 6953, loss = 0.00325506\n",
      "Iteration 6954, loss = 0.00325448\n",
      "Iteration 6955, loss = 0.00325376\n",
      "Iteration 6956, loss = 0.00325315\n",
      "Iteration 6957, loss = 0.00325254\n",
      "Iteration 6958, loss = 0.00325192\n",
      "Iteration 6959, loss = 0.00325137\n",
      "Iteration 6960, loss = 0.00325076\n",
      "Iteration 6961, loss = 0.00325015\n",
      "Iteration 6962, loss = 0.00324958\n",
      "Iteration 6963, loss = 0.00324900\n",
      "Iteration 6964, loss = 0.00324839\n",
      "Iteration 6965, loss = 0.00324780\n",
      "Iteration 6966, loss = 0.00324726\n",
      "Iteration 6967, loss = 0.00324654\n",
      "Iteration 6968, loss = 0.00324605\n",
      "Iteration 6969, loss = 0.00324610\n",
      "Iteration 6970, loss = 0.00324506\n",
      "Iteration 6971, loss = 0.00324433\n",
      "Iteration 6972, loss = 0.00324365\n",
      "Iteration 6973, loss = 0.00324291\n",
      "Iteration 6974, loss = 0.00324234\n",
      "Iteration 6975, loss = 0.00324161\n",
      "Iteration 6976, loss = 0.00324094\n",
      "Iteration 6977, loss = 0.00324033\n",
      "Iteration 6978, loss = 0.00323956\n",
      "Iteration 6979, loss = 0.00323887\n",
      "Iteration 6980, loss = 0.00323833\n",
      "Iteration 6981, loss = 0.00323745\n",
      "Iteration 6982, loss = 0.00323679\n",
      "Iteration 6983, loss = 0.00323628\n",
      "Iteration 6984, loss = 0.00323547\n",
      "Iteration 6985, loss = 0.00323476\n",
      "Iteration 6986, loss = 0.00323397\n",
      "Iteration 6987, loss = 0.00323333\n",
      "Iteration 6988, loss = 0.00323250\n",
      "Iteration 6989, loss = 0.00323183\n",
      "Iteration 6990, loss = 0.00323123\n",
      "Iteration 6991, loss = 0.00323035\n",
      "Iteration 6992, loss = 0.00322962\n",
      "Iteration 6993, loss = 0.00322907\n",
      "Iteration 6994, loss = 0.00322819\n",
      "Iteration 6995, loss = 0.00322745\n",
      "Iteration 6996, loss = 0.00322675\n",
      "Iteration 6997, loss = 0.00322610\n",
      "Iteration 6998, loss = 0.00322562\n",
      "Iteration 6999, loss = 0.00322479\n",
      "Iteration 7000, loss = 0.00322424\n",
      "Iteration 7001, loss = 0.00322349\n",
      "Iteration 7002, loss = 0.00322285\n",
      "Iteration 7003, loss = 0.00322222\n",
      "Iteration 7004, loss = 0.00322160\n",
      "Iteration 7005, loss = 0.00322111\n",
      "Iteration 7006, loss = 0.00322018\n",
      "Iteration 7007, loss = 0.00321959\n",
      "Iteration 7008, loss = 0.00321892\n",
      "Iteration 7009, loss = 0.00321839\n",
      "Iteration 7010, loss = 0.00321759\n",
      "Iteration 7011, loss = 0.00321722\n",
      "Iteration 7012, loss = 0.00321635\n",
      "Iteration 7013, loss = 0.00321597\n",
      "Iteration 7014, loss = 0.00321513\n",
      "Iteration 7015, loss = 0.00321450\n",
      "Iteration 7016, loss = 0.00321399\n",
      "Iteration 7017, loss = 0.00321338\n",
      "Iteration 7018, loss = 0.00321279\n",
      "Iteration 7019, loss = 0.00321218\n",
      "Iteration 7020, loss = 0.00321167\n",
      "Iteration 7021, loss = 0.00321114\n",
      "Iteration 7022, loss = 0.00321050\n",
      "Iteration 7023, loss = 0.00320991\n",
      "Iteration 7024, loss = 0.00320945\n",
      "Iteration 7025, loss = 0.00320883\n",
      "Iteration 7026, loss = 0.00320816\n",
      "Iteration 7027, loss = 0.00320769\n",
      "Iteration 7028, loss = 0.00320704\n",
      "Iteration 7029, loss = 0.00320654\n",
      "Iteration 7030, loss = 0.00320580\n",
      "Iteration 7031, loss = 0.00320510\n",
      "Iteration 7032, loss = 0.00320447\n",
      "Iteration 7033, loss = 0.00320410\n",
      "Iteration 7034, loss = 0.00320324\n",
      "Iteration 7035, loss = 0.00320265\n",
      "Iteration 7036, loss = 0.00320202\n",
      "Iteration 7037, loss = 0.00320133\n",
      "Iteration 7038, loss = 0.00320075\n",
      "Iteration 7039, loss = 0.00320021\n",
      "Iteration 7040, loss = 0.00319960\n",
      "Iteration 7041, loss = 0.00319891\n",
      "Iteration 7042, loss = 0.00319845\n",
      "Iteration 7043, loss = 0.00319775\n",
      "Iteration 7044, loss = 0.00319713\n",
      "Iteration 7045, loss = 0.00319653\n",
      "Iteration 7046, loss = 0.00319592\n",
      "Iteration 7047, loss = 0.00319541\n",
      "Iteration 7048, loss = 0.00319504\n",
      "Iteration 7049, loss = 0.00319422\n",
      "Iteration 7050, loss = 0.00319411\n",
      "Iteration 7051, loss = 0.00319304\n",
      "Iteration 7052, loss = 0.00319236\n",
      "Iteration 7053, loss = 0.00319170\n",
      "Iteration 7054, loss = 0.00319113\n",
      "Iteration 7055, loss = 0.00319046\n",
      "Iteration 7056, loss = 0.00318981\n",
      "Iteration 7057, loss = 0.00318898\n",
      "Iteration 7058, loss = 0.00318826\n",
      "Iteration 7059, loss = 0.00318748\n",
      "Iteration 7060, loss = 0.00318685\n",
      "Iteration 7061, loss = 0.00318612\n",
      "Iteration 7062, loss = 0.00318603\n",
      "Iteration 7063, loss = 0.00318479\n",
      "Iteration 7064, loss = 0.00318413\n",
      "Iteration 7065, loss = 0.00318342\n",
      "Iteration 7066, loss = 0.00318278\n",
      "Iteration 7067, loss = 0.00318222\n",
      "Iteration 7068, loss = 0.00318153\n",
      "Iteration 7069, loss = 0.00318092\n",
      "Iteration 7070, loss = 0.00318030\n",
      "Iteration 7071, loss = 0.00318007\n",
      "Iteration 7072, loss = 0.00317916\n",
      "Iteration 7073, loss = 0.00317849\n",
      "Iteration 7074, loss = 0.00317784\n",
      "Iteration 7075, loss = 0.00317726\n",
      "Iteration 7076, loss = 0.00317665\n",
      "Iteration 7077, loss = 0.00317602\n",
      "Iteration 7078, loss = 0.00317539\n",
      "Iteration 7079, loss = 0.00317468\n",
      "Iteration 7080, loss = 0.00317405\n",
      "Iteration 7081, loss = 0.00317342\n",
      "Iteration 7082, loss = 0.00317297\n",
      "Iteration 7083, loss = 0.00317222\n",
      "Iteration 7084, loss = 0.00317164\n",
      "Iteration 7085, loss = 0.00317106\n",
      "Iteration 7086, loss = 0.00317058\n",
      "Iteration 7087, loss = 0.00316997\n",
      "Iteration 7088, loss = 0.00316915\n",
      "Iteration 7089, loss = 0.00316839\n",
      "Iteration 7090, loss = 0.00316788\n",
      "Iteration 7091, loss = 0.00316716\n",
      "Iteration 7092, loss = 0.00316647\n",
      "Iteration 7093, loss = 0.00316591\n",
      "Iteration 7094, loss = 0.00316517\n",
      "Iteration 7095, loss = 0.00316453\n",
      "Iteration 7096, loss = 0.00316384\n",
      "Iteration 7097, loss = 0.00316320\n",
      "Iteration 7098, loss = 0.00316259\n",
      "Iteration 7099, loss = 0.00316189\n",
      "Iteration 7100, loss = 0.00316120\n",
      "Iteration 7101, loss = 0.00316102\n",
      "Iteration 7102, loss = 0.00315993\n",
      "Iteration 7103, loss = 0.00315933\n",
      "Iteration 7104, loss = 0.00315872\n",
      "Iteration 7105, loss = 0.00315810\n",
      "Iteration 7106, loss = 0.00315752\n",
      "Iteration 7107, loss = 0.00315692\n",
      "Iteration 7108, loss = 0.00315640\n",
      "Iteration 7109, loss = 0.00315574\n",
      "Iteration 7110, loss = 0.00315519\n",
      "Iteration 7111, loss = 0.00315459\n",
      "Iteration 7112, loss = 0.00315396\n",
      "Iteration 7113, loss = 0.00315334\n",
      "Iteration 7114, loss = 0.00315277\n",
      "Iteration 7115, loss = 0.00315220\n",
      "Iteration 7116, loss = 0.00315162\n",
      "Iteration 7117, loss = 0.00315100\n",
      "Iteration 7118, loss = 0.00315061\n",
      "Iteration 7119, loss = 0.00314978\n",
      "Iteration 7120, loss = 0.00314932\n",
      "Iteration 7121, loss = 0.00314875\n",
      "Iteration 7122, loss = 0.00314813\n",
      "Iteration 7123, loss = 0.00314739\n",
      "Iteration 7124, loss = 0.00314663\n",
      "Iteration 7125, loss = 0.00314597\n",
      "Iteration 7126, loss = 0.00314531\n",
      "Iteration 7127, loss = 0.00314458\n",
      "Iteration 7128, loss = 0.00314406\n",
      "Iteration 7129, loss = 0.00314336\n",
      "Iteration 7130, loss = 0.00314268\n",
      "Iteration 7131, loss = 0.00314209\n",
      "Iteration 7132, loss = 0.00314156\n",
      "Iteration 7133, loss = 0.00314087\n",
      "Iteration 7134, loss = 0.00314040\n",
      "Iteration 7135, loss = 0.00313968\n",
      "Iteration 7136, loss = 0.00313916\n",
      "Iteration 7137, loss = 0.00313845\n",
      "Iteration 7138, loss = 0.00313786\n",
      "Iteration 7139, loss = 0.00313732\n",
      "Iteration 7140, loss = 0.00313676\n",
      "Iteration 7141, loss = 0.00313625\n",
      "Iteration 7142, loss = 0.00313554\n",
      "Iteration 7143, loss = 0.00313507\n",
      "Iteration 7144, loss = 0.00313459\n",
      "Iteration 7145, loss = 0.00313400\n",
      "Iteration 7146, loss = 0.00313342\n",
      "Iteration 7147, loss = 0.00313309\n",
      "Iteration 7148, loss = 0.00313245\n",
      "Iteration 7149, loss = 0.00313197\n",
      "Iteration 7150, loss = 0.00313159\n",
      "Iteration 7151, loss = 0.00313102\n",
      "Iteration 7152, loss = 0.00313057\n",
      "Iteration 7153, loss = 0.00313023\n",
      "Iteration 7154, loss = 0.00312935\n",
      "Iteration 7155, loss = 0.00312874\n",
      "Iteration 7156, loss = 0.00312821\n",
      "Iteration 7157, loss = 0.00312764\n",
      "Iteration 7158, loss = 0.00312698\n",
      "Iteration 7159, loss = 0.00312639\n",
      "Iteration 7160, loss = 0.00312598\n",
      "Iteration 7161, loss = 0.00312516\n",
      "Iteration 7162, loss = 0.00312452\n",
      "Iteration 7163, loss = 0.00312395\n",
      "Iteration 7164, loss = 0.00312315\n",
      "Iteration 7165, loss = 0.00312261\n",
      "Iteration 7166, loss = 0.00312196\n",
      "Iteration 7167, loss = 0.00312132\n",
      "Iteration 7168, loss = 0.00312081\n",
      "Iteration 7169, loss = 0.00312010\n",
      "Iteration 7170, loss = 0.00311969\n",
      "Iteration 7171, loss = 0.00311896\n",
      "Iteration 7172, loss = 0.00311852\n",
      "Iteration 7173, loss = 0.00311777\n",
      "Iteration 7174, loss = 0.00311716\n",
      "Iteration 7175, loss = 0.00311650\n",
      "Iteration 7176, loss = 0.00311584\n",
      "Iteration 7177, loss = 0.00311518\n",
      "Iteration 7178, loss = 0.00311461\n",
      "Iteration 7179, loss = 0.00311401\n",
      "Iteration 7180, loss = 0.00311317\n",
      "Iteration 7181, loss = 0.00311258\n",
      "Iteration 7182, loss = 0.00311191\n",
      "Iteration 7183, loss = 0.00311158\n",
      "Iteration 7184, loss = 0.00311076\n",
      "Iteration 7185, loss = 0.00311005\n",
      "Iteration 7186, loss = 0.00310957\n",
      "Iteration 7187, loss = 0.00310907\n",
      "Iteration 7188, loss = 0.00310820\n",
      "Iteration 7189, loss = 0.00310764\n",
      "Iteration 7190, loss = 0.00310704\n",
      "Iteration 7191, loss = 0.00310662\n",
      "Iteration 7192, loss = 0.00310567\n",
      "Iteration 7193, loss = 0.00310509\n",
      "Iteration 7194, loss = 0.00310451\n",
      "Iteration 7195, loss = 0.00310388\n",
      "Iteration 7196, loss = 0.00310316\n",
      "Iteration 7197, loss = 0.00310250\n",
      "Iteration 7198, loss = 0.00310169\n",
      "Iteration 7199, loss = 0.00310127\n",
      "Iteration 7200, loss = 0.00310047\n",
      "Iteration 7201, loss = 0.00309970\n",
      "Iteration 7202, loss = 0.00309915\n",
      "Iteration 7203, loss = 0.00309848\n",
      "Iteration 7204, loss = 0.00309763\n",
      "Iteration 7205, loss = 0.00309700\n",
      "Iteration 7206, loss = 0.00309624\n",
      "Iteration 7207, loss = 0.00309565\n",
      "Iteration 7208, loss = 0.00309496\n",
      "Iteration 7209, loss = 0.00309444\n",
      "Iteration 7210, loss = 0.00309378\n",
      "Iteration 7211, loss = 0.00309307\n",
      "Iteration 7212, loss = 0.00309267\n",
      "Iteration 7213, loss = 0.00309185\n",
      "Iteration 7214, loss = 0.00309121\n",
      "Iteration 7215, loss = 0.00309071\n",
      "Iteration 7216, loss = 0.00309015\n",
      "Iteration 7217, loss = 0.00308959\n",
      "Iteration 7218, loss = 0.00308897\n",
      "Iteration 7219, loss = 0.00308837\n",
      "Iteration 7220, loss = 0.00308786\n",
      "Iteration 7221, loss = 0.00308727\n",
      "Iteration 7222, loss = 0.00308673\n",
      "Iteration 7223, loss = 0.00308609\n",
      "Iteration 7224, loss = 0.00308555\n",
      "Iteration 7225, loss = 0.00308510\n",
      "Iteration 7226, loss = 0.00308462\n",
      "Iteration 7227, loss = 0.00308401\n",
      "Iteration 7228, loss = 0.00308342\n",
      "Iteration 7229, loss = 0.00308288\n",
      "Iteration 7230, loss = 0.00308236\n",
      "Iteration 7231, loss = 0.00308183\n",
      "Iteration 7232, loss = 0.00308131\n",
      "Iteration 7233, loss = 0.00308076\n",
      "Iteration 7234, loss = 0.00308016\n",
      "Iteration 7235, loss = 0.00307953\n",
      "Iteration 7236, loss = 0.00307889\n",
      "Iteration 7237, loss = 0.00307839\n",
      "Iteration 7238, loss = 0.00307795\n",
      "Iteration 7239, loss = 0.00307724\n",
      "Iteration 7240, loss = 0.00307660\n",
      "Iteration 7241, loss = 0.00307620\n",
      "Iteration 7242, loss = 0.00307548\n",
      "Iteration 7243, loss = 0.00307494\n",
      "Iteration 7244, loss = 0.00307456\n",
      "Iteration 7245, loss = 0.00307379\n",
      "Iteration 7246, loss = 0.00307311\n",
      "Iteration 7247, loss = 0.00307271\n",
      "Iteration 7248, loss = 0.00307206\n",
      "Iteration 7249, loss = 0.00307162\n",
      "Iteration 7250, loss = 0.00307084\n",
      "Iteration 7251, loss = 0.00307028\n",
      "Iteration 7252, loss = 0.00306974\n",
      "Iteration 7253, loss = 0.00306917\n",
      "Iteration 7254, loss = 0.00306853\n",
      "Iteration 7255, loss = 0.00306794\n",
      "Iteration 7256, loss = 0.00306731\n",
      "Iteration 7257, loss = 0.00306682\n",
      "Iteration 7258, loss = 0.00306652\n",
      "Iteration 7259, loss = 0.00306577\n",
      "Iteration 7260, loss = 0.00306528\n",
      "Iteration 7261, loss = 0.00306455\n",
      "Iteration 7262, loss = 0.00306419\n",
      "Iteration 7263, loss = 0.00306350\n",
      "Iteration 7264, loss = 0.00306274\n",
      "Iteration 7265, loss = 0.00306227\n",
      "Iteration 7266, loss = 0.00306152\n",
      "Iteration 7267, loss = 0.00306090\n",
      "Iteration 7268, loss = 0.00306041\n",
      "Iteration 7269, loss = 0.00305981\n",
      "Iteration 7270, loss = 0.00305916\n",
      "Iteration 7271, loss = 0.00305868\n",
      "Iteration 7272, loss = 0.00305811\n",
      "Iteration 7273, loss = 0.00305753\n",
      "Iteration 7274, loss = 0.00305702\n",
      "Iteration 7275, loss = 0.00305634\n",
      "Iteration 7276, loss = 0.00305582\n",
      "Iteration 7277, loss = 0.00305544\n",
      "Iteration 7278, loss = 0.00305467\n",
      "Iteration 7279, loss = 0.00305416\n",
      "Iteration 7280, loss = 0.00305359\n",
      "Iteration 7281, loss = 0.00305291\n",
      "Iteration 7282, loss = 0.00305225\n",
      "Iteration 7283, loss = 0.00305178\n",
      "Iteration 7284, loss = 0.00305110\n",
      "Iteration 7285, loss = 0.00305050\n",
      "Iteration 7286, loss = 0.00304987\n",
      "Iteration 7287, loss = 0.00304928\n",
      "Iteration 7288, loss = 0.00304866\n",
      "Iteration 7289, loss = 0.00304840\n",
      "Iteration 7290, loss = 0.00304755\n",
      "Iteration 7291, loss = 0.00304720\n",
      "Iteration 7292, loss = 0.00304652\n",
      "Iteration 7293, loss = 0.00304573\n",
      "Iteration 7294, loss = 0.00304504\n",
      "Iteration 7295, loss = 0.00304449\n",
      "Iteration 7296, loss = 0.00304376\n",
      "Iteration 7297, loss = 0.00304318\n",
      "Iteration 7298, loss = 0.00304249\n",
      "Iteration 7299, loss = 0.00304184\n",
      "Iteration 7300, loss = 0.00304142\n",
      "Iteration 7301, loss = 0.00304071\n",
      "Iteration 7302, loss = 0.00304017\n",
      "Iteration 7303, loss = 0.00303954\n",
      "Iteration 7304, loss = 0.00303925\n",
      "Iteration 7305, loss = 0.00303842\n",
      "Iteration 7306, loss = 0.00303782\n",
      "Iteration 7307, loss = 0.00303726\n",
      "Iteration 7308, loss = 0.00303660\n",
      "Iteration 7309, loss = 0.00303633\n",
      "Iteration 7310, loss = 0.00303546\n",
      "Iteration 7311, loss = 0.00303489\n",
      "Iteration 7312, loss = 0.00303421\n",
      "Iteration 7313, loss = 0.00303353\n",
      "Iteration 7314, loss = 0.00303298\n",
      "Iteration 7315, loss = 0.00303224\n",
      "Iteration 7316, loss = 0.00303165\n",
      "Iteration 7317, loss = 0.00303124\n",
      "Iteration 7318, loss = 0.00303024\n",
      "Iteration 7319, loss = 0.00302956\n",
      "Iteration 7320, loss = 0.00302874\n",
      "Iteration 7321, loss = 0.00302816\n",
      "Iteration 7322, loss = 0.00302764\n",
      "Iteration 7323, loss = 0.00302711\n",
      "Iteration 7324, loss = 0.00302650\n",
      "Iteration 7325, loss = 0.00302589\n",
      "Iteration 7326, loss = 0.00302560\n",
      "Iteration 7327, loss = 0.00302480\n",
      "Iteration 7328, loss = 0.00302426\n",
      "Iteration 7329, loss = 0.00302352\n",
      "Iteration 7330, loss = 0.00302291\n",
      "Iteration 7331, loss = 0.00302228\n",
      "Iteration 7332, loss = 0.00302160\n",
      "Iteration 7333, loss = 0.00302100\n",
      "Iteration 7334, loss = 0.00302023\n",
      "Iteration 7335, loss = 0.00301973\n",
      "Iteration 7336, loss = 0.00301922\n",
      "Iteration 7337, loss = 0.00301850\n",
      "Iteration 7338, loss = 0.00301785\n",
      "Iteration 7339, loss = 0.00301740\n",
      "Iteration 7340, loss = 0.00301675\n",
      "Iteration 7341, loss = 0.00301621\n",
      "Iteration 7342, loss = 0.00301546\n",
      "Iteration 7343, loss = 0.00301508\n",
      "Iteration 7344, loss = 0.00301433\n",
      "Iteration 7345, loss = 0.00301401\n",
      "Iteration 7346, loss = 0.00301350\n",
      "Iteration 7347, loss = 0.00301278\n",
      "Iteration 7348, loss = 0.00301223\n",
      "Iteration 7349, loss = 0.00301171\n",
      "Iteration 7350, loss = 0.00301122\n",
      "Iteration 7351, loss = 0.00301081\n",
      "Iteration 7352, loss = 0.00301027\n",
      "Iteration 7353, loss = 0.00300978\n",
      "Iteration 7354, loss = 0.00300925\n",
      "Iteration 7355, loss = 0.00300877\n",
      "Iteration 7356, loss = 0.00300817\n",
      "Iteration 7357, loss = 0.00300765\n",
      "Iteration 7358, loss = 0.00300719\n",
      "Iteration 7359, loss = 0.00300655\n",
      "Iteration 7360, loss = 0.00300601\n",
      "Iteration 7361, loss = 0.00300549\n",
      "Iteration 7362, loss = 0.00300497\n",
      "Iteration 7363, loss = 0.00300451\n",
      "Iteration 7364, loss = 0.00300378\n",
      "Iteration 7365, loss = 0.00300322\n",
      "Iteration 7366, loss = 0.00300265\n",
      "Iteration 7367, loss = 0.00300200\n",
      "Iteration 7368, loss = 0.00300134\n",
      "Iteration 7369, loss = 0.00300104\n",
      "Iteration 7370, loss = 0.00300042\n",
      "Iteration 7371, loss = 0.00299988\n",
      "Iteration 7372, loss = 0.00299910\n",
      "Iteration 7373, loss = 0.00299870\n",
      "Iteration 7374, loss = 0.00299795\n",
      "Iteration 7375, loss = 0.00299735\n",
      "Iteration 7376, loss = 0.00299678\n",
      "Iteration 7377, loss = 0.00299617\n",
      "Iteration 7378, loss = 0.00299557\n",
      "Iteration 7379, loss = 0.00299519\n",
      "Iteration 7380, loss = 0.00299444\n",
      "Iteration 7381, loss = 0.00299372\n",
      "Iteration 7382, loss = 0.00299338\n",
      "Iteration 7383, loss = 0.00299263\n",
      "Iteration 7384, loss = 0.00299211\n",
      "Iteration 7385, loss = 0.00299144\n",
      "Iteration 7386, loss = 0.00299085\n",
      "Iteration 7387, loss = 0.00299031\n",
      "Iteration 7388, loss = 0.00298965\n",
      "Iteration 7389, loss = 0.00298909\n",
      "Iteration 7390, loss = 0.00298864\n",
      "Iteration 7391, loss = 0.00298800\n",
      "Iteration 7392, loss = 0.00298758\n",
      "Iteration 7393, loss = 0.00298695\n",
      "Iteration 7394, loss = 0.00298639\n",
      "Iteration 7395, loss = 0.00298587\n",
      "Iteration 7396, loss = 0.00298529\n",
      "Iteration 7397, loss = 0.00298481\n",
      "Iteration 7398, loss = 0.00298431\n",
      "Iteration 7399, loss = 0.00298400\n",
      "Iteration 7400, loss = 0.00298312\n",
      "Iteration 7401, loss = 0.00298260\n",
      "Iteration 7402, loss = 0.00298219\n",
      "Iteration 7403, loss = 0.00298151\n",
      "Iteration 7404, loss = 0.00298105\n",
      "Iteration 7405, loss = 0.00298047\n",
      "Iteration 7406, loss = 0.00297998\n",
      "Iteration 7407, loss = 0.00297951\n",
      "Iteration 7408, loss = 0.00297906\n",
      "Iteration 7409, loss = 0.00297837\n",
      "Iteration 7410, loss = 0.00297769\n",
      "Iteration 7411, loss = 0.00297735\n",
      "Iteration 7412, loss = 0.00297646\n",
      "Iteration 7413, loss = 0.00297594\n",
      "Iteration 7414, loss = 0.00297532\n",
      "Iteration 7415, loss = 0.00297452\n",
      "Iteration 7416, loss = 0.00297389\n",
      "Iteration 7417, loss = 0.00297326\n",
      "Iteration 7418, loss = 0.00297257\n",
      "Iteration 7419, loss = 0.00297180\n",
      "Iteration 7420, loss = 0.00297124\n",
      "Iteration 7421, loss = 0.00297072\n",
      "Iteration 7422, loss = 0.00297026\n",
      "Iteration 7423, loss = 0.00296942\n",
      "Iteration 7424, loss = 0.00296895\n",
      "Iteration 7425, loss = 0.00296824\n",
      "Iteration 7426, loss = 0.00296761\n",
      "Iteration 7427, loss = 0.00296700\n",
      "Iteration 7428, loss = 0.00296661\n",
      "Iteration 7429, loss = 0.00296593\n",
      "Iteration 7430, loss = 0.00296543\n",
      "Iteration 7431, loss = 0.00296467\n",
      "Iteration 7432, loss = 0.00296404\n",
      "Iteration 7433, loss = 0.00296340\n",
      "Iteration 7434, loss = 0.00296282\n",
      "Iteration 7435, loss = 0.00296236\n",
      "Iteration 7436, loss = 0.00296172\n",
      "Iteration 7437, loss = 0.00296137\n",
      "Iteration 7438, loss = 0.00296083\n",
      "Iteration 7439, loss = 0.00296027\n",
      "Iteration 7440, loss = 0.00295968\n",
      "Iteration 7441, loss = 0.00295912\n",
      "Iteration 7442, loss = 0.00295865\n",
      "Iteration 7443, loss = 0.00295806\n",
      "Iteration 7444, loss = 0.00295750\n",
      "Iteration 7445, loss = 0.00295704\n",
      "Iteration 7446, loss = 0.00295640\n",
      "Iteration 7447, loss = 0.00295589\n",
      "Iteration 7448, loss = 0.00295546\n",
      "Iteration 7449, loss = 0.00295491\n",
      "Iteration 7450, loss = 0.00295442\n",
      "Iteration 7451, loss = 0.00295394\n",
      "Iteration 7452, loss = 0.00295350\n",
      "Iteration 7453, loss = 0.00295295\n",
      "Iteration 7454, loss = 0.00295265\n",
      "Iteration 7455, loss = 0.00295212\n",
      "Iteration 7456, loss = 0.00295171\n",
      "Iteration 7457, loss = 0.00295107\n",
      "Iteration 7458, loss = 0.00295068\n",
      "Iteration 7459, loss = 0.00295027\n",
      "Iteration 7460, loss = 0.00294959\n",
      "Iteration 7461, loss = 0.00294934\n",
      "Iteration 7462, loss = 0.00294880\n",
      "Iteration 7463, loss = 0.00294800\n",
      "Iteration 7464, loss = 0.00294742\n",
      "Iteration 7465, loss = 0.00294687\n",
      "Iteration 7466, loss = 0.00294638\n",
      "Iteration 7467, loss = 0.00294586\n",
      "Iteration 7468, loss = 0.00294539\n",
      "Iteration 7469, loss = 0.00294469\n",
      "Iteration 7470, loss = 0.00294415\n",
      "Iteration 7471, loss = 0.00294368\n",
      "Iteration 7472, loss = 0.00294302\n",
      "Iteration 7473, loss = 0.00294249\n",
      "Iteration 7474, loss = 0.00294205\n",
      "Iteration 7475, loss = 0.00294156\n",
      "Iteration 7476, loss = 0.00294103\n",
      "Iteration 7477, loss = 0.00294051\n",
      "Iteration 7478, loss = 0.00294010\n",
      "Iteration 7479, loss = 0.00293954\n",
      "Iteration 7480, loss = 0.00293896\n",
      "Iteration 7481, loss = 0.00293841\n",
      "Iteration 7482, loss = 0.00293782\n",
      "Iteration 7483, loss = 0.00293750\n",
      "Iteration 7484, loss = 0.00293681\n",
      "Iteration 7485, loss = 0.00293625\n",
      "Iteration 7486, loss = 0.00293586\n",
      "Iteration 7487, loss = 0.00293517\n",
      "Iteration 7488, loss = 0.00293466\n",
      "Iteration 7489, loss = 0.00293410\n",
      "Iteration 7490, loss = 0.00293363\n",
      "Iteration 7491, loss = 0.00293312\n",
      "Iteration 7492, loss = 0.00293262\n",
      "Iteration 7493, loss = 0.00293208\n",
      "Iteration 7494, loss = 0.00293156\n",
      "Iteration 7495, loss = 0.00293109\n",
      "Iteration 7496, loss = 0.00293055\n",
      "Iteration 7497, loss = 0.00293017\n",
      "Iteration 7498, loss = 0.00292962\n",
      "Iteration 7499, loss = 0.00292922\n",
      "Iteration 7500, loss = 0.00292867\n",
      "Iteration 7501, loss = 0.00292795\n",
      "Iteration 7502, loss = 0.00292763\n",
      "Iteration 7503, loss = 0.00292691\n",
      "Iteration 7504, loss = 0.00292630\n",
      "Iteration 7505, loss = 0.00292573\n",
      "Iteration 7506, loss = 0.00292524\n",
      "Iteration 7507, loss = 0.00292466\n",
      "Iteration 7508, loss = 0.00292416\n",
      "Iteration 7509, loss = 0.00292352\n",
      "Iteration 7510, loss = 0.00292296\n",
      "Iteration 7511, loss = 0.00292243\n",
      "Iteration 7512, loss = 0.00292175\n",
      "Iteration 7513, loss = 0.00292126\n",
      "Iteration 7514, loss = 0.00292063\n",
      "Iteration 7515, loss = 0.00292016\n",
      "Iteration 7516, loss = 0.00291958\n",
      "Iteration 7517, loss = 0.00291915\n",
      "Iteration 7518, loss = 0.00291842\n",
      "Iteration 7519, loss = 0.00291794\n",
      "Iteration 7520, loss = 0.00291739\n",
      "Iteration 7521, loss = 0.00291681\n",
      "Iteration 7522, loss = 0.00291624\n",
      "Iteration 7523, loss = 0.00291594\n",
      "Iteration 7524, loss = 0.00291525\n",
      "Iteration 7525, loss = 0.00291471\n",
      "Iteration 7526, loss = 0.00291421\n",
      "Iteration 7527, loss = 0.00291371\n",
      "Iteration 7528, loss = 0.00291314\n",
      "Iteration 7529, loss = 0.00291273\n",
      "Iteration 7530, loss = 0.00291212\n",
      "Iteration 7531, loss = 0.00291169\n",
      "Iteration 7532, loss = 0.00291124\n",
      "Iteration 7533, loss = 0.00291063\n",
      "Iteration 7534, loss = 0.00291016\n",
      "Iteration 7535, loss = 0.00290974\n",
      "Iteration 7536, loss = 0.00290902\n",
      "Iteration 7537, loss = 0.00290837\n",
      "Iteration 7538, loss = 0.00290781\n",
      "Iteration 7539, loss = 0.00290732\n",
      "Iteration 7540, loss = 0.00290663\n",
      "Iteration 7541, loss = 0.00290606\n",
      "Iteration 7542, loss = 0.00290550\n",
      "Iteration 7543, loss = 0.00290502\n",
      "Iteration 7544, loss = 0.00290448\n",
      "Iteration 7545, loss = 0.00290399\n",
      "Iteration 7546, loss = 0.00290365\n",
      "Iteration 7547, loss = 0.00290309\n",
      "Iteration 7548, loss = 0.00290268\n",
      "Iteration 7549, loss = 0.00290199\n",
      "Iteration 7550, loss = 0.00290147\n",
      "Iteration 7551, loss = 0.00290094\n",
      "Iteration 7552, loss = 0.00290048\n",
      "Iteration 7553, loss = 0.00289995\n",
      "Iteration 7554, loss = 0.00289953\n",
      "Iteration 7555, loss = 0.00289906\n",
      "Iteration 7556, loss = 0.00289850\n",
      "Iteration 7557, loss = 0.00289796\n",
      "Iteration 7558, loss = 0.00289742\n",
      "Iteration 7559, loss = 0.00289693\n",
      "Iteration 7560, loss = 0.00289633\n",
      "Iteration 7561, loss = 0.00289598\n",
      "Iteration 7562, loss = 0.00289542\n",
      "Iteration 7563, loss = 0.00289486\n",
      "Iteration 7564, loss = 0.00289440\n",
      "Iteration 7565, loss = 0.00289388\n",
      "Iteration 7566, loss = 0.00289340\n",
      "Iteration 7567, loss = 0.00289302\n",
      "Iteration 7568, loss = 0.00289253\n",
      "Iteration 7569, loss = 0.00289190\n",
      "Iteration 7570, loss = 0.00289138\n",
      "Iteration 7571, loss = 0.00289087\n",
      "Iteration 7572, loss = 0.00289043\n",
      "Iteration 7573, loss = 0.00288999\n",
      "Iteration 7574, loss = 0.00288937\n",
      "Iteration 7575, loss = 0.00288894\n",
      "Iteration 7576, loss = 0.00288844\n",
      "Iteration 7577, loss = 0.00288805\n",
      "Iteration 7578, loss = 0.00288746\n",
      "Iteration 7579, loss = 0.00288703\n",
      "Iteration 7580, loss = 0.00288637\n",
      "Iteration 7581, loss = 0.00288584\n",
      "Iteration 7582, loss = 0.00288559\n",
      "Iteration 7583, loss = 0.00288489\n",
      "Iteration 7584, loss = 0.00288435\n",
      "Iteration 7585, loss = 0.00288382\n",
      "Iteration 7586, loss = 0.00288325\n",
      "Iteration 7587, loss = 0.00288274\n",
      "Iteration 7588, loss = 0.00288221\n",
      "Iteration 7589, loss = 0.00288165\n",
      "Iteration 7590, loss = 0.00288108\n",
      "Iteration 7591, loss = 0.00288064\n",
      "Iteration 7592, loss = 0.00287992\n",
      "Iteration 7593, loss = 0.00287937\n",
      "Iteration 7594, loss = 0.00287871\n",
      "Iteration 7595, loss = 0.00287827\n",
      "Iteration 7596, loss = 0.00287767\n",
      "Iteration 7597, loss = 0.00287712\n",
      "Iteration 7598, loss = 0.00287658\n",
      "Iteration 7599, loss = 0.00287604\n",
      "Iteration 7600, loss = 0.00287554\n",
      "Iteration 7601, loss = 0.00287502\n",
      "Iteration 7602, loss = 0.00287453\n",
      "Iteration 7603, loss = 0.00287418\n",
      "Iteration 7604, loss = 0.00287355\n",
      "Iteration 7605, loss = 0.00287334\n",
      "Iteration 7606, loss = 0.00287259\n",
      "Iteration 7607, loss = 0.00287213\n",
      "Iteration 7608, loss = 0.00287160\n",
      "Iteration 7609, loss = 0.00287116\n",
      "Iteration 7610, loss = 0.00287057\n",
      "Iteration 7611, loss = 0.00287009\n",
      "Iteration 7612, loss = 0.00286947\n",
      "Iteration 7613, loss = 0.00286910\n",
      "Iteration 7614, loss = 0.00286842\n",
      "Iteration 7615, loss = 0.00286796\n",
      "Iteration 7616, loss = 0.00286740\n",
      "Iteration 7617, loss = 0.00286688\n",
      "Iteration 7618, loss = 0.00286636\n",
      "Iteration 7619, loss = 0.00286589\n",
      "Iteration 7620, loss = 0.00286542\n",
      "Iteration 7621, loss = 0.00286498\n",
      "Iteration 7622, loss = 0.00286475\n",
      "Iteration 7623, loss = 0.00286410\n",
      "Iteration 7624, loss = 0.00286359\n",
      "Iteration 7625, loss = 0.00286332\n",
      "Iteration 7626, loss = 0.00286274\n",
      "Iteration 7627, loss = 0.00286244\n",
      "Iteration 7628, loss = 0.00286172\n",
      "Iteration 7629, loss = 0.00286127\n",
      "Iteration 7630, loss = 0.00286074\n",
      "Iteration 7631, loss = 0.00286019\n",
      "Iteration 7632, loss = 0.00285977\n",
      "Iteration 7633, loss = 0.00285906\n",
      "Iteration 7634, loss = 0.00285851\n",
      "Iteration 7635, loss = 0.00285793\n",
      "Iteration 7636, loss = 0.00285740\n",
      "Iteration 7637, loss = 0.00285688\n",
      "Iteration 7638, loss = 0.00285637\n",
      "Iteration 7639, loss = 0.00285568\n",
      "Iteration 7640, loss = 0.00285514\n",
      "Iteration 7641, loss = 0.00285453\n",
      "Iteration 7642, loss = 0.00285412\n",
      "Iteration 7643, loss = 0.00285338\n",
      "Iteration 7644, loss = 0.00285277\n",
      "Iteration 7645, loss = 0.00285229\n",
      "Iteration 7646, loss = 0.00285163\n",
      "Iteration 7647, loss = 0.00285111\n",
      "Iteration 7648, loss = 0.00285055\n",
      "Iteration 7649, loss = 0.00285004\n",
      "Iteration 7650, loss = 0.00284948\n",
      "Iteration 7651, loss = 0.00284897\n",
      "Iteration 7652, loss = 0.00284834\n",
      "Iteration 7653, loss = 0.00284777\n",
      "Iteration 7654, loss = 0.00284735\n",
      "Iteration 7655, loss = 0.00284694\n",
      "Iteration 7656, loss = 0.00284620\n",
      "Iteration 7657, loss = 0.00284562\n",
      "Iteration 7658, loss = 0.00284527\n",
      "Iteration 7659, loss = 0.00284457\n",
      "Iteration 7660, loss = 0.00284423\n",
      "Iteration 7661, loss = 0.00284370\n",
      "Iteration 7662, loss = 0.00284310\n",
      "Iteration 7663, loss = 0.00284263\n",
      "Iteration 7664, loss = 0.00284214\n",
      "Iteration 7665, loss = 0.00284216\n",
      "Iteration 7666, loss = 0.00284127\n",
      "Iteration 7667, loss = 0.00284075\n",
      "Iteration 7668, loss = 0.00284016\n",
      "Iteration 7669, loss = 0.00283961\n",
      "Iteration 7670, loss = 0.00283906\n",
      "Iteration 7671, loss = 0.00283854\n",
      "Iteration 7672, loss = 0.00283793\n",
      "Iteration 7673, loss = 0.00283756\n",
      "Iteration 7674, loss = 0.00283691\n",
      "Iteration 7675, loss = 0.00283632\n",
      "Iteration 7676, loss = 0.00283582\n",
      "Iteration 7677, loss = 0.00283537\n",
      "Iteration 7678, loss = 0.00283487\n",
      "Iteration 7679, loss = 0.00283440\n",
      "Iteration 7680, loss = 0.00283417\n",
      "Iteration 7681, loss = 0.00283345\n",
      "Iteration 7682, loss = 0.00283287\n",
      "Iteration 7683, loss = 0.00283240\n",
      "Iteration 7684, loss = 0.00283186\n",
      "Iteration 7685, loss = 0.00283144\n",
      "Iteration 7686, loss = 0.00283091\n",
      "Iteration 7687, loss = 0.00283040\n",
      "Iteration 7688, loss = 0.00282994\n",
      "Iteration 7689, loss = 0.00282938\n",
      "Iteration 7690, loss = 0.00282894\n",
      "Iteration 7691, loss = 0.00282869\n",
      "Iteration 7692, loss = 0.00282806\n",
      "Iteration 7693, loss = 0.00282753\n",
      "Iteration 7694, loss = 0.00282711\n",
      "Iteration 7695, loss = 0.00282663\n",
      "Iteration 7696, loss = 0.00282621\n",
      "Iteration 7697, loss = 0.00282574\n",
      "Iteration 7698, loss = 0.00282538\n",
      "Iteration 7699, loss = 0.00282492\n",
      "Iteration 7700, loss = 0.00282455\n",
      "Iteration 7701, loss = 0.00282424\n",
      "Iteration 7702, loss = 0.00282392\n",
      "Iteration 7703, loss = 0.00282336\n",
      "Iteration 7704, loss = 0.00282276\n",
      "Iteration 7705, loss = 0.00282232\n",
      "Iteration 7706, loss = 0.00282188\n",
      "Iteration 7707, loss = 0.00282137\n",
      "Iteration 7708, loss = 0.00282120\n",
      "Iteration 7709, loss = 0.00282058\n",
      "Iteration 7710, loss = 0.00282004\n",
      "Iteration 7711, loss = 0.00281950\n",
      "Iteration 7712, loss = 0.00281898\n",
      "Iteration 7713, loss = 0.00281852\n",
      "Iteration 7714, loss = 0.00281788\n",
      "Iteration 7715, loss = 0.00281740\n",
      "Iteration 7716, loss = 0.00281700\n",
      "Iteration 7717, loss = 0.00281641\n",
      "Iteration 7718, loss = 0.00281594\n",
      "Iteration 7719, loss = 0.00281541\n",
      "Iteration 7720, loss = 0.00281506\n",
      "Iteration 7721, loss = 0.00281525\n",
      "Iteration 7722, loss = 0.00281405\n",
      "Iteration 7723, loss = 0.00281358\n",
      "Iteration 7724, loss = 0.00281299\n",
      "Iteration 7725, loss = 0.00281249\n",
      "Iteration 7726, loss = 0.00281191\n",
      "Iteration 7727, loss = 0.00281130\n",
      "Iteration 7728, loss = 0.00281062\n",
      "Iteration 7729, loss = 0.00281041\n",
      "Iteration 7730, loss = 0.00280950\n",
      "Iteration 7731, loss = 0.00280870\n",
      "Iteration 7732, loss = 0.00280839\n",
      "Iteration 7733, loss = 0.00280767\n",
      "Iteration 7734, loss = 0.00280716\n",
      "Iteration 7735, loss = 0.00280677\n",
      "Iteration 7736, loss = 0.00280617\n",
      "Iteration 7737, loss = 0.00280585\n",
      "Iteration 7738, loss = 0.00280542\n",
      "Iteration 7739, loss = 0.00280492\n",
      "Iteration 7740, loss = 0.00280460\n",
      "Iteration 7741, loss = 0.00280413\n",
      "Iteration 7742, loss = 0.00280380\n",
      "Iteration 7743, loss = 0.00280325\n",
      "Iteration 7744, loss = 0.00280270\n",
      "Iteration 7745, loss = 0.00280220\n",
      "Iteration 7746, loss = 0.00280160\n",
      "Iteration 7747, loss = 0.00280124\n",
      "Iteration 7748, loss = 0.00280050\n",
      "Iteration 7749, loss = 0.00279996\n",
      "Iteration 7750, loss = 0.00279941\n",
      "Iteration 7751, loss = 0.00279884\n",
      "Iteration 7752, loss = 0.00279842\n",
      "Iteration 7753, loss = 0.00279778\n",
      "Iteration 7754, loss = 0.00279720\n",
      "Iteration 7755, loss = 0.00279662\n",
      "Iteration 7756, loss = 0.00279639\n",
      "Iteration 7757, loss = 0.00279563\n",
      "Iteration 7758, loss = 0.00279515\n",
      "Iteration 7759, loss = 0.00279466\n",
      "Iteration 7760, loss = 0.00279409\n",
      "Iteration 7761, loss = 0.00279347\n",
      "Iteration 7762, loss = 0.00279318\n",
      "Iteration 7763, loss = 0.00279243\n",
      "Iteration 7764, loss = 0.00279199\n",
      "Iteration 7765, loss = 0.00279138\n",
      "Iteration 7766, loss = 0.00279086\n",
      "Iteration 7767, loss = 0.00279035\n",
      "Iteration 7768, loss = 0.00278982\n",
      "Iteration 7769, loss = 0.00278932\n",
      "Iteration 7770, loss = 0.00278880\n",
      "Iteration 7771, loss = 0.00278831\n",
      "Iteration 7772, loss = 0.00278775\n",
      "Iteration 7773, loss = 0.00278712\n",
      "Iteration 7774, loss = 0.00278664\n",
      "Iteration 7775, loss = 0.00278610\n",
      "Iteration 7776, loss = 0.00278557\n",
      "Iteration 7777, loss = 0.00278537\n",
      "Iteration 7778, loss = 0.00278460\n",
      "Iteration 7779, loss = 0.00278407\n",
      "Iteration 7780, loss = 0.00278373\n",
      "Iteration 7781, loss = 0.00278314\n",
      "Iteration 7782, loss = 0.00278266\n",
      "Iteration 7783, loss = 0.00278199\n",
      "Iteration 7784, loss = 0.00278168\n",
      "Iteration 7785, loss = 0.00278115\n",
      "Iteration 7786, loss = 0.00278053\n",
      "Iteration 7787, loss = 0.00277994\n",
      "Iteration 7788, loss = 0.00277949\n",
      "Iteration 7789, loss = 0.00277892\n",
      "Iteration 7790, loss = 0.00277835\n",
      "Iteration 7791, loss = 0.00277784\n",
      "Iteration 7792, loss = 0.00277742\n",
      "Iteration 7793, loss = 0.00277695\n",
      "Iteration 7794, loss = 0.00277649\n",
      "Iteration 7795, loss = 0.00277600\n",
      "Iteration 7796, loss = 0.00277565\n",
      "Iteration 7797, loss = 0.00277483\n",
      "Iteration 7798, loss = 0.00277434\n",
      "Iteration 7799, loss = 0.00277380\n",
      "Iteration 7800, loss = 0.00277330\n",
      "Iteration 7801, loss = 0.00277285\n",
      "Iteration 7802, loss = 0.00277253\n",
      "Iteration 7803, loss = 0.00277181\n",
      "Iteration 7804, loss = 0.00277154\n",
      "Iteration 7805, loss = 0.00277081\n",
      "Iteration 7806, loss = 0.00277038\n",
      "Iteration 7807, loss = 0.00276986\n",
      "Iteration 7808, loss = 0.00276935\n",
      "Iteration 7809, loss = 0.00276894\n",
      "Iteration 7810, loss = 0.00276847\n",
      "Iteration 7811, loss = 0.00276795\n",
      "Iteration 7812, loss = 0.00276749\n",
      "Iteration 7813, loss = 0.00276708\n",
      "Iteration 7814, loss = 0.00276643\n",
      "Iteration 7815, loss = 0.00276590\n",
      "Iteration 7816, loss = 0.00276543\n",
      "Iteration 7817, loss = 0.00276521\n",
      "Iteration 7818, loss = 0.00276447\n",
      "Iteration 7819, loss = 0.00276402\n",
      "Iteration 7820, loss = 0.00276354\n",
      "Iteration 7821, loss = 0.00276296\n",
      "Iteration 7822, loss = 0.00276239\n",
      "Iteration 7823, loss = 0.00276190\n",
      "Iteration 7824, loss = 0.00276140\n",
      "Iteration 7825, loss = 0.00276100\n",
      "Iteration 7826, loss = 0.00276036\n",
      "Iteration 7827, loss = 0.00275995\n",
      "Iteration 7828, loss = 0.00275968\n",
      "Iteration 7829, loss = 0.00275915\n",
      "Iteration 7830, loss = 0.00275862\n",
      "Iteration 7831, loss = 0.00275813\n",
      "Iteration 7832, loss = 0.00275766\n",
      "Iteration 7833, loss = 0.00275733\n",
      "Iteration 7834, loss = 0.00275669\n",
      "Iteration 7835, loss = 0.00275650\n",
      "Iteration 7836, loss = 0.00275571\n",
      "Iteration 7837, loss = 0.00275517\n",
      "Iteration 7838, loss = 0.00275464\n",
      "Iteration 7839, loss = 0.00275441\n",
      "Iteration 7840, loss = 0.00275401\n",
      "Iteration 7841, loss = 0.00275315\n",
      "Iteration 7842, loss = 0.00275269\n",
      "Iteration 7843, loss = 0.00275221\n",
      "Iteration 7844, loss = 0.00275166\n",
      "Iteration 7845, loss = 0.00275111\n",
      "Iteration 7846, loss = 0.00275042\n",
      "Iteration 7847, loss = 0.00274998\n",
      "Iteration 7848, loss = 0.00274944\n",
      "Iteration 7849, loss = 0.00274894\n",
      "Iteration 7850, loss = 0.00274878\n",
      "Iteration 7851, loss = 0.00274810\n",
      "Iteration 7852, loss = 0.00274758\n",
      "Iteration 7853, loss = 0.00274714\n",
      "Iteration 7854, loss = 0.00274671\n",
      "Iteration 7855, loss = 0.00274619\n",
      "Iteration 7856, loss = 0.00274571\n",
      "Iteration 7857, loss = 0.00274564\n",
      "Iteration 7858, loss = 0.00274476\n",
      "Iteration 7859, loss = 0.00274412\n",
      "Iteration 7860, loss = 0.00274349\n",
      "Iteration 7861, loss = 0.00274308\n",
      "Iteration 7862, loss = 0.00274249\n",
      "Iteration 7863, loss = 0.00274200\n",
      "Iteration 7864, loss = 0.00274148\n",
      "Iteration 7865, loss = 0.00274094\n",
      "Iteration 7866, loss = 0.00274046\n",
      "Iteration 7867, loss = 0.00273996\n",
      "Iteration 7868, loss = 0.00273959\n",
      "Iteration 7869, loss = 0.00273901\n",
      "Iteration 7870, loss = 0.00273855\n",
      "Iteration 7871, loss = 0.00273820\n",
      "Iteration 7872, loss = 0.00273789\n",
      "Iteration 7873, loss = 0.00273719\n",
      "Iteration 7874, loss = 0.00273683\n",
      "Iteration 7875, loss = 0.00273655\n",
      "Iteration 7876, loss = 0.00273583\n",
      "Iteration 7877, loss = 0.00273533\n",
      "Iteration 7878, loss = 0.00273489\n",
      "Iteration 7879, loss = 0.00273446\n",
      "Iteration 7880, loss = 0.00273400\n",
      "Iteration 7881, loss = 0.00273376\n",
      "Iteration 7882, loss = 0.00273334\n",
      "Iteration 7883, loss = 0.00273238\n",
      "Iteration 7884, loss = 0.00273196\n",
      "Iteration 7885, loss = 0.00273127\n",
      "Iteration 7886, loss = 0.00273088\n",
      "Iteration 7887, loss = 0.00273025\n",
      "Iteration 7888, loss = 0.00272964\n",
      "Iteration 7889, loss = 0.00272920\n",
      "Iteration 7890, loss = 0.00272859\n",
      "Iteration 7891, loss = 0.00272843\n",
      "Iteration 7892, loss = 0.00272774\n",
      "Iteration 7893, loss = 0.00272717\n",
      "Iteration 7894, loss = 0.00272673\n",
      "Iteration 7895, loss = 0.00272618\n",
      "Iteration 7896, loss = 0.00272563\n",
      "Iteration 7897, loss = 0.00272514\n",
      "Iteration 7898, loss = 0.00272468\n",
      "Iteration 7899, loss = 0.00272417\n",
      "Iteration 7900, loss = 0.00272381\n",
      "Iteration 7901, loss = 0.00272339\n",
      "Iteration 7902, loss = 0.00272308\n",
      "Iteration 7903, loss = 0.00272257\n",
      "Iteration 7904, loss = 0.00272212\n",
      "Iteration 7905, loss = 0.00272167\n",
      "Iteration 7906, loss = 0.00272118\n",
      "Iteration 7907, loss = 0.00272094\n",
      "Iteration 7908, loss = 0.00272022\n",
      "Iteration 7909, loss = 0.00271986\n",
      "Iteration 7910, loss = 0.00271944\n",
      "Iteration 7911, loss = 0.00271884\n",
      "Iteration 7912, loss = 0.00271852\n",
      "Iteration 7913, loss = 0.00271787\n",
      "Iteration 7914, loss = 0.00271731\n",
      "Iteration 7915, loss = 0.00271695\n",
      "Iteration 7916, loss = 0.00271636\n",
      "Iteration 7917, loss = 0.00271582\n",
      "Iteration 7918, loss = 0.00271526\n",
      "Iteration 7919, loss = 0.00271477\n",
      "Iteration 7920, loss = 0.00271427\n",
      "Iteration 7921, loss = 0.00271376\n",
      "Iteration 7922, loss = 0.00271318\n",
      "Iteration 7923, loss = 0.00271292\n",
      "Iteration 7924, loss = 0.00271222\n",
      "Iteration 7925, loss = 0.00271177\n",
      "Iteration 7926, loss = 0.00271133\n",
      "Iteration 7927, loss = 0.00271084\n",
      "Iteration 7928, loss = 0.00271075\n",
      "Iteration 7929, loss = 0.00270994\n",
      "Iteration 7930, loss = 0.00270937\n",
      "Iteration 7931, loss = 0.00270887\n",
      "Iteration 7932, loss = 0.00270838\n",
      "Iteration 7933, loss = 0.00270796\n",
      "Iteration 7934, loss = 0.00270739\n",
      "Iteration 7935, loss = 0.00270685\n",
      "Iteration 7936, loss = 0.00270644\n",
      "Iteration 7937, loss = 0.00270588\n",
      "Iteration 7938, loss = 0.00270544\n",
      "Iteration 7939, loss = 0.00270487\n",
      "Iteration 7940, loss = 0.00270429\n",
      "Iteration 7941, loss = 0.00270399\n",
      "Iteration 7942, loss = 0.00270343\n",
      "Iteration 7943, loss = 0.00270285\n",
      "Iteration 7944, loss = 0.00270237\n",
      "Iteration 7945, loss = 0.00270173\n",
      "Iteration 7946, loss = 0.00270130\n",
      "Iteration 7947, loss = 0.00270109\n",
      "Iteration 7948, loss = 0.00270034\n",
      "Iteration 7949, loss = 0.00269983\n",
      "Iteration 7950, loss = 0.00269944\n",
      "Iteration 7951, loss = 0.00269888\n",
      "Iteration 7952, loss = 0.00269835\n",
      "Iteration 7953, loss = 0.00269786\n",
      "Iteration 7954, loss = 0.00269745\n",
      "Iteration 7955, loss = 0.00269690\n",
      "Iteration 7956, loss = 0.00269645\n",
      "Iteration 7957, loss = 0.00269594\n",
      "Iteration 7958, loss = 0.00269556\n",
      "Iteration 7959, loss = 0.00269504\n",
      "Iteration 7960, loss = 0.00269454\n",
      "Iteration 7961, loss = 0.00269411\n",
      "Iteration 7962, loss = 0.00269366\n",
      "Iteration 7963, loss = 0.00269323\n",
      "Iteration 7964, loss = 0.00269280\n",
      "Iteration 7965, loss = 0.00269240\n",
      "Iteration 7966, loss = 0.00269195\n",
      "Iteration 7967, loss = 0.00269144\n",
      "Iteration 7968, loss = 0.00269128\n",
      "Iteration 7969, loss = 0.00269086\n",
      "Iteration 7970, loss = 0.00269038\n",
      "Iteration 7971, loss = 0.00269016\n",
      "Iteration 7972, loss = 0.00268948\n",
      "Iteration 7973, loss = 0.00268915\n",
      "Iteration 7974, loss = 0.00268865\n",
      "Iteration 7975, loss = 0.00268818\n",
      "Iteration 7976, loss = 0.00268773\n",
      "Iteration 7977, loss = 0.00268716\n",
      "Iteration 7978, loss = 0.00268701\n",
      "Iteration 7979, loss = 0.00268618\n",
      "Iteration 7980, loss = 0.00268571\n",
      "Iteration 7981, loss = 0.00268524\n",
      "Iteration 7982, loss = 0.00268474\n",
      "Iteration 7983, loss = 0.00268397\n",
      "Iteration 7984, loss = 0.00268360\n",
      "Iteration 7985, loss = 0.00268298\n",
      "Iteration 7986, loss = 0.00268248\n",
      "Iteration 7987, loss = 0.00268263\n",
      "Iteration 7988, loss = 0.00268162\n",
      "Iteration 7989, loss = 0.00268111\n",
      "Iteration 7990, loss = 0.00268073\n",
      "Iteration 7991, loss = 0.00268029\n",
      "Iteration 7992, loss = 0.00267986\n",
      "Iteration 7993, loss = 0.00267939\n",
      "Iteration 7994, loss = 0.00267897\n",
      "Iteration 7995, loss = 0.00267861\n",
      "Iteration 7996, loss = 0.00267811\n",
      "Iteration 7997, loss = 0.00267762\n",
      "Iteration 7998, loss = 0.00267726\n",
      "Iteration 7999, loss = 0.00267684\n",
      "Iteration 8000, loss = 0.00267637\n",
      "Iteration 1, loss = 1.04177453\n",
      "Iteration 2, loss = 1.03868137\n",
      "Iteration 3, loss = 1.03371997\n",
      "Iteration 4, loss = 1.02749678\n",
      "Iteration 5, loss = 1.02020169\n",
      "Iteration 6, loss = 1.01210999\n",
      "Iteration 7, loss = 1.00359825\n",
      "Iteration 8, loss = 0.99474913\n",
      "Iteration 9, loss = 0.98528209\n",
      "Iteration 10, loss = 0.97619983\n",
      "Iteration 11, loss = 0.96665718\n",
      "Iteration 12, loss = 0.95742216\n",
      "Iteration 13, loss = 0.94805584\n",
      "Iteration 14, loss = 0.93908173\n",
      "Iteration 15, loss = 0.93015474\n",
      "Iteration 16, loss = 0.92142719\n",
      "Iteration 17, loss = 0.91277785\n",
      "Iteration 18, loss = 0.90440662\n",
      "Iteration 19, loss = 0.89643144\n",
      "Iteration 20, loss = 0.88845959\n",
      "Iteration 21, loss = 0.88066510\n",
      "Iteration 22, loss = 0.87326192\n",
      "Iteration 23, loss = 0.86597243\n",
      "Iteration 24, loss = 0.85862085\n",
      "Iteration 25, loss = 0.85173467\n",
      "Iteration 26, loss = 0.84479330\n",
      "Iteration 27, loss = 0.83793228\n",
      "Iteration 28, loss = 0.83143110\n",
      "Iteration 29, loss = 0.82513226\n",
      "Iteration 30, loss = 0.81889463\n",
      "Iteration 31, loss = 0.81293504\n",
      "Iteration 32, loss = 0.80711047\n",
      "Iteration 33, loss = 0.80139018\n",
      "Iteration 34, loss = 0.79597413\n",
      "Iteration 35, loss = 0.79059570\n",
      "Iteration 36, loss = 0.78527792\n",
      "Iteration 37, loss = 0.78035267\n",
      "Iteration 38, loss = 0.77536576\n",
      "Iteration 39, loss = 0.77058748\n",
      "Iteration 40, loss = 0.76609830\n",
      "Iteration 41, loss = 0.76157937\n",
      "Iteration 42, loss = 0.75728338\n",
      "Iteration 43, loss = 0.75319195\n",
      "Iteration 44, loss = 0.74913297\n",
      "Iteration 45, loss = 0.74511883\n",
      "Iteration 46, loss = 0.74135742\n",
      "Iteration 47, loss = 0.73756034\n",
      "Iteration 48, loss = 0.73382059\n",
      "Iteration 49, loss = 0.73018910\n",
      "Iteration 50, loss = 0.72654406\n",
      "Iteration 51, loss = 0.72308977\n",
      "Iteration 52, loss = 0.71956484\n",
      "Iteration 53, loss = 0.71622283\n",
      "Iteration 54, loss = 0.71279432\n",
      "Iteration 55, loss = 0.70950648\n",
      "Iteration 56, loss = 0.70619254\n",
      "Iteration 57, loss = 0.70278269\n",
      "Iteration 58, loss = 0.69954013\n",
      "Iteration 59, loss = 0.69616671\n",
      "Iteration 60, loss = 0.69282500\n",
      "Iteration 61, loss = 0.68958101\n",
      "Iteration 62, loss = 0.68638941\n",
      "Iteration 63, loss = 0.68326864\n",
      "Iteration 64, loss = 0.68011906\n",
      "Iteration 65, loss = 0.67715892\n",
      "Iteration 66, loss = 0.67424079\n",
      "Iteration 67, loss = 0.67124514\n",
      "Iteration 68, loss = 0.66847300\n",
      "Iteration 69, loss = 0.66553256\n",
      "Iteration 70, loss = 0.66281070\n",
      "Iteration 71, loss = 0.65995989\n",
      "Iteration 72, loss = 0.65725613\n",
      "Iteration 73, loss = 0.65443971\n",
      "Iteration 74, loss = 0.65174448\n",
      "Iteration 75, loss = 0.64900530\n",
      "Iteration 76, loss = 0.64627414\n",
      "Iteration 77, loss = 0.64358511\n",
      "Iteration 78, loss = 0.64088997\n",
      "Iteration 79, loss = 0.63825574\n",
      "Iteration 80, loss = 0.63560560\n",
      "Iteration 81, loss = 0.63294966\n",
      "Iteration 82, loss = 0.63034024\n",
      "Iteration 83, loss = 0.62774287\n",
      "Iteration 84, loss = 0.62507733\n",
      "Iteration 85, loss = 0.62253007\n",
      "Iteration 86, loss = 0.61992816\n",
      "Iteration 87, loss = 0.61733878\n",
      "Iteration 88, loss = 0.61474525\n",
      "Iteration 89, loss = 0.61222777\n",
      "Iteration 90, loss = 0.60966141\n",
      "Iteration 91, loss = 0.60707329\n",
      "Iteration 92, loss = 0.60460827\n",
      "Iteration 93, loss = 0.60207671\n",
      "Iteration 94, loss = 0.59956383\n",
      "Iteration 95, loss = 0.59709881\n",
      "Iteration 96, loss = 0.59464580\n",
      "Iteration 97, loss = 0.59222003\n",
      "Iteration 98, loss = 0.58978862\n",
      "Iteration 99, loss = 0.58733894\n",
      "Iteration 100, loss = 0.58495603\n",
      "Iteration 101, loss = 0.58256681\n",
      "Iteration 102, loss = 0.58015083\n",
      "Iteration 103, loss = 0.57778214\n",
      "Iteration 104, loss = 0.57543506\n",
      "Iteration 105, loss = 0.57303841\n",
      "Iteration 106, loss = 0.57070784\n",
      "Iteration 107, loss = 0.56835610\n",
      "Iteration 108, loss = 0.56607527\n",
      "Iteration 109, loss = 0.56371591\n",
      "Iteration 110, loss = 0.56142137\n",
      "Iteration 111, loss = 0.55913530\n",
      "Iteration 112, loss = 0.55683816\n",
      "Iteration 113, loss = 0.55457258\n",
      "Iteration 114, loss = 0.55222002\n",
      "Iteration 115, loss = 0.54997821\n",
      "Iteration 116, loss = 0.54769384\n",
      "Iteration 117, loss = 0.54536897\n",
      "Iteration 118, loss = 0.54318059\n",
      "Iteration 119, loss = 0.54088372\n",
      "Iteration 120, loss = 0.53868925\n",
      "Iteration 121, loss = 0.53650413\n",
      "Iteration 122, loss = 0.53432362\n",
      "Iteration 123, loss = 0.53215247\n",
      "Iteration 124, loss = 0.52998663\n",
      "Iteration 125, loss = 0.52783436\n",
      "Iteration 126, loss = 0.52568419\n",
      "Iteration 127, loss = 0.52357154\n",
      "Iteration 128, loss = 0.52148724\n",
      "Iteration 129, loss = 0.51937764\n",
      "Iteration 130, loss = 0.51732254\n",
      "Iteration 131, loss = 0.51527378\n",
      "Iteration 132, loss = 0.51319389\n",
      "Iteration 133, loss = 0.51115364\n",
      "Iteration 134, loss = 0.50911974\n",
      "Iteration 135, loss = 0.50706445\n",
      "Iteration 136, loss = 0.50502858\n",
      "Iteration 137, loss = 0.50295859\n",
      "Iteration 138, loss = 0.50089770\n",
      "Iteration 139, loss = 0.49883001\n",
      "Iteration 140, loss = 0.49673090\n",
      "Iteration 141, loss = 0.49464261\n",
      "Iteration 142, loss = 0.49255469\n",
      "Iteration 143, loss = 0.49048270\n",
      "Iteration 144, loss = 0.48841305\n",
      "Iteration 145, loss = 0.48634201\n",
      "Iteration 146, loss = 0.48428205\n",
      "Iteration 147, loss = 0.48224242\n",
      "Iteration 148, loss = 0.48021676\n",
      "Iteration 149, loss = 0.47812948\n",
      "Iteration 150, loss = 0.47609411\n",
      "Iteration 151, loss = 0.47403857\n",
      "Iteration 152, loss = 0.47196802\n",
      "Iteration 153, loss = 0.46990518\n",
      "Iteration 154, loss = 0.46784949\n",
      "Iteration 155, loss = 0.46584427\n",
      "Iteration 156, loss = 0.46376998\n",
      "Iteration 157, loss = 0.46175781\n",
      "Iteration 158, loss = 0.45970990\n",
      "Iteration 159, loss = 0.45765699\n",
      "Iteration 160, loss = 0.45557920\n",
      "Iteration 161, loss = 0.45351563\n",
      "Iteration 162, loss = 0.45141661\n",
      "Iteration 163, loss = 0.44932752\n",
      "Iteration 164, loss = 0.44723323\n",
      "Iteration 165, loss = 0.44511576\n",
      "Iteration 166, loss = 0.44301619\n",
      "Iteration 167, loss = 0.44090005\n",
      "Iteration 168, loss = 0.43881737\n",
      "Iteration 169, loss = 0.43667688\n",
      "Iteration 170, loss = 0.43461121\n",
      "Iteration 171, loss = 0.43249538\n",
      "Iteration 172, loss = 0.43040965\n",
      "Iteration 173, loss = 0.42834228\n",
      "Iteration 174, loss = 0.42626233\n",
      "Iteration 175, loss = 0.42418190\n",
      "Iteration 176, loss = 0.42214217\n",
      "Iteration 177, loss = 0.42007525\n",
      "Iteration 178, loss = 0.41802062\n",
      "Iteration 179, loss = 0.41595475\n",
      "Iteration 180, loss = 0.41392610\n",
      "Iteration 181, loss = 0.41184082\n",
      "Iteration 182, loss = 0.40980242\n",
      "Iteration 183, loss = 0.40777699\n",
      "Iteration 184, loss = 0.40569220\n",
      "Iteration 185, loss = 0.40364512\n",
      "Iteration 186, loss = 0.40159005\n",
      "Iteration 187, loss = 0.39950365\n",
      "Iteration 188, loss = 0.39746437\n",
      "Iteration 189, loss = 0.39541085\n",
      "Iteration 190, loss = 0.39334285\n",
      "Iteration 191, loss = 0.39131976\n",
      "Iteration 192, loss = 0.38927878\n",
      "Iteration 193, loss = 0.38726546\n",
      "Iteration 194, loss = 0.38524730\n",
      "Iteration 195, loss = 0.38325991\n",
      "Iteration 196, loss = 0.38123122\n",
      "Iteration 197, loss = 0.37926933\n",
      "Iteration 198, loss = 0.37726739\n",
      "Iteration 199, loss = 0.37530145\n",
      "Iteration 200, loss = 0.37332332\n",
      "Iteration 201, loss = 0.37133910\n",
      "Iteration 202, loss = 0.36938701\n",
      "Iteration 203, loss = 0.36742032\n",
      "Iteration 204, loss = 0.36544638\n",
      "Iteration 205, loss = 0.36348875\n",
      "Iteration 206, loss = 0.36153449\n",
      "Iteration 207, loss = 0.35954676\n",
      "Iteration 208, loss = 0.35757568\n",
      "Iteration 209, loss = 0.35559529\n",
      "Iteration 210, loss = 0.35360813\n",
      "Iteration 211, loss = 0.35163312\n",
      "Iteration 212, loss = 0.34960790\n",
      "Iteration 213, loss = 0.34764730\n",
      "Iteration 214, loss = 0.34565365\n",
      "Iteration 215, loss = 0.34366947\n",
      "Iteration 216, loss = 0.34170303\n",
      "Iteration 217, loss = 0.33974351\n",
      "Iteration 218, loss = 0.33779131\n",
      "Iteration 219, loss = 0.33585650\n",
      "Iteration 220, loss = 0.33392512\n",
      "Iteration 221, loss = 0.33200227\n",
      "Iteration 222, loss = 0.33011402\n",
      "Iteration 223, loss = 0.32820327\n",
      "Iteration 224, loss = 0.32629477\n",
      "Iteration 225, loss = 0.32442637\n",
      "Iteration 226, loss = 0.32251983\n",
      "Iteration 227, loss = 0.32063337\n",
      "Iteration 228, loss = 0.31874542\n",
      "Iteration 229, loss = 0.31685704\n",
      "Iteration 230, loss = 0.31497983\n",
      "Iteration 231, loss = 0.31311700\n",
      "Iteration 232, loss = 0.31125061\n",
      "Iteration 233, loss = 0.30937834\n",
      "Iteration 234, loss = 0.30752760\n",
      "Iteration 235, loss = 0.30568281\n",
      "Iteration 236, loss = 0.30382634\n",
      "Iteration 237, loss = 0.30198406\n",
      "Iteration 238, loss = 0.30016336\n",
      "Iteration 239, loss = 0.29833604\n",
      "Iteration 240, loss = 0.29652663\n",
      "Iteration 241, loss = 0.29473207\n",
      "Iteration 242, loss = 0.29294790\n",
      "Iteration 243, loss = 0.29115608\n",
      "Iteration 244, loss = 0.28937525\n",
      "Iteration 245, loss = 0.28762391\n",
      "Iteration 246, loss = 0.28582865\n",
      "Iteration 247, loss = 0.28409827\n",
      "Iteration 248, loss = 0.28233175\n",
      "Iteration 249, loss = 0.28058975\n",
      "Iteration 250, loss = 0.27889390\n",
      "Iteration 251, loss = 0.27718080\n",
      "Iteration 252, loss = 0.27548324\n",
      "Iteration 253, loss = 0.27379591\n",
      "Iteration 254, loss = 0.27213639\n",
      "Iteration 255, loss = 0.27045945\n",
      "Iteration 256, loss = 0.26881339\n",
      "Iteration 257, loss = 0.26714510\n",
      "Iteration 258, loss = 0.26552177\n",
      "Iteration 259, loss = 0.26387386\n",
      "Iteration 260, loss = 0.26225335\n",
      "Iteration 261, loss = 0.26062966\n",
      "Iteration 262, loss = 0.25903589\n",
      "Iteration 263, loss = 0.25741547\n",
      "Iteration 264, loss = 0.25582473\n",
      "Iteration 265, loss = 0.25423773\n",
      "Iteration 266, loss = 0.25267482\n",
      "Iteration 267, loss = 0.25110200\n",
      "Iteration 268, loss = 0.24955838\n",
      "Iteration 269, loss = 0.24802795\n",
      "Iteration 270, loss = 0.24652324\n",
      "Iteration 271, loss = 0.24501677\n",
      "Iteration 272, loss = 0.24353297\n",
      "Iteration 273, loss = 0.24204221\n",
      "Iteration 274, loss = 0.24058678\n",
      "Iteration 275, loss = 0.23912452\n",
      "Iteration 276, loss = 0.23768899\n",
      "Iteration 277, loss = 0.23625117\n",
      "Iteration 278, loss = 0.23483474\n",
      "Iteration 279, loss = 0.23343248\n",
      "Iteration 280, loss = 0.23203316\n",
      "Iteration 281, loss = 0.23063816\n",
      "Iteration 282, loss = 0.22925294\n",
      "Iteration 283, loss = 0.22787293\n",
      "Iteration 284, loss = 0.22649685\n",
      "Iteration 285, loss = 0.22512511\n",
      "Iteration 286, loss = 0.22377191\n",
      "Iteration 287, loss = 0.22244038\n",
      "Iteration 288, loss = 0.22110542\n",
      "Iteration 289, loss = 0.21978557\n",
      "Iteration 290, loss = 0.21847512\n",
      "Iteration 291, loss = 0.21717289\n",
      "Iteration 292, loss = 0.21589175\n",
      "Iteration 293, loss = 0.21460437\n",
      "Iteration 294, loss = 0.21333023\n",
      "Iteration 295, loss = 0.21207436\n",
      "Iteration 296, loss = 0.21081191\n",
      "Iteration 297, loss = 0.20957536\n",
      "Iteration 298, loss = 0.20832089\n",
      "Iteration 299, loss = 0.20710471\n",
      "Iteration 300, loss = 0.20587862\n",
      "Iteration 301, loss = 0.20466667\n",
      "Iteration 302, loss = 0.20347151\n",
      "Iteration 303, loss = 0.20229091\n",
      "Iteration 304, loss = 0.20110568\n",
      "Iteration 305, loss = 0.19994242\n",
      "Iteration 306, loss = 0.19877991\n",
      "Iteration 307, loss = 0.19762764\n",
      "Iteration 308, loss = 0.19650048\n",
      "Iteration 309, loss = 0.19536271\n",
      "Iteration 310, loss = 0.19425350\n",
      "Iteration 311, loss = 0.19314666\n",
      "Iteration 312, loss = 0.19204928\n",
      "Iteration 313, loss = 0.19096253\n",
      "Iteration 314, loss = 0.18988092\n",
      "Iteration 315, loss = 0.18880075\n",
      "Iteration 316, loss = 0.18773520\n",
      "Iteration 317, loss = 0.18666858\n",
      "Iteration 318, loss = 0.18561471\n",
      "Iteration 319, loss = 0.18456048\n",
      "Iteration 320, loss = 0.18351707\n",
      "Iteration 321, loss = 0.18248067\n",
      "Iteration 322, loss = 0.18146406\n",
      "Iteration 323, loss = 0.18045405\n",
      "Iteration 324, loss = 0.17945469\n",
      "Iteration 325, loss = 0.17845109\n",
      "Iteration 326, loss = 0.17747347\n",
      "Iteration 327, loss = 0.17650082\n",
      "Iteration 328, loss = 0.17552974\n",
      "Iteration 329, loss = 0.17457048\n",
      "Iteration 330, loss = 0.17361132\n",
      "Iteration 331, loss = 0.17265787\n",
      "Iteration 332, loss = 0.17171454\n",
      "Iteration 333, loss = 0.17078316\n",
      "Iteration 334, loss = 0.16985148\n",
      "Iteration 335, loss = 0.16893595\n",
      "Iteration 336, loss = 0.16802035\n",
      "Iteration 337, loss = 0.16710678\n",
      "Iteration 338, loss = 0.16620777\n",
      "Iteration 339, loss = 0.16531504\n",
      "Iteration 340, loss = 0.16442473\n",
      "Iteration 341, loss = 0.16354346\n",
      "Iteration 342, loss = 0.16266678\n",
      "Iteration 343, loss = 0.16181488\n",
      "Iteration 344, loss = 0.16094426\n",
      "Iteration 345, loss = 0.16010174\n",
      "Iteration 346, loss = 0.15925905\n",
      "Iteration 347, loss = 0.15841100\n",
      "Iteration 348, loss = 0.15758614\n",
      "Iteration 349, loss = 0.15675157\n",
      "Iteration 350, loss = 0.15592960\n",
      "Iteration 351, loss = 0.15511402\n",
      "Iteration 352, loss = 0.15430873\n",
      "Iteration 353, loss = 0.15351764\n",
      "Iteration 354, loss = 0.15272836\n",
      "Iteration 355, loss = 0.15194977\n",
      "Iteration 356, loss = 0.15118354\n",
      "Iteration 357, loss = 0.15041555\n",
      "Iteration 358, loss = 0.14965471\n",
      "Iteration 359, loss = 0.14890210\n",
      "Iteration 360, loss = 0.14815972\n",
      "Iteration 361, loss = 0.14742137\n",
      "Iteration 362, loss = 0.14669196\n",
      "Iteration 363, loss = 0.14596167\n",
      "Iteration 364, loss = 0.14524570\n",
      "Iteration 365, loss = 0.14453815\n",
      "Iteration 366, loss = 0.14382242\n",
      "Iteration 367, loss = 0.14312549\n",
      "Iteration 368, loss = 0.14243044\n",
      "Iteration 369, loss = 0.14174573\n",
      "Iteration 370, loss = 0.14106085\n",
      "Iteration 371, loss = 0.14039043\n",
      "Iteration 372, loss = 0.13971921\n",
      "Iteration 373, loss = 0.13905682\n",
      "Iteration 374, loss = 0.13838411\n",
      "Iteration 375, loss = 0.13772630\n",
      "Iteration 376, loss = 0.13707523\n",
      "Iteration 377, loss = 0.13642616\n",
      "Iteration 378, loss = 0.13578584\n",
      "Iteration 379, loss = 0.13514343\n",
      "Iteration 380, loss = 0.13451573\n",
      "Iteration 381, loss = 0.13388987\n",
      "Iteration 382, loss = 0.13327073\n",
      "Iteration 383, loss = 0.13265707\n",
      "Iteration 384, loss = 0.13204377\n",
      "Iteration 385, loss = 0.13144337\n",
      "Iteration 386, loss = 0.13083742\n",
      "Iteration 387, loss = 0.13024086\n",
      "Iteration 388, loss = 0.12964434\n",
      "Iteration 389, loss = 0.12906002\n",
      "Iteration 390, loss = 0.12847145\n",
      "Iteration 391, loss = 0.12789728\n",
      "Iteration 392, loss = 0.12731278\n",
      "Iteration 393, loss = 0.12674636\n",
      "Iteration 394, loss = 0.12618635\n",
      "Iteration 395, loss = 0.12562648\n",
      "Iteration 396, loss = 0.12507545\n",
      "Iteration 397, loss = 0.12453123\n",
      "Iteration 398, loss = 0.12399003\n",
      "Iteration 399, loss = 0.12345264\n",
      "Iteration 400, loss = 0.12292272\n",
      "Iteration 401, loss = 0.12239119\n",
      "Iteration 402, loss = 0.12187814\n",
      "Iteration 403, loss = 0.12135715\n",
      "Iteration 404, loss = 0.12084351\n",
      "Iteration 405, loss = 0.12032732\n",
      "Iteration 406, loss = 0.11981631\n",
      "Iteration 407, loss = 0.11930703\n",
      "Iteration 408, loss = 0.11880115\n",
      "Iteration 409, loss = 0.11829536\n",
      "Iteration 410, loss = 0.11779726\n",
      "Iteration 411, loss = 0.11730519\n",
      "Iteration 412, loss = 0.11681439\n",
      "Iteration 413, loss = 0.11633579\n",
      "Iteration 414, loss = 0.11585612\n",
      "Iteration 415, loss = 0.11537430\n",
      "Iteration 416, loss = 0.11490886\n",
      "Iteration 417, loss = 0.11442960\n",
      "Iteration 418, loss = 0.11396636\n",
      "Iteration 419, loss = 0.11349896\n",
      "Iteration 420, loss = 0.11303775\n",
      "Iteration 421, loss = 0.11257486\n",
      "Iteration 422, loss = 0.11212326\n",
      "Iteration 423, loss = 0.11166809\n",
      "Iteration 424, loss = 0.11122189\n",
      "Iteration 425, loss = 0.11077281\n",
      "Iteration 426, loss = 0.11033145\n",
      "Iteration 427, loss = 0.10989753\n",
      "Iteration 428, loss = 0.10946865\n",
      "Iteration 429, loss = 0.10903406\n",
      "Iteration 430, loss = 0.10861485\n",
      "Iteration 431, loss = 0.10819805\n",
      "Iteration 432, loss = 0.10778154\n",
      "Iteration 433, loss = 0.10736023\n",
      "Iteration 434, loss = 0.10694388\n",
      "Iteration 435, loss = 0.10654247\n",
      "Iteration 436, loss = 0.10612957\n",
      "Iteration 437, loss = 0.10572616\n",
      "Iteration 438, loss = 0.10532509\n",
      "Iteration 439, loss = 0.10492886\n",
      "Iteration 440, loss = 0.10452830\n",
      "Iteration 441, loss = 0.10414161\n",
      "Iteration 442, loss = 0.10374858\n",
      "Iteration 443, loss = 0.10336927\n",
      "Iteration 444, loss = 0.10298912\n",
      "Iteration 445, loss = 0.10261119\n",
      "Iteration 446, loss = 0.10223632\n",
      "Iteration 447, loss = 0.10186492\n",
      "Iteration 448, loss = 0.10148163\n",
      "Iteration 449, loss = 0.10110623\n",
      "Iteration 450, loss = 0.10073376\n",
      "Iteration 451, loss = 0.10035915\n",
      "Iteration 452, loss = 0.09999802\n",
      "Iteration 453, loss = 0.09963459\n",
      "Iteration 454, loss = 0.09928082\n",
      "Iteration 455, loss = 0.09893552\n",
      "Iteration 456, loss = 0.09857376\n",
      "Iteration 457, loss = 0.09822398\n",
      "Iteration 458, loss = 0.09787415\n",
      "Iteration 459, loss = 0.09752187\n",
      "Iteration 460, loss = 0.09718279\n",
      "Iteration 461, loss = 0.09683865\n",
      "Iteration 462, loss = 0.09650064\n",
      "Iteration 463, loss = 0.09616693\n",
      "Iteration 464, loss = 0.09583753\n",
      "Iteration 465, loss = 0.09551228\n",
      "Iteration 466, loss = 0.09518940\n",
      "Iteration 467, loss = 0.09487475\n",
      "Iteration 468, loss = 0.09455190\n",
      "Iteration 469, loss = 0.09423342\n",
      "Iteration 470, loss = 0.09391299\n",
      "Iteration 471, loss = 0.09360496\n",
      "Iteration 472, loss = 0.09328848\n",
      "Iteration 473, loss = 0.09297735\n",
      "Iteration 474, loss = 0.09266644\n",
      "Iteration 475, loss = 0.09235735\n",
      "Iteration 476, loss = 0.09205634\n",
      "Iteration 477, loss = 0.09175200\n",
      "Iteration 478, loss = 0.09144960\n",
      "Iteration 479, loss = 0.09115149\n",
      "Iteration 480, loss = 0.09085929\n",
      "Iteration 481, loss = 0.09057146\n",
      "Iteration 482, loss = 0.09027114\n",
      "Iteration 483, loss = 0.08998711\n",
      "Iteration 484, loss = 0.08969718\n",
      "Iteration 485, loss = 0.08940885\n",
      "Iteration 486, loss = 0.08911878\n",
      "Iteration 487, loss = 0.08882792\n",
      "Iteration 488, loss = 0.08855221\n",
      "Iteration 489, loss = 0.08827151\n",
      "Iteration 490, loss = 0.08798988\n",
      "Iteration 491, loss = 0.08772154\n",
      "Iteration 492, loss = 0.08744127\n",
      "Iteration 493, loss = 0.08716617\n",
      "Iteration 494, loss = 0.08689118\n",
      "Iteration 495, loss = 0.08661859\n",
      "Iteration 496, loss = 0.08635359\n",
      "Iteration 497, loss = 0.08608672\n",
      "Iteration 498, loss = 0.08583959\n",
      "Iteration 499, loss = 0.08555472\n",
      "Iteration 500, loss = 0.08528989\n",
      "Iteration 501, loss = 0.08504044\n",
      "Iteration 502, loss = 0.08476608\n",
      "Iteration 503, loss = 0.08451083\n",
      "Iteration 504, loss = 0.08425015\n",
      "Iteration 505, loss = 0.08399851\n",
      "Iteration 506, loss = 0.08374015\n",
      "Iteration 507, loss = 0.08348690\n",
      "Iteration 508, loss = 0.08324070\n",
      "Iteration 509, loss = 0.08298932\n",
      "Iteration 510, loss = 0.08273726\n",
      "Iteration 511, loss = 0.08249429\n",
      "Iteration 512, loss = 0.08224489\n",
      "Iteration 513, loss = 0.08200842\n",
      "Iteration 514, loss = 0.08176491\n",
      "Iteration 515, loss = 0.08151745\n",
      "Iteration 516, loss = 0.08127991\n",
      "Iteration 517, loss = 0.08103511\n",
      "Iteration 518, loss = 0.08079681\n",
      "Iteration 519, loss = 0.08055718\n",
      "Iteration 520, loss = 0.08032262\n",
      "Iteration 521, loss = 0.08009348\n",
      "Iteration 522, loss = 0.07985214\n",
      "Iteration 523, loss = 0.07962591\n",
      "Iteration 524, loss = 0.07939259\n",
      "Iteration 525, loss = 0.07916476\n",
      "Iteration 526, loss = 0.07894247\n",
      "Iteration 527, loss = 0.07871821\n",
      "Iteration 528, loss = 0.07849468\n",
      "Iteration 529, loss = 0.07827654\n",
      "Iteration 530, loss = 0.07805414\n",
      "Iteration 531, loss = 0.07783702\n",
      "Iteration 532, loss = 0.07761764\n",
      "Iteration 533, loss = 0.07740199\n",
      "Iteration 534, loss = 0.07718810\n",
      "Iteration 535, loss = 0.07697968\n",
      "Iteration 536, loss = 0.07676678\n",
      "Iteration 537, loss = 0.07655956\n",
      "Iteration 538, loss = 0.07635345\n",
      "Iteration 539, loss = 0.07614694\n",
      "Iteration 540, loss = 0.07594481\n",
      "Iteration 541, loss = 0.07574515\n",
      "Iteration 542, loss = 0.07554297\n",
      "Iteration 543, loss = 0.07534611\n",
      "Iteration 544, loss = 0.07515068\n",
      "Iteration 545, loss = 0.07495487\n",
      "Iteration 546, loss = 0.07475547\n",
      "Iteration 547, loss = 0.07456133\n",
      "Iteration 548, loss = 0.07436891\n",
      "Iteration 549, loss = 0.07417407\n",
      "Iteration 550, loss = 0.07398018\n",
      "Iteration 551, loss = 0.07378739\n",
      "Iteration 552, loss = 0.07360044\n",
      "Iteration 553, loss = 0.07340928\n",
      "Iteration 554, loss = 0.07322594\n",
      "Iteration 555, loss = 0.07304033\n",
      "Iteration 556, loss = 0.07286175\n",
      "Iteration 557, loss = 0.07267911\n",
      "Iteration 558, loss = 0.07250559\n",
      "Iteration 559, loss = 0.07232140\n",
      "Iteration 560, loss = 0.07214550\n",
      "Iteration 561, loss = 0.07196767\n",
      "Iteration 562, loss = 0.07178997\n",
      "Iteration 563, loss = 0.07161394\n",
      "Iteration 564, loss = 0.07143635\n",
      "Iteration 565, loss = 0.07126619\n",
      "Iteration 566, loss = 0.07108654\n",
      "Iteration 567, loss = 0.07091237\n",
      "Iteration 568, loss = 0.07073953\n",
      "Iteration 569, loss = 0.07057093\n",
      "Iteration 570, loss = 0.07040003\n",
      "Iteration 571, loss = 0.07022978\n",
      "Iteration 572, loss = 0.07006156\n",
      "Iteration 573, loss = 0.06989938\n",
      "Iteration 574, loss = 0.06973072\n",
      "Iteration 575, loss = 0.06956128\n",
      "Iteration 576, loss = 0.06939244\n",
      "Iteration 577, loss = 0.06923000\n",
      "Iteration 578, loss = 0.06906380\n",
      "Iteration 579, loss = 0.06890235\n",
      "Iteration 580, loss = 0.06873753\n",
      "Iteration 581, loss = 0.06858100\n",
      "Iteration 582, loss = 0.06841974\n",
      "Iteration 583, loss = 0.06826147\n",
      "Iteration 584, loss = 0.06810376\n",
      "Iteration 585, loss = 0.06795561\n",
      "Iteration 586, loss = 0.06779463\n",
      "Iteration 587, loss = 0.06763522\n",
      "Iteration 588, loss = 0.06747882\n",
      "Iteration 589, loss = 0.06732349\n",
      "Iteration 590, loss = 0.06716741\n",
      "Iteration 591, loss = 0.06701486\n",
      "Iteration 592, loss = 0.06685713\n",
      "Iteration 593, loss = 0.06671138\n",
      "Iteration 594, loss = 0.06655717\n",
      "Iteration 595, loss = 0.06640629\n",
      "Iteration 596, loss = 0.06625520\n",
      "Iteration 597, loss = 0.06610556\n",
      "Iteration 598, loss = 0.06595775\n",
      "Iteration 599, loss = 0.06581255\n",
      "Iteration 600, loss = 0.06566530\n",
      "Iteration 601, loss = 0.06551838\n",
      "Iteration 602, loss = 0.06537324\n",
      "Iteration 603, loss = 0.06522713\n",
      "Iteration 604, loss = 0.06508072\n",
      "Iteration 605, loss = 0.06493346\n",
      "Iteration 606, loss = 0.06478920\n",
      "Iteration 607, loss = 0.06464147\n",
      "Iteration 608, loss = 0.06450357\n",
      "Iteration 609, loss = 0.06435683\n",
      "Iteration 610, loss = 0.06421735\n",
      "Iteration 611, loss = 0.06407037\n",
      "Iteration 612, loss = 0.06392799\n",
      "Iteration 613, loss = 0.06378483\n",
      "Iteration 614, loss = 0.06364608\n",
      "Iteration 615, loss = 0.06350269\n",
      "Iteration 616, loss = 0.06336016\n",
      "Iteration 617, loss = 0.06322566\n",
      "Iteration 618, loss = 0.06309515\n",
      "Iteration 619, loss = 0.06295081\n",
      "Iteration 620, loss = 0.06281201\n",
      "Iteration 621, loss = 0.06267893\n",
      "Iteration 622, loss = 0.06254778\n",
      "Iteration 623, loss = 0.06241935\n",
      "Iteration 624, loss = 0.06228855\n",
      "Iteration 625, loss = 0.06215272\n",
      "Iteration 626, loss = 0.06202113\n",
      "Iteration 627, loss = 0.06188765\n",
      "Iteration 628, loss = 0.06175431\n",
      "Iteration 629, loss = 0.06162399\n",
      "Iteration 630, loss = 0.06149081\n",
      "Iteration 631, loss = 0.06136009\n",
      "Iteration 632, loss = 0.06123450\n",
      "Iteration 633, loss = 0.06110349\n",
      "Iteration 634, loss = 0.06097809\n",
      "Iteration 635, loss = 0.06085015\n",
      "Iteration 636, loss = 0.06072648\n",
      "Iteration 637, loss = 0.06059776\n",
      "Iteration 638, loss = 0.06047209\n",
      "Iteration 639, loss = 0.06034638\n",
      "Iteration 640, loss = 0.06022292\n",
      "Iteration 641, loss = 0.06009679\n",
      "Iteration 642, loss = 0.05997611\n",
      "Iteration 643, loss = 0.05984659\n",
      "Iteration 644, loss = 0.05972611\n",
      "Iteration 645, loss = 0.05960120\n",
      "Iteration 646, loss = 0.05947631\n",
      "Iteration 647, loss = 0.05935216\n",
      "Iteration 648, loss = 0.05923087\n",
      "Iteration 649, loss = 0.05910899\n",
      "Iteration 650, loss = 0.05899004\n",
      "Iteration 651, loss = 0.05887868\n",
      "Iteration 652, loss = 0.05875718\n",
      "Iteration 653, loss = 0.05864295\n",
      "Iteration 654, loss = 0.05852461\n",
      "Iteration 655, loss = 0.05841289\n",
      "Iteration 656, loss = 0.05829582\n",
      "Iteration 657, loss = 0.05817824\n",
      "Iteration 658, loss = 0.05806401\n",
      "Iteration 659, loss = 0.05795109\n",
      "Iteration 660, loss = 0.05783624\n",
      "Iteration 661, loss = 0.05772784\n",
      "Iteration 662, loss = 0.05761540\n",
      "Iteration 663, loss = 0.05750819\n",
      "Iteration 664, loss = 0.05739442\n",
      "Iteration 665, loss = 0.05728743\n",
      "Iteration 666, loss = 0.05717964\n",
      "Iteration 667, loss = 0.05707119\n",
      "Iteration 668, loss = 0.05696422\n",
      "Iteration 669, loss = 0.05685734\n",
      "Iteration 670, loss = 0.05675048\n",
      "Iteration 671, loss = 0.05664812\n",
      "Iteration 672, loss = 0.05653820\n",
      "Iteration 673, loss = 0.05643212\n",
      "Iteration 674, loss = 0.05632670\n",
      "Iteration 675, loss = 0.05622344\n",
      "Iteration 676, loss = 0.05611782\n",
      "Iteration 677, loss = 0.05601279\n",
      "Iteration 678, loss = 0.05590683\n",
      "Iteration 679, loss = 0.05580956\n",
      "Iteration 680, loss = 0.05570311\n",
      "Iteration 681, loss = 0.05560013\n",
      "Iteration 682, loss = 0.05549813\n",
      "Iteration 683, loss = 0.05539424\n",
      "Iteration 684, loss = 0.05529228\n",
      "Iteration 685, loss = 0.05519013\n",
      "Iteration 686, loss = 0.05508614\n",
      "Iteration 687, loss = 0.05499052\n",
      "Iteration 688, loss = 0.05488469\n",
      "Iteration 689, loss = 0.05478320\n",
      "Iteration 690, loss = 0.05468516\n",
      "Iteration 691, loss = 0.05458187\n",
      "Iteration 692, loss = 0.05448575\n",
      "Iteration 693, loss = 0.05438144\n",
      "Iteration 694, loss = 0.05428682\n",
      "Iteration 695, loss = 0.05418412\n",
      "Iteration 696, loss = 0.05408520\n",
      "Iteration 697, loss = 0.05398816\n",
      "Iteration 698, loss = 0.05389139\n",
      "Iteration 699, loss = 0.05380020\n",
      "Iteration 700, loss = 0.05370049\n",
      "Iteration 701, loss = 0.05360680\n",
      "Iteration 702, loss = 0.05351176\n",
      "Iteration 703, loss = 0.05342392\n",
      "Iteration 704, loss = 0.05332149\n",
      "Iteration 705, loss = 0.05322783\n",
      "Iteration 706, loss = 0.05314021\n",
      "Iteration 707, loss = 0.05304827\n",
      "Iteration 708, loss = 0.05295685\n",
      "Iteration 709, loss = 0.05286441\n",
      "Iteration 710, loss = 0.05277285\n",
      "Iteration 711, loss = 0.05268471\n",
      "Iteration 712, loss = 0.05259427\n",
      "Iteration 713, loss = 0.05250047\n",
      "Iteration 714, loss = 0.05241273\n",
      "Iteration 715, loss = 0.05231730\n",
      "Iteration 716, loss = 0.05222763\n",
      "Iteration 717, loss = 0.05213354\n",
      "Iteration 718, loss = 0.05204161\n",
      "Iteration 719, loss = 0.05196303\n",
      "Iteration 720, loss = 0.05186455\n",
      "Iteration 721, loss = 0.05177297\n",
      "Iteration 722, loss = 0.05168276\n",
      "Iteration 723, loss = 0.05159102\n",
      "Iteration 724, loss = 0.05150362\n",
      "Iteration 725, loss = 0.05141545\n",
      "Iteration 726, loss = 0.05132477\n",
      "Iteration 727, loss = 0.05123865\n",
      "Iteration 728, loss = 0.05115881\n",
      "Iteration 729, loss = 0.05106786\n",
      "Iteration 730, loss = 0.05098160\n",
      "Iteration 731, loss = 0.05089497\n",
      "Iteration 732, loss = 0.05080801\n",
      "Iteration 733, loss = 0.05072589\n",
      "Iteration 734, loss = 0.05063851\n",
      "Iteration 735, loss = 0.05055452\n",
      "Iteration 736, loss = 0.05047682\n",
      "Iteration 737, loss = 0.05039655\n",
      "Iteration 738, loss = 0.05030678\n",
      "Iteration 739, loss = 0.05022534\n",
      "Iteration 740, loss = 0.05014540\n",
      "Iteration 741, loss = 0.05005596\n",
      "Iteration 742, loss = 0.04996764\n",
      "Iteration 743, loss = 0.04988721\n",
      "Iteration 744, loss = 0.04980243\n",
      "Iteration 745, loss = 0.04971956\n",
      "Iteration 746, loss = 0.04963881\n",
      "Iteration 747, loss = 0.04955376\n",
      "Iteration 748, loss = 0.04947686\n",
      "Iteration 749, loss = 0.04938948\n",
      "Iteration 750, loss = 0.04931164\n",
      "Iteration 751, loss = 0.04923004\n",
      "Iteration 752, loss = 0.04914751\n",
      "Iteration 753, loss = 0.04907036\n",
      "Iteration 754, loss = 0.04899260\n",
      "Iteration 755, loss = 0.04891567\n",
      "Iteration 756, loss = 0.04883706\n",
      "Iteration 757, loss = 0.04875865\n",
      "Iteration 758, loss = 0.04868632\n",
      "Iteration 759, loss = 0.04860920\n",
      "Iteration 760, loss = 0.04854157\n",
      "Iteration 761, loss = 0.04846396\n",
      "Iteration 762, loss = 0.04839154\n",
      "Iteration 763, loss = 0.04831475\n",
      "Iteration 764, loss = 0.04824041\n",
      "Iteration 765, loss = 0.04816681\n",
      "Iteration 766, loss = 0.04809278\n",
      "Iteration 767, loss = 0.04801670\n",
      "Iteration 768, loss = 0.04794465\n",
      "Iteration 769, loss = 0.04786945\n",
      "Iteration 770, loss = 0.04779356\n",
      "Iteration 771, loss = 0.04772017\n",
      "Iteration 772, loss = 0.04764464\n",
      "Iteration 773, loss = 0.04757174\n",
      "Iteration 774, loss = 0.04749746\n",
      "Iteration 775, loss = 0.04742107\n",
      "Iteration 776, loss = 0.04735039\n",
      "Iteration 777, loss = 0.04727916\n",
      "Iteration 778, loss = 0.04720445\n",
      "Iteration 779, loss = 0.04713562\n",
      "Iteration 780, loss = 0.04706325\n",
      "Iteration 781, loss = 0.04698515\n",
      "Iteration 782, loss = 0.04691467\n",
      "Iteration 783, loss = 0.04683961\n",
      "Iteration 784, loss = 0.04676876\n",
      "Iteration 785, loss = 0.04669346\n",
      "Iteration 786, loss = 0.04662427\n",
      "Iteration 787, loss = 0.04655195\n",
      "Iteration 788, loss = 0.04647945\n",
      "Iteration 789, loss = 0.04640576\n",
      "Iteration 790, loss = 0.04633919\n",
      "Iteration 791, loss = 0.04626882\n",
      "Iteration 792, loss = 0.04619986\n",
      "Iteration 793, loss = 0.04613062\n",
      "Iteration 794, loss = 0.04606190\n",
      "Iteration 795, loss = 0.04599439\n",
      "Iteration 796, loss = 0.04592815\n",
      "Iteration 797, loss = 0.04586216\n",
      "Iteration 798, loss = 0.04579262\n",
      "Iteration 799, loss = 0.04572566\n",
      "Iteration 800, loss = 0.04566200\n",
      "Iteration 801, loss = 0.04559019\n",
      "Iteration 802, loss = 0.04552273\n",
      "Iteration 803, loss = 0.04545719\n",
      "Iteration 804, loss = 0.04538910\n",
      "Iteration 805, loss = 0.04532429\n",
      "Iteration 806, loss = 0.04526111\n",
      "Iteration 807, loss = 0.04519680\n",
      "Iteration 808, loss = 0.04513179\n",
      "Iteration 809, loss = 0.04506805\n",
      "Iteration 810, loss = 0.04500488\n",
      "Iteration 811, loss = 0.04494126\n",
      "Iteration 812, loss = 0.04487216\n",
      "Iteration 813, loss = 0.04481089\n",
      "Iteration 814, loss = 0.04474332\n",
      "Iteration 815, loss = 0.04467863\n",
      "Iteration 816, loss = 0.04461122\n",
      "Iteration 817, loss = 0.04454580\n",
      "Iteration 818, loss = 0.04448350\n",
      "Iteration 819, loss = 0.04441403\n",
      "Iteration 820, loss = 0.04435051\n",
      "Iteration 821, loss = 0.04428239\n",
      "Iteration 822, loss = 0.04421885\n",
      "Iteration 823, loss = 0.04415594\n",
      "Iteration 824, loss = 0.04409041\n",
      "Iteration 825, loss = 0.04402350\n",
      "Iteration 826, loss = 0.04395912\n",
      "Iteration 827, loss = 0.04390300\n",
      "Iteration 828, loss = 0.04382906\n",
      "Iteration 829, loss = 0.04377006\n",
      "Iteration 830, loss = 0.04370631\n",
      "Iteration 831, loss = 0.04364396\n",
      "Iteration 832, loss = 0.04358436\n",
      "Iteration 833, loss = 0.04352350\n",
      "Iteration 834, loss = 0.04346148\n",
      "Iteration 835, loss = 0.04340080\n",
      "Iteration 836, loss = 0.04334149\n",
      "Iteration 837, loss = 0.04328275\n",
      "Iteration 838, loss = 0.04322104\n",
      "Iteration 839, loss = 0.04316208\n",
      "Iteration 840, loss = 0.04310418\n",
      "Iteration 841, loss = 0.04304501\n",
      "Iteration 842, loss = 0.04298552\n",
      "Iteration 843, loss = 0.04292735\n",
      "Iteration 844, loss = 0.04286904\n",
      "Iteration 845, loss = 0.04281165\n",
      "Iteration 846, loss = 0.04275498\n",
      "Iteration 847, loss = 0.04269756\n",
      "Iteration 848, loss = 0.04264027\n",
      "Iteration 849, loss = 0.04258212\n",
      "Iteration 850, loss = 0.04252792\n",
      "Iteration 851, loss = 0.04246871\n",
      "Iteration 852, loss = 0.04241240\n",
      "Iteration 853, loss = 0.04235592\n",
      "Iteration 854, loss = 0.04229926\n",
      "Iteration 855, loss = 0.04224116\n",
      "Iteration 856, loss = 0.04218301\n",
      "Iteration 857, loss = 0.04213009\n",
      "Iteration 858, loss = 0.04207248\n",
      "Iteration 859, loss = 0.04201714\n",
      "Iteration 860, loss = 0.04196232\n",
      "Iteration 861, loss = 0.04190479\n",
      "Iteration 862, loss = 0.04184997\n",
      "Iteration 863, loss = 0.04179138\n",
      "Iteration 864, loss = 0.04173454\n",
      "Iteration 865, loss = 0.04167552\n",
      "Iteration 866, loss = 0.04162152\n",
      "Iteration 867, loss = 0.04156551\n",
      "Iteration 868, loss = 0.04151032\n",
      "Iteration 869, loss = 0.04145719\n",
      "Iteration 870, loss = 0.04140540\n",
      "Iteration 871, loss = 0.04135483\n",
      "Iteration 872, loss = 0.04129942\n",
      "Iteration 873, loss = 0.04124294\n",
      "Iteration 874, loss = 0.04118958\n",
      "Iteration 875, loss = 0.04113580\n",
      "Iteration 876, loss = 0.04107989\n",
      "Iteration 877, loss = 0.04103323\n",
      "Iteration 878, loss = 0.04097406\n",
      "Iteration 879, loss = 0.04091948\n",
      "Iteration 880, loss = 0.04086539\n",
      "Iteration 881, loss = 0.04081344\n",
      "Iteration 882, loss = 0.04075807\n",
      "Iteration 883, loss = 0.04070476\n",
      "Iteration 884, loss = 0.04064906\n",
      "Iteration 885, loss = 0.04059541\n",
      "Iteration 886, loss = 0.04054233\n",
      "Iteration 887, loss = 0.04048975\n",
      "Iteration 888, loss = 0.04043988\n",
      "Iteration 889, loss = 0.04038285\n",
      "Iteration 890, loss = 0.04032945\n",
      "Iteration 891, loss = 0.04027616\n",
      "Iteration 892, loss = 0.04022103\n",
      "Iteration 893, loss = 0.04016776\n",
      "Iteration 894, loss = 0.04011563\n",
      "Iteration 895, loss = 0.04005948\n",
      "Iteration 896, loss = 0.04000705\n",
      "Iteration 897, loss = 0.03995684\n",
      "Iteration 898, loss = 0.03990230\n",
      "Iteration 899, loss = 0.03984921\n",
      "Iteration 900, loss = 0.03979678\n",
      "Iteration 901, loss = 0.03974684\n",
      "Iteration 902, loss = 0.03969539\n",
      "Iteration 903, loss = 0.03964318\n",
      "Iteration 904, loss = 0.03959747\n",
      "Iteration 905, loss = 0.03953934\n",
      "Iteration 906, loss = 0.03948849\n",
      "Iteration 907, loss = 0.03943614\n",
      "Iteration 908, loss = 0.03938580\n",
      "Iteration 909, loss = 0.03933651\n",
      "Iteration 910, loss = 0.03928528\n",
      "Iteration 911, loss = 0.03923540\n",
      "Iteration 912, loss = 0.03918707\n",
      "Iteration 913, loss = 0.03913689\n",
      "Iteration 914, loss = 0.03908830\n",
      "Iteration 915, loss = 0.03904243\n",
      "Iteration 916, loss = 0.03899088\n",
      "Iteration 917, loss = 0.03894184\n",
      "Iteration 918, loss = 0.03889529\n",
      "Iteration 919, loss = 0.03884302\n",
      "Iteration 920, loss = 0.03879826\n",
      "Iteration 921, loss = 0.03874740\n",
      "Iteration 922, loss = 0.03869612\n",
      "Iteration 923, loss = 0.03864815\n",
      "Iteration 924, loss = 0.03860191\n",
      "Iteration 925, loss = 0.03855179\n",
      "Iteration 926, loss = 0.03850332\n",
      "Iteration 927, loss = 0.03845417\n",
      "Iteration 928, loss = 0.03840718\n",
      "Iteration 929, loss = 0.03836240\n",
      "Iteration 930, loss = 0.03831378\n",
      "Iteration 931, loss = 0.03826433\n",
      "Iteration 932, loss = 0.03821542\n",
      "Iteration 933, loss = 0.03816871\n",
      "Iteration 934, loss = 0.03812445\n",
      "Iteration 935, loss = 0.03807890\n",
      "Iteration 936, loss = 0.03803242\n",
      "Iteration 937, loss = 0.03799252\n",
      "Iteration 938, loss = 0.03794492\n",
      "Iteration 939, loss = 0.03790008\n",
      "Iteration 940, loss = 0.03785255\n",
      "Iteration 941, loss = 0.03780182\n",
      "Iteration 942, loss = 0.03776044\n",
      "Iteration 943, loss = 0.03771074\n",
      "Iteration 944, loss = 0.03766978\n",
      "Iteration 945, loss = 0.03762067\n",
      "Iteration 946, loss = 0.03757792\n",
      "Iteration 947, loss = 0.03753305\n",
      "Iteration 948, loss = 0.03748701\n",
      "Iteration 949, loss = 0.03744278\n",
      "Iteration 950, loss = 0.03739757\n",
      "Iteration 951, loss = 0.03734986\n",
      "Iteration 952, loss = 0.03730249\n",
      "Iteration 953, loss = 0.03725780\n",
      "Iteration 954, loss = 0.03721227\n",
      "Iteration 955, loss = 0.03716625\n",
      "Iteration 956, loss = 0.03712377\n",
      "Iteration 957, loss = 0.03707881\n",
      "Iteration 958, loss = 0.03703411\n",
      "Iteration 959, loss = 0.03699111\n",
      "Iteration 960, loss = 0.03694926\n",
      "Iteration 961, loss = 0.03690235\n",
      "Iteration 962, loss = 0.03685919\n",
      "Iteration 963, loss = 0.03681587\n",
      "Iteration 964, loss = 0.03677341\n",
      "Iteration 965, loss = 0.03673050\n",
      "Iteration 966, loss = 0.03668740\n",
      "Iteration 967, loss = 0.03664584\n",
      "Iteration 968, loss = 0.03660403\n",
      "Iteration 969, loss = 0.03655867\n",
      "Iteration 970, loss = 0.03651630\n",
      "Iteration 971, loss = 0.03647304\n",
      "Iteration 972, loss = 0.03642762\n",
      "Iteration 973, loss = 0.03638370\n",
      "Iteration 974, loss = 0.03634316\n",
      "Iteration 975, loss = 0.03630036\n",
      "Iteration 976, loss = 0.03625731\n",
      "Iteration 977, loss = 0.03621325\n",
      "Iteration 978, loss = 0.03617169\n",
      "Iteration 979, loss = 0.03612981\n",
      "Iteration 980, loss = 0.03608859\n",
      "Iteration 981, loss = 0.03604744\n",
      "Iteration 982, loss = 0.03600597\n",
      "Iteration 983, loss = 0.03596561\n",
      "Iteration 984, loss = 0.03592575\n",
      "Iteration 985, loss = 0.03588427\n",
      "Iteration 986, loss = 0.03584383\n",
      "Iteration 987, loss = 0.03580354\n",
      "Iteration 988, loss = 0.03576738\n",
      "Iteration 989, loss = 0.03572495\n",
      "Iteration 990, loss = 0.03569163\n",
      "Iteration 991, loss = 0.03564988\n",
      "Iteration 992, loss = 0.03560737\n",
      "Iteration 993, loss = 0.03556651\n",
      "Iteration 994, loss = 0.03552667\n",
      "Iteration 995, loss = 0.03548399\n",
      "Iteration 996, loss = 0.03544463\n",
      "Iteration 997, loss = 0.03540456\n",
      "Iteration 998, loss = 0.03536446\n",
      "Iteration 999, loss = 0.03532388\n",
      "Iteration 1000, loss = 0.03528408\n",
      "Iteration 1001, loss = 0.03524785\n",
      "Iteration 1002, loss = 0.03520654\n",
      "Iteration 1003, loss = 0.03516620\n",
      "Iteration 1004, loss = 0.03512874\n",
      "Iteration 1005, loss = 0.03509012\n",
      "Iteration 1006, loss = 0.03505225\n",
      "Iteration 1007, loss = 0.03501542\n",
      "Iteration 1008, loss = 0.03497485\n",
      "Iteration 1009, loss = 0.03493696\n",
      "Iteration 1010, loss = 0.03489943\n",
      "Iteration 1011, loss = 0.03485964\n",
      "Iteration 1012, loss = 0.03482318\n",
      "Iteration 1013, loss = 0.03478136\n",
      "Iteration 1014, loss = 0.03474552\n",
      "Iteration 1015, loss = 0.03470698\n",
      "Iteration 1016, loss = 0.03467037\n",
      "Iteration 1017, loss = 0.03463211\n",
      "Iteration 1018, loss = 0.03459507\n",
      "Iteration 1019, loss = 0.03455758\n",
      "Iteration 1020, loss = 0.03452190\n",
      "Iteration 1021, loss = 0.03448403\n",
      "Iteration 1022, loss = 0.03445069\n",
      "Iteration 1023, loss = 0.03440893\n",
      "Iteration 1024, loss = 0.03437014\n",
      "Iteration 1025, loss = 0.03433119\n",
      "Iteration 1026, loss = 0.03429256\n",
      "Iteration 1027, loss = 0.03425514\n",
      "Iteration 1028, loss = 0.03421805\n",
      "Iteration 1029, loss = 0.03418063\n",
      "Iteration 1030, loss = 0.03414169\n",
      "Iteration 1031, loss = 0.03410397\n",
      "Iteration 1032, loss = 0.03406802\n",
      "Iteration 1033, loss = 0.03403026\n",
      "Iteration 1034, loss = 0.03399170\n",
      "Iteration 1035, loss = 0.03395303\n",
      "Iteration 1036, loss = 0.03391583\n",
      "Iteration 1037, loss = 0.03387877\n",
      "Iteration 1038, loss = 0.03384050\n",
      "Iteration 1039, loss = 0.03380688\n",
      "Iteration 1040, loss = 0.03376359\n",
      "Iteration 1041, loss = 0.03372954\n",
      "Iteration 1042, loss = 0.03368771\n",
      "Iteration 1043, loss = 0.03365305\n",
      "Iteration 1044, loss = 0.03361631\n",
      "Iteration 1045, loss = 0.03357876\n",
      "Iteration 1046, loss = 0.03354525\n",
      "Iteration 1047, loss = 0.03350850\n",
      "Iteration 1048, loss = 0.03347248\n",
      "Iteration 1049, loss = 0.03343816\n",
      "Iteration 1050, loss = 0.03340080\n",
      "Iteration 1051, loss = 0.03336410\n",
      "Iteration 1052, loss = 0.03332842\n",
      "Iteration 1053, loss = 0.03329490\n",
      "Iteration 1054, loss = 0.03325781\n",
      "Iteration 1055, loss = 0.03322231\n",
      "Iteration 1056, loss = 0.03318611\n",
      "Iteration 1057, loss = 0.03315285\n",
      "Iteration 1058, loss = 0.03311845\n",
      "Iteration 1059, loss = 0.03308563\n",
      "Iteration 1060, loss = 0.03305018\n",
      "Iteration 1061, loss = 0.03301610\n",
      "Iteration 1062, loss = 0.03297896\n",
      "Iteration 1063, loss = 0.03294441\n",
      "Iteration 1064, loss = 0.03290909\n",
      "Iteration 1065, loss = 0.03287586\n",
      "Iteration 1066, loss = 0.03284193\n",
      "Iteration 1067, loss = 0.03280509\n",
      "Iteration 1068, loss = 0.03277422\n",
      "Iteration 1069, loss = 0.03274111\n",
      "Iteration 1070, loss = 0.03270917\n",
      "Iteration 1071, loss = 0.03267639\n",
      "Iteration 1072, loss = 0.03264340\n",
      "Iteration 1073, loss = 0.03261017\n",
      "Iteration 1074, loss = 0.03257842\n",
      "Iteration 1075, loss = 0.03254489\n",
      "Iteration 1076, loss = 0.03251190\n",
      "Iteration 1077, loss = 0.03248362\n",
      "Iteration 1078, loss = 0.03244591\n",
      "Iteration 1079, loss = 0.03241298\n",
      "Iteration 1080, loss = 0.03237911\n",
      "Iteration 1081, loss = 0.03234656\n",
      "Iteration 1082, loss = 0.03231027\n",
      "Iteration 1083, loss = 0.03227463\n",
      "Iteration 1084, loss = 0.03224039\n",
      "Iteration 1085, loss = 0.03220752\n",
      "Iteration 1086, loss = 0.03217478\n",
      "Iteration 1087, loss = 0.03214329\n",
      "Iteration 1088, loss = 0.03211066\n",
      "Iteration 1089, loss = 0.03207681\n",
      "Iteration 1090, loss = 0.03204453\n",
      "Iteration 1091, loss = 0.03201204\n",
      "Iteration 1092, loss = 0.03197923\n",
      "Iteration 1093, loss = 0.03194701\n",
      "Iteration 1094, loss = 0.03191489\n",
      "Iteration 1095, loss = 0.03188037\n",
      "Iteration 1096, loss = 0.03185059\n",
      "Iteration 1097, loss = 0.03181756\n",
      "Iteration 1098, loss = 0.03178314\n",
      "Iteration 1099, loss = 0.03174749\n",
      "Iteration 1100, loss = 0.03171691\n",
      "Iteration 1101, loss = 0.03168192\n",
      "Iteration 1102, loss = 0.03165206\n",
      "Iteration 1103, loss = 0.03162079\n",
      "Iteration 1104, loss = 0.03158813\n",
      "Iteration 1105, loss = 0.03155936\n",
      "Iteration 1106, loss = 0.03152870\n",
      "Iteration 1107, loss = 0.03149796\n",
      "Iteration 1108, loss = 0.03146628\n",
      "Iteration 1109, loss = 0.03143704\n",
      "Iteration 1110, loss = 0.03140863\n",
      "Iteration 1111, loss = 0.03137553\n",
      "Iteration 1112, loss = 0.03134296\n",
      "Iteration 1113, loss = 0.03131267\n",
      "Iteration 1114, loss = 0.03127878\n",
      "Iteration 1115, loss = 0.03124688\n",
      "Iteration 1116, loss = 0.03121678\n",
      "Iteration 1117, loss = 0.03118187\n",
      "Iteration 1118, loss = 0.03115411\n",
      "Iteration 1119, loss = 0.03112184\n",
      "Iteration 1120, loss = 0.03109160\n",
      "Iteration 1121, loss = 0.03106068\n",
      "Iteration 1122, loss = 0.03103304\n",
      "Iteration 1123, loss = 0.03100157\n",
      "Iteration 1124, loss = 0.03096983\n",
      "Iteration 1125, loss = 0.03094167\n",
      "Iteration 1126, loss = 0.03091037\n",
      "Iteration 1127, loss = 0.03088073\n",
      "Iteration 1128, loss = 0.03084912\n",
      "Iteration 1129, loss = 0.03081958\n",
      "Iteration 1130, loss = 0.03078914\n",
      "Iteration 1131, loss = 0.03076029\n",
      "Iteration 1132, loss = 0.03073303\n",
      "Iteration 1133, loss = 0.03070185\n",
      "Iteration 1134, loss = 0.03067286\n",
      "Iteration 1135, loss = 0.03064231\n",
      "Iteration 1136, loss = 0.03061276\n",
      "Iteration 1137, loss = 0.03058191\n",
      "Iteration 1138, loss = 0.03055348\n",
      "Iteration 1139, loss = 0.03052680\n",
      "Iteration 1140, loss = 0.03049754\n",
      "Iteration 1141, loss = 0.03046910\n",
      "Iteration 1142, loss = 0.03043897\n",
      "Iteration 1143, loss = 0.03040684\n",
      "Iteration 1144, loss = 0.03037708\n",
      "Iteration 1145, loss = 0.03034776\n",
      "Iteration 1146, loss = 0.03032162\n",
      "Iteration 1147, loss = 0.03029456\n",
      "Iteration 1148, loss = 0.03026453\n",
      "Iteration 1149, loss = 0.03023400\n",
      "Iteration 1150, loss = 0.03020468\n",
      "Iteration 1151, loss = 0.03017803\n",
      "Iteration 1152, loss = 0.03014864\n",
      "Iteration 1153, loss = 0.03012016\n",
      "Iteration 1154, loss = 0.03009373\n",
      "Iteration 1155, loss = 0.03006571\n",
      "Iteration 1156, loss = 0.03003838\n",
      "Iteration 1157, loss = 0.03001230\n",
      "Iteration 1158, loss = 0.02998432\n",
      "Iteration 1159, loss = 0.02995825\n",
      "Iteration 1160, loss = 0.02993156\n",
      "Iteration 1161, loss = 0.02990619\n",
      "Iteration 1162, loss = 0.02987840\n",
      "Iteration 1163, loss = 0.02985198\n",
      "Iteration 1164, loss = 0.02982507\n",
      "Iteration 1165, loss = 0.02980026\n",
      "Iteration 1166, loss = 0.02977179\n",
      "Iteration 1167, loss = 0.02974541\n",
      "Iteration 1168, loss = 0.02971901\n",
      "Iteration 1169, loss = 0.02969159\n",
      "Iteration 1170, loss = 0.02966293\n",
      "Iteration 1171, loss = 0.02963451\n",
      "Iteration 1172, loss = 0.02960845\n",
      "Iteration 1173, loss = 0.02957528\n",
      "Iteration 1174, loss = 0.02954816\n",
      "Iteration 1175, loss = 0.02952049\n",
      "Iteration 1176, loss = 0.02949022\n",
      "Iteration 1177, loss = 0.02946129\n",
      "Iteration 1178, loss = 0.02943304\n",
      "Iteration 1179, loss = 0.02940621\n",
      "Iteration 1180, loss = 0.02937669\n",
      "Iteration 1181, loss = 0.02934890\n",
      "Iteration 1182, loss = 0.02932096\n",
      "Iteration 1183, loss = 0.02929329\n",
      "Iteration 1184, loss = 0.02926669\n",
      "Iteration 1185, loss = 0.02923958\n",
      "Iteration 1186, loss = 0.02921441\n",
      "Iteration 1187, loss = 0.02918643\n",
      "Iteration 1188, loss = 0.02915980\n",
      "Iteration 1189, loss = 0.02913323\n",
      "Iteration 1190, loss = 0.02910677\n",
      "Iteration 1191, loss = 0.02908709\n",
      "Iteration 1192, loss = 0.02906193\n",
      "Iteration 1193, loss = 0.02903464\n",
      "Iteration 1194, loss = 0.02901012\n",
      "Iteration 1195, loss = 0.02898323\n",
      "Iteration 1196, loss = 0.02895806\n",
      "Iteration 1197, loss = 0.02893089\n",
      "Iteration 1198, loss = 0.02890300\n",
      "Iteration 1199, loss = 0.02887679\n",
      "Iteration 1200, loss = 0.02885088\n",
      "Iteration 1201, loss = 0.02882335\n",
      "Iteration 1202, loss = 0.02879625\n",
      "Iteration 1203, loss = 0.02877186\n",
      "Iteration 1204, loss = 0.02874458\n",
      "Iteration 1205, loss = 0.02871523\n",
      "Iteration 1206, loss = 0.02868803\n",
      "Iteration 1207, loss = 0.02865934\n",
      "Iteration 1208, loss = 0.02863174\n",
      "Iteration 1209, loss = 0.02860912\n",
      "Iteration 1210, loss = 0.02858244\n",
      "Iteration 1211, loss = 0.02855043\n",
      "Iteration 1212, loss = 0.02852572\n",
      "Iteration 1213, loss = 0.02849560\n",
      "Iteration 1214, loss = 0.02847031\n",
      "Iteration 1215, loss = 0.02844312\n",
      "Iteration 1216, loss = 0.02841713\n",
      "Iteration 1217, loss = 0.02838554\n",
      "Iteration 1218, loss = 0.02836096\n",
      "Iteration 1219, loss = 0.02833323\n",
      "Iteration 1220, loss = 0.02830572\n",
      "Iteration 1221, loss = 0.02828210\n",
      "Iteration 1222, loss = 0.02825373\n",
      "Iteration 1223, loss = 0.02822626\n",
      "Iteration 1224, loss = 0.02820215\n",
      "Iteration 1225, loss = 0.02817078\n",
      "Iteration 1226, loss = 0.02814939\n",
      "Iteration 1227, loss = 0.02812460\n",
      "Iteration 1228, loss = 0.02809354\n",
      "Iteration 1229, loss = 0.02806649\n",
      "Iteration 1230, loss = 0.02804124\n",
      "Iteration 1231, loss = 0.02801446\n",
      "Iteration 1232, loss = 0.02798714\n",
      "Iteration 1233, loss = 0.02796118\n",
      "Iteration 1234, loss = 0.02793614\n",
      "Iteration 1235, loss = 0.02791158\n",
      "Iteration 1236, loss = 0.02788631\n",
      "Iteration 1237, loss = 0.02786560\n",
      "Iteration 1238, loss = 0.02783677\n",
      "Iteration 1239, loss = 0.02781072\n",
      "Iteration 1240, loss = 0.02778956\n",
      "Iteration 1241, loss = 0.02776633\n",
      "Iteration 1242, loss = 0.02773586\n",
      "Iteration 1243, loss = 0.02771573\n",
      "Iteration 1244, loss = 0.02769329\n",
      "Iteration 1245, loss = 0.02766482\n",
      "Iteration 1246, loss = 0.02764110\n",
      "Iteration 1247, loss = 0.02761580\n",
      "Iteration 1248, loss = 0.02759111\n",
      "Iteration 1249, loss = 0.02756551\n",
      "Iteration 1250, loss = 0.02754498\n",
      "Iteration 1251, loss = 0.02751806\n",
      "Iteration 1252, loss = 0.02749420\n",
      "Iteration 1253, loss = 0.02746856\n",
      "Iteration 1254, loss = 0.02744553\n",
      "Iteration 1255, loss = 0.02742291\n",
      "Iteration 1256, loss = 0.02739786\n",
      "Iteration 1257, loss = 0.02737087\n",
      "Iteration 1258, loss = 0.02734594\n",
      "Iteration 1259, loss = 0.02732696\n",
      "Iteration 1260, loss = 0.02729802\n",
      "Iteration 1261, loss = 0.02727607\n",
      "Iteration 1262, loss = 0.02725064\n",
      "Iteration 1263, loss = 0.02722760\n",
      "Iteration 1264, loss = 0.02720410\n",
      "Iteration 1265, loss = 0.02718009\n",
      "Iteration 1266, loss = 0.02715700\n",
      "Iteration 1267, loss = 0.02713422\n",
      "Iteration 1268, loss = 0.02710924\n",
      "Iteration 1269, loss = 0.02708484\n",
      "Iteration 1270, loss = 0.02706052\n",
      "Iteration 1271, loss = 0.02703529\n",
      "Iteration 1272, loss = 0.02701247\n",
      "Iteration 1273, loss = 0.02698865\n",
      "Iteration 1274, loss = 0.02696576\n",
      "Iteration 1275, loss = 0.02694285\n",
      "Iteration 1276, loss = 0.02691980\n",
      "Iteration 1277, loss = 0.02689662\n",
      "Iteration 1278, loss = 0.02687692\n",
      "Iteration 1279, loss = 0.02685358\n",
      "Iteration 1280, loss = 0.02683163\n",
      "Iteration 1281, loss = 0.02680958\n",
      "Iteration 1282, loss = 0.02678561\n",
      "Iteration 1283, loss = 0.02676461\n",
      "Iteration 1284, loss = 0.02674104\n",
      "Iteration 1285, loss = 0.02671944\n",
      "Iteration 1286, loss = 0.02669981\n",
      "Iteration 1287, loss = 0.02667690\n",
      "Iteration 1288, loss = 0.02665337\n",
      "Iteration 1289, loss = 0.02663320\n",
      "Iteration 1290, loss = 0.02661082\n",
      "Iteration 1291, loss = 0.02659045\n",
      "Iteration 1292, loss = 0.02656746\n",
      "Iteration 1293, loss = 0.02654283\n",
      "Iteration 1294, loss = 0.02652105\n",
      "Iteration 1295, loss = 0.02649513\n",
      "Iteration 1296, loss = 0.02647495\n",
      "Iteration 1297, loss = 0.02644640\n",
      "Iteration 1298, loss = 0.02642204\n",
      "Iteration 1299, loss = 0.02639860\n",
      "Iteration 1300, loss = 0.02637474\n",
      "Iteration 1301, loss = 0.02635008\n",
      "Iteration 1302, loss = 0.02632681\n",
      "Iteration 1303, loss = 0.02630558\n",
      "Iteration 1304, loss = 0.02628181\n",
      "Iteration 1305, loss = 0.02625745\n",
      "Iteration 1306, loss = 0.02623381\n",
      "Iteration 1307, loss = 0.02621076\n",
      "Iteration 1308, loss = 0.02618683\n",
      "Iteration 1309, loss = 0.02616552\n",
      "Iteration 1310, loss = 0.02614133\n",
      "Iteration 1311, loss = 0.02611991\n",
      "Iteration 1312, loss = 0.02610079\n",
      "Iteration 1313, loss = 0.02607542\n",
      "Iteration 1314, loss = 0.02605325\n",
      "Iteration 1315, loss = 0.02603113\n",
      "Iteration 1316, loss = 0.02600907\n",
      "Iteration 1317, loss = 0.02598664\n",
      "Iteration 1318, loss = 0.02596584\n",
      "Iteration 1319, loss = 0.02594714\n",
      "Iteration 1320, loss = 0.02591985\n",
      "Iteration 1321, loss = 0.02589711\n",
      "Iteration 1322, loss = 0.02587326\n",
      "Iteration 1323, loss = 0.02585424\n",
      "Iteration 1324, loss = 0.02582976\n",
      "Iteration 1325, loss = 0.02580857\n",
      "Iteration 1326, loss = 0.02578708\n",
      "Iteration 1327, loss = 0.02577092\n",
      "Iteration 1328, loss = 0.02574255\n",
      "Iteration 1329, loss = 0.02572184\n",
      "Iteration 1330, loss = 0.02569897\n",
      "Iteration 1331, loss = 0.02568150\n",
      "Iteration 1332, loss = 0.02565591\n",
      "Iteration 1333, loss = 0.02563248\n",
      "Iteration 1334, loss = 0.02561326\n",
      "Iteration 1335, loss = 0.02559229\n",
      "Iteration 1336, loss = 0.02556815\n",
      "Iteration 1337, loss = 0.02554922\n",
      "Iteration 1338, loss = 0.02552497\n",
      "Iteration 1339, loss = 0.02550448\n",
      "Iteration 1340, loss = 0.02548362\n",
      "Iteration 1341, loss = 0.02546138\n",
      "Iteration 1342, loss = 0.02543939\n",
      "Iteration 1343, loss = 0.02541781\n",
      "Iteration 1344, loss = 0.02540156\n",
      "Iteration 1345, loss = 0.02537816\n",
      "Iteration 1346, loss = 0.02535618\n",
      "Iteration 1347, loss = 0.02533663\n",
      "Iteration 1348, loss = 0.02531581\n",
      "Iteration 1349, loss = 0.02529806\n",
      "Iteration 1350, loss = 0.02527425\n",
      "Iteration 1351, loss = 0.02525245\n",
      "Iteration 1352, loss = 0.02523004\n",
      "Iteration 1353, loss = 0.02520833\n",
      "Iteration 1354, loss = 0.02518739\n",
      "Iteration 1355, loss = 0.02516635\n",
      "Iteration 1356, loss = 0.02514633\n",
      "Iteration 1357, loss = 0.02512527\n",
      "Iteration 1358, loss = 0.02510645\n",
      "Iteration 1359, loss = 0.02508976\n",
      "Iteration 1360, loss = 0.02506329\n",
      "Iteration 1361, loss = 0.02504438\n",
      "Iteration 1362, loss = 0.02502406\n",
      "Iteration 1363, loss = 0.02500180\n",
      "Iteration 1364, loss = 0.02498026\n",
      "Iteration 1365, loss = 0.02495949\n",
      "Iteration 1366, loss = 0.02493900\n",
      "Iteration 1367, loss = 0.02491783\n",
      "Iteration 1368, loss = 0.02489763\n",
      "Iteration 1369, loss = 0.02487672\n",
      "Iteration 1370, loss = 0.02485590\n",
      "Iteration 1371, loss = 0.02483658\n",
      "Iteration 1372, loss = 0.02481617\n",
      "Iteration 1373, loss = 0.02479553\n",
      "Iteration 1374, loss = 0.02477568\n",
      "Iteration 1375, loss = 0.02475535\n",
      "Iteration 1376, loss = 0.02473614\n",
      "Iteration 1377, loss = 0.02471677\n",
      "Iteration 1378, loss = 0.02469974\n",
      "Iteration 1379, loss = 0.02467969\n",
      "Iteration 1380, loss = 0.02466015\n",
      "Iteration 1381, loss = 0.02464041\n",
      "Iteration 1382, loss = 0.02462118\n",
      "Iteration 1383, loss = 0.02460179\n",
      "Iteration 1384, loss = 0.02458209\n",
      "Iteration 1385, loss = 0.02456008\n",
      "Iteration 1386, loss = 0.02453782\n",
      "Iteration 1387, loss = 0.02451906\n",
      "Iteration 1388, loss = 0.02449822\n",
      "Iteration 1389, loss = 0.02447842\n",
      "Iteration 1390, loss = 0.02445908\n",
      "Iteration 1391, loss = 0.02443792\n",
      "Iteration 1392, loss = 0.02441770\n",
      "Iteration 1393, loss = 0.02439790\n",
      "Iteration 1394, loss = 0.02437990\n",
      "Iteration 1395, loss = 0.02436191\n",
      "Iteration 1396, loss = 0.02434538\n",
      "Iteration 1397, loss = 0.02432440\n",
      "Iteration 1398, loss = 0.02430426\n",
      "Iteration 1399, loss = 0.02428643\n",
      "Iteration 1400, loss = 0.02426682\n",
      "Iteration 1401, loss = 0.02424811\n",
      "Iteration 1402, loss = 0.02422596\n",
      "Iteration 1403, loss = 0.02420643\n",
      "Iteration 1404, loss = 0.02418649\n",
      "Iteration 1405, loss = 0.02416867\n",
      "Iteration 1406, loss = 0.02414869\n",
      "Iteration 1407, loss = 0.02412939\n",
      "Iteration 1408, loss = 0.02411322\n",
      "Iteration 1409, loss = 0.02409468\n",
      "Iteration 1410, loss = 0.02407356\n",
      "Iteration 1411, loss = 0.02405509\n",
      "Iteration 1412, loss = 0.02403684\n",
      "Iteration 1413, loss = 0.02402089\n",
      "Iteration 1414, loss = 0.02400034\n",
      "Iteration 1415, loss = 0.02398210\n",
      "Iteration 1416, loss = 0.02396374\n",
      "Iteration 1417, loss = 0.02394493\n",
      "Iteration 1418, loss = 0.02392727\n",
      "Iteration 1419, loss = 0.02390986\n",
      "Iteration 1420, loss = 0.02389243\n",
      "Iteration 1421, loss = 0.02387105\n",
      "Iteration 1422, loss = 0.02385249\n",
      "Iteration 1423, loss = 0.02383378\n",
      "Iteration 1424, loss = 0.02381368\n",
      "Iteration 1425, loss = 0.02379522\n",
      "Iteration 1426, loss = 0.02377714\n",
      "Iteration 1427, loss = 0.02375912\n",
      "Iteration 1428, loss = 0.02374433\n",
      "Iteration 1429, loss = 0.02372139\n",
      "Iteration 1430, loss = 0.02370029\n",
      "Iteration 1431, loss = 0.02368388\n",
      "Iteration 1432, loss = 0.02366475\n",
      "Iteration 1433, loss = 0.02364545\n",
      "Iteration 1434, loss = 0.02362650\n",
      "Iteration 1435, loss = 0.02361165\n",
      "Iteration 1436, loss = 0.02359050\n",
      "Iteration 1437, loss = 0.02357263\n",
      "Iteration 1438, loss = 0.02355510\n",
      "Iteration 1439, loss = 0.02353561\n",
      "Iteration 1440, loss = 0.02352216\n",
      "Iteration 1441, loss = 0.02349992\n",
      "Iteration 1442, loss = 0.02348012\n",
      "Iteration 1443, loss = 0.02346137\n",
      "Iteration 1444, loss = 0.02344434\n",
      "Iteration 1445, loss = 0.02342654\n",
      "Iteration 1446, loss = 0.02340888\n",
      "Iteration 1447, loss = 0.02338802\n",
      "Iteration 1448, loss = 0.02337006\n",
      "Iteration 1449, loss = 0.02335300\n",
      "Iteration 1450, loss = 0.02333507\n",
      "Iteration 1451, loss = 0.02331862\n",
      "Iteration 1452, loss = 0.02330038\n",
      "Iteration 1453, loss = 0.02328222\n",
      "Iteration 1454, loss = 0.02326555\n",
      "Iteration 1455, loss = 0.02324640\n",
      "Iteration 1456, loss = 0.02322880\n",
      "Iteration 1457, loss = 0.02321178\n",
      "Iteration 1458, loss = 0.02319466\n",
      "Iteration 1459, loss = 0.02317688\n",
      "Iteration 1460, loss = 0.02315858\n",
      "Iteration 1461, loss = 0.02314004\n",
      "Iteration 1462, loss = 0.02312426\n",
      "Iteration 1463, loss = 0.02310904\n",
      "Iteration 1464, loss = 0.02308798\n",
      "Iteration 1465, loss = 0.02307014\n",
      "Iteration 1466, loss = 0.02305138\n",
      "Iteration 1467, loss = 0.02303385\n",
      "Iteration 1468, loss = 0.02301693\n",
      "Iteration 1469, loss = 0.02299926\n",
      "Iteration 1470, loss = 0.02298030\n",
      "Iteration 1471, loss = 0.02296387\n",
      "Iteration 1472, loss = 0.02294238\n",
      "Iteration 1473, loss = 0.02292469\n",
      "Iteration 1474, loss = 0.02290937\n",
      "Iteration 1475, loss = 0.02289579\n",
      "Iteration 1476, loss = 0.02287536\n",
      "Iteration 1477, loss = 0.02285923\n",
      "Iteration 1478, loss = 0.02284229\n",
      "Iteration 1479, loss = 0.02282491\n",
      "Iteration 1480, loss = 0.02281135\n",
      "Iteration 1481, loss = 0.02279265\n",
      "Iteration 1482, loss = 0.02277642\n",
      "Iteration 1483, loss = 0.02275815\n",
      "Iteration 1484, loss = 0.02274134\n",
      "Iteration 1485, loss = 0.02272418\n",
      "Iteration 1486, loss = 0.02270641\n",
      "Iteration 1487, loss = 0.02268969\n",
      "Iteration 1488, loss = 0.02267134\n",
      "Iteration 1489, loss = 0.02265516\n",
      "Iteration 1490, loss = 0.02263838\n",
      "Iteration 1491, loss = 0.02262174\n",
      "Iteration 1492, loss = 0.02260451\n",
      "Iteration 1493, loss = 0.02258841\n",
      "Iteration 1494, loss = 0.02257148\n",
      "Iteration 1495, loss = 0.02255536\n",
      "Iteration 1496, loss = 0.02253876\n",
      "Iteration 1497, loss = 0.02252249\n",
      "Iteration 1498, loss = 0.02250590\n",
      "Iteration 1499, loss = 0.02248795\n",
      "Iteration 1500, loss = 0.02246919\n",
      "Iteration 1501, loss = 0.02245418\n",
      "Iteration 1502, loss = 0.02243648\n",
      "Iteration 1503, loss = 0.02241994\n",
      "Iteration 1504, loss = 0.02240199\n",
      "Iteration 1505, loss = 0.02238688\n",
      "Iteration 1506, loss = 0.02236838\n",
      "Iteration 1507, loss = 0.02234965\n",
      "Iteration 1508, loss = 0.02232953\n",
      "Iteration 1509, loss = 0.02231396\n",
      "Iteration 1510, loss = 0.02229849\n",
      "Iteration 1511, loss = 0.02227720\n",
      "Iteration 1512, loss = 0.02226212\n",
      "Iteration 1513, loss = 0.02224434\n",
      "Iteration 1514, loss = 0.02222747\n",
      "Iteration 1515, loss = 0.02221340\n",
      "Iteration 1516, loss = 0.02219566\n",
      "Iteration 1517, loss = 0.02217999\n",
      "Iteration 1518, loss = 0.02216395\n",
      "Iteration 1519, loss = 0.02214900\n",
      "Iteration 1520, loss = 0.02213258\n",
      "Iteration 1521, loss = 0.02211736\n",
      "Iteration 1522, loss = 0.02210054\n",
      "Iteration 1523, loss = 0.02208455\n",
      "Iteration 1524, loss = 0.02206944\n",
      "Iteration 1525, loss = 0.02205209\n",
      "Iteration 1526, loss = 0.02203465\n",
      "Iteration 1527, loss = 0.02201736\n",
      "Iteration 1528, loss = 0.02200117\n",
      "Iteration 1529, loss = 0.02198414\n",
      "Iteration 1530, loss = 0.02196925\n",
      "Iteration 1531, loss = 0.02195120\n",
      "Iteration 1532, loss = 0.02193785\n",
      "Iteration 1533, loss = 0.02192189\n",
      "Iteration 1534, loss = 0.02190533\n",
      "Iteration 1535, loss = 0.02188942\n",
      "Iteration 1536, loss = 0.02187329\n",
      "Iteration 1537, loss = 0.02185771\n",
      "Iteration 1538, loss = 0.02184384\n",
      "Iteration 1539, loss = 0.02182765\n",
      "Iteration 1540, loss = 0.02181195\n",
      "Iteration 1541, loss = 0.02179673\n",
      "Iteration 1542, loss = 0.02178096\n",
      "Iteration 1543, loss = 0.02176557\n",
      "Iteration 1544, loss = 0.02175126\n",
      "Iteration 1545, loss = 0.02173559\n",
      "Iteration 1546, loss = 0.02172024\n",
      "Iteration 1547, loss = 0.02170752\n",
      "Iteration 1548, loss = 0.02168982\n",
      "Iteration 1549, loss = 0.02167418\n",
      "Iteration 1550, loss = 0.02165854\n",
      "Iteration 1551, loss = 0.02164319\n",
      "Iteration 1552, loss = 0.02162751\n",
      "Iteration 1553, loss = 0.02161291\n",
      "Iteration 1554, loss = 0.02159664\n",
      "Iteration 1555, loss = 0.02158210\n",
      "Iteration 1556, loss = 0.02156615\n",
      "Iteration 1557, loss = 0.02155132\n",
      "Iteration 1558, loss = 0.02153602\n",
      "Iteration 1559, loss = 0.02152169\n",
      "Iteration 1560, loss = 0.02150777\n",
      "Iteration 1561, loss = 0.02149247\n",
      "Iteration 1562, loss = 0.02147450\n",
      "Iteration 1563, loss = 0.02145919\n",
      "Iteration 1564, loss = 0.02144396\n",
      "Iteration 1565, loss = 0.02142864\n",
      "Iteration 1566, loss = 0.02141485\n",
      "Iteration 1567, loss = 0.02139846\n",
      "Iteration 1568, loss = 0.02138438\n",
      "Iteration 1569, loss = 0.02136813\n",
      "Iteration 1570, loss = 0.02135469\n",
      "Iteration 1571, loss = 0.02133844\n",
      "Iteration 1572, loss = 0.02132320\n",
      "Iteration 1573, loss = 0.02130628\n",
      "Iteration 1574, loss = 0.02128927\n",
      "Iteration 1575, loss = 0.02127627\n",
      "Iteration 1576, loss = 0.02125849\n",
      "Iteration 1577, loss = 0.02124541\n",
      "Iteration 1578, loss = 0.02122920\n",
      "Iteration 1579, loss = 0.02121393\n",
      "Iteration 1580, loss = 0.02119904\n",
      "Iteration 1581, loss = 0.02118437\n",
      "Iteration 1582, loss = 0.02117049\n",
      "Iteration 1583, loss = 0.02115477\n",
      "Iteration 1584, loss = 0.02114042\n",
      "Iteration 1585, loss = 0.02112689\n",
      "Iteration 1586, loss = 0.02111234\n",
      "Iteration 1587, loss = 0.02109917\n",
      "Iteration 1588, loss = 0.02108387\n",
      "Iteration 1589, loss = 0.02107018\n",
      "Iteration 1590, loss = 0.02105550\n",
      "Iteration 1591, loss = 0.02104140\n",
      "Iteration 1592, loss = 0.02102474\n",
      "Iteration 1593, loss = 0.02101070\n",
      "Iteration 1594, loss = 0.02099547\n",
      "Iteration 1595, loss = 0.02098113\n",
      "Iteration 1596, loss = 0.02096846\n",
      "Iteration 1597, loss = 0.02095165\n",
      "Iteration 1598, loss = 0.02093520\n",
      "Iteration 1599, loss = 0.02091866\n",
      "Iteration 1600, loss = 0.02090665\n",
      "Iteration 1601, loss = 0.02088921\n",
      "Iteration 1602, loss = 0.02087413\n",
      "Iteration 1603, loss = 0.02085920\n",
      "Iteration 1604, loss = 0.02084324\n",
      "Iteration 1605, loss = 0.02082740\n",
      "Iteration 1606, loss = 0.02081494\n",
      "Iteration 1607, loss = 0.02079639\n",
      "Iteration 1608, loss = 0.02077978\n",
      "Iteration 1609, loss = 0.02076469\n",
      "Iteration 1610, loss = 0.02074934\n",
      "Iteration 1611, loss = 0.02073711\n",
      "Iteration 1612, loss = 0.02072007\n",
      "Iteration 1613, loss = 0.02070679\n",
      "Iteration 1614, loss = 0.02069207\n",
      "Iteration 1615, loss = 0.02067645\n",
      "Iteration 1616, loss = 0.02066105\n",
      "Iteration 1617, loss = 0.02065113\n",
      "Iteration 1618, loss = 0.02063267\n",
      "Iteration 1619, loss = 0.02061844\n",
      "Iteration 1620, loss = 0.02060529\n",
      "Iteration 1621, loss = 0.02058870\n",
      "Iteration 1622, loss = 0.02057441\n",
      "Iteration 1623, loss = 0.02056029\n",
      "Iteration 1624, loss = 0.02054360\n",
      "Iteration 1625, loss = 0.02052989\n",
      "Iteration 1626, loss = 0.02051421\n",
      "Iteration 1627, loss = 0.02049868\n",
      "Iteration 1628, loss = 0.02048386\n",
      "Iteration 1629, loss = 0.02046916\n",
      "Iteration 1630, loss = 0.02045488\n",
      "Iteration 1631, loss = 0.02043704\n",
      "Iteration 1632, loss = 0.02042192\n",
      "Iteration 1633, loss = 0.02040743\n",
      "Iteration 1634, loss = 0.02039218\n",
      "Iteration 1635, loss = 0.02037817\n",
      "Iteration 1636, loss = 0.02036171\n",
      "Iteration 1637, loss = 0.02034708\n",
      "Iteration 1638, loss = 0.02033218\n",
      "Iteration 1639, loss = 0.02031676\n",
      "Iteration 1640, loss = 0.02030248\n",
      "Iteration 1641, loss = 0.02028822\n",
      "Iteration 1642, loss = 0.02027313\n",
      "Iteration 1643, loss = 0.02025912\n",
      "Iteration 1644, loss = 0.02024531\n",
      "Iteration 1645, loss = 0.02023115\n",
      "Iteration 1646, loss = 0.02021800\n",
      "Iteration 1647, loss = 0.02020384\n",
      "Iteration 1648, loss = 0.02019181\n",
      "Iteration 1649, loss = 0.02017573\n",
      "Iteration 1650, loss = 0.02016278\n",
      "Iteration 1651, loss = 0.02014976\n",
      "Iteration 1652, loss = 0.02013459\n",
      "Iteration 1653, loss = 0.02012019\n",
      "Iteration 1654, loss = 0.02010681\n",
      "Iteration 1655, loss = 0.02009495\n",
      "Iteration 1656, loss = 0.02007892\n",
      "Iteration 1657, loss = 0.02006460\n",
      "Iteration 1658, loss = 0.02005002\n",
      "Iteration 1659, loss = 0.02003534\n",
      "Iteration 1660, loss = 0.02002251\n",
      "Iteration 1661, loss = 0.02000819\n",
      "Iteration 1662, loss = 0.01999210\n",
      "Iteration 1663, loss = 0.01997868\n",
      "Iteration 1664, loss = 0.01996531\n",
      "Iteration 1665, loss = 0.01995122\n",
      "Iteration 1666, loss = 0.01993700\n",
      "Iteration 1667, loss = 0.01992415\n",
      "Iteration 1668, loss = 0.01991128\n",
      "Iteration 1669, loss = 0.01989788\n",
      "Iteration 1670, loss = 0.01988374\n",
      "Iteration 1671, loss = 0.01986991\n",
      "Iteration 1672, loss = 0.01985562\n",
      "Iteration 1673, loss = 0.01984281\n",
      "Iteration 1674, loss = 0.01982951\n",
      "Iteration 1675, loss = 0.01981898\n",
      "Iteration 1676, loss = 0.01980318\n",
      "Iteration 1677, loss = 0.01979114\n",
      "Iteration 1678, loss = 0.01977570\n",
      "Iteration 1679, loss = 0.01976216\n",
      "Iteration 1680, loss = 0.01975020\n",
      "Iteration 1681, loss = 0.01973542\n",
      "Iteration 1682, loss = 0.01972165\n",
      "Iteration 1683, loss = 0.01970876\n",
      "Iteration 1684, loss = 0.01969579\n",
      "Iteration 1685, loss = 0.01968346\n",
      "Iteration 1686, loss = 0.01966880\n",
      "Iteration 1687, loss = 0.01965422\n",
      "Iteration 1688, loss = 0.01964096\n",
      "Iteration 1689, loss = 0.01962775\n",
      "Iteration 1690, loss = 0.01961527\n",
      "Iteration 1691, loss = 0.01960149\n",
      "Iteration 1692, loss = 0.01958842\n",
      "Iteration 1693, loss = 0.01957442\n",
      "Iteration 1694, loss = 0.01956215\n",
      "Iteration 1695, loss = 0.01954906\n",
      "Iteration 1696, loss = 0.01953586\n",
      "Iteration 1697, loss = 0.01952110\n",
      "Iteration 1698, loss = 0.01950860\n",
      "Iteration 1699, loss = 0.01949624\n",
      "Iteration 1700, loss = 0.01948287\n",
      "Iteration 1701, loss = 0.01946942\n",
      "Iteration 1702, loss = 0.01945640\n",
      "Iteration 1703, loss = 0.01944293\n",
      "Iteration 1704, loss = 0.01943318\n",
      "Iteration 1705, loss = 0.01941734\n",
      "Iteration 1706, loss = 0.01940388\n",
      "Iteration 1707, loss = 0.01939216\n",
      "Iteration 1708, loss = 0.01937805\n",
      "Iteration 1709, loss = 0.01936448\n",
      "Iteration 1710, loss = 0.01935217\n",
      "Iteration 1711, loss = 0.01933808\n",
      "Iteration 1712, loss = 0.01932787\n",
      "Iteration 1713, loss = 0.01931272\n",
      "Iteration 1714, loss = 0.01930169\n",
      "Iteration 1715, loss = 0.01928791\n",
      "Iteration 1716, loss = 0.01927656\n",
      "Iteration 1717, loss = 0.01925989\n",
      "Iteration 1718, loss = 0.01925085\n",
      "Iteration 1719, loss = 0.01923363\n",
      "Iteration 1720, loss = 0.01922073\n",
      "Iteration 1721, loss = 0.01920769\n",
      "Iteration 1722, loss = 0.01919391\n",
      "Iteration 1723, loss = 0.01918091\n",
      "Iteration 1724, loss = 0.01916844\n",
      "Iteration 1725, loss = 0.01915445\n",
      "Iteration 1726, loss = 0.01914214\n",
      "Iteration 1727, loss = 0.01912907\n",
      "Iteration 1728, loss = 0.01911681\n",
      "Iteration 1729, loss = 0.01910240\n",
      "Iteration 1730, loss = 0.01908875\n",
      "Iteration 1731, loss = 0.01907574\n",
      "Iteration 1732, loss = 0.01906361\n",
      "Iteration 1733, loss = 0.01905032\n",
      "Iteration 1734, loss = 0.01903530\n",
      "Iteration 1735, loss = 0.01902228\n",
      "Iteration 1736, loss = 0.01901017\n",
      "Iteration 1737, loss = 0.01899522\n",
      "Iteration 1738, loss = 0.01898169\n",
      "Iteration 1739, loss = 0.01896987\n",
      "Iteration 1740, loss = 0.01895598\n",
      "Iteration 1741, loss = 0.01894192\n",
      "Iteration 1742, loss = 0.01892837\n",
      "Iteration 1743, loss = 0.01891525\n",
      "Iteration 1744, loss = 0.01890268\n",
      "Iteration 1745, loss = 0.01888998\n",
      "Iteration 1746, loss = 0.01887673\n",
      "Iteration 1747, loss = 0.01886539\n",
      "Iteration 1748, loss = 0.01885205\n",
      "Iteration 1749, loss = 0.01884066\n",
      "Iteration 1750, loss = 0.01883065\n",
      "Iteration 1751, loss = 0.01881717\n",
      "Iteration 1752, loss = 0.01880446\n",
      "Iteration 1753, loss = 0.01879223\n",
      "Iteration 1754, loss = 0.01878062\n",
      "Iteration 1755, loss = 0.01876883\n",
      "Iteration 1756, loss = 0.01875920\n",
      "Iteration 1757, loss = 0.01874580\n",
      "Iteration 1758, loss = 0.01873469\n",
      "Iteration 1759, loss = 0.01872364\n",
      "Iteration 1760, loss = 0.01871052\n",
      "Iteration 1761, loss = 0.01869892\n",
      "Iteration 1762, loss = 0.01868757\n",
      "Iteration 1763, loss = 0.01867572\n",
      "Iteration 1764, loss = 0.01866456\n",
      "Iteration 1765, loss = 0.01865433\n",
      "Iteration 1766, loss = 0.01864135\n",
      "Iteration 1767, loss = 0.01862973\n",
      "Iteration 1768, loss = 0.01861961\n",
      "Iteration 1769, loss = 0.01860534\n",
      "Iteration 1770, loss = 0.01859374\n",
      "Iteration 1771, loss = 0.01858181\n",
      "Iteration 1772, loss = 0.01857053\n",
      "Iteration 1773, loss = 0.01855904\n",
      "Iteration 1774, loss = 0.01854648\n",
      "Iteration 1775, loss = 0.01853418\n",
      "Iteration 1776, loss = 0.01852155\n",
      "Iteration 1777, loss = 0.01850894\n",
      "Iteration 1778, loss = 0.01849878\n",
      "Iteration 1779, loss = 0.01848573\n",
      "Iteration 1780, loss = 0.01847210\n",
      "Iteration 1781, loss = 0.01845849\n",
      "Iteration 1782, loss = 0.01844499\n",
      "Iteration 1783, loss = 0.01843216\n",
      "Iteration 1784, loss = 0.01842202\n",
      "Iteration 1785, loss = 0.01840671\n",
      "Iteration 1786, loss = 0.01839744\n",
      "Iteration 1787, loss = 0.01838239\n",
      "Iteration 1788, loss = 0.01836944\n",
      "Iteration 1789, loss = 0.01836012\n",
      "Iteration 1790, loss = 0.01834966\n",
      "Iteration 1791, loss = 0.01833576\n",
      "Iteration 1792, loss = 0.01832480\n",
      "Iteration 1793, loss = 0.01831334\n",
      "Iteration 1794, loss = 0.01830246\n",
      "Iteration 1795, loss = 0.01829196\n",
      "Iteration 1796, loss = 0.01828176\n",
      "Iteration 1797, loss = 0.01826848\n",
      "Iteration 1798, loss = 0.01825586\n",
      "Iteration 1799, loss = 0.01824360\n",
      "Iteration 1800, loss = 0.01823187\n",
      "Iteration 1801, loss = 0.01821941\n",
      "Iteration 1802, loss = 0.01820836\n",
      "Iteration 1803, loss = 0.01819557\n",
      "Iteration 1804, loss = 0.01818497\n",
      "Iteration 1805, loss = 0.01817752\n",
      "Iteration 1806, loss = 0.01816322\n",
      "Iteration 1807, loss = 0.01815106\n",
      "Iteration 1808, loss = 0.01814035\n",
      "Iteration 1809, loss = 0.01812990\n",
      "Iteration 1810, loss = 0.01811713\n",
      "Iteration 1811, loss = 0.01810563\n",
      "Iteration 1812, loss = 0.01809470\n",
      "Iteration 1813, loss = 0.01808266\n",
      "Iteration 1814, loss = 0.01807097\n",
      "Iteration 1815, loss = 0.01806140\n",
      "Iteration 1816, loss = 0.01804848\n",
      "Iteration 1817, loss = 0.01804039\n",
      "Iteration 1818, loss = 0.01802540\n",
      "Iteration 1819, loss = 0.01801467\n",
      "Iteration 1820, loss = 0.01800177\n",
      "Iteration 1821, loss = 0.01799112\n",
      "Iteration 1822, loss = 0.01798100\n",
      "Iteration 1823, loss = 0.01796843\n",
      "Iteration 1824, loss = 0.01795649\n",
      "Iteration 1825, loss = 0.01794513\n",
      "Iteration 1826, loss = 0.01793532\n",
      "Iteration 1827, loss = 0.01792514\n",
      "Iteration 1828, loss = 0.01791246\n",
      "Iteration 1829, loss = 0.01790144\n",
      "Iteration 1830, loss = 0.01789025\n",
      "Iteration 1831, loss = 0.01787973\n",
      "Iteration 1832, loss = 0.01786996\n",
      "Iteration 1833, loss = 0.01785931\n",
      "Iteration 1834, loss = 0.01784827\n",
      "Iteration 1835, loss = 0.01783723\n",
      "Iteration 1836, loss = 0.01782635\n",
      "Iteration 1837, loss = 0.01781652\n",
      "Iteration 1838, loss = 0.01780619\n",
      "Iteration 1839, loss = 0.01779715\n",
      "Iteration 1840, loss = 0.01778994\n",
      "Iteration 1841, loss = 0.01777544\n",
      "Iteration 1842, loss = 0.01776484\n",
      "Iteration 1843, loss = 0.01775281\n",
      "Iteration 1844, loss = 0.01774192\n",
      "Iteration 1845, loss = 0.01773134\n",
      "Iteration 1846, loss = 0.01772220\n",
      "Iteration 1847, loss = 0.01771046\n",
      "Iteration 1848, loss = 0.01770022\n",
      "Iteration 1849, loss = 0.01769097\n",
      "Iteration 1850, loss = 0.01767995\n",
      "Iteration 1851, loss = 0.01767153\n",
      "Iteration 1852, loss = 0.01765963\n",
      "Iteration 1853, loss = 0.01765092\n",
      "Iteration 1854, loss = 0.01763996\n",
      "Iteration 1855, loss = 0.01762779\n",
      "Iteration 1856, loss = 0.01761630\n",
      "Iteration 1857, loss = 0.01760506\n",
      "Iteration 1858, loss = 0.01759473\n",
      "Iteration 1859, loss = 0.01758289\n",
      "Iteration 1860, loss = 0.01757321\n",
      "Iteration 1861, loss = 0.01756457\n",
      "Iteration 1862, loss = 0.01755462\n",
      "Iteration 1863, loss = 0.01754224\n",
      "Iteration 1864, loss = 0.01753082\n",
      "Iteration 1865, loss = 0.01752122\n",
      "Iteration 1866, loss = 0.01751043\n",
      "Iteration 1867, loss = 0.01749877\n",
      "Iteration 1868, loss = 0.01748710\n",
      "Iteration 1869, loss = 0.01747458\n",
      "Iteration 1870, loss = 0.01746133\n",
      "Iteration 1871, loss = 0.01745260\n",
      "Iteration 1872, loss = 0.01743960\n",
      "Iteration 1873, loss = 0.01742603\n",
      "Iteration 1874, loss = 0.01741602\n",
      "Iteration 1875, loss = 0.01740479\n",
      "Iteration 1876, loss = 0.01739459\n",
      "Iteration 1877, loss = 0.01738272\n",
      "Iteration 1878, loss = 0.01737208\n",
      "Iteration 1879, loss = 0.01736202\n",
      "Iteration 1880, loss = 0.01735113\n",
      "Iteration 1881, loss = 0.01734084\n",
      "Iteration 1882, loss = 0.01733245\n",
      "Iteration 1883, loss = 0.01732205\n",
      "Iteration 1884, loss = 0.01730947\n",
      "Iteration 1885, loss = 0.01729961\n",
      "Iteration 1886, loss = 0.01728744\n",
      "Iteration 1887, loss = 0.01727710\n",
      "Iteration 1888, loss = 0.01726633\n",
      "Iteration 1889, loss = 0.01725522\n",
      "Iteration 1890, loss = 0.01724407\n",
      "Iteration 1891, loss = 0.01723746\n",
      "Iteration 1892, loss = 0.01722470\n",
      "Iteration 1893, loss = 0.01721419\n",
      "Iteration 1894, loss = 0.01720601\n",
      "Iteration 1895, loss = 0.01719352\n",
      "Iteration 1896, loss = 0.01718335\n",
      "Iteration 1897, loss = 0.01717415\n",
      "Iteration 1898, loss = 0.01716260\n",
      "Iteration 1899, loss = 0.01715302\n",
      "Iteration 1900, loss = 0.01714314\n",
      "Iteration 1901, loss = 0.01713372\n",
      "Iteration 1902, loss = 0.01712487\n",
      "Iteration 1903, loss = 0.01711519\n",
      "Iteration 1904, loss = 0.01710490\n",
      "Iteration 1905, loss = 0.01709524\n",
      "Iteration 1906, loss = 0.01708419\n",
      "Iteration 1907, loss = 0.01707364\n",
      "Iteration 1908, loss = 0.01706430\n",
      "Iteration 1909, loss = 0.01705237\n",
      "Iteration 1910, loss = 0.01704125\n",
      "Iteration 1911, loss = 0.01702996\n",
      "Iteration 1912, loss = 0.01701955\n",
      "Iteration 1913, loss = 0.01700843\n",
      "Iteration 1914, loss = 0.01700031\n",
      "Iteration 1915, loss = 0.01698782\n",
      "Iteration 1916, loss = 0.01697937\n",
      "Iteration 1917, loss = 0.01696949\n",
      "Iteration 1918, loss = 0.01695826\n",
      "Iteration 1919, loss = 0.01694778\n",
      "Iteration 1920, loss = 0.01693857\n",
      "Iteration 1921, loss = 0.01692701\n",
      "Iteration 1922, loss = 0.01691676\n",
      "Iteration 1923, loss = 0.01690800\n",
      "Iteration 1924, loss = 0.01689583\n",
      "Iteration 1925, loss = 0.01688636\n",
      "Iteration 1926, loss = 0.01687578\n",
      "Iteration 1927, loss = 0.01686555\n",
      "Iteration 1928, loss = 0.01685607\n",
      "Iteration 1929, loss = 0.01684512\n",
      "Iteration 1930, loss = 0.01683478\n",
      "Iteration 1931, loss = 0.01682440\n",
      "Iteration 1932, loss = 0.01681428\n",
      "Iteration 1933, loss = 0.01680361\n",
      "Iteration 1934, loss = 0.01679329\n",
      "Iteration 1935, loss = 0.01678371\n",
      "Iteration 1936, loss = 0.01677405\n",
      "Iteration 1937, loss = 0.01676848\n",
      "Iteration 1938, loss = 0.01675661\n",
      "Iteration 1939, loss = 0.01674593\n",
      "Iteration 1940, loss = 0.01673608\n",
      "Iteration 1941, loss = 0.01672616\n",
      "Iteration 1942, loss = 0.01671543\n",
      "Iteration 1943, loss = 0.01670652\n",
      "Iteration 1944, loss = 0.01669755\n",
      "Iteration 1945, loss = 0.01668537\n",
      "Iteration 1946, loss = 0.01667560\n",
      "Iteration 1947, loss = 0.01666325\n",
      "Iteration 1948, loss = 0.01665381\n",
      "Iteration 1949, loss = 0.01664202\n",
      "Iteration 1950, loss = 0.01663044\n",
      "Iteration 1951, loss = 0.01662140\n",
      "Iteration 1952, loss = 0.01661166\n",
      "Iteration 1953, loss = 0.01660170\n",
      "Iteration 1954, loss = 0.01659115\n",
      "Iteration 1955, loss = 0.01658181\n",
      "Iteration 1956, loss = 0.01657200\n",
      "Iteration 1957, loss = 0.01656334\n",
      "Iteration 1958, loss = 0.01655363\n",
      "Iteration 1959, loss = 0.01654269\n",
      "Iteration 1960, loss = 0.01653234\n",
      "Iteration 1961, loss = 0.01652277\n",
      "Iteration 1962, loss = 0.01651389\n",
      "Iteration 1963, loss = 0.01650208\n",
      "Iteration 1964, loss = 0.01649229\n",
      "Iteration 1965, loss = 0.01648377\n",
      "Iteration 1966, loss = 0.01647454\n",
      "Iteration 1967, loss = 0.01646446\n",
      "Iteration 1968, loss = 0.01645459\n",
      "Iteration 1969, loss = 0.01644594\n",
      "Iteration 1970, loss = 0.01643509\n",
      "Iteration 1971, loss = 0.01642623\n",
      "Iteration 1972, loss = 0.01641684\n",
      "Iteration 1973, loss = 0.01640730\n",
      "Iteration 1974, loss = 0.01640330\n",
      "Iteration 1975, loss = 0.01638660\n",
      "Iteration 1976, loss = 0.01637897\n",
      "Iteration 1977, loss = 0.01636688\n",
      "Iteration 1978, loss = 0.01635589\n",
      "Iteration 1979, loss = 0.01634918\n",
      "Iteration 1980, loss = 0.01633705\n",
      "Iteration 1981, loss = 0.01632700\n",
      "Iteration 1982, loss = 0.01631606\n",
      "Iteration 1983, loss = 0.01630496\n",
      "Iteration 1984, loss = 0.01629662\n",
      "Iteration 1985, loss = 0.01628517\n",
      "Iteration 1986, loss = 0.01627812\n",
      "Iteration 1987, loss = 0.01626603\n",
      "Iteration 1988, loss = 0.01625679\n",
      "Iteration 1989, loss = 0.01624806\n",
      "Iteration 1990, loss = 0.01623901\n",
      "Iteration 1991, loss = 0.01622846\n",
      "Iteration 1992, loss = 0.01621930\n",
      "Iteration 1993, loss = 0.01620908\n",
      "Iteration 1994, loss = 0.01619939\n",
      "Iteration 1995, loss = 0.01618958\n",
      "Iteration 1996, loss = 0.01618013\n",
      "Iteration 1997, loss = 0.01616993\n",
      "Iteration 1998, loss = 0.01616082\n",
      "Iteration 1999, loss = 0.01615037\n",
      "Iteration 2000, loss = 0.01614060\n",
      "Iteration 2001, loss = 0.01613056\n",
      "Iteration 2002, loss = 0.01612272\n",
      "Iteration 2003, loss = 0.01611101\n",
      "Iteration 2004, loss = 0.01610110\n",
      "Iteration 2005, loss = 0.01609276\n",
      "Iteration 2006, loss = 0.01608209\n",
      "Iteration 2007, loss = 0.01607211\n",
      "Iteration 2008, loss = 0.01606288\n",
      "Iteration 2009, loss = 0.01605323\n",
      "Iteration 2010, loss = 0.01604365\n",
      "Iteration 2011, loss = 0.01603644\n",
      "Iteration 2012, loss = 0.01602513\n",
      "Iteration 2013, loss = 0.01601533\n",
      "Iteration 2014, loss = 0.01600630\n",
      "Iteration 2015, loss = 0.01599717\n",
      "Iteration 2016, loss = 0.01598680\n",
      "Iteration 2017, loss = 0.01597963\n",
      "Iteration 2018, loss = 0.01596881\n",
      "Iteration 2019, loss = 0.01595829\n",
      "Iteration 2020, loss = 0.01594878\n",
      "Iteration 2021, loss = 0.01594036\n",
      "Iteration 2022, loss = 0.01593028\n",
      "Iteration 2023, loss = 0.01592184\n",
      "Iteration 2024, loss = 0.01591259\n",
      "Iteration 2025, loss = 0.01590472\n",
      "Iteration 2026, loss = 0.01589630\n",
      "Iteration 2027, loss = 0.01588717\n",
      "Iteration 2028, loss = 0.01587698\n",
      "Iteration 2029, loss = 0.01587167\n",
      "Iteration 2030, loss = 0.01586016\n",
      "Iteration 2031, loss = 0.01585130\n",
      "Iteration 2032, loss = 0.01584183\n",
      "Iteration 2033, loss = 0.01583326\n",
      "Iteration 2034, loss = 0.01582360\n",
      "Iteration 2035, loss = 0.01581453\n",
      "Iteration 2036, loss = 0.01580572\n",
      "Iteration 2037, loss = 0.01579652\n",
      "Iteration 2038, loss = 0.01578795\n",
      "Iteration 2039, loss = 0.01577833\n",
      "Iteration 2040, loss = 0.01577121\n",
      "Iteration 2041, loss = 0.01576117\n",
      "Iteration 2042, loss = 0.01575284\n",
      "Iteration 2043, loss = 0.01574444\n",
      "Iteration 2044, loss = 0.01573573\n",
      "Iteration 2045, loss = 0.01572715\n",
      "Iteration 2046, loss = 0.01571883\n",
      "Iteration 2047, loss = 0.01571006\n",
      "Iteration 2048, loss = 0.01570163\n",
      "Iteration 2049, loss = 0.01569041\n",
      "Iteration 2050, loss = 0.01568160\n",
      "Iteration 2051, loss = 0.01567311\n",
      "Iteration 2052, loss = 0.01566470\n",
      "Iteration 2053, loss = 0.01565491\n",
      "Iteration 2054, loss = 0.01564621\n",
      "Iteration 2055, loss = 0.01563756\n",
      "Iteration 2056, loss = 0.01562843\n",
      "Iteration 2057, loss = 0.01561946\n",
      "Iteration 2058, loss = 0.01561249\n",
      "Iteration 2059, loss = 0.01560230\n",
      "Iteration 2060, loss = 0.01559188\n",
      "Iteration 2061, loss = 0.01558283\n",
      "Iteration 2062, loss = 0.01557526\n",
      "Iteration 2063, loss = 0.01556376\n",
      "Iteration 2064, loss = 0.01555397\n",
      "Iteration 2065, loss = 0.01554523\n",
      "Iteration 2066, loss = 0.01553518\n",
      "Iteration 2067, loss = 0.01552665\n",
      "Iteration 2068, loss = 0.01551883\n",
      "Iteration 2069, loss = 0.01550799\n",
      "Iteration 2070, loss = 0.01549987\n",
      "Iteration 2071, loss = 0.01549048\n",
      "Iteration 2072, loss = 0.01548087\n",
      "Iteration 2073, loss = 0.01547154\n",
      "Iteration 2074, loss = 0.01546316\n",
      "Iteration 2075, loss = 0.01545226\n",
      "Iteration 2076, loss = 0.01544515\n",
      "Iteration 2077, loss = 0.01543440\n",
      "Iteration 2078, loss = 0.01542521\n",
      "Iteration 2079, loss = 0.01541926\n",
      "Iteration 2080, loss = 0.01540906\n",
      "Iteration 2081, loss = 0.01540125\n",
      "Iteration 2082, loss = 0.01539233\n",
      "Iteration 2083, loss = 0.01538343\n",
      "Iteration 2084, loss = 0.01537601\n",
      "Iteration 2085, loss = 0.01536753\n",
      "Iteration 2086, loss = 0.01535905\n",
      "Iteration 2087, loss = 0.01534806\n",
      "Iteration 2088, loss = 0.01533949\n",
      "Iteration 2089, loss = 0.01532969\n",
      "Iteration 2090, loss = 0.01532146\n",
      "Iteration 2091, loss = 0.01531142\n",
      "Iteration 2092, loss = 0.01530323\n",
      "Iteration 2093, loss = 0.01529548\n",
      "Iteration 2094, loss = 0.01528529\n",
      "Iteration 2095, loss = 0.01527693\n",
      "Iteration 2096, loss = 0.01526766\n",
      "Iteration 2097, loss = 0.01525833\n",
      "Iteration 2098, loss = 0.01524916\n",
      "Iteration 2099, loss = 0.01524020\n",
      "Iteration 2100, loss = 0.01523018\n",
      "Iteration 2101, loss = 0.01522435\n",
      "Iteration 2102, loss = 0.01521450\n",
      "Iteration 2103, loss = 0.01520466\n",
      "Iteration 2104, loss = 0.01519685\n",
      "Iteration 2105, loss = 0.01518910\n",
      "Iteration 2106, loss = 0.01517947\n",
      "Iteration 2107, loss = 0.01517059\n",
      "Iteration 2108, loss = 0.01516066\n",
      "Iteration 2109, loss = 0.01515211\n",
      "Iteration 2110, loss = 0.01514362\n",
      "Iteration 2111, loss = 0.01513425\n",
      "Iteration 2112, loss = 0.01512505\n",
      "Iteration 2113, loss = 0.01511644\n",
      "Iteration 2114, loss = 0.01510822\n",
      "Iteration 2115, loss = 0.01509895\n",
      "Iteration 2116, loss = 0.01509122\n",
      "Iteration 2117, loss = 0.01508151\n",
      "Iteration 2118, loss = 0.01507363\n",
      "Iteration 2119, loss = 0.01506667\n",
      "Iteration 2120, loss = 0.01505647\n",
      "Iteration 2121, loss = 0.01504760\n",
      "Iteration 2122, loss = 0.01503965\n",
      "Iteration 2123, loss = 0.01503073\n",
      "Iteration 2124, loss = 0.01502102\n",
      "Iteration 2125, loss = 0.01501499\n",
      "Iteration 2126, loss = 0.01500648\n",
      "Iteration 2127, loss = 0.01499673\n",
      "Iteration 2128, loss = 0.01498775\n",
      "Iteration 2129, loss = 0.01497940\n",
      "Iteration 2130, loss = 0.01497092\n",
      "Iteration 2131, loss = 0.01496286\n",
      "Iteration 2132, loss = 0.01495473\n",
      "Iteration 2133, loss = 0.01494573\n",
      "Iteration 2134, loss = 0.01493871\n",
      "Iteration 2135, loss = 0.01492952\n",
      "Iteration 2136, loss = 0.01492137\n",
      "Iteration 2137, loss = 0.01491313\n",
      "Iteration 2138, loss = 0.01490515\n",
      "Iteration 2139, loss = 0.01489794\n",
      "Iteration 2140, loss = 0.01488914\n",
      "Iteration 2141, loss = 0.01487982\n",
      "Iteration 2142, loss = 0.01487190\n",
      "Iteration 2143, loss = 0.01486361\n",
      "Iteration 2144, loss = 0.01485563\n",
      "Iteration 2145, loss = 0.01484673\n",
      "Iteration 2146, loss = 0.01483783\n",
      "Iteration 2147, loss = 0.01483010\n",
      "Iteration 2148, loss = 0.01482261\n",
      "Iteration 2149, loss = 0.01481385\n",
      "Iteration 2150, loss = 0.01480456\n",
      "Iteration 2151, loss = 0.01479654\n",
      "Iteration 2152, loss = 0.01478889\n",
      "Iteration 2153, loss = 0.01477999\n",
      "Iteration 2154, loss = 0.01477178\n",
      "Iteration 2155, loss = 0.01476307\n",
      "Iteration 2156, loss = 0.01475528\n",
      "Iteration 2157, loss = 0.01474711\n",
      "Iteration 2158, loss = 0.01473947\n",
      "Iteration 2159, loss = 0.01473189\n",
      "Iteration 2160, loss = 0.01472448\n",
      "Iteration 2161, loss = 0.01471625\n",
      "Iteration 2162, loss = 0.01470812\n",
      "Iteration 2163, loss = 0.01470020\n",
      "Iteration 2164, loss = 0.01469295\n",
      "Iteration 2165, loss = 0.01468679\n",
      "Iteration 2166, loss = 0.01467709\n",
      "Iteration 2167, loss = 0.01466886\n",
      "Iteration 2168, loss = 0.01466126\n",
      "Iteration 2169, loss = 0.01465307\n",
      "Iteration 2170, loss = 0.01464601\n",
      "Iteration 2171, loss = 0.01463790\n",
      "Iteration 2172, loss = 0.01463099\n",
      "Iteration 2173, loss = 0.01462424\n",
      "Iteration 2174, loss = 0.01461616\n",
      "Iteration 2175, loss = 0.01460908\n",
      "Iteration 2176, loss = 0.01460207\n",
      "Iteration 2177, loss = 0.01459523\n",
      "Iteration 2178, loss = 0.01458754\n",
      "Iteration 2179, loss = 0.01457919\n",
      "Iteration 2180, loss = 0.01457154\n",
      "Iteration 2181, loss = 0.01456325\n",
      "Iteration 2182, loss = 0.01455483\n",
      "Iteration 2183, loss = 0.01454762\n",
      "Iteration 2184, loss = 0.01453924\n",
      "Iteration 2185, loss = 0.01453193\n",
      "Iteration 2186, loss = 0.01452561\n",
      "Iteration 2187, loss = 0.01451651\n",
      "Iteration 2188, loss = 0.01451010\n",
      "Iteration 2189, loss = 0.01450102\n",
      "Iteration 2190, loss = 0.01449308\n",
      "Iteration 2191, loss = 0.01448355\n",
      "Iteration 2192, loss = 0.01447591\n",
      "Iteration 2193, loss = 0.01446759\n",
      "Iteration 2194, loss = 0.01445807\n",
      "Iteration 2195, loss = 0.01445247\n",
      "Iteration 2196, loss = 0.01444237\n",
      "Iteration 2197, loss = 0.01443502\n",
      "Iteration 2198, loss = 0.01442729\n",
      "Iteration 2199, loss = 0.01441922\n",
      "Iteration 2200, loss = 0.01441235\n",
      "Iteration 2201, loss = 0.01440443\n",
      "Iteration 2202, loss = 0.01439712\n",
      "Iteration 2203, loss = 0.01438866\n",
      "Iteration 2204, loss = 0.01438123\n",
      "Iteration 2205, loss = 0.01437635\n",
      "Iteration 2206, loss = 0.01436661\n",
      "Iteration 2207, loss = 0.01435837\n",
      "Iteration 2208, loss = 0.01435258\n",
      "Iteration 2209, loss = 0.01434692\n",
      "Iteration 2210, loss = 0.01433935\n",
      "Iteration 2211, loss = 0.01432989\n",
      "Iteration 2212, loss = 0.01432132\n",
      "Iteration 2213, loss = 0.01431216\n",
      "Iteration 2214, loss = 0.01430365\n",
      "Iteration 2215, loss = 0.01429484\n",
      "Iteration 2216, loss = 0.01428622\n",
      "Iteration 2217, loss = 0.01427445\n",
      "Iteration 2218, loss = 0.01426617\n",
      "Iteration 2219, loss = 0.01425890\n",
      "Iteration 2220, loss = 0.01425273\n",
      "Iteration 2221, loss = 0.01424169\n",
      "Iteration 2222, loss = 0.01423378\n",
      "Iteration 2223, loss = 0.01422504\n",
      "Iteration 2224, loss = 0.01421781\n",
      "Iteration 2225, loss = 0.01420977\n",
      "Iteration 2226, loss = 0.01420297\n",
      "Iteration 2227, loss = 0.01419545\n",
      "Iteration 2228, loss = 0.01418616\n",
      "Iteration 2229, loss = 0.01417854\n",
      "Iteration 2230, loss = 0.01417062\n",
      "Iteration 2231, loss = 0.01416318\n",
      "Iteration 2232, loss = 0.01415582\n",
      "Iteration 2233, loss = 0.01414785\n",
      "Iteration 2234, loss = 0.01414088\n",
      "Iteration 2235, loss = 0.01413294\n",
      "Iteration 2236, loss = 0.01412546\n",
      "Iteration 2237, loss = 0.01411988\n",
      "Iteration 2238, loss = 0.01410994\n",
      "Iteration 2239, loss = 0.01410229\n",
      "Iteration 2240, loss = 0.01409535\n",
      "Iteration 2241, loss = 0.01408789\n",
      "Iteration 2242, loss = 0.01407930\n",
      "Iteration 2243, loss = 0.01407180\n",
      "Iteration 2244, loss = 0.01406438\n",
      "Iteration 2245, loss = 0.01405650\n",
      "Iteration 2246, loss = 0.01404902\n",
      "Iteration 2247, loss = 0.01404199\n",
      "Iteration 2248, loss = 0.01403380\n",
      "Iteration 2249, loss = 0.01402782\n",
      "Iteration 2250, loss = 0.01401906\n",
      "Iteration 2251, loss = 0.01401196\n",
      "Iteration 2252, loss = 0.01400437\n",
      "Iteration 2253, loss = 0.01399753\n",
      "Iteration 2254, loss = 0.01398940\n",
      "Iteration 2255, loss = 0.01398225\n",
      "Iteration 2256, loss = 0.01397541\n",
      "Iteration 2257, loss = 0.01396774\n",
      "Iteration 2258, loss = 0.01396078\n",
      "Iteration 2259, loss = 0.01395240\n",
      "Iteration 2260, loss = 0.01394585\n",
      "Iteration 2261, loss = 0.01393827\n",
      "Iteration 2262, loss = 0.01393136\n",
      "Iteration 2263, loss = 0.01392496\n",
      "Iteration 2264, loss = 0.01391702\n",
      "Iteration 2265, loss = 0.01391061\n",
      "Iteration 2266, loss = 0.01390292\n",
      "Iteration 2267, loss = 0.01389798\n",
      "Iteration 2268, loss = 0.01388980\n",
      "Iteration 2269, loss = 0.01388130\n",
      "Iteration 2270, loss = 0.01387373\n",
      "Iteration 2271, loss = 0.01386705\n",
      "Iteration 2272, loss = 0.01385834\n",
      "Iteration 2273, loss = 0.01385114\n",
      "Iteration 2274, loss = 0.01384266\n",
      "Iteration 2275, loss = 0.01383543\n",
      "Iteration 2276, loss = 0.01382819\n",
      "Iteration 2277, loss = 0.01381862\n",
      "Iteration 2278, loss = 0.01380992\n",
      "Iteration 2279, loss = 0.01380302\n",
      "Iteration 2280, loss = 0.01379425\n",
      "Iteration 2281, loss = 0.01378658\n",
      "Iteration 2282, loss = 0.01377718\n",
      "Iteration 2283, loss = 0.01376913\n",
      "Iteration 2284, loss = 0.01376301\n",
      "Iteration 2285, loss = 0.01375290\n",
      "Iteration 2286, loss = 0.01374620\n",
      "Iteration 2287, loss = 0.01373718\n",
      "Iteration 2288, loss = 0.01372930\n",
      "Iteration 2289, loss = 0.01372503\n",
      "Iteration 2290, loss = 0.01371874\n",
      "Iteration 2291, loss = 0.01371078\n",
      "Iteration 2292, loss = 0.01370283\n",
      "Iteration 2293, loss = 0.01369568\n",
      "Iteration 2294, loss = 0.01368853\n",
      "Iteration 2295, loss = 0.01368112\n",
      "Iteration 2296, loss = 0.01367298\n",
      "Iteration 2297, loss = 0.01366678\n",
      "Iteration 2298, loss = 0.01365686\n",
      "Iteration 2299, loss = 0.01365069\n",
      "Iteration 2300, loss = 0.01364175\n",
      "Iteration 2301, loss = 0.01363457\n",
      "Iteration 2302, loss = 0.01362699\n",
      "Iteration 2303, loss = 0.01361945\n",
      "Iteration 2304, loss = 0.01361175\n",
      "Iteration 2305, loss = 0.01360481\n",
      "Iteration 2306, loss = 0.01359768\n",
      "Iteration 2307, loss = 0.01359004\n",
      "Iteration 2308, loss = 0.01358329\n",
      "Iteration 2309, loss = 0.01357460\n",
      "Iteration 2310, loss = 0.01357005\n",
      "Iteration 2311, loss = 0.01356050\n",
      "Iteration 2312, loss = 0.01355310\n",
      "Iteration 2313, loss = 0.01354710\n",
      "Iteration 2314, loss = 0.01353815\n",
      "Iteration 2315, loss = 0.01353127\n",
      "Iteration 2316, loss = 0.01352245\n",
      "Iteration 2317, loss = 0.01351539\n",
      "Iteration 2318, loss = 0.01350775\n",
      "Iteration 2319, loss = 0.01350043\n",
      "Iteration 2320, loss = 0.01349368\n",
      "Iteration 2321, loss = 0.01348681\n",
      "Iteration 2322, loss = 0.01347951\n",
      "Iteration 2323, loss = 0.01347163\n",
      "Iteration 2324, loss = 0.01346520\n",
      "Iteration 2325, loss = 0.01345836\n",
      "Iteration 2326, loss = 0.01345116\n",
      "Iteration 2327, loss = 0.01344454\n",
      "Iteration 2328, loss = 0.01343870\n",
      "Iteration 2329, loss = 0.01343112\n",
      "Iteration 2330, loss = 0.01342445\n",
      "Iteration 2331, loss = 0.01341735\n",
      "Iteration 2332, loss = 0.01341238\n",
      "Iteration 2333, loss = 0.01340521\n",
      "Iteration 2334, loss = 0.01339891\n",
      "Iteration 2335, loss = 0.01339418\n",
      "Iteration 2336, loss = 0.01338533\n",
      "Iteration 2337, loss = 0.01337981\n",
      "Iteration 2338, loss = 0.01337108\n",
      "Iteration 2339, loss = 0.01336511\n",
      "Iteration 2340, loss = 0.01335755\n",
      "Iteration 2341, loss = 0.01335027\n",
      "Iteration 2342, loss = 0.01334375\n",
      "Iteration 2343, loss = 0.01333589\n",
      "Iteration 2344, loss = 0.01332892\n",
      "Iteration 2345, loss = 0.01332290\n",
      "Iteration 2346, loss = 0.01331503\n",
      "Iteration 2347, loss = 0.01330872\n",
      "Iteration 2348, loss = 0.01330123\n",
      "Iteration 2349, loss = 0.01329410\n",
      "Iteration 2350, loss = 0.01328734\n",
      "Iteration 2351, loss = 0.01328076\n",
      "Iteration 2352, loss = 0.01327615\n",
      "Iteration 2353, loss = 0.01326823\n",
      "Iteration 2354, loss = 0.01326232\n",
      "Iteration 2355, loss = 0.01325500\n",
      "Iteration 2356, loss = 0.01324779\n",
      "Iteration 2357, loss = 0.01324134\n",
      "Iteration 2358, loss = 0.01323483\n",
      "Iteration 2359, loss = 0.01322930\n",
      "Iteration 2360, loss = 0.01322017\n",
      "Iteration 2361, loss = 0.01321161\n",
      "Iteration 2362, loss = 0.01320354\n",
      "Iteration 2363, loss = 0.01319729\n",
      "Iteration 2364, loss = 0.01318971\n",
      "Iteration 2365, loss = 0.01318365\n",
      "Iteration 2366, loss = 0.01317657\n",
      "Iteration 2367, loss = 0.01316994\n",
      "Iteration 2368, loss = 0.01316372\n",
      "Iteration 2369, loss = 0.01315773\n",
      "Iteration 2370, loss = 0.01315076\n",
      "Iteration 2371, loss = 0.01314557\n",
      "Iteration 2372, loss = 0.01313962\n",
      "Iteration 2373, loss = 0.01313145\n",
      "Iteration 2374, loss = 0.01312456\n",
      "Iteration 2375, loss = 0.01311731\n",
      "Iteration 2376, loss = 0.01311037\n",
      "Iteration 2377, loss = 0.01310312\n",
      "Iteration 2378, loss = 0.01309706\n",
      "Iteration 2379, loss = 0.01309076\n",
      "Iteration 2380, loss = 0.01308225\n",
      "Iteration 2381, loss = 0.01307492\n",
      "Iteration 2382, loss = 0.01306844\n",
      "Iteration 2383, loss = 0.01306223\n",
      "Iteration 2384, loss = 0.01305516\n",
      "Iteration 2385, loss = 0.01304934\n",
      "Iteration 2386, loss = 0.01304331\n",
      "Iteration 2387, loss = 0.01303593\n",
      "Iteration 2388, loss = 0.01303168\n",
      "Iteration 2389, loss = 0.01302464\n",
      "Iteration 2390, loss = 0.01301835\n",
      "Iteration 2391, loss = 0.01301019\n",
      "Iteration 2392, loss = 0.01300380\n",
      "Iteration 2393, loss = 0.01299733\n",
      "Iteration 2394, loss = 0.01299279\n",
      "Iteration 2395, loss = 0.01298474\n",
      "Iteration 2396, loss = 0.01297843\n",
      "Iteration 2397, loss = 0.01297018\n",
      "Iteration 2398, loss = 0.01296412\n",
      "Iteration 2399, loss = 0.01295683\n",
      "Iteration 2400, loss = 0.01295061\n",
      "Iteration 2401, loss = 0.01294340\n",
      "Iteration 2402, loss = 0.01293655\n",
      "Iteration 2403, loss = 0.01292976\n",
      "Iteration 2404, loss = 0.01292406\n",
      "Iteration 2405, loss = 0.01291631\n",
      "Iteration 2406, loss = 0.01290801\n",
      "Iteration 2407, loss = 0.01290115\n",
      "Iteration 2408, loss = 0.01289507\n",
      "Iteration 2409, loss = 0.01288825\n",
      "Iteration 2410, loss = 0.01288153\n",
      "Iteration 2411, loss = 0.01287586\n",
      "Iteration 2412, loss = 0.01286975\n",
      "Iteration 2413, loss = 0.01286355\n",
      "Iteration 2414, loss = 0.01285792\n",
      "Iteration 2415, loss = 0.01285155\n",
      "Iteration 2416, loss = 0.01284720\n",
      "Iteration 2417, loss = 0.01283952\n",
      "Iteration 2418, loss = 0.01283281\n",
      "Iteration 2419, loss = 0.01282555\n",
      "Iteration 2420, loss = 0.01281907\n",
      "Iteration 2421, loss = 0.01281297\n",
      "Iteration 2422, loss = 0.01280676\n",
      "Iteration 2423, loss = 0.01279907\n",
      "Iteration 2424, loss = 0.01279279\n",
      "Iteration 2425, loss = 0.01278695\n",
      "Iteration 2426, loss = 0.01278124\n",
      "Iteration 2427, loss = 0.01277571\n",
      "Iteration 2428, loss = 0.01276926\n",
      "Iteration 2429, loss = 0.01276745\n",
      "Iteration 2430, loss = 0.01275792\n",
      "Iteration 2431, loss = 0.01275126\n",
      "Iteration 2432, loss = 0.01274372\n",
      "Iteration 2433, loss = 0.01273796\n",
      "Iteration 2434, loss = 0.01273031\n",
      "Iteration 2435, loss = 0.01272306\n",
      "Iteration 2436, loss = 0.01271571\n",
      "Iteration 2437, loss = 0.01271002\n",
      "Iteration 2438, loss = 0.01270365\n",
      "Iteration 2439, loss = 0.01269635\n",
      "Iteration 2440, loss = 0.01268952\n",
      "Iteration 2441, loss = 0.01268475\n",
      "Iteration 2442, loss = 0.01267706\n",
      "Iteration 2443, loss = 0.01267051\n",
      "Iteration 2444, loss = 0.01266486\n",
      "Iteration 2445, loss = 0.01265887\n",
      "Iteration 2446, loss = 0.01265137\n",
      "Iteration 2447, loss = 0.01264511\n",
      "Iteration 2448, loss = 0.01263918\n",
      "Iteration 2449, loss = 0.01263134\n",
      "Iteration 2450, loss = 0.01262509\n",
      "Iteration 2451, loss = 0.01261828\n",
      "Iteration 2452, loss = 0.01261188\n",
      "Iteration 2453, loss = 0.01260576\n",
      "Iteration 2454, loss = 0.01259965\n",
      "Iteration 2455, loss = 0.01259327\n",
      "Iteration 2456, loss = 0.01258678\n",
      "Iteration 2457, loss = 0.01258054\n",
      "Iteration 2458, loss = 0.01257614\n",
      "Iteration 2459, loss = 0.01256978\n",
      "Iteration 2460, loss = 0.01256368\n",
      "Iteration 2461, loss = 0.01255736\n",
      "Iteration 2462, loss = 0.01255207\n",
      "Iteration 2463, loss = 0.01254401\n",
      "Iteration 2464, loss = 0.01253779\n",
      "Iteration 2465, loss = 0.01253143\n",
      "Iteration 2466, loss = 0.01252386\n",
      "Iteration 2467, loss = 0.01251688\n",
      "Iteration 2468, loss = 0.01251320\n",
      "Iteration 2469, loss = 0.01250438\n",
      "Iteration 2470, loss = 0.01249861\n",
      "Iteration 2471, loss = 0.01249250\n",
      "Iteration 2472, loss = 0.01248656\n",
      "Iteration 2473, loss = 0.01248137\n",
      "Iteration 2474, loss = 0.01247576\n",
      "Iteration 2475, loss = 0.01246962\n",
      "Iteration 2476, loss = 0.01246445\n",
      "Iteration 2477, loss = 0.01245921\n",
      "Iteration 2478, loss = 0.01245199\n",
      "Iteration 2479, loss = 0.01244698\n",
      "Iteration 2480, loss = 0.01244037\n",
      "Iteration 2481, loss = 0.01243422\n",
      "Iteration 2482, loss = 0.01242719\n",
      "Iteration 2483, loss = 0.01242138\n",
      "Iteration 2484, loss = 0.01241482\n",
      "Iteration 2485, loss = 0.01240753\n",
      "Iteration 2486, loss = 0.01240118\n",
      "Iteration 2487, loss = 0.01239665\n",
      "Iteration 2488, loss = 0.01238939\n",
      "Iteration 2489, loss = 0.01238185\n",
      "Iteration 2490, loss = 0.01237576\n",
      "Iteration 2491, loss = 0.01236921\n",
      "Iteration 2492, loss = 0.01236201\n",
      "Iteration 2493, loss = 0.01235583\n",
      "Iteration 2494, loss = 0.01234927\n",
      "Iteration 2495, loss = 0.01234336\n",
      "Iteration 2496, loss = 0.01233690\n",
      "Iteration 2497, loss = 0.01233042\n",
      "Iteration 2498, loss = 0.01232534\n",
      "Iteration 2499, loss = 0.01231875\n",
      "Iteration 2500, loss = 0.01231238\n",
      "Iteration 2501, loss = 0.01230574\n",
      "Iteration 2502, loss = 0.01229882\n",
      "Iteration 2503, loss = 0.01229407\n",
      "Iteration 2504, loss = 0.01228578\n",
      "Iteration 2505, loss = 0.01228083\n",
      "Iteration 2506, loss = 0.01227351\n",
      "Iteration 2507, loss = 0.01226818\n",
      "Iteration 2508, loss = 0.01225973\n",
      "Iteration 2509, loss = 0.01225191\n",
      "Iteration 2510, loss = 0.01224519\n",
      "Iteration 2511, loss = 0.01224015\n",
      "Iteration 2512, loss = 0.01223212\n",
      "Iteration 2513, loss = 0.01222434\n",
      "Iteration 2514, loss = 0.01221842\n",
      "Iteration 2515, loss = 0.01221465\n",
      "Iteration 2516, loss = 0.01220602\n",
      "Iteration 2517, loss = 0.01219843\n",
      "Iteration 2518, loss = 0.01219252\n",
      "Iteration 2519, loss = 0.01218589\n",
      "Iteration 2520, loss = 0.01217947\n",
      "Iteration 2521, loss = 0.01217394\n",
      "Iteration 2522, loss = 0.01216687\n",
      "Iteration 2523, loss = 0.01216085\n",
      "Iteration 2524, loss = 0.01215455\n",
      "Iteration 2525, loss = 0.01214785\n",
      "Iteration 2526, loss = 0.01214372\n",
      "Iteration 2527, loss = 0.01213597\n",
      "Iteration 2528, loss = 0.01212984\n",
      "Iteration 2529, loss = 0.01212311\n",
      "Iteration 2530, loss = 0.01211737\n",
      "Iteration 2531, loss = 0.01210967\n",
      "Iteration 2532, loss = 0.01210659\n",
      "Iteration 2533, loss = 0.01209943\n",
      "Iteration 2534, loss = 0.01209348\n",
      "Iteration 2535, loss = 0.01208790\n",
      "Iteration 2536, loss = 0.01208202\n",
      "Iteration 2537, loss = 0.01207649\n",
      "Iteration 2538, loss = 0.01207046\n",
      "Iteration 2539, loss = 0.01206552\n",
      "Iteration 2540, loss = 0.01205976\n",
      "Iteration 2541, loss = 0.01205380\n",
      "Iteration 2542, loss = 0.01204800\n",
      "Iteration 2543, loss = 0.01204240\n",
      "Iteration 2544, loss = 0.01203685\n",
      "Iteration 2545, loss = 0.01203164\n",
      "Iteration 2546, loss = 0.01202556\n",
      "Iteration 2547, loss = 0.01202081\n",
      "Iteration 2548, loss = 0.01201488\n",
      "Iteration 2549, loss = 0.01200914\n",
      "Iteration 2550, loss = 0.01200410\n",
      "Iteration 2551, loss = 0.01199789\n",
      "Iteration 2552, loss = 0.01199242\n",
      "Iteration 2553, loss = 0.01198731\n",
      "Iteration 2554, loss = 0.01198130\n",
      "Iteration 2555, loss = 0.01197554\n",
      "Iteration 2556, loss = 0.01197014\n",
      "Iteration 2557, loss = 0.01196434\n",
      "Iteration 2558, loss = 0.01195867\n",
      "Iteration 2559, loss = 0.01195310\n",
      "Iteration 2560, loss = 0.01194758\n",
      "Iteration 2561, loss = 0.01194228\n",
      "Iteration 2562, loss = 0.01193684\n",
      "Iteration 2563, loss = 0.01193240\n",
      "Iteration 2564, loss = 0.01192665\n",
      "Iteration 2565, loss = 0.01192118\n",
      "Iteration 2566, loss = 0.01191509\n",
      "Iteration 2567, loss = 0.01191170\n",
      "Iteration 2568, loss = 0.01190292\n",
      "Iteration 2569, loss = 0.01189784\n",
      "Iteration 2570, loss = 0.01189301\n",
      "Iteration 2571, loss = 0.01188466\n",
      "Iteration 2572, loss = 0.01187961\n",
      "Iteration 2573, loss = 0.01187337\n",
      "Iteration 2574, loss = 0.01186734\n",
      "Iteration 2575, loss = 0.01186155\n",
      "Iteration 2576, loss = 0.01185599\n",
      "Iteration 2577, loss = 0.01184943\n",
      "Iteration 2578, loss = 0.01184320\n",
      "Iteration 2579, loss = 0.01183930\n",
      "Iteration 2580, loss = 0.01183270\n",
      "Iteration 2581, loss = 0.01182589\n",
      "Iteration 2582, loss = 0.01182025\n",
      "Iteration 2583, loss = 0.01181340\n",
      "Iteration 2584, loss = 0.01180838\n",
      "Iteration 2585, loss = 0.01180281\n",
      "Iteration 2586, loss = 0.01179678\n",
      "Iteration 2587, loss = 0.01179112\n",
      "Iteration 2588, loss = 0.01178556\n",
      "Iteration 2589, loss = 0.01177912\n",
      "Iteration 2590, loss = 0.01177375\n",
      "Iteration 2591, loss = 0.01176808\n",
      "Iteration 2592, loss = 0.01176201\n",
      "Iteration 2593, loss = 0.01175799\n",
      "Iteration 2594, loss = 0.01175246\n",
      "Iteration 2595, loss = 0.01174624\n",
      "Iteration 2596, loss = 0.01174066\n",
      "Iteration 2597, loss = 0.01173529\n",
      "Iteration 2598, loss = 0.01173055\n",
      "Iteration 2599, loss = 0.01172487\n",
      "Iteration 2600, loss = 0.01172024\n",
      "Iteration 2601, loss = 0.01171361\n",
      "Iteration 2602, loss = 0.01170808\n",
      "Iteration 2603, loss = 0.01170356\n",
      "Iteration 2604, loss = 0.01169754\n",
      "Iteration 2605, loss = 0.01169179\n",
      "Iteration 2606, loss = 0.01168593\n",
      "Iteration 2607, loss = 0.01168054\n",
      "Iteration 2608, loss = 0.01167525\n",
      "Iteration 2609, loss = 0.01167074\n",
      "Iteration 2610, loss = 0.01166497\n",
      "Iteration 2611, loss = 0.01165988\n",
      "Iteration 2612, loss = 0.01165474\n",
      "Iteration 2613, loss = 0.01164919\n",
      "Iteration 2614, loss = 0.01164378\n",
      "Iteration 2615, loss = 0.01163845\n",
      "Iteration 2616, loss = 0.01163285\n",
      "Iteration 2617, loss = 0.01162778\n",
      "Iteration 2618, loss = 0.01162024\n",
      "Iteration 2619, loss = 0.01161410\n",
      "Iteration 2620, loss = 0.01160707\n",
      "Iteration 2621, loss = 0.01160089\n",
      "Iteration 2622, loss = 0.01159577\n",
      "Iteration 2623, loss = 0.01158901\n",
      "Iteration 2624, loss = 0.01158340\n",
      "Iteration 2625, loss = 0.01157700\n",
      "Iteration 2626, loss = 0.01157132\n",
      "Iteration 2627, loss = 0.01156544\n",
      "Iteration 2628, loss = 0.01156034\n",
      "Iteration 2629, loss = 0.01155392\n",
      "Iteration 2630, loss = 0.01154819\n",
      "Iteration 2631, loss = 0.01154266\n",
      "Iteration 2632, loss = 0.01153701\n",
      "Iteration 2633, loss = 0.01153236\n",
      "Iteration 2634, loss = 0.01152703\n",
      "Iteration 2635, loss = 0.01152073\n",
      "Iteration 2636, loss = 0.01151606\n",
      "Iteration 2637, loss = 0.01151030\n",
      "Iteration 2638, loss = 0.01150782\n",
      "Iteration 2639, loss = 0.01150000\n",
      "Iteration 2640, loss = 0.01149566\n",
      "Iteration 2641, loss = 0.01149073\n",
      "Iteration 2642, loss = 0.01148490\n",
      "Iteration 2643, loss = 0.01147962\n",
      "Iteration 2644, loss = 0.01147452\n",
      "Iteration 2645, loss = 0.01146934\n",
      "Iteration 2646, loss = 0.01146590\n",
      "Iteration 2647, loss = 0.01146089\n",
      "Iteration 2648, loss = 0.01145553\n",
      "Iteration 2649, loss = 0.01144956\n",
      "Iteration 2650, loss = 0.01144468\n",
      "Iteration 2651, loss = 0.01143814\n",
      "Iteration 2652, loss = 0.01143233\n",
      "Iteration 2653, loss = 0.01142712\n",
      "Iteration 2654, loss = 0.01142035\n",
      "Iteration 2655, loss = 0.01141491\n",
      "Iteration 2656, loss = 0.01141046\n",
      "Iteration 2657, loss = 0.01140368\n",
      "Iteration 2658, loss = 0.01139725\n",
      "Iteration 2659, loss = 0.01139243\n",
      "Iteration 2660, loss = 0.01138589\n",
      "Iteration 2661, loss = 0.01138110\n",
      "Iteration 2662, loss = 0.01137569\n",
      "Iteration 2663, loss = 0.01136999\n",
      "Iteration 2664, loss = 0.01136411\n",
      "Iteration 2665, loss = 0.01135885\n",
      "Iteration 2666, loss = 0.01135451\n",
      "Iteration 2667, loss = 0.01134847\n",
      "Iteration 2668, loss = 0.01134350\n",
      "Iteration 2669, loss = 0.01133782\n",
      "Iteration 2670, loss = 0.01133260\n",
      "Iteration 2671, loss = 0.01132732\n",
      "Iteration 2672, loss = 0.01132394\n",
      "Iteration 2673, loss = 0.01131895\n",
      "Iteration 2674, loss = 0.01131267\n",
      "Iteration 2675, loss = 0.01130761\n",
      "Iteration 2676, loss = 0.01130226\n",
      "Iteration 2677, loss = 0.01129707\n",
      "Iteration 2678, loss = 0.01129213\n",
      "Iteration 2679, loss = 0.01128744\n",
      "Iteration 2680, loss = 0.01128175\n",
      "Iteration 2681, loss = 0.01127745\n",
      "Iteration 2682, loss = 0.01127148\n",
      "Iteration 2683, loss = 0.01126675\n",
      "Iteration 2684, loss = 0.01126131\n",
      "Iteration 2685, loss = 0.01125625\n",
      "Iteration 2686, loss = 0.01125134\n",
      "Iteration 2687, loss = 0.01124624\n",
      "Iteration 2688, loss = 0.01124147\n",
      "Iteration 2689, loss = 0.01123636\n",
      "Iteration 2690, loss = 0.01123171\n",
      "Iteration 2691, loss = 0.01122758\n",
      "Iteration 2692, loss = 0.01122240\n",
      "Iteration 2693, loss = 0.01121770\n",
      "Iteration 2694, loss = 0.01121508\n",
      "Iteration 2695, loss = 0.01120809\n",
      "Iteration 2696, loss = 0.01120329\n",
      "Iteration 2697, loss = 0.01119789\n",
      "Iteration 2698, loss = 0.01119312\n",
      "Iteration 2699, loss = 0.01118818\n",
      "Iteration 2700, loss = 0.01118290\n",
      "Iteration 2701, loss = 0.01117897\n",
      "Iteration 2702, loss = 0.01117373\n",
      "Iteration 2703, loss = 0.01116778\n",
      "Iteration 2704, loss = 0.01116276\n",
      "Iteration 2705, loss = 0.01115776\n",
      "Iteration 2706, loss = 0.01115310\n",
      "Iteration 2707, loss = 0.01114770\n",
      "Iteration 2708, loss = 0.01114307\n",
      "Iteration 2709, loss = 0.01113823\n",
      "Iteration 2710, loss = 0.01113650\n",
      "Iteration 2711, loss = 0.01112989\n",
      "Iteration 2712, loss = 0.01112591\n",
      "Iteration 2713, loss = 0.01112131\n",
      "Iteration 2714, loss = 0.01111955\n",
      "Iteration 2715, loss = 0.01111375\n",
      "Iteration 2716, loss = 0.01110709\n",
      "Iteration 2717, loss = 0.01110195\n",
      "Iteration 2718, loss = 0.01109645\n",
      "Iteration 2719, loss = 0.01109062\n",
      "Iteration 2720, loss = 0.01108602\n",
      "Iteration 2721, loss = 0.01107946\n",
      "Iteration 2722, loss = 0.01107416\n",
      "Iteration 2723, loss = 0.01106829\n",
      "Iteration 2724, loss = 0.01106196\n",
      "Iteration 2725, loss = 0.01105727\n",
      "Iteration 2726, loss = 0.01105171\n",
      "Iteration 2727, loss = 0.01104774\n",
      "Iteration 2728, loss = 0.01104079\n",
      "Iteration 2729, loss = 0.01103584\n",
      "Iteration 2730, loss = 0.01103063\n",
      "Iteration 2731, loss = 0.01102503\n",
      "Iteration 2732, loss = 0.01101982\n",
      "Iteration 2733, loss = 0.01101406\n",
      "Iteration 2734, loss = 0.01100852\n",
      "Iteration 2735, loss = 0.01100293\n",
      "Iteration 2736, loss = 0.01099790\n",
      "Iteration 2737, loss = 0.01099137\n",
      "Iteration 2738, loss = 0.01098667\n",
      "Iteration 2739, loss = 0.01098246\n",
      "Iteration 2740, loss = 0.01097586\n",
      "Iteration 2741, loss = 0.01097159\n",
      "Iteration 2742, loss = 0.01096626\n",
      "Iteration 2743, loss = 0.01096071\n",
      "Iteration 2744, loss = 0.01095564\n",
      "Iteration 2745, loss = 0.01095068\n",
      "Iteration 2746, loss = 0.01094474\n",
      "Iteration 2747, loss = 0.01094132\n",
      "Iteration 2748, loss = 0.01093525\n",
      "Iteration 2749, loss = 0.01092877\n",
      "Iteration 2750, loss = 0.01092308\n",
      "Iteration 2751, loss = 0.01092061\n",
      "Iteration 2752, loss = 0.01091262\n",
      "Iteration 2753, loss = 0.01090781\n",
      "Iteration 2754, loss = 0.01090273\n",
      "Iteration 2755, loss = 0.01089714\n",
      "Iteration 2756, loss = 0.01089262\n",
      "Iteration 2757, loss = 0.01088724\n",
      "Iteration 2758, loss = 0.01088217\n",
      "Iteration 2759, loss = 0.01087692\n",
      "Iteration 2760, loss = 0.01087313\n",
      "Iteration 2761, loss = 0.01086757\n",
      "Iteration 2762, loss = 0.01086265\n",
      "Iteration 2763, loss = 0.01085732\n",
      "Iteration 2764, loss = 0.01085258\n",
      "Iteration 2765, loss = 0.01084778\n",
      "Iteration 2766, loss = 0.01084251\n",
      "Iteration 2767, loss = 0.01083774\n",
      "Iteration 2768, loss = 0.01083296\n",
      "Iteration 2769, loss = 0.01082863\n",
      "Iteration 2770, loss = 0.01082368\n",
      "Iteration 2771, loss = 0.01081892\n",
      "Iteration 2772, loss = 0.01081450\n",
      "Iteration 2773, loss = 0.01080957\n",
      "Iteration 2774, loss = 0.01080535\n",
      "Iteration 2775, loss = 0.01080039\n",
      "Iteration 2776, loss = 0.01079525\n",
      "Iteration 2777, loss = 0.01079039\n",
      "Iteration 2778, loss = 0.01078580\n",
      "Iteration 2779, loss = 0.01078188\n",
      "Iteration 2780, loss = 0.01077665\n",
      "Iteration 2781, loss = 0.01077212\n",
      "Iteration 2782, loss = 0.01076715\n",
      "Iteration 2783, loss = 0.01076218\n",
      "Iteration 2784, loss = 0.01075878\n",
      "Iteration 2785, loss = 0.01075333\n",
      "Iteration 2786, loss = 0.01074815\n",
      "Iteration 2787, loss = 0.01074334\n",
      "Iteration 2788, loss = 0.01073774\n",
      "Iteration 2789, loss = 0.01073325\n",
      "Iteration 2790, loss = 0.01072817\n",
      "Iteration 2791, loss = 0.01072330\n",
      "Iteration 2792, loss = 0.01071826\n",
      "Iteration 2793, loss = 0.01071367\n",
      "Iteration 2794, loss = 0.01070792\n",
      "Iteration 2795, loss = 0.01070386\n",
      "Iteration 2796, loss = 0.01069870\n",
      "Iteration 2797, loss = 0.01069318\n",
      "Iteration 2798, loss = 0.01068852\n",
      "Iteration 2799, loss = 0.01068382\n",
      "Iteration 2800, loss = 0.01067856\n",
      "Iteration 2801, loss = 0.01067459\n",
      "Iteration 2802, loss = 0.01066908\n",
      "Iteration 2803, loss = 0.01066404\n",
      "Iteration 2804, loss = 0.01065951\n",
      "Iteration 2805, loss = 0.01065461\n",
      "Iteration 2806, loss = 0.01065020\n",
      "Iteration 2807, loss = 0.01064380\n",
      "Iteration 2808, loss = 0.01063920\n",
      "Iteration 2809, loss = 0.01063458\n",
      "Iteration 2810, loss = 0.01062834\n",
      "Iteration 2811, loss = 0.01062358\n",
      "Iteration 2812, loss = 0.01061904\n",
      "Iteration 2813, loss = 0.01061426\n",
      "Iteration 2814, loss = 0.01060924\n",
      "Iteration 2815, loss = 0.01060457\n",
      "Iteration 2816, loss = 0.01060212\n",
      "Iteration 2817, loss = 0.01059575\n",
      "Iteration 2818, loss = 0.01059135\n",
      "Iteration 2819, loss = 0.01058604\n",
      "Iteration 2820, loss = 0.01058140\n",
      "Iteration 2821, loss = 0.01057617\n",
      "Iteration 2822, loss = 0.01057187\n",
      "Iteration 2823, loss = 0.01056675\n",
      "Iteration 2824, loss = 0.01056215\n",
      "Iteration 2825, loss = 0.01055814\n",
      "Iteration 2826, loss = 0.01055436\n",
      "Iteration 2827, loss = 0.01054919\n",
      "Iteration 2828, loss = 0.01054464\n",
      "Iteration 2829, loss = 0.01053957\n",
      "Iteration 2830, loss = 0.01053600\n",
      "Iteration 2831, loss = 0.01053104\n",
      "Iteration 2832, loss = 0.01052947\n",
      "Iteration 2833, loss = 0.01052265\n",
      "Iteration 2834, loss = 0.01051919\n",
      "Iteration 2835, loss = 0.01051392\n",
      "Iteration 2836, loss = 0.01050932\n",
      "Iteration 2837, loss = 0.01050511\n",
      "Iteration 2838, loss = 0.01050059\n",
      "Iteration 2839, loss = 0.01049704\n",
      "Iteration 2840, loss = 0.01049253\n",
      "Iteration 2841, loss = 0.01048779\n",
      "Iteration 2842, loss = 0.01048453\n",
      "Iteration 2843, loss = 0.01047877\n",
      "Iteration 2844, loss = 0.01047441\n",
      "Iteration 2845, loss = 0.01046981\n",
      "Iteration 2846, loss = 0.01046539\n",
      "Iteration 2847, loss = 0.01045987\n",
      "Iteration 2848, loss = 0.01045521\n",
      "Iteration 2849, loss = 0.01045020\n",
      "Iteration 2850, loss = 0.01044570\n",
      "Iteration 2851, loss = 0.01044071\n",
      "Iteration 2852, loss = 0.01043453\n",
      "Iteration 2853, loss = 0.01042946\n",
      "Iteration 2854, loss = 0.01042495\n",
      "Iteration 2855, loss = 0.01041996\n",
      "Iteration 2856, loss = 0.01041509\n",
      "Iteration 2857, loss = 0.01041074\n",
      "Iteration 2858, loss = 0.01040617\n",
      "Iteration 2859, loss = 0.01040162\n",
      "Iteration 2860, loss = 0.01039737\n",
      "Iteration 2861, loss = 0.01039287\n",
      "Iteration 2862, loss = 0.01038860\n",
      "Iteration 2863, loss = 0.01038450\n",
      "Iteration 2864, loss = 0.01038041\n",
      "Iteration 2865, loss = 0.01037602\n",
      "Iteration 2866, loss = 0.01037151\n",
      "Iteration 2867, loss = 0.01036711\n",
      "Iteration 2868, loss = 0.01036352\n",
      "Iteration 2869, loss = 0.01035830\n",
      "Iteration 2870, loss = 0.01035367\n",
      "Iteration 2871, loss = 0.01034881\n",
      "Iteration 2872, loss = 0.01034464\n",
      "Iteration 2873, loss = 0.01034111\n",
      "Iteration 2874, loss = 0.01033569\n",
      "Iteration 2875, loss = 0.01033140\n",
      "Iteration 2876, loss = 0.01032743\n",
      "Iteration 2877, loss = 0.01032316\n",
      "Iteration 2878, loss = 0.01031871\n",
      "Iteration 2879, loss = 0.01031305\n",
      "Iteration 2880, loss = 0.01030838\n",
      "Iteration 2881, loss = 0.01030277\n",
      "Iteration 2882, loss = 0.01029951\n",
      "Iteration 2883, loss = 0.01029306\n",
      "Iteration 2884, loss = 0.01028964\n",
      "Iteration 2885, loss = 0.01028472\n",
      "Iteration 2886, loss = 0.01027999\n",
      "Iteration 2887, loss = 0.01027515\n",
      "Iteration 2888, loss = 0.01027141\n",
      "Iteration 2889, loss = 0.01026709\n",
      "Iteration 2890, loss = 0.01026255\n",
      "Iteration 2891, loss = 0.01025857\n",
      "Iteration 2892, loss = 0.01025305\n",
      "Iteration 2893, loss = 0.01024955\n",
      "Iteration 2894, loss = 0.01024451\n",
      "Iteration 2895, loss = 0.01024137\n",
      "Iteration 2896, loss = 0.01023518\n",
      "Iteration 2897, loss = 0.01023050\n",
      "Iteration 2898, loss = 0.01022585\n",
      "Iteration 2899, loss = 0.01022104\n",
      "Iteration 2900, loss = 0.01021643\n",
      "Iteration 2901, loss = 0.01021189\n",
      "Iteration 2902, loss = 0.01020798\n",
      "Iteration 2903, loss = 0.01020397\n",
      "Iteration 2904, loss = 0.01019856\n",
      "Iteration 2905, loss = 0.01019369\n",
      "Iteration 2906, loss = 0.01018912\n",
      "Iteration 2907, loss = 0.01018448\n",
      "Iteration 2908, loss = 0.01017956\n",
      "Iteration 2909, loss = 0.01017516\n",
      "Iteration 2910, loss = 0.01017243\n",
      "Iteration 2911, loss = 0.01016636\n",
      "Iteration 2912, loss = 0.01016208\n",
      "Iteration 2913, loss = 0.01015755\n",
      "Iteration 2914, loss = 0.01015338\n",
      "Iteration 2915, loss = 0.01014939\n",
      "Iteration 2916, loss = 0.01014479\n",
      "Iteration 2917, loss = 0.01014034\n",
      "Iteration 2918, loss = 0.01013656\n",
      "Iteration 2919, loss = 0.01013214\n",
      "Iteration 2920, loss = 0.01012919\n",
      "Iteration 2921, loss = 0.01012406\n",
      "Iteration 2922, loss = 0.01012032\n",
      "Iteration 2923, loss = 0.01011626\n",
      "Iteration 2924, loss = 0.01011160\n",
      "Iteration 2925, loss = 0.01010814\n",
      "Iteration 2926, loss = 0.01010352\n",
      "Iteration 2927, loss = 0.01009932\n",
      "Iteration 2928, loss = 0.01009460\n",
      "Iteration 2929, loss = 0.01009081\n",
      "Iteration 2930, loss = 0.01008483\n",
      "Iteration 2931, loss = 0.01008006\n",
      "Iteration 2932, loss = 0.01007638\n",
      "Iteration 2933, loss = 0.01007114\n",
      "Iteration 2934, loss = 0.01006725\n",
      "Iteration 2935, loss = 0.01006309\n",
      "Iteration 2936, loss = 0.01005679\n",
      "Iteration 2937, loss = 0.01005349\n",
      "Iteration 2938, loss = 0.01004821\n",
      "Iteration 2939, loss = 0.01004415\n",
      "Iteration 2940, loss = 0.01003938\n",
      "Iteration 2941, loss = 0.01003530\n",
      "Iteration 2942, loss = 0.01003009\n",
      "Iteration 2943, loss = 0.01002575\n",
      "Iteration 2944, loss = 0.01002117\n",
      "Iteration 2945, loss = 0.01001698\n",
      "Iteration 2946, loss = 0.01001349\n",
      "Iteration 2947, loss = 0.01000876\n",
      "Iteration 2948, loss = 0.01000514\n",
      "Iteration 2949, loss = 0.01000251\n",
      "Iteration 2950, loss = 0.00999730\n",
      "Iteration 2951, loss = 0.00999291\n",
      "Iteration 2952, loss = 0.00998965\n",
      "Iteration 2953, loss = 0.00998474\n",
      "Iteration 2954, loss = 0.00997981\n",
      "Iteration 2955, loss = 0.00997627\n",
      "Iteration 2956, loss = 0.00997301\n",
      "Iteration 2957, loss = 0.00996729\n",
      "Iteration 2958, loss = 0.00996312\n",
      "Iteration 2959, loss = 0.00995922\n",
      "Iteration 2960, loss = 0.00995371\n",
      "Iteration 2961, loss = 0.00994968\n",
      "Iteration 2962, loss = 0.00994543\n",
      "Iteration 2963, loss = 0.00993999\n",
      "Iteration 2964, loss = 0.00993481\n",
      "Iteration 2965, loss = 0.00993036\n",
      "Iteration 2966, loss = 0.00992590\n",
      "Iteration 2967, loss = 0.00992393\n",
      "Iteration 2968, loss = 0.00991799\n",
      "Iteration 2969, loss = 0.00991631\n",
      "Iteration 2970, loss = 0.00990920\n",
      "Iteration 2971, loss = 0.00990500\n",
      "Iteration 2972, loss = 0.00990103\n",
      "Iteration 2973, loss = 0.00989645\n",
      "Iteration 2974, loss = 0.00989213\n",
      "Iteration 2975, loss = 0.00988829\n",
      "Iteration 2976, loss = 0.00988404\n",
      "Iteration 2977, loss = 0.00988005\n",
      "Iteration 2978, loss = 0.00987616\n",
      "Iteration 2979, loss = 0.00987214\n",
      "Iteration 2980, loss = 0.00986832\n",
      "Iteration 2981, loss = 0.00986470\n",
      "Iteration 2982, loss = 0.00986183\n",
      "Iteration 2983, loss = 0.00985726\n",
      "Iteration 2984, loss = 0.00985380\n",
      "Iteration 2985, loss = 0.00984921\n",
      "Iteration 2986, loss = 0.00984526\n",
      "Iteration 2987, loss = 0.00984128\n",
      "Iteration 2988, loss = 0.00983741\n",
      "Iteration 2989, loss = 0.00983349\n",
      "Iteration 2990, loss = 0.00983012\n",
      "Iteration 2991, loss = 0.00982574\n",
      "Iteration 2992, loss = 0.00982161\n",
      "Iteration 2993, loss = 0.00981756\n",
      "Iteration 2994, loss = 0.00981388\n",
      "Iteration 2995, loss = 0.00980958\n",
      "Iteration 2996, loss = 0.00980547\n",
      "Iteration 2997, loss = 0.00980169\n",
      "Iteration 2998, loss = 0.00979762\n",
      "Iteration 2999, loss = 0.00979345\n",
      "Iteration 3000, loss = 0.00978932\n",
      "Iteration 3001, loss = 0.00978638\n",
      "Iteration 3002, loss = 0.00978167\n",
      "Iteration 3003, loss = 0.00977725\n",
      "Iteration 3004, loss = 0.00977295\n",
      "Iteration 3005, loss = 0.00976896\n",
      "Iteration 3006, loss = 0.00976473\n",
      "Iteration 3007, loss = 0.00976113\n",
      "Iteration 3008, loss = 0.00975744\n",
      "Iteration 3009, loss = 0.00975395\n",
      "Iteration 3010, loss = 0.00975154\n",
      "Iteration 3011, loss = 0.00974659\n",
      "Iteration 3012, loss = 0.00974208\n",
      "Iteration 3013, loss = 0.00973735\n",
      "Iteration 3014, loss = 0.00973334\n",
      "Iteration 3015, loss = 0.00972923\n",
      "Iteration 3016, loss = 0.00972497\n",
      "Iteration 3017, loss = 0.00972131\n",
      "Iteration 3018, loss = 0.00971559\n",
      "Iteration 3019, loss = 0.00971189\n",
      "Iteration 3020, loss = 0.00970659\n",
      "Iteration 3021, loss = 0.00970185\n",
      "Iteration 3022, loss = 0.00969666\n",
      "Iteration 3023, loss = 0.00969176\n",
      "Iteration 3024, loss = 0.00968739\n",
      "Iteration 3025, loss = 0.00968465\n",
      "Iteration 3026, loss = 0.00967967\n",
      "Iteration 3027, loss = 0.00967577\n",
      "Iteration 3028, loss = 0.00967118\n",
      "Iteration 3029, loss = 0.00966718\n",
      "Iteration 3030, loss = 0.00966383\n",
      "Iteration 3031, loss = 0.00966070\n",
      "Iteration 3032, loss = 0.00965480\n",
      "Iteration 3033, loss = 0.00965061\n",
      "Iteration 3034, loss = 0.00964647\n",
      "Iteration 3035, loss = 0.00964111\n",
      "Iteration 3036, loss = 0.00963675\n",
      "Iteration 3037, loss = 0.00963169\n",
      "Iteration 3038, loss = 0.00962688\n",
      "Iteration 3039, loss = 0.00962380\n",
      "Iteration 3040, loss = 0.00961812\n",
      "Iteration 3041, loss = 0.00961390\n",
      "Iteration 3042, loss = 0.00961187\n",
      "Iteration 3043, loss = 0.00960552\n",
      "Iteration 3044, loss = 0.00960177\n",
      "Iteration 3045, loss = 0.00959938\n",
      "Iteration 3046, loss = 0.00959581\n",
      "Iteration 3047, loss = 0.00959071\n",
      "Iteration 3048, loss = 0.00958794\n",
      "Iteration 3049, loss = 0.00958365\n",
      "Iteration 3050, loss = 0.00958043\n",
      "Iteration 3051, loss = 0.00957633\n",
      "Iteration 3052, loss = 0.00957232\n",
      "Iteration 3053, loss = 0.00956756\n",
      "Iteration 3054, loss = 0.00956343\n",
      "Iteration 3055, loss = 0.00955959\n",
      "Iteration 3056, loss = 0.00955559\n",
      "Iteration 3057, loss = 0.00955140\n",
      "Iteration 3058, loss = 0.00954730\n",
      "Iteration 3059, loss = 0.00954295\n",
      "Iteration 3060, loss = 0.00953971\n",
      "Iteration 3061, loss = 0.00953583\n",
      "Iteration 3062, loss = 0.00953104\n",
      "Iteration 3063, loss = 0.00952668\n",
      "Iteration 3064, loss = 0.00952281\n",
      "Iteration 3065, loss = 0.00951843\n",
      "Iteration 3066, loss = 0.00951456\n",
      "Iteration 3067, loss = 0.00951089\n",
      "Iteration 3068, loss = 0.00950659\n",
      "Iteration 3069, loss = 0.00950266\n",
      "Iteration 3070, loss = 0.00950072\n",
      "Iteration 3071, loss = 0.00949557\n",
      "Iteration 3072, loss = 0.00949124\n",
      "Iteration 3073, loss = 0.00948738\n",
      "Iteration 3074, loss = 0.00948331\n",
      "Iteration 3075, loss = 0.00947912\n",
      "Iteration 3076, loss = 0.00947500\n",
      "Iteration 3077, loss = 0.00947134\n",
      "Iteration 3078, loss = 0.00946699\n",
      "Iteration 3079, loss = 0.00946279\n",
      "Iteration 3080, loss = 0.00945954\n",
      "Iteration 3081, loss = 0.00945487\n",
      "Iteration 3082, loss = 0.00945124\n",
      "Iteration 3083, loss = 0.00944737\n",
      "Iteration 3084, loss = 0.00944313\n",
      "Iteration 3085, loss = 0.00943897\n",
      "Iteration 3086, loss = 0.00943602\n",
      "Iteration 3087, loss = 0.00943148\n",
      "Iteration 3088, loss = 0.00942815\n",
      "Iteration 3089, loss = 0.00942404\n",
      "Iteration 3090, loss = 0.00941962\n",
      "Iteration 3091, loss = 0.00941541\n",
      "Iteration 3092, loss = 0.00941119\n",
      "Iteration 3093, loss = 0.00940728\n",
      "Iteration 3094, loss = 0.00940393\n",
      "Iteration 3095, loss = 0.00939968\n",
      "Iteration 3096, loss = 0.00939572\n",
      "Iteration 3097, loss = 0.00939166\n",
      "Iteration 3098, loss = 0.00938723\n",
      "Iteration 3099, loss = 0.00938347\n",
      "Iteration 3100, loss = 0.00937966\n",
      "Iteration 3101, loss = 0.00937548\n",
      "Iteration 3102, loss = 0.00937149\n",
      "Iteration 3103, loss = 0.00936737\n",
      "Iteration 3104, loss = 0.00936539\n",
      "Iteration 3105, loss = 0.00936048\n",
      "Iteration 3106, loss = 0.00935738\n",
      "Iteration 3107, loss = 0.00935309\n",
      "Iteration 3108, loss = 0.00934942\n",
      "Iteration 3109, loss = 0.00934581\n",
      "Iteration 3110, loss = 0.00934262\n",
      "Iteration 3111, loss = 0.00933965\n",
      "Iteration 3112, loss = 0.00933569\n",
      "Iteration 3113, loss = 0.00933166\n",
      "Iteration 3114, loss = 0.00932844\n",
      "Iteration 3115, loss = 0.00932405\n",
      "Iteration 3116, loss = 0.00932036\n",
      "Iteration 3117, loss = 0.00931645\n",
      "Iteration 3118, loss = 0.00931178\n",
      "Iteration 3119, loss = 0.00930803\n",
      "Iteration 3120, loss = 0.00930372\n",
      "Iteration 3121, loss = 0.00929957\n",
      "Iteration 3122, loss = 0.00929636\n",
      "Iteration 3123, loss = 0.00929226\n",
      "Iteration 3124, loss = 0.00928869\n",
      "Iteration 3125, loss = 0.00928432\n",
      "Iteration 3126, loss = 0.00928030\n",
      "Iteration 3127, loss = 0.00927752\n",
      "Iteration 3128, loss = 0.00927223\n",
      "Iteration 3129, loss = 0.00926819\n",
      "Iteration 3130, loss = 0.00926435\n",
      "Iteration 3131, loss = 0.00926040\n",
      "Iteration 3132, loss = 0.00925656\n",
      "Iteration 3133, loss = 0.00925283\n",
      "Iteration 3134, loss = 0.00924906\n",
      "Iteration 3135, loss = 0.00924538\n",
      "Iteration 3136, loss = 0.00924173\n",
      "Iteration 3137, loss = 0.00923816\n",
      "Iteration 3138, loss = 0.00923607\n",
      "Iteration 3139, loss = 0.00923128\n",
      "Iteration 3140, loss = 0.00922750\n",
      "Iteration 3141, loss = 0.00922313\n",
      "Iteration 3142, loss = 0.00921903\n",
      "Iteration 3143, loss = 0.00921509\n",
      "Iteration 3144, loss = 0.00921290\n",
      "Iteration 3145, loss = 0.00920713\n",
      "Iteration 3146, loss = 0.00920358\n",
      "Iteration 3147, loss = 0.00919914\n",
      "Iteration 3148, loss = 0.00919505\n",
      "Iteration 3149, loss = 0.00919158\n",
      "Iteration 3150, loss = 0.00918722\n",
      "Iteration 3151, loss = 0.00918592\n",
      "Iteration 3152, loss = 0.00918054\n",
      "Iteration 3153, loss = 0.00917651\n",
      "Iteration 3154, loss = 0.00917276\n",
      "Iteration 3155, loss = 0.00916965\n",
      "Iteration 3156, loss = 0.00916580\n",
      "Iteration 3157, loss = 0.00916364\n",
      "Iteration 3158, loss = 0.00915956\n",
      "Iteration 3159, loss = 0.00915584\n",
      "Iteration 3160, loss = 0.00915146\n",
      "Iteration 3161, loss = 0.00914753\n",
      "Iteration 3162, loss = 0.00914377\n",
      "Iteration 3163, loss = 0.00913930\n",
      "Iteration 3164, loss = 0.00913527\n",
      "Iteration 3165, loss = 0.00913076\n",
      "Iteration 3166, loss = 0.00912878\n",
      "Iteration 3167, loss = 0.00912227\n",
      "Iteration 3168, loss = 0.00911928\n",
      "Iteration 3169, loss = 0.00911484\n",
      "Iteration 3170, loss = 0.00911211\n",
      "Iteration 3171, loss = 0.00910755\n",
      "Iteration 3172, loss = 0.00910229\n",
      "Iteration 3173, loss = 0.00909906\n",
      "Iteration 3174, loss = 0.00909566\n",
      "Iteration 3175, loss = 0.00909094\n",
      "Iteration 3176, loss = 0.00908685\n",
      "Iteration 3177, loss = 0.00908296\n",
      "Iteration 3178, loss = 0.00907972\n",
      "Iteration 3179, loss = 0.00907607\n",
      "Iteration 3180, loss = 0.00907181\n",
      "Iteration 3181, loss = 0.00906866\n",
      "Iteration 3182, loss = 0.00906376\n",
      "Iteration 3183, loss = 0.00906039\n",
      "Iteration 3184, loss = 0.00905652\n",
      "Iteration 3185, loss = 0.00905256\n",
      "Iteration 3186, loss = 0.00904870\n",
      "Iteration 3187, loss = 0.00904513\n",
      "Iteration 3188, loss = 0.00904132\n",
      "Iteration 3189, loss = 0.00903713\n",
      "Iteration 3190, loss = 0.00903383\n",
      "Iteration 3191, loss = 0.00903028\n",
      "Iteration 3192, loss = 0.00902566\n",
      "Iteration 3193, loss = 0.00902224\n",
      "Iteration 3194, loss = 0.00901857\n",
      "Iteration 3195, loss = 0.00901506\n",
      "Iteration 3196, loss = 0.00901166\n",
      "Iteration 3197, loss = 0.00900839\n",
      "Iteration 3198, loss = 0.00900346\n",
      "Iteration 3199, loss = 0.00900009\n",
      "Iteration 3200, loss = 0.00899654\n",
      "Iteration 3201, loss = 0.00899324\n",
      "Iteration 3202, loss = 0.00898949\n",
      "Iteration 3203, loss = 0.00898492\n",
      "Iteration 3204, loss = 0.00898159\n",
      "Iteration 3205, loss = 0.00897816\n",
      "Iteration 3206, loss = 0.00897358\n",
      "Iteration 3207, loss = 0.00896931\n",
      "Iteration 3208, loss = 0.00896507\n",
      "Iteration 3209, loss = 0.00896194\n",
      "Iteration 3210, loss = 0.00895756\n",
      "Iteration 3211, loss = 0.00895342\n",
      "Iteration 3212, loss = 0.00894955\n",
      "Iteration 3213, loss = 0.00894604\n",
      "Iteration 3214, loss = 0.00894197\n",
      "Iteration 3215, loss = 0.00893854\n",
      "Iteration 3216, loss = 0.00893519\n",
      "Iteration 3217, loss = 0.00893178\n",
      "Iteration 3218, loss = 0.00892741\n",
      "Iteration 3219, loss = 0.00892402\n",
      "Iteration 3220, loss = 0.00892055\n",
      "Iteration 3221, loss = 0.00891707\n",
      "Iteration 3222, loss = 0.00891363\n",
      "Iteration 3223, loss = 0.00891089\n",
      "Iteration 3224, loss = 0.00890673\n",
      "Iteration 3225, loss = 0.00890349\n",
      "Iteration 3226, loss = 0.00889991\n",
      "Iteration 3227, loss = 0.00889585\n",
      "Iteration 3228, loss = 0.00889345\n",
      "Iteration 3229, loss = 0.00888951\n",
      "Iteration 3230, loss = 0.00888555\n",
      "Iteration 3231, loss = 0.00888198\n",
      "Iteration 3232, loss = 0.00887820\n",
      "Iteration 3233, loss = 0.00887459\n",
      "Iteration 3234, loss = 0.00887105\n",
      "Iteration 3235, loss = 0.00886902\n",
      "Iteration 3236, loss = 0.00886420\n",
      "Iteration 3237, loss = 0.00885970\n",
      "Iteration 3238, loss = 0.00885710\n",
      "Iteration 3239, loss = 0.00885372\n",
      "Iteration 3240, loss = 0.00884954\n",
      "Iteration 3241, loss = 0.00884613\n",
      "Iteration 3242, loss = 0.00884244\n",
      "Iteration 3243, loss = 0.00883869\n",
      "Iteration 3244, loss = 0.00883526\n",
      "Iteration 3245, loss = 0.00883180\n",
      "Iteration 3246, loss = 0.00882757\n",
      "Iteration 3247, loss = 0.00882500\n",
      "Iteration 3248, loss = 0.00882013\n",
      "Iteration 3249, loss = 0.00881621\n",
      "Iteration 3250, loss = 0.00881261\n",
      "Iteration 3251, loss = 0.00880885\n",
      "Iteration 3252, loss = 0.00880572\n",
      "Iteration 3253, loss = 0.00880233\n",
      "Iteration 3254, loss = 0.00879934\n",
      "Iteration 3255, loss = 0.00879484\n",
      "Iteration 3256, loss = 0.00879198\n",
      "Iteration 3257, loss = 0.00878770\n",
      "Iteration 3258, loss = 0.00878388\n",
      "Iteration 3259, loss = 0.00878043\n",
      "Iteration 3260, loss = 0.00877678\n",
      "Iteration 3261, loss = 0.00877300\n",
      "Iteration 3262, loss = 0.00876957\n",
      "Iteration 3263, loss = 0.00876525\n",
      "Iteration 3264, loss = 0.00876118\n",
      "Iteration 3265, loss = 0.00875803\n",
      "Iteration 3266, loss = 0.00875373\n",
      "Iteration 3267, loss = 0.00875055\n",
      "Iteration 3268, loss = 0.00874687\n",
      "Iteration 3269, loss = 0.00874414\n",
      "Iteration 3270, loss = 0.00874001\n",
      "Iteration 3271, loss = 0.00873697\n",
      "Iteration 3272, loss = 0.00873333\n",
      "Iteration 3273, loss = 0.00873097\n",
      "Iteration 3274, loss = 0.00872625\n",
      "Iteration 3275, loss = 0.00872282\n",
      "Iteration 3276, loss = 0.00871880\n",
      "Iteration 3277, loss = 0.00871627\n",
      "Iteration 3278, loss = 0.00871195\n",
      "Iteration 3279, loss = 0.00870825\n",
      "Iteration 3280, loss = 0.00870410\n",
      "Iteration 3281, loss = 0.00870147\n",
      "Iteration 3282, loss = 0.00869694\n",
      "Iteration 3283, loss = 0.00869428\n",
      "Iteration 3284, loss = 0.00868966\n",
      "Iteration 3285, loss = 0.00868607\n",
      "Iteration 3286, loss = 0.00868225\n",
      "Iteration 3287, loss = 0.00867848\n",
      "Iteration 3288, loss = 0.00867608\n",
      "Iteration 3289, loss = 0.00867170\n",
      "Iteration 3290, loss = 0.00866823\n",
      "Iteration 3291, loss = 0.00866491\n",
      "Iteration 3292, loss = 0.00866131\n",
      "Iteration 3293, loss = 0.00865790\n",
      "Iteration 3294, loss = 0.00865496\n",
      "Iteration 3295, loss = 0.00865137\n",
      "Iteration 3296, loss = 0.00864778\n",
      "Iteration 3297, loss = 0.00864409\n",
      "Iteration 3298, loss = 0.00864040\n",
      "Iteration 3299, loss = 0.00863768\n",
      "Iteration 3300, loss = 0.00863431\n",
      "Iteration 3301, loss = 0.00863301\n",
      "Iteration 3302, loss = 0.00862833\n",
      "Iteration 3303, loss = 0.00862499\n",
      "Iteration 3304, loss = 0.00862163\n",
      "Iteration 3305, loss = 0.00861947\n",
      "Iteration 3306, loss = 0.00861548\n",
      "Iteration 3307, loss = 0.00861142\n",
      "Iteration 3308, loss = 0.00860831\n",
      "Iteration 3309, loss = 0.00860437\n",
      "Iteration 3310, loss = 0.00860106\n",
      "Iteration 3311, loss = 0.00859689\n",
      "Iteration 3312, loss = 0.00859280\n",
      "Iteration 3313, loss = 0.00858896\n",
      "Iteration 3314, loss = 0.00858561\n",
      "Iteration 3315, loss = 0.00858224\n",
      "Iteration 3316, loss = 0.00857802\n",
      "Iteration 3317, loss = 0.00857429\n",
      "Iteration 3318, loss = 0.00857097\n",
      "Iteration 3319, loss = 0.00856766\n",
      "Iteration 3320, loss = 0.00856403\n",
      "Iteration 3321, loss = 0.00856044\n",
      "Iteration 3322, loss = 0.00855762\n",
      "Iteration 3323, loss = 0.00855386\n",
      "Iteration 3324, loss = 0.00855112\n",
      "Iteration 3325, loss = 0.00854783\n",
      "Iteration 3326, loss = 0.00854504\n",
      "Iteration 3327, loss = 0.00854206\n",
      "Iteration 3328, loss = 0.00853961\n",
      "Iteration 3329, loss = 0.00853639\n",
      "Iteration 3330, loss = 0.00853318\n",
      "Iteration 3331, loss = 0.00852983\n",
      "Iteration 3332, loss = 0.00852646\n",
      "Iteration 3333, loss = 0.00852330\n",
      "Iteration 3334, loss = 0.00852019\n",
      "Iteration 3335, loss = 0.00851709\n",
      "Iteration 3336, loss = 0.00851439\n",
      "Iteration 3337, loss = 0.00851145\n",
      "Iteration 3338, loss = 0.00850851\n",
      "Iteration 3339, loss = 0.00850706\n",
      "Iteration 3340, loss = 0.00850275\n",
      "Iteration 3341, loss = 0.00849949\n",
      "Iteration 3342, loss = 0.00849678\n",
      "Iteration 3343, loss = 0.00849318\n",
      "Iteration 3344, loss = 0.00849064\n",
      "Iteration 3345, loss = 0.00848737\n",
      "Iteration 3346, loss = 0.00848465\n",
      "Iteration 3347, loss = 0.00848085\n",
      "Iteration 3348, loss = 0.00847809\n",
      "Iteration 3349, loss = 0.00847484\n",
      "Iteration 3350, loss = 0.00847159\n",
      "Iteration 3351, loss = 0.00846826\n",
      "Iteration 3352, loss = 0.00846500\n",
      "Iteration 3353, loss = 0.00846184\n",
      "Iteration 3354, loss = 0.00845890\n",
      "Iteration 3355, loss = 0.00845627\n",
      "Iteration 3356, loss = 0.00845338\n",
      "Iteration 3357, loss = 0.00844979\n",
      "Iteration 3358, loss = 0.00844595\n",
      "Iteration 3359, loss = 0.00844212\n",
      "Iteration 3360, loss = 0.00843954\n",
      "Iteration 3361, loss = 0.00843536\n",
      "Iteration 3362, loss = 0.00843227\n",
      "Iteration 3363, loss = 0.00842837\n",
      "Iteration 3364, loss = 0.00842523\n",
      "Iteration 3365, loss = 0.00842091\n",
      "Iteration 3366, loss = 0.00841776\n",
      "Iteration 3367, loss = 0.00841297\n",
      "Iteration 3368, loss = 0.00840983\n",
      "Iteration 3369, loss = 0.00840547\n",
      "Iteration 3370, loss = 0.00840287\n",
      "Iteration 3371, loss = 0.00839836\n",
      "Iteration 3372, loss = 0.00839636\n",
      "Iteration 3373, loss = 0.00839249\n",
      "Iteration 3374, loss = 0.00838849\n",
      "Iteration 3375, loss = 0.00838592\n",
      "Iteration 3376, loss = 0.00838218\n",
      "Iteration 3377, loss = 0.00837978\n",
      "Iteration 3378, loss = 0.00837620\n",
      "Iteration 3379, loss = 0.00837287\n",
      "Iteration 3380, loss = 0.00836973\n",
      "Iteration 3381, loss = 0.00836656\n",
      "Iteration 3382, loss = 0.00836360\n",
      "Iteration 3383, loss = 0.00836038\n",
      "Iteration 3384, loss = 0.00835686\n",
      "Iteration 3385, loss = 0.00835408\n",
      "Iteration 3386, loss = 0.00835083\n",
      "Iteration 3387, loss = 0.00834774\n",
      "Iteration 3388, loss = 0.00834472\n",
      "Iteration 3389, loss = 0.00834259\n",
      "Iteration 3390, loss = 0.00833936\n",
      "Iteration 3391, loss = 0.00833606\n",
      "Iteration 3392, loss = 0.00833274\n",
      "Iteration 3393, loss = 0.00832988\n",
      "Iteration 3394, loss = 0.00832653\n",
      "Iteration 3395, loss = 0.00832349\n",
      "Iteration 3396, loss = 0.00832040\n",
      "Iteration 3397, loss = 0.00831855\n",
      "Iteration 3398, loss = 0.00831460\n",
      "Iteration 3399, loss = 0.00831178\n",
      "Iteration 3400, loss = 0.00830834\n",
      "Iteration 3401, loss = 0.00830478\n",
      "Iteration 3402, loss = 0.00830111\n",
      "Iteration 3403, loss = 0.00829801\n",
      "Iteration 3404, loss = 0.00829491\n",
      "Iteration 3405, loss = 0.00829150\n",
      "Iteration 3406, loss = 0.00828841\n",
      "Iteration 3407, loss = 0.00828472\n",
      "Iteration 3408, loss = 0.00828170\n",
      "Iteration 3409, loss = 0.00827857\n",
      "Iteration 3410, loss = 0.00827544\n",
      "Iteration 3411, loss = 0.00827227\n",
      "Iteration 3412, loss = 0.00826914\n",
      "Iteration 3413, loss = 0.00826580\n",
      "Iteration 3414, loss = 0.00826306\n",
      "Iteration 3415, loss = 0.00825986\n",
      "Iteration 3416, loss = 0.00825671\n",
      "Iteration 3417, loss = 0.00825399\n",
      "Iteration 3418, loss = 0.00825024\n",
      "Iteration 3419, loss = 0.00824705\n",
      "Iteration 3420, loss = 0.00824410\n",
      "Iteration 3421, loss = 0.00824115\n",
      "Iteration 3422, loss = 0.00823777\n",
      "Iteration 3423, loss = 0.00823487\n",
      "Iteration 3424, loss = 0.00823158\n",
      "Iteration 3425, loss = 0.00822877\n",
      "Iteration 3426, loss = 0.00822587\n",
      "Iteration 3427, loss = 0.00822451\n",
      "Iteration 3428, loss = 0.00822045\n",
      "Iteration 3429, loss = 0.00821752\n",
      "Iteration 3430, loss = 0.00821539\n",
      "Iteration 3431, loss = 0.00821238\n",
      "Iteration 3432, loss = 0.00820943\n",
      "Iteration 3433, loss = 0.00820590\n",
      "Iteration 3434, loss = 0.00820308\n",
      "Iteration 3435, loss = 0.00819957\n",
      "Iteration 3436, loss = 0.00819662\n",
      "Iteration 3437, loss = 0.00819222\n",
      "Iteration 3438, loss = 0.00818949\n",
      "Iteration 3439, loss = 0.00818575\n",
      "Iteration 3440, loss = 0.00818255\n",
      "Iteration 3441, loss = 0.00817928\n",
      "Iteration 3442, loss = 0.00817560\n",
      "Iteration 3443, loss = 0.00817263\n",
      "Iteration 3444, loss = 0.00817009\n",
      "Iteration 3445, loss = 0.00816689\n",
      "Iteration 3446, loss = 0.00816362\n",
      "Iteration 3447, loss = 0.00816056\n",
      "Iteration 3448, loss = 0.00815780\n",
      "Iteration 3449, loss = 0.00815478\n",
      "Iteration 3450, loss = 0.00815206\n",
      "Iteration 3451, loss = 0.00814949\n",
      "Iteration 3452, loss = 0.00814723\n",
      "Iteration 3453, loss = 0.00814468\n",
      "Iteration 3454, loss = 0.00814209\n",
      "Iteration 3455, loss = 0.00813943\n",
      "Iteration 3456, loss = 0.00813684\n",
      "Iteration 3457, loss = 0.00813524\n",
      "Iteration 3458, loss = 0.00813056\n",
      "Iteration 3459, loss = 0.00812713\n",
      "Iteration 3460, loss = 0.00812429\n",
      "Iteration 3461, loss = 0.00812044\n",
      "Iteration 3462, loss = 0.00811697\n",
      "Iteration 3463, loss = 0.00811399\n",
      "Iteration 3464, loss = 0.00811025\n",
      "Iteration 3465, loss = 0.00810748\n",
      "Iteration 3466, loss = 0.00810403\n",
      "Iteration 3467, loss = 0.00810088\n",
      "Iteration 3468, loss = 0.00809789\n",
      "Iteration 3469, loss = 0.00809492\n",
      "Iteration 3470, loss = 0.00809286\n",
      "Iteration 3471, loss = 0.00809014\n",
      "Iteration 3472, loss = 0.00808656\n",
      "Iteration 3473, loss = 0.00808359\n",
      "Iteration 3474, loss = 0.00808061\n",
      "Iteration 3475, loss = 0.00807744\n",
      "Iteration 3476, loss = 0.00807466\n",
      "Iteration 3477, loss = 0.00807254\n",
      "Iteration 3478, loss = 0.00806895\n",
      "Iteration 3479, loss = 0.00806635\n",
      "Iteration 3480, loss = 0.00806324\n",
      "Iteration 3481, loss = 0.00806042\n",
      "Iteration 3482, loss = 0.00805901\n",
      "Iteration 3483, loss = 0.00805651\n",
      "Iteration 3484, loss = 0.00805350\n",
      "Iteration 3485, loss = 0.00805138\n",
      "Iteration 3486, loss = 0.00804797\n",
      "Iteration 3487, loss = 0.00804525\n",
      "Iteration 3488, loss = 0.00804239\n",
      "Iteration 3489, loss = 0.00803963\n",
      "Iteration 3490, loss = 0.00803726\n",
      "Iteration 3491, loss = 0.00803486\n",
      "Iteration 3492, loss = 0.00803239\n",
      "Iteration 3493, loss = 0.00802909\n",
      "Iteration 3494, loss = 0.00802566\n",
      "Iteration 3495, loss = 0.00802193\n",
      "Iteration 3496, loss = 0.00802037\n",
      "Iteration 3497, loss = 0.00801555\n",
      "Iteration 3498, loss = 0.00801264\n",
      "Iteration 3499, loss = 0.00800921\n",
      "Iteration 3500, loss = 0.00800558\n",
      "Iteration 3501, loss = 0.00800177\n",
      "Iteration 3502, loss = 0.00799749\n",
      "Iteration 3503, loss = 0.00799434\n",
      "Iteration 3504, loss = 0.00799042\n",
      "Iteration 3505, loss = 0.00798751\n",
      "Iteration 3506, loss = 0.00798332\n",
      "Iteration 3507, loss = 0.00797941\n",
      "Iteration 3508, loss = 0.00797713\n",
      "Iteration 3509, loss = 0.00797234\n",
      "Iteration 3510, loss = 0.00797051\n",
      "Iteration 3511, loss = 0.00796640\n",
      "Iteration 3512, loss = 0.00796259\n",
      "Iteration 3513, loss = 0.00796005\n",
      "Iteration 3514, loss = 0.00795658\n",
      "Iteration 3515, loss = 0.00795358\n",
      "Iteration 3516, loss = 0.00795041\n",
      "Iteration 3517, loss = 0.00794778\n",
      "Iteration 3518, loss = 0.00794451\n",
      "Iteration 3519, loss = 0.00794147\n",
      "Iteration 3520, loss = 0.00793845\n",
      "Iteration 3521, loss = 0.00793548\n",
      "Iteration 3522, loss = 0.00793276\n",
      "Iteration 3523, loss = 0.00792973\n",
      "Iteration 3524, loss = 0.00792728\n",
      "Iteration 3525, loss = 0.00792415\n",
      "Iteration 3526, loss = 0.00792210\n",
      "Iteration 3527, loss = 0.00791974\n",
      "Iteration 3528, loss = 0.00791750\n",
      "Iteration 3529, loss = 0.00791351\n",
      "Iteration 3530, loss = 0.00791155\n",
      "Iteration 3531, loss = 0.00790722\n",
      "Iteration 3532, loss = 0.00790560\n",
      "Iteration 3533, loss = 0.00790172\n",
      "Iteration 3534, loss = 0.00789892\n",
      "Iteration 3535, loss = 0.00789623\n",
      "Iteration 3536, loss = 0.00789324\n",
      "Iteration 3537, loss = 0.00789072\n",
      "Iteration 3538, loss = 0.00788827\n",
      "Iteration 3539, loss = 0.00788504\n",
      "Iteration 3540, loss = 0.00788157\n",
      "Iteration 3541, loss = 0.00787875\n",
      "Iteration 3542, loss = 0.00787593\n",
      "Iteration 3543, loss = 0.00787306\n",
      "Iteration 3544, loss = 0.00786985\n",
      "Iteration 3545, loss = 0.00786655\n",
      "Iteration 3546, loss = 0.00786350\n",
      "Iteration 3547, loss = 0.00786042\n",
      "Iteration 3548, loss = 0.00785756\n",
      "Iteration 3549, loss = 0.00785435\n",
      "Iteration 3550, loss = 0.00785165\n",
      "Iteration 3551, loss = 0.00784889\n",
      "Iteration 3552, loss = 0.00784521\n",
      "Iteration 3553, loss = 0.00784156\n",
      "Iteration 3554, loss = 0.00783828\n",
      "Iteration 3555, loss = 0.00783430\n",
      "Iteration 3556, loss = 0.00783115\n",
      "Iteration 3557, loss = 0.00782783\n",
      "Iteration 3558, loss = 0.00782502\n",
      "Iteration 3559, loss = 0.00782173\n",
      "Iteration 3560, loss = 0.00781916\n",
      "Iteration 3561, loss = 0.00781601\n",
      "Iteration 3562, loss = 0.00781302\n",
      "Iteration 3563, loss = 0.00781024\n",
      "Iteration 3564, loss = 0.00780661\n",
      "Iteration 3565, loss = 0.00780374\n",
      "Iteration 3566, loss = 0.00780046\n",
      "Iteration 3567, loss = 0.00779741\n",
      "Iteration 3568, loss = 0.00779436\n",
      "Iteration 3569, loss = 0.00779089\n",
      "Iteration 3570, loss = 0.00778704\n",
      "Iteration 3571, loss = 0.00778419\n",
      "Iteration 3572, loss = 0.00778080\n",
      "Iteration 3573, loss = 0.00777721\n",
      "Iteration 3574, loss = 0.00777518\n",
      "Iteration 3575, loss = 0.00777145\n",
      "Iteration 3576, loss = 0.00776825\n",
      "Iteration 3577, loss = 0.00776503\n",
      "Iteration 3578, loss = 0.00776217\n",
      "Iteration 3579, loss = 0.00775882\n",
      "Iteration 3580, loss = 0.00775614\n",
      "Iteration 3581, loss = 0.00775335\n",
      "Iteration 3582, loss = 0.00775037\n",
      "Iteration 3583, loss = 0.00774739\n",
      "Iteration 3584, loss = 0.00774433\n",
      "Iteration 3585, loss = 0.00774157\n",
      "Iteration 3586, loss = 0.00773919\n",
      "Iteration 3587, loss = 0.00773676\n",
      "Iteration 3588, loss = 0.00773381\n",
      "Iteration 3589, loss = 0.00773185\n",
      "Iteration 3590, loss = 0.00772996\n",
      "Iteration 3591, loss = 0.00772770\n",
      "Iteration 3592, loss = 0.00772422\n",
      "Iteration 3593, loss = 0.00772171\n",
      "Iteration 3594, loss = 0.00771928\n",
      "Iteration 3595, loss = 0.00771594\n",
      "Iteration 3596, loss = 0.00771287\n",
      "Iteration 3597, loss = 0.00771181\n",
      "Iteration 3598, loss = 0.00770817\n",
      "Iteration 3599, loss = 0.00770524\n",
      "Iteration 3600, loss = 0.00770241\n",
      "Iteration 3601, loss = 0.00769983\n",
      "Iteration 3602, loss = 0.00769683\n",
      "Iteration 3603, loss = 0.00769440\n",
      "Iteration 3604, loss = 0.00769154\n",
      "Iteration 3605, loss = 0.00768859\n",
      "Iteration 3606, loss = 0.00768625\n",
      "Iteration 3607, loss = 0.00768273\n",
      "Iteration 3608, loss = 0.00768039\n",
      "Iteration 3609, loss = 0.00767657\n",
      "Iteration 3610, loss = 0.00767355\n",
      "Iteration 3611, loss = 0.00767021\n",
      "Iteration 3612, loss = 0.00766725\n",
      "Iteration 3613, loss = 0.00766513\n",
      "Iteration 3614, loss = 0.00766184\n",
      "Iteration 3615, loss = 0.00765909\n",
      "Iteration 3616, loss = 0.00765682\n",
      "Iteration 3617, loss = 0.00765342\n",
      "Iteration 3618, loss = 0.00765006\n",
      "Iteration 3619, loss = 0.00764723\n",
      "Iteration 3620, loss = 0.00764448\n",
      "Iteration 3621, loss = 0.00764125\n",
      "Iteration 3622, loss = 0.00763863\n",
      "Iteration 3623, loss = 0.00763569\n",
      "Iteration 3624, loss = 0.00763241\n",
      "Iteration 3625, loss = 0.00762967\n",
      "Iteration 3626, loss = 0.00762706\n",
      "Iteration 3627, loss = 0.00762455\n",
      "Iteration 3628, loss = 0.00762211\n",
      "Iteration 3629, loss = 0.00761938\n",
      "Iteration 3630, loss = 0.00761666\n",
      "Iteration 3631, loss = 0.00761489\n",
      "Iteration 3632, loss = 0.00761122\n",
      "Iteration 3633, loss = 0.00760868\n",
      "Iteration 3634, loss = 0.00760586\n",
      "Iteration 3635, loss = 0.00760329\n",
      "Iteration 3636, loss = 0.00760081\n",
      "Iteration 3637, loss = 0.00759732\n",
      "Iteration 3638, loss = 0.00759476\n",
      "Iteration 3639, loss = 0.00759168\n",
      "Iteration 3640, loss = 0.00758893\n",
      "Iteration 3641, loss = 0.00758599\n",
      "Iteration 3642, loss = 0.00758333\n",
      "Iteration 3643, loss = 0.00758051\n",
      "Iteration 3644, loss = 0.00757823\n",
      "Iteration 3645, loss = 0.00757528\n",
      "Iteration 3646, loss = 0.00757250\n",
      "Iteration 3647, loss = 0.00756967\n",
      "Iteration 3648, loss = 0.00756724\n",
      "Iteration 3649, loss = 0.00756443\n",
      "Iteration 3650, loss = 0.00756176\n",
      "Iteration 3651, loss = 0.00755881\n",
      "Iteration 3652, loss = 0.00755591\n",
      "Iteration 3653, loss = 0.00755312\n",
      "Iteration 3654, loss = 0.00755059\n",
      "Iteration 3655, loss = 0.00754671\n",
      "Iteration 3656, loss = 0.00754557\n",
      "Iteration 3657, loss = 0.00754017\n",
      "Iteration 3658, loss = 0.00753732\n",
      "Iteration 3659, loss = 0.00753442\n",
      "Iteration 3660, loss = 0.00753135\n",
      "Iteration 3661, loss = 0.00752876\n",
      "Iteration 3662, loss = 0.00752544\n",
      "Iteration 3663, loss = 0.00752262\n",
      "Iteration 3664, loss = 0.00751948\n",
      "Iteration 3665, loss = 0.00751637\n",
      "Iteration 3666, loss = 0.00751394\n",
      "Iteration 3667, loss = 0.00751077\n",
      "Iteration 3668, loss = 0.00750764\n",
      "Iteration 3669, loss = 0.00750442\n",
      "Iteration 3670, loss = 0.00750158\n",
      "Iteration 3671, loss = 0.00749908\n",
      "Iteration 3672, loss = 0.00749546\n",
      "Iteration 3673, loss = 0.00749258\n",
      "Iteration 3674, loss = 0.00748998\n",
      "Iteration 3675, loss = 0.00748733\n",
      "Iteration 3676, loss = 0.00748523\n",
      "Iteration 3677, loss = 0.00748235\n",
      "Iteration 3678, loss = 0.00748009\n",
      "Iteration 3679, loss = 0.00747708\n",
      "Iteration 3680, loss = 0.00747445\n",
      "Iteration 3681, loss = 0.00747235\n",
      "Iteration 3682, loss = 0.00746892\n",
      "Iteration 3683, loss = 0.00746641\n",
      "Iteration 3684, loss = 0.00746333\n",
      "Iteration 3685, loss = 0.00746131\n",
      "Iteration 3686, loss = 0.00745805\n",
      "Iteration 3687, loss = 0.00745548\n",
      "Iteration 3688, loss = 0.00745267\n",
      "Iteration 3689, loss = 0.00744939\n",
      "Iteration 3690, loss = 0.00744699\n",
      "Iteration 3691, loss = 0.00744493\n",
      "Iteration 3692, loss = 0.00744238\n",
      "Iteration 3693, loss = 0.00743957\n",
      "Iteration 3694, loss = 0.00743725\n",
      "Iteration 3695, loss = 0.00743544\n",
      "Iteration 3696, loss = 0.00743271\n",
      "Iteration 3697, loss = 0.00742935\n",
      "Iteration 3698, loss = 0.00742614\n",
      "Iteration 3699, loss = 0.00742397\n",
      "Iteration 3700, loss = 0.00742047\n",
      "Iteration 3701, loss = 0.00741827\n",
      "Iteration 3702, loss = 0.00741505\n",
      "Iteration 3703, loss = 0.00741190\n",
      "Iteration 3704, loss = 0.00740879\n",
      "Iteration 3705, loss = 0.00740544\n",
      "Iteration 3706, loss = 0.00740370\n",
      "Iteration 3707, loss = 0.00739993\n",
      "Iteration 3708, loss = 0.00739670\n",
      "Iteration 3709, loss = 0.00739374\n",
      "Iteration 3710, loss = 0.00739064\n",
      "Iteration 3711, loss = 0.00738919\n",
      "Iteration 3712, loss = 0.00738622\n",
      "Iteration 3713, loss = 0.00738323\n",
      "Iteration 3714, loss = 0.00738035\n",
      "Iteration 3715, loss = 0.00737751\n",
      "Iteration 3716, loss = 0.00737545\n",
      "Iteration 3717, loss = 0.00737119\n",
      "Iteration 3718, loss = 0.00736919\n",
      "Iteration 3719, loss = 0.00736625\n",
      "Iteration 3720, loss = 0.00736290\n",
      "Iteration 3721, loss = 0.00736040\n",
      "Iteration 3722, loss = 0.00735772\n",
      "Iteration 3723, loss = 0.00735491\n",
      "Iteration 3724, loss = 0.00735177\n",
      "Iteration 3725, loss = 0.00734866\n",
      "Iteration 3726, loss = 0.00734632\n",
      "Iteration 3727, loss = 0.00734297\n",
      "Iteration 3728, loss = 0.00734062\n",
      "Iteration 3729, loss = 0.00733804\n",
      "Iteration 3730, loss = 0.00733509\n",
      "Iteration 3731, loss = 0.00733214\n",
      "Iteration 3732, loss = 0.00732961\n",
      "Iteration 3733, loss = 0.00732664\n",
      "Iteration 3734, loss = 0.00732412\n",
      "Iteration 3735, loss = 0.00732124\n",
      "Iteration 3736, loss = 0.00731907\n",
      "Iteration 3737, loss = 0.00731602\n",
      "Iteration 3738, loss = 0.00731376\n",
      "Iteration 3739, loss = 0.00731112\n",
      "Iteration 3740, loss = 0.00730845\n",
      "Iteration 3741, loss = 0.00730528\n",
      "Iteration 3742, loss = 0.00730264\n",
      "Iteration 3743, loss = 0.00730030\n",
      "Iteration 3744, loss = 0.00729711\n",
      "Iteration 3745, loss = 0.00729426\n",
      "Iteration 3746, loss = 0.00729167\n",
      "Iteration 3747, loss = 0.00728879\n",
      "Iteration 3748, loss = 0.00728641\n",
      "Iteration 3749, loss = 0.00728341\n",
      "Iteration 3750, loss = 0.00728071\n",
      "Iteration 3751, loss = 0.00727822\n",
      "Iteration 3752, loss = 0.00727595\n",
      "Iteration 3753, loss = 0.00727292\n",
      "Iteration 3754, loss = 0.00727071\n",
      "Iteration 3755, loss = 0.00726803\n",
      "Iteration 3756, loss = 0.00726551\n",
      "Iteration 3757, loss = 0.00726282\n",
      "Iteration 3758, loss = 0.00725985\n",
      "Iteration 3759, loss = 0.00725713\n",
      "Iteration 3760, loss = 0.00725493\n",
      "Iteration 3761, loss = 0.00725185\n",
      "Iteration 3762, loss = 0.00724946\n",
      "Iteration 3763, loss = 0.00724646\n",
      "Iteration 3764, loss = 0.00724371\n",
      "Iteration 3765, loss = 0.00724108\n",
      "Iteration 3766, loss = 0.00723857\n",
      "Iteration 3767, loss = 0.00723544\n",
      "Iteration 3768, loss = 0.00723317\n",
      "Iteration 3769, loss = 0.00723016\n",
      "Iteration 3770, loss = 0.00722776\n",
      "Iteration 3771, loss = 0.00722514\n",
      "Iteration 3772, loss = 0.00722220\n",
      "Iteration 3773, loss = 0.00721927\n",
      "Iteration 3774, loss = 0.00721682\n",
      "Iteration 3775, loss = 0.00721432\n",
      "Iteration 3776, loss = 0.00721126\n",
      "Iteration 3777, loss = 0.00720883\n",
      "Iteration 3778, loss = 0.00720566\n",
      "Iteration 3779, loss = 0.00720394\n",
      "Iteration 3780, loss = 0.00720060\n",
      "Iteration 3781, loss = 0.00719873\n",
      "Iteration 3782, loss = 0.00719711\n",
      "Iteration 3783, loss = 0.00719321\n",
      "Iteration 3784, loss = 0.00719060\n",
      "Iteration 3785, loss = 0.00718872\n",
      "Iteration 3786, loss = 0.00718717\n",
      "Iteration 3787, loss = 0.00718371\n",
      "Iteration 3788, loss = 0.00718036\n",
      "Iteration 3789, loss = 0.00717778\n",
      "Iteration 3790, loss = 0.00717530\n",
      "Iteration 3791, loss = 0.00717269\n",
      "Iteration 3792, loss = 0.00717008\n",
      "Iteration 3793, loss = 0.00716824\n",
      "Iteration 3794, loss = 0.00716517\n",
      "Iteration 3795, loss = 0.00716307\n",
      "Iteration 3796, loss = 0.00716016\n",
      "Iteration 3797, loss = 0.00715796\n",
      "Iteration 3798, loss = 0.00715538\n",
      "Iteration 3799, loss = 0.00715294\n",
      "Iteration 3800, loss = 0.00715069\n",
      "Iteration 3801, loss = 0.00714831\n",
      "Iteration 3802, loss = 0.00714596\n",
      "Iteration 3803, loss = 0.00714364\n",
      "Iteration 3804, loss = 0.00714149\n",
      "Iteration 3805, loss = 0.00713894\n",
      "Iteration 3806, loss = 0.00713571\n",
      "Iteration 3807, loss = 0.00713338\n",
      "Iteration 3808, loss = 0.00713105\n",
      "Iteration 3809, loss = 0.00712890\n",
      "Iteration 3810, loss = 0.00712561\n",
      "Iteration 3811, loss = 0.00712414\n",
      "Iteration 3812, loss = 0.00712109\n",
      "Iteration 3813, loss = 0.00711857\n",
      "Iteration 3814, loss = 0.00711640\n",
      "Iteration 3815, loss = 0.00711363\n",
      "Iteration 3816, loss = 0.00711232\n",
      "Iteration 3817, loss = 0.00710864\n",
      "Iteration 3818, loss = 0.00710588\n",
      "Iteration 3819, loss = 0.00710273\n",
      "Iteration 3820, loss = 0.00710036\n",
      "Iteration 3821, loss = 0.00709723\n",
      "Iteration 3822, loss = 0.00709509\n",
      "Iteration 3823, loss = 0.00709174\n",
      "Iteration 3824, loss = 0.00708907\n",
      "Iteration 3825, loss = 0.00708637\n",
      "Iteration 3826, loss = 0.00708465\n",
      "Iteration 3827, loss = 0.00708184\n",
      "Iteration 3828, loss = 0.00707887\n",
      "Iteration 3829, loss = 0.00707610\n",
      "Iteration 3830, loss = 0.00707378\n",
      "Iteration 3831, loss = 0.00707070\n",
      "Iteration 3832, loss = 0.00706829\n",
      "Iteration 3833, loss = 0.00706544\n",
      "Iteration 3834, loss = 0.00706293\n",
      "Iteration 3835, loss = 0.00706035\n",
      "Iteration 3836, loss = 0.00705806\n",
      "Iteration 3837, loss = 0.00705662\n",
      "Iteration 3838, loss = 0.00705290\n",
      "Iteration 3839, loss = 0.00705022\n",
      "Iteration 3840, loss = 0.00704792\n",
      "Iteration 3841, loss = 0.00704527\n",
      "Iteration 3842, loss = 0.00704334\n",
      "Iteration 3843, loss = 0.00704016\n",
      "Iteration 3844, loss = 0.00703714\n",
      "Iteration 3845, loss = 0.00703492\n",
      "Iteration 3846, loss = 0.00703193\n",
      "Iteration 3847, loss = 0.00702996\n",
      "Iteration 3848, loss = 0.00702689\n",
      "Iteration 3849, loss = 0.00702450\n",
      "Iteration 3850, loss = 0.00702166\n",
      "Iteration 3851, loss = 0.00701925\n",
      "Iteration 3852, loss = 0.00701675\n",
      "Iteration 3853, loss = 0.00701432\n",
      "Iteration 3854, loss = 0.00701177\n",
      "Iteration 3855, loss = 0.00700920\n",
      "Iteration 3856, loss = 0.00700676\n",
      "Iteration 3857, loss = 0.00700453\n",
      "Iteration 3858, loss = 0.00700255\n",
      "Iteration 3859, loss = 0.00699979\n",
      "Iteration 3860, loss = 0.00699760\n",
      "Iteration 3861, loss = 0.00699448\n",
      "Iteration 3862, loss = 0.00699292\n",
      "Iteration 3863, loss = 0.00698992\n",
      "Iteration 3864, loss = 0.00698697\n",
      "Iteration 3865, loss = 0.00698438\n",
      "Iteration 3866, loss = 0.00698235\n",
      "Iteration 3867, loss = 0.00697927\n",
      "Iteration 3868, loss = 0.00697671\n",
      "Iteration 3869, loss = 0.00697417\n",
      "Iteration 3870, loss = 0.00697165\n",
      "Iteration 3871, loss = 0.00696938\n",
      "Iteration 3872, loss = 0.00696626\n",
      "Iteration 3873, loss = 0.00696398\n",
      "Iteration 3874, loss = 0.00696116\n",
      "Iteration 3875, loss = 0.00695832\n",
      "Iteration 3876, loss = 0.00695620\n",
      "Iteration 3877, loss = 0.00695365\n",
      "Iteration 3878, loss = 0.00695098\n",
      "Iteration 3879, loss = 0.00694873\n",
      "Iteration 3880, loss = 0.00694640\n",
      "Iteration 3881, loss = 0.00694366\n",
      "Iteration 3882, loss = 0.00694122\n",
      "Iteration 3883, loss = 0.00693898\n",
      "Iteration 3884, loss = 0.00693649\n",
      "Iteration 3885, loss = 0.00693360\n",
      "Iteration 3886, loss = 0.00693132\n",
      "Iteration 3887, loss = 0.00692906\n",
      "Iteration 3888, loss = 0.00692648\n",
      "Iteration 3889, loss = 0.00692428\n",
      "Iteration 3890, loss = 0.00692231\n",
      "Iteration 3891, loss = 0.00691936\n",
      "Iteration 3892, loss = 0.00691706\n",
      "Iteration 3893, loss = 0.00691443\n",
      "Iteration 3894, loss = 0.00691220\n",
      "Iteration 3895, loss = 0.00690942\n",
      "Iteration 3896, loss = 0.00690709\n",
      "Iteration 3897, loss = 0.00690431\n",
      "Iteration 3898, loss = 0.00690196\n",
      "Iteration 3899, loss = 0.00689939\n",
      "Iteration 3900, loss = 0.00689697\n",
      "Iteration 3901, loss = 0.00689441\n",
      "Iteration 3902, loss = 0.00689279\n",
      "Iteration 3903, loss = 0.00688940\n",
      "Iteration 3904, loss = 0.00688734\n",
      "Iteration 3905, loss = 0.00688499\n",
      "Iteration 3906, loss = 0.00688232\n",
      "Iteration 3907, loss = 0.00688007\n",
      "Iteration 3908, loss = 0.00687751\n",
      "Iteration 3909, loss = 0.00687481\n",
      "Iteration 3910, loss = 0.00687286\n",
      "Iteration 3911, loss = 0.00687046\n",
      "Iteration 3912, loss = 0.00686787\n",
      "Iteration 3913, loss = 0.00686504\n",
      "Iteration 3914, loss = 0.00686271\n",
      "Iteration 3915, loss = 0.00686021\n",
      "Iteration 3916, loss = 0.00685830\n",
      "Iteration 3917, loss = 0.00685535\n",
      "Iteration 3918, loss = 0.00685320\n",
      "Iteration 3919, loss = 0.00685058\n",
      "Iteration 3920, loss = 0.00684795\n",
      "Iteration 3921, loss = 0.00684633\n",
      "Iteration 3922, loss = 0.00684340\n",
      "Iteration 3923, loss = 0.00684101\n",
      "Iteration 3924, loss = 0.00683854\n",
      "Iteration 3925, loss = 0.00683606\n",
      "Iteration 3926, loss = 0.00683371\n",
      "Iteration 3927, loss = 0.00683127\n",
      "Iteration 3928, loss = 0.00682895\n",
      "Iteration 3929, loss = 0.00682657\n",
      "Iteration 3930, loss = 0.00682390\n",
      "Iteration 3931, loss = 0.00682203\n",
      "Iteration 3932, loss = 0.00681966\n",
      "Iteration 3933, loss = 0.00681704\n",
      "Iteration 3934, loss = 0.00681444\n",
      "Iteration 3935, loss = 0.00681216\n",
      "Iteration 3936, loss = 0.00681019\n",
      "Iteration 3937, loss = 0.00680837\n",
      "Iteration 3938, loss = 0.00680535\n",
      "Iteration 3939, loss = 0.00680319\n",
      "Iteration 3940, loss = 0.00680057\n",
      "Iteration 3941, loss = 0.00679846\n",
      "Iteration 3942, loss = 0.00679572\n",
      "Iteration 3943, loss = 0.00679350\n",
      "Iteration 3944, loss = 0.00679092\n",
      "Iteration 3945, loss = 0.00678863\n",
      "Iteration 3946, loss = 0.00678652\n",
      "Iteration 3947, loss = 0.00678454\n",
      "Iteration 3948, loss = 0.00678259\n",
      "Iteration 3949, loss = 0.00677982\n",
      "Iteration 3950, loss = 0.00677829\n",
      "Iteration 3951, loss = 0.00677549\n",
      "Iteration 3952, loss = 0.00677337\n",
      "Iteration 3953, loss = 0.00677143\n",
      "Iteration 3954, loss = 0.00676944\n",
      "Iteration 3955, loss = 0.00676698\n",
      "Iteration 3956, loss = 0.00676501\n",
      "Iteration 3957, loss = 0.00676315\n",
      "Iteration 3958, loss = 0.00676114\n",
      "Iteration 3959, loss = 0.00675897\n",
      "Iteration 3960, loss = 0.00675622\n",
      "Iteration 3961, loss = 0.00675378\n",
      "Iteration 3962, loss = 0.00675145\n",
      "Iteration 3963, loss = 0.00674912\n",
      "Iteration 3964, loss = 0.00674631\n",
      "Iteration 3965, loss = 0.00674332\n",
      "Iteration 3966, loss = 0.00674130\n",
      "Iteration 3967, loss = 0.00673840\n",
      "Iteration 3968, loss = 0.00673574\n",
      "Iteration 3969, loss = 0.00673318\n",
      "Iteration 3970, loss = 0.00673080\n",
      "Iteration 3971, loss = 0.00672886\n",
      "Iteration 3972, loss = 0.00672586\n",
      "Iteration 3973, loss = 0.00672352\n",
      "Iteration 3974, loss = 0.00672109\n",
      "Iteration 3975, loss = 0.00671856\n",
      "Iteration 3976, loss = 0.00671694\n",
      "Iteration 3977, loss = 0.00671431\n",
      "Iteration 3978, loss = 0.00671206\n",
      "Iteration 3979, loss = 0.00670951\n",
      "Iteration 3980, loss = 0.00670738\n",
      "Iteration 3981, loss = 0.00670524\n",
      "Iteration 3982, loss = 0.00670260\n",
      "Iteration 3983, loss = 0.00670035\n",
      "Iteration 3984, loss = 0.00669926\n",
      "Iteration 3985, loss = 0.00669633\n",
      "Iteration 3986, loss = 0.00669378\n",
      "Iteration 3987, loss = 0.00669144\n",
      "Iteration 3988, loss = 0.00668929\n",
      "Iteration 3989, loss = 0.00668692\n",
      "Iteration 3990, loss = 0.00668474\n",
      "Iteration 3991, loss = 0.00668234\n",
      "Iteration 3992, loss = 0.00667982\n",
      "Iteration 3993, loss = 0.00667774\n",
      "Iteration 3994, loss = 0.00667579\n",
      "Iteration 3995, loss = 0.00667355\n",
      "Iteration 3996, loss = 0.00667160\n",
      "Iteration 3997, loss = 0.00666971\n",
      "Iteration 3998, loss = 0.00666771\n",
      "Iteration 3999, loss = 0.00666639\n",
      "Iteration 4000, loss = 0.00666394\n",
      "Iteration 4001, loss = 0.00666198\n",
      "Iteration 4002, loss = 0.00666003\n",
      "Iteration 4003, loss = 0.00665814\n",
      "Iteration 4004, loss = 0.00665595\n",
      "Iteration 4005, loss = 0.00665444\n",
      "Iteration 4006, loss = 0.00665166\n",
      "Iteration 4007, loss = 0.00664950\n",
      "Iteration 4008, loss = 0.00664727\n",
      "Iteration 4009, loss = 0.00664486\n",
      "Iteration 4010, loss = 0.00664242\n",
      "Iteration 4011, loss = 0.00663988\n",
      "Iteration 4012, loss = 0.00663871\n",
      "Iteration 4013, loss = 0.00663547\n",
      "Iteration 4014, loss = 0.00663381\n",
      "Iteration 4015, loss = 0.00663094\n",
      "Iteration 4016, loss = 0.00662926\n",
      "Iteration 4017, loss = 0.00662698\n",
      "Iteration 4018, loss = 0.00662427\n",
      "Iteration 4019, loss = 0.00662196\n",
      "Iteration 4020, loss = 0.00661984\n",
      "Iteration 4021, loss = 0.00661793\n",
      "Iteration 4022, loss = 0.00661618\n",
      "Iteration 4023, loss = 0.00661373\n",
      "Iteration 4024, loss = 0.00661141\n",
      "Iteration 4025, loss = 0.00660976\n",
      "Iteration 4026, loss = 0.00660727\n",
      "Iteration 4027, loss = 0.00660549\n",
      "Iteration 4028, loss = 0.00660328\n",
      "Iteration 4029, loss = 0.00660134\n",
      "Iteration 4030, loss = 0.00659929\n",
      "Iteration 4031, loss = 0.00659751\n",
      "Iteration 4032, loss = 0.00659539\n",
      "Iteration 4033, loss = 0.00659336\n",
      "Iteration 4034, loss = 0.00659273\n",
      "Iteration 4035, loss = 0.00658966\n",
      "Iteration 4036, loss = 0.00658777\n",
      "Iteration 4037, loss = 0.00658547\n",
      "Iteration 4038, loss = 0.00658356\n",
      "Iteration 4039, loss = 0.00658118\n",
      "Iteration 4040, loss = 0.00657865\n",
      "Iteration 4041, loss = 0.00657622\n",
      "Iteration 4042, loss = 0.00657345\n",
      "Iteration 4043, loss = 0.00657183\n",
      "Iteration 4044, loss = 0.00656893\n",
      "Iteration 4045, loss = 0.00656643\n",
      "Iteration 4046, loss = 0.00656402\n",
      "Iteration 4047, loss = 0.00656154\n",
      "Iteration 4048, loss = 0.00656003\n",
      "Iteration 4049, loss = 0.00655717\n",
      "Iteration 4050, loss = 0.00655489\n",
      "Iteration 4051, loss = 0.00655252\n",
      "Iteration 4052, loss = 0.00655070\n",
      "Iteration 4053, loss = 0.00654804\n",
      "Iteration 4054, loss = 0.00654569\n",
      "Iteration 4055, loss = 0.00654338\n",
      "Iteration 4056, loss = 0.00654102\n",
      "Iteration 4057, loss = 0.00653911\n",
      "Iteration 4058, loss = 0.00653649\n",
      "Iteration 4059, loss = 0.00653418\n",
      "Iteration 4060, loss = 0.00653201\n",
      "Iteration 4061, loss = 0.00653018\n",
      "Iteration 4062, loss = 0.00652799\n",
      "Iteration 4063, loss = 0.00652544\n",
      "Iteration 4064, loss = 0.00652307\n",
      "Iteration 4065, loss = 0.00652088\n",
      "Iteration 4066, loss = 0.00651864\n",
      "Iteration 4067, loss = 0.00651663\n",
      "Iteration 4068, loss = 0.00651511\n",
      "Iteration 4069, loss = 0.00651242\n",
      "Iteration 4070, loss = 0.00651041\n",
      "Iteration 4071, loss = 0.00650837\n",
      "Iteration 4072, loss = 0.00650625\n",
      "Iteration 4073, loss = 0.00650490\n",
      "Iteration 4074, loss = 0.00650263\n",
      "Iteration 4075, loss = 0.00650015\n",
      "Iteration 4076, loss = 0.00649755\n",
      "Iteration 4077, loss = 0.00649487\n",
      "Iteration 4078, loss = 0.00649255\n",
      "Iteration 4079, loss = 0.00649025\n",
      "Iteration 4080, loss = 0.00648756\n",
      "Iteration 4081, loss = 0.00648571\n",
      "Iteration 4082, loss = 0.00648296\n",
      "Iteration 4083, loss = 0.00647983\n",
      "Iteration 4084, loss = 0.00647795\n",
      "Iteration 4085, loss = 0.00647490\n",
      "Iteration 4086, loss = 0.00647300\n",
      "Iteration 4087, loss = 0.00647021\n",
      "Iteration 4088, loss = 0.00646823\n",
      "Iteration 4089, loss = 0.00646631\n",
      "Iteration 4090, loss = 0.00646393\n",
      "Iteration 4091, loss = 0.00646177\n",
      "Iteration 4092, loss = 0.00645982\n",
      "Iteration 4093, loss = 0.00645787\n",
      "Iteration 4094, loss = 0.00645598\n",
      "Iteration 4095, loss = 0.00645393\n",
      "Iteration 4096, loss = 0.00645207\n",
      "Iteration 4097, loss = 0.00645137\n",
      "Iteration 4098, loss = 0.00644875\n",
      "Iteration 4099, loss = 0.00644636\n",
      "Iteration 4100, loss = 0.00644418\n",
      "Iteration 4101, loss = 0.00644244\n",
      "Iteration 4102, loss = 0.00644046\n",
      "Iteration 4103, loss = 0.00643809\n",
      "Iteration 4104, loss = 0.00643618\n",
      "Iteration 4105, loss = 0.00643415\n",
      "Iteration 4106, loss = 0.00643340\n",
      "Iteration 4107, loss = 0.00643012\n",
      "Iteration 4108, loss = 0.00642820\n",
      "Iteration 4109, loss = 0.00642584\n",
      "Iteration 4110, loss = 0.00642362\n",
      "Iteration 4111, loss = 0.00642124\n",
      "Iteration 4112, loss = 0.00641913\n",
      "Iteration 4113, loss = 0.00641777\n",
      "Iteration 4114, loss = 0.00641480\n",
      "Iteration 4115, loss = 0.00641279\n",
      "Iteration 4116, loss = 0.00640929\n",
      "Iteration 4117, loss = 0.00640786\n",
      "Iteration 4118, loss = 0.00640655\n",
      "Iteration 4119, loss = 0.00640281\n",
      "Iteration 4120, loss = 0.00640035\n",
      "Iteration 4121, loss = 0.00639809\n",
      "Iteration 4122, loss = 0.00639574\n",
      "Iteration 4123, loss = 0.00639419\n",
      "Iteration 4124, loss = 0.00639140\n",
      "Iteration 4125, loss = 0.00638912\n",
      "Iteration 4126, loss = 0.00638703\n",
      "Iteration 4127, loss = 0.00638433\n",
      "Iteration 4128, loss = 0.00638229\n",
      "Iteration 4129, loss = 0.00638029\n",
      "Iteration 4130, loss = 0.00637780\n",
      "Iteration 4131, loss = 0.00637561\n",
      "Iteration 4132, loss = 0.00637320\n",
      "Iteration 4133, loss = 0.00637223\n",
      "Iteration 4134, loss = 0.00636948\n",
      "Iteration 4135, loss = 0.00636787\n",
      "Iteration 4136, loss = 0.00636633\n",
      "Iteration 4137, loss = 0.00636378\n",
      "Iteration 4138, loss = 0.00636167\n",
      "Iteration 4139, loss = 0.00635971\n",
      "Iteration 4140, loss = 0.00635729\n",
      "Iteration 4141, loss = 0.00635544\n",
      "Iteration 4142, loss = 0.00635267\n",
      "Iteration 4143, loss = 0.00635037\n",
      "Iteration 4144, loss = 0.00634779\n",
      "Iteration 4145, loss = 0.00634560\n",
      "Iteration 4146, loss = 0.00634345\n",
      "Iteration 4147, loss = 0.00634074\n",
      "Iteration 4148, loss = 0.00633844\n",
      "Iteration 4149, loss = 0.00633641\n",
      "Iteration 4150, loss = 0.00633435\n",
      "Iteration 4151, loss = 0.00633219\n",
      "Iteration 4152, loss = 0.00632987\n",
      "Iteration 4153, loss = 0.00632780\n",
      "Iteration 4154, loss = 0.00632557\n",
      "Iteration 4155, loss = 0.00632358\n",
      "Iteration 4156, loss = 0.00632132\n",
      "Iteration 4157, loss = 0.00631934\n",
      "Iteration 4158, loss = 0.00631720\n",
      "Iteration 4159, loss = 0.00631533\n",
      "Iteration 4160, loss = 0.00631338\n",
      "Iteration 4161, loss = 0.00631155\n",
      "Iteration 4162, loss = 0.00630941\n",
      "Iteration 4163, loss = 0.00630755\n",
      "Iteration 4164, loss = 0.00630564\n",
      "Iteration 4165, loss = 0.00630383\n",
      "Iteration 4166, loss = 0.00630165\n",
      "Iteration 4167, loss = 0.00630011\n",
      "Iteration 4168, loss = 0.00629816\n",
      "Iteration 4169, loss = 0.00629617\n",
      "Iteration 4170, loss = 0.00629435\n",
      "Iteration 4171, loss = 0.00629242\n",
      "Iteration 4172, loss = 0.00629131\n",
      "Iteration 4173, loss = 0.00628963\n",
      "Iteration 4174, loss = 0.00628701\n",
      "Iteration 4175, loss = 0.00628495\n",
      "Iteration 4176, loss = 0.00628260\n",
      "Iteration 4177, loss = 0.00628022\n",
      "Iteration 4178, loss = 0.00627869\n",
      "Iteration 4179, loss = 0.00627619\n",
      "Iteration 4180, loss = 0.00627414\n",
      "Iteration 4181, loss = 0.00627190\n",
      "Iteration 4182, loss = 0.00626972\n",
      "Iteration 4183, loss = 0.00626756\n",
      "Iteration 4184, loss = 0.00626552\n",
      "Iteration 4185, loss = 0.00626342\n",
      "Iteration 4186, loss = 0.00626099\n",
      "Iteration 4187, loss = 0.00625894\n",
      "Iteration 4188, loss = 0.00625674\n",
      "Iteration 4189, loss = 0.00625434\n",
      "Iteration 4190, loss = 0.00625241\n",
      "Iteration 4191, loss = 0.00625099\n",
      "Iteration 4192, loss = 0.00624868\n",
      "Iteration 4193, loss = 0.00624716\n",
      "Iteration 4194, loss = 0.00624509\n",
      "Iteration 4195, loss = 0.00624319\n",
      "Iteration 4196, loss = 0.00624179\n",
      "Iteration 4197, loss = 0.00623862\n",
      "Iteration 4198, loss = 0.00623695\n",
      "Iteration 4199, loss = 0.00623431\n",
      "Iteration 4200, loss = 0.00623248\n",
      "Iteration 4201, loss = 0.00623017\n",
      "Iteration 4202, loss = 0.00622812\n",
      "Iteration 4203, loss = 0.00622604\n",
      "Iteration 4204, loss = 0.00622415\n",
      "Iteration 4205, loss = 0.00622197\n",
      "Iteration 4206, loss = 0.00621977\n",
      "Iteration 4207, loss = 0.00621784\n",
      "Iteration 4208, loss = 0.00621599\n",
      "Iteration 4209, loss = 0.00621424\n",
      "Iteration 4210, loss = 0.00621236\n",
      "Iteration 4211, loss = 0.00621105\n",
      "Iteration 4212, loss = 0.00620907\n",
      "Iteration 4213, loss = 0.00620652\n",
      "Iteration 4214, loss = 0.00620495\n",
      "Iteration 4215, loss = 0.00620232\n",
      "Iteration 4216, loss = 0.00620001\n",
      "Iteration 4217, loss = 0.00619752\n",
      "Iteration 4218, loss = 0.00619508\n",
      "Iteration 4219, loss = 0.00619378\n",
      "Iteration 4220, loss = 0.00619093\n",
      "Iteration 4221, loss = 0.00619018\n",
      "Iteration 4222, loss = 0.00618779\n",
      "Iteration 4223, loss = 0.00618555\n",
      "Iteration 4224, loss = 0.00618325\n",
      "Iteration 4225, loss = 0.00618095\n",
      "Iteration 4226, loss = 0.00617914\n",
      "Iteration 4227, loss = 0.00617852\n",
      "Iteration 4228, loss = 0.00617559\n",
      "Iteration 4229, loss = 0.00617348\n",
      "Iteration 4230, loss = 0.00617183\n",
      "Iteration 4231, loss = 0.00617045\n",
      "Iteration 4232, loss = 0.00616766\n",
      "Iteration 4233, loss = 0.00616554\n",
      "Iteration 4234, loss = 0.00616391\n",
      "Iteration 4235, loss = 0.00616170\n",
      "Iteration 4236, loss = 0.00615972\n",
      "Iteration 4237, loss = 0.00615771\n",
      "Iteration 4238, loss = 0.00615571\n",
      "Iteration 4239, loss = 0.00615377\n",
      "Iteration 4240, loss = 0.00615189\n",
      "Iteration 4241, loss = 0.00614994\n",
      "Iteration 4242, loss = 0.00614810\n",
      "Iteration 4243, loss = 0.00614609\n",
      "Iteration 4244, loss = 0.00614411\n",
      "Iteration 4245, loss = 0.00614197\n",
      "Iteration 4246, loss = 0.00613992\n",
      "Iteration 4247, loss = 0.00613798\n",
      "Iteration 4248, loss = 0.00613588\n",
      "Iteration 4249, loss = 0.00613571\n",
      "Iteration 4250, loss = 0.00613178\n",
      "Iteration 4251, loss = 0.00612967\n",
      "Iteration 4252, loss = 0.00612734\n",
      "Iteration 4253, loss = 0.00612607\n",
      "Iteration 4254, loss = 0.00612320\n",
      "Iteration 4255, loss = 0.00612085\n",
      "Iteration 4256, loss = 0.00611868\n",
      "Iteration 4257, loss = 0.00611646\n",
      "Iteration 4258, loss = 0.00611422\n",
      "Iteration 4259, loss = 0.00611235\n",
      "Iteration 4260, loss = 0.00611015\n",
      "Iteration 4261, loss = 0.00610833\n",
      "Iteration 4262, loss = 0.00610634\n",
      "Iteration 4263, loss = 0.00610423\n",
      "Iteration 4264, loss = 0.00610191\n",
      "Iteration 4265, loss = 0.00609981\n",
      "Iteration 4266, loss = 0.00609773\n",
      "Iteration 4267, loss = 0.00609655\n",
      "Iteration 4268, loss = 0.00609349\n",
      "Iteration 4269, loss = 0.00609134\n",
      "Iteration 4270, loss = 0.00608902\n",
      "Iteration 4271, loss = 0.00608722\n",
      "Iteration 4272, loss = 0.00608490\n",
      "Iteration 4273, loss = 0.00608307\n",
      "Iteration 4274, loss = 0.00608089\n",
      "Iteration 4275, loss = 0.00607867\n",
      "Iteration 4276, loss = 0.00607759\n",
      "Iteration 4277, loss = 0.00607465\n",
      "Iteration 4278, loss = 0.00607251\n",
      "Iteration 4279, loss = 0.00607024\n",
      "Iteration 4280, loss = 0.00606841\n",
      "Iteration 4281, loss = 0.00606638\n",
      "Iteration 4282, loss = 0.00606412\n",
      "Iteration 4283, loss = 0.00606192\n",
      "Iteration 4284, loss = 0.00606007\n",
      "Iteration 4285, loss = 0.00605795\n",
      "Iteration 4286, loss = 0.00605699\n",
      "Iteration 4287, loss = 0.00605444\n",
      "Iteration 4288, loss = 0.00605268\n",
      "Iteration 4289, loss = 0.00605091\n",
      "Iteration 4290, loss = 0.00604868\n",
      "Iteration 4291, loss = 0.00604654\n",
      "Iteration 4292, loss = 0.00604488\n",
      "Iteration 4293, loss = 0.00604297\n",
      "Iteration 4294, loss = 0.00604182\n",
      "Iteration 4295, loss = 0.00603990\n",
      "Iteration 4296, loss = 0.00603808\n",
      "Iteration 4297, loss = 0.00603618\n",
      "Iteration 4298, loss = 0.00603402\n",
      "Iteration 4299, loss = 0.00603249\n",
      "Iteration 4300, loss = 0.00603020\n",
      "Iteration 4301, loss = 0.00602808\n",
      "Iteration 4302, loss = 0.00602613\n",
      "Iteration 4303, loss = 0.00602425\n",
      "Iteration 4304, loss = 0.00602243\n",
      "Iteration 4305, loss = 0.00602045\n",
      "Iteration 4306, loss = 0.00601890\n",
      "Iteration 4307, loss = 0.00601696\n",
      "Iteration 4308, loss = 0.00601554\n",
      "Iteration 4309, loss = 0.00601376\n",
      "Iteration 4310, loss = 0.00601196\n",
      "Iteration 4311, loss = 0.00601021\n",
      "Iteration 4312, loss = 0.00600878\n",
      "Iteration 4313, loss = 0.00600680\n",
      "Iteration 4314, loss = 0.00600466\n",
      "Iteration 4315, loss = 0.00600299\n",
      "Iteration 4316, loss = 0.00600142\n",
      "Iteration 4317, loss = 0.00599921\n",
      "Iteration 4318, loss = 0.00599728\n",
      "Iteration 4319, loss = 0.00599548\n",
      "Iteration 4320, loss = 0.00599357\n",
      "Iteration 4321, loss = 0.00599184\n",
      "Iteration 4322, loss = 0.00598991\n",
      "Iteration 4323, loss = 0.00598809\n",
      "Iteration 4324, loss = 0.00598632\n",
      "Iteration 4325, loss = 0.00598451\n",
      "Iteration 4326, loss = 0.00598263\n",
      "Iteration 4327, loss = 0.00598100\n",
      "Iteration 4328, loss = 0.00597911\n",
      "Iteration 4329, loss = 0.00597708\n",
      "Iteration 4330, loss = 0.00597534\n",
      "Iteration 4331, loss = 0.00597323\n",
      "Iteration 4332, loss = 0.00597187\n",
      "Iteration 4333, loss = 0.00596934\n",
      "Iteration 4334, loss = 0.00596709\n",
      "Iteration 4335, loss = 0.00596546\n",
      "Iteration 4336, loss = 0.00596336\n",
      "Iteration 4337, loss = 0.00596165\n",
      "Iteration 4338, loss = 0.00595969\n",
      "Iteration 4339, loss = 0.00595773\n",
      "Iteration 4340, loss = 0.00595598\n",
      "Iteration 4341, loss = 0.00595374\n",
      "Iteration 4342, loss = 0.00595221\n",
      "Iteration 4343, loss = 0.00594988\n",
      "Iteration 4344, loss = 0.00594836\n",
      "Iteration 4345, loss = 0.00594745\n",
      "Iteration 4346, loss = 0.00594478\n",
      "Iteration 4347, loss = 0.00594265\n",
      "Iteration 4348, loss = 0.00594054\n",
      "Iteration 4349, loss = 0.00593871\n",
      "Iteration 4350, loss = 0.00593671\n",
      "Iteration 4351, loss = 0.00593455\n",
      "Iteration 4352, loss = 0.00593261\n",
      "Iteration 4353, loss = 0.00593089\n",
      "Iteration 4354, loss = 0.00592859\n",
      "Iteration 4355, loss = 0.00592697\n",
      "Iteration 4356, loss = 0.00592518\n",
      "Iteration 4357, loss = 0.00592322\n",
      "Iteration 4358, loss = 0.00592155\n",
      "Iteration 4359, loss = 0.00591945\n",
      "Iteration 4360, loss = 0.00591747\n",
      "Iteration 4361, loss = 0.00591609\n",
      "Iteration 4362, loss = 0.00591379\n",
      "Iteration 4363, loss = 0.00591194\n",
      "Iteration 4364, loss = 0.00590987\n",
      "Iteration 4365, loss = 0.00590836\n",
      "Iteration 4366, loss = 0.00590658\n",
      "Iteration 4367, loss = 0.00590440\n",
      "Iteration 4368, loss = 0.00590302\n",
      "Iteration 4369, loss = 0.00590054\n",
      "Iteration 4370, loss = 0.00589866\n",
      "Iteration 4371, loss = 0.00589669\n",
      "Iteration 4372, loss = 0.00589471\n",
      "Iteration 4373, loss = 0.00589348\n",
      "Iteration 4374, loss = 0.00589164\n",
      "Iteration 4375, loss = 0.00588953\n",
      "Iteration 4376, loss = 0.00588815\n",
      "Iteration 4377, loss = 0.00588604\n",
      "Iteration 4378, loss = 0.00588381\n",
      "Iteration 4379, loss = 0.00588206\n",
      "Iteration 4380, loss = 0.00588026\n",
      "Iteration 4381, loss = 0.00587844\n",
      "Iteration 4382, loss = 0.00587654\n",
      "Iteration 4383, loss = 0.00587482\n",
      "Iteration 4384, loss = 0.00587315\n",
      "Iteration 4385, loss = 0.00587131\n",
      "Iteration 4386, loss = 0.00586938\n",
      "Iteration 4387, loss = 0.00586761\n",
      "Iteration 4388, loss = 0.00586600\n",
      "Iteration 4389, loss = 0.00586378\n",
      "Iteration 4390, loss = 0.00586265\n",
      "Iteration 4391, loss = 0.00586006\n",
      "Iteration 4392, loss = 0.00585825\n",
      "Iteration 4393, loss = 0.00585594\n",
      "Iteration 4394, loss = 0.00585441\n",
      "Iteration 4395, loss = 0.00585229\n",
      "Iteration 4396, loss = 0.00585032\n",
      "Iteration 4397, loss = 0.00584856\n",
      "Iteration 4398, loss = 0.00584659\n",
      "Iteration 4399, loss = 0.00584498\n",
      "Iteration 4400, loss = 0.00584319\n",
      "Iteration 4401, loss = 0.00584107\n",
      "Iteration 4402, loss = 0.00583932\n",
      "Iteration 4403, loss = 0.00583713\n",
      "Iteration 4404, loss = 0.00583563\n",
      "Iteration 4405, loss = 0.00583345\n",
      "Iteration 4406, loss = 0.00583144\n",
      "Iteration 4407, loss = 0.00582978\n",
      "Iteration 4408, loss = 0.00582756\n",
      "Iteration 4409, loss = 0.00582560\n",
      "Iteration 4410, loss = 0.00582369\n",
      "Iteration 4411, loss = 0.00582173\n",
      "Iteration 4412, loss = 0.00581992\n",
      "Iteration 4413, loss = 0.00581859\n",
      "Iteration 4414, loss = 0.00581663\n",
      "Iteration 4415, loss = 0.00581483\n",
      "Iteration 4416, loss = 0.00581328\n",
      "Iteration 4417, loss = 0.00581142\n",
      "Iteration 4418, loss = 0.00580946\n",
      "Iteration 4419, loss = 0.00580786\n",
      "Iteration 4420, loss = 0.00580614\n",
      "Iteration 4421, loss = 0.00580433\n",
      "Iteration 4422, loss = 0.00580266\n",
      "Iteration 4423, loss = 0.00580097\n",
      "Iteration 4424, loss = 0.00579887\n",
      "Iteration 4425, loss = 0.00579695\n",
      "Iteration 4426, loss = 0.00579601\n",
      "Iteration 4427, loss = 0.00579342\n",
      "Iteration 4428, loss = 0.00579151\n",
      "Iteration 4429, loss = 0.00578971\n",
      "Iteration 4430, loss = 0.00578759\n",
      "Iteration 4431, loss = 0.00578555\n",
      "Iteration 4432, loss = 0.00578384\n",
      "Iteration 4433, loss = 0.00578171\n",
      "Iteration 4434, loss = 0.00577994\n",
      "Iteration 4435, loss = 0.00577817\n",
      "Iteration 4436, loss = 0.00577639\n",
      "Iteration 4437, loss = 0.00577437\n",
      "Iteration 4438, loss = 0.00577250\n",
      "Iteration 4439, loss = 0.00577080\n",
      "Iteration 4440, loss = 0.00576882\n",
      "Iteration 4441, loss = 0.00576681\n",
      "Iteration 4442, loss = 0.00576490\n",
      "Iteration 4443, loss = 0.00576347\n",
      "Iteration 4444, loss = 0.00576135\n",
      "Iteration 4445, loss = 0.00575966\n",
      "Iteration 4446, loss = 0.00575827\n",
      "Iteration 4447, loss = 0.00575622\n",
      "Iteration 4448, loss = 0.00575452\n",
      "Iteration 4449, loss = 0.00575277\n",
      "Iteration 4450, loss = 0.00575084\n",
      "Iteration 4451, loss = 0.00574936\n",
      "Iteration 4452, loss = 0.00574755\n",
      "Iteration 4453, loss = 0.00574588\n",
      "Iteration 4454, loss = 0.00574401\n",
      "Iteration 4455, loss = 0.00574230\n",
      "Iteration 4456, loss = 0.00574071\n",
      "Iteration 4457, loss = 0.00573905\n",
      "Iteration 4458, loss = 0.00573759\n",
      "Iteration 4459, loss = 0.00573614\n",
      "Iteration 4460, loss = 0.00573352\n",
      "Iteration 4461, loss = 0.00573167\n",
      "Iteration 4462, loss = 0.00572961\n",
      "Iteration 4463, loss = 0.00572836\n",
      "Iteration 4464, loss = 0.00572617\n",
      "Iteration 4465, loss = 0.00572486\n",
      "Iteration 4466, loss = 0.00572306\n",
      "Iteration 4467, loss = 0.00572151\n",
      "Iteration 4468, loss = 0.00571986\n",
      "Iteration 4469, loss = 0.00571820\n",
      "Iteration 4470, loss = 0.00571661\n",
      "Iteration 4471, loss = 0.00571472\n",
      "Iteration 4472, loss = 0.00571304\n",
      "Iteration 4473, loss = 0.00571143\n",
      "Iteration 4474, loss = 0.00570971\n",
      "Iteration 4475, loss = 0.00570795\n",
      "Iteration 4476, loss = 0.00570620\n",
      "Iteration 4477, loss = 0.00570481\n",
      "Iteration 4478, loss = 0.00570319\n",
      "Iteration 4479, loss = 0.00570152\n",
      "Iteration 4480, loss = 0.00570074\n",
      "Iteration 4481, loss = 0.00569851\n",
      "Iteration 4482, loss = 0.00569678\n",
      "Iteration 4483, loss = 0.00569510\n",
      "Iteration 4484, loss = 0.00569339\n",
      "Iteration 4485, loss = 0.00569182\n",
      "Iteration 4486, loss = 0.00569036\n",
      "Iteration 4487, loss = 0.00568837\n",
      "Iteration 4488, loss = 0.00568680\n",
      "Iteration 4489, loss = 0.00568481\n",
      "Iteration 4490, loss = 0.00568351\n",
      "Iteration 4491, loss = 0.00568142\n",
      "Iteration 4492, loss = 0.00567982\n",
      "Iteration 4493, loss = 0.00567790\n",
      "Iteration 4494, loss = 0.00567629\n",
      "Iteration 4495, loss = 0.00567461\n",
      "Iteration 4496, loss = 0.00567307\n",
      "Iteration 4497, loss = 0.00567153\n",
      "Iteration 4498, loss = 0.00566976\n",
      "Iteration 4499, loss = 0.00566781\n",
      "Iteration 4500, loss = 0.00566666\n",
      "Iteration 4501, loss = 0.00566402\n",
      "Iteration 4502, loss = 0.00566191\n",
      "Iteration 4503, loss = 0.00566064\n",
      "Iteration 4504, loss = 0.00565788\n",
      "Iteration 4505, loss = 0.00565600\n",
      "Iteration 4506, loss = 0.00565467\n",
      "Iteration 4507, loss = 0.00565233\n",
      "Iteration 4508, loss = 0.00565020\n",
      "Iteration 4509, loss = 0.00564841\n",
      "Iteration 4510, loss = 0.00564591\n",
      "Iteration 4511, loss = 0.00564467\n",
      "Iteration 4512, loss = 0.00564227\n",
      "Iteration 4513, loss = 0.00564023\n",
      "Iteration 4514, loss = 0.00563959\n",
      "Iteration 4515, loss = 0.00563763\n",
      "Iteration 4516, loss = 0.00563578\n",
      "Iteration 4517, loss = 0.00563443\n",
      "Iteration 4518, loss = 0.00563232\n",
      "Iteration 4519, loss = 0.00563081\n",
      "Iteration 4520, loss = 0.00562907\n",
      "Iteration 4521, loss = 0.00562737\n",
      "Iteration 4522, loss = 0.00562573\n",
      "Iteration 4523, loss = 0.00562405\n",
      "Iteration 4524, loss = 0.00562230\n",
      "Iteration 4525, loss = 0.00562017\n",
      "Iteration 4526, loss = 0.00561891\n",
      "Iteration 4527, loss = 0.00561663\n",
      "Iteration 4528, loss = 0.00561499\n",
      "Iteration 4529, loss = 0.00561322\n",
      "Iteration 4530, loss = 0.00561126\n",
      "Iteration 4531, loss = 0.00560929\n",
      "Iteration 4532, loss = 0.00560752\n",
      "Iteration 4533, loss = 0.00560595\n",
      "Iteration 4534, loss = 0.00560392\n",
      "Iteration 4535, loss = 0.00560206\n",
      "Iteration 4536, loss = 0.00560054\n",
      "Iteration 4537, loss = 0.00559948\n",
      "Iteration 4538, loss = 0.00559735\n",
      "Iteration 4539, loss = 0.00559547\n",
      "Iteration 4540, loss = 0.00559368\n",
      "Iteration 4541, loss = 0.00559209\n",
      "Iteration 4542, loss = 0.00559044\n",
      "Iteration 4543, loss = 0.00558872\n",
      "Iteration 4544, loss = 0.00558707\n",
      "Iteration 4545, loss = 0.00558535\n",
      "Iteration 4546, loss = 0.00558359\n",
      "Iteration 4547, loss = 0.00558182\n",
      "Iteration 4548, loss = 0.00557999\n",
      "Iteration 4549, loss = 0.00557801\n",
      "Iteration 4550, loss = 0.00557660\n",
      "Iteration 4551, loss = 0.00557460\n",
      "Iteration 4552, loss = 0.00557256\n",
      "Iteration 4553, loss = 0.00557083\n",
      "Iteration 4554, loss = 0.00556912\n",
      "Iteration 4555, loss = 0.00556729\n",
      "Iteration 4556, loss = 0.00556557\n",
      "Iteration 4557, loss = 0.00556386\n",
      "Iteration 4558, loss = 0.00556217\n",
      "Iteration 4559, loss = 0.00556062\n",
      "Iteration 4560, loss = 0.00555881\n",
      "Iteration 4561, loss = 0.00555718\n",
      "Iteration 4562, loss = 0.00555542\n",
      "Iteration 4563, loss = 0.00555362\n",
      "Iteration 4564, loss = 0.00555229\n",
      "Iteration 4565, loss = 0.00555050\n",
      "Iteration 4566, loss = 0.00554890\n",
      "Iteration 4567, loss = 0.00554724\n",
      "Iteration 4568, loss = 0.00554561\n",
      "Iteration 4569, loss = 0.00554419\n",
      "Iteration 4570, loss = 0.00554230\n",
      "Iteration 4571, loss = 0.00554054\n",
      "Iteration 4572, loss = 0.00553909\n",
      "Iteration 4573, loss = 0.00553711\n",
      "Iteration 4574, loss = 0.00553532\n",
      "Iteration 4575, loss = 0.00553370\n",
      "Iteration 4576, loss = 0.00553281\n",
      "Iteration 4577, loss = 0.00552991\n",
      "Iteration 4578, loss = 0.00552872\n",
      "Iteration 4579, loss = 0.00552699\n",
      "Iteration 4580, loss = 0.00552493\n",
      "Iteration 4581, loss = 0.00552330\n",
      "Iteration 4582, loss = 0.00552136\n",
      "Iteration 4583, loss = 0.00551965\n",
      "Iteration 4584, loss = 0.00551826\n",
      "Iteration 4585, loss = 0.00551649\n",
      "Iteration 4586, loss = 0.00551461\n",
      "Iteration 4587, loss = 0.00551307\n",
      "Iteration 4588, loss = 0.00551149\n",
      "Iteration 4589, loss = 0.00551113\n",
      "Iteration 4590, loss = 0.00550820\n",
      "Iteration 4591, loss = 0.00550647\n",
      "Iteration 4592, loss = 0.00550481\n",
      "Iteration 4593, loss = 0.00550401\n",
      "Iteration 4594, loss = 0.00550174\n",
      "Iteration 4595, loss = 0.00550020\n",
      "Iteration 4596, loss = 0.00549888\n",
      "Iteration 4597, loss = 0.00549649\n",
      "Iteration 4598, loss = 0.00549494\n",
      "Iteration 4599, loss = 0.00549280\n",
      "Iteration 4600, loss = 0.00549139\n",
      "Iteration 4601, loss = 0.00548964\n",
      "Iteration 4602, loss = 0.00548789\n",
      "Iteration 4603, loss = 0.00548614\n",
      "Iteration 4604, loss = 0.00548454\n",
      "Iteration 4605, loss = 0.00548288\n",
      "Iteration 4606, loss = 0.00548141\n",
      "Iteration 4607, loss = 0.00547985\n",
      "Iteration 4608, loss = 0.00547807\n",
      "Iteration 4609, loss = 0.00547644\n",
      "Iteration 4610, loss = 0.00547492\n",
      "Iteration 4611, loss = 0.00547336\n",
      "Iteration 4612, loss = 0.00547185\n",
      "Iteration 4613, loss = 0.00547013\n",
      "Iteration 4614, loss = 0.00546880\n",
      "Iteration 4615, loss = 0.00546716\n",
      "Iteration 4616, loss = 0.00546559\n",
      "Iteration 4617, loss = 0.00546379\n",
      "Iteration 4618, loss = 0.00546207\n",
      "Iteration 4619, loss = 0.00546074\n",
      "Iteration 4620, loss = 0.00545886\n",
      "Iteration 4621, loss = 0.00545712\n",
      "Iteration 4622, loss = 0.00545500\n",
      "Iteration 4623, loss = 0.00545368\n",
      "Iteration 4624, loss = 0.00545203\n",
      "Iteration 4625, loss = 0.00545026\n",
      "Iteration 4626, loss = 0.00544932\n",
      "Iteration 4627, loss = 0.00544722\n",
      "Iteration 4628, loss = 0.00544569\n",
      "Iteration 4629, loss = 0.00544392\n",
      "Iteration 4630, loss = 0.00544221\n",
      "Iteration 4631, loss = 0.00544048\n",
      "Iteration 4632, loss = 0.00543900\n",
      "Iteration 4633, loss = 0.00543713\n",
      "Iteration 4634, loss = 0.00543583\n",
      "Iteration 4635, loss = 0.00543411\n",
      "Iteration 4636, loss = 0.00543261\n",
      "Iteration 4637, loss = 0.00543073\n",
      "Iteration 4638, loss = 0.00542885\n",
      "Iteration 4639, loss = 0.00542728\n",
      "Iteration 4640, loss = 0.00542560\n",
      "Iteration 4641, loss = 0.00542410\n",
      "Iteration 4642, loss = 0.00542245\n",
      "Iteration 4643, loss = 0.00542081\n",
      "Iteration 4644, loss = 0.00541922\n",
      "Iteration 4645, loss = 0.00541776\n",
      "Iteration 4646, loss = 0.00541616\n",
      "Iteration 4647, loss = 0.00541448\n",
      "Iteration 4648, loss = 0.00541325\n",
      "Iteration 4649, loss = 0.00541173\n",
      "Iteration 4650, loss = 0.00541019\n",
      "Iteration 4651, loss = 0.00540888\n",
      "Iteration 4652, loss = 0.00540735\n",
      "Iteration 4653, loss = 0.00540619\n",
      "Iteration 4654, loss = 0.00540455\n",
      "Iteration 4655, loss = 0.00540308\n",
      "Iteration 4656, loss = 0.00540179\n",
      "Iteration 4657, loss = 0.00539998\n",
      "Iteration 4658, loss = 0.00539834\n",
      "Iteration 4659, loss = 0.00539691\n",
      "Iteration 4660, loss = 0.00539533\n",
      "Iteration 4661, loss = 0.00539364\n",
      "Iteration 4662, loss = 0.00539191\n",
      "Iteration 4663, loss = 0.00539048\n",
      "Iteration 4664, loss = 0.00538883\n",
      "Iteration 4665, loss = 0.00538726\n",
      "Iteration 4666, loss = 0.00538586\n",
      "Iteration 4667, loss = 0.00538434\n",
      "Iteration 4668, loss = 0.00538315\n",
      "Iteration 4669, loss = 0.00538175\n",
      "Iteration 4670, loss = 0.00538019\n",
      "Iteration 4671, loss = 0.00537838\n",
      "Iteration 4672, loss = 0.00537661\n",
      "Iteration 4673, loss = 0.00537506\n",
      "Iteration 4674, loss = 0.00537340\n",
      "Iteration 4675, loss = 0.00537177\n",
      "Iteration 4676, loss = 0.00537058\n",
      "Iteration 4677, loss = 0.00536888\n",
      "Iteration 4678, loss = 0.00536761\n",
      "Iteration 4679, loss = 0.00536607\n",
      "Iteration 4680, loss = 0.00536460\n",
      "Iteration 4681, loss = 0.00536341\n",
      "Iteration 4682, loss = 0.00536182\n",
      "Iteration 4683, loss = 0.00536065\n",
      "Iteration 4684, loss = 0.00535928\n",
      "Iteration 4685, loss = 0.00535765\n",
      "Iteration 4686, loss = 0.00535625\n",
      "Iteration 4687, loss = 0.00535498\n",
      "Iteration 4688, loss = 0.00535343\n",
      "Iteration 4689, loss = 0.00535211\n",
      "Iteration 4690, loss = 0.00535069\n",
      "Iteration 4691, loss = 0.00534953\n",
      "Iteration 4692, loss = 0.00534832\n",
      "Iteration 4693, loss = 0.00534687\n",
      "Iteration 4694, loss = 0.00534509\n",
      "Iteration 4695, loss = 0.00534358\n",
      "Iteration 4696, loss = 0.00534170\n",
      "Iteration 4697, loss = 0.00533981\n",
      "Iteration 4698, loss = 0.00533843\n",
      "Iteration 4699, loss = 0.00533657\n",
      "Iteration 4700, loss = 0.00533470\n",
      "Iteration 4701, loss = 0.00533326\n",
      "Iteration 4702, loss = 0.00533105\n",
      "Iteration 4703, loss = 0.00532943\n",
      "Iteration 4704, loss = 0.00532762\n",
      "Iteration 4705, loss = 0.00532592\n",
      "Iteration 4706, loss = 0.00532456\n",
      "Iteration 4707, loss = 0.00532255\n",
      "Iteration 4708, loss = 0.00532076\n",
      "Iteration 4709, loss = 0.00531966\n",
      "Iteration 4710, loss = 0.00531775\n",
      "Iteration 4711, loss = 0.00531659\n",
      "Iteration 4712, loss = 0.00531455\n",
      "Iteration 4713, loss = 0.00531310\n",
      "Iteration 4714, loss = 0.00531154\n",
      "Iteration 4715, loss = 0.00531026\n",
      "Iteration 4716, loss = 0.00530869\n",
      "Iteration 4717, loss = 0.00530728\n",
      "Iteration 4718, loss = 0.00530565\n",
      "Iteration 4719, loss = 0.00530420\n",
      "Iteration 4720, loss = 0.00530282\n",
      "Iteration 4721, loss = 0.00530165\n",
      "Iteration 4722, loss = 0.00529991\n",
      "Iteration 4723, loss = 0.00529865\n",
      "Iteration 4724, loss = 0.00529739\n",
      "Iteration 4725, loss = 0.00529597\n",
      "Iteration 4726, loss = 0.00529444\n",
      "Iteration 4727, loss = 0.00529266\n",
      "Iteration 4728, loss = 0.00529125\n",
      "Iteration 4729, loss = 0.00529001\n",
      "Iteration 4730, loss = 0.00528858\n",
      "Iteration 4731, loss = 0.00528727\n",
      "Iteration 4732, loss = 0.00528613\n",
      "Iteration 4733, loss = 0.00528425\n",
      "Iteration 4734, loss = 0.00528267\n",
      "Iteration 4735, loss = 0.00528106\n",
      "Iteration 4736, loss = 0.00527968\n",
      "Iteration 4737, loss = 0.00527797\n",
      "Iteration 4738, loss = 0.00527658\n",
      "Iteration 4739, loss = 0.00527491\n",
      "Iteration 4740, loss = 0.00527307\n",
      "Iteration 4741, loss = 0.00527089\n",
      "Iteration 4742, loss = 0.00526937\n",
      "Iteration 4743, loss = 0.00526824\n",
      "Iteration 4744, loss = 0.00526634\n",
      "Iteration 4745, loss = 0.00526413\n",
      "Iteration 4746, loss = 0.00526257\n",
      "Iteration 4747, loss = 0.00526128\n",
      "Iteration 4748, loss = 0.00526032\n",
      "Iteration 4749, loss = 0.00525809\n",
      "Iteration 4750, loss = 0.00525674\n",
      "Iteration 4751, loss = 0.00525531\n",
      "Iteration 4752, loss = 0.00525389\n",
      "Iteration 4753, loss = 0.00525228\n",
      "Iteration 4754, loss = 0.00525093\n",
      "Iteration 4755, loss = 0.00524940\n",
      "Iteration 4756, loss = 0.00524801\n",
      "Iteration 4757, loss = 0.00524640\n",
      "Iteration 4758, loss = 0.00524480\n",
      "Iteration 4759, loss = 0.00524320\n",
      "Iteration 4760, loss = 0.00524160\n",
      "Iteration 4761, loss = 0.00523988\n",
      "Iteration 4762, loss = 0.00523833\n",
      "Iteration 4763, loss = 0.00523689\n",
      "Iteration 4764, loss = 0.00523527\n",
      "Iteration 4765, loss = 0.00523339\n",
      "Iteration 4766, loss = 0.00523230\n",
      "Iteration 4767, loss = 0.00523061\n",
      "Iteration 4768, loss = 0.00522912\n",
      "Iteration 4769, loss = 0.00522735\n",
      "Iteration 4770, loss = 0.00522584\n",
      "Iteration 4771, loss = 0.00522439\n",
      "Iteration 4772, loss = 0.00522278\n",
      "Iteration 4773, loss = 0.00522138\n",
      "Iteration 4774, loss = 0.00521964\n",
      "Iteration 4775, loss = 0.00521833\n",
      "Iteration 4776, loss = 0.00521685\n",
      "Iteration 4777, loss = 0.00521527\n",
      "Iteration 4778, loss = 0.00521371\n",
      "Iteration 4779, loss = 0.00521267\n",
      "Iteration 4780, loss = 0.00521090\n",
      "Iteration 4781, loss = 0.00520956\n",
      "Iteration 4782, loss = 0.00520814\n",
      "Iteration 4783, loss = 0.00520650\n",
      "Iteration 4784, loss = 0.00520500\n",
      "Iteration 4785, loss = 0.00520349\n",
      "Iteration 4786, loss = 0.00520187\n",
      "Iteration 4787, loss = 0.00520046\n",
      "Iteration 4788, loss = 0.00519847\n",
      "Iteration 4789, loss = 0.00519666\n",
      "Iteration 4790, loss = 0.00519611\n",
      "Iteration 4791, loss = 0.00519406\n",
      "Iteration 4792, loss = 0.00519232\n",
      "Iteration 4793, loss = 0.00519045\n",
      "Iteration 4794, loss = 0.00518898\n",
      "Iteration 4795, loss = 0.00518725\n",
      "Iteration 4796, loss = 0.00518584\n",
      "Iteration 4797, loss = 0.00518398\n",
      "Iteration 4798, loss = 0.00518261\n",
      "Iteration 4799, loss = 0.00518154\n",
      "Iteration 4800, loss = 0.00517929\n",
      "Iteration 4801, loss = 0.00517775\n",
      "Iteration 4802, loss = 0.00517618\n",
      "Iteration 4803, loss = 0.00517441\n",
      "Iteration 4804, loss = 0.00517289\n",
      "Iteration 4805, loss = 0.00517148\n",
      "Iteration 4806, loss = 0.00516972\n",
      "Iteration 4807, loss = 0.00516857\n",
      "Iteration 4808, loss = 0.00516714\n",
      "Iteration 4809, loss = 0.00516534\n",
      "Iteration 4810, loss = 0.00516400\n",
      "Iteration 4811, loss = 0.00516284\n",
      "Iteration 4812, loss = 0.00516140\n",
      "Iteration 4813, loss = 0.00515975\n",
      "Iteration 4814, loss = 0.00515854\n",
      "Iteration 4815, loss = 0.00515655\n",
      "Iteration 4816, loss = 0.00515515\n",
      "Iteration 4817, loss = 0.00515365\n",
      "Iteration 4818, loss = 0.00515207\n",
      "Iteration 4819, loss = 0.00515078\n",
      "Iteration 4820, loss = 0.00514936\n",
      "Iteration 4821, loss = 0.00514805\n",
      "Iteration 4822, loss = 0.00514664\n",
      "Iteration 4823, loss = 0.00514554\n",
      "Iteration 4824, loss = 0.00514394\n",
      "Iteration 4825, loss = 0.00514272\n",
      "Iteration 4826, loss = 0.00514129\n",
      "Iteration 4827, loss = 0.00513981\n",
      "Iteration 4828, loss = 0.00513880\n",
      "Iteration 4829, loss = 0.00513715\n",
      "Iteration 4830, loss = 0.00513590\n",
      "Iteration 4831, loss = 0.00513437\n",
      "Iteration 4832, loss = 0.00513309\n",
      "Iteration 4833, loss = 0.00513153\n",
      "Iteration 4834, loss = 0.00513011\n",
      "Iteration 4835, loss = 0.00512869\n",
      "Iteration 4836, loss = 0.00512825\n",
      "Iteration 4837, loss = 0.00512587\n",
      "Iteration 4838, loss = 0.00512448\n",
      "Iteration 4839, loss = 0.00512288\n",
      "Iteration 4840, loss = 0.00512142\n",
      "Iteration 4841, loss = 0.00512038\n",
      "Iteration 4842, loss = 0.00511893\n",
      "Iteration 4843, loss = 0.00511766\n",
      "Iteration 4844, loss = 0.00511590\n",
      "Iteration 4845, loss = 0.00511447\n",
      "Iteration 4846, loss = 0.00511287\n",
      "Iteration 4847, loss = 0.00511130\n",
      "Iteration 4848, loss = 0.00510980\n",
      "Iteration 4849, loss = 0.00510844\n",
      "Iteration 4850, loss = 0.00510710\n",
      "Iteration 4851, loss = 0.00510560\n",
      "Iteration 4852, loss = 0.00510406\n",
      "Iteration 4853, loss = 0.00510273\n",
      "Iteration 4854, loss = 0.00510144\n",
      "Iteration 4855, loss = 0.00510002\n",
      "Iteration 4856, loss = 0.00509853\n",
      "Iteration 4857, loss = 0.00509721\n",
      "Iteration 4858, loss = 0.00509566\n",
      "Iteration 4859, loss = 0.00509447\n",
      "Iteration 4860, loss = 0.00509274\n",
      "Iteration 4861, loss = 0.00509111\n",
      "Iteration 4862, loss = 0.00508977\n",
      "Iteration 4863, loss = 0.00508835\n",
      "Iteration 4864, loss = 0.00508717\n",
      "Iteration 4865, loss = 0.00508521\n",
      "Iteration 4866, loss = 0.00508359\n",
      "Iteration 4867, loss = 0.00508214\n",
      "Iteration 4868, loss = 0.00508073\n",
      "Iteration 4869, loss = 0.00507921\n",
      "Iteration 4870, loss = 0.00507757\n",
      "Iteration 4871, loss = 0.00507614\n",
      "Iteration 4872, loss = 0.00507461\n",
      "Iteration 4873, loss = 0.00507305\n",
      "Iteration 4874, loss = 0.00507194\n",
      "Iteration 4875, loss = 0.00507039\n",
      "Iteration 4876, loss = 0.00506873\n",
      "Iteration 4877, loss = 0.00506730\n",
      "Iteration 4878, loss = 0.00506609\n",
      "Iteration 4879, loss = 0.00506450\n",
      "Iteration 4880, loss = 0.00506319\n",
      "Iteration 4881, loss = 0.00506167\n",
      "Iteration 4882, loss = 0.00506061\n",
      "Iteration 4883, loss = 0.00505914\n",
      "Iteration 4884, loss = 0.00505763\n",
      "Iteration 4885, loss = 0.00505625\n",
      "Iteration 4886, loss = 0.00505506\n",
      "Iteration 4887, loss = 0.00505378\n",
      "Iteration 4888, loss = 0.00505244\n",
      "Iteration 4889, loss = 0.00505123\n",
      "Iteration 4890, loss = 0.00504996\n",
      "Iteration 4891, loss = 0.00504856\n",
      "Iteration 4892, loss = 0.00504715\n",
      "Iteration 4893, loss = 0.00504611\n",
      "Iteration 4894, loss = 0.00504509\n",
      "Iteration 4895, loss = 0.00504329\n",
      "Iteration 4896, loss = 0.00504208\n",
      "Iteration 4897, loss = 0.00504057\n",
      "Iteration 4898, loss = 0.00503895\n",
      "Iteration 4899, loss = 0.00503779\n",
      "Iteration 4900, loss = 0.00503635\n",
      "Iteration 4901, loss = 0.00503471\n",
      "Iteration 4902, loss = 0.00503332\n",
      "Iteration 4903, loss = 0.00503161\n",
      "Iteration 4904, loss = 0.00503016\n",
      "Iteration 4905, loss = 0.00502883\n",
      "Iteration 4906, loss = 0.00502724\n",
      "Iteration 4907, loss = 0.00502564\n",
      "Iteration 4908, loss = 0.00502414\n",
      "Iteration 4909, loss = 0.00502280\n",
      "Iteration 4910, loss = 0.00502127\n",
      "Iteration 4911, loss = 0.00501979\n",
      "Iteration 4912, loss = 0.00501850\n",
      "Iteration 4913, loss = 0.00501701\n",
      "Iteration 4914, loss = 0.00501583\n",
      "Iteration 4915, loss = 0.00501450\n",
      "Iteration 4916, loss = 0.00501301\n",
      "Iteration 4917, loss = 0.00501171\n",
      "Iteration 4918, loss = 0.00501055\n",
      "Iteration 4919, loss = 0.00500899\n",
      "Iteration 4920, loss = 0.00500786\n",
      "Iteration 4921, loss = 0.00500630\n",
      "Iteration 4922, loss = 0.00500493\n",
      "Iteration 4923, loss = 0.00500362\n",
      "Iteration 4924, loss = 0.00500225\n",
      "Iteration 4925, loss = 0.00500078\n",
      "Iteration 4926, loss = 0.00500016\n",
      "Iteration 4927, loss = 0.00499808\n",
      "Iteration 4928, loss = 0.00499640\n",
      "Iteration 4929, loss = 0.00499529\n",
      "Iteration 4930, loss = 0.00499356\n",
      "Iteration 4931, loss = 0.00499197\n",
      "Iteration 4932, loss = 0.00499044\n",
      "Iteration 4933, loss = 0.00498900\n",
      "Iteration 4934, loss = 0.00498756\n",
      "Iteration 4935, loss = 0.00498638\n",
      "Iteration 4936, loss = 0.00498478\n",
      "Iteration 4937, loss = 0.00498356\n",
      "Iteration 4938, loss = 0.00498202\n",
      "Iteration 4939, loss = 0.00498082\n",
      "Iteration 4940, loss = 0.00497980\n",
      "Iteration 4941, loss = 0.00497797\n",
      "Iteration 4942, loss = 0.00497664\n",
      "Iteration 4943, loss = 0.00497512\n",
      "Iteration 4944, loss = 0.00497381\n",
      "Iteration 4945, loss = 0.00497238\n",
      "Iteration 4946, loss = 0.00497091\n",
      "Iteration 4947, loss = 0.00496948\n",
      "Iteration 4948, loss = 0.00496846\n",
      "Iteration 4949, loss = 0.00496673\n",
      "Iteration 4950, loss = 0.00496537\n",
      "Iteration 4951, loss = 0.00496393\n",
      "Iteration 4952, loss = 0.00496276\n",
      "Iteration 4953, loss = 0.00496127\n",
      "Iteration 4954, loss = 0.00495983\n",
      "Iteration 4955, loss = 0.00495853\n",
      "Iteration 4956, loss = 0.00495732\n",
      "Iteration 4957, loss = 0.00495614\n",
      "Iteration 4958, loss = 0.00495490\n",
      "Iteration 4959, loss = 0.00495392\n",
      "Iteration 4960, loss = 0.00495247\n",
      "Iteration 4961, loss = 0.00495124\n",
      "Iteration 4962, loss = 0.00495002\n",
      "Iteration 4963, loss = 0.00494883\n",
      "Iteration 4964, loss = 0.00494757\n",
      "Iteration 4965, loss = 0.00494625\n",
      "Iteration 4966, loss = 0.00494481\n",
      "Iteration 4967, loss = 0.00494370\n",
      "Iteration 4968, loss = 0.00494242\n",
      "Iteration 4969, loss = 0.00494144\n",
      "Iteration 4970, loss = 0.00493946\n",
      "Iteration 4971, loss = 0.00493832\n",
      "Iteration 4972, loss = 0.00493653\n",
      "Iteration 4973, loss = 0.00493523\n",
      "Iteration 4974, loss = 0.00493343\n",
      "Iteration 4975, loss = 0.00493219\n",
      "Iteration 4976, loss = 0.00493072\n",
      "Iteration 4977, loss = 0.00492931\n",
      "Iteration 4978, loss = 0.00492779\n",
      "Iteration 4979, loss = 0.00492644\n",
      "Iteration 4980, loss = 0.00492517\n",
      "Iteration 4981, loss = 0.00492369\n",
      "Iteration 4982, loss = 0.00492246\n",
      "Iteration 4983, loss = 0.00492068\n",
      "Iteration 4984, loss = 0.00491993\n",
      "Iteration 4985, loss = 0.00491813\n",
      "Iteration 4986, loss = 0.00491688\n",
      "Iteration 4987, loss = 0.00491518\n",
      "Iteration 4988, loss = 0.00491379\n",
      "Iteration 4989, loss = 0.00491249\n",
      "Iteration 4990, loss = 0.00491083\n",
      "Iteration 4991, loss = 0.00490947\n",
      "Iteration 4992, loss = 0.00490872\n",
      "Iteration 4993, loss = 0.00490671\n",
      "Iteration 4994, loss = 0.00490551\n",
      "Iteration 4995, loss = 0.00490370\n",
      "Iteration 4996, loss = 0.00490241\n",
      "Iteration 4997, loss = 0.00490108\n",
      "Iteration 4998, loss = 0.00489954\n",
      "Iteration 4999, loss = 0.00489756\n",
      "Iteration 5000, loss = 0.00489659\n",
      "Iteration 5001, loss = 0.00489481\n",
      "Iteration 5002, loss = 0.00489330\n",
      "Iteration 5003, loss = 0.00489173\n",
      "Iteration 5004, loss = 0.00489039\n",
      "Iteration 5005, loss = 0.00488909\n",
      "Iteration 5006, loss = 0.00488761\n",
      "Iteration 5007, loss = 0.00488631\n",
      "Iteration 5008, loss = 0.00488510\n",
      "Iteration 5009, loss = 0.00488372\n",
      "Iteration 5010, loss = 0.00488313\n",
      "Iteration 5011, loss = 0.00488092\n",
      "Iteration 5012, loss = 0.00487962\n",
      "Iteration 5013, loss = 0.00487830\n",
      "Iteration 5014, loss = 0.00487692\n",
      "Iteration 5015, loss = 0.00487511\n",
      "Iteration 5016, loss = 0.00487379\n",
      "Iteration 5017, loss = 0.00487254\n",
      "Iteration 5018, loss = 0.00487100\n",
      "Iteration 5019, loss = 0.00487012\n",
      "Iteration 5020, loss = 0.00486827\n",
      "Iteration 5021, loss = 0.00486684\n",
      "Iteration 5022, loss = 0.00486536\n",
      "Iteration 5023, loss = 0.00486441\n",
      "Iteration 5024, loss = 0.00486263\n",
      "Iteration 5025, loss = 0.00486139\n",
      "Iteration 5026, loss = 0.00486007\n",
      "Iteration 5027, loss = 0.00485911\n",
      "Iteration 5028, loss = 0.00485731\n",
      "Iteration 5029, loss = 0.00485624\n",
      "Iteration 5030, loss = 0.00485448\n",
      "Iteration 5031, loss = 0.00485304\n",
      "Iteration 5032, loss = 0.00485151\n",
      "Iteration 5033, loss = 0.00485033\n",
      "Iteration 5034, loss = 0.00484882\n",
      "Iteration 5035, loss = 0.00484751\n",
      "Iteration 5036, loss = 0.00484606\n",
      "Iteration 5037, loss = 0.00484495\n",
      "Iteration 5038, loss = 0.00484370\n",
      "Iteration 5039, loss = 0.00484274\n",
      "Iteration 5040, loss = 0.00484106\n",
      "Iteration 5041, loss = 0.00483981\n",
      "Iteration 5042, loss = 0.00483822\n",
      "Iteration 5043, loss = 0.00483701\n",
      "Iteration 5044, loss = 0.00483566\n",
      "Iteration 5045, loss = 0.00483458\n",
      "Iteration 5046, loss = 0.00483298\n",
      "Iteration 5047, loss = 0.00483159\n",
      "Iteration 5048, loss = 0.00483026\n",
      "Iteration 5049, loss = 0.00482896\n",
      "Iteration 5050, loss = 0.00482816\n",
      "Iteration 5051, loss = 0.00482680\n",
      "Iteration 5052, loss = 0.00482522\n",
      "Iteration 5053, loss = 0.00482440\n",
      "Iteration 5054, loss = 0.00482270\n",
      "Iteration 5055, loss = 0.00482133\n",
      "Iteration 5056, loss = 0.00482037\n",
      "Iteration 5057, loss = 0.00481927\n",
      "Iteration 5058, loss = 0.00481777\n",
      "Iteration 5059, loss = 0.00481639\n",
      "Iteration 5060, loss = 0.00481504\n",
      "Iteration 5061, loss = 0.00481371\n",
      "Iteration 5062, loss = 0.00481245\n",
      "Iteration 5063, loss = 0.00481119\n",
      "Iteration 5064, loss = 0.00481100\n",
      "Iteration 5065, loss = 0.00480886\n",
      "Iteration 5066, loss = 0.00480730\n",
      "Iteration 5067, loss = 0.00480588\n",
      "Iteration 5068, loss = 0.00480436\n",
      "Iteration 5069, loss = 0.00480308\n",
      "Iteration 5070, loss = 0.00480213\n",
      "Iteration 5071, loss = 0.00480055\n",
      "Iteration 5072, loss = 0.00479953\n",
      "Iteration 5073, loss = 0.00479822\n",
      "Iteration 5074, loss = 0.00479674\n",
      "Iteration 5075, loss = 0.00479560\n",
      "Iteration 5076, loss = 0.00479437\n",
      "Iteration 5077, loss = 0.00479355\n",
      "Iteration 5078, loss = 0.00479204\n",
      "Iteration 5079, loss = 0.00479067\n",
      "Iteration 5080, loss = 0.00478941\n",
      "Iteration 5081, loss = 0.00478825\n",
      "Iteration 5082, loss = 0.00478714\n",
      "Iteration 5083, loss = 0.00478559\n",
      "Iteration 5084, loss = 0.00478416\n",
      "Iteration 5085, loss = 0.00478276\n",
      "Iteration 5086, loss = 0.00478159\n",
      "Iteration 5087, loss = 0.00477989\n",
      "Iteration 5088, loss = 0.00477880\n",
      "Iteration 5089, loss = 0.00477739\n",
      "Iteration 5090, loss = 0.00477600\n",
      "Iteration 5091, loss = 0.00477485\n",
      "Iteration 5092, loss = 0.00477346\n",
      "Iteration 5093, loss = 0.00477236\n",
      "Iteration 5094, loss = 0.00477103\n",
      "Iteration 5095, loss = 0.00477012\n",
      "Iteration 5096, loss = 0.00476879\n",
      "Iteration 5097, loss = 0.00476757\n",
      "Iteration 5098, loss = 0.00476649\n",
      "Iteration 5099, loss = 0.00476499\n",
      "Iteration 5100, loss = 0.00476428\n",
      "Iteration 5101, loss = 0.00476283\n",
      "Iteration 5102, loss = 0.00476153\n",
      "Iteration 5103, loss = 0.00476032\n",
      "Iteration 5104, loss = 0.00475898\n",
      "Iteration 5105, loss = 0.00475772\n",
      "Iteration 5106, loss = 0.00475645\n",
      "Iteration 5107, loss = 0.00475532\n",
      "Iteration 5108, loss = 0.00475408\n",
      "Iteration 5109, loss = 0.00475415\n",
      "Iteration 5110, loss = 0.00475203\n",
      "Iteration 5111, loss = 0.00475021\n",
      "Iteration 5112, loss = 0.00474901\n",
      "Iteration 5113, loss = 0.00474757\n",
      "Iteration 5114, loss = 0.00474621\n",
      "Iteration 5115, loss = 0.00474456\n",
      "Iteration 5116, loss = 0.00474326\n",
      "Iteration 5117, loss = 0.00474209\n",
      "Iteration 5118, loss = 0.00474140\n",
      "Iteration 5119, loss = 0.00473947\n",
      "Iteration 5120, loss = 0.00473809\n",
      "Iteration 5121, loss = 0.00473677\n",
      "Iteration 5122, loss = 0.00473554\n",
      "Iteration 5123, loss = 0.00473445\n",
      "Iteration 5124, loss = 0.00473266\n",
      "Iteration 5125, loss = 0.00473138\n",
      "Iteration 5126, loss = 0.00472998\n",
      "Iteration 5127, loss = 0.00472873\n",
      "Iteration 5128, loss = 0.00472743\n",
      "Iteration 5129, loss = 0.00472609\n",
      "Iteration 5130, loss = 0.00472480\n",
      "Iteration 5131, loss = 0.00472349\n",
      "Iteration 5132, loss = 0.00472221\n",
      "Iteration 5133, loss = 0.00472156\n",
      "Iteration 5134, loss = 0.00471968\n",
      "Iteration 5135, loss = 0.00471847\n",
      "Iteration 5136, loss = 0.00471694\n",
      "Iteration 5137, loss = 0.00471571\n",
      "Iteration 5138, loss = 0.00471442\n",
      "Iteration 5139, loss = 0.00471299\n",
      "Iteration 5140, loss = 0.00471182\n",
      "Iteration 5141, loss = 0.00471051\n",
      "Iteration 5142, loss = 0.00470903\n",
      "Iteration 5143, loss = 0.00470828\n",
      "Iteration 5144, loss = 0.00470629\n",
      "Iteration 5145, loss = 0.00470505\n",
      "Iteration 5146, loss = 0.00470386\n",
      "Iteration 5147, loss = 0.00470286\n",
      "Iteration 5148, loss = 0.00470135\n",
      "Iteration 5149, loss = 0.00470027\n",
      "Iteration 5150, loss = 0.00469899\n",
      "Iteration 5151, loss = 0.00469759\n",
      "Iteration 5152, loss = 0.00469644\n",
      "Iteration 5153, loss = 0.00469510\n",
      "Iteration 5154, loss = 0.00469374\n",
      "Iteration 5155, loss = 0.00469273\n",
      "Iteration 5156, loss = 0.00469125\n",
      "Iteration 5157, loss = 0.00468999\n",
      "Iteration 5158, loss = 0.00468896\n",
      "Iteration 5159, loss = 0.00468761\n",
      "Iteration 5160, loss = 0.00468627\n",
      "Iteration 5161, loss = 0.00468520\n",
      "Iteration 5162, loss = 0.00468389\n",
      "Iteration 5163, loss = 0.00468254\n",
      "Iteration 5164, loss = 0.00468127\n",
      "Iteration 5165, loss = 0.00468009\n",
      "Iteration 5166, loss = 0.00467887\n",
      "Iteration 5167, loss = 0.00467763\n",
      "Iteration 5168, loss = 0.00467646\n",
      "Iteration 5169, loss = 0.00467537\n",
      "Iteration 5170, loss = 0.00467405\n",
      "Iteration 5171, loss = 0.00467264\n",
      "Iteration 5172, loss = 0.00467157\n",
      "Iteration 5173, loss = 0.00467057\n",
      "Iteration 5174, loss = 0.00466922\n",
      "Iteration 5175, loss = 0.00466810\n",
      "Iteration 5176, loss = 0.00466731\n",
      "Iteration 5177, loss = 0.00466596\n",
      "Iteration 5178, loss = 0.00466469\n",
      "Iteration 5179, loss = 0.00466359\n",
      "Iteration 5180, loss = 0.00466252\n",
      "Iteration 5181, loss = 0.00466126\n",
      "Iteration 5182, loss = 0.00466024\n",
      "Iteration 5183, loss = 0.00465896\n",
      "Iteration 5184, loss = 0.00465770\n",
      "Iteration 5185, loss = 0.00465651\n",
      "Iteration 5186, loss = 0.00465505\n",
      "Iteration 5187, loss = 0.00465365\n",
      "Iteration 5188, loss = 0.00465234\n",
      "Iteration 5189, loss = 0.00465130\n",
      "Iteration 5190, loss = 0.00464995\n",
      "Iteration 5191, loss = 0.00464874\n",
      "Iteration 5192, loss = 0.00464732\n",
      "Iteration 5193, loss = 0.00464623\n",
      "Iteration 5194, loss = 0.00464473\n",
      "Iteration 5195, loss = 0.00464345\n",
      "Iteration 5196, loss = 0.00464237\n",
      "Iteration 5197, loss = 0.00464111\n",
      "Iteration 5198, loss = 0.00463962\n",
      "Iteration 5199, loss = 0.00463852\n",
      "Iteration 5200, loss = 0.00463726\n",
      "Iteration 5201, loss = 0.00463575\n",
      "Iteration 5202, loss = 0.00463483\n",
      "Iteration 5203, loss = 0.00463318\n",
      "Iteration 5204, loss = 0.00463190\n",
      "Iteration 5205, loss = 0.00463092\n",
      "Iteration 5206, loss = 0.00462928\n",
      "Iteration 5207, loss = 0.00462800\n",
      "Iteration 5208, loss = 0.00462648\n",
      "Iteration 5209, loss = 0.00462532\n",
      "Iteration 5210, loss = 0.00462394\n",
      "Iteration 5211, loss = 0.00462255\n",
      "Iteration 5212, loss = 0.00462123\n",
      "Iteration 5213, loss = 0.00461991\n",
      "Iteration 5214, loss = 0.00461862\n",
      "Iteration 5215, loss = 0.00461744\n",
      "Iteration 5216, loss = 0.00461621\n",
      "Iteration 5217, loss = 0.00461503\n",
      "Iteration 5218, loss = 0.00461395\n",
      "Iteration 5219, loss = 0.00461288\n",
      "Iteration 5220, loss = 0.00461158\n",
      "Iteration 5221, loss = 0.00461039\n",
      "Iteration 5222, loss = 0.00461030\n",
      "Iteration 5223, loss = 0.00460765\n",
      "Iteration 5224, loss = 0.00460654\n",
      "Iteration 5225, loss = 0.00460564\n",
      "Iteration 5226, loss = 0.00460403\n",
      "Iteration 5227, loss = 0.00460326\n",
      "Iteration 5228, loss = 0.00460212\n",
      "Iteration 5229, loss = 0.00460053\n",
      "Iteration 5230, loss = 0.00459964\n",
      "Iteration 5231, loss = 0.00459816\n",
      "Iteration 5232, loss = 0.00459693\n",
      "Iteration 5233, loss = 0.00459567\n",
      "Iteration 5234, loss = 0.00459468\n",
      "Iteration 5235, loss = 0.00459354\n",
      "Iteration 5236, loss = 0.00459130\n",
      "Iteration 5237, loss = 0.00459027\n",
      "Iteration 5238, loss = 0.00458919\n",
      "Iteration 5239, loss = 0.00458740\n",
      "Iteration 5240, loss = 0.00458623\n",
      "Iteration 5241, loss = 0.00458480\n",
      "Iteration 5242, loss = 0.00458355\n",
      "Iteration 5243, loss = 0.00458222\n",
      "Iteration 5244, loss = 0.00458105\n",
      "Iteration 5245, loss = 0.00458018\n",
      "Iteration 5246, loss = 0.00457853\n",
      "Iteration 5247, loss = 0.00457717\n",
      "Iteration 5248, loss = 0.00457633\n",
      "Iteration 5249, loss = 0.00457472\n",
      "Iteration 5250, loss = 0.00457348\n",
      "Iteration 5251, loss = 0.00457302\n",
      "Iteration 5252, loss = 0.00457103\n",
      "Iteration 5253, loss = 0.00456995\n",
      "Iteration 5254, loss = 0.00456876\n",
      "Iteration 5255, loss = 0.00456746\n",
      "Iteration 5256, loss = 0.00456638\n",
      "Iteration 5257, loss = 0.00456501\n",
      "Iteration 5258, loss = 0.00456392\n",
      "Iteration 5259, loss = 0.00456258\n",
      "Iteration 5260, loss = 0.00456134\n",
      "Iteration 5261, loss = 0.00455984\n",
      "Iteration 5262, loss = 0.00455857\n",
      "Iteration 5263, loss = 0.00455767\n",
      "Iteration 5264, loss = 0.00455631\n",
      "Iteration 5265, loss = 0.00455525\n",
      "Iteration 5266, loss = 0.00455387\n",
      "Iteration 5267, loss = 0.00455290\n",
      "Iteration 5268, loss = 0.00455153\n",
      "Iteration 5269, loss = 0.00455057\n",
      "Iteration 5270, loss = 0.00454991\n",
      "Iteration 5271, loss = 0.00454841\n",
      "Iteration 5272, loss = 0.00454716\n",
      "Iteration 5273, loss = 0.00454599\n",
      "Iteration 5274, loss = 0.00454484\n",
      "Iteration 5275, loss = 0.00454371\n",
      "Iteration 5276, loss = 0.00454338\n",
      "Iteration 5277, loss = 0.00454178\n",
      "Iteration 5278, loss = 0.00454083\n",
      "Iteration 5279, loss = 0.00453950\n",
      "Iteration 5280, loss = 0.00453827\n",
      "Iteration 5281, loss = 0.00453701\n",
      "Iteration 5282, loss = 0.00453565\n",
      "Iteration 5283, loss = 0.00453459\n",
      "Iteration 5284, loss = 0.00453336\n",
      "Iteration 5285, loss = 0.00453213\n",
      "Iteration 5286, loss = 0.00453108\n",
      "Iteration 5287, loss = 0.00453018\n",
      "Iteration 5288, loss = 0.00452900\n",
      "Iteration 5289, loss = 0.00452766\n",
      "Iteration 5290, loss = 0.00452623\n",
      "Iteration 5291, loss = 0.00452516\n",
      "Iteration 5292, loss = 0.00452387\n",
      "Iteration 5293, loss = 0.00452251\n",
      "Iteration 5294, loss = 0.00452142\n",
      "Iteration 5295, loss = 0.00452001\n",
      "Iteration 5296, loss = 0.00451911\n",
      "Iteration 5297, loss = 0.00451734\n",
      "Iteration 5298, loss = 0.00451642\n",
      "Iteration 5299, loss = 0.00451526\n",
      "Iteration 5300, loss = 0.00451412\n",
      "Iteration 5301, loss = 0.00451282\n",
      "Iteration 5302, loss = 0.00451130\n",
      "Iteration 5303, loss = 0.00451018\n",
      "Iteration 5304, loss = 0.00450890\n",
      "Iteration 5305, loss = 0.00450803\n",
      "Iteration 5306, loss = 0.00450646\n",
      "Iteration 5307, loss = 0.00450513\n",
      "Iteration 5308, loss = 0.00450390\n",
      "Iteration 5309, loss = 0.00450264\n",
      "Iteration 5310, loss = 0.00450148\n",
      "Iteration 5311, loss = 0.00450015\n",
      "Iteration 5312, loss = 0.00449880\n",
      "Iteration 5313, loss = 0.00449756\n",
      "Iteration 5314, loss = 0.00449637\n",
      "Iteration 5315, loss = 0.00449523\n",
      "Iteration 5316, loss = 0.00449387\n",
      "Iteration 5317, loss = 0.00449292\n",
      "Iteration 5318, loss = 0.00449250\n",
      "Iteration 5319, loss = 0.00449003\n",
      "Iteration 5320, loss = 0.00448894\n",
      "Iteration 5321, loss = 0.00448761\n",
      "Iteration 5322, loss = 0.00448644\n",
      "Iteration 5323, loss = 0.00448517\n",
      "Iteration 5324, loss = 0.00448439\n",
      "Iteration 5325, loss = 0.00448282\n",
      "Iteration 5326, loss = 0.00448207\n",
      "Iteration 5327, loss = 0.00448051\n",
      "Iteration 5328, loss = 0.00447975\n",
      "Iteration 5329, loss = 0.00447814\n",
      "Iteration 5330, loss = 0.00447706\n",
      "Iteration 5331, loss = 0.00447585\n",
      "Iteration 5332, loss = 0.00447454\n",
      "Iteration 5333, loss = 0.00447346\n",
      "Iteration 5334, loss = 0.00447224\n",
      "Iteration 5335, loss = 0.00447102\n",
      "Iteration 5336, loss = 0.00446992\n",
      "Iteration 5337, loss = 0.00446861\n",
      "Iteration 5338, loss = 0.00446746\n",
      "Iteration 5339, loss = 0.00446650\n",
      "Iteration 5340, loss = 0.00446517\n",
      "Iteration 5341, loss = 0.00446393\n",
      "Iteration 5342, loss = 0.00446288\n",
      "Iteration 5343, loss = 0.00446175\n",
      "Iteration 5344, loss = 0.00446034\n",
      "Iteration 5345, loss = 0.00445961\n",
      "Iteration 5346, loss = 0.00445805\n",
      "Iteration 5347, loss = 0.00445702\n",
      "Iteration 5348, loss = 0.00445576\n",
      "Iteration 5349, loss = 0.00445446\n",
      "Iteration 5350, loss = 0.00445382\n",
      "Iteration 5351, loss = 0.00445228\n",
      "Iteration 5352, loss = 0.00445127\n",
      "Iteration 5353, loss = 0.00444979\n",
      "Iteration 5354, loss = 0.00444878\n",
      "Iteration 5355, loss = 0.00444814\n",
      "Iteration 5356, loss = 0.00444651\n",
      "Iteration 5357, loss = 0.00444523\n",
      "Iteration 5358, loss = 0.00444396\n",
      "Iteration 5359, loss = 0.00444295\n",
      "Iteration 5360, loss = 0.00444163\n",
      "Iteration 5361, loss = 0.00444081\n",
      "Iteration 5362, loss = 0.00443956\n",
      "Iteration 5363, loss = 0.00443813\n",
      "Iteration 5364, loss = 0.00443695\n",
      "Iteration 5365, loss = 0.00443571\n",
      "Iteration 5366, loss = 0.00443468\n",
      "Iteration 5367, loss = 0.00443342\n",
      "Iteration 5368, loss = 0.00443217\n",
      "Iteration 5369, loss = 0.00443105\n",
      "Iteration 5370, loss = 0.00442987\n",
      "Iteration 5371, loss = 0.00442895\n",
      "Iteration 5372, loss = 0.00442756\n",
      "Iteration 5373, loss = 0.00442650\n",
      "Iteration 5374, loss = 0.00442585\n",
      "Iteration 5375, loss = 0.00442410\n",
      "Iteration 5376, loss = 0.00442320\n",
      "Iteration 5377, loss = 0.00442192\n",
      "Iteration 5378, loss = 0.00442080\n",
      "Iteration 5379, loss = 0.00441928\n",
      "Iteration 5380, loss = 0.00441824\n",
      "Iteration 5381, loss = 0.00441715\n",
      "Iteration 5382, loss = 0.00441558\n",
      "Iteration 5383, loss = 0.00441436\n",
      "Iteration 5384, loss = 0.00441315\n",
      "Iteration 5385, loss = 0.00441200\n",
      "Iteration 5386, loss = 0.00441088\n",
      "Iteration 5387, loss = 0.00440967\n",
      "Iteration 5388, loss = 0.00440859\n",
      "Iteration 5389, loss = 0.00440701\n",
      "Iteration 5390, loss = 0.00440590\n",
      "Iteration 5391, loss = 0.00440485\n",
      "Iteration 5392, loss = 0.00440366\n",
      "Iteration 5393, loss = 0.00440242\n",
      "Iteration 5394, loss = 0.00440146\n",
      "Iteration 5395, loss = 0.00440022\n",
      "Iteration 5396, loss = 0.00439916\n",
      "Iteration 5397, loss = 0.00439810\n",
      "Iteration 5398, loss = 0.00439721\n",
      "Iteration 5399, loss = 0.00439612\n",
      "Iteration 5400, loss = 0.00439523\n",
      "Iteration 5401, loss = 0.00439402\n",
      "Iteration 5402, loss = 0.00439287\n",
      "Iteration 5403, loss = 0.00439182\n",
      "Iteration 5404, loss = 0.00439078\n",
      "Iteration 5405, loss = 0.00438975\n",
      "Iteration 5406, loss = 0.00438848\n",
      "Iteration 5407, loss = 0.00438749\n",
      "Iteration 5408, loss = 0.00438637\n",
      "Iteration 5409, loss = 0.00438531\n",
      "Iteration 5410, loss = 0.00438439\n",
      "Iteration 5411, loss = 0.00438317\n",
      "Iteration 5412, loss = 0.00438217\n",
      "Iteration 5413, loss = 0.00438151\n",
      "Iteration 5414, loss = 0.00438008\n",
      "Iteration 5415, loss = 0.00437887\n",
      "Iteration 5416, loss = 0.00437765\n",
      "Iteration 5417, loss = 0.00437697\n",
      "Iteration 5418, loss = 0.00437555\n",
      "Iteration 5419, loss = 0.00437438\n",
      "Iteration 5420, loss = 0.00437330\n",
      "Iteration 5421, loss = 0.00437235\n",
      "Iteration 5422, loss = 0.00437156\n",
      "Iteration 5423, loss = 0.00437021\n",
      "Iteration 5424, loss = 0.00436927\n",
      "Iteration 5425, loss = 0.00436816\n",
      "Iteration 5426, loss = 0.00436698\n",
      "Iteration 5427, loss = 0.00436581\n",
      "Iteration 5428, loss = 0.00436458\n",
      "Iteration 5429, loss = 0.00436345\n",
      "Iteration 5430, loss = 0.00436249\n",
      "Iteration 5431, loss = 0.00436108\n",
      "Iteration 5432, loss = 0.00435990\n",
      "Iteration 5433, loss = 0.00435865\n",
      "Iteration 5434, loss = 0.00435738\n",
      "Iteration 5435, loss = 0.00435646\n",
      "Iteration 5436, loss = 0.00435570\n",
      "Iteration 5437, loss = 0.00435448\n",
      "Iteration 5438, loss = 0.00435343\n",
      "Iteration 5439, loss = 0.00435227\n",
      "Iteration 5440, loss = 0.00435109\n",
      "Iteration 5441, loss = 0.00435053\n",
      "Iteration 5442, loss = 0.00434886\n",
      "Iteration 5443, loss = 0.00434784\n",
      "Iteration 5444, loss = 0.00434706\n",
      "Iteration 5445, loss = 0.00434570\n",
      "Iteration 5446, loss = 0.00434423\n",
      "Iteration 5447, loss = 0.00434314\n",
      "Iteration 5448, loss = 0.00434197\n",
      "Iteration 5449, loss = 0.00434085\n",
      "Iteration 5450, loss = 0.00433970\n",
      "Iteration 5451, loss = 0.00433866\n",
      "Iteration 5452, loss = 0.00433755\n",
      "Iteration 5453, loss = 0.00433629\n",
      "Iteration 5454, loss = 0.00433563\n",
      "Iteration 5455, loss = 0.00433435\n",
      "Iteration 5456, loss = 0.00433321\n",
      "Iteration 5457, loss = 0.00433212\n",
      "Iteration 5458, loss = 0.00433115\n",
      "Iteration 5459, loss = 0.00433012\n",
      "Iteration 5460, loss = 0.00432913\n",
      "Iteration 5461, loss = 0.00432809\n",
      "Iteration 5462, loss = 0.00432720\n",
      "Iteration 5463, loss = 0.00432655\n",
      "Iteration 5464, loss = 0.00432554\n",
      "Iteration 5465, loss = 0.00432436\n",
      "Iteration 5466, loss = 0.00432338\n",
      "Iteration 5467, loss = 0.00432232\n",
      "Iteration 5468, loss = 0.00432143\n",
      "Iteration 5469, loss = 0.00432041\n",
      "Iteration 5470, loss = 0.00431928\n",
      "Iteration 5471, loss = 0.00431831\n",
      "Iteration 5472, loss = 0.00431732\n",
      "Iteration 5473, loss = 0.00431623\n",
      "Iteration 5474, loss = 0.00431525\n",
      "Iteration 5475, loss = 0.00431449\n",
      "Iteration 5476, loss = 0.00431343\n",
      "Iteration 5477, loss = 0.00431271\n",
      "Iteration 5478, loss = 0.00431150\n",
      "Iteration 5479, loss = 0.00431062\n",
      "Iteration 5480, loss = 0.00430948\n",
      "Iteration 5481, loss = 0.00430851\n",
      "Iteration 5482, loss = 0.00430759\n",
      "Iteration 5483, loss = 0.00430664\n",
      "Iteration 5484, loss = 0.00430560\n",
      "Iteration 5485, loss = 0.00430448\n",
      "Iteration 5486, loss = 0.00430362\n",
      "Iteration 5487, loss = 0.00430251\n",
      "Iteration 5488, loss = 0.00430238\n",
      "Iteration 5489, loss = 0.00430087\n",
      "Iteration 5490, loss = 0.00429949\n",
      "Iteration 5491, loss = 0.00429843\n",
      "Iteration 5492, loss = 0.00429732\n",
      "Iteration 5493, loss = 0.00429633\n",
      "Iteration 5494, loss = 0.00429521\n",
      "Iteration 5495, loss = 0.00429399\n",
      "Iteration 5496, loss = 0.00429291\n",
      "Iteration 5497, loss = 0.00429179\n",
      "Iteration 5498, loss = 0.00429106\n",
      "Iteration 5499, loss = 0.00428962\n",
      "Iteration 5500, loss = 0.00428827\n",
      "Iteration 5501, loss = 0.00428724\n",
      "Iteration 5502, loss = 0.00428601\n",
      "Iteration 5503, loss = 0.00428483\n",
      "Iteration 5504, loss = 0.00428368\n",
      "Iteration 5505, loss = 0.00428248\n",
      "Iteration 5506, loss = 0.00428138\n",
      "Iteration 5507, loss = 0.00428025\n",
      "Iteration 5508, loss = 0.00427897\n",
      "Iteration 5509, loss = 0.00427785\n",
      "Iteration 5510, loss = 0.00427665\n",
      "Iteration 5511, loss = 0.00427559\n",
      "Iteration 5512, loss = 0.00427455\n",
      "Iteration 5513, loss = 0.00427345\n",
      "Iteration 5514, loss = 0.00427233\n",
      "Iteration 5515, loss = 0.00427130\n",
      "Iteration 5516, loss = 0.00427028\n",
      "Iteration 5517, loss = 0.00426916\n",
      "Iteration 5518, loss = 0.00426813\n",
      "Iteration 5519, loss = 0.00426727\n",
      "Iteration 5520, loss = 0.00426696\n",
      "Iteration 5521, loss = 0.00426493\n",
      "Iteration 5522, loss = 0.00426374\n",
      "Iteration 5523, loss = 0.00426235\n",
      "Iteration 5524, loss = 0.00426141\n",
      "Iteration 5525, loss = 0.00426024\n",
      "Iteration 5526, loss = 0.00425892\n",
      "Iteration 5527, loss = 0.00425791\n",
      "Iteration 5528, loss = 0.00425707\n",
      "Iteration 5529, loss = 0.00425585\n",
      "Iteration 5530, loss = 0.00425493\n",
      "Iteration 5531, loss = 0.00425348\n",
      "Iteration 5532, loss = 0.00425263\n",
      "Iteration 5533, loss = 0.00425102\n",
      "Iteration 5534, loss = 0.00424995\n",
      "Iteration 5535, loss = 0.00424867\n",
      "Iteration 5536, loss = 0.00424746\n",
      "Iteration 5537, loss = 0.00424653\n",
      "Iteration 5538, loss = 0.00424517\n",
      "Iteration 5539, loss = 0.00424470\n",
      "Iteration 5540, loss = 0.00424336\n",
      "Iteration 5541, loss = 0.00424214\n",
      "Iteration 5542, loss = 0.00424115\n",
      "Iteration 5543, loss = 0.00424019\n",
      "Iteration 5544, loss = 0.00423927\n",
      "Iteration 5545, loss = 0.00423802\n",
      "Iteration 5546, loss = 0.00423758\n",
      "Iteration 5547, loss = 0.00423618\n",
      "Iteration 5548, loss = 0.00423510\n",
      "Iteration 5549, loss = 0.00423422\n",
      "Iteration 5550, loss = 0.00423317\n",
      "Iteration 5551, loss = 0.00423236\n",
      "Iteration 5552, loss = 0.00423126\n",
      "Iteration 5553, loss = 0.00423069\n",
      "Iteration 5554, loss = 0.00422900\n",
      "Iteration 5555, loss = 0.00422787\n",
      "Iteration 5556, loss = 0.00422679\n",
      "Iteration 5557, loss = 0.00422574\n",
      "Iteration 5558, loss = 0.00422482\n",
      "Iteration 5559, loss = 0.00422365\n",
      "Iteration 5560, loss = 0.00422288\n",
      "Iteration 5561, loss = 0.00422160\n",
      "Iteration 5562, loss = 0.00422080\n",
      "Iteration 5563, loss = 0.00421969\n",
      "Iteration 5564, loss = 0.00421879\n",
      "Iteration 5565, loss = 0.00421778\n",
      "Iteration 5566, loss = 0.00421700\n",
      "Iteration 5567, loss = 0.00421576\n",
      "Iteration 5568, loss = 0.00421458\n",
      "Iteration 5569, loss = 0.00421353\n",
      "Iteration 5570, loss = 0.00421247\n",
      "Iteration 5571, loss = 0.00421132\n",
      "Iteration 5572, loss = 0.00420981\n",
      "Iteration 5573, loss = 0.00420875\n",
      "Iteration 5574, loss = 0.00420731\n",
      "Iteration 5575, loss = 0.00420614\n",
      "Iteration 5576, loss = 0.00420514\n",
      "Iteration 5577, loss = 0.00420368\n",
      "Iteration 5578, loss = 0.00420285\n",
      "Iteration 5579, loss = 0.00420197\n",
      "Iteration 5580, loss = 0.00420078\n",
      "Iteration 5581, loss = 0.00419999\n",
      "Iteration 5582, loss = 0.00419886\n",
      "Iteration 5583, loss = 0.00419797\n",
      "Iteration 5584, loss = 0.00419698\n",
      "Iteration 5585, loss = 0.00419607\n",
      "Iteration 5586, loss = 0.00419520\n",
      "Iteration 5587, loss = 0.00419442\n",
      "Iteration 5588, loss = 0.00419395\n",
      "Iteration 5589, loss = 0.00419238\n",
      "Iteration 5590, loss = 0.00419106\n",
      "Iteration 5591, loss = 0.00418993\n",
      "Iteration 5592, loss = 0.00418950\n",
      "Iteration 5593, loss = 0.00418783\n",
      "Iteration 5594, loss = 0.00418667\n",
      "Iteration 5595, loss = 0.00418553\n",
      "Iteration 5596, loss = 0.00418455\n",
      "Iteration 5597, loss = 0.00418333\n",
      "Iteration 5598, loss = 0.00418227\n",
      "Iteration 5599, loss = 0.00418129\n",
      "Iteration 5600, loss = 0.00418024\n",
      "Iteration 5601, loss = 0.00417902\n",
      "Iteration 5602, loss = 0.00417829\n",
      "Iteration 5603, loss = 0.00417693\n",
      "Iteration 5604, loss = 0.00417589\n",
      "Iteration 5605, loss = 0.00417468\n",
      "Iteration 5606, loss = 0.00417355\n",
      "Iteration 5607, loss = 0.00417246\n",
      "Iteration 5608, loss = 0.00417133\n",
      "Iteration 5609, loss = 0.00417049\n",
      "Iteration 5610, loss = 0.00416922\n",
      "Iteration 5611, loss = 0.00416840\n",
      "Iteration 5612, loss = 0.00416743\n",
      "Iteration 5613, loss = 0.00416634\n",
      "Iteration 5614, loss = 0.00416544\n",
      "Iteration 5615, loss = 0.00416462\n",
      "Iteration 5616, loss = 0.00416341\n",
      "Iteration 5617, loss = 0.00416239\n",
      "Iteration 5618, loss = 0.00416125\n",
      "Iteration 5619, loss = 0.00415980\n",
      "Iteration 5620, loss = 0.00415872\n",
      "Iteration 5621, loss = 0.00415748\n",
      "Iteration 5622, loss = 0.00415636\n",
      "Iteration 5623, loss = 0.00415545\n",
      "Iteration 5624, loss = 0.00415413\n",
      "Iteration 5625, loss = 0.00415312\n",
      "Iteration 5626, loss = 0.00415208\n",
      "Iteration 5627, loss = 0.00415100\n",
      "Iteration 5628, loss = 0.00414995\n",
      "Iteration 5629, loss = 0.00414931\n",
      "Iteration 5630, loss = 0.00414809\n",
      "Iteration 5631, loss = 0.00414722\n",
      "Iteration 5632, loss = 0.00414599\n",
      "Iteration 5633, loss = 0.00414469\n",
      "Iteration 5634, loss = 0.00414351\n",
      "Iteration 5635, loss = 0.00414268\n",
      "Iteration 5636, loss = 0.00414135\n",
      "Iteration 5637, loss = 0.00414013\n",
      "Iteration 5638, loss = 0.00413938\n",
      "Iteration 5639, loss = 0.00413827\n",
      "Iteration 5640, loss = 0.00413707\n",
      "Iteration 5641, loss = 0.00413581\n",
      "Iteration 5642, loss = 0.00413500\n",
      "Iteration 5643, loss = 0.00413391\n",
      "Iteration 5644, loss = 0.00413313\n",
      "Iteration 5645, loss = 0.00413195\n",
      "Iteration 5646, loss = 0.00413089\n",
      "Iteration 5647, loss = 0.00412981\n",
      "Iteration 5648, loss = 0.00412874\n",
      "Iteration 5649, loss = 0.00412769\n",
      "Iteration 5650, loss = 0.00412681\n",
      "Iteration 5651, loss = 0.00412562\n",
      "Iteration 5652, loss = 0.00412448\n",
      "Iteration 5653, loss = 0.00412364\n",
      "Iteration 5654, loss = 0.00412250\n",
      "Iteration 5655, loss = 0.00412152\n",
      "Iteration 5656, loss = 0.00412051\n",
      "Iteration 5657, loss = 0.00411956\n",
      "Iteration 5658, loss = 0.00411867\n",
      "Iteration 5659, loss = 0.00411781\n",
      "Iteration 5660, loss = 0.00411664\n",
      "Iteration 5661, loss = 0.00411557\n",
      "Iteration 5662, loss = 0.00411492\n",
      "Iteration 5663, loss = 0.00411373\n",
      "Iteration 5664, loss = 0.00411267\n",
      "Iteration 5665, loss = 0.00411172\n",
      "Iteration 5666, loss = 0.00411067\n",
      "Iteration 5667, loss = 0.00410946\n",
      "Iteration 5668, loss = 0.00410867\n",
      "Iteration 5669, loss = 0.00410763\n",
      "Iteration 5670, loss = 0.00410664\n",
      "Iteration 5671, loss = 0.00410567\n",
      "Iteration 5672, loss = 0.00410483\n",
      "Iteration 5673, loss = 0.00410383\n",
      "Iteration 5674, loss = 0.00410280\n",
      "Iteration 5675, loss = 0.00410232\n",
      "Iteration 5676, loss = 0.00410111\n",
      "Iteration 5677, loss = 0.00410021\n",
      "Iteration 5678, loss = 0.00409908\n",
      "Iteration 5679, loss = 0.00409799\n",
      "Iteration 5680, loss = 0.00409702\n",
      "Iteration 5681, loss = 0.00409585\n",
      "Iteration 5682, loss = 0.00409462\n",
      "Iteration 5683, loss = 0.00409344\n",
      "Iteration 5684, loss = 0.00409230\n",
      "Iteration 5685, loss = 0.00409107\n",
      "Iteration 5686, loss = 0.00408974\n",
      "Iteration 5687, loss = 0.00408856\n",
      "Iteration 5688, loss = 0.00408773\n",
      "Iteration 5689, loss = 0.00408634\n",
      "Iteration 5690, loss = 0.00408539\n",
      "Iteration 5691, loss = 0.00408418\n",
      "Iteration 5692, loss = 0.00408314\n",
      "Iteration 5693, loss = 0.00408197\n",
      "Iteration 5694, loss = 0.00408100\n",
      "Iteration 5695, loss = 0.00407993\n",
      "Iteration 5696, loss = 0.00407870\n",
      "Iteration 5697, loss = 0.00407757\n",
      "Iteration 5698, loss = 0.00407702\n",
      "Iteration 5699, loss = 0.00407595\n",
      "Iteration 5700, loss = 0.00407441\n",
      "Iteration 5701, loss = 0.00407331\n",
      "Iteration 5702, loss = 0.00407254\n",
      "Iteration 5703, loss = 0.00407120\n",
      "Iteration 5704, loss = 0.00406977\n",
      "Iteration 5705, loss = 0.00406840\n",
      "Iteration 5706, loss = 0.00406740\n",
      "Iteration 5707, loss = 0.00406668\n",
      "Iteration 5708, loss = 0.00406595\n",
      "Iteration 5709, loss = 0.00406427\n",
      "Iteration 5710, loss = 0.00406335\n",
      "Iteration 5711, loss = 0.00406223\n",
      "Iteration 5712, loss = 0.00406124\n",
      "Iteration 5713, loss = 0.00406003\n",
      "Iteration 5714, loss = 0.00405939\n",
      "Iteration 5715, loss = 0.00405815\n",
      "Iteration 5716, loss = 0.00405696\n",
      "Iteration 5717, loss = 0.00405581\n",
      "Iteration 5718, loss = 0.00405469\n",
      "Iteration 5719, loss = 0.00405371\n",
      "Iteration 5720, loss = 0.00405264\n",
      "Iteration 5721, loss = 0.00405202\n",
      "Iteration 5722, loss = 0.00405073\n",
      "Iteration 5723, loss = 0.00405033\n",
      "Iteration 5724, loss = 0.00404897\n",
      "Iteration 5725, loss = 0.00404787\n",
      "Iteration 5726, loss = 0.00404664\n",
      "Iteration 5727, loss = 0.00404574\n",
      "Iteration 5728, loss = 0.00404499\n",
      "Iteration 5729, loss = 0.00404368\n",
      "Iteration 5730, loss = 0.00404282\n",
      "Iteration 5731, loss = 0.00404182\n",
      "Iteration 5732, loss = 0.00404065\n",
      "Iteration 5733, loss = 0.00403972\n",
      "Iteration 5734, loss = 0.00403881\n",
      "Iteration 5735, loss = 0.00403812\n",
      "Iteration 5736, loss = 0.00403710\n",
      "Iteration 5737, loss = 0.00403620\n",
      "Iteration 5738, loss = 0.00403528\n",
      "Iteration 5739, loss = 0.00403460\n",
      "Iteration 5740, loss = 0.00403372\n",
      "Iteration 5741, loss = 0.00403288\n",
      "Iteration 5742, loss = 0.00403227\n",
      "Iteration 5743, loss = 0.00403132\n",
      "Iteration 5744, loss = 0.00403030\n",
      "Iteration 5745, loss = 0.00402914\n",
      "Iteration 5746, loss = 0.00402833\n",
      "Iteration 5747, loss = 0.00402731\n",
      "Iteration 5748, loss = 0.00402630\n",
      "Iteration 5749, loss = 0.00402538\n",
      "Iteration 5750, loss = 0.00402455\n",
      "Iteration 5751, loss = 0.00402355\n",
      "Iteration 5752, loss = 0.00402265\n",
      "Iteration 5753, loss = 0.00402171\n",
      "Iteration 5754, loss = 0.00402076\n",
      "Iteration 5755, loss = 0.00401969\n",
      "Iteration 5756, loss = 0.00401845\n",
      "Iteration 5757, loss = 0.00401759\n",
      "Iteration 5758, loss = 0.00401672\n",
      "Iteration 5759, loss = 0.00401598\n",
      "Iteration 5760, loss = 0.00401508\n",
      "Iteration 5761, loss = 0.00401395\n",
      "Iteration 5762, loss = 0.00401268\n",
      "Iteration 5763, loss = 0.00401178\n",
      "Iteration 5764, loss = 0.00401098\n",
      "Iteration 5765, loss = 0.00400988\n",
      "Iteration 5766, loss = 0.00400879\n",
      "Iteration 5767, loss = 0.00400805\n",
      "Iteration 5768, loss = 0.00400688\n",
      "Iteration 5769, loss = 0.00400609\n",
      "Iteration 5770, loss = 0.00400506\n",
      "Iteration 5771, loss = 0.00400416\n",
      "Iteration 5772, loss = 0.00400325\n",
      "Iteration 5773, loss = 0.00400273\n",
      "Iteration 5774, loss = 0.00400121\n",
      "Iteration 5775, loss = 0.00400036\n",
      "Iteration 5776, loss = 0.00399910\n",
      "Iteration 5777, loss = 0.00399820\n",
      "Iteration 5778, loss = 0.00399729\n",
      "Iteration 5779, loss = 0.00399592\n",
      "Iteration 5780, loss = 0.00399485\n",
      "Iteration 5781, loss = 0.00399390\n",
      "Iteration 5782, loss = 0.00399285\n",
      "Iteration 5783, loss = 0.00399173\n",
      "Iteration 5784, loss = 0.00399089\n",
      "Iteration 5785, loss = 0.00398984\n",
      "Iteration 5786, loss = 0.00398881\n",
      "Iteration 5787, loss = 0.00398786\n",
      "Iteration 5788, loss = 0.00398702\n",
      "Iteration 5789, loss = 0.00398608\n",
      "Iteration 5790, loss = 0.00398520\n",
      "Iteration 5791, loss = 0.00398404\n",
      "Iteration 5792, loss = 0.00398375\n",
      "Iteration 5793, loss = 0.00398223\n",
      "Iteration 5794, loss = 0.00398123\n",
      "Iteration 5795, loss = 0.00398017\n",
      "Iteration 5796, loss = 0.00397927\n",
      "Iteration 5797, loss = 0.00397861\n",
      "Iteration 5798, loss = 0.00397701\n",
      "Iteration 5799, loss = 0.00397589\n",
      "Iteration 5800, loss = 0.00397490\n",
      "Iteration 5801, loss = 0.00397389\n",
      "Iteration 5802, loss = 0.00397287\n",
      "Iteration 5803, loss = 0.00397225\n",
      "Iteration 5804, loss = 0.00397103\n",
      "Iteration 5805, loss = 0.00397003\n",
      "Iteration 5806, loss = 0.00396917\n",
      "Iteration 5807, loss = 0.00396866\n",
      "Iteration 5808, loss = 0.00396768\n",
      "Iteration 5809, loss = 0.00396691\n",
      "Iteration 5810, loss = 0.00396575\n",
      "Iteration 5811, loss = 0.00396488\n",
      "Iteration 5812, loss = 0.00396393\n",
      "Iteration 5813, loss = 0.00396305\n",
      "Iteration 5814, loss = 0.00396219\n",
      "Iteration 5815, loss = 0.00396195\n",
      "Iteration 5816, loss = 0.00396043\n",
      "Iteration 5817, loss = 0.00395942\n",
      "Iteration 5818, loss = 0.00395867\n",
      "Iteration 5819, loss = 0.00395754\n",
      "Iteration 5820, loss = 0.00395686\n",
      "Iteration 5821, loss = 0.00395591\n",
      "Iteration 5822, loss = 0.00395502\n",
      "Iteration 5823, loss = 0.00395384\n",
      "Iteration 5824, loss = 0.00395297\n",
      "Iteration 5825, loss = 0.00395209\n",
      "Iteration 5826, loss = 0.00395103\n",
      "Iteration 5827, loss = 0.00395006\n",
      "Iteration 5828, loss = 0.00394886\n",
      "Iteration 5829, loss = 0.00394846\n",
      "Iteration 5830, loss = 0.00394670\n",
      "Iteration 5831, loss = 0.00394564\n",
      "Iteration 5832, loss = 0.00394460\n",
      "Iteration 5833, loss = 0.00394354\n",
      "Iteration 5834, loss = 0.00394260\n",
      "Iteration 5835, loss = 0.00394165\n",
      "Iteration 5836, loss = 0.00394064\n",
      "Iteration 5837, loss = 0.00393949\n",
      "Iteration 5838, loss = 0.00393841\n",
      "Iteration 5839, loss = 0.00393743\n",
      "Iteration 5840, loss = 0.00393658\n",
      "Iteration 5841, loss = 0.00393561\n",
      "Iteration 5842, loss = 0.00393459\n",
      "Iteration 5843, loss = 0.00393348\n",
      "Iteration 5844, loss = 0.00393266\n",
      "Iteration 5845, loss = 0.00393215\n",
      "Iteration 5846, loss = 0.00393077\n",
      "Iteration 5847, loss = 0.00392968\n",
      "Iteration 5848, loss = 0.00392873\n",
      "Iteration 5849, loss = 0.00392778\n",
      "Iteration 5850, loss = 0.00392666\n",
      "Iteration 5851, loss = 0.00392547\n",
      "Iteration 5852, loss = 0.00392502\n",
      "Iteration 5853, loss = 0.00392388\n",
      "Iteration 5854, loss = 0.00392277\n",
      "Iteration 5855, loss = 0.00392157\n",
      "Iteration 5856, loss = 0.00392075\n",
      "Iteration 5857, loss = 0.00391994\n",
      "Iteration 5858, loss = 0.00391888\n",
      "Iteration 5859, loss = 0.00391799\n",
      "Iteration 5860, loss = 0.00391675\n",
      "Iteration 5861, loss = 0.00391584\n",
      "Iteration 5862, loss = 0.00391477\n",
      "Iteration 5863, loss = 0.00391387\n",
      "Iteration 5864, loss = 0.00391323\n",
      "Iteration 5865, loss = 0.00391204\n",
      "Iteration 5866, loss = 0.00391145\n",
      "Iteration 5867, loss = 0.00391033\n",
      "Iteration 5868, loss = 0.00390942\n",
      "Iteration 5869, loss = 0.00390851\n",
      "Iteration 5870, loss = 0.00390751\n",
      "Iteration 5871, loss = 0.00390648\n",
      "Iteration 5872, loss = 0.00390549\n",
      "Iteration 5873, loss = 0.00390444\n",
      "Iteration 5874, loss = 0.00390370\n",
      "Iteration 5875, loss = 0.00390246\n",
      "Iteration 5876, loss = 0.00390158\n",
      "Iteration 5877, loss = 0.00390051\n",
      "Iteration 5878, loss = 0.00389953\n",
      "Iteration 5879, loss = 0.00389867\n",
      "Iteration 5880, loss = 0.00389785\n",
      "Iteration 5881, loss = 0.00389697\n",
      "Iteration 5882, loss = 0.00389606\n",
      "Iteration 5883, loss = 0.00389523\n",
      "Iteration 5884, loss = 0.00389425\n",
      "Iteration 5885, loss = 0.00389338\n",
      "Iteration 5886, loss = 0.00389254\n",
      "Iteration 5887, loss = 0.00389144\n",
      "Iteration 5888, loss = 0.00389056\n",
      "Iteration 5889, loss = 0.00388976\n",
      "Iteration 5890, loss = 0.00388884\n",
      "Iteration 5891, loss = 0.00388776\n",
      "Iteration 5892, loss = 0.00388718\n",
      "Iteration 5893, loss = 0.00388598\n",
      "Iteration 5894, loss = 0.00388512\n",
      "Iteration 5895, loss = 0.00388428\n",
      "Iteration 5896, loss = 0.00388321\n",
      "Iteration 5897, loss = 0.00388214\n",
      "Iteration 5898, loss = 0.00388131\n",
      "Iteration 5899, loss = 0.00388032\n",
      "Iteration 5900, loss = 0.00387929\n",
      "Iteration 5901, loss = 0.00387842\n",
      "Iteration 5902, loss = 0.00387750\n",
      "Iteration 5903, loss = 0.00387663\n",
      "Iteration 5904, loss = 0.00387579\n",
      "Iteration 5905, loss = 0.00387486\n",
      "Iteration 5906, loss = 0.00387426\n",
      "Iteration 5907, loss = 0.00387315\n",
      "Iteration 5908, loss = 0.00387240\n",
      "Iteration 5909, loss = 0.00387163\n",
      "Iteration 5910, loss = 0.00387057\n",
      "Iteration 5911, loss = 0.00386976\n",
      "Iteration 5912, loss = 0.00386865\n",
      "Iteration 5913, loss = 0.00386789\n",
      "Iteration 5914, loss = 0.00386700\n",
      "Iteration 5915, loss = 0.00386617\n",
      "Iteration 5916, loss = 0.00386524\n",
      "Iteration 5917, loss = 0.00386443\n",
      "Iteration 5918, loss = 0.00386352\n",
      "Iteration 5919, loss = 0.00386289\n",
      "Iteration 5920, loss = 0.00386184\n",
      "Iteration 5921, loss = 0.00386086\n",
      "Iteration 5922, loss = 0.00385973\n",
      "Iteration 5923, loss = 0.00385892\n",
      "Iteration 5924, loss = 0.00385792\n",
      "Iteration 5925, loss = 0.00385702\n",
      "Iteration 5926, loss = 0.00385604\n",
      "Iteration 5927, loss = 0.00385509\n",
      "Iteration 5928, loss = 0.00385414\n",
      "Iteration 5929, loss = 0.00385310\n",
      "Iteration 5930, loss = 0.00385212\n",
      "Iteration 5931, loss = 0.00385115\n",
      "Iteration 5932, loss = 0.00385013\n",
      "Iteration 5933, loss = 0.00384910\n",
      "Iteration 5934, loss = 0.00384796\n",
      "Iteration 5935, loss = 0.00384664\n",
      "Iteration 5936, loss = 0.00384535\n",
      "Iteration 5937, loss = 0.00384477\n",
      "Iteration 5938, loss = 0.00384406\n",
      "Iteration 5939, loss = 0.00384330\n",
      "Iteration 5940, loss = 0.00384179\n",
      "Iteration 5941, loss = 0.00384106\n",
      "Iteration 5942, loss = 0.00384018\n",
      "Iteration 5943, loss = 0.00383934\n",
      "Iteration 5944, loss = 0.00383839\n",
      "Iteration 5945, loss = 0.00383743\n",
      "Iteration 5946, loss = 0.00383652\n",
      "Iteration 5947, loss = 0.00383554\n",
      "Iteration 5948, loss = 0.00383465\n",
      "Iteration 5949, loss = 0.00383381\n",
      "Iteration 5950, loss = 0.00383284\n",
      "Iteration 5951, loss = 0.00383205\n",
      "Iteration 5952, loss = 0.00383106\n",
      "Iteration 5953, loss = 0.00383005\n",
      "Iteration 5954, loss = 0.00382919\n",
      "Iteration 5955, loss = 0.00382821\n",
      "Iteration 5956, loss = 0.00382728\n",
      "Iteration 5957, loss = 0.00382637\n",
      "Iteration 5958, loss = 0.00382547\n",
      "Iteration 5959, loss = 0.00382458\n",
      "Iteration 5960, loss = 0.00382365\n",
      "Iteration 5961, loss = 0.00382280\n",
      "Iteration 5962, loss = 0.00382205\n",
      "Iteration 5963, loss = 0.00382130\n",
      "Iteration 5964, loss = 0.00382017\n",
      "Iteration 5965, loss = 0.00381932\n",
      "Iteration 5966, loss = 0.00381825\n",
      "Iteration 5967, loss = 0.00381747\n",
      "Iteration 5968, loss = 0.00381629\n",
      "Iteration 5969, loss = 0.00381529\n",
      "Iteration 5970, loss = 0.00381455\n",
      "Iteration 5971, loss = 0.00381379\n",
      "Iteration 5972, loss = 0.00381262\n",
      "Iteration 5973, loss = 0.00381191\n",
      "Iteration 5974, loss = 0.00381120\n",
      "Iteration 5975, loss = 0.00381011\n",
      "Iteration 5976, loss = 0.00380931\n",
      "Iteration 5977, loss = 0.00380828\n",
      "Iteration 5978, loss = 0.00380747\n",
      "Iteration 5979, loss = 0.00380634\n",
      "Iteration 5980, loss = 0.00380582\n",
      "Iteration 5981, loss = 0.00380462\n",
      "Iteration 5982, loss = 0.00380374\n",
      "Iteration 5983, loss = 0.00380268\n",
      "Iteration 5984, loss = 0.00380180\n",
      "Iteration 5985, loss = 0.00380100\n",
      "Iteration 5986, loss = 0.00379990\n",
      "Iteration 5987, loss = 0.00379909\n",
      "Iteration 5988, loss = 0.00379803\n",
      "Iteration 5989, loss = 0.00379711\n",
      "Iteration 5990, loss = 0.00379644\n",
      "Iteration 5991, loss = 0.00379532\n",
      "Iteration 5992, loss = 0.00379426\n",
      "Iteration 5993, loss = 0.00379344\n",
      "Iteration 5994, loss = 0.00379237\n",
      "Iteration 5995, loss = 0.00379135\n",
      "Iteration 5996, loss = 0.00379058\n",
      "Iteration 5997, loss = 0.00378957\n",
      "Iteration 5998, loss = 0.00378858\n",
      "Iteration 5999, loss = 0.00378803\n",
      "Iteration 6000, loss = 0.00378707\n",
      "Iteration 6001, loss = 0.00378597\n",
      "Iteration 6002, loss = 0.00378505\n",
      "Iteration 6003, loss = 0.00378435\n",
      "Iteration 6004, loss = 0.00378333\n",
      "Iteration 6005, loss = 0.00378255\n",
      "Iteration 6006, loss = 0.00378174\n",
      "Iteration 6007, loss = 0.00378091\n",
      "Iteration 6008, loss = 0.00378007\n",
      "Iteration 6009, loss = 0.00377923\n",
      "Iteration 6010, loss = 0.00377859\n",
      "Iteration 6011, loss = 0.00377766\n",
      "Iteration 6012, loss = 0.00377739\n",
      "Iteration 6013, loss = 0.00377594\n",
      "Iteration 6014, loss = 0.00377511\n",
      "Iteration 6015, loss = 0.00377422\n",
      "Iteration 6016, loss = 0.00377334\n",
      "Iteration 6017, loss = 0.00377238\n",
      "Iteration 6018, loss = 0.00377158\n",
      "Iteration 6019, loss = 0.00377050\n",
      "Iteration 6020, loss = 0.00376949\n",
      "Iteration 6021, loss = 0.00376855\n",
      "Iteration 6022, loss = 0.00376757\n",
      "Iteration 6023, loss = 0.00376668\n",
      "Iteration 6024, loss = 0.00376636\n",
      "Iteration 6025, loss = 0.00376531\n",
      "Iteration 6026, loss = 0.00376445\n",
      "Iteration 6027, loss = 0.00376358\n",
      "Iteration 6028, loss = 0.00376265\n",
      "Iteration 6029, loss = 0.00376186\n",
      "Iteration 6030, loss = 0.00376105\n",
      "Iteration 6031, loss = 0.00376016\n",
      "Iteration 6032, loss = 0.00375939\n",
      "Iteration 6033, loss = 0.00375856\n",
      "Iteration 6034, loss = 0.00375790\n",
      "Iteration 6035, loss = 0.00375684\n",
      "Iteration 6036, loss = 0.00375600\n",
      "Iteration 6037, loss = 0.00375513\n",
      "Iteration 6038, loss = 0.00375435\n",
      "Iteration 6039, loss = 0.00375338\n",
      "Iteration 6040, loss = 0.00375252\n",
      "Iteration 6041, loss = 0.00375201\n",
      "Iteration 6042, loss = 0.00375085\n",
      "Iteration 6043, loss = 0.00374984\n",
      "Iteration 6044, loss = 0.00374907\n",
      "Iteration 6045, loss = 0.00374840\n",
      "Iteration 6046, loss = 0.00374714\n",
      "Iteration 6047, loss = 0.00374609\n",
      "Iteration 6048, loss = 0.00374517\n",
      "Iteration 6049, loss = 0.00374421\n",
      "Iteration 6050, loss = 0.00374332\n",
      "Iteration 6051, loss = 0.00374253\n",
      "Iteration 6052, loss = 0.00374155\n",
      "Iteration 6053, loss = 0.00374058\n",
      "Iteration 6054, loss = 0.00373956\n",
      "Iteration 6055, loss = 0.00373937\n",
      "Iteration 6056, loss = 0.00373775\n",
      "Iteration 6057, loss = 0.00373698\n",
      "Iteration 6058, loss = 0.00373633\n",
      "Iteration 6059, loss = 0.00373553\n",
      "Iteration 6060, loss = 0.00373435\n",
      "Iteration 6061, loss = 0.00373354\n",
      "Iteration 6062, loss = 0.00373273\n",
      "Iteration 6063, loss = 0.00373205\n",
      "Iteration 6064, loss = 0.00373089\n",
      "Iteration 6065, loss = 0.00373028\n",
      "Iteration 6066, loss = 0.00372944\n",
      "Iteration 6067, loss = 0.00372844\n",
      "Iteration 6068, loss = 0.00372760\n",
      "Iteration 6069, loss = 0.00372682\n",
      "Iteration 6070, loss = 0.00372612\n",
      "Iteration 6071, loss = 0.00372515\n",
      "Iteration 6072, loss = 0.00372441\n",
      "Iteration 6073, loss = 0.00372354\n",
      "Iteration 6074, loss = 0.00372274\n",
      "Iteration 6075, loss = 0.00372188\n",
      "Iteration 6076, loss = 0.00372089\n",
      "Iteration 6077, loss = 0.00372005\n",
      "Iteration 6078, loss = 0.00371921\n",
      "Iteration 6079, loss = 0.00371853\n",
      "Iteration 6080, loss = 0.00371739\n",
      "Iteration 6081, loss = 0.00371636\n",
      "Iteration 6082, loss = 0.00371567\n",
      "Iteration 6083, loss = 0.00371458\n",
      "Iteration 6084, loss = 0.00371362\n",
      "Iteration 6085, loss = 0.00371276\n",
      "Iteration 6086, loss = 0.00371183\n",
      "Iteration 6087, loss = 0.00371101\n",
      "Iteration 6088, loss = 0.00371012\n",
      "Iteration 6089, loss = 0.00370917\n",
      "Iteration 6090, loss = 0.00370822\n",
      "Iteration 6091, loss = 0.00370751\n",
      "Iteration 6092, loss = 0.00370645\n",
      "Iteration 6093, loss = 0.00370558\n",
      "Iteration 6094, loss = 0.00370466\n",
      "Iteration 6095, loss = 0.00370426\n",
      "Iteration 6096, loss = 0.00370306\n",
      "Iteration 6097, loss = 0.00370211\n",
      "Iteration 6098, loss = 0.00370102\n",
      "Iteration 6099, loss = 0.00370035\n",
      "Iteration 6100, loss = 0.00369927\n",
      "Iteration 6101, loss = 0.00369860\n",
      "Iteration 6102, loss = 0.00369758\n",
      "Iteration 6103, loss = 0.00369690\n",
      "Iteration 6104, loss = 0.00369577\n",
      "Iteration 6105, loss = 0.00369493\n",
      "Iteration 6106, loss = 0.00369406\n",
      "Iteration 6107, loss = 0.00369322\n",
      "Iteration 6108, loss = 0.00369263\n",
      "Iteration 6109, loss = 0.00369166\n",
      "Iteration 6110, loss = 0.00369091\n",
      "Iteration 6111, loss = 0.00369014\n",
      "Iteration 6112, loss = 0.00368924\n",
      "Iteration 6113, loss = 0.00368851\n",
      "Iteration 6114, loss = 0.00368767\n",
      "Iteration 6115, loss = 0.00368695\n",
      "Iteration 6116, loss = 0.00368625\n",
      "Iteration 6117, loss = 0.00368547\n",
      "Iteration 6118, loss = 0.00368458\n",
      "Iteration 6119, loss = 0.00368386\n",
      "Iteration 6120, loss = 0.00368312\n",
      "Iteration 6121, loss = 0.00368266\n",
      "Iteration 6122, loss = 0.00368162\n",
      "Iteration 6123, loss = 0.00368081\n",
      "Iteration 6124, loss = 0.00368002\n",
      "Iteration 6125, loss = 0.00367935\n",
      "Iteration 6126, loss = 0.00367848\n",
      "Iteration 6127, loss = 0.00367766\n",
      "Iteration 6128, loss = 0.00367684\n",
      "Iteration 6129, loss = 0.00367594\n",
      "Iteration 6130, loss = 0.00367534\n",
      "Iteration 6131, loss = 0.00367498\n",
      "Iteration 6132, loss = 0.00367364\n",
      "Iteration 6133, loss = 0.00367295\n",
      "Iteration 6134, loss = 0.00367207\n",
      "Iteration 6135, loss = 0.00367101\n",
      "Iteration 6136, loss = 0.00367032\n",
      "Iteration 6137, loss = 0.00366947\n",
      "Iteration 6138, loss = 0.00366864\n",
      "Iteration 6139, loss = 0.00366774\n",
      "Iteration 6140, loss = 0.00366692\n",
      "Iteration 6141, loss = 0.00366613\n",
      "Iteration 6142, loss = 0.00366521\n",
      "Iteration 6143, loss = 0.00366476\n",
      "Iteration 6144, loss = 0.00366337\n",
      "Iteration 6145, loss = 0.00366254\n",
      "Iteration 6146, loss = 0.00366202\n",
      "Iteration 6147, loss = 0.00366087\n",
      "Iteration 6148, loss = 0.00366006\n",
      "Iteration 6149, loss = 0.00365923\n",
      "Iteration 6150, loss = 0.00365833\n",
      "Iteration 6151, loss = 0.00365744\n",
      "Iteration 6152, loss = 0.00365666\n",
      "Iteration 6153, loss = 0.00365576\n",
      "Iteration 6154, loss = 0.00365494\n",
      "Iteration 6155, loss = 0.00365414\n",
      "Iteration 6156, loss = 0.00365315\n",
      "Iteration 6157, loss = 0.00365231\n",
      "Iteration 6158, loss = 0.00365124\n",
      "Iteration 6159, loss = 0.00365065\n",
      "Iteration 6160, loss = 0.00364976\n",
      "Iteration 6161, loss = 0.00364863\n",
      "Iteration 6162, loss = 0.00364762\n",
      "Iteration 6163, loss = 0.00364654\n",
      "Iteration 6164, loss = 0.00364664\n",
      "Iteration 6165, loss = 0.00364496\n",
      "Iteration 6166, loss = 0.00364411\n",
      "Iteration 6167, loss = 0.00364337\n",
      "Iteration 6168, loss = 0.00364274\n",
      "Iteration 6169, loss = 0.00364177\n",
      "Iteration 6170, loss = 0.00364073\n",
      "Iteration 6171, loss = 0.00363972\n",
      "Iteration 6172, loss = 0.00363922\n",
      "Iteration 6173, loss = 0.00363797\n",
      "Iteration 6174, loss = 0.00363711\n",
      "Iteration 6175, loss = 0.00363610\n",
      "Iteration 6176, loss = 0.00363548\n",
      "Iteration 6177, loss = 0.00363438\n",
      "Iteration 6178, loss = 0.00363349\n",
      "Iteration 6179, loss = 0.00363267\n",
      "Iteration 6180, loss = 0.00363190\n",
      "Iteration 6181, loss = 0.00363120\n",
      "Iteration 6182, loss = 0.00363022\n",
      "Iteration 6183, loss = 0.00362940\n",
      "Iteration 6184, loss = 0.00362851\n",
      "Iteration 6185, loss = 0.00362760\n",
      "Iteration 6186, loss = 0.00362674\n",
      "Iteration 6187, loss = 0.00362597\n",
      "Iteration 6188, loss = 0.00362533\n",
      "Iteration 6189, loss = 0.00362444\n",
      "Iteration 6190, loss = 0.00362368\n",
      "Iteration 6191, loss = 0.00362307\n",
      "Iteration 6192, loss = 0.00362233\n",
      "Iteration 6193, loss = 0.00362173\n",
      "Iteration 6194, loss = 0.00362092\n",
      "Iteration 6195, loss = 0.00362011\n",
      "Iteration 6196, loss = 0.00361945\n",
      "Iteration 6197, loss = 0.00361858\n",
      "Iteration 6198, loss = 0.00361779\n",
      "Iteration 6199, loss = 0.00361710\n",
      "Iteration 6200, loss = 0.00361654\n",
      "Iteration 6201, loss = 0.00361584\n",
      "Iteration 6202, loss = 0.00361491\n",
      "Iteration 6203, loss = 0.00361396\n",
      "Iteration 6204, loss = 0.00361320\n",
      "Iteration 6205, loss = 0.00361230\n",
      "Iteration 6206, loss = 0.00361145\n",
      "Iteration 6207, loss = 0.00361072\n",
      "Iteration 6208, loss = 0.00360990\n",
      "Iteration 6209, loss = 0.00360919\n",
      "Iteration 6210, loss = 0.00360847\n",
      "Iteration 6211, loss = 0.00360779\n",
      "Iteration 6212, loss = 0.00360736\n",
      "Iteration 6213, loss = 0.00360651\n",
      "Iteration 6214, loss = 0.00360569\n",
      "Iteration 6215, loss = 0.00360496\n",
      "Iteration 6216, loss = 0.00360420\n",
      "Iteration 6217, loss = 0.00360346\n",
      "Iteration 6218, loss = 0.00360271\n",
      "Iteration 6219, loss = 0.00360190\n",
      "Iteration 6220, loss = 0.00360133\n",
      "Iteration 6221, loss = 0.00360057\n",
      "Iteration 6222, loss = 0.00359962\n",
      "Iteration 6223, loss = 0.00359878\n",
      "Iteration 6224, loss = 0.00359806\n",
      "Iteration 6225, loss = 0.00359717\n",
      "Iteration 6226, loss = 0.00359621\n",
      "Iteration 6227, loss = 0.00359575\n",
      "Iteration 6228, loss = 0.00359448\n",
      "Iteration 6229, loss = 0.00359388\n",
      "Iteration 6230, loss = 0.00359284\n",
      "Iteration 6231, loss = 0.00359198\n",
      "Iteration 6232, loss = 0.00359113\n",
      "Iteration 6233, loss = 0.00359022\n",
      "Iteration 6234, loss = 0.00358934\n",
      "Iteration 6235, loss = 0.00358835\n",
      "Iteration 6236, loss = 0.00358775\n",
      "Iteration 6237, loss = 0.00358673\n",
      "Iteration 6238, loss = 0.00358587\n",
      "Iteration 6239, loss = 0.00358504\n",
      "Iteration 6240, loss = 0.00358414\n",
      "Iteration 6241, loss = 0.00358338\n",
      "Iteration 6242, loss = 0.00358269\n",
      "Iteration 6243, loss = 0.00358191\n",
      "Iteration 6244, loss = 0.00358119\n",
      "Iteration 6245, loss = 0.00358062\n",
      "Iteration 6246, loss = 0.00357983\n",
      "Iteration 6247, loss = 0.00357901\n",
      "Iteration 6248, loss = 0.00357842\n",
      "Iteration 6249, loss = 0.00357771\n",
      "Iteration 6250, loss = 0.00357685\n",
      "Iteration 6251, loss = 0.00357605\n",
      "Iteration 6252, loss = 0.00357534\n",
      "Iteration 6253, loss = 0.00357452\n",
      "Iteration 6254, loss = 0.00357360\n",
      "Iteration 6255, loss = 0.00357287\n",
      "Iteration 6256, loss = 0.00357189\n",
      "Iteration 6257, loss = 0.00357158\n",
      "Iteration 6258, loss = 0.00357037\n",
      "Iteration 6259, loss = 0.00356947\n",
      "Iteration 6260, loss = 0.00356869\n",
      "Iteration 6261, loss = 0.00356775\n",
      "Iteration 6262, loss = 0.00356683\n",
      "Iteration 6263, loss = 0.00356585\n",
      "Iteration 6264, loss = 0.00356529\n",
      "Iteration 6265, loss = 0.00356429\n",
      "Iteration 6266, loss = 0.00356345\n",
      "Iteration 6267, loss = 0.00356248\n",
      "Iteration 6268, loss = 0.00356169\n",
      "Iteration 6269, loss = 0.00356086\n",
      "Iteration 6270, loss = 0.00355995\n",
      "Iteration 6271, loss = 0.00355911\n",
      "Iteration 6272, loss = 0.00355828\n",
      "Iteration 6273, loss = 0.00355757\n",
      "Iteration 6274, loss = 0.00355655\n",
      "Iteration 6275, loss = 0.00355569\n",
      "Iteration 6276, loss = 0.00355484\n",
      "Iteration 6277, loss = 0.00355382\n",
      "Iteration 6278, loss = 0.00355300\n",
      "Iteration 6279, loss = 0.00355231\n",
      "Iteration 6280, loss = 0.00355130\n",
      "Iteration 6281, loss = 0.00355058\n",
      "Iteration 6282, loss = 0.00354968\n",
      "Iteration 6283, loss = 0.00354896\n",
      "Iteration 6284, loss = 0.00354830\n",
      "Iteration 6285, loss = 0.00354740\n",
      "Iteration 6286, loss = 0.00354664\n",
      "Iteration 6287, loss = 0.00354630\n",
      "Iteration 6288, loss = 0.00354524\n",
      "Iteration 6289, loss = 0.00354443\n",
      "Iteration 6290, loss = 0.00354343\n",
      "Iteration 6291, loss = 0.00354249\n",
      "Iteration 6292, loss = 0.00354168\n",
      "Iteration 6293, loss = 0.00354141\n",
      "Iteration 6294, loss = 0.00354025\n",
      "Iteration 6295, loss = 0.00353940\n",
      "Iteration 6296, loss = 0.00353875\n",
      "Iteration 6297, loss = 0.00353800\n",
      "Iteration 6298, loss = 0.00353698\n",
      "Iteration 6299, loss = 0.00353659\n",
      "Iteration 6300, loss = 0.00353557\n",
      "Iteration 6301, loss = 0.00353459\n",
      "Iteration 6302, loss = 0.00353393\n",
      "Iteration 6303, loss = 0.00353310\n",
      "Iteration 6304, loss = 0.00353198\n",
      "Iteration 6305, loss = 0.00353147\n",
      "Iteration 6306, loss = 0.00353033\n",
      "Iteration 6307, loss = 0.00352986\n",
      "Iteration 6308, loss = 0.00352873\n",
      "Iteration 6309, loss = 0.00352792\n",
      "Iteration 6310, loss = 0.00352726\n",
      "Iteration 6311, loss = 0.00352647\n",
      "Iteration 6312, loss = 0.00352552\n",
      "Iteration 6313, loss = 0.00352505\n",
      "Iteration 6314, loss = 0.00352399\n",
      "Iteration 6315, loss = 0.00352340\n",
      "Iteration 6316, loss = 0.00352232\n",
      "Iteration 6317, loss = 0.00352159\n",
      "Iteration 6318, loss = 0.00352078\n",
      "Iteration 6319, loss = 0.00352004\n",
      "Iteration 6320, loss = 0.00351915\n",
      "Iteration 6321, loss = 0.00351835\n",
      "Iteration 6322, loss = 0.00351755\n",
      "Iteration 6323, loss = 0.00351676\n",
      "Iteration 6324, loss = 0.00351586\n",
      "Iteration 6325, loss = 0.00351529\n",
      "Iteration 6326, loss = 0.00351419\n",
      "Iteration 6327, loss = 0.00351340\n",
      "Iteration 6328, loss = 0.00351259\n",
      "Iteration 6329, loss = 0.00351180\n",
      "Iteration 6330, loss = 0.00351116\n",
      "Iteration 6331, loss = 0.00351007\n",
      "Iteration 6332, loss = 0.00350924\n",
      "Iteration 6333, loss = 0.00350848\n",
      "Iteration 6334, loss = 0.00350768\n",
      "Iteration 6335, loss = 0.00350687\n",
      "Iteration 6336, loss = 0.00350614\n",
      "Iteration 6337, loss = 0.00350541\n",
      "Iteration 6338, loss = 0.00350466\n",
      "Iteration 6339, loss = 0.00350398\n",
      "Iteration 6340, loss = 0.00350319\n",
      "Iteration 6341, loss = 0.00350249\n",
      "Iteration 6342, loss = 0.00350184\n",
      "Iteration 6343, loss = 0.00350104\n",
      "Iteration 6344, loss = 0.00350029\n",
      "Iteration 6345, loss = 0.00349942\n",
      "Iteration 6346, loss = 0.00349905\n",
      "Iteration 6347, loss = 0.00349790\n",
      "Iteration 6348, loss = 0.00349713\n",
      "Iteration 6349, loss = 0.00349643\n",
      "Iteration 6350, loss = 0.00349599\n",
      "Iteration 6351, loss = 0.00349505\n",
      "Iteration 6352, loss = 0.00349426\n",
      "Iteration 6353, loss = 0.00349348\n",
      "Iteration 6354, loss = 0.00349279\n",
      "Iteration 6355, loss = 0.00349204\n",
      "Iteration 6356, loss = 0.00349133\n",
      "Iteration 6357, loss = 0.00349048\n",
      "Iteration 6358, loss = 0.00348967\n",
      "Iteration 6359, loss = 0.00348888\n",
      "Iteration 6360, loss = 0.00348801\n",
      "Iteration 6361, loss = 0.00348729\n",
      "Iteration 6362, loss = 0.00348651\n",
      "Iteration 6363, loss = 0.00348578\n",
      "Iteration 6364, loss = 0.00348498\n",
      "Iteration 6365, loss = 0.00348460\n",
      "Iteration 6366, loss = 0.00348327\n",
      "Iteration 6367, loss = 0.00348255\n",
      "Iteration 6368, loss = 0.00348162\n",
      "Iteration 6369, loss = 0.00348081\n",
      "Iteration 6370, loss = 0.00348047\n",
      "Iteration 6371, loss = 0.00347992\n",
      "Iteration 6372, loss = 0.00347878\n",
      "Iteration 6373, loss = 0.00347817\n",
      "Iteration 6374, loss = 0.00347751\n",
      "Iteration 6375, loss = 0.00347696\n",
      "Iteration 6376, loss = 0.00347598\n",
      "Iteration 6377, loss = 0.00347530\n",
      "Iteration 6378, loss = 0.00347441\n",
      "Iteration 6379, loss = 0.00347362\n",
      "Iteration 6380, loss = 0.00347278\n",
      "Iteration 6381, loss = 0.00347211\n",
      "Iteration 6382, loss = 0.00347126\n",
      "Iteration 6383, loss = 0.00347044\n",
      "Iteration 6384, loss = 0.00346970\n",
      "Iteration 6385, loss = 0.00346893\n",
      "Iteration 6386, loss = 0.00346836\n",
      "Iteration 6387, loss = 0.00346735\n",
      "Iteration 6388, loss = 0.00346661\n",
      "Iteration 6389, loss = 0.00346566\n",
      "Iteration 6390, loss = 0.00346496\n",
      "Iteration 6391, loss = 0.00346407\n",
      "Iteration 6392, loss = 0.00346334\n",
      "Iteration 6393, loss = 0.00346239\n",
      "Iteration 6394, loss = 0.00346155\n",
      "Iteration 6395, loss = 0.00346084\n",
      "Iteration 6396, loss = 0.00346006\n",
      "Iteration 6397, loss = 0.00345916\n",
      "Iteration 6398, loss = 0.00345874\n",
      "Iteration 6399, loss = 0.00345789\n",
      "Iteration 6400, loss = 0.00345715\n",
      "Iteration 6401, loss = 0.00345642\n",
      "Iteration 6402, loss = 0.00345568\n",
      "Iteration 6403, loss = 0.00345490\n",
      "Iteration 6404, loss = 0.00345419\n",
      "Iteration 6405, loss = 0.00345372\n",
      "Iteration 6406, loss = 0.00345296\n",
      "Iteration 6407, loss = 0.00345227\n",
      "Iteration 6408, loss = 0.00345162\n",
      "Iteration 6409, loss = 0.00345103\n",
      "Iteration 6410, loss = 0.00345046\n",
      "Iteration 6411, loss = 0.00344966\n",
      "Iteration 6412, loss = 0.00344895\n",
      "Iteration 6413, loss = 0.00344829\n",
      "Iteration 6414, loss = 0.00344761\n",
      "Iteration 6415, loss = 0.00344727\n",
      "Iteration 6416, loss = 0.00344647\n",
      "Iteration 6417, loss = 0.00344572\n",
      "Iteration 6418, loss = 0.00344494\n",
      "Iteration 6419, loss = 0.00344464\n",
      "Iteration 6420, loss = 0.00344364\n",
      "Iteration 6421, loss = 0.00344288\n",
      "Iteration 6422, loss = 0.00344202\n",
      "Iteration 6423, loss = 0.00344123\n",
      "Iteration 6424, loss = 0.00344043\n",
      "Iteration 6425, loss = 0.00343957\n",
      "Iteration 6426, loss = 0.00343891\n",
      "Iteration 6427, loss = 0.00343801\n",
      "Iteration 6428, loss = 0.00343713\n",
      "Iteration 6429, loss = 0.00343664\n",
      "Iteration 6430, loss = 0.00343579\n",
      "Iteration 6431, loss = 0.00343512\n",
      "Iteration 6432, loss = 0.00343422\n",
      "Iteration 6433, loss = 0.00343324\n",
      "Iteration 6434, loss = 0.00343258\n",
      "Iteration 6435, loss = 0.00343182\n",
      "Iteration 6436, loss = 0.00343121\n",
      "Iteration 6437, loss = 0.00342987\n",
      "Iteration 6438, loss = 0.00342908\n",
      "Iteration 6439, loss = 0.00342798\n",
      "Iteration 6440, loss = 0.00342719\n",
      "Iteration 6441, loss = 0.00342648\n",
      "Iteration 6442, loss = 0.00342555\n",
      "Iteration 6443, loss = 0.00342451\n",
      "Iteration 6444, loss = 0.00342364\n",
      "Iteration 6445, loss = 0.00342265\n",
      "Iteration 6446, loss = 0.00342256\n",
      "Iteration 6447, loss = 0.00342135\n",
      "Iteration 6448, loss = 0.00342038\n",
      "Iteration 6449, loss = 0.00341993\n",
      "Iteration 6450, loss = 0.00341900\n",
      "Iteration 6451, loss = 0.00341817\n",
      "Iteration 6452, loss = 0.00341746\n",
      "Iteration 6453, loss = 0.00341675\n",
      "Iteration 6454, loss = 0.00341607\n",
      "Iteration 6455, loss = 0.00341543\n",
      "Iteration 6456, loss = 0.00341486\n",
      "Iteration 6457, loss = 0.00341412\n",
      "Iteration 6458, loss = 0.00341350\n",
      "Iteration 6459, loss = 0.00341288\n",
      "Iteration 6460, loss = 0.00341216\n",
      "Iteration 6461, loss = 0.00341160\n",
      "Iteration 6462, loss = 0.00341081\n",
      "Iteration 6463, loss = 0.00341005\n",
      "Iteration 6464, loss = 0.00340932\n",
      "Iteration 6465, loss = 0.00340873\n",
      "Iteration 6466, loss = 0.00340790\n",
      "Iteration 6467, loss = 0.00340794\n",
      "Iteration 6468, loss = 0.00340660\n",
      "Iteration 6469, loss = 0.00340591\n",
      "Iteration 6470, loss = 0.00340517\n",
      "Iteration 6471, loss = 0.00340449\n",
      "Iteration 6472, loss = 0.00340371\n",
      "Iteration 6473, loss = 0.00340327\n",
      "Iteration 6474, loss = 0.00340220\n",
      "Iteration 6475, loss = 0.00340162\n",
      "Iteration 6476, loss = 0.00340098\n",
      "Iteration 6477, loss = 0.00340021\n",
      "Iteration 6478, loss = 0.00339949\n",
      "Iteration 6479, loss = 0.00339874\n",
      "Iteration 6480, loss = 0.00339795\n",
      "Iteration 6481, loss = 0.00339717\n",
      "Iteration 6482, loss = 0.00339664\n",
      "Iteration 6483, loss = 0.00339596\n",
      "Iteration 6484, loss = 0.00339550\n",
      "Iteration 6485, loss = 0.00339458\n",
      "Iteration 6486, loss = 0.00339391\n",
      "Iteration 6487, loss = 0.00339319\n",
      "Iteration 6488, loss = 0.00339238\n",
      "Iteration 6489, loss = 0.00339191\n",
      "Iteration 6490, loss = 0.00339093\n",
      "Iteration 6491, loss = 0.00339005\n",
      "Iteration 6492, loss = 0.00338918\n",
      "Iteration 6493, loss = 0.00338833\n",
      "Iteration 6494, loss = 0.00338794\n",
      "Iteration 6495, loss = 0.00338696\n",
      "Iteration 6496, loss = 0.00338610\n",
      "Iteration 6497, loss = 0.00338574\n",
      "Iteration 6498, loss = 0.00338480\n",
      "Iteration 6499, loss = 0.00338389\n",
      "Iteration 6500, loss = 0.00338298\n",
      "Iteration 6501, loss = 0.00338270\n",
      "Iteration 6502, loss = 0.00338173\n",
      "Iteration 6503, loss = 0.00338102\n",
      "Iteration 6504, loss = 0.00338028\n",
      "Iteration 6505, loss = 0.00337961\n",
      "Iteration 6506, loss = 0.00337887\n",
      "Iteration 6507, loss = 0.00337834\n",
      "Iteration 6508, loss = 0.00337769\n",
      "Iteration 6509, loss = 0.00337686\n",
      "Iteration 6510, loss = 0.00337611\n",
      "Iteration 6511, loss = 0.00337563\n",
      "Iteration 6512, loss = 0.00337481\n",
      "Iteration 6513, loss = 0.00337422\n",
      "Iteration 6514, loss = 0.00337354\n",
      "Iteration 6515, loss = 0.00337286\n",
      "Iteration 6516, loss = 0.00337223\n",
      "Iteration 6517, loss = 0.00337158\n",
      "Iteration 6518, loss = 0.00337081\n",
      "Iteration 6519, loss = 0.00337018\n",
      "Iteration 6520, loss = 0.00336948\n",
      "Iteration 6521, loss = 0.00336867\n",
      "Iteration 6522, loss = 0.00336813\n",
      "Iteration 6523, loss = 0.00336739\n",
      "Iteration 6524, loss = 0.00336643\n",
      "Iteration 6525, loss = 0.00336565\n",
      "Iteration 6526, loss = 0.00336499\n",
      "Iteration 6527, loss = 0.00336414\n",
      "Iteration 6528, loss = 0.00336351\n",
      "Iteration 6529, loss = 0.00336272\n",
      "Iteration 6530, loss = 0.00336233\n",
      "Iteration 6531, loss = 0.00336130\n",
      "Iteration 6532, loss = 0.00336046\n",
      "Iteration 6533, loss = 0.00335974\n",
      "Iteration 6534, loss = 0.00335896\n",
      "Iteration 6535, loss = 0.00335824\n",
      "Iteration 6536, loss = 0.00335769\n",
      "Iteration 6537, loss = 0.00335692\n",
      "Iteration 6538, loss = 0.00335608\n",
      "Iteration 6539, loss = 0.00335532\n",
      "Iteration 6540, loss = 0.00335463\n",
      "Iteration 6541, loss = 0.00335395\n",
      "Iteration 6542, loss = 0.00335335\n",
      "Iteration 6543, loss = 0.00335256\n",
      "Iteration 6544, loss = 0.00335186\n",
      "Iteration 6545, loss = 0.00335113\n",
      "Iteration 6546, loss = 0.00335058\n",
      "Iteration 6547, loss = 0.00334966\n",
      "Iteration 6548, loss = 0.00334893\n",
      "Iteration 6549, loss = 0.00334819\n",
      "Iteration 6550, loss = 0.00334745\n",
      "Iteration 6551, loss = 0.00334672\n",
      "Iteration 6552, loss = 0.00334599\n",
      "Iteration 6553, loss = 0.00334513\n",
      "Iteration 6554, loss = 0.00334432\n",
      "Iteration 6555, loss = 0.00334356\n",
      "Iteration 6556, loss = 0.00334315\n",
      "Iteration 6557, loss = 0.00334206\n",
      "Iteration 6558, loss = 0.00334137\n",
      "Iteration 6559, loss = 0.00334079\n",
      "Iteration 6560, loss = 0.00333992\n",
      "Iteration 6561, loss = 0.00333913\n",
      "Iteration 6562, loss = 0.00333849\n",
      "Iteration 6563, loss = 0.00333763\n",
      "Iteration 6564, loss = 0.00333754\n",
      "Iteration 6565, loss = 0.00333633\n",
      "Iteration 6566, loss = 0.00333557\n",
      "Iteration 6567, loss = 0.00333501\n",
      "Iteration 6568, loss = 0.00333412\n",
      "Iteration 6569, loss = 0.00333342\n",
      "Iteration 6570, loss = 0.00333273\n",
      "Iteration 6571, loss = 0.00333203\n",
      "Iteration 6572, loss = 0.00333143\n",
      "Iteration 6573, loss = 0.00333075\n",
      "Iteration 6574, loss = 0.00332995\n",
      "Iteration 6575, loss = 0.00332926\n",
      "Iteration 6576, loss = 0.00332853\n",
      "Iteration 6577, loss = 0.00332816\n",
      "Iteration 6578, loss = 0.00332717\n",
      "Iteration 6579, loss = 0.00332649\n",
      "Iteration 6580, loss = 0.00332579\n",
      "Iteration 6581, loss = 0.00332510\n",
      "Iteration 6582, loss = 0.00332439\n",
      "Iteration 6583, loss = 0.00332380\n",
      "Iteration 6584, loss = 0.00332310\n",
      "Iteration 6585, loss = 0.00332233\n",
      "Iteration 6586, loss = 0.00332155\n",
      "Iteration 6587, loss = 0.00332085\n",
      "Iteration 6588, loss = 0.00332032\n",
      "Iteration 6589, loss = 0.00331951\n",
      "Iteration 6590, loss = 0.00331877\n",
      "Iteration 6591, loss = 0.00331818\n",
      "Iteration 6592, loss = 0.00331736\n",
      "Iteration 6593, loss = 0.00331686\n",
      "Iteration 6594, loss = 0.00331609\n",
      "Iteration 6595, loss = 0.00331530\n",
      "Iteration 6596, loss = 0.00331469\n",
      "Iteration 6597, loss = 0.00331413\n",
      "Iteration 6598, loss = 0.00331342\n",
      "Iteration 6599, loss = 0.00331235\n",
      "Iteration 6600, loss = 0.00331183\n",
      "Iteration 6601, loss = 0.00331094\n",
      "Iteration 6602, loss = 0.00331011\n",
      "Iteration 6603, loss = 0.00330922\n",
      "Iteration 6604, loss = 0.00330850\n",
      "Iteration 6605, loss = 0.00330779\n",
      "Iteration 6606, loss = 0.00330705\n",
      "Iteration 6607, loss = 0.00330650\n",
      "Iteration 6608, loss = 0.00330571\n",
      "Iteration 6609, loss = 0.00330517\n",
      "Iteration 6610, loss = 0.00330433\n",
      "Iteration 6611, loss = 0.00330367\n",
      "Iteration 6612, loss = 0.00330320\n",
      "Iteration 6613, loss = 0.00330226\n",
      "Iteration 6614, loss = 0.00330161\n",
      "Iteration 6615, loss = 0.00330083\n",
      "Iteration 6616, loss = 0.00330006\n",
      "Iteration 6617, loss = 0.00329938\n",
      "Iteration 6618, loss = 0.00329871\n",
      "Iteration 6619, loss = 0.00329818\n",
      "Iteration 6620, loss = 0.00329720\n",
      "Iteration 6621, loss = 0.00329657\n",
      "Iteration 6622, loss = 0.00329576\n",
      "Iteration 6623, loss = 0.00329506\n",
      "Iteration 6624, loss = 0.00329427\n",
      "Iteration 6625, loss = 0.00329347\n",
      "Iteration 6626, loss = 0.00329291\n",
      "Iteration 6627, loss = 0.00329219\n",
      "Iteration 6628, loss = 0.00329139\n",
      "Iteration 6629, loss = 0.00329065\n",
      "Iteration 6630, loss = 0.00329000\n",
      "Iteration 6631, loss = 0.00328924\n",
      "Iteration 6632, loss = 0.00328898\n",
      "Iteration 6633, loss = 0.00328779\n",
      "Iteration 6634, loss = 0.00328700\n",
      "Iteration 6635, loss = 0.00328643\n",
      "Iteration 6636, loss = 0.00328561\n",
      "Iteration 6637, loss = 0.00328520\n",
      "Iteration 6638, loss = 0.00328427\n",
      "Iteration 6639, loss = 0.00328357\n",
      "Iteration 6640, loss = 0.00328277\n",
      "Iteration 6641, loss = 0.00328213\n",
      "Iteration 6642, loss = 0.00328152\n",
      "Iteration 6643, loss = 0.00328072\n",
      "Iteration 6644, loss = 0.00328016\n",
      "Iteration 6645, loss = 0.00327959\n",
      "Iteration 6646, loss = 0.00327878\n",
      "Iteration 6647, loss = 0.00327810\n",
      "Iteration 6648, loss = 0.00327757\n",
      "Iteration 6649, loss = 0.00327679\n",
      "Iteration 6650, loss = 0.00327612\n",
      "Iteration 6651, loss = 0.00327554\n",
      "Iteration 6652, loss = 0.00327486\n",
      "Iteration 6653, loss = 0.00327415\n",
      "Iteration 6654, loss = 0.00327350\n",
      "Iteration 6655, loss = 0.00327271\n",
      "Iteration 6656, loss = 0.00327207\n",
      "Iteration 6657, loss = 0.00327162\n",
      "Iteration 6658, loss = 0.00327081\n",
      "Iteration 6659, loss = 0.00327007\n",
      "Iteration 6660, loss = 0.00326939\n",
      "Iteration 6661, loss = 0.00326871\n",
      "Iteration 6662, loss = 0.00326794\n",
      "Iteration 6663, loss = 0.00326728\n",
      "Iteration 6664, loss = 0.00326656\n",
      "Iteration 6665, loss = 0.00326593\n",
      "Iteration 6666, loss = 0.00326507\n",
      "Iteration 6667, loss = 0.00326448\n",
      "Iteration 6668, loss = 0.00326376\n",
      "Iteration 6669, loss = 0.00326314\n",
      "Iteration 6670, loss = 0.00326238\n",
      "Iteration 6671, loss = 0.00326171\n",
      "Iteration 6672, loss = 0.00326105\n",
      "Iteration 6673, loss = 0.00326034\n",
      "Iteration 6674, loss = 0.00325971\n",
      "Iteration 6675, loss = 0.00325903\n",
      "Iteration 6676, loss = 0.00325831\n",
      "Iteration 6677, loss = 0.00325757\n",
      "Iteration 6678, loss = 0.00325705\n",
      "Iteration 6679, loss = 0.00325625\n",
      "Iteration 6680, loss = 0.00325554\n",
      "Iteration 6681, loss = 0.00325492\n",
      "Iteration 6682, loss = 0.00325411\n",
      "Iteration 6683, loss = 0.00325345\n",
      "Iteration 6684, loss = 0.00325280\n",
      "Iteration 6685, loss = 0.00325213\n",
      "Iteration 6686, loss = 0.00325147\n",
      "Iteration 6687, loss = 0.00325120\n",
      "Iteration 6688, loss = 0.00325018\n",
      "Iteration 6689, loss = 0.00324961\n",
      "Iteration 6690, loss = 0.00324895\n",
      "Iteration 6691, loss = 0.00324825\n",
      "Iteration 6692, loss = 0.00324776\n",
      "Iteration 6693, loss = 0.00324707\n",
      "Iteration 6694, loss = 0.00324641\n",
      "Iteration 6695, loss = 0.00324571\n",
      "Iteration 6696, loss = 0.00324509\n",
      "Iteration 6697, loss = 0.00324450\n",
      "Iteration 6698, loss = 0.00324382\n",
      "Iteration 6699, loss = 0.00324333\n",
      "Iteration 6700, loss = 0.00324242\n",
      "Iteration 6701, loss = 0.00324166\n",
      "Iteration 6702, loss = 0.00324103\n",
      "Iteration 6703, loss = 0.00324028\n",
      "Iteration 6704, loss = 0.00323962\n",
      "Iteration 6705, loss = 0.00323885\n",
      "Iteration 6706, loss = 0.00323812\n",
      "Iteration 6707, loss = 0.00323748\n",
      "Iteration 6708, loss = 0.00323673\n",
      "Iteration 6709, loss = 0.00323606\n",
      "Iteration 6710, loss = 0.00323532\n",
      "Iteration 6711, loss = 0.00323491\n",
      "Iteration 6712, loss = 0.00323390\n",
      "Iteration 6713, loss = 0.00323318\n",
      "Iteration 6714, loss = 0.00323254\n",
      "Iteration 6715, loss = 0.00323191\n",
      "Iteration 6716, loss = 0.00323131\n",
      "Iteration 6717, loss = 0.00323057\n",
      "Iteration 6718, loss = 0.00322993\n",
      "Iteration 6719, loss = 0.00322926\n",
      "Iteration 6720, loss = 0.00322867\n",
      "Iteration 6721, loss = 0.00322787\n",
      "Iteration 6722, loss = 0.00322718\n",
      "Iteration 6723, loss = 0.00322655\n",
      "Iteration 6724, loss = 0.00322576\n",
      "Iteration 6725, loss = 0.00322512\n",
      "Iteration 6726, loss = 0.00322441\n",
      "Iteration 6727, loss = 0.00322376\n",
      "Iteration 6728, loss = 0.00322300\n",
      "Iteration 6729, loss = 0.00322265\n",
      "Iteration 6730, loss = 0.00322166\n",
      "Iteration 6731, loss = 0.00322117\n",
      "Iteration 6732, loss = 0.00322037\n",
      "Iteration 6733, loss = 0.00321971\n",
      "Iteration 6734, loss = 0.00321884\n",
      "Iteration 6735, loss = 0.00321819\n",
      "Iteration 6736, loss = 0.00321738\n",
      "Iteration 6737, loss = 0.00321685\n",
      "Iteration 6738, loss = 0.00321605\n",
      "Iteration 6739, loss = 0.00321536\n",
      "Iteration 6740, loss = 0.00321470\n",
      "Iteration 6741, loss = 0.00321401\n",
      "Iteration 6742, loss = 0.00321333\n",
      "Iteration 6743, loss = 0.00321271\n",
      "Iteration 6744, loss = 0.00321207\n",
      "Iteration 6745, loss = 0.00321137\n",
      "Iteration 6746, loss = 0.00321084\n",
      "Iteration 6747, loss = 0.00321016\n",
      "Iteration 6748, loss = 0.00320958\n",
      "Iteration 6749, loss = 0.00320931\n",
      "Iteration 6750, loss = 0.00320805\n",
      "Iteration 6751, loss = 0.00320720\n",
      "Iteration 6752, loss = 0.00320679\n",
      "Iteration 6753, loss = 0.00320608\n",
      "Iteration 6754, loss = 0.00320521\n",
      "Iteration 6755, loss = 0.00320454\n",
      "Iteration 6756, loss = 0.00320397\n",
      "Iteration 6757, loss = 0.00320325\n",
      "Iteration 6758, loss = 0.00320264\n",
      "Iteration 6759, loss = 0.00320199\n",
      "Iteration 6760, loss = 0.00320136\n",
      "Iteration 6761, loss = 0.00320077\n",
      "Iteration 6762, loss = 0.00320014\n",
      "Iteration 6763, loss = 0.00319958\n",
      "Iteration 6764, loss = 0.00319875\n",
      "Iteration 6765, loss = 0.00319820\n",
      "Iteration 6766, loss = 0.00319751\n",
      "Iteration 6767, loss = 0.00319688\n",
      "Iteration 6768, loss = 0.00319612\n",
      "Iteration 6769, loss = 0.00319564\n",
      "Iteration 6770, loss = 0.00319491\n",
      "Iteration 6771, loss = 0.00319456\n",
      "Iteration 6772, loss = 0.00319364\n",
      "Iteration 6773, loss = 0.00319295\n",
      "Iteration 6774, loss = 0.00319231\n",
      "Iteration 6775, loss = 0.00319166\n",
      "Iteration 6776, loss = 0.00319102\n",
      "Iteration 6777, loss = 0.00319032\n",
      "Iteration 6778, loss = 0.00318972\n",
      "Iteration 6779, loss = 0.00318906\n",
      "Iteration 6780, loss = 0.00318839\n",
      "Iteration 6781, loss = 0.00318778\n",
      "Iteration 6782, loss = 0.00318709\n",
      "Iteration 6783, loss = 0.00318641\n",
      "Iteration 6784, loss = 0.00318593\n",
      "Iteration 6785, loss = 0.00318538\n",
      "Iteration 6786, loss = 0.00318456\n",
      "Iteration 6787, loss = 0.00318387\n",
      "Iteration 6788, loss = 0.00318359\n",
      "Iteration 6789, loss = 0.00318272\n",
      "Iteration 6790, loss = 0.00318227\n",
      "Iteration 6791, loss = 0.00318120\n",
      "Iteration 6792, loss = 0.00318059\n",
      "Iteration 6793, loss = 0.00317995\n",
      "Iteration 6794, loss = 0.00317955\n",
      "Iteration 6795, loss = 0.00317869\n",
      "Iteration 6796, loss = 0.00317796\n",
      "Iteration 6797, loss = 0.00317732\n",
      "Iteration 6798, loss = 0.00317674\n",
      "Iteration 6799, loss = 0.00317607\n",
      "Iteration 6800, loss = 0.00317541\n",
      "Iteration 6801, loss = 0.00317477\n",
      "Iteration 6802, loss = 0.00317413\n",
      "Iteration 6803, loss = 0.00317342\n",
      "Iteration 6804, loss = 0.00317278\n",
      "Iteration 6805, loss = 0.00317222\n",
      "Iteration 6806, loss = 0.00317169\n",
      "Iteration 6807, loss = 0.00317095\n",
      "Iteration 6808, loss = 0.00317049\n",
      "Iteration 6809, loss = 0.00316984\n",
      "Iteration 6810, loss = 0.00316901\n",
      "Iteration 6811, loss = 0.00316846\n",
      "Iteration 6812, loss = 0.00316784\n",
      "Iteration 6813, loss = 0.00316705\n",
      "Iteration 6814, loss = 0.00316642\n",
      "Iteration 6815, loss = 0.00316569\n",
      "Iteration 6816, loss = 0.00316500\n",
      "Iteration 6817, loss = 0.00316438\n",
      "Iteration 6818, loss = 0.00316360\n",
      "Iteration 6819, loss = 0.00316302\n",
      "Iteration 6820, loss = 0.00316244\n",
      "Iteration 6821, loss = 0.00316144\n",
      "Iteration 6822, loss = 0.00316075\n",
      "Iteration 6823, loss = 0.00316005\n",
      "Iteration 6824, loss = 0.00315948\n",
      "Iteration 6825, loss = 0.00315882\n",
      "Iteration 6826, loss = 0.00315811\n",
      "Iteration 6827, loss = 0.00315736\n",
      "Iteration 6828, loss = 0.00315669\n",
      "Iteration 6829, loss = 0.00315595\n",
      "Iteration 6830, loss = 0.00315515\n",
      "Iteration 6831, loss = 0.00315493\n",
      "Iteration 6832, loss = 0.00315388\n",
      "Iteration 6833, loss = 0.00315303\n",
      "Iteration 6834, loss = 0.00315230\n",
      "Iteration 6835, loss = 0.00315145\n",
      "Iteration 6836, loss = 0.00315082\n",
      "Iteration 6837, loss = 0.00314999\n",
      "Iteration 6838, loss = 0.00314923\n",
      "Iteration 6839, loss = 0.00314856\n",
      "Iteration 6840, loss = 0.00314794\n",
      "Iteration 6841, loss = 0.00314740\n",
      "Iteration 6842, loss = 0.00314647\n",
      "Iteration 6843, loss = 0.00314572\n",
      "Iteration 6844, loss = 0.00314525\n",
      "Iteration 6845, loss = 0.00314429\n",
      "Iteration 6846, loss = 0.00314382\n",
      "Iteration 6847, loss = 0.00314282\n",
      "Iteration 6848, loss = 0.00314225\n",
      "Iteration 6849, loss = 0.00314146\n",
      "Iteration 6850, loss = 0.00314064\n",
      "Iteration 6851, loss = 0.00313999\n",
      "Iteration 6852, loss = 0.00313923\n",
      "Iteration 6853, loss = 0.00313856\n",
      "Iteration 6854, loss = 0.00313791\n",
      "Iteration 6855, loss = 0.00313720\n",
      "Iteration 6856, loss = 0.00313649\n",
      "Iteration 6857, loss = 0.00313579\n",
      "Iteration 6858, loss = 0.00313520\n",
      "Iteration 6859, loss = 0.00313449\n",
      "Iteration 6860, loss = 0.00313384\n",
      "Iteration 6861, loss = 0.00313313\n",
      "Iteration 6862, loss = 0.00313265\n",
      "Iteration 6863, loss = 0.00313183\n",
      "Iteration 6864, loss = 0.00313104\n",
      "Iteration 6865, loss = 0.00313033\n",
      "Iteration 6866, loss = 0.00312972\n",
      "Iteration 6867, loss = 0.00312900\n",
      "Iteration 6868, loss = 0.00312843\n",
      "Iteration 6869, loss = 0.00312783\n",
      "Iteration 6870, loss = 0.00312713\n",
      "Iteration 6871, loss = 0.00312653\n",
      "Iteration 6872, loss = 0.00312613\n",
      "Iteration 6873, loss = 0.00312536\n",
      "Iteration 6874, loss = 0.00312474\n",
      "Iteration 6875, loss = 0.00312424\n",
      "Iteration 6876, loss = 0.00312370\n",
      "Iteration 6877, loss = 0.00312308\n",
      "Iteration 6878, loss = 0.00312250\n",
      "Iteration 6879, loss = 0.00312193\n",
      "Iteration 6880, loss = 0.00312139\n",
      "Iteration 6881, loss = 0.00312104\n",
      "Iteration 6882, loss = 0.00312028\n",
      "Iteration 6883, loss = 0.00311973\n",
      "Iteration 6884, loss = 0.00311910\n",
      "Iteration 6885, loss = 0.00311855\n",
      "Iteration 6886, loss = 0.00311799\n",
      "Iteration 6887, loss = 0.00311747\n",
      "Iteration 6888, loss = 0.00311669\n",
      "Iteration 6889, loss = 0.00311609\n",
      "Iteration 6890, loss = 0.00311555\n",
      "Iteration 6891, loss = 0.00311474\n",
      "Iteration 6892, loss = 0.00311408\n",
      "Iteration 6893, loss = 0.00311358\n",
      "Iteration 6894, loss = 0.00311293\n",
      "Iteration 6895, loss = 0.00311218\n",
      "Iteration 6896, loss = 0.00311161\n",
      "Iteration 6897, loss = 0.00311112\n",
      "Iteration 6898, loss = 0.00311030\n",
      "Iteration 6899, loss = 0.00310966\n",
      "Iteration 6900, loss = 0.00310889\n",
      "Iteration 6901, loss = 0.00310825\n",
      "Iteration 6902, loss = 0.00310789\n",
      "Iteration 6903, loss = 0.00310725\n",
      "Iteration 6904, loss = 0.00310645\n",
      "Iteration 6905, loss = 0.00310570\n",
      "Iteration 6906, loss = 0.00310498\n",
      "Iteration 6907, loss = 0.00310454\n",
      "Iteration 6908, loss = 0.00310373\n",
      "Iteration 6909, loss = 0.00310313\n",
      "Iteration 6910, loss = 0.00310261\n",
      "Iteration 6911, loss = 0.00310183\n",
      "Iteration 6912, loss = 0.00310107\n",
      "Iteration 6913, loss = 0.00310045\n",
      "Iteration 6914, loss = 0.00309981\n",
      "Iteration 6915, loss = 0.00309926\n",
      "Iteration 6916, loss = 0.00309848\n",
      "Iteration 6917, loss = 0.00309806\n",
      "Iteration 6918, loss = 0.00309734\n",
      "Iteration 6919, loss = 0.00309658\n",
      "Iteration 6920, loss = 0.00309598\n",
      "Iteration 6921, loss = 0.00309533\n",
      "Iteration 6922, loss = 0.00309466\n",
      "Iteration 6923, loss = 0.00309396\n",
      "Iteration 6924, loss = 0.00309338\n",
      "Iteration 6925, loss = 0.00309270\n",
      "Iteration 6926, loss = 0.00309201\n",
      "Iteration 6927, loss = 0.00309134\n",
      "Iteration 6928, loss = 0.00309090\n",
      "Iteration 6929, loss = 0.00308998\n",
      "Iteration 6930, loss = 0.00308948\n",
      "Iteration 6931, loss = 0.00308872\n",
      "Iteration 6932, loss = 0.00308814\n",
      "Iteration 6933, loss = 0.00308753\n",
      "Iteration 6934, loss = 0.00308692\n",
      "Iteration 6935, loss = 0.00308634\n",
      "Iteration 6936, loss = 0.00308567\n",
      "Iteration 6937, loss = 0.00308508\n",
      "Iteration 6938, loss = 0.00308449\n",
      "Iteration 6939, loss = 0.00308386\n",
      "Iteration 6940, loss = 0.00308315\n",
      "Iteration 6941, loss = 0.00308264\n",
      "Iteration 6942, loss = 0.00308204\n",
      "Iteration 6943, loss = 0.00308156\n",
      "Iteration 6944, loss = 0.00308106\n",
      "Iteration 6945, loss = 0.00308038\n",
      "Iteration 6946, loss = 0.00308010\n",
      "Iteration 6947, loss = 0.00307929\n",
      "Iteration 6948, loss = 0.00307858\n",
      "Iteration 6949, loss = 0.00307798\n",
      "Iteration 6950, loss = 0.00307756\n",
      "Iteration 6951, loss = 0.00307686\n",
      "Iteration 6952, loss = 0.00307639\n",
      "Iteration 6953, loss = 0.00307574\n",
      "Iteration 6954, loss = 0.00307511\n",
      "Iteration 6955, loss = 0.00307454\n",
      "Iteration 6956, loss = 0.00307399\n",
      "Iteration 6957, loss = 0.00307338\n",
      "Iteration 6958, loss = 0.00307286\n",
      "Iteration 6959, loss = 0.00307231\n",
      "Iteration 6960, loss = 0.00307178\n",
      "Iteration 6961, loss = 0.00307119\n",
      "Iteration 6962, loss = 0.00307064\n",
      "Iteration 6963, loss = 0.00307005\n",
      "Iteration 6964, loss = 0.00306946\n",
      "Iteration 6965, loss = 0.00306893\n",
      "Iteration 6966, loss = 0.00306836\n",
      "Iteration 6967, loss = 0.00306773\n",
      "Iteration 6968, loss = 0.00306719\n",
      "Iteration 6969, loss = 0.00306710\n",
      "Iteration 6970, loss = 0.00306639\n",
      "Iteration 6971, loss = 0.00306565\n",
      "Iteration 6972, loss = 0.00306504\n",
      "Iteration 6973, loss = 0.00306445\n",
      "Iteration 6974, loss = 0.00306402\n",
      "Iteration 6975, loss = 0.00306330\n",
      "Iteration 6976, loss = 0.00306270\n",
      "Iteration 6977, loss = 0.00306209\n",
      "Iteration 6978, loss = 0.00306143\n",
      "Iteration 6979, loss = 0.00306077\n",
      "Iteration 6980, loss = 0.00306027\n",
      "Iteration 6981, loss = 0.00305949\n",
      "Iteration 6982, loss = 0.00305885\n",
      "Iteration 6983, loss = 0.00305843\n",
      "Iteration 6984, loss = 0.00305766\n",
      "Iteration 6985, loss = 0.00305704\n",
      "Iteration 6986, loss = 0.00305622\n",
      "Iteration 6987, loss = 0.00305578\n",
      "Iteration 6988, loss = 0.00305469\n",
      "Iteration 6989, loss = 0.00305403\n",
      "Iteration 6990, loss = 0.00305348\n",
      "Iteration 6991, loss = 0.00305270\n",
      "Iteration 6992, loss = 0.00305196\n",
      "Iteration 6993, loss = 0.00305137\n",
      "Iteration 6994, loss = 0.00305056\n",
      "Iteration 6995, loss = 0.00304999\n",
      "Iteration 6996, loss = 0.00304921\n",
      "Iteration 6997, loss = 0.00304863\n",
      "Iteration 6998, loss = 0.00304817\n",
      "Iteration 6999, loss = 0.00304736\n",
      "Iteration 7000, loss = 0.00304679\n",
      "Iteration 7001, loss = 0.00304621\n",
      "Iteration 7002, loss = 0.00304556\n",
      "Iteration 7003, loss = 0.00304489\n",
      "Iteration 7004, loss = 0.00304435\n",
      "Iteration 7005, loss = 0.00304381\n",
      "Iteration 7006, loss = 0.00304278\n",
      "Iteration 7007, loss = 0.00304247\n",
      "Iteration 7008, loss = 0.00304159\n",
      "Iteration 7009, loss = 0.00304120\n",
      "Iteration 7010, loss = 0.00304030\n",
      "Iteration 7011, loss = 0.00303991\n",
      "Iteration 7012, loss = 0.00303911\n",
      "Iteration 7013, loss = 0.00303860\n",
      "Iteration 7014, loss = 0.00303795\n",
      "Iteration 7015, loss = 0.00303737\n",
      "Iteration 7016, loss = 0.00303694\n",
      "Iteration 7017, loss = 0.00303636\n",
      "Iteration 7018, loss = 0.00303579\n",
      "Iteration 7019, loss = 0.00303523\n",
      "Iteration 7020, loss = 0.00303473\n",
      "Iteration 7021, loss = 0.00303419\n",
      "Iteration 7022, loss = 0.00303370\n",
      "Iteration 7023, loss = 0.00303314\n",
      "Iteration 7024, loss = 0.00303257\n",
      "Iteration 7025, loss = 0.00303208\n",
      "Iteration 7026, loss = 0.00303150\n",
      "Iteration 7027, loss = 0.00303097\n",
      "Iteration 7028, loss = 0.00303050\n",
      "Iteration 7029, loss = 0.00302994\n",
      "Iteration 7030, loss = 0.00302930\n",
      "Iteration 7031, loss = 0.00302855\n",
      "Iteration 7032, loss = 0.00302794\n",
      "Iteration 7033, loss = 0.00302755\n",
      "Iteration 7034, loss = 0.00302668\n",
      "Iteration 7035, loss = 0.00302618\n",
      "Iteration 7036, loss = 0.00302546\n",
      "Iteration 7037, loss = 0.00302489\n",
      "Iteration 7038, loss = 0.00302432\n",
      "Iteration 7039, loss = 0.00302378\n",
      "Iteration 7040, loss = 0.00302321\n",
      "Iteration 7041, loss = 0.00302249\n",
      "Iteration 7042, loss = 0.00302206\n",
      "Iteration 7043, loss = 0.00302139\n",
      "Iteration 7044, loss = 0.00302079\n",
      "Iteration 7045, loss = 0.00302023\n",
      "Iteration 7046, loss = 0.00301962\n",
      "Iteration 7047, loss = 0.00301911\n",
      "Iteration 7048, loss = 0.00301882\n",
      "Iteration 7049, loss = 0.00301798\n",
      "Iteration 7050, loss = 0.00301776\n",
      "Iteration 7051, loss = 0.00301682\n",
      "Iteration 7052, loss = 0.00301614\n",
      "Iteration 7053, loss = 0.00301556\n",
      "Iteration 7054, loss = 0.00301489\n",
      "Iteration 7055, loss = 0.00301452\n",
      "Iteration 7056, loss = 0.00301360\n",
      "Iteration 7057, loss = 0.00301296\n",
      "Iteration 7058, loss = 0.00301230\n",
      "Iteration 7059, loss = 0.00301165\n",
      "Iteration 7060, loss = 0.00301099\n",
      "Iteration 7061, loss = 0.00301042\n",
      "Iteration 7062, loss = 0.00300995\n",
      "Iteration 7063, loss = 0.00300913\n",
      "Iteration 7064, loss = 0.00300847\n",
      "Iteration 7065, loss = 0.00300780\n",
      "Iteration 7066, loss = 0.00300718\n",
      "Iteration 7067, loss = 0.00300666\n",
      "Iteration 7068, loss = 0.00300609\n",
      "Iteration 7069, loss = 0.00300538\n",
      "Iteration 7070, loss = 0.00300483\n",
      "Iteration 7071, loss = 0.00300453\n",
      "Iteration 7072, loss = 0.00300378\n",
      "Iteration 7073, loss = 0.00300314\n",
      "Iteration 7074, loss = 0.00300260\n",
      "Iteration 7075, loss = 0.00300200\n",
      "Iteration 7076, loss = 0.00300139\n",
      "Iteration 7077, loss = 0.00300107\n",
      "Iteration 7078, loss = 0.00300012\n",
      "Iteration 7079, loss = 0.00299955\n",
      "Iteration 7080, loss = 0.00299893\n",
      "Iteration 7081, loss = 0.00299833\n",
      "Iteration 7082, loss = 0.00299785\n",
      "Iteration 7083, loss = 0.00299716\n",
      "Iteration 7084, loss = 0.00299671\n",
      "Iteration 7085, loss = 0.00299604\n",
      "Iteration 7086, loss = 0.00299548\n",
      "Iteration 7087, loss = 0.00299492\n",
      "Iteration 7088, loss = 0.00299431\n",
      "Iteration 7089, loss = 0.00299352\n",
      "Iteration 7090, loss = 0.00299321\n",
      "Iteration 7091, loss = 0.00299232\n",
      "Iteration 7092, loss = 0.00299173\n",
      "Iteration 7093, loss = 0.00299120\n",
      "Iteration 7094, loss = 0.00299050\n",
      "Iteration 7095, loss = 0.00298985\n",
      "Iteration 7096, loss = 0.00298924\n",
      "Iteration 7097, loss = 0.00298862\n",
      "Iteration 7098, loss = 0.00298806\n",
      "Iteration 7099, loss = 0.00298739\n",
      "Iteration 7100, loss = 0.00298666\n",
      "Iteration 7101, loss = 0.00298658\n",
      "Iteration 7102, loss = 0.00298544\n",
      "Iteration 7103, loss = 0.00298484\n",
      "Iteration 7104, loss = 0.00298434\n",
      "Iteration 7105, loss = 0.00298371\n",
      "Iteration 7106, loss = 0.00298322\n",
      "Iteration 7107, loss = 0.00298261\n",
      "Iteration 7108, loss = 0.00298214\n",
      "Iteration 7109, loss = 0.00298148\n",
      "Iteration 7110, loss = 0.00298097\n",
      "Iteration 7111, loss = 0.00298038\n",
      "Iteration 7112, loss = 0.00297979\n",
      "Iteration 7113, loss = 0.00297914\n",
      "Iteration 7114, loss = 0.00297859\n",
      "Iteration 7115, loss = 0.00297801\n",
      "Iteration 7116, loss = 0.00297749\n",
      "Iteration 7117, loss = 0.00297691\n",
      "Iteration 7118, loss = 0.00297653\n",
      "Iteration 7119, loss = 0.00297575\n",
      "Iteration 7120, loss = 0.00297524\n",
      "Iteration 7121, loss = 0.00297467\n",
      "Iteration 7122, loss = 0.00297389\n",
      "Iteration 7123, loss = 0.00297339\n",
      "Iteration 7124, loss = 0.00297265\n",
      "Iteration 7125, loss = 0.00297197\n",
      "Iteration 7126, loss = 0.00297141\n",
      "Iteration 7127, loss = 0.00297067\n",
      "Iteration 7128, loss = 0.00297011\n",
      "Iteration 7129, loss = 0.00296944\n",
      "Iteration 7130, loss = 0.00296880\n",
      "Iteration 7131, loss = 0.00296827\n",
      "Iteration 7132, loss = 0.00296772\n",
      "Iteration 7133, loss = 0.00296709\n",
      "Iteration 7134, loss = 0.00296654\n",
      "Iteration 7135, loss = 0.00296594\n",
      "Iteration 7136, loss = 0.00296549\n",
      "Iteration 7137, loss = 0.00296473\n",
      "Iteration 7138, loss = 0.00296415\n",
      "Iteration 7139, loss = 0.00296362\n",
      "Iteration 7140, loss = 0.00296309\n",
      "Iteration 7141, loss = 0.00296259\n",
      "Iteration 7142, loss = 0.00296183\n",
      "Iteration 7143, loss = 0.00296136\n",
      "Iteration 7144, loss = 0.00296094\n",
      "Iteration 7145, loss = 0.00296036\n",
      "Iteration 7146, loss = 0.00295973\n",
      "Iteration 7147, loss = 0.00295938\n",
      "Iteration 7148, loss = 0.00295878\n",
      "Iteration 7149, loss = 0.00295826\n",
      "Iteration 7150, loss = 0.00295776\n",
      "Iteration 7151, loss = 0.00295744\n",
      "Iteration 7152, loss = 0.00295684\n",
      "Iteration 7153, loss = 0.00295639\n",
      "Iteration 7154, loss = 0.00295573\n",
      "Iteration 7155, loss = 0.00295512\n",
      "Iteration 7156, loss = 0.00295464\n",
      "Iteration 7157, loss = 0.00295420\n",
      "Iteration 7158, loss = 0.00295350\n",
      "Iteration 7159, loss = 0.00295288\n",
      "Iteration 7160, loss = 0.00295244\n",
      "Iteration 7161, loss = 0.00295170\n",
      "Iteration 7162, loss = 0.00295108\n",
      "Iteration 7163, loss = 0.00295055\n",
      "Iteration 7164, loss = 0.00294989\n",
      "Iteration 7165, loss = 0.00294927\n",
      "Iteration 7166, loss = 0.00294868\n",
      "Iteration 7167, loss = 0.00294804\n",
      "Iteration 7168, loss = 0.00294753\n",
      "Iteration 7169, loss = 0.00294688\n",
      "Iteration 7170, loss = 0.00294652\n",
      "Iteration 7171, loss = 0.00294578\n",
      "Iteration 7172, loss = 0.00294521\n",
      "Iteration 7173, loss = 0.00294467\n",
      "Iteration 7174, loss = 0.00294404\n",
      "Iteration 7175, loss = 0.00294339\n",
      "Iteration 7176, loss = 0.00294280\n",
      "Iteration 7177, loss = 0.00294217\n",
      "Iteration 7178, loss = 0.00294168\n",
      "Iteration 7179, loss = 0.00294106\n",
      "Iteration 7180, loss = 0.00294026\n",
      "Iteration 7181, loss = 0.00293967\n",
      "Iteration 7182, loss = 0.00293903\n",
      "Iteration 7183, loss = 0.00293868\n",
      "Iteration 7184, loss = 0.00293803\n",
      "Iteration 7185, loss = 0.00293724\n",
      "Iteration 7186, loss = 0.00293676\n",
      "Iteration 7187, loss = 0.00293610\n",
      "Iteration 7188, loss = 0.00293548\n",
      "Iteration 7189, loss = 0.00293494\n",
      "Iteration 7190, loss = 0.00293432\n",
      "Iteration 7191, loss = 0.00293391\n",
      "Iteration 7192, loss = 0.00293310\n",
      "Iteration 7193, loss = 0.00293250\n",
      "Iteration 7194, loss = 0.00293194\n",
      "Iteration 7195, loss = 0.00293136\n",
      "Iteration 7196, loss = 0.00293082\n",
      "Iteration 7197, loss = 0.00292998\n",
      "Iteration 7198, loss = 0.00292929\n",
      "Iteration 7199, loss = 0.00292882\n",
      "Iteration 7200, loss = 0.00292806\n",
      "Iteration 7201, loss = 0.00292743\n",
      "Iteration 7202, loss = 0.00292689\n",
      "Iteration 7203, loss = 0.00292617\n",
      "Iteration 7204, loss = 0.00292551\n",
      "Iteration 7205, loss = 0.00292492\n",
      "Iteration 7206, loss = 0.00292423\n",
      "Iteration 7207, loss = 0.00292354\n",
      "Iteration 7208, loss = 0.00292299\n",
      "Iteration 7209, loss = 0.00292250\n",
      "Iteration 7210, loss = 0.00292213\n",
      "Iteration 7211, loss = 0.00292128\n",
      "Iteration 7212, loss = 0.00292084\n",
      "Iteration 7213, loss = 0.00292015\n",
      "Iteration 7214, loss = 0.00291953\n",
      "Iteration 7215, loss = 0.00291901\n",
      "Iteration 7216, loss = 0.00291846\n",
      "Iteration 7217, loss = 0.00291790\n",
      "Iteration 7218, loss = 0.00291736\n",
      "Iteration 7219, loss = 0.00291678\n",
      "Iteration 7220, loss = 0.00291629\n",
      "Iteration 7221, loss = 0.00291568\n",
      "Iteration 7222, loss = 0.00291517\n",
      "Iteration 7223, loss = 0.00291460\n",
      "Iteration 7224, loss = 0.00291405\n",
      "Iteration 7225, loss = 0.00291357\n",
      "Iteration 7226, loss = 0.00291315\n",
      "Iteration 7227, loss = 0.00291252\n",
      "Iteration 7228, loss = 0.00291197\n",
      "Iteration 7229, loss = 0.00291145\n",
      "Iteration 7230, loss = 0.00291093\n",
      "Iteration 7231, loss = 0.00291041\n",
      "Iteration 7232, loss = 0.00290987\n",
      "Iteration 7233, loss = 0.00290933\n",
      "Iteration 7234, loss = 0.00290875\n",
      "Iteration 7235, loss = 0.00290815\n",
      "Iteration 7236, loss = 0.00290750\n",
      "Iteration 7237, loss = 0.00290702\n",
      "Iteration 7238, loss = 0.00290640\n",
      "Iteration 7239, loss = 0.00290578\n",
      "Iteration 7240, loss = 0.00290522\n",
      "Iteration 7241, loss = 0.00290469\n",
      "Iteration 7242, loss = 0.00290412\n",
      "Iteration 7243, loss = 0.00290365\n",
      "Iteration 7244, loss = 0.00290330\n",
      "Iteration 7245, loss = 0.00290252\n",
      "Iteration 7246, loss = 0.00290202\n",
      "Iteration 7247, loss = 0.00290154\n",
      "Iteration 7248, loss = 0.00290087\n",
      "Iteration 7249, loss = 0.00290051\n",
      "Iteration 7250, loss = 0.00289972\n",
      "Iteration 7251, loss = 0.00289916\n",
      "Iteration 7252, loss = 0.00289859\n",
      "Iteration 7253, loss = 0.00289809\n",
      "Iteration 7254, loss = 0.00289755\n",
      "Iteration 7255, loss = 0.00289695\n",
      "Iteration 7256, loss = 0.00289636\n",
      "Iteration 7257, loss = 0.00289588\n",
      "Iteration 7258, loss = 0.00289560\n",
      "Iteration 7259, loss = 0.00289490\n",
      "Iteration 7260, loss = 0.00289435\n",
      "Iteration 7261, loss = 0.00289373\n",
      "Iteration 7262, loss = 0.00289339\n",
      "Iteration 7263, loss = 0.00289261\n",
      "Iteration 7264, loss = 0.00289201\n",
      "Iteration 7265, loss = 0.00289155\n",
      "Iteration 7266, loss = 0.00289095\n",
      "Iteration 7267, loss = 0.00289035\n",
      "Iteration 7268, loss = 0.00288983\n",
      "Iteration 7269, loss = 0.00288929\n",
      "Iteration 7270, loss = 0.00288868\n",
      "Iteration 7271, loss = 0.00288816\n",
      "Iteration 7272, loss = 0.00288770\n",
      "Iteration 7273, loss = 0.00288713\n",
      "Iteration 7274, loss = 0.00288661\n",
      "Iteration 7275, loss = 0.00288601\n",
      "Iteration 7276, loss = 0.00288552\n",
      "Iteration 7277, loss = 0.00288520\n",
      "Iteration 7278, loss = 0.00288441\n",
      "Iteration 7279, loss = 0.00288394\n",
      "Iteration 7280, loss = 0.00288331\n",
      "Iteration 7281, loss = 0.00288269\n",
      "Iteration 7282, loss = 0.00288200\n",
      "Iteration 7283, loss = 0.00288163\n",
      "Iteration 7284, loss = 0.00288090\n",
      "Iteration 7285, loss = 0.00288037\n",
      "Iteration 7286, loss = 0.00287970\n",
      "Iteration 7287, loss = 0.00287913\n",
      "Iteration 7288, loss = 0.00287866\n",
      "Iteration 7289, loss = 0.00287829\n",
      "Iteration 7290, loss = 0.00287751\n",
      "Iteration 7291, loss = 0.00287723\n",
      "Iteration 7292, loss = 0.00287667\n",
      "Iteration 7293, loss = 0.00287589\n",
      "Iteration 7294, loss = 0.00287529\n",
      "Iteration 7295, loss = 0.00287466\n",
      "Iteration 7296, loss = 0.00287403\n",
      "Iteration 7297, loss = 0.00287351\n",
      "Iteration 7298, loss = 0.00287284\n",
      "Iteration 7299, loss = 0.00287223\n",
      "Iteration 7300, loss = 0.00287165\n",
      "Iteration 7301, loss = 0.00287113\n",
      "Iteration 7302, loss = 0.00287066\n",
      "Iteration 7303, loss = 0.00287012\n",
      "Iteration 7304, loss = 0.00286974\n",
      "Iteration 7305, loss = 0.00286903\n",
      "Iteration 7306, loss = 0.00286844\n",
      "Iteration 7307, loss = 0.00286789\n",
      "Iteration 7308, loss = 0.00286727\n",
      "Iteration 7309, loss = 0.00286703\n",
      "Iteration 7310, loss = 0.00286632\n",
      "Iteration 7311, loss = 0.00286576\n",
      "Iteration 7312, loss = 0.00286528\n",
      "Iteration 7313, loss = 0.00286440\n",
      "Iteration 7314, loss = 0.00286388\n",
      "Iteration 7315, loss = 0.00286315\n",
      "Iteration 7316, loss = 0.00286269\n",
      "Iteration 7317, loss = 0.00286234\n",
      "Iteration 7318, loss = 0.00286139\n",
      "Iteration 7319, loss = 0.00286078\n",
      "Iteration 7320, loss = 0.00285999\n",
      "Iteration 7321, loss = 0.00285947\n",
      "Iteration 7322, loss = 0.00285884\n",
      "Iteration 7323, loss = 0.00285833\n",
      "Iteration 7324, loss = 0.00285770\n",
      "Iteration 7325, loss = 0.00285712\n",
      "Iteration 7326, loss = 0.00285667\n",
      "Iteration 7327, loss = 0.00285602\n",
      "Iteration 7328, loss = 0.00285542\n",
      "Iteration 7329, loss = 0.00285486\n",
      "Iteration 7330, loss = 0.00285425\n",
      "Iteration 7331, loss = 0.00285364\n",
      "Iteration 7332, loss = 0.00285310\n",
      "Iteration 7333, loss = 0.00285232\n",
      "Iteration 7334, loss = 0.00285163\n",
      "Iteration 7335, loss = 0.00285112\n",
      "Iteration 7336, loss = 0.00285070\n",
      "Iteration 7337, loss = 0.00284999\n",
      "Iteration 7338, loss = 0.00284928\n",
      "Iteration 7339, loss = 0.00284887\n",
      "Iteration 7340, loss = 0.00284825\n",
      "Iteration 7341, loss = 0.00284770\n",
      "Iteration 7342, loss = 0.00284695\n",
      "Iteration 7343, loss = 0.00284650\n",
      "Iteration 7344, loss = 0.00284580\n",
      "Iteration 7345, loss = 0.00284555\n",
      "Iteration 7346, loss = 0.00284513\n",
      "Iteration 7347, loss = 0.00284428\n",
      "Iteration 7348, loss = 0.00284372\n",
      "Iteration 7349, loss = 0.00284321\n",
      "Iteration 7350, loss = 0.00284271\n",
      "Iteration 7351, loss = 0.00284227\n",
      "Iteration 7352, loss = 0.00284175\n",
      "Iteration 7353, loss = 0.00284127\n",
      "Iteration 7354, loss = 0.00284075\n",
      "Iteration 7355, loss = 0.00284033\n",
      "Iteration 7356, loss = 0.00283967\n",
      "Iteration 7357, loss = 0.00283928\n",
      "Iteration 7358, loss = 0.00283869\n",
      "Iteration 7359, loss = 0.00283810\n",
      "Iteration 7360, loss = 0.00283759\n",
      "Iteration 7361, loss = 0.00283707\n",
      "Iteration 7362, loss = 0.00283657\n",
      "Iteration 7363, loss = 0.00283614\n",
      "Iteration 7364, loss = 0.00283551\n",
      "Iteration 7365, loss = 0.00283501\n",
      "Iteration 7366, loss = 0.00283437\n",
      "Iteration 7367, loss = 0.00283376\n",
      "Iteration 7368, loss = 0.00283314\n",
      "Iteration 7369, loss = 0.00283272\n",
      "Iteration 7370, loss = 0.00283216\n",
      "Iteration 7371, loss = 0.00283178\n",
      "Iteration 7372, loss = 0.00283099\n",
      "Iteration 7373, loss = 0.00283058\n",
      "Iteration 7374, loss = 0.00282984\n",
      "Iteration 7375, loss = 0.00282942\n",
      "Iteration 7376, loss = 0.00282877\n",
      "Iteration 7377, loss = 0.00282823\n",
      "Iteration 7378, loss = 0.00282759\n",
      "Iteration 7379, loss = 0.00282717\n",
      "Iteration 7380, loss = 0.00282653\n",
      "Iteration 7381, loss = 0.00282580\n",
      "Iteration 7382, loss = 0.00282557\n",
      "Iteration 7383, loss = 0.00282504\n",
      "Iteration 7384, loss = 0.00282433\n",
      "Iteration 7385, loss = 0.00282372\n",
      "Iteration 7386, loss = 0.00282326\n",
      "Iteration 7387, loss = 0.00282267\n",
      "Iteration 7388, loss = 0.00282207\n",
      "Iteration 7389, loss = 0.00282151\n",
      "Iteration 7390, loss = 0.00282109\n",
      "Iteration 7391, loss = 0.00282047\n",
      "Iteration 7392, loss = 0.00282006\n",
      "Iteration 7393, loss = 0.00281945\n",
      "Iteration 7394, loss = 0.00281908\n",
      "Iteration 7395, loss = 0.00281846\n",
      "Iteration 7396, loss = 0.00281795\n",
      "Iteration 7397, loss = 0.00281744\n",
      "Iteration 7398, loss = 0.00281702\n",
      "Iteration 7399, loss = 0.00281652\n",
      "Iteration 7400, loss = 0.00281586\n",
      "Iteration 7401, loss = 0.00281539\n",
      "Iteration 7402, loss = 0.00281495\n",
      "Iteration 7403, loss = 0.00281434\n",
      "Iteration 7404, loss = 0.00281381\n",
      "Iteration 7405, loss = 0.00281332\n",
      "Iteration 7406, loss = 0.00281280\n",
      "Iteration 7407, loss = 0.00281234\n",
      "Iteration 7408, loss = 0.00281194\n",
      "Iteration 7409, loss = 0.00281117\n",
      "Iteration 7410, loss = 0.00281057\n",
      "Iteration 7411, loss = 0.00281013\n",
      "Iteration 7412, loss = 0.00280961\n",
      "Iteration 7413, loss = 0.00280894\n",
      "Iteration 7414, loss = 0.00280847\n",
      "Iteration 7415, loss = 0.00280761\n",
      "Iteration 7416, loss = 0.00280702\n",
      "Iteration 7417, loss = 0.00280647\n",
      "Iteration 7418, loss = 0.00280579\n",
      "Iteration 7419, loss = 0.00280512\n",
      "Iteration 7420, loss = 0.00280446\n",
      "Iteration 7421, loss = 0.00280381\n",
      "Iteration 7422, loss = 0.00280331\n",
      "Iteration 7423, loss = 0.00280275\n",
      "Iteration 7424, loss = 0.00280217\n",
      "Iteration 7425, loss = 0.00280148\n",
      "Iteration 7426, loss = 0.00280090\n",
      "Iteration 7427, loss = 0.00280031\n",
      "Iteration 7428, loss = 0.00279994\n",
      "Iteration 7429, loss = 0.00279938\n",
      "Iteration 7430, loss = 0.00279882\n",
      "Iteration 7431, loss = 0.00279812\n",
      "Iteration 7432, loss = 0.00279750\n",
      "Iteration 7433, loss = 0.00279690\n",
      "Iteration 7434, loss = 0.00279632\n",
      "Iteration 7435, loss = 0.00279593\n",
      "Iteration 7436, loss = 0.00279527\n",
      "Iteration 7437, loss = 0.00279488\n",
      "Iteration 7438, loss = 0.00279428\n",
      "Iteration 7439, loss = 0.00279378\n",
      "Iteration 7440, loss = 0.00279321\n",
      "Iteration 7441, loss = 0.00279264\n",
      "Iteration 7442, loss = 0.00279209\n",
      "Iteration 7443, loss = 0.00279153\n",
      "Iteration 7444, loss = 0.00279101\n",
      "Iteration 7445, loss = 0.00279048\n",
      "Iteration 7446, loss = 0.00278998\n",
      "Iteration 7447, loss = 0.00278943\n",
      "Iteration 7448, loss = 0.00278902\n",
      "Iteration 7449, loss = 0.00278846\n",
      "Iteration 7450, loss = 0.00278801\n",
      "Iteration 7451, loss = 0.00278754\n",
      "Iteration 7452, loss = 0.00278716\n",
      "Iteration 7453, loss = 0.00278658\n",
      "Iteration 7454, loss = 0.00278630\n",
      "Iteration 7455, loss = 0.00278574\n",
      "Iteration 7456, loss = 0.00278535\n",
      "Iteration 7457, loss = 0.00278475\n",
      "Iteration 7458, loss = 0.00278444\n",
      "Iteration 7459, loss = 0.00278407\n",
      "Iteration 7460, loss = 0.00278341\n",
      "Iteration 7461, loss = 0.00278310\n",
      "Iteration 7462, loss = 0.00278256\n",
      "Iteration 7463, loss = 0.00278188\n",
      "Iteration 7464, loss = 0.00278135\n",
      "Iteration 7465, loss = 0.00278079\n",
      "Iteration 7466, loss = 0.00278032\n",
      "Iteration 7467, loss = 0.00277987\n",
      "Iteration 7468, loss = 0.00277944\n",
      "Iteration 7469, loss = 0.00277883\n",
      "Iteration 7470, loss = 0.00277824\n",
      "Iteration 7471, loss = 0.00277777\n",
      "Iteration 7472, loss = 0.00277717\n",
      "Iteration 7473, loss = 0.00277666\n",
      "Iteration 7474, loss = 0.00277623\n",
      "Iteration 7475, loss = 0.00277577\n",
      "Iteration 7476, loss = 0.00277527\n",
      "Iteration 7477, loss = 0.00277480\n",
      "Iteration 7478, loss = 0.00277433\n",
      "Iteration 7479, loss = 0.00277375\n",
      "Iteration 7480, loss = 0.00277319\n",
      "Iteration 7481, loss = 0.00277262\n",
      "Iteration 7482, loss = 0.00277209\n",
      "Iteration 7483, loss = 0.00277180\n",
      "Iteration 7484, loss = 0.00277114\n",
      "Iteration 7485, loss = 0.00277054\n",
      "Iteration 7486, loss = 0.00277012\n",
      "Iteration 7487, loss = 0.00276955\n",
      "Iteration 7488, loss = 0.00276901\n",
      "Iteration 7489, loss = 0.00276851\n",
      "Iteration 7490, loss = 0.00276804\n",
      "Iteration 7491, loss = 0.00276751\n",
      "Iteration 7492, loss = 0.00276714\n",
      "Iteration 7493, loss = 0.00276654\n",
      "Iteration 7494, loss = 0.00276602\n",
      "Iteration 7495, loss = 0.00276559\n",
      "Iteration 7496, loss = 0.00276510\n",
      "Iteration 7497, loss = 0.00276471\n",
      "Iteration 7498, loss = 0.00276415\n",
      "Iteration 7499, loss = 0.00276371\n",
      "Iteration 7500, loss = 0.00276312\n",
      "Iteration 7501, loss = 0.00276252\n",
      "Iteration 7502, loss = 0.00276211\n",
      "Iteration 7503, loss = 0.00276159\n",
      "Iteration 7504, loss = 0.00276099\n",
      "Iteration 7505, loss = 0.00276041\n",
      "Iteration 7506, loss = 0.00276001\n",
      "Iteration 7507, loss = 0.00275940\n",
      "Iteration 7508, loss = 0.00275886\n",
      "Iteration 7509, loss = 0.00275830\n",
      "Iteration 7510, loss = 0.00275771\n",
      "Iteration 7511, loss = 0.00275727\n",
      "Iteration 7512, loss = 0.00275662\n",
      "Iteration 7513, loss = 0.00275612\n",
      "Iteration 7514, loss = 0.00275559\n",
      "Iteration 7515, loss = 0.00275516\n",
      "Iteration 7516, loss = 0.00275465\n",
      "Iteration 7517, loss = 0.00275421\n",
      "Iteration 7518, loss = 0.00275353\n",
      "Iteration 7519, loss = 0.00275300\n",
      "Iteration 7520, loss = 0.00275249\n",
      "Iteration 7521, loss = 0.00275195\n",
      "Iteration 7522, loss = 0.00275141\n",
      "Iteration 7523, loss = 0.00275100\n",
      "Iteration 7524, loss = 0.00275043\n",
      "Iteration 7525, loss = 0.00274989\n",
      "Iteration 7526, loss = 0.00274946\n",
      "Iteration 7527, loss = 0.00274897\n",
      "Iteration 7528, loss = 0.00274839\n",
      "Iteration 7529, loss = 0.00274802\n",
      "Iteration 7530, loss = 0.00274741\n",
      "Iteration 7531, loss = 0.00274691\n",
      "Iteration 7532, loss = 0.00274648\n",
      "Iteration 7533, loss = 0.00274601\n",
      "Iteration 7534, loss = 0.00274571\n",
      "Iteration 7535, loss = 0.00274522\n",
      "Iteration 7536, loss = 0.00274447\n",
      "Iteration 7537, loss = 0.00274397\n",
      "Iteration 7538, loss = 0.00274334\n",
      "Iteration 7539, loss = 0.00274286\n",
      "Iteration 7540, loss = 0.00274231\n",
      "Iteration 7541, loss = 0.00274179\n",
      "Iteration 7542, loss = 0.00274127\n",
      "Iteration 7543, loss = 0.00274085\n",
      "Iteration 7544, loss = 0.00274027\n",
      "Iteration 7545, loss = 0.00273981\n",
      "Iteration 7546, loss = 0.00273958\n",
      "Iteration 7547, loss = 0.00273894\n",
      "Iteration 7548, loss = 0.00273855\n",
      "Iteration 7549, loss = 0.00273785\n",
      "Iteration 7550, loss = 0.00273731\n",
      "Iteration 7551, loss = 0.00273673\n",
      "Iteration 7552, loss = 0.00273630\n",
      "Iteration 7553, loss = 0.00273575\n",
      "Iteration 7554, loss = 0.00273540\n",
      "Iteration 7555, loss = 0.00273476\n",
      "Iteration 7556, loss = 0.00273423\n",
      "Iteration 7557, loss = 0.00273371\n",
      "Iteration 7558, loss = 0.00273323\n",
      "Iteration 7559, loss = 0.00273274\n",
      "Iteration 7560, loss = 0.00273217\n",
      "Iteration 7561, loss = 0.00273180\n",
      "Iteration 7562, loss = 0.00273138\n",
      "Iteration 7563, loss = 0.00273075\n",
      "Iteration 7564, loss = 0.00273030\n",
      "Iteration 7565, loss = 0.00272979\n",
      "Iteration 7566, loss = 0.00272931\n",
      "Iteration 7567, loss = 0.00272905\n",
      "Iteration 7568, loss = 0.00272846\n",
      "Iteration 7569, loss = 0.00272783\n",
      "Iteration 7570, loss = 0.00272731\n",
      "Iteration 7571, loss = 0.00272681\n",
      "Iteration 7572, loss = 0.00272637\n",
      "Iteration 7573, loss = 0.00272595\n",
      "Iteration 7574, loss = 0.00272535\n",
      "Iteration 7575, loss = 0.00272484\n",
      "Iteration 7576, loss = 0.00272440\n",
      "Iteration 7577, loss = 0.00272411\n",
      "Iteration 7578, loss = 0.00272348\n",
      "Iteration 7579, loss = 0.00272308\n",
      "Iteration 7580, loss = 0.00272241\n",
      "Iteration 7581, loss = 0.00272191\n",
      "Iteration 7582, loss = 0.00272146\n",
      "Iteration 7583, loss = 0.00272099\n",
      "Iteration 7584, loss = 0.00272043\n",
      "Iteration 7585, loss = 0.00271990\n",
      "Iteration 7586, loss = 0.00271934\n",
      "Iteration 7587, loss = 0.00271886\n",
      "Iteration 7588, loss = 0.00271832\n",
      "Iteration 7589, loss = 0.00271771\n",
      "Iteration 7590, loss = 0.00271723\n",
      "Iteration 7591, loss = 0.00271683\n",
      "Iteration 7592, loss = 0.00271612\n",
      "Iteration 7593, loss = 0.00271581\n",
      "Iteration 7594, loss = 0.00271504\n",
      "Iteration 7595, loss = 0.00271456\n",
      "Iteration 7596, loss = 0.00271403\n",
      "Iteration 7597, loss = 0.00271355\n",
      "Iteration 7598, loss = 0.00271297\n",
      "Iteration 7599, loss = 0.00271246\n",
      "Iteration 7600, loss = 0.00271199\n",
      "Iteration 7601, loss = 0.00271153\n",
      "Iteration 7602, loss = 0.00271106\n",
      "Iteration 7603, loss = 0.00271076\n",
      "Iteration 7604, loss = 0.00271011\n",
      "Iteration 7605, loss = 0.00270981\n",
      "Iteration 7606, loss = 0.00270915\n",
      "Iteration 7607, loss = 0.00270865\n",
      "Iteration 7608, loss = 0.00270821\n",
      "Iteration 7609, loss = 0.00270772\n",
      "Iteration 7610, loss = 0.00270723\n",
      "Iteration 7611, loss = 0.00270671\n",
      "Iteration 7612, loss = 0.00270623\n",
      "Iteration 7613, loss = 0.00270597\n",
      "Iteration 7614, loss = 0.00270527\n",
      "Iteration 7615, loss = 0.00270481\n",
      "Iteration 7616, loss = 0.00270431\n",
      "Iteration 7617, loss = 0.00270379\n",
      "Iteration 7618, loss = 0.00270332\n",
      "Iteration 7619, loss = 0.00270283\n",
      "Iteration 7620, loss = 0.00270241\n",
      "Iteration 7621, loss = 0.00270199\n",
      "Iteration 7622, loss = 0.00270165\n",
      "Iteration 7623, loss = 0.00270116\n",
      "Iteration 7624, loss = 0.00270066\n",
      "Iteration 7625, loss = 0.00270043\n",
      "Iteration 7626, loss = 0.00269985\n",
      "Iteration 7627, loss = 0.00269941\n",
      "Iteration 7628, loss = 0.00269892\n",
      "Iteration 7629, loss = 0.00269846\n",
      "Iteration 7630, loss = 0.00269792\n",
      "Iteration 7631, loss = 0.00269741\n",
      "Iteration 7632, loss = 0.00269697\n",
      "Iteration 7633, loss = 0.00269621\n",
      "Iteration 7634, loss = 0.00269565\n",
      "Iteration 7635, loss = 0.00269518\n",
      "Iteration 7636, loss = 0.00269468\n",
      "Iteration 7637, loss = 0.00269415\n",
      "Iteration 7638, loss = 0.00269377\n",
      "Iteration 7639, loss = 0.00269297\n",
      "Iteration 7640, loss = 0.00269240\n",
      "Iteration 7641, loss = 0.00269190\n",
      "Iteration 7642, loss = 0.00269147\n",
      "Iteration 7643, loss = 0.00269075\n",
      "Iteration 7644, loss = 0.00269026\n",
      "Iteration 7645, loss = 0.00268972\n",
      "Iteration 7646, loss = 0.00268919\n",
      "Iteration 7647, loss = 0.00268863\n",
      "Iteration 7648, loss = 0.00268809\n",
      "Iteration 7649, loss = 0.00268761\n",
      "Iteration 7650, loss = 0.00268708\n",
      "Iteration 7651, loss = 0.00268660\n",
      "Iteration 7652, loss = 0.00268603\n",
      "Iteration 7653, loss = 0.00268550\n",
      "Iteration 7654, loss = 0.00268500\n",
      "Iteration 7655, loss = 0.00268459\n",
      "Iteration 7656, loss = 0.00268407\n",
      "Iteration 7657, loss = 0.00268340\n",
      "Iteration 7658, loss = 0.00268312\n",
      "Iteration 7659, loss = 0.00268235\n",
      "Iteration 7660, loss = 0.00268199\n",
      "Iteration 7661, loss = 0.00268151\n",
      "Iteration 7662, loss = 0.00268088\n",
      "Iteration 7663, loss = 0.00268039\n",
      "Iteration 7664, loss = 0.00267990\n",
      "Iteration 7665, loss = 0.00267993\n",
      "Iteration 7666, loss = 0.00267905\n",
      "Iteration 7667, loss = 0.00267863\n",
      "Iteration 7668, loss = 0.00267820\n",
      "Iteration 7669, loss = 0.00267758\n",
      "Iteration 7670, loss = 0.00267710\n",
      "Iteration 7671, loss = 0.00267652\n",
      "Iteration 7672, loss = 0.00267592\n",
      "Iteration 7673, loss = 0.00267557\n",
      "Iteration 7674, loss = 0.00267498\n",
      "Iteration 7675, loss = 0.00267439\n",
      "Iteration 7676, loss = 0.00267389\n",
      "Iteration 7677, loss = 0.00267346\n",
      "Iteration 7678, loss = 0.00267291\n",
      "Iteration 7679, loss = 0.00267250\n",
      "Iteration 7680, loss = 0.00267214\n",
      "Iteration 7681, loss = 0.00267158\n",
      "Iteration 7682, loss = 0.00267091\n",
      "Iteration 7683, loss = 0.00267042\n",
      "Iteration 7684, loss = 0.00266990\n",
      "Iteration 7685, loss = 0.00266941\n",
      "Iteration 7686, loss = 0.00266891\n",
      "Iteration 7687, loss = 0.00266841\n",
      "Iteration 7688, loss = 0.00266802\n",
      "Iteration 7689, loss = 0.00266748\n",
      "Iteration 7690, loss = 0.00266699\n",
      "Iteration 7691, loss = 0.00266655\n",
      "Iteration 7692, loss = 0.00266609\n",
      "Iteration 7693, loss = 0.00266563\n",
      "Iteration 7694, loss = 0.00266522\n",
      "Iteration 7695, loss = 0.00266475\n",
      "Iteration 7696, loss = 0.00266434\n",
      "Iteration 7697, loss = 0.00266388\n",
      "Iteration 7698, loss = 0.00266352\n",
      "Iteration 7699, loss = 0.00266308\n",
      "Iteration 7700, loss = 0.00266269\n",
      "Iteration 7701, loss = 0.00266230\n",
      "Iteration 7702, loss = 0.00266234\n",
      "Iteration 7703, loss = 0.00266151\n",
      "Iteration 7704, loss = 0.00266098\n",
      "Iteration 7705, loss = 0.00266055\n",
      "Iteration 7706, loss = 0.00266008\n",
      "Iteration 7707, loss = 0.00265960\n",
      "Iteration 7708, loss = 0.00265957\n",
      "Iteration 7709, loss = 0.00265873\n",
      "Iteration 7710, loss = 0.00265829\n",
      "Iteration 7711, loss = 0.00265777\n",
      "Iteration 7712, loss = 0.00265727\n",
      "Iteration 7713, loss = 0.00265684\n",
      "Iteration 7714, loss = 0.00265625\n",
      "Iteration 7715, loss = 0.00265578\n",
      "Iteration 7716, loss = 0.00265532\n",
      "Iteration 7717, loss = 0.00265486\n",
      "Iteration 7718, loss = 0.00265440\n",
      "Iteration 7719, loss = 0.00265393\n",
      "Iteration 7720, loss = 0.00265352\n",
      "Iteration 7721, loss = 0.00265359\n",
      "Iteration 7722, loss = 0.00265261\n",
      "Iteration 7723, loss = 0.00265222\n",
      "Iteration 7724, loss = 0.00265164\n",
      "Iteration 7725, loss = 0.00265117\n",
      "Iteration 7726, loss = 0.00265062\n",
      "Iteration 7727, loss = 0.00265009\n",
      "Iteration 7728, loss = 0.00264946\n",
      "Iteration 7729, loss = 0.00264933\n",
      "Iteration 7730, loss = 0.00264841\n",
      "Iteration 7731, loss = 0.00264775\n",
      "Iteration 7732, loss = 0.00264739\n",
      "Iteration 7733, loss = 0.00264676\n",
      "Iteration 7734, loss = 0.00264628\n",
      "Iteration 7735, loss = 0.00264584\n",
      "Iteration 7736, loss = 0.00264533\n",
      "Iteration 7737, loss = 0.00264500\n",
      "Iteration 7738, loss = 0.00264456\n",
      "Iteration 7739, loss = 0.00264407\n",
      "Iteration 7740, loss = 0.00264371\n",
      "Iteration 7741, loss = 0.00264328\n",
      "Iteration 7742, loss = 0.00264300\n",
      "Iteration 7743, loss = 0.00264242\n",
      "Iteration 7744, loss = 0.00264198\n",
      "Iteration 7745, loss = 0.00264129\n",
      "Iteration 7746, loss = 0.00264084\n",
      "Iteration 7747, loss = 0.00264045\n",
      "Iteration 7748, loss = 0.00263976\n",
      "Iteration 7749, loss = 0.00263923\n",
      "Iteration 7750, loss = 0.00263876\n",
      "Iteration 7751, loss = 0.00263813\n",
      "Iteration 7752, loss = 0.00263794\n",
      "Iteration 7753, loss = 0.00263716\n",
      "Iteration 7754, loss = 0.00263660\n",
      "Iteration 7755, loss = 0.00263614\n",
      "Iteration 7756, loss = 0.00263583\n",
      "Iteration 7757, loss = 0.00263514\n",
      "Iteration 7758, loss = 0.00263462\n",
      "Iteration 7759, loss = 0.00263425\n",
      "Iteration 7760, loss = 0.00263368\n",
      "Iteration 7761, loss = 0.00263317\n",
      "Iteration 7762, loss = 0.00263275\n",
      "Iteration 7763, loss = 0.00263218\n",
      "Iteration 7764, loss = 0.00263177\n",
      "Iteration 7765, loss = 0.00263121\n",
      "Iteration 7766, loss = 0.00263064\n",
      "Iteration 7767, loss = 0.00263008\n",
      "Iteration 7768, loss = 0.00262958\n",
      "Iteration 7769, loss = 0.00262910\n",
      "Iteration 7770, loss = 0.00262851\n",
      "Iteration 7771, loss = 0.00262796\n",
      "Iteration 7772, loss = 0.00262740\n",
      "Iteration 7773, loss = 0.00262681\n",
      "Iteration 7774, loss = 0.00262634\n",
      "Iteration 7775, loss = 0.00262599\n",
      "Iteration 7776, loss = 0.00262532\n",
      "Iteration 7777, loss = 0.00262501\n",
      "Iteration 7778, loss = 0.00262437\n",
      "Iteration 7779, loss = 0.00262389\n",
      "Iteration 7780, loss = 0.00262347\n",
      "Iteration 7781, loss = 0.00262297\n",
      "Iteration 7782, loss = 0.00262251\n",
      "Iteration 7783, loss = 0.00262196\n",
      "Iteration 7784, loss = 0.00262146\n",
      "Iteration 7785, loss = 0.00262115\n",
      "Iteration 7786, loss = 0.00262047\n",
      "Iteration 7787, loss = 0.00261985\n",
      "Iteration 7788, loss = 0.00261944\n",
      "Iteration 7789, loss = 0.00261886\n",
      "Iteration 7790, loss = 0.00261838\n",
      "Iteration 7791, loss = 0.00261781\n",
      "Iteration 7792, loss = 0.00261750\n",
      "Iteration 7793, loss = 0.00261701\n",
      "Iteration 7794, loss = 0.00261656\n",
      "Iteration 7795, loss = 0.00261598\n",
      "Iteration 7796, loss = 0.00261568\n",
      "Iteration 7797, loss = 0.00261495\n",
      "Iteration 7798, loss = 0.00261448\n",
      "Iteration 7799, loss = 0.00261393\n",
      "Iteration 7800, loss = 0.00261347\n",
      "Iteration 7801, loss = 0.00261303\n",
      "Iteration 7802, loss = 0.00261260\n",
      "Iteration 7803, loss = 0.00261202\n",
      "Iteration 7804, loss = 0.00261179\n",
      "Iteration 7805, loss = 0.00261107\n",
      "Iteration 7806, loss = 0.00261066\n",
      "Iteration 7807, loss = 0.00261015\n",
      "Iteration 7808, loss = 0.00260962\n",
      "Iteration 7809, loss = 0.00260921\n",
      "Iteration 7810, loss = 0.00260875\n",
      "Iteration 7811, loss = 0.00260834\n",
      "Iteration 7812, loss = 0.00260781\n",
      "Iteration 7813, loss = 0.00260737\n",
      "Iteration 7814, loss = 0.00260685\n",
      "Iteration 7815, loss = 0.00260634\n",
      "Iteration 7816, loss = 0.00260587\n",
      "Iteration 7817, loss = 0.00260550\n",
      "Iteration 7818, loss = 0.00260494\n",
      "Iteration 7819, loss = 0.00260446\n",
      "Iteration 7820, loss = 0.00260408\n",
      "Iteration 7821, loss = 0.00260348\n",
      "Iteration 7822, loss = 0.00260299\n",
      "Iteration 7823, loss = 0.00260253\n",
      "Iteration 7824, loss = 0.00260202\n",
      "Iteration 7825, loss = 0.00260163\n",
      "Iteration 7826, loss = 0.00260099\n",
      "Iteration 7827, loss = 0.00260061\n",
      "Iteration 7828, loss = 0.00260019\n",
      "Iteration 7829, loss = 0.00259985\n",
      "Iteration 7830, loss = 0.00259930\n",
      "Iteration 7831, loss = 0.00259884\n",
      "Iteration 7832, loss = 0.00259838\n",
      "Iteration 7833, loss = 0.00259816\n",
      "Iteration 7834, loss = 0.00259743\n",
      "Iteration 7835, loss = 0.00259732\n",
      "Iteration 7836, loss = 0.00259649\n",
      "Iteration 7837, loss = 0.00259596\n",
      "Iteration 7838, loss = 0.00259543\n",
      "Iteration 7839, loss = 0.00259522\n",
      "Iteration 7840, loss = 0.00259474\n",
      "Iteration 7841, loss = 0.00259391\n",
      "Iteration 7842, loss = 0.00259339\n",
      "Iteration 7843, loss = 0.00259291\n",
      "Iteration 7844, loss = 0.00259253\n",
      "Iteration 7845, loss = 0.00259194\n",
      "Iteration 7846, loss = 0.00259131\n",
      "Iteration 7847, loss = 0.00259083\n",
      "Iteration 7848, loss = 0.00259035\n",
      "Iteration 7849, loss = 0.00258982\n",
      "Iteration 7850, loss = 0.00258964\n",
      "Iteration 7851, loss = 0.00258897\n",
      "Iteration 7852, loss = 0.00258848\n",
      "Iteration 7853, loss = 0.00258783\n",
      "Iteration 7854, loss = 0.00258749\n",
      "Iteration 7855, loss = 0.00258700\n",
      "Iteration 7856, loss = 0.00258648\n",
      "Iteration 7857, loss = 0.00258625\n",
      "Iteration 7858, loss = 0.00258558\n",
      "Iteration 7859, loss = 0.00258502\n",
      "Iteration 7860, loss = 0.00258450\n",
      "Iteration 7861, loss = 0.00258404\n",
      "Iteration 7862, loss = 0.00258354\n",
      "Iteration 7863, loss = 0.00258305\n",
      "Iteration 7864, loss = 0.00258262\n",
      "Iteration 7865, loss = 0.00258209\n",
      "Iteration 7866, loss = 0.00258165\n",
      "Iteration 7867, loss = 0.00258119\n",
      "Iteration 7868, loss = 0.00258084\n",
      "Iteration 7869, loss = 0.00258032\n",
      "Iteration 7870, loss = 0.00257992\n",
      "Iteration 7871, loss = 0.00257971\n",
      "Iteration 7872, loss = 0.00257933\n",
      "Iteration 7873, loss = 0.00257871\n",
      "Iteration 7874, loss = 0.00257826\n",
      "Iteration 7875, loss = 0.00257806\n",
      "Iteration 7876, loss = 0.00257739\n",
      "Iteration 7877, loss = 0.00257704\n",
      "Iteration 7878, loss = 0.00257666\n",
      "Iteration 7879, loss = 0.00257622\n",
      "Iteration 7880, loss = 0.00257579\n",
      "Iteration 7881, loss = 0.00257547\n",
      "Iteration 7882, loss = 0.00257532\n",
      "Iteration 7883, loss = 0.00257452\n",
      "Iteration 7884, loss = 0.00257404\n",
      "Iteration 7885, loss = 0.00257340\n",
      "Iteration 7886, loss = 0.00257294\n",
      "Iteration 7887, loss = 0.00257243\n",
      "Iteration 7888, loss = 0.00257202\n",
      "Iteration 7889, loss = 0.00257148\n",
      "Iteration 7890, loss = 0.00257101\n",
      "Iteration 7891, loss = 0.00257075\n",
      "Iteration 7892, loss = 0.00257021\n",
      "Iteration 7893, loss = 0.00256971\n",
      "Iteration 7894, loss = 0.00256920\n",
      "Iteration 7895, loss = 0.00256873\n",
      "Iteration 7896, loss = 0.00256824\n",
      "Iteration 7897, loss = 0.00256798\n",
      "Iteration 7898, loss = 0.00256743\n",
      "Iteration 7899, loss = 0.00256692\n",
      "Iteration 7900, loss = 0.00256653\n",
      "Iteration 7901, loss = 0.00256615\n",
      "Iteration 7902, loss = 0.00256585\n",
      "Iteration 7903, loss = 0.00256536\n",
      "Iteration 7904, loss = 0.00256489\n",
      "Iteration 7905, loss = 0.00256448\n",
      "Iteration 7906, loss = 0.00256406\n",
      "Iteration 7907, loss = 0.00256375\n",
      "Iteration 7908, loss = 0.00256315\n",
      "Iteration 7909, loss = 0.00256275\n",
      "Iteration 7910, loss = 0.00256252\n",
      "Iteration 7911, loss = 0.00256187\n",
      "Iteration 7912, loss = 0.00256151\n",
      "Iteration 7913, loss = 0.00256090\n",
      "Iteration 7914, loss = 0.00256036\n",
      "Iteration 7915, loss = 0.00256021\n",
      "Iteration 7916, loss = 0.00255939\n",
      "Iteration 7917, loss = 0.00255890\n",
      "Iteration 7918, loss = 0.00255832\n",
      "Iteration 7919, loss = 0.00255785\n",
      "Iteration 7920, loss = 0.00255747\n",
      "Iteration 7921, loss = 0.00255687\n",
      "Iteration 7922, loss = 0.00255633\n",
      "Iteration 7923, loss = 0.00255604\n",
      "Iteration 7924, loss = 0.00255541\n",
      "Iteration 7925, loss = 0.00255498\n",
      "Iteration 7926, loss = 0.00255460\n",
      "Iteration 7927, loss = 0.00255410\n",
      "Iteration 7928, loss = 0.00255401\n",
      "Iteration 7929, loss = 0.00255330\n",
      "Iteration 7930, loss = 0.00255281\n",
      "Iteration 7931, loss = 0.00255241\n",
      "Iteration 7932, loss = 0.00255191\n",
      "Iteration 7933, loss = 0.00255150\n",
      "Iteration 7934, loss = 0.00255100\n",
      "Iteration 7935, loss = 0.00255047\n",
      "Iteration 7936, loss = 0.00255008\n",
      "Iteration 7937, loss = 0.00254951\n",
      "Iteration 7938, loss = 0.00254908\n",
      "Iteration 7939, loss = 0.00254847\n",
      "Iteration 7940, loss = 0.00254797\n",
      "Iteration 7941, loss = 0.00254764\n",
      "Iteration 7942, loss = 0.00254714\n",
      "Iteration 7943, loss = 0.00254660\n",
      "Iteration 7944, loss = 0.00254611\n",
      "Iteration 7945, loss = 0.00254550\n",
      "Iteration 7946, loss = 0.00254518\n",
      "Iteration 7947, loss = 0.00254476\n",
      "Iteration 7948, loss = 0.00254416\n",
      "Iteration 7949, loss = 0.00254368\n",
      "Iteration 7950, loss = 0.00254331\n",
      "Iteration 7951, loss = 0.00254275\n",
      "Iteration 7952, loss = 0.00254229\n",
      "Iteration 7953, loss = 0.00254182\n",
      "Iteration 7954, loss = 0.00254134\n",
      "Iteration 7955, loss = 0.00254085\n",
      "Iteration 7956, loss = 0.00254048\n",
      "Iteration 7957, loss = 0.00253994\n",
      "Iteration 7958, loss = 0.00253954\n",
      "Iteration 7959, loss = 0.00253903\n",
      "Iteration 7960, loss = 0.00253856\n",
      "Iteration 7961, loss = 0.00253815\n",
      "Iteration 7962, loss = 0.00253772\n",
      "Iteration 7963, loss = 0.00253728\n",
      "Iteration 7964, loss = 0.00253689\n",
      "Iteration 7965, loss = 0.00253650\n",
      "Iteration 7966, loss = 0.00253604\n",
      "Iteration 7967, loss = 0.00253560\n",
      "Iteration 7968, loss = 0.00253547\n",
      "Iteration 7969, loss = 0.00253493\n",
      "Iteration 7970, loss = 0.00253451\n",
      "Iteration 7971, loss = 0.00253410\n",
      "Iteration 7972, loss = 0.00253365\n",
      "Iteration 7973, loss = 0.00253328\n",
      "Iteration 7974, loss = 0.00253284\n",
      "Iteration 7975, loss = 0.00253237\n",
      "Iteration 7976, loss = 0.00253188\n",
      "Iteration 7977, loss = 0.00253134\n",
      "Iteration 7978, loss = 0.00253117\n",
      "Iteration 7979, loss = 0.00253039\n",
      "Iteration 7980, loss = 0.00252990\n",
      "Iteration 7981, loss = 0.00252943\n",
      "Iteration 7982, loss = 0.00252880\n",
      "Iteration 7983, loss = 0.00252822\n",
      "Iteration 7984, loss = 0.00252786\n",
      "Iteration 7985, loss = 0.00252746\n",
      "Iteration 7986, loss = 0.00252702\n",
      "Iteration 7987, loss = 0.00252673\n",
      "Iteration 7988, loss = 0.00252610\n",
      "Iteration 7989, loss = 0.00252564\n",
      "Iteration 7990, loss = 0.00252522\n",
      "Iteration 7991, loss = 0.00252480\n",
      "Iteration 7992, loss = 0.00252439\n",
      "Iteration 7993, loss = 0.00252400\n",
      "Iteration 7994, loss = 0.00252357\n",
      "Iteration 7995, loss = 0.00252322\n",
      "Iteration 7996, loss = 0.00252274\n",
      "Iteration 7997, loss = 0.00252235\n",
      "Iteration 7998, loss = 0.00252192\n",
      "Iteration 7999, loss = 0.00252152\n",
      "Iteration 8000, loss = 0.00252110\n",
      "Iteration 1, loss = 1.02709999\n",
      "Iteration 2, loss = 1.02411093\n",
      "Iteration 3, loss = 1.01930461\n",
      "Iteration 4, loss = 1.01328347\n",
      "Iteration 5, loss = 1.00622561\n",
      "Iteration 6, loss = 0.99845165\n",
      "Iteration 7, loss = 0.99018610\n",
      "Iteration 8, loss = 0.98147679\n",
      "Iteration 9, loss = 0.97239050\n",
      "Iteration 10, loss = 0.96348596\n",
      "Iteration 11, loss = 0.95416563\n",
      "Iteration 12, loss = 0.94507336\n",
      "Iteration 13, loss = 0.93597766\n",
      "Iteration 14, loss = 0.92711378\n",
      "Iteration 15, loss = 0.91831435\n",
      "Iteration 16, loss = 0.90981434\n",
      "Iteration 17, loss = 0.90121955\n",
      "Iteration 18, loss = 0.89315869\n",
      "Iteration 19, loss = 0.88525401\n",
      "Iteration 20, loss = 0.87757669\n",
      "Iteration 21, loss = 0.87004667\n",
      "Iteration 22, loss = 0.86288703\n",
      "Iteration 23, loss = 0.85575934\n",
      "Iteration 24, loss = 0.84874449\n",
      "Iteration 25, loss = 0.84198547\n",
      "Iteration 26, loss = 0.83527794\n",
      "Iteration 27, loss = 0.82864907\n",
      "Iteration 28, loss = 0.82228373\n",
      "Iteration 29, loss = 0.81622522\n",
      "Iteration 30, loss = 0.81020688\n",
      "Iteration 31, loss = 0.80437638\n",
      "Iteration 32, loss = 0.79875539\n",
      "Iteration 33, loss = 0.79318706\n",
      "Iteration 34, loss = 0.78788388\n",
      "Iteration 35, loss = 0.78260815\n",
      "Iteration 36, loss = 0.77736127\n",
      "Iteration 37, loss = 0.77254672\n",
      "Iteration 38, loss = 0.76771553\n",
      "Iteration 39, loss = 0.76302948\n",
      "Iteration 40, loss = 0.75870005\n",
      "Iteration 41, loss = 0.75436468\n",
      "Iteration 42, loss = 0.75018198\n",
      "Iteration 43, loss = 0.74627704\n",
      "Iteration 44, loss = 0.74235443\n",
      "Iteration 45, loss = 0.73854513\n",
      "Iteration 46, loss = 0.73493454\n",
      "Iteration 47, loss = 0.73125975\n",
      "Iteration 48, loss = 0.72769798\n",
      "Iteration 49, loss = 0.72425267\n",
      "Iteration 50, loss = 0.72068940\n",
      "Iteration 51, loss = 0.71733071\n",
      "Iteration 52, loss = 0.71389590\n",
      "Iteration 53, loss = 0.71060131\n",
      "Iteration 54, loss = 0.70723778\n",
      "Iteration 55, loss = 0.70400049\n",
      "Iteration 56, loss = 0.70075595\n",
      "Iteration 57, loss = 0.69740177\n",
      "Iteration 58, loss = 0.69423922\n",
      "Iteration 59, loss = 0.69094430\n",
      "Iteration 60, loss = 0.68768263\n",
      "Iteration 61, loss = 0.68442563\n",
      "Iteration 62, loss = 0.68133267\n",
      "Iteration 63, loss = 0.67823208\n",
      "Iteration 64, loss = 0.67510893\n",
      "Iteration 65, loss = 0.67218596\n",
      "Iteration 66, loss = 0.66921741\n",
      "Iteration 67, loss = 0.66626883\n",
      "Iteration 68, loss = 0.66348618\n",
      "Iteration 69, loss = 0.66054484\n",
      "Iteration 70, loss = 0.65777253\n",
      "Iteration 71, loss = 0.65487415\n",
      "Iteration 72, loss = 0.65214519\n",
      "Iteration 73, loss = 0.64930724\n",
      "Iteration 74, loss = 0.64657588\n",
      "Iteration 75, loss = 0.64383623\n",
      "Iteration 76, loss = 0.64111136\n",
      "Iteration 77, loss = 0.63842029\n",
      "Iteration 78, loss = 0.63572863\n",
      "Iteration 79, loss = 0.63307103\n",
      "Iteration 80, loss = 0.63044780\n",
      "Iteration 81, loss = 0.62781540\n",
      "Iteration 82, loss = 0.62523378\n",
      "Iteration 83, loss = 0.62270268\n",
      "Iteration 84, loss = 0.62007821\n",
      "Iteration 85, loss = 0.61761506\n",
      "Iteration 86, loss = 0.61505227\n",
      "Iteration 87, loss = 0.61253683\n",
      "Iteration 88, loss = 0.61000104\n",
      "Iteration 89, loss = 0.60752092\n",
      "Iteration 90, loss = 0.60502438\n",
      "Iteration 91, loss = 0.60250024\n",
      "Iteration 92, loss = 0.60006265\n",
      "Iteration 93, loss = 0.59764223\n",
      "Iteration 94, loss = 0.59515999\n",
      "Iteration 95, loss = 0.59272012\n",
      "Iteration 96, loss = 0.59031473\n",
      "Iteration 97, loss = 0.58788990\n",
      "Iteration 98, loss = 0.58549344\n",
      "Iteration 99, loss = 0.58308573\n",
      "Iteration 100, loss = 0.58068541\n",
      "Iteration 101, loss = 0.57833261\n",
      "Iteration 102, loss = 0.57592009\n",
      "Iteration 103, loss = 0.57357010\n",
      "Iteration 104, loss = 0.57124342\n",
      "Iteration 105, loss = 0.56889054\n",
      "Iteration 106, loss = 0.56656016\n",
      "Iteration 107, loss = 0.56425266\n",
      "Iteration 108, loss = 0.56203976\n",
      "Iteration 109, loss = 0.55972363\n",
      "Iteration 110, loss = 0.55748153\n",
      "Iteration 111, loss = 0.55527157\n",
      "Iteration 112, loss = 0.55302701\n",
      "Iteration 113, loss = 0.55086304\n",
      "Iteration 114, loss = 0.54859731\n",
      "Iteration 115, loss = 0.54640070\n",
      "Iteration 116, loss = 0.54421332\n",
      "Iteration 117, loss = 0.54195190\n",
      "Iteration 118, loss = 0.53979984\n",
      "Iteration 119, loss = 0.53754004\n",
      "Iteration 120, loss = 0.53534277\n",
      "Iteration 121, loss = 0.53318824\n",
      "Iteration 122, loss = 0.53103790\n",
      "Iteration 123, loss = 0.52890858\n",
      "Iteration 124, loss = 0.52678926\n",
      "Iteration 125, loss = 0.52467650\n",
      "Iteration 126, loss = 0.52256329\n",
      "Iteration 127, loss = 0.52047578\n",
      "Iteration 128, loss = 0.51838336\n",
      "Iteration 129, loss = 0.51629314\n",
      "Iteration 130, loss = 0.51428101\n",
      "Iteration 131, loss = 0.51226764\n",
      "Iteration 132, loss = 0.51025513\n",
      "Iteration 133, loss = 0.50827574\n",
      "Iteration 134, loss = 0.50630541\n",
      "Iteration 135, loss = 0.50431040\n",
      "Iteration 136, loss = 0.50234112\n",
      "Iteration 137, loss = 0.50032891\n",
      "Iteration 138, loss = 0.49832514\n",
      "Iteration 139, loss = 0.49632206\n",
      "Iteration 140, loss = 0.49429306\n",
      "Iteration 141, loss = 0.49227635\n",
      "Iteration 142, loss = 0.49027168\n",
      "Iteration 143, loss = 0.48827127\n",
      "Iteration 144, loss = 0.48626895\n",
      "Iteration 145, loss = 0.48426457\n",
      "Iteration 146, loss = 0.48227057\n",
      "Iteration 147, loss = 0.48028374\n",
      "Iteration 148, loss = 0.47830719\n",
      "Iteration 149, loss = 0.47627824\n",
      "Iteration 150, loss = 0.47430108\n",
      "Iteration 151, loss = 0.47230911\n",
      "Iteration 152, loss = 0.47028973\n",
      "Iteration 153, loss = 0.46827545\n",
      "Iteration 154, loss = 0.46628023\n",
      "Iteration 155, loss = 0.46432996\n",
      "Iteration 156, loss = 0.46229582\n",
      "Iteration 157, loss = 0.46032411\n",
      "Iteration 158, loss = 0.45833322\n",
      "Iteration 159, loss = 0.45633414\n",
      "Iteration 160, loss = 0.45430057\n",
      "Iteration 161, loss = 0.45229787\n",
      "Iteration 162, loss = 0.45025819\n",
      "Iteration 163, loss = 0.44820665\n",
      "Iteration 164, loss = 0.44616644\n",
      "Iteration 165, loss = 0.44412478\n",
      "Iteration 166, loss = 0.44207677\n",
      "Iteration 167, loss = 0.44003942\n",
      "Iteration 168, loss = 0.43802799\n",
      "Iteration 169, loss = 0.43598421\n",
      "Iteration 170, loss = 0.43399426\n",
      "Iteration 171, loss = 0.43196335\n",
      "Iteration 172, loss = 0.42996692\n",
      "Iteration 173, loss = 0.42797631\n",
      "Iteration 174, loss = 0.42597825\n",
      "Iteration 175, loss = 0.42397527\n",
      "Iteration 176, loss = 0.42201627\n",
      "Iteration 177, loss = 0.42003084\n",
      "Iteration 178, loss = 0.41806111\n",
      "Iteration 179, loss = 0.41607442\n",
      "Iteration 180, loss = 0.41413146\n",
      "Iteration 181, loss = 0.41210472\n",
      "Iteration 182, loss = 0.41012998\n",
      "Iteration 183, loss = 0.40817045\n",
      "Iteration 184, loss = 0.40614311\n",
      "Iteration 185, loss = 0.40417537\n",
      "Iteration 186, loss = 0.40218600\n",
      "Iteration 187, loss = 0.40017981\n",
      "Iteration 188, loss = 0.39820879\n",
      "Iteration 189, loss = 0.39623857\n",
      "Iteration 190, loss = 0.39424178\n",
      "Iteration 191, loss = 0.39229683\n",
      "Iteration 192, loss = 0.39033357\n",
      "Iteration 193, loss = 0.38839131\n",
      "Iteration 194, loss = 0.38644634\n",
      "Iteration 195, loss = 0.38453107\n",
      "Iteration 196, loss = 0.38256736\n",
      "Iteration 197, loss = 0.38066785\n",
      "Iteration 198, loss = 0.37872106\n",
      "Iteration 199, loss = 0.37681847\n",
      "Iteration 200, loss = 0.37488581\n",
      "Iteration 201, loss = 0.37297083\n",
      "Iteration 202, loss = 0.37107776\n",
      "Iteration 203, loss = 0.36916552\n",
      "Iteration 204, loss = 0.36726990\n",
      "Iteration 205, loss = 0.36536696\n",
      "Iteration 206, loss = 0.36347975\n",
      "Iteration 207, loss = 0.36154641\n",
      "Iteration 208, loss = 0.35965187\n",
      "Iteration 209, loss = 0.35772494\n",
      "Iteration 210, loss = 0.35580809\n",
      "Iteration 211, loss = 0.35389377\n",
      "Iteration 212, loss = 0.35193454\n",
      "Iteration 213, loss = 0.35003263\n",
      "Iteration 214, loss = 0.34809295\n",
      "Iteration 215, loss = 0.34616997\n",
      "Iteration 216, loss = 0.34425295\n",
      "Iteration 217, loss = 0.34234803\n",
      "Iteration 218, loss = 0.34046140\n",
      "Iteration 219, loss = 0.33857194\n",
      "Iteration 220, loss = 0.33670367\n",
      "Iteration 221, loss = 0.33484339\n",
      "Iteration 222, loss = 0.33299376\n",
      "Iteration 223, loss = 0.33115120\n",
      "Iteration 224, loss = 0.32928616\n",
      "Iteration 225, loss = 0.32746690\n",
      "Iteration 226, loss = 0.32560601\n",
      "Iteration 227, loss = 0.32376087\n",
      "Iteration 228, loss = 0.32190756\n",
      "Iteration 229, loss = 0.32006734\n",
      "Iteration 230, loss = 0.31822396\n",
      "Iteration 231, loss = 0.31641283\n",
      "Iteration 232, loss = 0.31458224\n",
      "Iteration 233, loss = 0.31275205\n",
      "Iteration 234, loss = 0.31095663\n",
      "Iteration 235, loss = 0.30916236\n",
      "Iteration 236, loss = 0.30735827\n",
      "Iteration 237, loss = 0.30556879\n",
      "Iteration 238, loss = 0.30379617\n",
      "Iteration 239, loss = 0.30202263\n",
      "Iteration 240, loss = 0.30025006\n",
      "Iteration 241, loss = 0.29849959\n",
      "Iteration 242, loss = 0.29674717\n",
      "Iteration 243, loss = 0.29499350\n",
      "Iteration 244, loss = 0.29326500\n",
      "Iteration 245, loss = 0.29154295\n",
      "Iteration 246, loss = 0.28981238\n",
      "Iteration 247, loss = 0.28812685\n",
      "Iteration 248, loss = 0.28642661\n",
      "Iteration 249, loss = 0.28474148\n",
      "Iteration 250, loss = 0.28310294\n",
      "Iteration 251, loss = 0.28145068\n",
      "Iteration 252, loss = 0.27979873\n",
      "Iteration 253, loss = 0.27817048\n",
      "Iteration 254, loss = 0.27656278\n",
      "Iteration 255, loss = 0.27494069\n",
      "Iteration 256, loss = 0.27336054\n",
      "Iteration 257, loss = 0.27175165\n",
      "Iteration 258, loss = 0.27018486\n",
      "Iteration 259, loss = 0.26860087\n",
      "Iteration 260, loss = 0.26704076\n",
      "Iteration 261, loss = 0.26546838\n",
      "Iteration 262, loss = 0.26393188\n",
      "Iteration 263, loss = 0.26238129\n",
      "Iteration 264, loss = 0.26084025\n",
      "Iteration 265, loss = 0.25932396\n",
      "Iteration 266, loss = 0.25782239\n",
      "Iteration 267, loss = 0.25631868\n",
      "Iteration 268, loss = 0.25483221\n",
      "Iteration 269, loss = 0.25336502\n",
      "Iteration 270, loss = 0.25191167\n",
      "Iteration 271, loss = 0.25045872\n",
      "Iteration 272, loss = 0.24904088\n",
      "Iteration 273, loss = 0.24760233\n",
      "Iteration 274, loss = 0.24620331\n",
      "Iteration 275, loss = 0.24479480\n",
      "Iteration 276, loss = 0.24341046\n",
      "Iteration 277, loss = 0.24202106\n",
      "Iteration 278, loss = 0.24065172\n",
      "Iteration 279, loss = 0.23930617\n",
      "Iteration 280, loss = 0.23794451\n",
      "Iteration 281, loss = 0.23659484\n",
      "Iteration 282, loss = 0.23525439\n",
      "Iteration 283, loss = 0.23392037\n",
      "Iteration 284, loss = 0.23258469\n",
      "Iteration 285, loss = 0.23124939\n",
      "Iteration 286, loss = 0.22992535\n",
      "Iteration 287, loss = 0.22861531\n",
      "Iteration 288, loss = 0.22731297\n",
      "Iteration 289, loss = 0.22601588\n",
      "Iteration 290, loss = 0.22473510\n",
      "Iteration 291, loss = 0.22345565\n",
      "Iteration 292, loss = 0.22220065\n",
      "Iteration 293, loss = 0.22093611\n",
      "Iteration 294, loss = 0.21969104\n",
      "Iteration 295, loss = 0.21846864\n",
      "Iteration 296, loss = 0.21723033\n",
      "Iteration 297, loss = 0.21601740\n",
      "Iteration 298, loss = 0.21479179\n",
      "Iteration 299, loss = 0.21360548\n",
      "Iteration 300, loss = 0.21239518\n",
      "Iteration 301, loss = 0.21120025\n",
      "Iteration 302, loss = 0.21001603\n",
      "Iteration 303, loss = 0.20885568\n",
      "Iteration 304, loss = 0.20768852\n",
      "Iteration 305, loss = 0.20654197\n",
      "Iteration 306, loss = 0.20539378\n",
      "Iteration 307, loss = 0.20426725\n",
      "Iteration 308, loss = 0.20314804\n",
      "Iteration 309, loss = 0.20203322\n",
      "Iteration 310, loss = 0.20094005\n",
      "Iteration 311, loss = 0.19984440\n",
      "Iteration 312, loss = 0.19876991\n",
      "Iteration 313, loss = 0.19769829\n",
      "Iteration 314, loss = 0.19662761\n",
      "Iteration 315, loss = 0.19556716\n",
      "Iteration 316, loss = 0.19451233\n",
      "Iteration 317, loss = 0.19346865\n",
      "Iteration 318, loss = 0.19242929\n",
      "Iteration 319, loss = 0.19140141\n",
      "Iteration 320, loss = 0.19037440\n",
      "Iteration 321, loss = 0.18935527\n",
      "Iteration 322, loss = 0.18835348\n",
      "Iteration 323, loss = 0.18736157\n",
      "Iteration 324, loss = 0.18637810\n",
      "Iteration 325, loss = 0.18538702\n",
      "Iteration 326, loss = 0.18442131\n",
      "Iteration 327, loss = 0.18346304\n",
      "Iteration 328, loss = 0.18250741\n",
      "Iteration 329, loss = 0.18155156\n",
      "Iteration 330, loss = 0.18060824\n",
      "Iteration 331, loss = 0.17965860\n",
      "Iteration 332, loss = 0.17872117\n",
      "Iteration 333, loss = 0.17779882\n",
      "Iteration 334, loss = 0.17686542\n",
      "Iteration 335, loss = 0.17594869\n",
      "Iteration 336, loss = 0.17503618\n",
      "Iteration 337, loss = 0.17411999\n",
      "Iteration 338, loss = 0.17321498\n",
      "Iteration 339, loss = 0.17231381\n",
      "Iteration 340, loss = 0.17141500\n",
      "Iteration 341, loss = 0.17053721\n",
      "Iteration 342, loss = 0.16965259\n",
      "Iteration 343, loss = 0.16879789\n",
      "Iteration 344, loss = 0.16793419\n",
      "Iteration 345, loss = 0.16708588\n",
      "Iteration 346, loss = 0.16624416\n",
      "Iteration 347, loss = 0.16539817\n",
      "Iteration 348, loss = 0.16457445\n",
      "Iteration 349, loss = 0.16373022\n",
      "Iteration 350, loss = 0.16290835\n",
      "Iteration 351, loss = 0.16208846\n",
      "Iteration 352, loss = 0.16128047\n",
      "Iteration 353, loss = 0.16048706\n",
      "Iteration 354, loss = 0.15969263\n",
      "Iteration 355, loss = 0.15891164\n",
      "Iteration 356, loss = 0.15814615\n",
      "Iteration 357, loss = 0.15737699\n",
      "Iteration 358, loss = 0.15661477\n",
      "Iteration 359, loss = 0.15585978\n",
      "Iteration 360, loss = 0.15510822\n",
      "Iteration 361, loss = 0.15436757\n",
      "Iteration 362, loss = 0.15363230\n",
      "Iteration 363, loss = 0.15289838\n",
      "Iteration 364, loss = 0.15217636\n",
      "Iteration 365, loss = 0.15146071\n",
      "Iteration 366, loss = 0.15073650\n",
      "Iteration 367, loss = 0.15003454\n",
      "Iteration 368, loss = 0.14933383\n",
      "Iteration 369, loss = 0.14864243\n",
      "Iteration 370, loss = 0.14795389\n",
      "Iteration 371, loss = 0.14727939\n",
      "Iteration 372, loss = 0.14660102\n",
      "Iteration 373, loss = 0.14593400\n",
      "Iteration 374, loss = 0.14525665\n",
      "Iteration 375, loss = 0.14458991\n",
      "Iteration 376, loss = 0.14392828\n",
      "Iteration 377, loss = 0.14327211\n",
      "Iteration 378, loss = 0.14262624\n",
      "Iteration 379, loss = 0.14197411\n",
      "Iteration 380, loss = 0.14133863\n",
      "Iteration 381, loss = 0.14070416\n",
      "Iteration 382, loss = 0.14007558\n",
      "Iteration 383, loss = 0.13945560\n",
      "Iteration 384, loss = 0.13883038\n",
      "Iteration 385, loss = 0.13822192\n",
      "Iteration 386, loss = 0.13760628\n",
      "Iteration 387, loss = 0.13699539\n",
      "Iteration 388, loss = 0.13638548\n",
      "Iteration 389, loss = 0.13578724\n",
      "Iteration 390, loss = 0.13518740\n",
      "Iteration 391, loss = 0.13459209\n",
      "Iteration 392, loss = 0.13400053\n",
      "Iteration 393, loss = 0.13341660\n",
      "Iteration 394, loss = 0.13284316\n",
      "Iteration 395, loss = 0.13227157\n",
      "Iteration 396, loss = 0.13170457\n",
      "Iteration 397, loss = 0.13115422\n",
      "Iteration 398, loss = 0.13059769\n",
      "Iteration 399, loss = 0.13004618\n",
      "Iteration 400, loss = 0.12950010\n",
      "Iteration 401, loss = 0.12895406\n",
      "Iteration 402, loss = 0.12842420\n",
      "Iteration 403, loss = 0.12788999\n",
      "Iteration 404, loss = 0.12736552\n",
      "Iteration 405, loss = 0.12683707\n",
      "Iteration 406, loss = 0.12632349\n",
      "Iteration 407, loss = 0.12580757\n",
      "Iteration 408, loss = 0.12529574\n",
      "Iteration 409, loss = 0.12478917\n",
      "Iteration 410, loss = 0.12428692\n",
      "Iteration 411, loss = 0.12379033\n",
      "Iteration 412, loss = 0.12329670\n",
      "Iteration 413, loss = 0.12281758\n",
      "Iteration 414, loss = 0.12232995\n",
      "Iteration 415, loss = 0.12184557\n",
      "Iteration 416, loss = 0.12137149\n",
      "Iteration 417, loss = 0.12089305\n",
      "Iteration 418, loss = 0.12042756\n",
      "Iteration 419, loss = 0.11995400\n",
      "Iteration 420, loss = 0.11949089\n",
      "Iteration 421, loss = 0.11902391\n",
      "Iteration 422, loss = 0.11856174\n",
      "Iteration 423, loss = 0.11810043\n",
      "Iteration 424, loss = 0.11764535\n",
      "Iteration 425, loss = 0.11718926\n",
      "Iteration 426, loss = 0.11673945\n",
      "Iteration 427, loss = 0.11629696\n",
      "Iteration 428, loss = 0.11586077\n",
      "Iteration 429, loss = 0.11542308\n",
      "Iteration 430, loss = 0.11499383\n",
      "Iteration 431, loss = 0.11457233\n",
      "Iteration 432, loss = 0.11414811\n",
      "Iteration 433, loss = 0.11372029\n",
      "Iteration 434, loss = 0.11329459\n",
      "Iteration 435, loss = 0.11288617\n",
      "Iteration 436, loss = 0.11246569\n",
      "Iteration 437, loss = 0.11205250\n",
      "Iteration 438, loss = 0.11164130\n",
      "Iteration 439, loss = 0.11123479\n",
      "Iteration 440, loss = 0.11082153\n",
      "Iteration 441, loss = 0.11042075\n",
      "Iteration 442, loss = 0.11002412\n",
      "Iteration 443, loss = 0.10963202\n",
      "Iteration 444, loss = 0.10924364\n",
      "Iteration 445, loss = 0.10885569\n",
      "Iteration 446, loss = 0.10847302\n",
      "Iteration 447, loss = 0.10809977\n",
      "Iteration 448, loss = 0.10770671\n",
      "Iteration 449, loss = 0.10732517\n",
      "Iteration 450, loss = 0.10694891\n",
      "Iteration 451, loss = 0.10656509\n",
      "Iteration 452, loss = 0.10619741\n",
      "Iteration 453, loss = 0.10582501\n",
      "Iteration 454, loss = 0.10546112\n",
      "Iteration 455, loss = 0.10510474\n",
      "Iteration 456, loss = 0.10473272\n",
      "Iteration 457, loss = 0.10437680\n",
      "Iteration 458, loss = 0.10401331\n",
      "Iteration 459, loss = 0.10365321\n",
      "Iteration 460, loss = 0.10330595\n",
      "Iteration 461, loss = 0.10295105\n",
      "Iteration 462, loss = 0.10260474\n",
      "Iteration 463, loss = 0.10226170\n",
      "Iteration 464, loss = 0.10191968\n",
      "Iteration 465, loss = 0.10158580\n",
      "Iteration 466, loss = 0.10125332\n",
      "Iteration 467, loss = 0.10092659\n",
      "Iteration 468, loss = 0.10059612\n",
      "Iteration 469, loss = 0.10026812\n",
      "Iteration 470, loss = 0.09993805\n",
      "Iteration 471, loss = 0.09961980\n",
      "Iteration 472, loss = 0.09928863\n",
      "Iteration 473, loss = 0.09896686\n",
      "Iteration 474, loss = 0.09863969\n",
      "Iteration 475, loss = 0.09831674\n",
      "Iteration 476, loss = 0.09800351\n",
      "Iteration 477, loss = 0.09768675\n",
      "Iteration 478, loss = 0.09736857\n",
      "Iteration 479, loss = 0.09705604\n",
      "Iteration 480, loss = 0.09674912\n",
      "Iteration 481, loss = 0.09644819\n",
      "Iteration 482, loss = 0.09613189\n",
      "Iteration 483, loss = 0.09583490\n",
      "Iteration 484, loss = 0.09553243\n",
      "Iteration 485, loss = 0.09523256\n",
      "Iteration 486, loss = 0.09492838\n",
      "Iteration 487, loss = 0.09462564\n",
      "Iteration 488, loss = 0.09433865\n",
      "Iteration 489, loss = 0.09404648\n",
      "Iteration 490, loss = 0.09375190\n",
      "Iteration 491, loss = 0.09347227\n",
      "Iteration 492, loss = 0.09318534\n",
      "Iteration 493, loss = 0.09290186\n",
      "Iteration 494, loss = 0.09261866\n",
      "Iteration 495, loss = 0.09233797\n",
      "Iteration 496, loss = 0.09206899\n",
      "Iteration 497, loss = 0.09178797\n",
      "Iteration 498, loss = 0.09153093\n",
      "Iteration 499, loss = 0.09123934\n",
      "Iteration 500, loss = 0.09096189\n",
      "Iteration 501, loss = 0.09070152\n",
      "Iteration 502, loss = 0.09041906\n",
      "Iteration 503, loss = 0.09015142\n",
      "Iteration 504, loss = 0.08988277\n",
      "Iteration 505, loss = 0.08962013\n",
      "Iteration 506, loss = 0.08935530\n",
      "Iteration 507, loss = 0.08909500\n",
      "Iteration 508, loss = 0.08883947\n",
      "Iteration 509, loss = 0.08858170\n",
      "Iteration 510, loss = 0.08832391\n",
      "Iteration 511, loss = 0.08807236\n",
      "Iteration 512, loss = 0.08781618\n",
      "Iteration 513, loss = 0.08757358\n",
      "Iteration 514, loss = 0.08732911\n",
      "Iteration 515, loss = 0.08707026\n",
      "Iteration 516, loss = 0.08682112\n",
      "Iteration 517, loss = 0.08657185\n",
      "Iteration 518, loss = 0.08632439\n",
      "Iteration 519, loss = 0.08607691\n",
      "Iteration 520, loss = 0.08583261\n",
      "Iteration 521, loss = 0.08559421\n",
      "Iteration 522, loss = 0.08534680\n",
      "Iteration 523, loss = 0.08511190\n",
      "Iteration 524, loss = 0.08486881\n",
      "Iteration 525, loss = 0.08463610\n",
      "Iteration 526, loss = 0.08440573\n",
      "Iteration 527, loss = 0.08417593\n",
      "Iteration 528, loss = 0.08394493\n",
      "Iteration 529, loss = 0.08371817\n",
      "Iteration 530, loss = 0.08348637\n",
      "Iteration 531, loss = 0.08326338\n",
      "Iteration 532, loss = 0.08303788\n",
      "Iteration 533, loss = 0.08281447\n",
      "Iteration 534, loss = 0.08259508\n",
      "Iteration 535, loss = 0.08237923\n",
      "Iteration 536, loss = 0.08216035\n",
      "Iteration 537, loss = 0.08194631\n",
      "Iteration 538, loss = 0.08173327\n",
      "Iteration 539, loss = 0.08152103\n",
      "Iteration 540, loss = 0.08131052\n",
      "Iteration 541, loss = 0.08110305\n",
      "Iteration 542, loss = 0.08089370\n",
      "Iteration 543, loss = 0.08068483\n",
      "Iteration 544, loss = 0.08048273\n",
      "Iteration 545, loss = 0.08027867\n",
      "Iteration 546, loss = 0.08006948\n",
      "Iteration 547, loss = 0.07986896\n",
      "Iteration 548, loss = 0.07966650\n",
      "Iteration 549, loss = 0.07946477\n",
      "Iteration 550, loss = 0.07926428\n",
      "Iteration 551, loss = 0.07906279\n",
      "Iteration 552, loss = 0.07886506\n",
      "Iteration 553, loss = 0.07866605\n",
      "Iteration 554, loss = 0.07847440\n",
      "Iteration 555, loss = 0.07827734\n",
      "Iteration 556, loss = 0.07809009\n",
      "Iteration 557, loss = 0.07789832\n",
      "Iteration 558, loss = 0.07771443\n",
      "Iteration 559, loss = 0.07751784\n",
      "Iteration 560, loss = 0.07733360\n",
      "Iteration 561, loss = 0.07714563\n",
      "Iteration 562, loss = 0.07695575\n",
      "Iteration 563, loss = 0.07677219\n",
      "Iteration 564, loss = 0.07658367\n",
      "Iteration 565, loss = 0.07640447\n",
      "Iteration 566, loss = 0.07621911\n",
      "Iteration 567, loss = 0.07603179\n",
      "Iteration 568, loss = 0.07585174\n",
      "Iteration 569, loss = 0.07567297\n",
      "Iteration 570, loss = 0.07549356\n",
      "Iteration 571, loss = 0.07531308\n",
      "Iteration 572, loss = 0.07513497\n",
      "Iteration 573, loss = 0.07496337\n",
      "Iteration 574, loss = 0.07478541\n",
      "Iteration 575, loss = 0.07460768\n",
      "Iteration 576, loss = 0.07442925\n",
      "Iteration 577, loss = 0.07426048\n",
      "Iteration 578, loss = 0.07408527\n",
      "Iteration 579, loss = 0.07391602\n",
      "Iteration 580, loss = 0.07374256\n",
      "Iteration 581, loss = 0.07357691\n",
      "Iteration 582, loss = 0.07340643\n",
      "Iteration 583, loss = 0.07323739\n",
      "Iteration 584, loss = 0.07307072\n",
      "Iteration 585, loss = 0.07291408\n",
      "Iteration 586, loss = 0.07274168\n",
      "Iteration 587, loss = 0.07257263\n",
      "Iteration 588, loss = 0.07240562\n",
      "Iteration 589, loss = 0.07224141\n",
      "Iteration 590, loss = 0.07207360\n",
      "Iteration 591, loss = 0.07191428\n",
      "Iteration 592, loss = 0.07174660\n",
      "Iteration 593, loss = 0.07158857\n",
      "Iteration 594, loss = 0.07142866\n",
      "Iteration 595, loss = 0.07126798\n",
      "Iteration 596, loss = 0.07110713\n",
      "Iteration 597, loss = 0.07095211\n",
      "Iteration 598, loss = 0.07079508\n",
      "Iteration 599, loss = 0.07064212\n",
      "Iteration 600, loss = 0.07048670\n",
      "Iteration 601, loss = 0.07033101\n",
      "Iteration 602, loss = 0.07017927\n",
      "Iteration 603, loss = 0.07002355\n",
      "Iteration 604, loss = 0.06986942\n",
      "Iteration 605, loss = 0.06971459\n",
      "Iteration 606, loss = 0.06956193\n",
      "Iteration 607, loss = 0.06940616\n",
      "Iteration 608, loss = 0.06926077\n",
      "Iteration 609, loss = 0.06910622\n",
      "Iteration 610, loss = 0.06895793\n",
      "Iteration 611, loss = 0.06880261\n",
      "Iteration 612, loss = 0.06865268\n",
      "Iteration 613, loss = 0.06850293\n",
      "Iteration 614, loss = 0.06835576\n",
      "Iteration 615, loss = 0.06820605\n",
      "Iteration 616, loss = 0.06805549\n",
      "Iteration 617, loss = 0.06791188\n",
      "Iteration 618, loss = 0.06777165\n",
      "Iteration 619, loss = 0.06762025\n",
      "Iteration 620, loss = 0.06747404\n",
      "Iteration 621, loss = 0.06733422\n",
      "Iteration 622, loss = 0.06719577\n",
      "Iteration 623, loss = 0.06706446\n",
      "Iteration 624, loss = 0.06692249\n",
      "Iteration 625, loss = 0.06678124\n",
      "Iteration 626, loss = 0.06664183\n",
      "Iteration 627, loss = 0.06650205\n",
      "Iteration 628, loss = 0.06636124\n",
      "Iteration 629, loss = 0.06622334\n",
      "Iteration 630, loss = 0.06608599\n",
      "Iteration 631, loss = 0.06594960\n",
      "Iteration 632, loss = 0.06581884\n",
      "Iteration 633, loss = 0.06568493\n",
      "Iteration 634, loss = 0.06555635\n",
      "Iteration 635, loss = 0.06542549\n",
      "Iteration 636, loss = 0.06529475\n",
      "Iteration 637, loss = 0.06516204\n",
      "Iteration 638, loss = 0.06503100\n",
      "Iteration 639, loss = 0.06489838\n",
      "Iteration 640, loss = 0.06476750\n",
      "Iteration 641, loss = 0.06463522\n",
      "Iteration 642, loss = 0.06450962\n",
      "Iteration 643, loss = 0.06437266\n",
      "Iteration 644, loss = 0.06424566\n",
      "Iteration 645, loss = 0.06411398\n",
      "Iteration 646, loss = 0.06398273\n",
      "Iteration 647, loss = 0.06385218\n",
      "Iteration 648, loss = 0.06372544\n",
      "Iteration 649, loss = 0.06360000\n",
      "Iteration 650, loss = 0.06347571\n",
      "Iteration 651, loss = 0.06335666\n",
      "Iteration 652, loss = 0.06323219\n",
      "Iteration 653, loss = 0.06311312\n",
      "Iteration 654, loss = 0.06298874\n",
      "Iteration 655, loss = 0.06287246\n",
      "Iteration 656, loss = 0.06274754\n",
      "Iteration 657, loss = 0.06262394\n",
      "Iteration 658, loss = 0.06250376\n",
      "Iteration 659, loss = 0.06238450\n",
      "Iteration 660, loss = 0.06226363\n",
      "Iteration 661, loss = 0.06214822\n",
      "Iteration 662, loss = 0.06203154\n",
      "Iteration 663, loss = 0.06191643\n",
      "Iteration 664, loss = 0.06179642\n",
      "Iteration 665, loss = 0.06168391\n",
      "Iteration 666, loss = 0.06156887\n",
      "Iteration 667, loss = 0.06145335\n",
      "Iteration 668, loss = 0.06134047\n",
      "Iteration 669, loss = 0.06122593\n",
      "Iteration 670, loss = 0.06111120\n",
      "Iteration 671, loss = 0.06099997\n",
      "Iteration 672, loss = 0.06088443\n",
      "Iteration 673, loss = 0.06077067\n",
      "Iteration 674, loss = 0.06065834\n",
      "Iteration 675, loss = 0.06054828\n",
      "Iteration 676, loss = 0.06043462\n",
      "Iteration 677, loss = 0.06032430\n",
      "Iteration 678, loss = 0.06021107\n",
      "Iteration 679, loss = 0.06011046\n",
      "Iteration 680, loss = 0.05999630\n",
      "Iteration 681, loss = 0.05988659\n",
      "Iteration 682, loss = 0.05977764\n",
      "Iteration 683, loss = 0.05966714\n",
      "Iteration 684, loss = 0.05955716\n",
      "Iteration 685, loss = 0.05944862\n",
      "Iteration 686, loss = 0.05933669\n",
      "Iteration 687, loss = 0.05923535\n",
      "Iteration 688, loss = 0.05912289\n",
      "Iteration 689, loss = 0.05901540\n",
      "Iteration 690, loss = 0.05890896\n",
      "Iteration 691, loss = 0.05879971\n",
      "Iteration 692, loss = 0.05869834\n",
      "Iteration 693, loss = 0.05858581\n",
      "Iteration 694, loss = 0.05848410\n",
      "Iteration 695, loss = 0.05837475\n",
      "Iteration 696, loss = 0.05826973\n",
      "Iteration 697, loss = 0.05816688\n",
      "Iteration 698, loss = 0.05806432\n",
      "Iteration 699, loss = 0.05796757\n",
      "Iteration 700, loss = 0.05786252\n",
      "Iteration 701, loss = 0.05776347\n",
      "Iteration 702, loss = 0.05766331\n",
      "Iteration 703, loss = 0.05756797\n",
      "Iteration 704, loss = 0.05746077\n",
      "Iteration 705, loss = 0.05736170\n",
      "Iteration 706, loss = 0.05726793\n",
      "Iteration 707, loss = 0.05717066\n",
      "Iteration 708, loss = 0.05707192\n",
      "Iteration 709, loss = 0.05697576\n",
      "Iteration 710, loss = 0.05687853\n",
      "Iteration 711, loss = 0.05678453\n",
      "Iteration 712, loss = 0.05668769\n",
      "Iteration 713, loss = 0.05658858\n",
      "Iteration 714, loss = 0.05649581\n",
      "Iteration 715, loss = 0.05639350\n",
      "Iteration 716, loss = 0.05629851\n",
      "Iteration 717, loss = 0.05619764\n",
      "Iteration 718, loss = 0.05610036\n",
      "Iteration 719, loss = 0.05601001\n",
      "Iteration 720, loss = 0.05590562\n",
      "Iteration 721, loss = 0.05580785\n",
      "Iteration 722, loss = 0.05571187\n",
      "Iteration 723, loss = 0.05561457\n",
      "Iteration 724, loss = 0.05552131\n",
      "Iteration 725, loss = 0.05542761\n",
      "Iteration 726, loss = 0.05533062\n",
      "Iteration 727, loss = 0.05523774\n",
      "Iteration 728, loss = 0.05515043\n",
      "Iteration 729, loss = 0.05505180\n",
      "Iteration 730, loss = 0.05495938\n",
      "Iteration 731, loss = 0.05486658\n",
      "Iteration 732, loss = 0.05477303\n",
      "Iteration 733, loss = 0.05468536\n",
      "Iteration 734, loss = 0.05459269\n",
      "Iteration 735, loss = 0.05450321\n",
      "Iteration 736, loss = 0.05442054\n",
      "Iteration 737, loss = 0.05432982\n",
      "Iteration 738, loss = 0.05423938\n",
      "Iteration 739, loss = 0.05415132\n",
      "Iteration 740, loss = 0.05407025\n",
      "Iteration 741, loss = 0.05397661\n",
      "Iteration 742, loss = 0.05388454\n",
      "Iteration 743, loss = 0.05379963\n",
      "Iteration 744, loss = 0.05371004\n",
      "Iteration 745, loss = 0.05362337\n",
      "Iteration 746, loss = 0.05353701\n",
      "Iteration 747, loss = 0.05344679\n",
      "Iteration 748, loss = 0.05336278\n",
      "Iteration 749, loss = 0.05327330\n",
      "Iteration 750, loss = 0.05318921\n",
      "Iteration 751, loss = 0.05310085\n",
      "Iteration 752, loss = 0.05301357\n",
      "Iteration 753, loss = 0.05293019\n",
      "Iteration 754, loss = 0.05284647\n",
      "Iteration 755, loss = 0.05276274\n",
      "Iteration 756, loss = 0.05267994\n",
      "Iteration 757, loss = 0.05259613\n",
      "Iteration 758, loss = 0.05251693\n",
      "Iteration 759, loss = 0.05243637\n",
      "Iteration 760, loss = 0.05236199\n",
      "Iteration 761, loss = 0.05227570\n",
      "Iteration 762, loss = 0.05219870\n",
      "Iteration 763, loss = 0.05211626\n",
      "Iteration 764, loss = 0.05203554\n",
      "Iteration 765, loss = 0.05195432\n",
      "Iteration 766, loss = 0.05187562\n",
      "Iteration 767, loss = 0.05179395\n",
      "Iteration 768, loss = 0.05171664\n",
      "Iteration 769, loss = 0.05163492\n",
      "Iteration 770, loss = 0.05155442\n",
      "Iteration 771, loss = 0.05147876\n",
      "Iteration 772, loss = 0.05139572\n",
      "Iteration 773, loss = 0.05131464\n",
      "Iteration 774, loss = 0.05123627\n",
      "Iteration 775, loss = 0.05115379\n",
      "Iteration 776, loss = 0.05107620\n",
      "Iteration 777, loss = 0.05099917\n",
      "Iteration 778, loss = 0.05091991\n",
      "Iteration 779, loss = 0.05084595\n",
      "Iteration 780, loss = 0.05076701\n",
      "Iteration 781, loss = 0.05068422\n",
      "Iteration 782, loss = 0.05060717\n",
      "Iteration 783, loss = 0.05052739\n",
      "Iteration 784, loss = 0.05045017\n",
      "Iteration 785, loss = 0.05036761\n",
      "Iteration 786, loss = 0.05029339\n",
      "Iteration 787, loss = 0.05021375\n",
      "Iteration 788, loss = 0.05013611\n",
      "Iteration 789, loss = 0.05005718\n",
      "Iteration 790, loss = 0.04998352\n",
      "Iteration 791, loss = 0.04990617\n",
      "Iteration 792, loss = 0.04983163\n",
      "Iteration 793, loss = 0.04975793\n",
      "Iteration 794, loss = 0.04968057\n",
      "Iteration 795, loss = 0.04960622\n",
      "Iteration 796, loss = 0.04953423\n",
      "Iteration 797, loss = 0.04946434\n",
      "Iteration 798, loss = 0.04938818\n",
      "Iteration 799, loss = 0.04931606\n",
      "Iteration 800, loss = 0.04924534\n",
      "Iteration 801, loss = 0.04916717\n",
      "Iteration 802, loss = 0.04909388\n",
      "Iteration 803, loss = 0.04902171\n",
      "Iteration 804, loss = 0.04894931\n",
      "Iteration 805, loss = 0.04887930\n",
      "Iteration 806, loss = 0.04880837\n",
      "Iteration 807, loss = 0.04873857\n",
      "Iteration 808, loss = 0.04866867\n",
      "Iteration 809, loss = 0.04859959\n",
      "Iteration 810, loss = 0.04853056\n",
      "Iteration 811, loss = 0.04846475\n",
      "Iteration 812, loss = 0.04838766\n",
      "Iteration 813, loss = 0.04831968\n",
      "Iteration 814, loss = 0.04824862\n",
      "Iteration 815, loss = 0.04817873\n",
      "Iteration 816, loss = 0.04810523\n",
      "Iteration 817, loss = 0.04803494\n",
      "Iteration 818, loss = 0.04796824\n",
      "Iteration 819, loss = 0.04789210\n",
      "Iteration 820, loss = 0.04782458\n",
      "Iteration 821, loss = 0.04775088\n",
      "Iteration 822, loss = 0.04768300\n",
      "Iteration 823, loss = 0.04761408\n",
      "Iteration 824, loss = 0.04754576\n",
      "Iteration 825, loss = 0.04747370\n",
      "Iteration 826, loss = 0.04740547\n",
      "Iteration 827, loss = 0.04734239\n",
      "Iteration 828, loss = 0.04726554\n",
      "Iteration 829, loss = 0.04720235\n",
      "Iteration 830, loss = 0.04713420\n",
      "Iteration 831, loss = 0.04706825\n",
      "Iteration 832, loss = 0.04700376\n",
      "Iteration 833, loss = 0.04693945\n",
      "Iteration 834, loss = 0.04687330\n",
      "Iteration 835, loss = 0.04680659\n",
      "Iteration 836, loss = 0.04674212\n",
      "Iteration 837, loss = 0.04667786\n",
      "Iteration 838, loss = 0.04661079\n",
      "Iteration 839, loss = 0.04654487\n",
      "Iteration 840, loss = 0.04648212\n",
      "Iteration 841, loss = 0.04641612\n",
      "Iteration 842, loss = 0.04635153\n",
      "Iteration 843, loss = 0.04628735\n",
      "Iteration 844, loss = 0.04622403\n",
      "Iteration 845, loss = 0.04616137\n",
      "Iteration 846, loss = 0.04609793\n",
      "Iteration 847, loss = 0.04603750\n",
      "Iteration 848, loss = 0.04597440\n",
      "Iteration 849, loss = 0.04590974\n",
      "Iteration 850, loss = 0.04585314\n",
      "Iteration 851, loss = 0.04578715\n",
      "Iteration 852, loss = 0.04572479\n",
      "Iteration 853, loss = 0.04566300\n",
      "Iteration 854, loss = 0.04560065\n",
      "Iteration 855, loss = 0.04553867\n",
      "Iteration 856, loss = 0.04547464\n",
      "Iteration 857, loss = 0.04541755\n",
      "Iteration 858, loss = 0.04535489\n",
      "Iteration 859, loss = 0.04529626\n",
      "Iteration 860, loss = 0.04523463\n",
      "Iteration 861, loss = 0.04517183\n",
      "Iteration 862, loss = 0.04510704\n",
      "Iteration 863, loss = 0.04504762\n",
      "Iteration 864, loss = 0.04498407\n",
      "Iteration 865, loss = 0.04491965\n",
      "Iteration 866, loss = 0.04486132\n",
      "Iteration 867, loss = 0.04480027\n",
      "Iteration 868, loss = 0.04474038\n",
      "Iteration 869, loss = 0.04468156\n",
      "Iteration 870, loss = 0.04462583\n",
      "Iteration 871, loss = 0.04456976\n",
      "Iteration 872, loss = 0.04451201\n",
      "Iteration 873, loss = 0.04444977\n",
      "Iteration 874, loss = 0.04439257\n",
      "Iteration 875, loss = 0.04433488\n",
      "Iteration 876, loss = 0.04427395\n",
      "Iteration 877, loss = 0.04422423\n",
      "Iteration 878, loss = 0.04416002\n",
      "Iteration 879, loss = 0.04410099\n",
      "Iteration 880, loss = 0.04404192\n",
      "Iteration 881, loss = 0.04398802\n",
      "Iteration 882, loss = 0.04392735\n",
      "Iteration 883, loss = 0.04386983\n",
      "Iteration 884, loss = 0.04381006\n",
      "Iteration 885, loss = 0.04375216\n",
      "Iteration 886, loss = 0.04369388\n",
      "Iteration 887, loss = 0.04363764\n",
      "Iteration 888, loss = 0.04358096\n",
      "Iteration 889, loss = 0.04352113\n",
      "Iteration 890, loss = 0.04346227\n",
      "Iteration 891, loss = 0.04340492\n",
      "Iteration 892, loss = 0.04334609\n",
      "Iteration 893, loss = 0.04328768\n",
      "Iteration 894, loss = 0.04323183\n",
      "Iteration 895, loss = 0.04317023\n",
      "Iteration 896, loss = 0.04311297\n",
      "Iteration 897, loss = 0.04305734\n",
      "Iteration 898, loss = 0.04299790\n",
      "Iteration 899, loss = 0.04294100\n",
      "Iteration 900, loss = 0.04288358\n",
      "Iteration 901, loss = 0.04282936\n",
      "Iteration 902, loss = 0.04277351\n",
      "Iteration 903, loss = 0.04271794\n",
      "Iteration 904, loss = 0.04266611\n",
      "Iteration 905, loss = 0.04260467\n",
      "Iteration 906, loss = 0.04254972\n",
      "Iteration 907, loss = 0.04249306\n",
      "Iteration 908, loss = 0.04243931\n",
      "Iteration 909, loss = 0.04238494\n",
      "Iteration 910, loss = 0.04233129\n",
      "Iteration 911, loss = 0.04227678\n",
      "Iteration 912, loss = 0.04222521\n",
      "Iteration 913, loss = 0.04217102\n",
      "Iteration 914, loss = 0.04211796\n",
      "Iteration 915, loss = 0.04206869\n",
      "Iteration 916, loss = 0.04201391\n",
      "Iteration 917, loss = 0.04196330\n",
      "Iteration 918, loss = 0.04191099\n",
      "Iteration 919, loss = 0.04185591\n",
      "Iteration 920, loss = 0.04180439\n",
      "Iteration 921, loss = 0.04175158\n",
      "Iteration 922, loss = 0.04169600\n",
      "Iteration 923, loss = 0.04164291\n",
      "Iteration 924, loss = 0.04159110\n",
      "Iteration 925, loss = 0.04153746\n",
      "Iteration 926, loss = 0.04148309\n",
      "Iteration 927, loss = 0.04143081\n",
      "Iteration 928, loss = 0.04137799\n",
      "Iteration 929, loss = 0.04132845\n",
      "Iteration 930, loss = 0.04127275\n",
      "Iteration 931, loss = 0.04121885\n",
      "Iteration 932, loss = 0.04116489\n",
      "Iteration 933, loss = 0.04111284\n",
      "Iteration 934, loss = 0.04106329\n",
      "Iteration 935, loss = 0.04101305\n",
      "Iteration 936, loss = 0.04096208\n",
      "Iteration 937, loss = 0.04091687\n",
      "Iteration 938, loss = 0.04086551\n",
      "Iteration 939, loss = 0.04081353\n",
      "Iteration 940, loss = 0.04076341\n",
      "Iteration 941, loss = 0.04070906\n",
      "Iteration 942, loss = 0.04066067\n",
      "Iteration 943, loss = 0.04060822\n",
      "Iteration 944, loss = 0.04056143\n",
      "Iteration 945, loss = 0.04050730\n",
      "Iteration 946, loss = 0.04045744\n",
      "Iteration 947, loss = 0.04041125\n",
      "Iteration 948, loss = 0.04035932\n",
      "Iteration 949, loss = 0.04030816\n",
      "Iteration 950, loss = 0.04025792\n",
      "Iteration 951, loss = 0.04020312\n",
      "Iteration 952, loss = 0.04015241\n",
      "Iteration 953, loss = 0.04010123\n",
      "Iteration 954, loss = 0.04005127\n",
      "Iteration 955, loss = 0.04000115\n",
      "Iteration 956, loss = 0.03995408\n",
      "Iteration 957, loss = 0.03990352\n",
      "Iteration 958, loss = 0.03985504\n",
      "Iteration 959, loss = 0.03980684\n",
      "Iteration 960, loss = 0.03976094\n",
      "Iteration 961, loss = 0.03970963\n",
      "Iteration 962, loss = 0.03966203\n",
      "Iteration 963, loss = 0.03961460\n",
      "Iteration 964, loss = 0.03956778\n",
      "Iteration 965, loss = 0.03952035\n",
      "Iteration 966, loss = 0.03947275\n",
      "Iteration 967, loss = 0.03942556\n",
      "Iteration 968, loss = 0.03937971\n",
      "Iteration 969, loss = 0.03932918\n",
      "Iteration 970, loss = 0.03928234\n",
      "Iteration 971, loss = 0.03923669\n",
      "Iteration 972, loss = 0.03918674\n",
      "Iteration 973, loss = 0.03913820\n",
      "Iteration 974, loss = 0.03909331\n",
      "Iteration 975, loss = 0.03904750\n",
      "Iteration 976, loss = 0.03899976\n",
      "Iteration 977, loss = 0.03895250\n",
      "Iteration 978, loss = 0.03890642\n",
      "Iteration 979, loss = 0.03885999\n",
      "Iteration 980, loss = 0.03881565\n",
      "Iteration 981, loss = 0.03877065\n",
      "Iteration 982, loss = 0.03872367\n",
      "Iteration 983, loss = 0.03867836\n",
      "Iteration 984, loss = 0.03863369\n",
      "Iteration 985, loss = 0.03858913\n",
      "Iteration 986, loss = 0.03854246\n",
      "Iteration 987, loss = 0.03849710\n",
      "Iteration 988, loss = 0.03845337\n",
      "Iteration 989, loss = 0.03840988\n",
      "Iteration 990, loss = 0.03837007\n",
      "Iteration 991, loss = 0.03832613\n",
      "Iteration 992, loss = 0.03827795\n",
      "Iteration 993, loss = 0.03823410\n",
      "Iteration 994, loss = 0.03818803\n",
      "Iteration 995, loss = 0.03814044\n",
      "Iteration 996, loss = 0.03809681\n",
      "Iteration 997, loss = 0.03805269\n",
      "Iteration 998, loss = 0.03800787\n",
      "Iteration 999, loss = 0.03796226\n",
      "Iteration 1000, loss = 0.03791599\n",
      "Iteration 1001, loss = 0.03787624\n",
      "Iteration 1002, loss = 0.03782880\n",
      "Iteration 1003, loss = 0.03778525\n",
      "Iteration 1004, loss = 0.03774283\n",
      "Iteration 1005, loss = 0.03770076\n",
      "Iteration 1006, loss = 0.03765914\n",
      "Iteration 1007, loss = 0.03761813\n",
      "Iteration 1008, loss = 0.03757357\n",
      "Iteration 1009, loss = 0.03753106\n",
      "Iteration 1010, loss = 0.03748876\n",
      "Iteration 1011, loss = 0.03744512\n",
      "Iteration 1012, loss = 0.03740492\n",
      "Iteration 1013, loss = 0.03735794\n",
      "Iteration 1014, loss = 0.03731888\n",
      "Iteration 1015, loss = 0.03727764\n",
      "Iteration 1016, loss = 0.03723656\n",
      "Iteration 1017, loss = 0.03719480\n",
      "Iteration 1018, loss = 0.03715606\n",
      "Iteration 1019, loss = 0.03711432\n",
      "Iteration 1020, loss = 0.03707440\n",
      "Iteration 1021, loss = 0.03703415\n",
      "Iteration 1022, loss = 0.03699532\n",
      "Iteration 1023, loss = 0.03694936\n",
      "Iteration 1024, loss = 0.03690732\n",
      "Iteration 1025, loss = 0.03686434\n",
      "Iteration 1026, loss = 0.03682200\n",
      "Iteration 1027, loss = 0.03678005\n",
      "Iteration 1028, loss = 0.03673706\n",
      "Iteration 1029, loss = 0.03670060\n",
      "Iteration 1030, loss = 0.03665630\n",
      "Iteration 1031, loss = 0.03661492\n",
      "Iteration 1032, loss = 0.03657420\n",
      "Iteration 1033, loss = 0.03653447\n",
      "Iteration 1034, loss = 0.03649239\n",
      "Iteration 1035, loss = 0.03645053\n",
      "Iteration 1036, loss = 0.03640985\n",
      "Iteration 1037, loss = 0.03637067\n",
      "Iteration 1038, loss = 0.03632882\n",
      "Iteration 1039, loss = 0.03629186\n",
      "Iteration 1040, loss = 0.03624545\n",
      "Iteration 1041, loss = 0.03620668\n",
      "Iteration 1042, loss = 0.03616242\n",
      "Iteration 1043, loss = 0.03612383\n",
      "Iteration 1044, loss = 0.03608249\n",
      "Iteration 1045, loss = 0.03604245\n",
      "Iteration 1046, loss = 0.03600437\n",
      "Iteration 1047, loss = 0.03596413\n",
      "Iteration 1048, loss = 0.03592496\n",
      "Iteration 1049, loss = 0.03588650\n",
      "Iteration 1050, loss = 0.03584659\n",
      "Iteration 1051, loss = 0.03580584\n",
      "Iteration 1052, loss = 0.03576660\n",
      "Iteration 1053, loss = 0.03572939\n",
      "Iteration 1054, loss = 0.03568928\n",
      "Iteration 1055, loss = 0.03564988\n",
      "Iteration 1056, loss = 0.03561029\n",
      "Iteration 1057, loss = 0.03557336\n",
      "Iteration 1058, loss = 0.03553561\n",
      "Iteration 1059, loss = 0.03549933\n",
      "Iteration 1060, loss = 0.03546077\n",
      "Iteration 1061, loss = 0.03542096\n",
      "Iteration 1062, loss = 0.03538014\n",
      "Iteration 1063, loss = 0.03534222\n",
      "Iteration 1064, loss = 0.03530298\n",
      "Iteration 1065, loss = 0.03526514\n",
      "Iteration 1066, loss = 0.03522552\n",
      "Iteration 1067, loss = 0.03518546\n",
      "Iteration 1068, loss = 0.03515068\n",
      "Iteration 1069, loss = 0.03511382\n",
      "Iteration 1070, loss = 0.03507658\n",
      "Iteration 1071, loss = 0.03504083\n",
      "Iteration 1072, loss = 0.03500476\n",
      "Iteration 1073, loss = 0.03496609\n",
      "Iteration 1074, loss = 0.03493041\n",
      "Iteration 1075, loss = 0.03489360\n",
      "Iteration 1076, loss = 0.03485626\n",
      "Iteration 1077, loss = 0.03482217\n",
      "Iteration 1078, loss = 0.03478304\n",
      "Iteration 1079, loss = 0.03474487\n",
      "Iteration 1080, loss = 0.03470688\n",
      "Iteration 1081, loss = 0.03466982\n",
      "Iteration 1082, loss = 0.03463361\n",
      "Iteration 1083, loss = 0.03459067\n",
      "Iteration 1084, loss = 0.03455416\n",
      "Iteration 1085, loss = 0.03451746\n",
      "Iteration 1086, loss = 0.03447986\n",
      "Iteration 1087, loss = 0.03444523\n",
      "Iteration 1088, loss = 0.03440995\n",
      "Iteration 1089, loss = 0.03437277\n",
      "Iteration 1090, loss = 0.03433672\n",
      "Iteration 1091, loss = 0.03430188\n",
      "Iteration 1092, loss = 0.03426677\n",
      "Iteration 1093, loss = 0.03423085\n",
      "Iteration 1094, loss = 0.03419716\n",
      "Iteration 1095, loss = 0.03415903\n",
      "Iteration 1096, loss = 0.03412669\n",
      "Iteration 1097, loss = 0.03409005\n",
      "Iteration 1098, loss = 0.03405329\n",
      "Iteration 1099, loss = 0.03401511\n",
      "Iteration 1100, loss = 0.03398115\n",
      "Iteration 1101, loss = 0.03394434\n",
      "Iteration 1102, loss = 0.03390963\n",
      "Iteration 1103, loss = 0.03387570\n",
      "Iteration 1104, loss = 0.03384013\n",
      "Iteration 1105, loss = 0.03380860\n",
      "Iteration 1106, loss = 0.03377420\n",
      "Iteration 1107, loss = 0.03374011\n",
      "Iteration 1108, loss = 0.03370531\n",
      "Iteration 1109, loss = 0.03367380\n",
      "Iteration 1110, loss = 0.03364162\n",
      "Iteration 1111, loss = 0.03360627\n",
      "Iteration 1112, loss = 0.03357036\n",
      "Iteration 1113, loss = 0.03353657\n",
      "Iteration 1114, loss = 0.03349949\n",
      "Iteration 1115, loss = 0.03346698\n",
      "Iteration 1116, loss = 0.03343106\n",
      "Iteration 1117, loss = 0.03339205\n",
      "Iteration 1118, loss = 0.03336147\n",
      "Iteration 1119, loss = 0.03332513\n",
      "Iteration 1120, loss = 0.03329135\n",
      "Iteration 1121, loss = 0.03325701\n",
      "Iteration 1122, loss = 0.03322563\n",
      "Iteration 1123, loss = 0.03319146\n",
      "Iteration 1124, loss = 0.03315615\n",
      "Iteration 1125, loss = 0.03312428\n",
      "Iteration 1126, loss = 0.03309011\n",
      "Iteration 1127, loss = 0.03305744\n",
      "Iteration 1128, loss = 0.03302321\n",
      "Iteration 1129, loss = 0.03299141\n",
      "Iteration 1130, loss = 0.03295738\n",
      "Iteration 1131, loss = 0.03292549\n",
      "Iteration 1132, loss = 0.03289395\n",
      "Iteration 1133, loss = 0.03285954\n",
      "Iteration 1134, loss = 0.03282834\n",
      "Iteration 1135, loss = 0.03279362\n",
      "Iteration 1136, loss = 0.03276095\n",
      "Iteration 1137, loss = 0.03272665\n",
      "Iteration 1138, loss = 0.03269470\n",
      "Iteration 1139, loss = 0.03266407\n",
      "Iteration 1140, loss = 0.03263284\n",
      "Iteration 1141, loss = 0.03260069\n",
      "Iteration 1142, loss = 0.03256811\n",
      "Iteration 1143, loss = 0.03253319\n",
      "Iteration 1144, loss = 0.03250123\n",
      "Iteration 1145, loss = 0.03246990\n",
      "Iteration 1146, loss = 0.03244071\n",
      "Iteration 1147, loss = 0.03241113\n",
      "Iteration 1148, loss = 0.03237817\n",
      "Iteration 1149, loss = 0.03234656\n",
      "Iteration 1150, loss = 0.03231539\n",
      "Iteration 1151, loss = 0.03228488\n",
      "Iteration 1152, loss = 0.03225377\n",
      "Iteration 1153, loss = 0.03222263\n",
      "Iteration 1154, loss = 0.03219271\n",
      "Iteration 1155, loss = 0.03216258\n",
      "Iteration 1156, loss = 0.03213276\n",
      "Iteration 1157, loss = 0.03210322\n",
      "Iteration 1158, loss = 0.03207301\n",
      "Iteration 1159, loss = 0.03204444\n",
      "Iteration 1160, loss = 0.03201518\n",
      "Iteration 1161, loss = 0.03198794\n",
      "Iteration 1162, loss = 0.03195581\n",
      "Iteration 1163, loss = 0.03192637\n",
      "Iteration 1164, loss = 0.03189597\n",
      "Iteration 1165, loss = 0.03186724\n",
      "Iteration 1166, loss = 0.03183647\n",
      "Iteration 1167, loss = 0.03180652\n",
      "Iteration 1168, loss = 0.03177767\n",
      "Iteration 1169, loss = 0.03174913\n",
      "Iteration 1170, loss = 0.03171731\n",
      "Iteration 1171, loss = 0.03168809\n",
      "Iteration 1172, loss = 0.03165614\n",
      "Iteration 1173, loss = 0.03161996\n",
      "Iteration 1174, loss = 0.03158791\n",
      "Iteration 1175, loss = 0.03155588\n",
      "Iteration 1176, loss = 0.03152187\n",
      "Iteration 1177, loss = 0.03148994\n",
      "Iteration 1178, loss = 0.03145852\n",
      "Iteration 1179, loss = 0.03142595\n",
      "Iteration 1180, loss = 0.03139486\n",
      "Iteration 1181, loss = 0.03136331\n",
      "Iteration 1182, loss = 0.03133289\n",
      "Iteration 1183, loss = 0.03130217\n",
      "Iteration 1184, loss = 0.03127256\n",
      "Iteration 1185, loss = 0.03124263\n",
      "Iteration 1186, loss = 0.03121470\n",
      "Iteration 1187, loss = 0.03118456\n",
      "Iteration 1188, loss = 0.03115599\n",
      "Iteration 1189, loss = 0.03112739\n",
      "Iteration 1190, loss = 0.03109862\n",
      "Iteration 1191, loss = 0.03107366\n",
      "Iteration 1192, loss = 0.03104689\n",
      "Iteration 1193, loss = 0.03101549\n",
      "Iteration 1194, loss = 0.03098791\n",
      "Iteration 1195, loss = 0.03095690\n",
      "Iteration 1196, loss = 0.03092579\n",
      "Iteration 1197, loss = 0.03089630\n",
      "Iteration 1198, loss = 0.03086391\n",
      "Iteration 1199, loss = 0.03083480\n",
      "Iteration 1200, loss = 0.03080605\n",
      "Iteration 1201, loss = 0.03077605\n",
      "Iteration 1202, loss = 0.03074597\n",
      "Iteration 1203, loss = 0.03071690\n",
      "Iteration 1204, loss = 0.03068770\n",
      "Iteration 1205, loss = 0.03065524\n",
      "Iteration 1206, loss = 0.03062256\n",
      "Iteration 1207, loss = 0.03059148\n",
      "Iteration 1208, loss = 0.03056186\n",
      "Iteration 1209, loss = 0.03053182\n",
      "Iteration 1210, loss = 0.03050161\n",
      "Iteration 1211, loss = 0.03046830\n",
      "Iteration 1212, loss = 0.03044224\n",
      "Iteration 1213, loss = 0.03040939\n",
      "Iteration 1214, loss = 0.03038111\n",
      "Iteration 1215, loss = 0.03035190\n",
      "Iteration 1216, loss = 0.03032394\n",
      "Iteration 1217, loss = 0.03029045\n",
      "Iteration 1218, loss = 0.03026326\n",
      "Iteration 1219, loss = 0.03023256\n",
      "Iteration 1220, loss = 0.03020189\n",
      "Iteration 1221, loss = 0.03017518\n",
      "Iteration 1222, loss = 0.03014388\n",
      "Iteration 1223, loss = 0.03011337\n",
      "Iteration 1224, loss = 0.03008630\n",
      "Iteration 1225, loss = 0.03005301\n",
      "Iteration 1226, loss = 0.03002774\n",
      "Iteration 1227, loss = 0.02999942\n",
      "Iteration 1228, loss = 0.02996593\n",
      "Iteration 1229, loss = 0.02993603\n",
      "Iteration 1230, loss = 0.02990797\n",
      "Iteration 1231, loss = 0.02987847\n",
      "Iteration 1232, loss = 0.02984863\n",
      "Iteration 1233, loss = 0.02982033\n",
      "Iteration 1234, loss = 0.02979221\n",
      "Iteration 1235, loss = 0.02976505\n",
      "Iteration 1236, loss = 0.02973736\n",
      "Iteration 1237, loss = 0.02971369\n",
      "Iteration 1238, loss = 0.02968266\n",
      "Iteration 1239, loss = 0.02965354\n",
      "Iteration 1240, loss = 0.02962738\n",
      "Iteration 1241, loss = 0.02959948\n",
      "Iteration 1242, loss = 0.02956755\n",
      "Iteration 1243, loss = 0.02954516\n",
      "Iteration 1244, loss = 0.02951965\n",
      "Iteration 1245, loss = 0.02948737\n",
      "Iteration 1246, loss = 0.02945859\n",
      "Iteration 1247, loss = 0.02943162\n",
      "Iteration 1248, loss = 0.02940382\n",
      "Iteration 1249, loss = 0.02937607\n",
      "Iteration 1250, loss = 0.02935003\n",
      "Iteration 1251, loss = 0.02932089\n",
      "Iteration 1252, loss = 0.02929518\n",
      "Iteration 1253, loss = 0.02926788\n",
      "Iteration 1254, loss = 0.02924406\n",
      "Iteration 1255, loss = 0.02921333\n",
      "Iteration 1256, loss = 0.02918732\n",
      "Iteration 1257, loss = 0.02915770\n",
      "Iteration 1258, loss = 0.02912998\n",
      "Iteration 1259, loss = 0.02910714\n",
      "Iteration 1260, loss = 0.02907662\n",
      "Iteration 1261, loss = 0.02905173\n",
      "Iteration 1262, loss = 0.02902442\n",
      "Iteration 1263, loss = 0.02899795\n",
      "Iteration 1264, loss = 0.02897091\n",
      "Iteration 1265, loss = 0.02894511\n",
      "Iteration 1266, loss = 0.02891816\n",
      "Iteration 1267, loss = 0.02889256\n",
      "Iteration 1268, loss = 0.02886542\n",
      "Iteration 1269, loss = 0.02883775\n",
      "Iteration 1270, loss = 0.02881094\n",
      "Iteration 1271, loss = 0.02878244\n",
      "Iteration 1272, loss = 0.02875650\n",
      "Iteration 1273, loss = 0.02873085\n",
      "Iteration 1274, loss = 0.02870357\n",
      "Iteration 1275, loss = 0.02867880\n",
      "Iteration 1276, loss = 0.02865305\n",
      "Iteration 1277, loss = 0.02862761\n",
      "Iteration 1278, loss = 0.02860462\n",
      "Iteration 1279, loss = 0.02857825\n",
      "Iteration 1280, loss = 0.02855367\n",
      "Iteration 1281, loss = 0.02852989\n",
      "Iteration 1282, loss = 0.02850489\n",
      "Iteration 1283, loss = 0.02848021\n",
      "Iteration 1284, loss = 0.02845458\n",
      "Iteration 1285, loss = 0.02843003\n",
      "Iteration 1286, loss = 0.02840860\n",
      "Iteration 1287, loss = 0.02838235\n",
      "Iteration 1288, loss = 0.02835530\n",
      "Iteration 1289, loss = 0.02833147\n",
      "Iteration 1290, loss = 0.02830592\n",
      "Iteration 1291, loss = 0.02828135\n",
      "Iteration 1292, loss = 0.02825464\n",
      "Iteration 1293, loss = 0.02822887\n",
      "Iteration 1294, loss = 0.02820385\n",
      "Iteration 1295, loss = 0.02817433\n",
      "Iteration 1296, loss = 0.02815114\n",
      "Iteration 1297, loss = 0.02811991\n",
      "Iteration 1298, loss = 0.02809413\n",
      "Iteration 1299, loss = 0.02806581\n",
      "Iteration 1300, loss = 0.02803886\n",
      "Iteration 1301, loss = 0.02801215\n",
      "Iteration 1302, loss = 0.02798593\n",
      "Iteration 1303, loss = 0.02796059\n",
      "Iteration 1304, loss = 0.02793421\n",
      "Iteration 1305, loss = 0.02790737\n",
      "Iteration 1306, loss = 0.02788153\n",
      "Iteration 1307, loss = 0.02785528\n",
      "Iteration 1308, loss = 0.02782965\n",
      "Iteration 1309, loss = 0.02780553\n",
      "Iteration 1310, loss = 0.02778033\n",
      "Iteration 1311, loss = 0.02775539\n",
      "Iteration 1312, loss = 0.02773307\n",
      "Iteration 1313, loss = 0.02770609\n",
      "Iteration 1314, loss = 0.02767922\n",
      "Iteration 1315, loss = 0.02765568\n",
      "Iteration 1316, loss = 0.02763102\n",
      "Iteration 1317, loss = 0.02760592\n",
      "Iteration 1318, loss = 0.02758246\n",
      "Iteration 1319, loss = 0.02755997\n",
      "Iteration 1320, loss = 0.02753124\n",
      "Iteration 1321, loss = 0.02750645\n",
      "Iteration 1322, loss = 0.02747960\n",
      "Iteration 1323, loss = 0.02745824\n",
      "Iteration 1324, loss = 0.02743119\n",
      "Iteration 1325, loss = 0.02740717\n",
      "Iteration 1326, loss = 0.02738342\n",
      "Iteration 1327, loss = 0.02736272\n",
      "Iteration 1328, loss = 0.02733399\n",
      "Iteration 1329, loss = 0.02730806\n",
      "Iteration 1330, loss = 0.02728496\n",
      "Iteration 1331, loss = 0.02726626\n",
      "Iteration 1332, loss = 0.02723542\n",
      "Iteration 1333, loss = 0.02720759\n",
      "Iteration 1334, loss = 0.02718801\n",
      "Iteration 1335, loss = 0.02716251\n",
      "Iteration 1336, loss = 0.02713579\n",
      "Iteration 1337, loss = 0.02711417\n",
      "Iteration 1338, loss = 0.02708747\n",
      "Iteration 1339, loss = 0.02706441\n",
      "Iteration 1340, loss = 0.02704077\n",
      "Iteration 1341, loss = 0.02701659\n",
      "Iteration 1342, loss = 0.02699272\n",
      "Iteration 1343, loss = 0.02696914\n",
      "Iteration 1344, loss = 0.02695111\n",
      "Iteration 1345, loss = 0.02692561\n",
      "Iteration 1346, loss = 0.02690219\n",
      "Iteration 1347, loss = 0.02688035\n",
      "Iteration 1348, loss = 0.02685779\n",
      "Iteration 1349, loss = 0.02683553\n",
      "Iteration 1350, loss = 0.02681309\n",
      "Iteration 1351, loss = 0.02678914\n",
      "Iteration 1352, loss = 0.02676567\n",
      "Iteration 1353, loss = 0.02674174\n",
      "Iteration 1354, loss = 0.02671897\n",
      "Iteration 1355, loss = 0.02669563\n",
      "Iteration 1356, loss = 0.02667342\n",
      "Iteration 1357, loss = 0.02665079\n",
      "Iteration 1358, loss = 0.02662886\n",
      "Iteration 1359, loss = 0.02660975\n",
      "Iteration 1360, loss = 0.02658318\n",
      "Iteration 1361, loss = 0.02656115\n",
      "Iteration 1362, loss = 0.02653779\n",
      "Iteration 1363, loss = 0.02651454\n",
      "Iteration 1364, loss = 0.02649010\n",
      "Iteration 1365, loss = 0.02646670\n",
      "Iteration 1366, loss = 0.02644510\n",
      "Iteration 1367, loss = 0.02642167\n",
      "Iteration 1368, loss = 0.02639845\n",
      "Iteration 1369, loss = 0.02637594\n",
      "Iteration 1370, loss = 0.02635341\n",
      "Iteration 1371, loss = 0.02633149\n",
      "Iteration 1372, loss = 0.02630822\n",
      "Iteration 1373, loss = 0.02628664\n",
      "Iteration 1374, loss = 0.02626392\n",
      "Iteration 1375, loss = 0.02624167\n",
      "Iteration 1376, loss = 0.02622014\n",
      "Iteration 1377, loss = 0.02619912\n",
      "Iteration 1378, loss = 0.02618118\n",
      "Iteration 1379, loss = 0.02615685\n",
      "Iteration 1380, loss = 0.02613430\n",
      "Iteration 1381, loss = 0.02611300\n",
      "Iteration 1382, loss = 0.02609196\n",
      "Iteration 1383, loss = 0.02606849\n",
      "Iteration 1384, loss = 0.02604565\n",
      "Iteration 1385, loss = 0.02602123\n",
      "Iteration 1386, loss = 0.02599685\n",
      "Iteration 1387, loss = 0.02597461\n",
      "Iteration 1388, loss = 0.02595064\n",
      "Iteration 1389, loss = 0.02592882\n",
      "Iteration 1390, loss = 0.02590597\n",
      "Iteration 1391, loss = 0.02588316\n",
      "Iteration 1392, loss = 0.02586080\n",
      "Iteration 1393, loss = 0.02583730\n",
      "Iteration 1394, loss = 0.02581672\n",
      "Iteration 1395, loss = 0.02579586\n",
      "Iteration 1396, loss = 0.02577628\n",
      "Iteration 1397, loss = 0.02575474\n",
      "Iteration 1398, loss = 0.02573172\n",
      "Iteration 1399, loss = 0.02571051\n",
      "Iteration 1400, loss = 0.02568896\n",
      "Iteration 1401, loss = 0.02566967\n",
      "Iteration 1402, loss = 0.02564489\n",
      "Iteration 1403, loss = 0.02562322\n",
      "Iteration 1404, loss = 0.02560105\n",
      "Iteration 1405, loss = 0.02558076\n",
      "Iteration 1406, loss = 0.02555953\n",
      "Iteration 1407, loss = 0.02553873\n",
      "Iteration 1408, loss = 0.02551927\n",
      "Iteration 1409, loss = 0.02549986\n",
      "Iteration 1410, loss = 0.02547670\n",
      "Iteration 1411, loss = 0.02545656\n",
      "Iteration 1412, loss = 0.02543611\n",
      "Iteration 1413, loss = 0.02541724\n",
      "Iteration 1414, loss = 0.02539631\n",
      "Iteration 1415, loss = 0.02537529\n",
      "Iteration 1416, loss = 0.02535553\n",
      "Iteration 1417, loss = 0.02533486\n",
      "Iteration 1418, loss = 0.02531459\n",
      "Iteration 1419, loss = 0.02529437\n",
      "Iteration 1420, loss = 0.02527508\n",
      "Iteration 1421, loss = 0.02525089\n",
      "Iteration 1422, loss = 0.02522999\n",
      "Iteration 1423, loss = 0.02520953\n",
      "Iteration 1424, loss = 0.02518674\n",
      "Iteration 1425, loss = 0.02516637\n",
      "Iteration 1426, loss = 0.02514632\n",
      "Iteration 1427, loss = 0.02512612\n",
      "Iteration 1428, loss = 0.02510915\n",
      "Iteration 1429, loss = 0.02508522\n",
      "Iteration 1430, loss = 0.02506186\n",
      "Iteration 1431, loss = 0.02504247\n",
      "Iteration 1432, loss = 0.02501958\n",
      "Iteration 1433, loss = 0.02499872\n",
      "Iteration 1434, loss = 0.02497633\n",
      "Iteration 1435, loss = 0.02496029\n",
      "Iteration 1436, loss = 0.02493632\n",
      "Iteration 1437, loss = 0.02491526\n",
      "Iteration 1438, loss = 0.02489668\n",
      "Iteration 1439, loss = 0.02487445\n",
      "Iteration 1440, loss = 0.02485874\n",
      "Iteration 1441, loss = 0.02483448\n",
      "Iteration 1442, loss = 0.02481332\n",
      "Iteration 1443, loss = 0.02479307\n",
      "Iteration 1444, loss = 0.02477437\n",
      "Iteration 1445, loss = 0.02475425\n",
      "Iteration 1446, loss = 0.02473587\n",
      "Iteration 1447, loss = 0.02471291\n",
      "Iteration 1448, loss = 0.02469391\n",
      "Iteration 1449, loss = 0.02467515\n",
      "Iteration 1450, loss = 0.02465526\n",
      "Iteration 1451, loss = 0.02463624\n",
      "Iteration 1452, loss = 0.02461593\n",
      "Iteration 1453, loss = 0.02459696\n",
      "Iteration 1454, loss = 0.02457792\n",
      "Iteration 1455, loss = 0.02455765\n",
      "Iteration 1456, loss = 0.02453759\n",
      "Iteration 1457, loss = 0.02451831\n",
      "Iteration 1458, loss = 0.02449857\n",
      "Iteration 1459, loss = 0.02447998\n",
      "Iteration 1460, loss = 0.02445861\n",
      "Iteration 1461, loss = 0.02443858\n",
      "Iteration 1462, loss = 0.02441856\n",
      "Iteration 1463, loss = 0.02440052\n",
      "Iteration 1464, loss = 0.02437874\n",
      "Iteration 1465, loss = 0.02435816\n",
      "Iteration 1466, loss = 0.02433808\n",
      "Iteration 1467, loss = 0.02431843\n",
      "Iteration 1468, loss = 0.02429946\n",
      "Iteration 1469, loss = 0.02428007\n",
      "Iteration 1470, loss = 0.02425950\n",
      "Iteration 1471, loss = 0.02424148\n",
      "Iteration 1472, loss = 0.02421849\n",
      "Iteration 1473, loss = 0.02419907\n",
      "Iteration 1474, loss = 0.02418072\n",
      "Iteration 1475, loss = 0.02416416\n",
      "Iteration 1476, loss = 0.02414208\n",
      "Iteration 1477, loss = 0.02412328\n",
      "Iteration 1478, loss = 0.02410431\n",
      "Iteration 1479, loss = 0.02408476\n",
      "Iteration 1480, loss = 0.02406918\n",
      "Iteration 1481, loss = 0.02404870\n",
      "Iteration 1482, loss = 0.02403001\n",
      "Iteration 1483, loss = 0.02400859\n",
      "Iteration 1484, loss = 0.02398867\n",
      "Iteration 1485, loss = 0.02397129\n",
      "Iteration 1486, loss = 0.02395153\n",
      "Iteration 1487, loss = 0.02393275\n",
      "Iteration 1488, loss = 0.02391240\n",
      "Iteration 1489, loss = 0.02389384\n",
      "Iteration 1490, loss = 0.02387534\n",
      "Iteration 1491, loss = 0.02385785\n",
      "Iteration 1492, loss = 0.02383771\n",
      "Iteration 1493, loss = 0.02381948\n",
      "Iteration 1494, loss = 0.02380080\n",
      "Iteration 1495, loss = 0.02378274\n",
      "Iteration 1496, loss = 0.02376373\n",
      "Iteration 1497, loss = 0.02374519\n",
      "Iteration 1498, loss = 0.02372567\n",
      "Iteration 1499, loss = 0.02370675\n",
      "Iteration 1500, loss = 0.02368653\n",
      "Iteration 1501, loss = 0.02366838\n",
      "Iteration 1502, loss = 0.02364971\n",
      "Iteration 1503, loss = 0.02363136\n",
      "Iteration 1504, loss = 0.02361140\n",
      "Iteration 1505, loss = 0.02359355\n",
      "Iteration 1506, loss = 0.02357489\n",
      "Iteration 1507, loss = 0.02355503\n",
      "Iteration 1508, loss = 0.02353374\n",
      "Iteration 1509, loss = 0.02351588\n",
      "Iteration 1510, loss = 0.02349654\n",
      "Iteration 1511, loss = 0.02347511\n",
      "Iteration 1512, loss = 0.02345899\n",
      "Iteration 1513, loss = 0.02343995\n",
      "Iteration 1514, loss = 0.02342130\n",
      "Iteration 1515, loss = 0.02340497\n",
      "Iteration 1516, loss = 0.02338551\n",
      "Iteration 1517, loss = 0.02336794\n",
      "Iteration 1518, loss = 0.02334970\n",
      "Iteration 1519, loss = 0.02333244\n",
      "Iteration 1520, loss = 0.02331436\n",
      "Iteration 1521, loss = 0.02329742\n",
      "Iteration 1522, loss = 0.02327951\n",
      "Iteration 1523, loss = 0.02326083\n",
      "Iteration 1524, loss = 0.02324273\n",
      "Iteration 1525, loss = 0.02322372\n",
      "Iteration 1526, loss = 0.02320442\n",
      "Iteration 1527, loss = 0.02318504\n",
      "Iteration 1528, loss = 0.02316922\n",
      "Iteration 1529, loss = 0.02314727\n",
      "Iteration 1530, loss = 0.02313109\n",
      "Iteration 1531, loss = 0.02311117\n",
      "Iteration 1532, loss = 0.02309438\n",
      "Iteration 1533, loss = 0.02307783\n",
      "Iteration 1534, loss = 0.02305865\n",
      "Iteration 1535, loss = 0.02304253\n",
      "Iteration 1536, loss = 0.02302469\n",
      "Iteration 1537, loss = 0.02300655\n",
      "Iteration 1538, loss = 0.02299049\n",
      "Iteration 1539, loss = 0.02297330\n",
      "Iteration 1540, loss = 0.02295298\n",
      "Iteration 1541, loss = 0.02293547\n",
      "Iteration 1542, loss = 0.02291816\n",
      "Iteration 1543, loss = 0.02290048\n",
      "Iteration 1544, loss = 0.02288449\n",
      "Iteration 1545, loss = 0.02286656\n",
      "Iteration 1546, loss = 0.02284948\n",
      "Iteration 1547, loss = 0.02283570\n",
      "Iteration 1548, loss = 0.02281600\n",
      "Iteration 1549, loss = 0.02279840\n",
      "Iteration 1550, loss = 0.02278179\n",
      "Iteration 1551, loss = 0.02276531\n",
      "Iteration 1552, loss = 0.02274767\n",
      "Iteration 1553, loss = 0.02273109\n",
      "Iteration 1554, loss = 0.02271223\n",
      "Iteration 1555, loss = 0.02269541\n",
      "Iteration 1556, loss = 0.02267838\n",
      "Iteration 1557, loss = 0.02266145\n",
      "Iteration 1558, loss = 0.02264351\n",
      "Iteration 1559, loss = 0.02262658\n",
      "Iteration 1560, loss = 0.02261131\n",
      "Iteration 1561, loss = 0.02259314\n",
      "Iteration 1562, loss = 0.02257517\n",
      "Iteration 1563, loss = 0.02255805\n",
      "Iteration 1564, loss = 0.02254128\n",
      "Iteration 1565, loss = 0.02252611\n",
      "Iteration 1566, loss = 0.02250975\n",
      "Iteration 1567, loss = 0.02249203\n",
      "Iteration 1568, loss = 0.02247833\n",
      "Iteration 1569, loss = 0.02245891\n",
      "Iteration 1570, loss = 0.02244391\n",
      "Iteration 1571, loss = 0.02242592\n",
      "Iteration 1572, loss = 0.02240836\n",
      "Iteration 1573, loss = 0.02238998\n",
      "Iteration 1574, loss = 0.02237116\n",
      "Iteration 1575, loss = 0.02235840\n",
      "Iteration 1576, loss = 0.02233687\n",
      "Iteration 1577, loss = 0.02232045\n",
      "Iteration 1578, loss = 0.02230231\n",
      "Iteration 1579, loss = 0.02228507\n",
      "Iteration 1580, loss = 0.02226759\n",
      "Iteration 1581, loss = 0.02225069\n",
      "Iteration 1582, loss = 0.02223509\n",
      "Iteration 1583, loss = 0.02221803\n",
      "Iteration 1584, loss = 0.02220134\n",
      "Iteration 1585, loss = 0.02218602\n",
      "Iteration 1586, loss = 0.02216965\n",
      "Iteration 1587, loss = 0.02215485\n",
      "Iteration 1588, loss = 0.02213752\n",
      "Iteration 1589, loss = 0.02212149\n",
      "Iteration 1590, loss = 0.02210580\n",
      "Iteration 1591, loss = 0.02209019\n",
      "Iteration 1592, loss = 0.02207249\n",
      "Iteration 1593, loss = 0.02205603\n",
      "Iteration 1594, loss = 0.02204009\n",
      "Iteration 1595, loss = 0.02202378\n",
      "Iteration 1596, loss = 0.02201000\n",
      "Iteration 1597, loss = 0.02199150\n",
      "Iteration 1598, loss = 0.02197369\n",
      "Iteration 1599, loss = 0.02195638\n",
      "Iteration 1600, loss = 0.02194156\n",
      "Iteration 1601, loss = 0.02192277\n",
      "Iteration 1602, loss = 0.02190631\n",
      "Iteration 1603, loss = 0.02188938\n",
      "Iteration 1604, loss = 0.02187271\n",
      "Iteration 1605, loss = 0.02185585\n",
      "Iteration 1606, loss = 0.02184116\n",
      "Iteration 1607, loss = 0.02182380\n",
      "Iteration 1608, loss = 0.02180485\n",
      "Iteration 1609, loss = 0.02178759\n",
      "Iteration 1610, loss = 0.02177159\n",
      "Iteration 1611, loss = 0.02175719\n",
      "Iteration 1612, loss = 0.02173922\n",
      "Iteration 1613, loss = 0.02172407\n",
      "Iteration 1614, loss = 0.02170940\n",
      "Iteration 1615, loss = 0.02169206\n",
      "Iteration 1616, loss = 0.02167551\n",
      "Iteration 1617, loss = 0.02166388\n",
      "Iteration 1618, loss = 0.02164471\n",
      "Iteration 1619, loss = 0.02162822\n",
      "Iteration 1620, loss = 0.02161453\n",
      "Iteration 1621, loss = 0.02159625\n",
      "Iteration 1622, loss = 0.02157956\n",
      "Iteration 1623, loss = 0.02156552\n",
      "Iteration 1624, loss = 0.02154709\n",
      "Iteration 1625, loss = 0.02153090\n",
      "Iteration 1626, loss = 0.02151371\n",
      "Iteration 1627, loss = 0.02149705\n",
      "Iteration 1628, loss = 0.02148126\n",
      "Iteration 1629, loss = 0.02146376\n",
      "Iteration 1630, loss = 0.02144842\n",
      "Iteration 1631, loss = 0.02143120\n",
      "Iteration 1632, loss = 0.02141345\n",
      "Iteration 1633, loss = 0.02139744\n",
      "Iteration 1634, loss = 0.02138015\n",
      "Iteration 1635, loss = 0.02136444\n",
      "Iteration 1636, loss = 0.02134685\n",
      "Iteration 1637, loss = 0.02133130\n",
      "Iteration 1638, loss = 0.02131475\n",
      "Iteration 1639, loss = 0.02129757\n",
      "Iteration 1640, loss = 0.02128347\n",
      "Iteration 1641, loss = 0.02126788\n",
      "Iteration 1642, loss = 0.02125076\n",
      "Iteration 1643, loss = 0.02123496\n",
      "Iteration 1644, loss = 0.02121929\n",
      "Iteration 1645, loss = 0.02120396\n",
      "Iteration 1646, loss = 0.02118889\n",
      "Iteration 1647, loss = 0.02117327\n",
      "Iteration 1648, loss = 0.02115856\n",
      "Iteration 1649, loss = 0.02114283\n",
      "Iteration 1650, loss = 0.02112729\n",
      "Iteration 1651, loss = 0.02111237\n",
      "Iteration 1652, loss = 0.02109593\n",
      "Iteration 1653, loss = 0.02108081\n",
      "Iteration 1654, loss = 0.02106587\n",
      "Iteration 1655, loss = 0.02105323\n",
      "Iteration 1656, loss = 0.02103686\n",
      "Iteration 1657, loss = 0.02102026\n",
      "Iteration 1658, loss = 0.02100335\n",
      "Iteration 1659, loss = 0.02098801\n",
      "Iteration 1660, loss = 0.02097254\n",
      "Iteration 1661, loss = 0.02095953\n",
      "Iteration 1662, loss = 0.02094118\n",
      "Iteration 1663, loss = 0.02092646\n",
      "Iteration 1664, loss = 0.02091175\n",
      "Iteration 1665, loss = 0.02089627\n",
      "Iteration 1666, loss = 0.02088064\n",
      "Iteration 1667, loss = 0.02086678\n",
      "Iteration 1668, loss = 0.02085280\n",
      "Iteration 1669, loss = 0.02083825\n",
      "Iteration 1670, loss = 0.02082198\n",
      "Iteration 1671, loss = 0.02080680\n",
      "Iteration 1672, loss = 0.02079114\n",
      "Iteration 1673, loss = 0.02077625\n",
      "Iteration 1674, loss = 0.02076148\n",
      "Iteration 1675, loss = 0.02074989\n",
      "Iteration 1676, loss = 0.02073314\n",
      "Iteration 1677, loss = 0.02071917\n",
      "Iteration 1678, loss = 0.02070183\n",
      "Iteration 1679, loss = 0.02068690\n",
      "Iteration 1680, loss = 0.02067192\n",
      "Iteration 1681, loss = 0.02065651\n",
      "Iteration 1682, loss = 0.02064101\n",
      "Iteration 1683, loss = 0.02062788\n",
      "Iteration 1684, loss = 0.02061185\n",
      "Iteration 1685, loss = 0.02059861\n",
      "Iteration 1686, loss = 0.02058161\n",
      "Iteration 1687, loss = 0.02056621\n",
      "Iteration 1688, loss = 0.02055182\n",
      "Iteration 1689, loss = 0.02053762\n",
      "Iteration 1690, loss = 0.02052436\n",
      "Iteration 1691, loss = 0.02050885\n",
      "Iteration 1692, loss = 0.02049482\n",
      "Iteration 1693, loss = 0.02047958\n",
      "Iteration 1694, loss = 0.02046522\n",
      "Iteration 1695, loss = 0.02045063\n",
      "Iteration 1696, loss = 0.02043735\n",
      "Iteration 1697, loss = 0.02042042\n",
      "Iteration 1698, loss = 0.02040730\n",
      "Iteration 1699, loss = 0.02039344\n",
      "Iteration 1700, loss = 0.02037702\n",
      "Iteration 1701, loss = 0.02036127\n",
      "Iteration 1702, loss = 0.02034649\n",
      "Iteration 1703, loss = 0.02033099\n",
      "Iteration 1704, loss = 0.02031896\n",
      "Iteration 1705, loss = 0.02030121\n",
      "Iteration 1706, loss = 0.02028702\n",
      "Iteration 1707, loss = 0.02027126\n",
      "Iteration 1708, loss = 0.02025690\n",
      "Iteration 1709, loss = 0.02024125\n",
      "Iteration 1710, loss = 0.02022784\n",
      "Iteration 1711, loss = 0.02021201\n",
      "Iteration 1712, loss = 0.02019901\n",
      "Iteration 1713, loss = 0.02018276\n",
      "Iteration 1714, loss = 0.02016750\n",
      "Iteration 1715, loss = 0.02015478\n",
      "Iteration 1716, loss = 0.02014048\n",
      "Iteration 1717, loss = 0.02012407\n",
      "Iteration 1718, loss = 0.02011218\n",
      "Iteration 1719, loss = 0.02009535\n",
      "Iteration 1720, loss = 0.02008245\n",
      "Iteration 1721, loss = 0.02006646\n",
      "Iteration 1722, loss = 0.02005289\n",
      "Iteration 1723, loss = 0.02003855\n",
      "Iteration 1724, loss = 0.02002565\n",
      "Iteration 1725, loss = 0.02001007\n",
      "Iteration 1726, loss = 0.01999618\n",
      "Iteration 1727, loss = 0.01998247\n",
      "Iteration 1728, loss = 0.01996958\n",
      "Iteration 1729, loss = 0.01995383\n",
      "Iteration 1730, loss = 0.01993929\n",
      "Iteration 1731, loss = 0.01992513\n",
      "Iteration 1732, loss = 0.01991219\n",
      "Iteration 1733, loss = 0.01989641\n",
      "Iteration 1734, loss = 0.01988150\n",
      "Iteration 1735, loss = 0.01986736\n",
      "Iteration 1736, loss = 0.01985148\n",
      "Iteration 1737, loss = 0.01983616\n",
      "Iteration 1738, loss = 0.01982056\n",
      "Iteration 1739, loss = 0.01980767\n",
      "Iteration 1740, loss = 0.01979193\n",
      "Iteration 1741, loss = 0.01977609\n",
      "Iteration 1742, loss = 0.01976004\n",
      "Iteration 1743, loss = 0.01974562\n",
      "Iteration 1744, loss = 0.01973142\n",
      "Iteration 1745, loss = 0.01971711\n",
      "Iteration 1746, loss = 0.01970224\n",
      "Iteration 1747, loss = 0.01968984\n",
      "Iteration 1748, loss = 0.01967489\n",
      "Iteration 1749, loss = 0.01966338\n",
      "Iteration 1750, loss = 0.01964890\n",
      "Iteration 1751, loss = 0.01963518\n",
      "Iteration 1752, loss = 0.01962144\n",
      "Iteration 1753, loss = 0.01960794\n",
      "Iteration 1754, loss = 0.01959467\n",
      "Iteration 1755, loss = 0.01958214\n",
      "Iteration 1756, loss = 0.01957050\n",
      "Iteration 1757, loss = 0.01955555\n",
      "Iteration 1758, loss = 0.01954284\n",
      "Iteration 1759, loss = 0.01953059\n",
      "Iteration 1760, loss = 0.01951676\n",
      "Iteration 1761, loss = 0.01950466\n",
      "Iteration 1762, loss = 0.01949129\n",
      "Iteration 1763, loss = 0.01947846\n",
      "Iteration 1764, loss = 0.01946676\n",
      "Iteration 1765, loss = 0.01945426\n",
      "Iteration 1766, loss = 0.01944121\n",
      "Iteration 1767, loss = 0.01942739\n",
      "Iteration 1768, loss = 0.01941443\n",
      "Iteration 1769, loss = 0.01940014\n",
      "Iteration 1770, loss = 0.01938732\n",
      "Iteration 1771, loss = 0.01937367\n",
      "Iteration 1772, loss = 0.01935949\n",
      "Iteration 1773, loss = 0.01934739\n",
      "Iteration 1774, loss = 0.01933325\n",
      "Iteration 1775, loss = 0.01931939\n",
      "Iteration 1776, loss = 0.01930550\n",
      "Iteration 1777, loss = 0.01929161\n",
      "Iteration 1778, loss = 0.01927907\n",
      "Iteration 1779, loss = 0.01926518\n",
      "Iteration 1780, loss = 0.01925142\n",
      "Iteration 1781, loss = 0.01923568\n",
      "Iteration 1782, loss = 0.01921998\n",
      "Iteration 1783, loss = 0.01920729\n",
      "Iteration 1784, loss = 0.01919598\n",
      "Iteration 1785, loss = 0.01917902\n",
      "Iteration 1786, loss = 0.01916687\n",
      "Iteration 1787, loss = 0.01915122\n",
      "Iteration 1788, loss = 0.01913628\n",
      "Iteration 1789, loss = 0.01912587\n",
      "Iteration 1790, loss = 0.01911292\n",
      "Iteration 1791, loss = 0.01910143\n",
      "Iteration 1792, loss = 0.01908760\n",
      "Iteration 1793, loss = 0.01907731\n",
      "Iteration 1794, loss = 0.01906475\n",
      "Iteration 1795, loss = 0.01905196\n",
      "Iteration 1796, loss = 0.01904121\n",
      "Iteration 1797, loss = 0.01902599\n",
      "Iteration 1798, loss = 0.01901203\n",
      "Iteration 1799, loss = 0.01899924\n",
      "Iteration 1800, loss = 0.01898607\n",
      "Iteration 1801, loss = 0.01897236\n",
      "Iteration 1802, loss = 0.01895985\n",
      "Iteration 1803, loss = 0.01894665\n",
      "Iteration 1804, loss = 0.01893384\n",
      "Iteration 1805, loss = 0.01892380\n",
      "Iteration 1806, loss = 0.01890851\n",
      "Iteration 1807, loss = 0.01889630\n",
      "Iteration 1808, loss = 0.01888298\n",
      "Iteration 1809, loss = 0.01887157\n",
      "Iteration 1810, loss = 0.01885808\n",
      "Iteration 1811, loss = 0.01884494\n",
      "Iteration 1812, loss = 0.01883445\n",
      "Iteration 1813, loss = 0.01882063\n",
      "Iteration 1814, loss = 0.01880759\n",
      "Iteration 1815, loss = 0.01879663\n",
      "Iteration 1816, loss = 0.01878271\n",
      "Iteration 1817, loss = 0.01877272\n",
      "Iteration 1818, loss = 0.01875608\n",
      "Iteration 1819, loss = 0.01874601\n",
      "Iteration 1820, loss = 0.01873123\n",
      "Iteration 1821, loss = 0.01872115\n",
      "Iteration 1822, loss = 0.01870910\n",
      "Iteration 1823, loss = 0.01869556\n",
      "Iteration 1824, loss = 0.01868277\n",
      "Iteration 1825, loss = 0.01867083\n",
      "Iteration 1826, loss = 0.01865909\n",
      "Iteration 1827, loss = 0.01864816\n",
      "Iteration 1828, loss = 0.01863355\n",
      "Iteration 1829, loss = 0.01862121\n",
      "Iteration 1830, loss = 0.01860841\n",
      "Iteration 1831, loss = 0.01859592\n",
      "Iteration 1832, loss = 0.01858483\n",
      "Iteration 1833, loss = 0.01857249\n",
      "Iteration 1834, loss = 0.01856010\n",
      "Iteration 1835, loss = 0.01854732\n",
      "Iteration 1836, loss = 0.01853530\n",
      "Iteration 1837, loss = 0.01852367\n",
      "Iteration 1838, loss = 0.01851216\n",
      "Iteration 1839, loss = 0.01850161\n",
      "Iteration 1840, loss = 0.01849279\n",
      "Iteration 1841, loss = 0.01847797\n",
      "Iteration 1842, loss = 0.01846594\n",
      "Iteration 1843, loss = 0.01845356\n",
      "Iteration 1844, loss = 0.01844186\n",
      "Iteration 1845, loss = 0.01842938\n",
      "Iteration 1846, loss = 0.01841795\n",
      "Iteration 1847, loss = 0.01840491\n",
      "Iteration 1848, loss = 0.01839376\n",
      "Iteration 1849, loss = 0.01838177\n",
      "Iteration 1850, loss = 0.01836908\n",
      "Iteration 1851, loss = 0.01835962\n",
      "Iteration 1852, loss = 0.01834518\n",
      "Iteration 1853, loss = 0.01833366\n",
      "Iteration 1854, loss = 0.01832209\n",
      "Iteration 1855, loss = 0.01830908\n",
      "Iteration 1856, loss = 0.01829648\n",
      "Iteration 1857, loss = 0.01828446\n",
      "Iteration 1858, loss = 0.01827227\n",
      "Iteration 1859, loss = 0.01825935\n",
      "Iteration 1860, loss = 0.01824811\n",
      "Iteration 1861, loss = 0.01823710\n",
      "Iteration 1862, loss = 0.01822603\n",
      "Iteration 1863, loss = 0.01821312\n",
      "Iteration 1864, loss = 0.01820265\n",
      "Iteration 1865, loss = 0.01819051\n",
      "Iteration 1866, loss = 0.01817726\n",
      "Iteration 1867, loss = 0.01816451\n",
      "Iteration 1868, loss = 0.01815215\n",
      "Iteration 1869, loss = 0.01813904\n",
      "Iteration 1870, loss = 0.01812647\n",
      "Iteration 1871, loss = 0.01811629\n",
      "Iteration 1872, loss = 0.01810293\n",
      "Iteration 1873, loss = 0.01808948\n",
      "Iteration 1874, loss = 0.01807814\n",
      "Iteration 1875, loss = 0.01806633\n",
      "Iteration 1876, loss = 0.01805497\n",
      "Iteration 1877, loss = 0.01804273\n",
      "Iteration 1878, loss = 0.01803148\n",
      "Iteration 1879, loss = 0.01802047\n",
      "Iteration 1880, loss = 0.01800836\n",
      "Iteration 1881, loss = 0.01799736\n",
      "Iteration 1882, loss = 0.01798691\n",
      "Iteration 1883, loss = 0.01797614\n",
      "Iteration 1884, loss = 0.01796252\n",
      "Iteration 1885, loss = 0.01795278\n",
      "Iteration 1886, loss = 0.01793918\n",
      "Iteration 1887, loss = 0.01792828\n",
      "Iteration 1888, loss = 0.01791578\n",
      "Iteration 1889, loss = 0.01790424\n",
      "Iteration 1890, loss = 0.01789307\n",
      "Iteration 1891, loss = 0.01788520\n",
      "Iteration 1892, loss = 0.01787117\n",
      "Iteration 1893, loss = 0.01785906\n",
      "Iteration 1894, loss = 0.01785003\n",
      "Iteration 1895, loss = 0.01783772\n",
      "Iteration 1896, loss = 0.01782675\n",
      "Iteration 1897, loss = 0.01781654\n",
      "Iteration 1898, loss = 0.01780422\n",
      "Iteration 1899, loss = 0.01779366\n",
      "Iteration 1900, loss = 0.01778261\n",
      "Iteration 1901, loss = 0.01777205\n",
      "Iteration 1902, loss = 0.01776186\n",
      "Iteration 1903, loss = 0.01775132\n",
      "Iteration 1904, loss = 0.01774045\n",
      "Iteration 1905, loss = 0.01772906\n",
      "Iteration 1906, loss = 0.01771708\n",
      "Iteration 1907, loss = 0.01770643\n",
      "Iteration 1908, loss = 0.01769380\n",
      "Iteration 1909, loss = 0.01768226\n",
      "Iteration 1910, loss = 0.01766992\n",
      "Iteration 1911, loss = 0.01765808\n",
      "Iteration 1912, loss = 0.01764687\n",
      "Iteration 1913, loss = 0.01763500\n",
      "Iteration 1914, loss = 0.01762537\n",
      "Iteration 1915, loss = 0.01761268\n",
      "Iteration 1916, loss = 0.01760321\n",
      "Iteration 1917, loss = 0.01759145\n",
      "Iteration 1918, loss = 0.01758014\n",
      "Iteration 1919, loss = 0.01756928\n",
      "Iteration 1920, loss = 0.01755730\n",
      "Iteration 1921, loss = 0.01754612\n",
      "Iteration 1922, loss = 0.01753449\n",
      "Iteration 1923, loss = 0.01752607\n",
      "Iteration 1924, loss = 0.01751125\n",
      "Iteration 1925, loss = 0.01750005\n",
      "Iteration 1926, loss = 0.01748902\n",
      "Iteration 1927, loss = 0.01747804\n",
      "Iteration 1928, loss = 0.01746628\n",
      "Iteration 1929, loss = 0.01745492\n",
      "Iteration 1930, loss = 0.01744362\n",
      "Iteration 1931, loss = 0.01743199\n",
      "Iteration 1932, loss = 0.01742106\n",
      "Iteration 1933, loss = 0.01740886\n",
      "Iteration 1934, loss = 0.01739743\n",
      "Iteration 1935, loss = 0.01738697\n",
      "Iteration 1936, loss = 0.01737516\n",
      "Iteration 1937, loss = 0.01736602\n",
      "Iteration 1938, loss = 0.01735461\n",
      "Iteration 1939, loss = 0.01734326\n",
      "Iteration 1940, loss = 0.01733195\n",
      "Iteration 1941, loss = 0.01732118\n",
      "Iteration 1942, loss = 0.01730953\n",
      "Iteration 1943, loss = 0.01729907\n",
      "Iteration 1944, loss = 0.01728731\n",
      "Iteration 1945, loss = 0.01727490\n",
      "Iteration 1946, loss = 0.01726521\n",
      "Iteration 1947, loss = 0.01725243\n",
      "Iteration 1948, loss = 0.01724148\n",
      "Iteration 1949, loss = 0.01722894\n",
      "Iteration 1950, loss = 0.01721695\n",
      "Iteration 1951, loss = 0.01720724\n",
      "Iteration 1952, loss = 0.01719633\n",
      "Iteration 1953, loss = 0.01718552\n",
      "Iteration 1954, loss = 0.01717499\n",
      "Iteration 1955, loss = 0.01716447\n",
      "Iteration 1956, loss = 0.01715401\n",
      "Iteration 1957, loss = 0.01714410\n",
      "Iteration 1958, loss = 0.01713401\n",
      "Iteration 1959, loss = 0.01712257\n",
      "Iteration 1960, loss = 0.01711199\n",
      "Iteration 1961, loss = 0.01710086\n",
      "Iteration 1962, loss = 0.01709037\n",
      "Iteration 1963, loss = 0.01707911\n",
      "Iteration 1964, loss = 0.01706942\n",
      "Iteration 1965, loss = 0.01705827\n",
      "Iteration 1966, loss = 0.01704814\n",
      "Iteration 1967, loss = 0.01703689\n",
      "Iteration 1968, loss = 0.01702671\n",
      "Iteration 1969, loss = 0.01701567\n",
      "Iteration 1970, loss = 0.01700523\n",
      "Iteration 1971, loss = 0.01699591\n",
      "Iteration 1972, loss = 0.01698487\n",
      "Iteration 1973, loss = 0.01697414\n",
      "Iteration 1974, loss = 0.01696731\n",
      "Iteration 1975, loss = 0.01695208\n",
      "Iteration 1976, loss = 0.01694294\n",
      "Iteration 1977, loss = 0.01693030\n",
      "Iteration 1978, loss = 0.01691878\n",
      "Iteration 1979, loss = 0.01690960\n",
      "Iteration 1980, loss = 0.01689796\n",
      "Iteration 1981, loss = 0.01688773\n",
      "Iteration 1982, loss = 0.01687579\n",
      "Iteration 1983, loss = 0.01686350\n",
      "Iteration 1984, loss = 0.01685460\n",
      "Iteration 1985, loss = 0.01684238\n",
      "Iteration 1986, loss = 0.01683375\n",
      "Iteration 1987, loss = 0.01682161\n",
      "Iteration 1988, loss = 0.01681077\n",
      "Iteration 1989, loss = 0.01680165\n",
      "Iteration 1990, loss = 0.01679188\n",
      "Iteration 1991, loss = 0.01678012\n",
      "Iteration 1992, loss = 0.01677067\n",
      "Iteration 1993, loss = 0.01675876\n",
      "Iteration 1994, loss = 0.01674820\n",
      "Iteration 1995, loss = 0.01673758\n",
      "Iteration 1996, loss = 0.01672644\n",
      "Iteration 1997, loss = 0.01671609\n",
      "Iteration 1998, loss = 0.01670624\n",
      "Iteration 1999, loss = 0.01669491\n",
      "Iteration 2000, loss = 0.01668449\n",
      "Iteration 2001, loss = 0.01667361\n",
      "Iteration 2002, loss = 0.01666429\n",
      "Iteration 2003, loss = 0.01665342\n",
      "Iteration 2004, loss = 0.01664198\n",
      "Iteration 2005, loss = 0.01663273\n",
      "Iteration 2006, loss = 0.01662141\n",
      "Iteration 2007, loss = 0.01661053\n",
      "Iteration 2008, loss = 0.01660084\n",
      "Iteration 2009, loss = 0.01659073\n",
      "Iteration 2010, loss = 0.01658019\n",
      "Iteration 2011, loss = 0.01657202\n",
      "Iteration 2012, loss = 0.01656052\n",
      "Iteration 2013, loss = 0.01655062\n",
      "Iteration 2014, loss = 0.01654019\n",
      "Iteration 2015, loss = 0.01652992\n",
      "Iteration 2016, loss = 0.01651918\n",
      "Iteration 2017, loss = 0.01651093\n",
      "Iteration 2018, loss = 0.01650077\n",
      "Iteration 2019, loss = 0.01648917\n",
      "Iteration 2020, loss = 0.01647856\n",
      "Iteration 2021, loss = 0.01646872\n",
      "Iteration 2022, loss = 0.01645910\n",
      "Iteration 2023, loss = 0.01644919\n",
      "Iteration 2024, loss = 0.01643940\n",
      "Iteration 2025, loss = 0.01643068\n",
      "Iteration 2026, loss = 0.01642143\n",
      "Iteration 2027, loss = 0.01641083\n",
      "Iteration 2028, loss = 0.01640080\n",
      "Iteration 2029, loss = 0.01639238\n",
      "Iteration 2030, loss = 0.01638110\n",
      "Iteration 2031, loss = 0.01637218\n",
      "Iteration 2032, loss = 0.01636126\n",
      "Iteration 2033, loss = 0.01635220\n",
      "Iteration 2034, loss = 0.01634201\n",
      "Iteration 2035, loss = 0.01633211\n",
      "Iteration 2036, loss = 0.01632322\n",
      "Iteration 2037, loss = 0.01631312\n",
      "Iteration 2038, loss = 0.01630409\n",
      "Iteration 2039, loss = 0.01629339\n",
      "Iteration 2040, loss = 0.01628394\n",
      "Iteration 2041, loss = 0.01627323\n",
      "Iteration 2042, loss = 0.01626421\n",
      "Iteration 2043, loss = 0.01625450\n",
      "Iteration 2044, loss = 0.01624533\n",
      "Iteration 2045, loss = 0.01623602\n",
      "Iteration 2046, loss = 0.01622629\n",
      "Iteration 2047, loss = 0.01621698\n",
      "Iteration 2048, loss = 0.01620778\n",
      "Iteration 2049, loss = 0.01619670\n",
      "Iteration 2050, loss = 0.01618695\n",
      "Iteration 2051, loss = 0.01617765\n",
      "Iteration 2052, loss = 0.01616831\n",
      "Iteration 2053, loss = 0.01615785\n",
      "Iteration 2054, loss = 0.01614817\n",
      "Iteration 2055, loss = 0.01613893\n",
      "Iteration 2056, loss = 0.01612944\n",
      "Iteration 2057, loss = 0.01611968\n",
      "Iteration 2058, loss = 0.01611147\n",
      "Iteration 2059, loss = 0.01610020\n",
      "Iteration 2060, loss = 0.01608970\n",
      "Iteration 2061, loss = 0.01607952\n",
      "Iteration 2062, loss = 0.01606911\n",
      "Iteration 2063, loss = 0.01605824\n",
      "Iteration 2064, loss = 0.01604751\n",
      "Iteration 2065, loss = 0.01603824\n",
      "Iteration 2066, loss = 0.01602733\n",
      "Iteration 2067, loss = 0.01601674\n",
      "Iteration 2068, loss = 0.01601026\n",
      "Iteration 2069, loss = 0.01599751\n",
      "Iteration 2070, loss = 0.01598815\n",
      "Iteration 2071, loss = 0.01597726\n",
      "Iteration 2072, loss = 0.01596785\n",
      "Iteration 2073, loss = 0.01595752\n",
      "Iteration 2074, loss = 0.01594828\n",
      "Iteration 2075, loss = 0.01593719\n",
      "Iteration 2076, loss = 0.01592895\n",
      "Iteration 2077, loss = 0.01591769\n",
      "Iteration 2078, loss = 0.01590791\n",
      "Iteration 2079, loss = 0.01590024\n",
      "Iteration 2080, loss = 0.01589001\n",
      "Iteration 2081, loss = 0.01588030\n",
      "Iteration 2082, loss = 0.01587060\n",
      "Iteration 2083, loss = 0.01586220\n",
      "Iteration 2084, loss = 0.01585236\n",
      "Iteration 2085, loss = 0.01584279\n",
      "Iteration 2086, loss = 0.01583332\n",
      "Iteration 2087, loss = 0.01582334\n",
      "Iteration 2088, loss = 0.01581287\n",
      "Iteration 2089, loss = 0.01580239\n",
      "Iteration 2090, loss = 0.01579280\n",
      "Iteration 2091, loss = 0.01578301\n",
      "Iteration 2092, loss = 0.01577426\n",
      "Iteration 2093, loss = 0.01576682\n",
      "Iteration 2094, loss = 0.01575537\n",
      "Iteration 2095, loss = 0.01574618\n",
      "Iteration 2096, loss = 0.01573631\n",
      "Iteration 2097, loss = 0.01572640\n",
      "Iteration 2098, loss = 0.01571642\n",
      "Iteration 2099, loss = 0.01570696\n",
      "Iteration 2100, loss = 0.01569633\n",
      "Iteration 2101, loss = 0.01569000\n",
      "Iteration 2102, loss = 0.01567940\n",
      "Iteration 2103, loss = 0.01566853\n",
      "Iteration 2104, loss = 0.01566030\n",
      "Iteration 2105, loss = 0.01565152\n",
      "Iteration 2106, loss = 0.01564114\n",
      "Iteration 2107, loss = 0.01563286\n",
      "Iteration 2108, loss = 0.01562070\n",
      "Iteration 2109, loss = 0.01561161\n",
      "Iteration 2110, loss = 0.01560219\n",
      "Iteration 2111, loss = 0.01559127\n",
      "Iteration 2112, loss = 0.01558155\n",
      "Iteration 2113, loss = 0.01557202\n",
      "Iteration 2114, loss = 0.01556352\n",
      "Iteration 2115, loss = 0.01555239\n",
      "Iteration 2116, loss = 0.01554424\n",
      "Iteration 2117, loss = 0.01553360\n",
      "Iteration 2118, loss = 0.01552469\n",
      "Iteration 2119, loss = 0.01551685\n",
      "Iteration 2120, loss = 0.01550628\n",
      "Iteration 2121, loss = 0.01549682\n",
      "Iteration 2122, loss = 0.01548782\n",
      "Iteration 2123, loss = 0.01547737\n",
      "Iteration 2124, loss = 0.01546644\n",
      "Iteration 2125, loss = 0.01545896\n",
      "Iteration 2126, loss = 0.01545214\n",
      "Iteration 2127, loss = 0.01544129\n",
      "Iteration 2128, loss = 0.01543093\n",
      "Iteration 2129, loss = 0.01542236\n",
      "Iteration 2130, loss = 0.01541336\n",
      "Iteration 2131, loss = 0.01540506\n",
      "Iteration 2132, loss = 0.01539524\n",
      "Iteration 2133, loss = 0.01538622\n",
      "Iteration 2134, loss = 0.01537893\n",
      "Iteration 2135, loss = 0.01536886\n",
      "Iteration 2136, loss = 0.01536007\n",
      "Iteration 2137, loss = 0.01535132\n",
      "Iteration 2138, loss = 0.01534301\n",
      "Iteration 2139, loss = 0.01533487\n",
      "Iteration 2140, loss = 0.01532516\n",
      "Iteration 2141, loss = 0.01531555\n",
      "Iteration 2142, loss = 0.01530608\n",
      "Iteration 2143, loss = 0.01529782\n",
      "Iteration 2144, loss = 0.01529015\n",
      "Iteration 2145, loss = 0.01527980\n",
      "Iteration 2146, loss = 0.01527108\n",
      "Iteration 2147, loss = 0.01526216\n",
      "Iteration 2148, loss = 0.01525382\n",
      "Iteration 2149, loss = 0.01524526\n",
      "Iteration 2150, loss = 0.01523484\n",
      "Iteration 2151, loss = 0.01522581\n",
      "Iteration 2152, loss = 0.01521745\n",
      "Iteration 2153, loss = 0.01520792\n",
      "Iteration 2154, loss = 0.01519864\n",
      "Iteration 2155, loss = 0.01518955\n",
      "Iteration 2156, loss = 0.01518038\n",
      "Iteration 2157, loss = 0.01517177\n",
      "Iteration 2158, loss = 0.01516338\n",
      "Iteration 2159, loss = 0.01515409\n",
      "Iteration 2160, loss = 0.01514607\n",
      "Iteration 2161, loss = 0.01513694\n",
      "Iteration 2162, loss = 0.01512821\n",
      "Iteration 2163, loss = 0.01511850\n",
      "Iteration 2164, loss = 0.01511005\n",
      "Iteration 2165, loss = 0.01510202\n",
      "Iteration 2166, loss = 0.01509306\n",
      "Iteration 2167, loss = 0.01508402\n",
      "Iteration 2168, loss = 0.01507535\n",
      "Iteration 2169, loss = 0.01506577\n",
      "Iteration 2170, loss = 0.01505809\n",
      "Iteration 2171, loss = 0.01504908\n",
      "Iteration 2172, loss = 0.01504240\n",
      "Iteration 2173, loss = 0.01503374\n",
      "Iteration 2174, loss = 0.01502516\n",
      "Iteration 2175, loss = 0.01501819\n",
      "Iteration 2176, loss = 0.01500891\n",
      "Iteration 2177, loss = 0.01500129\n",
      "Iteration 2178, loss = 0.01499306\n",
      "Iteration 2179, loss = 0.01498409\n",
      "Iteration 2180, loss = 0.01497547\n",
      "Iteration 2181, loss = 0.01496699\n",
      "Iteration 2182, loss = 0.01495817\n",
      "Iteration 2183, loss = 0.01495031\n",
      "Iteration 2184, loss = 0.01494179\n",
      "Iteration 2185, loss = 0.01493375\n",
      "Iteration 2186, loss = 0.01492731\n",
      "Iteration 2187, loss = 0.01491792\n",
      "Iteration 2188, loss = 0.01491054\n",
      "Iteration 2189, loss = 0.01490145\n",
      "Iteration 2190, loss = 0.01489356\n",
      "Iteration 2191, loss = 0.01488358\n",
      "Iteration 2192, loss = 0.01487550\n",
      "Iteration 2193, loss = 0.01486636\n",
      "Iteration 2194, loss = 0.01485685\n",
      "Iteration 2195, loss = 0.01485028\n",
      "Iteration 2196, loss = 0.01484037\n",
      "Iteration 2197, loss = 0.01483247\n",
      "Iteration 2198, loss = 0.01482353\n",
      "Iteration 2199, loss = 0.01481538\n",
      "Iteration 2200, loss = 0.01480875\n",
      "Iteration 2201, loss = 0.01479998\n",
      "Iteration 2202, loss = 0.01479297\n",
      "Iteration 2203, loss = 0.01478470\n",
      "Iteration 2204, loss = 0.01477668\n",
      "Iteration 2205, loss = 0.01477080\n",
      "Iteration 2206, loss = 0.01476097\n",
      "Iteration 2207, loss = 0.01475276\n",
      "Iteration 2208, loss = 0.01474560\n",
      "Iteration 2209, loss = 0.01473965\n",
      "Iteration 2210, loss = 0.01473275\n",
      "Iteration 2211, loss = 0.01472078\n",
      "Iteration 2212, loss = 0.01471229\n",
      "Iteration 2213, loss = 0.01470160\n",
      "Iteration 2214, loss = 0.01469331\n",
      "Iteration 2215, loss = 0.01468294\n",
      "Iteration 2216, loss = 0.01467389\n",
      "Iteration 2217, loss = 0.01466299\n",
      "Iteration 2218, loss = 0.01465448\n",
      "Iteration 2219, loss = 0.01464645\n",
      "Iteration 2220, loss = 0.01463672\n",
      "Iteration 2221, loss = 0.01462775\n",
      "Iteration 2222, loss = 0.01461896\n",
      "Iteration 2223, loss = 0.01460969\n",
      "Iteration 2224, loss = 0.01460204\n",
      "Iteration 2225, loss = 0.01459385\n",
      "Iteration 2226, loss = 0.01458599\n",
      "Iteration 2227, loss = 0.01457823\n",
      "Iteration 2228, loss = 0.01456817\n",
      "Iteration 2229, loss = 0.01456052\n",
      "Iteration 2230, loss = 0.01455223\n",
      "Iteration 2231, loss = 0.01454418\n",
      "Iteration 2232, loss = 0.01453662\n",
      "Iteration 2233, loss = 0.01452922\n",
      "Iteration 2234, loss = 0.01451968\n",
      "Iteration 2235, loss = 0.01451128\n",
      "Iteration 2236, loss = 0.01450221\n",
      "Iteration 2237, loss = 0.01449667\n",
      "Iteration 2238, loss = 0.01448567\n",
      "Iteration 2239, loss = 0.01447681\n",
      "Iteration 2240, loss = 0.01446961\n",
      "Iteration 2241, loss = 0.01446143\n",
      "Iteration 2242, loss = 0.01445229\n",
      "Iteration 2243, loss = 0.01444376\n",
      "Iteration 2244, loss = 0.01443621\n",
      "Iteration 2245, loss = 0.01442682\n",
      "Iteration 2246, loss = 0.01441995\n",
      "Iteration 2247, loss = 0.01441179\n",
      "Iteration 2248, loss = 0.01440272\n",
      "Iteration 2249, loss = 0.01439497\n",
      "Iteration 2250, loss = 0.01438624\n",
      "Iteration 2251, loss = 0.01437809\n",
      "Iteration 2252, loss = 0.01436977\n",
      "Iteration 2253, loss = 0.01436326\n",
      "Iteration 2254, loss = 0.01435380\n",
      "Iteration 2255, loss = 0.01434570\n",
      "Iteration 2256, loss = 0.01433741\n",
      "Iteration 2257, loss = 0.01432918\n",
      "Iteration 2258, loss = 0.01432207\n",
      "Iteration 2259, loss = 0.01431388\n",
      "Iteration 2260, loss = 0.01430573\n",
      "Iteration 2261, loss = 0.01429727\n",
      "Iteration 2262, loss = 0.01428944\n",
      "Iteration 2263, loss = 0.01428157\n",
      "Iteration 2264, loss = 0.01427357\n",
      "Iteration 2265, loss = 0.01426623\n",
      "Iteration 2266, loss = 0.01425815\n",
      "Iteration 2267, loss = 0.01425266\n",
      "Iteration 2268, loss = 0.01424504\n",
      "Iteration 2269, loss = 0.01423615\n",
      "Iteration 2270, loss = 0.01422755\n",
      "Iteration 2271, loss = 0.01422159\n",
      "Iteration 2272, loss = 0.01421228\n",
      "Iteration 2273, loss = 0.01420412\n",
      "Iteration 2274, loss = 0.01419552\n",
      "Iteration 2275, loss = 0.01418742\n",
      "Iteration 2276, loss = 0.01418009\n",
      "Iteration 2277, loss = 0.01416966\n",
      "Iteration 2278, loss = 0.01416060\n",
      "Iteration 2279, loss = 0.01415385\n",
      "Iteration 2280, loss = 0.01414420\n",
      "Iteration 2281, loss = 0.01413523\n",
      "Iteration 2282, loss = 0.01412592\n",
      "Iteration 2283, loss = 0.01411739\n",
      "Iteration 2284, loss = 0.01410967\n",
      "Iteration 2285, loss = 0.01410035\n",
      "Iteration 2286, loss = 0.01409280\n",
      "Iteration 2287, loss = 0.01408317\n",
      "Iteration 2288, loss = 0.01407453\n",
      "Iteration 2289, loss = 0.01406865\n",
      "Iteration 2290, loss = 0.01406169\n",
      "Iteration 2291, loss = 0.01405337\n",
      "Iteration 2292, loss = 0.01404459\n",
      "Iteration 2293, loss = 0.01403670\n",
      "Iteration 2294, loss = 0.01402903\n",
      "Iteration 2295, loss = 0.01402107\n",
      "Iteration 2296, loss = 0.01401263\n",
      "Iteration 2297, loss = 0.01400634\n",
      "Iteration 2298, loss = 0.01399667\n",
      "Iteration 2299, loss = 0.01398952\n",
      "Iteration 2300, loss = 0.01398014\n",
      "Iteration 2301, loss = 0.01397257\n",
      "Iteration 2302, loss = 0.01396479\n",
      "Iteration 2303, loss = 0.01395665\n",
      "Iteration 2304, loss = 0.01394830\n",
      "Iteration 2305, loss = 0.01394052\n",
      "Iteration 2306, loss = 0.01393410\n",
      "Iteration 2307, loss = 0.01392543\n",
      "Iteration 2308, loss = 0.01391801\n",
      "Iteration 2309, loss = 0.01390955\n",
      "Iteration 2310, loss = 0.01390429\n",
      "Iteration 2311, loss = 0.01389483\n",
      "Iteration 2312, loss = 0.01388684\n",
      "Iteration 2313, loss = 0.01388088\n",
      "Iteration 2314, loss = 0.01387183\n",
      "Iteration 2315, loss = 0.01386426\n",
      "Iteration 2316, loss = 0.01385525\n",
      "Iteration 2317, loss = 0.01384742\n",
      "Iteration 2318, loss = 0.01383907\n",
      "Iteration 2319, loss = 0.01383168\n",
      "Iteration 2320, loss = 0.01382536\n",
      "Iteration 2321, loss = 0.01381661\n",
      "Iteration 2322, loss = 0.01380960\n",
      "Iteration 2323, loss = 0.01380119\n",
      "Iteration 2324, loss = 0.01379334\n",
      "Iteration 2325, loss = 0.01378578\n",
      "Iteration 2326, loss = 0.01377890\n",
      "Iteration 2327, loss = 0.01377129\n",
      "Iteration 2328, loss = 0.01376474\n",
      "Iteration 2329, loss = 0.01375631\n",
      "Iteration 2330, loss = 0.01374909\n",
      "Iteration 2331, loss = 0.01374103\n",
      "Iteration 2332, loss = 0.01373558\n",
      "Iteration 2333, loss = 0.01372759\n",
      "Iteration 2334, loss = 0.01372051\n",
      "Iteration 2335, loss = 0.01371418\n",
      "Iteration 2336, loss = 0.01370530\n",
      "Iteration 2337, loss = 0.01369839\n",
      "Iteration 2338, loss = 0.01369051\n",
      "Iteration 2339, loss = 0.01368293\n",
      "Iteration 2340, loss = 0.01367502\n",
      "Iteration 2341, loss = 0.01366731\n",
      "Iteration 2342, loss = 0.01366028\n",
      "Iteration 2343, loss = 0.01365092\n",
      "Iteration 2344, loss = 0.01364304\n",
      "Iteration 2345, loss = 0.01363706\n",
      "Iteration 2346, loss = 0.01362774\n",
      "Iteration 2347, loss = 0.01361977\n",
      "Iteration 2348, loss = 0.01361178\n",
      "Iteration 2349, loss = 0.01360386\n",
      "Iteration 2350, loss = 0.01359678\n",
      "Iteration 2351, loss = 0.01358907\n",
      "Iteration 2352, loss = 0.01358272\n",
      "Iteration 2353, loss = 0.01357511\n",
      "Iteration 2354, loss = 0.01356689\n",
      "Iteration 2355, loss = 0.01356055\n",
      "Iteration 2356, loss = 0.01355126\n",
      "Iteration 2357, loss = 0.01354357\n",
      "Iteration 2358, loss = 0.01353561\n",
      "Iteration 2359, loss = 0.01352904\n",
      "Iteration 2360, loss = 0.01351954\n",
      "Iteration 2361, loss = 0.01350995\n",
      "Iteration 2362, loss = 0.01350025\n",
      "Iteration 2363, loss = 0.01349266\n",
      "Iteration 2364, loss = 0.01348442\n",
      "Iteration 2365, loss = 0.01347832\n",
      "Iteration 2366, loss = 0.01346983\n",
      "Iteration 2367, loss = 0.01346224\n",
      "Iteration 2368, loss = 0.01345449\n",
      "Iteration 2369, loss = 0.01344680\n",
      "Iteration 2370, loss = 0.01343902\n",
      "Iteration 2371, loss = 0.01343167\n",
      "Iteration 2372, loss = 0.01342375\n",
      "Iteration 2373, loss = 0.01341532\n",
      "Iteration 2374, loss = 0.01340722\n",
      "Iteration 2375, loss = 0.01339926\n",
      "Iteration 2376, loss = 0.01339219\n",
      "Iteration 2377, loss = 0.01338418\n",
      "Iteration 2378, loss = 0.01337727\n",
      "Iteration 2379, loss = 0.01336924\n",
      "Iteration 2380, loss = 0.01336196\n",
      "Iteration 2381, loss = 0.01335308\n",
      "Iteration 2382, loss = 0.01334533\n",
      "Iteration 2383, loss = 0.01333811\n",
      "Iteration 2384, loss = 0.01333038\n",
      "Iteration 2385, loss = 0.01332349\n",
      "Iteration 2386, loss = 0.01331657\n",
      "Iteration 2387, loss = 0.01330860\n",
      "Iteration 2388, loss = 0.01330359\n",
      "Iteration 2389, loss = 0.01329692\n",
      "Iteration 2390, loss = 0.01328810\n",
      "Iteration 2391, loss = 0.01327993\n",
      "Iteration 2392, loss = 0.01327269\n",
      "Iteration 2393, loss = 0.01326536\n",
      "Iteration 2394, loss = 0.01325942\n",
      "Iteration 2395, loss = 0.01325164\n",
      "Iteration 2396, loss = 0.01324433\n",
      "Iteration 2397, loss = 0.01323650\n",
      "Iteration 2398, loss = 0.01322963\n",
      "Iteration 2399, loss = 0.01322252\n",
      "Iteration 2400, loss = 0.01321621\n",
      "Iteration 2401, loss = 0.01320965\n",
      "Iteration 2402, loss = 0.01320064\n",
      "Iteration 2403, loss = 0.01319390\n",
      "Iteration 2404, loss = 0.01318536\n",
      "Iteration 2405, loss = 0.01317981\n",
      "Iteration 2406, loss = 0.01317129\n",
      "Iteration 2407, loss = 0.01316437\n",
      "Iteration 2408, loss = 0.01315830\n",
      "Iteration 2409, loss = 0.01315024\n",
      "Iteration 2410, loss = 0.01314302\n",
      "Iteration 2411, loss = 0.01313653\n",
      "Iteration 2412, loss = 0.01312967\n",
      "Iteration 2413, loss = 0.01312276\n",
      "Iteration 2414, loss = 0.01311594\n",
      "Iteration 2415, loss = 0.01311001\n",
      "Iteration 2416, loss = 0.01310434\n",
      "Iteration 2417, loss = 0.01309616\n",
      "Iteration 2418, loss = 0.01309084\n",
      "Iteration 2419, loss = 0.01308204\n",
      "Iteration 2420, loss = 0.01307501\n",
      "Iteration 2421, loss = 0.01306894\n",
      "Iteration 2422, loss = 0.01306166\n",
      "Iteration 2423, loss = 0.01305433\n",
      "Iteration 2424, loss = 0.01304689\n",
      "Iteration 2425, loss = 0.01304017\n",
      "Iteration 2426, loss = 0.01303455\n",
      "Iteration 2427, loss = 0.01302754\n",
      "Iteration 2428, loss = 0.01302045\n",
      "Iteration 2429, loss = 0.01301760\n",
      "Iteration 2430, loss = 0.01300796\n",
      "Iteration 2431, loss = 0.01300146\n",
      "Iteration 2432, loss = 0.01299371\n",
      "Iteration 2433, loss = 0.01298815\n",
      "Iteration 2434, loss = 0.01297980\n",
      "Iteration 2435, loss = 0.01297280\n",
      "Iteration 2436, loss = 0.01296488\n",
      "Iteration 2437, loss = 0.01295869\n",
      "Iteration 2438, loss = 0.01295088\n",
      "Iteration 2439, loss = 0.01294378\n",
      "Iteration 2440, loss = 0.01293679\n",
      "Iteration 2441, loss = 0.01293076\n",
      "Iteration 2442, loss = 0.01292338\n",
      "Iteration 2443, loss = 0.01291647\n",
      "Iteration 2444, loss = 0.01291021\n",
      "Iteration 2445, loss = 0.01290371\n",
      "Iteration 2446, loss = 0.01289625\n",
      "Iteration 2447, loss = 0.01288915\n",
      "Iteration 2448, loss = 0.01288214\n",
      "Iteration 2449, loss = 0.01287401\n",
      "Iteration 2450, loss = 0.01286743\n",
      "Iteration 2451, loss = 0.01286103\n",
      "Iteration 2452, loss = 0.01285411\n",
      "Iteration 2453, loss = 0.01284648\n",
      "Iteration 2454, loss = 0.01283937\n",
      "Iteration 2455, loss = 0.01283209\n",
      "Iteration 2456, loss = 0.01282476\n",
      "Iteration 2457, loss = 0.01281774\n",
      "Iteration 2458, loss = 0.01281372\n",
      "Iteration 2459, loss = 0.01280638\n",
      "Iteration 2460, loss = 0.01279902\n",
      "Iteration 2461, loss = 0.01279275\n",
      "Iteration 2462, loss = 0.01278921\n",
      "Iteration 2463, loss = 0.01277893\n",
      "Iteration 2464, loss = 0.01277182\n",
      "Iteration 2465, loss = 0.01276455\n",
      "Iteration 2466, loss = 0.01275705\n",
      "Iteration 2467, loss = 0.01274915\n",
      "Iteration 2468, loss = 0.01274445\n",
      "Iteration 2469, loss = 0.01273621\n",
      "Iteration 2470, loss = 0.01272945\n",
      "Iteration 2471, loss = 0.01272333\n",
      "Iteration 2472, loss = 0.01271666\n",
      "Iteration 2473, loss = 0.01271082\n",
      "Iteration 2474, loss = 0.01270473\n",
      "Iteration 2475, loss = 0.01269843\n",
      "Iteration 2476, loss = 0.01269305\n",
      "Iteration 2477, loss = 0.01268666\n",
      "Iteration 2478, loss = 0.01267975\n",
      "Iteration 2479, loss = 0.01267436\n",
      "Iteration 2480, loss = 0.01266706\n",
      "Iteration 2481, loss = 0.01266025\n",
      "Iteration 2482, loss = 0.01265303\n",
      "Iteration 2483, loss = 0.01264502\n",
      "Iteration 2484, loss = 0.01263899\n",
      "Iteration 2485, loss = 0.01263045\n",
      "Iteration 2486, loss = 0.01262284\n",
      "Iteration 2487, loss = 0.01261758\n",
      "Iteration 2488, loss = 0.01260870\n",
      "Iteration 2489, loss = 0.01260171\n",
      "Iteration 2490, loss = 0.01259468\n",
      "Iteration 2491, loss = 0.01258893\n",
      "Iteration 2492, loss = 0.01257925\n",
      "Iteration 2493, loss = 0.01257313\n",
      "Iteration 2494, loss = 0.01256496\n",
      "Iteration 2495, loss = 0.01255834\n",
      "Iteration 2496, loss = 0.01255103\n",
      "Iteration 2497, loss = 0.01254439\n",
      "Iteration 2498, loss = 0.01253868\n",
      "Iteration 2499, loss = 0.01253018\n",
      "Iteration 2500, loss = 0.01252363\n",
      "Iteration 2501, loss = 0.01251606\n",
      "Iteration 2502, loss = 0.01250990\n",
      "Iteration 2503, loss = 0.01250418\n",
      "Iteration 2504, loss = 0.01249601\n",
      "Iteration 2505, loss = 0.01249008\n",
      "Iteration 2506, loss = 0.01248282\n",
      "Iteration 2507, loss = 0.01247699\n",
      "Iteration 2508, loss = 0.01246940\n",
      "Iteration 2509, loss = 0.01246157\n",
      "Iteration 2510, loss = 0.01245478\n",
      "Iteration 2511, loss = 0.01244943\n",
      "Iteration 2512, loss = 0.01244156\n",
      "Iteration 2513, loss = 0.01243441\n",
      "Iteration 2514, loss = 0.01242859\n",
      "Iteration 2515, loss = 0.01242367\n",
      "Iteration 2516, loss = 0.01241517\n",
      "Iteration 2517, loss = 0.01240763\n",
      "Iteration 2518, loss = 0.01240074\n",
      "Iteration 2519, loss = 0.01239420\n",
      "Iteration 2520, loss = 0.01238732\n",
      "Iteration 2521, loss = 0.01238097\n",
      "Iteration 2522, loss = 0.01237318\n",
      "Iteration 2523, loss = 0.01236663\n",
      "Iteration 2524, loss = 0.01235988\n",
      "Iteration 2525, loss = 0.01235270\n",
      "Iteration 2526, loss = 0.01234800\n",
      "Iteration 2527, loss = 0.01233972\n",
      "Iteration 2528, loss = 0.01233295\n",
      "Iteration 2529, loss = 0.01232654\n",
      "Iteration 2530, loss = 0.01231938\n",
      "Iteration 2531, loss = 0.01231156\n",
      "Iteration 2532, loss = 0.01230842\n",
      "Iteration 2533, loss = 0.01230124\n",
      "Iteration 2534, loss = 0.01229455\n",
      "Iteration 2535, loss = 0.01228802\n",
      "Iteration 2536, loss = 0.01228213\n",
      "Iteration 2537, loss = 0.01227683\n",
      "Iteration 2538, loss = 0.01227013\n",
      "Iteration 2539, loss = 0.01226466\n",
      "Iteration 2540, loss = 0.01225838\n",
      "Iteration 2541, loss = 0.01225176\n",
      "Iteration 2542, loss = 0.01224568\n",
      "Iteration 2543, loss = 0.01223951\n",
      "Iteration 2544, loss = 0.01223349\n",
      "Iteration 2545, loss = 0.01222827\n",
      "Iteration 2546, loss = 0.01222149\n",
      "Iteration 2547, loss = 0.01221638\n",
      "Iteration 2548, loss = 0.01220936\n",
      "Iteration 2549, loss = 0.01220312\n",
      "Iteration 2550, loss = 0.01219698\n",
      "Iteration 2551, loss = 0.01219024\n",
      "Iteration 2552, loss = 0.01218391\n",
      "Iteration 2553, loss = 0.01217746\n",
      "Iteration 2554, loss = 0.01217163\n",
      "Iteration 2555, loss = 0.01216477\n",
      "Iteration 2556, loss = 0.01215898\n",
      "Iteration 2557, loss = 0.01215238\n",
      "Iteration 2558, loss = 0.01214627\n",
      "Iteration 2559, loss = 0.01214044\n",
      "Iteration 2560, loss = 0.01213464\n",
      "Iteration 2561, loss = 0.01212888\n",
      "Iteration 2562, loss = 0.01212303\n",
      "Iteration 2563, loss = 0.01211754\n",
      "Iteration 2564, loss = 0.01211221\n",
      "Iteration 2565, loss = 0.01210626\n",
      "Iteration 2566, loss = 0.01209957\n",
      "Iteration 2567, loss = 0.01209560\n",
      "Iteration 2568, loss = 0.01208710\n",
      "Iteration 2569, loss = 0.01208200\n",
      "Iteration 2570, loss = 0.01207529\n",
      "Iteration 2571, loss = 0.01206659\n",
      "Iteration 2572, loss = 0.01206155\n",
      "Iteration 2573, loss = 0.01205388\n",
      "Iteration 2574, loss = 0.01204665\n",
      "Iteration 2575, loss = 0.01204022\n",
      "Iteration 2576, loss = 0.01203337\n",
      "Iteration 2577, loss = 0.01202636\n",
      "Iteration 2578, loss = 0.01201926\n",
      "Iteration 2579, loss = 0.01201389\n",
      "Iteration 2580, loss = 0.01200761\n",
      "Iteration 2581, loss = 0.01199977\n",
      "Iteration 2582, loss = 0.01199359\n",
      "Iteration 2583, loss = 0.01198746\n",
      "Iteration 2584, loss = 0.01198088\n",
      "Iteration 2585, loss = 0.01197573\n",
      "Iteration 2586, loss = 0.01196831\n",
      "Iteration 2587, loss = 0.01196259\n",
      "Iteration 2588, loss = 0.01195576\n",
      "Iteration 2589, loss = 0.01195006\n",
      "Iteration 2590, loss = 0.01194498\n",
      "Iteration 2591, loss = 0.01193776\n",
      "Iteration 2592, loss = 0.01193186\n",
      "Iteration 2593, loss = 0.01192688\n",
      "Iteration 2594, loss = 0.01192025\n",
      "Iteration 2595, loss = 0.01191389\n",
      "Iteration 2596, loss = 0.01190818\n",
      "Iteration 2597, loss = 0.01190226\n",
      "Iteration 2598, loss = 0.01189634\n",
      "Iteration 2599, loss = 0.01189094\n",
      "Iteration 2600, loss = 0.01188528\n",
      "Iteration 2601, loss = 0.01187896\n",
      "Iteration 2602, loss = 0.01187309\n",
      "Iteration 2603, loss = 0.01186889\n",
      "Iteration 2604, loss = 0.01186227\n",
      "Iteration 2605, loss = 0.01185664\n",
      "Iteration 2606, loss = 0.01185037\n",
      "Iteration 2607, loss = 0.01184457\n",
      "Iteration 2608, loss = 0.01183957\n",
      "Iteration 2609, loss = 0.01183378\n",
      "Iteration 2610, loss = 0.01182761\n",
      "Iteration 2611, loss = 0.01182285\n",
      "Iteration 2612, loss = 0.01181684\n",
      "Iteration 2613, loss = 0.01181129\n",
      "Iteration 2614, loss = 0.01180434\n",
      "Iteration 2615, loss = 0.01179902\n",
      "Iteration 2616, loss = 0.01179169\n",
      "Iteration 2617, loss = 0.01178610\n",
      "Iteration 2618, loss = 0.01177832\n",
      "Iteration 2619, loss = 0.01177189\n",
      "Iteration 2620, loss = 0.01176445\n",
      "Iteration 2621, loss = 0.01175748\n",
      "Iteration 2622, loss = 0.01175202\n",
      "Iteration 2623, loss = 0.01174468\n",
      "Iteration 2624, loss = 0.01173836\n",
      "Iteration 2625, loss = 0.01173172\n",
      "Iteration 2626, loss = 0.01172544\n",
      "Iteration 2627, loss = 0.01171912\n",
      "Iteration 2628, loss = 0.01171357\n",
      "Iteration 2629, loss = 0.01170679\n",
      "Iteration 2630, loss = 0.01170051\n",
      "Iteration 2631, loss = 0.01169399\n",
      "Iteration 2632, loss = 0.01168850\n",
      "Iteration 2633, loss = 0.01168184\n",
      "Iteration 2634, loss = 0.01167727\n",
      "Iteration 2635, loss = 0.01166973\n",
      "Iteration 2636, loss = 0.01166402\n",
      "Iteration 2637, loss = 0.01165779\n",
      "Iteration 2638, loss = 0.01165339\n",
      "Iteration 2639, loss = 0.01164594\n",
      "Iteration 2640, loss = 0.01164029\n",
      "Iteration 2641, loss = 0.01163449\n",
      "Iteration 2642, loss = 0.01162814\n",
      "Iteration 2643, loss = 0.01162228\n",
      "Iteration 2644, loss = 0.01161611\n",
      "Iteration 2645, loss = 0.01161009\n",
      "Iteration 2646, loss = 0.01160497\n",
      "Iteration 2647, loss = 0.01159979\n",
      "Iteration 2648, loss = 0.01159304\n",
      "Iteration 2649, loss = 0.01158693\n",
      "Iteration 2650, loss = 0.01158168\n",
      "Iteration 2651, loss = 0.01157450\n",
      "Iteration 2652, loss = 0.01156907\n",
      "Iteration 2653, loss = 0.01156466\n",
      "Iteration 2654, loss = 0.01155661\n",
      "Iteration 2655, loss = 0.01155115\n",
      "Iteration 2656, loss = 0.01154646\n",
      "Iteration 2657, loss = 0.01153970\n",
      "Iteration 2658, loss = 0.01153234\n",
      "Iteration 2659, loss = 0.01152671\n",
      "Iteration 2660, loss = 0.01151987\n",
      "Iteration 2661, loss = 0.01151486\n",
      "Iteration 2662, loss = 0.01150813\n",
      "Iteration 2663, loss = 0.01150229\n",
      "Iteration 2664, loss = 0.01149621\n",
      "Iteration 2665, loss = 0.01149070\n",
      "Iteration 2666, loss = 0.01148653\n",
      "Iteration 2667, loss = 0.01147936\n",
      "Iteration 2668, loss = 0.01147409\n",
      "Iteration 2669, loss = 0.01146767\n",
      "Iteration 2670, loss = 0.01146193\n",
      "Iteration 2671, loss = 0.01145576\n",
      "Iteration 2672, loss = 0.01145269\n",
      "Iteration 2673, loss = 0.01144626\n",
      "Iteration 2674, loss = 0.01144078\n",
      "Iteration 2675, loss = 0.01143476\n",
      "Iteration 2676, loss = 0.01142918\n",
      "Iteration 2677, loss = 0.01142380\n",
      "Iteration 2678, loss = 0.01141846\n",
      "Iteration 2679, loss = 0.01141257\n",
      "Iteration 2680, loss = 0.01140673\n",
      "Iteration 2681, loss = 0.01140195\n",
      "Iteration 2682, loss = 0.01139595\n",
      "Iteration 2683, loss = 0.01139048\n",
      "Iteration 2684, loss = 0.01138439\n",
      "Iteration 2685, loss = 0.01137879\n",
      "Iteration 2686, loss = 0.01137349\n",
      "Iteration 2687, loss = 0.01136811\n",
      "Iteration 2688, loss = 0.01136344\n",
      "Iteration 2689, loss = 0.01135749\n",
      "Iteration 2690, loss = 0.01135212\n",
      "Iteration 2691, loss = 0.01134762\n",
      "Iteration 2692, loss = 0.01134208\n",
      "Iteration 2693, loss = 0.01133692\n",
      "Iteration 2694, loss = 0.01133236\n",
      "Iteration 2695, loss = 0.01132615\n",
      "Iteration 2696, loss = 0.01132072\n",
      "Iteration 2697, loss = 0.01131518\n",
      "Iteration 2698, loss = 0.01130980\n",
      "Iteration 2699, loss = 0.01130437\n",
      "Iteration 2700, loss = 0.01129901\n",
      "Iteration 2701, loss = 0.01129323\n",
      "Iteration 2702, loss = 0.01128739\n",
      "Iteration 2703, loss = 0.01128169\n",
      "Iteration 2704, loss = 0.01127676\n",
      "Iteration 2705, loss = 0.01127065\n",
      "Iteration 2706, loss = 0.01126530\n",
      "Iteration 2707, loss = 0.01125980\n",
      "Iteration 2708, loss = 0.01125399\n",
      "Iteration 2709, loss = 0.01124845\n",
      "Iteration 2710, loss = 0.01124493\n",
      "Iteration 2711, loss = 0.01123821\n",
      "Iteration 2712, loss = 0.01123367\n",
      "Iteration 2713, loss = 0.01122867\n",
      "Iteration 2714, loss = 0.01122655\n",
      "Iteration 2715, loss = 0.01122164\n",
      "Iteration 2716, loss = 0.01121382\n",
      "Iteration 2717, loss = 0.01120821\n",
      "Iteration 2718, loss = 0.01120229\n",
      "Iteration 2719, loss = 0.01119655\n",
      "Iteration 2720, loss = 0.01119148\n",
      "Iteration 2721, loss = 0.01118534\n",
      "Iteration 2722, loss = 0.01117947\n",
      "Iteration 2723, loss = 0.01117365\n",
      "Iteration 2724, loss = 0.01116774\n",
      "Iteration 2725, loss = 0.01116229\n",
      "Iteration 2726, loss = 0.01115694\n",
      "Iteration 2727, loss = 0.01115198\n",
      "Iteration 2728, loss = 0.01114504\n",
      "Iteration 2729, loss = 0.01114087\n",
      "Iteration 2730, loss = 0.01113425\n",
      "Iteration 2731, loss = 0.01112872\n",
      "Iteration 2732, loss = 0.01112233\n",
      "Iteration 2733, loss = 0.01111683\n",
      "Iteration 2734, loss = 0.01111062\n",
      "Iteration 2735, loss = 0.01110500\n",
      "Iteration 2736, loss = 0.01109994\n",
      "Iteration 2737, loss = 0.01109312\n",
      "Iteration 2738, loss = 0.01108805\n",
      "Iteration 2739, loss = 0.01108363\n",
      "Iteration 2740, loss = 0.01107675\n",
      "Iteration 2741, loss = 0.01107231\n",
      "Iteration 2742, loss = 0.01106653\n",
      "Iteration 2743, loss = 0.01106099\n",
      "Iteration 2744, loss = 0.01105589\n",
      "Iteration 2745, loss = 0.01105077\n",
      "Iteration 2746, loss = 0.01104485\n",
      "Iteration 2747, loss = 0.01104110\n",
      "Iteration 2748, loss = 0.01103528\n",
      "Iteration 2749, loss = 0.01102892\n",
      "Iteration 2750, loss = 0.01102361\n",
      "Iteration 2751, loss = 0.01101821\n",
      "Iteration 2752, loss = 0.01101191\n",
      "Iteration 2753, loss = 0.01100697\n",
      "Iteration 2754, loss = 0.01100108\n",
      "Iteration 2755, loss = 0.01099621\n",
      "Iteration 2756, loss = 0.01099084\n",
      "Iteration 2757, loss = 0.01098525\n",
      "Iteration 2758, loss = 0.01097978\n",
      "Iteration 2759, loss = 0.01097419\n",
      "Iteration 2760, loss = 0.01097074\n",
      "Iteration 2761, loss = 0.01096496\n",
      "Iteration 2762, loss = 0.01095969\n",
      "Iteration 2763, loss = 0.01095406\n",
      "Iteration 2764, loss = 0.01094913\n",
      "Iteration 2765, loss = 0.01094430\n",
      "Iteration 2766, loss = 0.01093868\n",
      "Iteration 2767, loss = 0.01093338\n",
      "Iteration 2768, loss = 0.01092813\n",
      "Iteration 2769, loss = 0.01092321\n",
      "Iteration 2770, loss = 0.01091830\n",
      "Iteration 2771, loss = 0.01091260\n",
      "Iteration 2772, loss = 0.01090755\n",
      "Iteration 2773, loss = 0.01090242\n",
      "Iteration 2774, loss = 0.01089749\n",
      "Iteration 2775, loss = 0.01089255\n",
      "Iteration 2776, loss = 0.01088669\n",
      "Iteration 2777, loss = 0.01088130\n",
      "Iteration 2778, loss = 0.01087582\n",
      "Iteration 2779, loss = 0.01087143\n",
      "Iteration 2780, loss = 0.01086620\n",
      "Iteration 2781, loss = 0.01086113\n",
      "Iteration 2782, loss = 0.01085498\n",
      "Iteration 2783, loss = 0.01084951\n",
      "Iteration 2784, loss = 0.01084524\n",
      "Iteration 2785, loss = 0.01083939\n",
      "Iteration 2786, loss = 0.01083386\n",
      "Iteration 2787, loss = 0.01082847\n",
      "Iteration 2788, loss = 0.01082273\n",
      "Iteration 2789, loss = 0.01081779\n",
      "Iteration 2790, loss = 0.01081316\n",
      "Iteration 2791, loss = 0.01080726\n",
      "Iteration 2792, loss = 0.01080184\n",
      "Iteration 2793, loss = 0.01079694\n",
      "Iteration 2794, loss = 0.01079109\n",
      "Iteration 2795, loss = 0.01078748\n",
      "Iteration 2796, loss = 0.01078147\n",
      "Iteration 2797, loss = 0.01077556\n",
      "Iteration 2798, loss = 0.01077078\n",
      "Iteration 2799, loss = 0.01076615\n",
      "Iteration 2800, loss = 0.01076082\n",
      "Iteration 2801, loss = 0.01075588\n",
      "Iteration 2802, loss = 0.01075020\n",
      "Iteration 2803, loss = 0.01074506\n",
      "Iteration 2804, loss = 0.01073990\n",
      "Iteration 2805, loss = 0.01073547\n",
      "Iteration 2806, loss = 0.01072992\n",
      "Iteration 2807, loss = 0.01072339\n",
      "Iteration 2808, loss = 0.01071777\n",
      "Iteration 2809, loss = 0.01071338\n",
      "Iteration 2810, loss = 0.01070680\n",
      "Iteration 2811, loss = 0.01070184\n",
      "Iteration 2812, loss = 0.01069654\n",
      "Iteration 2813, loss = 0.01069187\n",
      "Iteration 2814, loss = 0.01068650\n",
      "Iteration 2815, loss = 0.01068149\n",
      "Iteration 2816, loss = 0.01067784\n",
      "Iteration 2817, loss = 0.01067205\n",
      "Iteration 2818, loss = 0.01066731\n",
      "Iteration 2819, loss = 0.01066184\n",
      "Iteration 2820, loss = 0.01065716\n",
      "Iteration 2821, loss = 0.01065171\n",
      "Iteration 2822, loss = 0.01064710\n",
      "Iteration 2823, loss = 0.01064193\n",
      "Iteration 2824, loss = 0.01063755\n",
      "Iteration 2825, loss = 0.01063344\n",
      "Iteration 2826, loss = 0.01063121\n",
      "Iteration 2827, loss = 0.01062432\n",
      "Iteration 2828, loss = 0.01061947\n",
      "Iteration 2829, loss = 0.01061465\n",
      "Iteration 2830, loss = 0.01061088\n",
      "Iteration 2831, loss = 0.01060562\n",
      "Iteration 2832, loss = 0.01060327\n",
      "Iteration 2833, loss = 0.01059702\n",
      "Iteration 2834, loss = 0.01059385\n",
      "Iteration 2835, loss = 0.01058825\n",
      "Iteration 2836, loss = 0.01058325\n",
      "Iteration 2837, loss = 0.01057889\n",
      "Iteration 2838, loss = 0.01057437\n",
      "Iteration 2839, loss = 0.01057013\n",
      "Iteration 2840, loss = 0.01056609\n",
      "Iteration 2841, loss = 0.01056116\n",
      "Iteration 2842, loss = 0.01055643\n",
      "Iteration 2843, loss = 0.01055159\n",
      "Iteration 2844, loss = 0.01054670\n",
      "Iteration 2845, loss = 0.01054183\n",
      "Iteration 2846, loss = 0.01053708\n",
      "Iteration 2847, loss = 0.01053154\n",
      "Iteration 2848, loss = 0.01052616\n",
      "Iteration 2849, loss = 0.01052109\n",
      "Iteration 2850, loss = 0.01051555\n",
      "Iteration 2851, loss = 0.01051051\n",
      "Iteration 2852, loss = 0.01050339\n",
      "Iteration 2853, loss = 0.01049812\n",
      "Iteration 2854, loss = 0.01049345\n",
      "Iteration 2855, loss = 0.01048765\n",
      "Iteration 2856, loss = 0.01048264\n",
      "Iteration 2857, loss = 0.01047723\n",
      "Iteration 2858, loss = 0.01047278\n",
      "Iteration 2859, loss = 0.01046767\n",
      "Iteration 2860, loss = 0.01046292\n",
      "Iteration 2861, loss = 0.01045808\n",
      "Iteration 2862, loss = 0.01045369\n",
      "Iteration 2863, loss = 0.01044885\n",
      "Iteration 2864, loss = 0.01044424\n",
      "Iteration 2865, loss = 0.01044018\n",
      "Iteration 2866, loss = 0.01043512\n",
      "Iteration 2867, loss = 0.01043055\n",
      "Iteration 2868, loss = 0.01042623\n",
      "Iteration 2869, loss = 0.01042131\n",
      "Iteration 2870, loss = 0.01041659\n",
      "Iteration 2871, loss = 0.01041116\n",
      "Iteration 2872, loss = 0.01040637\n",
      "Iteration 2873, loss = 0.01040231\n",
      "Iteration 2874, loss = 0.01039703\n",
      "Iteration 2875, loss = 0.01039275\n",
      "Iteration 2876, loss = 0.01038782\n",
      "Iteration 2877, loss = 0.01038380\n",
      "Iteration 2878, loss = 0.01037941\n",
      "Iteration 2879, loss = 0.01037395\n",
      "Iteration 2880, loss = 0.01036920\n",
      "Iteration 2881, loss = 0.01036384\n",
      "Iteration 2882, loss = 0.01035978\n",
      "Iteration 2883, loss = 0.01035377\n",
      "Iteration 2884, loss = 0.01035007\n",
      "Iteration 2885, loss = 0.01034490\n",
      "Iteration 2886, loss = 0.01034051\n",
      "Iteration 2887, loss = 0.01033578\n",
      "Iteration 2888, loss = 0.01033169\n",
      "Iteration 2889, loss = 0.01032809\n",
      "Iteration 2890, loss = 0.01032312\n",
      "Iteration 2891, loss = 0.01031914\n",
      "Iteration 2892, loss = 0.01031401\n",
      "Iteration 2893, loss = 0.01030970\n",
      "Iteration 2894, loss = 0.01030493\n",
      "Iteration 2895, loss = 0.01030068\n",
      "Iteration 2896, loss = 0.01029527\n",
      "Iteration 2897, loss = 0.01029063\n",
      "Iteration 2898, loss = 0.01028587\n",
      "Iteration 2899, loss = 0.01028193\n",
      "Iteration 2900, loss = 0.01027660\n",
      "Iteration 2901, loss = 0.01027157\n",
      "Iteration 2902, loss = 0.01026759\n",
      "Iteration 2903, loss = 0.01026312\n",
      "Iteration 2904, loss = 0.01025812\n",
      "Iteration 2905, loss = 0.01025340\n",
      "Iteration 2906, loss = 0.01024859\n",
      "Iteration 2907, loss = 0.01024414\n",
      "Iteration 2908, loss = 0.01023923\n",
      "Iteration 2909, loss = 0.01023437\n",
      "Iteration 2910, loss = 0.01022986\n",
      "Iteration 2911, loss = 0.01022521\n",
      "Iteration 2912, loss = 0.01022052\n",
      "Iteration 2913, loss = 0.01021582\n",
      "Iteration 2914, loss = 0.01021146\n",
      "Iteration 2915, loss = 0.01020715\n",
      "Iteration 2916, loss = 0.01020227\n",
      "Iteration 2917, loss = 0.01019785\n",
      "Iteration 2918, loss = 0.01019372\n",
      "Iteration 2919, loss = 0.01018902\n",
      "Iteration 2920, loss = 0.01018583\n",
      "Iteration 2921, loss = 0.01018074\n",
      "Iteration 2922, loss = 0.01017649\n",
      "Iteration 2923, loss = 0.01017248\n",
      "Iteration 2924, loss = 0.01016820\n",
      "Iteration 2925, loss = 0.01016456\n",
      "Iteration 2926, loss = 0.01015963\n",
      "Iteration 2927, loss = 0.01015509\n",
      "Iteration 2928, loss = 0.01015071\n",
      "Iteration 2929, loss = 0.01014681\n",
      "Iteration 2930, loss = 0.01014073\n",
      "Iteration 2931, loss = 0.01013576\n",
      "Iteration 2932, loss = 0.01013213\n",
      "Iteration 2933, loss = 0.01012710\n",
      "Iteration 2934, loss = 0.01012225\n",
      "Iteration 2935, loss = 0.01011760\n",
      "Iteration 2936, loss = 0.01011209\n",
      "Iteration 2937, loss = 0.01010824\n",
      "Iteration 2938, loss = 0.01010280\n",
      "Iteration 2939, loss = 0.01009860\n",
      "Iteration 2940, loss = 0.01009378\n",
      "Iteration 2941, loss = 0.01008945\n",
      "Iteration 2942, loss = 0.01008416\n",
      "Iteration 2943, loss = 0.01007994\n",
      "Iteration 2944, loss = 0.01007496\n",
      "Iteration 2945, loss = 0.01007109\n",
      "Iteration 2946, loss = 0.01006721\n",
      "Iteration 2947, loss = 0.01006249\n",
      "Iteration 2948, loss = 0.01005870\n",
      "Iteration 2949, loss = 0.01005525\n",
      "Iteration 2950, loss = 0.01005065\n",
      "Iteration 2951, loss = 0.01004640\n",
      "Iteration 2952, loss = 0.01004286\n",
      "Iteration 2953, loss = 0.01003778\n",
      "Iteration 2954, loss = 0.01003278\n",
      "Iteration 2955, loss = 0.01002940\n",
      "Iteration 2956, loss = 0.01002510\n",
      "Iteration 2957, loss = 0.01001975\n",
      "Iteration 2958, loss = 0.01001555\n",
      "Iteration 2959, loss = 0.01001150\n",
      "Iteration 2960, loss = 0.01000649\n",
      "Iteration 2961, loss = 0.01000241\n",
      "Iteration 2962, loss = 0.00999783\n",
      "Iteration 2963, loss = 0.00999314\n",
      "Iteration 2964, loss = 0.00998812\n",
      "Iteration 2965, loss = 0.00998387\n",
      "Iteration 2966, loss = 0.00997972\n",
      "Iteration 2967, loss = 0.00997830\n",
      "Iteration 2968, loss = 0.00997169\n",
      "Iteration 2969, loss = 0.00996900\n",
      "Iteration 2970, loss = 0.00996297\n",
      "Iteration 2971, loss = 0.00995846\n",
      "Iteration 2972, loss = 0.00995414\n",
      "Iteration 2973, loss = 0.00994984\n",
      "Iteration 2974, loss = 0.00994537\n",
      "Iteration 2975, loss = 0.00994142\n",
      "Iteration 2976, loss = 0.00993728\n",
      "Iteration 2977, loss = 0.00993311\n",
      "Iteration 2978, loss = 0.00992914\n",
      "Iteration 2979, loss = 0.00992546\n",
      "Iteration 2980, loss = 0.00992210\n",
      "Iteration 2981, loss = 0.00991815\n",
      "Iteration 2982, loss = 0.00991441\n",
      "Iteration 2983, loss = 0.00991033\n",
      "Iteration 2984, loss = 0.00990628\n",
      "Iteration 2985, loss = 0.00990176\n",
      "Iteration 2986, loss = 0.00989749\n",
      "Iteration 2987, loss = 0.00989361\n",
      "Iteration 2988, loss = 0.00988916\n",
      "Iteration 2989, loss = 0.00988509\n",
      "Iteration 2990, loss = 0.00988094\n",
      "Iteration 2991, loss = 0.00987640\n",
      "Iteration 2992, loss = 0.00987222\n",
      "Iteration 2993, loss = 0.00986764\n",
      "Iteration 2994, loss = 0.00986340\n",
      "Iteration 2995, loss = 0.00985895\n",
      "Iteration 2996, loss = 0.00985479\n",
      "Iteration 2997, loss = 0.00984999\n",
      "Iteration 2998, loss = 0.00984533\n",
      "Iteration 2999, loss = 0.00984129\n",
      "Iteration 3000, loss = 0.00983669\n",
      "Iteration 3001, loss = 0.00983313\n",
      "Iteration 3002, loss = 0.00982802\n",
      "Iteration 3003, loss = 0.00982289\n",
      "Iteration 3004, loss = 0.00981856\n",
      "Iteration 3005, loss = 0.00981422\n",
      "Iteration 3006, loss = 0.00980959\n",
      "Iteration 3007, loss = 0.00980537\n",
      "Iteration 3008, loss = 0.00980139\n",
      "Iteration 3009, loss = 0.00979765\n",
      "Iteration 3010, loss = 0.00979385\n",
      "Iteration 3011, loss = 0.00979013\n",
      "Iteration 3012, loss = 0.00978414\n",
      "Iteration 3013, loss = 0.00977929\n",
      "Iteration 3014, loss = 0.00977484\n",
      "Iteration 3015, loss = 0.00977102\n",
      "Iteration 3016, loss = 0.00976631\n",
      "Iteration 3017, loss = 0.00976141\n",
      "Iteration 3018, loss = 0.00975666\n",
      "Iteration 3019, loss = 0.00975238\n",
      "Iteration 3020, loss = 0.00974775\n",
      "Iteration 3021, loss = 0.00974300\n",
      "Iteration 3022, loss = 0.00973834\n",
      "Iteration 3023, loss = 0.00973291\n",
      "Iteration 3024, loss = 0.00972877\n",
      "Iteration 3025, loss = 0.00972453\n",
      "Iteration 3026, loss = 0.00972025\n",
      "Iteration 3027, loss = 0.00971712\n",
      "Iteration 3028, loss = 0.00971217\n",
      "Iteration 3029, loss = 0.00970783\n",
      "Iteration 3030, loss = 0.00970409\n",
      "Iteration 3031, loss = 0.00970072\n",
      "Iteration 3032, loss = 0.00969470\n",
      "Iteration 3033, loss = 0.00969042\n",
      "Iteration 3034, loss = 0.00968609\n",
      "Iteration 3035, loss = 0.00968102\n",
      "Iteration 3036, loss = 0.00967640\n",
      "Iteration 3037, loss = 0.00967155\n",
      "Iteration 3038, loss = 0.00966685\n",
      "Iteration 3039, loss = 0.00966241\n",
      "Iteration 3040, loss = 0.00965771\n",
      "Iteration 3041, loss = 0.00965386\n",
      "Iteration 3042, loss = 0.00964937\n",
      "Iteration 3043, loss = 0.00964444\n",
      "Iteration 3044, loss = 0.00964075\n",
      "Iteration 3045, loss = 0.00963714\n",
      "Iteration 3046, loss = 0.00963475\n",
      "Iteration 3047, loss = 0.00962923\n",
      "Iteration 3048, loss = 0.00962704\n",
      "Iteration 3049, loss = 0.00962185\n",
      "Iteration 3050, loss = 0.00961868\n",
      "Iteration 3051, loss = 0.00961414\n",
      "Iteration 3052, loss = 0.00961025\n",
      "Iteration 3053, loss = 0.00960573\n",
      "Iteration 3054, loss = 0.00960138\n",
      "Iteration 3055, loss = 0.00959752\n",
      "Iteration 3056, loss = 0.00959312\n",
      "Iteration 3057, loss = 0.00958885\n",
      "Iteration 3058, loss = 0.00958455\n",
      "Iteration 3059, loss = 0.00957990\n",
      "Iteration 3060, loss = 0.00957604\n",
      "Iteration 3061, loss = 0.00957286\n",
      "Iteration 3062, loss = 0.00956774\n",
      "Iteration 3063, loss = 0.00956322\n",
      "Iteration 3064, loss = 0.00955946\n",
      "Iteration 3065, loss = 0.00955464\n",
      "Iteration 3066, loss = 0.00955051\n",
      "Iteration 3067, loss = 0.00954632\n",
      "Iteration 3068, loss = 0.00954211\n",
      "Iteration 3069, loss = 0.00953798\n",
      "Iteration 3070, loss = 0.00953469\n",
      "Iteration 3071, loss = 0.00952969\n",
      "Iteration 3072, loss = 0.00952567\n",
      "Iteration 3073, loss = 0.00952157\n",
      "Iteration 3074, loss = 0.00951791\n",
      "Iteration 3075, loss = 0.00951350\n",
      "Iteration 3076, loss = 0.00950955\n",
      "Iteration 3077, loss = 0.00950650\n",
      "Iteration 3078, loss = 0.00950114\n",
      "Iteration 3079, loss = 0.00949702\n",
      "Iteration 3080, loss = 0.00949464\n",
      "Iteration 3081, loss = 0.00948936\n",
      "Iteration 3082, loss = 0.00948581\n",
      "Iteration 3083, loss = 0.00948188\n",
      "Iteration 3084, loss = 0.00947771\n",
      "Iteration 3085, loss = 0.00947347\n",
      "Iteration 3086, loss = 0.00947039\n",
      "Iteration 3087, loss = 0.00946562\n",
      "Iteration 3088, loss = 0.00946149\n",
      "Iteration 3089, loss = 0.00945749\n",
      "Iteration 3090, loss = 0.00945297\n",
      "Iteration 3091, loss = 0.00944871\n",
      "Iteration 3092, loss = 0.00944498\n",
      "Iteration 3093, loss = 0.00944010\n",
      "Iteration 3094, loss = 0.00943629\n",
      "Iteration 3095, loss = 0.00943201\n",
      "Iteration 3096, loss = 0.00942797\n",
      "Iteration 3097, loss = 0.00942377\n",
      "Iteration 3098, loss = 0.00941901\n",
      "Iteration 3099, loss = 0.00941509\n",
      "Iteration 3100, loss = 0.00941104\n",
      "Iteration 3101, loss = 0.00940695\n",
      "Iteration 3102, loss = 0.00940314\n",
      "Iteration 3103, loss = 0.00939848\n",
      "Iteration 3104, loss = 0.00939582\n",
      "Iteration 3105, loss = 0.00939055\n",
      "Iteration 3106, loss = 0.00938714\n",
      "Iteration 3107, loss = 0.00938271\n",
      "Iteration 3108, loss = 0.00937946\n",
      "Iteration 3109, loss = 0.00937535\n",
      "Iteration 3110, loss = 0.00937144\n",
      "Iteration 3111, loss = 0.00936789\n",
      "Iteration 3112, loss = 0.00936380\n",
      "Iteration 3113, loss = 0.00935962\n",
      "Iteration 3114, loss = 0.00935587\n",
      "Iteration 3115, loss = 0.00935117\n",
      "Iteration 3116, loss = 0.00934699\n",
      "Iteration 3117, loss = 0.00934315\n",
      "Iteration 3118, loss = 0.00933885\n",
      "Iteration 3119, loss = 0.00933524\n",
      "Iteration 3120, loss = 0.00933046\n",
      "Iteration 3121, loss = 0.00932616\n",
      "Iteration 3122, loss = 0.00932256\n",
      "Iteration 3123, loss = 0.00931830\n",
      "Iteration 3124, loss = 0.00931449\n",
      "Iteration 3125, loss = 0.00931059\n",
      "Iteration 3126, loss = 0.00930643\n",
      "Iteration 3127, loss = 0.00930236\n",
      "Iteration 3128, loss = 0.00929794\n",
      "Iteration 3129, loss = 0.00929401\n",
      "Iteration 3130, loss = 0.00928981\n",
      "Iteration 3131, loss = 0.00928573\n",
      "Iteration 3132, loss = 0.00928200\n",
      "Iteration 3133, loss = 0.00927810\n",
      "Iteration 3134, loss = 0.00927426\n",
      "Iteration 3135, loss = 0.00927072\n",
      "Iteration 3136, loss = 0.00926667\n",
      "Iteration 3137, loss = 0.00926308\n",
      "Iteration 3138, loss = 0.00926107\n",
      "Iteration 3139, loss = 0.00925568\n",
      "Iteration 3140, loss = 0.00925172\n",
      "Iteration 3141, loss = 0.00924721\n",
      "Iteration 3142, loss = 0.00924337\n",
      "Iteration 3143, loss = 0.00923881\n",
      "Iteration 3144, loss = 0.00923647\n",
      "Iteration 3145, loss = 0.00923004\n",
      "Iteration 3146, loss = 0.00922626\n",
      "Iteration 3147, loss = 0.00922177\n",
      "Iteration 3148, loss = 0.00921760\n",
      "Iteration 3149, loss = 0.00921349\n",
      "Iteration 3150, loss = 0.00920923\n",
      "Iteration 3151, loss = 0.00920690\n",
      "Iteration 3152, loss = 0.00920215\n",
      "Iteration 3153, loss = 0.00919776\n",
      "Iteration 3154, loss = 0.00919365\n",
      "Iteration 3155, loss = 0.00919029\n",
      "Iteration 3156, loss = 0.00918620\n",
      "Iteration 3157, loss = 0.00918317\n",
      "Iteration 3158, loss = 0.00917935\n",
      "Iteration 3159, loss = 0.00917490\n",
      "Iteration 3160, loss = 0.00917115\n",
      "Iteration 3161, loss = 0.00916722\n",
      "Iteration 3162, loss = 0.00916332\n",
      "Iteration 3163, loss = 0.00915911\n",
      "Iteration 3164, loss = 0.00915517\n",
      "Iteration 3165, loss = 0.00915104\n",
      "Iteration 3166, loss = 0.00914878\n",
      "Iteration 3167, loss = 0.00914301\n",
      "Iteration 3168, loss = 0.00914000\n",
      "Iteration 3169, loss = 0.00913682\n",
      "Iteration 3170, loss = 0.00913351\n",
      "Iteration 3171, loss = 0.00912819\n",
      "Iteration 3172, loss = 0.00912326\n",
      "Iteration 3173, loss = 0.00911971\n",
      "Iteration 3174, loss = 0.00911584\n",
      "Iteration 3175, loss = 0.00911150\n",
      "Iteration 3176, loss = 0.00910728\n",
      "Iteration 3177, loss = 0.00910326\n",
      "Iteration 3178, loss = 0.00909977\n",
      "Iteration 3179, loss = 0.00909612\n",
      "Iteration 3180, loss = 0.00909223\n",
      "Iteration 3181, loss = 0.00908808\n",
      "Iteration 3182, loss = 0.00908418\n",
      "Iteration 3183, loss = 0.00908089\n",
      "Iteration 3184, loss = 0.00907681\n",
      "Iteration 3185, loss = 0.00907237\n",
      "Iteration 3186, loss = 0.00906840\n",
      "Iteration 3187, loss = 0.00906477\n",
      "Iteration 3188, loss = 0.00906093\n",
      "Iteration 3189, loss = 0.00905673\n",
      "Iteration 3190, loss = 0.00905353\n",
      "Iteration 3191, loss = 0.00904940\n",
      "Iteration 3192, loss = 0.00904516\n",
      "Iteration 3193, loss = 0.00904147\n",
      "Iteration 3194, loss = 0.00903750\n",
      "Iteration 3195, loss = 0.00903370\n",
      "Iteration 3196, loss = 0.00903014\n",
      "Iteration 3197, loss = 0.00902689\n",
      "Iteration 3198, loss = 0.00902239\n",
      "Iteration 3199, loss = 0.00901865\n",
      "Iteration 3200, loss = 0.00901518\n",
      "Iteration 3201, loss = 0.00901106\n",
      "Iteration 3202, loss = 0.00900706\n",
      "Iteration 3203, loss = 0.00900315\n",
      "Iteration 3204, loss = 0.00899956\n",
      "Iteration 3205, loss = 0.00899550\n",
      "Iteration 3206, loss = 0.00899187\n",
      "Iteration 3207, loss = 0.00898819\n",
      "Iteration 3208, loss = 0.00898377\n",
      "Iteration 3209, loss = 0.00898105\n",
      "Iteration 3210, loss = 0.00897666\n",
      "Iteration 3211, loss = 0.00897275\n",
      "Iteration 3212, loss = 0.00896905\n",
      "Iteration 3213, loss = 0.00896548\n",
      "Iteration 3214, loss = 0.00896105\n",
      "Iteration 3215, loss = 0.00895733\n",
      "Iteration 3216, loss = 0.00895395\n",
      "Iteration 3217, loss = 0.00895016\n",
      "Iteration 3218, loss = 0.00894606\n",
      "Iteration 3219, loss = 0.00894231\n",
      "Iteration 3220, loss = 0.00893875\n",
      "Iteration 3221, loss = 0.00893583\n",
      "Iteration 3222, loss = 0.00893175\n",
      "Iteration 3223, loss = 0.00892861\n",
      "Iteration 3224, loss = 0.00892451\n",
      "Iteration 3225, loss = 0.00892109\n",
      "Iteration 3226, loss = 0.00891770\n",
      "Iteration 3227, loss = 0.00891392\n",
      "Iteration 3228, loss = 0.00891096\n",
      "Iteration 3229, loss = 0.00890723\n",
      "Iteration 3230, loss = 0.00890331\n",
      "Iteration 3231, loss = 0.00889983\n",
      "Iteration 3232, loss = 0.00889588\n",
      "Iteration 3233, loss = 0.00889232\n",
      "Iteration 3234, loss = 0.00888824\n",
      "Iteration 3235, loss = 0.00888601\n",
      "Iteration 3236, loss = 0.00888171\n",
      "Iteration 3237, loss = 0.00887693\n",
      "Iteration 3238, loss = 0.00887330\n",
      "Iteration 3239, loss = 0.00887040\n",
      "Iteration 3240, loss = 0.00886662\n",
      "Iteration 3241, loss = 0.00886319\n",
      "Iteration 3242, loss = 0.00885932\n",
      "Iteration 3243, loss = 0.00885573\n",
      "Iteration 3244, loss = 0.00885237\n",
      "Iteration 3245, loss = 0.00884911\n",
      "Iteration 3246, loss = 0.00884513\n",
      "Iteration 3247, loss = 0.00884144\n",
      "Iteration 3248, loss = 0.00883747\n",
      "Iteration 3249, loss = 0.00883360\n",
      "Iteration 3250, loss = 0.00882997\n",
      "Iteration 3251, loss = 0.00882633\n",
      "Iteration 3252, loss = 0.00882247\n",
      "Iteration 3253, loss = 0.00881888\n",
      "Iteration 3254, loss = 0.00881575\n",
      "Iteration 3255, loss = 0.00881167\n",
      "Iteration 3256, loss = 0.00880844\n",
      "Iteration 3257, loss = 0.00880423\n",
      "Iteration 3258, loss = 0.00880048\n",
      "Iteration 3259, loss = 0.00879734\n",
      "Iteration 3260, loss = 0.00879339\n",
      "Iteration 3261, loss = 0.00878989\n",
      "Iteration 3262, loss = 0.00878619\n",
      "Iteration 3263, loss = 0.00878249\n",
      "Iteration 3264, loss = 0.00877902\n",
      "Iteration 3265, loss = 0.00877582\n",
      "Iteration 3266, loss = 0.00877156\n",
      "Iteration 3267, loss = 0.00876820\n",
      "Iteration 3268, loss = 0.00876427\n",
      "Iteration 3269, loss = 0.00876124\n",
      "Iteration 3270, loss = 0.00875722\n",
      "Iteration 3271, loss = 0.00875376\n",
      "Iteration 3272, loss = 0.00874941\n",
      "Iteration 3273, loss = 0.00874647\n",
      "Iteration 3274, loss = 0.00874227\n",
      "Iteration 3275, loss = 0.00873868\n",
      "Iteration 3276, loss = 0.00873505\n",
      "Iteration 3277, loss = 0.00873262\n",
      "Iteration 3278, loss = 0.00872829\n",
      "Iteration 3279, loss = 0.00872469\n",
      "Iteration 3280, loss = 0.00872080\n",
      "Iteration 3281, loss = 0.00871784\n",
      "Iteration 3282, loss = 0.00871355\n",
      "Iteration 3283, loss = 0.00871022\n",
      "Iteration 3284, loss = 0.00870631\n",
      "Iteration 3285, loss = 0.00870268\n",
      "Iteration 3286, loss = 0.00869832\n",
      "Iteration 3287, loss = 0.00869403\n",
      "Iteration 3288, loss = 0.00869096\n",
      "Iteration 3289, loss = 0.00868712\n",
      "Iteration 3290, loss = 0.00868287\n",
      "Iteration 3291, loss = 0.00867922\n",
      "Iteration 3292, loss = 0.00867553\n",
      "Iteration 3293, loss = 0.00867200\n",
      "Iteration 3294, loss = 0.00866811\n",
      "Iteration 3295, loss = 0.00866527\n",
      "Iteration 3296, loss = 0.00866116\n",
      "Iteration 3297, loss = 0.00865709\n",
      "Iteration 3298, loss = 0.00865334\n",
      "Iteration 3299, loss = 0.00865017\n",
      "Iteration 3300, loss = 0.00864667\n",
      "Iteration 3301, loss = 0.00864386\n",
      "Iteration 3302, loss = 0.00863951\n",
      "Iteration 3303, loss = 0.00863583\n",
      "Iteration 3304, loss = 0.00863245\n",
      "Iteration 3305, loss = 0.00862943\n",
      "Iteration 3306, loss = 0.00862573\n",
      "Iteration 3307, loss = 0.00862162\n",
      "Iteration 3308, loss = 0.00861869\n",
      "Iteration 3309, loss = 0.00861447\n",
      "Iteration 3310, loss = 0.00861105\n",
      "Iteration 3311, loss = 0.00860684\n",
      "Iteration 3312, loss = 0.00860306\n",
      "Iteration 3313, loss = 0.00859931\n",
      "Iteration 3314, loss = 0.00859597\n",
      "Iteration 3315, loss = 0.00859238\n",
      "Iteration 3316, loss = 0.00858839\n",
      "Iteration 3317, loss = 0.00858443\n",
      "Iteration 3318, loss = 0.00858125\n",
      "Iteration 3319, loss = 0.00857802\n",
      "Iteration 3320, loss = 0.00857410\n",
      "Iteration 3321, loss = 0.00857049\n",
      "Iteration 3322, loss = 0.00856792\n",
      "Iteration 3323, loss = 0.00856378\n",
      "Iteration 3324, loss = 0.00856086\n",
      "Iteration 3325, loss = 0.00855732\n",
      "Iteration 3326, loss = 0.00855419\n",
      "Iteration 3327, loss = 0.00855109\n",
      "Iteration 3328, loss = 0.00854835\n",
      "Iteration 3329, loss = 0.00854508\n",
      "Iteration 3330, loss = 0.00854201\n",
      "Iteration 3331, loss = 0.00853881\n",
      "Iteration 3332, loss = 0.00853529\n",
      "Iteration 3333, loss = 0.00853205\n",
      "Iteration 3334, loss = 0.00852875\n",
      "Iteration 3335, loss = 0.00852571\n",
      "Iteration 3336, loss = 0.00852266\n",
      "Iteration 3337, loss = 0.00852007\n",
      "Iteration 3338, loss = 0.00851693\n",
      "Iteration 3339, loss = 0.00851523\n",
      "Iteration 3340, loss = 0.00851120\n",
      "Iteration 3341, loss = 0.00850785\n",
      "Iteration 3342, loss = 0.00850502\n",
      "Iteration 3343, loss = 0.00850136\n",
      "Iteration 3344, loss = 0.00849872\n",
      "Iteration 3345, loss = 0.00849520\n",
      "Iteration 3346, loss = 0.00849274\n",
      "Iteration 3347, loss = 0.00848877\n",
      "Iteration 3348, loss = 0.00848580\n",
      "Iteration 3349, loss = 0.00848218\n",
      "Iteration 3350, loss = 0.00847877\n",
      "Iteration 3351, loss = 0.00847523\n",
      "Iteration 3352, loss = 0.00847173\n",
      "Iteration 3353, loss = 0.00846823\n",
      "Iteration 3354, loss = 0.00846490\n",
      "Iteration 3355, loss = 0.00846126\n",
      "Iteration 3356, loss = 0.00845802\n",
      "Iteration 3357, loss = 0.00845482\n",
      "Iteration 3358, loss = 0.00845094\n",
      "Iteration 3359, loss = 0.00844732\n",
      "Iteration 3360, loss = 0.00844410\n",
      "Iteration 3361, loss = 0.00844033\n",
      "Iteration 3362, loss = 0.00843711\n",
      "Iteration 3363, loss = 0.00843326\n",
      "Iteration 3364, loss = 0.00843027\n",
      "Iteration 3365, loss = 0.00842617\n",
      "Iteration 3366, loss = 0.00842293\n",
      "Iteration 3367, loss = 0.00841902\n",
      "Iteration 3368, loss = 0.00841532\n",
      "Iteration 3369, loss = 0.00841119\n",
      "Iteration 3370, loss = 0.00840814\n",
      "Iteration 3371, loss = 0.00840397\n",
      "Iteration 3372, loss = 0.00840068\n",
      "Iteration 3373, loss = 0.00839794\n",
      "Iteration 3374, loss = 0.00839353\n",
      "Iteration 3375, loss = 0.00839024\n",
      "Iteration 3376, loss = 0.00838704\n",
      "Iteration 3377, loss = 0.00838393\n",
      "Iteration 3378, loss = 0.00838026\n",
      "Iteration 3379, loss = 0.00837674\n",
      "Iteration 3380, loss = 0.00837360\n",
      "Iteration 3381, loss = 0.00836993\n",
      "Iteration 3382, loss = 0.00836787\n",
      "Iteration 3383, loss = 0.00836469\n",
      "Iteration 3384, loss = 0.00836022\n",
      "Iteration 3385, loss = 0.00835718\n",
      "Iteration 3386, loss = 0.00835396\n",
      "Iteration 3387, loss = 0.00835072\n",
      "Iteration 3388, loss = 0.00834782\n",
      "Iteration 3389, loss = 0.00834508\n",
      "Iteration 3390, loss = 0.00834195\n",
      "Iteration 3391, loss = 0.00833874\n",
      "Iteration 3392, loss = 0.00833544\n",
      "Iteration 3393, loss = 0.00833251\n",
      "Iteration 3394, loss = 0.00832922\n",
      "Iteration 3395, loss = 0.00832621\n",
      "Iteration 3396, loss = 0.00832310\n",
      "Iteration 3397, loss = 0.00832149\n",
      "Iteration 3398, loss = 0.00831826\n",
      "Iteration 3399, loss = 0.00831463\n",
      "Iteration 3400, loss = 0.00831130\n",
      "Iteration 3401, loss = 0.00830775\n",
      "Iteration 3402, loss = 0.00830432\n",
      "Iteration 3403, loss = 0.00830144\n",
      "Iteration 3404, loss = 0.00829845\n",
      "Iteration 3405, loss = 0.00829518\n",
      "Iteration 3406, loss = 0.00829228\n",
      "Iteration 3407, loss = 0.00828878\n",
      "Iteration 3408, loss = 0.00828599\n",
      "Iteration 3409, loss = 0.00828291\n",
      "Iteration 3410, loss = 0.00828036\n",
      "Iteration 3411, loss = 0.00827689\n",
      "Iteration 3412, loss = 0.00827399\n",
      "Iteration 3413, loss = 0.00827090\n",
      "Iteration 3414, loss = 0.00826797\n",
      "Iteration 3415, loss = 0.00826501\n",
      "Iteration 3416, loss = 0.00826193\n",
      "Iteration 3417, loss = 0.00825909\n",
      "Iteration 3418, loss = 0.00825560\n",
      "Iteration 3419, loss = 0.00825250\n",
      "Iteration 3420, loss = 0.00824953\n",
      "Iteration 3421, loss = 0.00824644\n",
      "Iteration 3422, loss = 0.00824313\n",
      "Iteration 3423, loss = 0.00824008\n",
      "Iteration 3424, loss = 0.00823688\n",
      "Iteration 3425, loss = 0.00823423\n",
      "Iteration 3426, loss = 0.00823150\n",
      "Iteration 3427, loss = 0.00822994\n",
      "Iteration 3428, loss = 0.00822548\n",
      "Iteration 3429, loss = 0.00822253\n",
      "Iteration 3430, loss = 0.00822009\n",
      "Iteration 3431, loss = 0.00821700\n",
      "Iteration 3432, loss = 0.00821377\n",
      "Iteration 3433, loss = 0.00821068\n",
      "Iteration 3434, loss = 0.00820681\n",
      "Iteration 3435, loss = 0.00820280\n",
      "Iteration 3436, loss = 0.00819963\n",
      "Iteration 3437, loss = 0.00819610\n",
      "Iteration 3438, loss = 0.00819280\n",
      "Iteration 3439, loss = 0.00818936\n",
      "Iteration 3440, loss = 0.00818592\n",
      "Iteration 3441, loss = 0.00818258\n",
      "Iteration 3442, loss = 0.00817896\n",
      "Iteration 3443, loss = 0.00817595\n",
      "Iteration 3444, loss = 0.00817307\n",
      "Iteration 3445, loss = 0.00817005\n",
      "Iteration 3446, loss = 0.00816686\n",
      "Iteration 3447, loss = 0.00816352\n",
      "Iteration 3448, loss = 0.00816071\n",
      "Iteration 3449, loss = 0.00815732\n",
      "Iteration 3450, loss = 0.00815450\n",
      "Iteration 3451, loss = 0.00815132\n",
      "Iteration 3452, loss = 0.00814892\n",
      "Iteration 3453, loss = 0.00814608\n",
      "Iteration 3454, loss = 0.00814328\n",
      "Iteration 3455, loss = 0.00814042\n",
      "Iteration 3456, loss = 0.00813831\n",
      "Iteration 3457, loss = 0.00813544\n",
      "Iteration 3458, loss = 0.00813137\n",
      "Iteration 3459, loss = 0.00812809\n",
      "Iteration 3460, loss = 0.00812503\n",
      "Iteration 3461, loss = 0.00812149\n",
      "Iteration 3462, loss = 0.00811813\n",
      "Iteration 3463, loss = 0.00811526\n",
      "Iteration 3464, loss = 0.00811212\n",
      "Iteration 3465, loss = 0.00810889\n",
      "Iteration 3466, loss = 0.00810546\n",
      "Iteration 3467, loss = 0.00810224\n",
      "Iteration 3468, loss = 0.00809899\n",
      "Iteration 3469, loss = 0.00809551\n",
      "Iteration 3470, loss = 0.00809385\n",
      "Iteration 3471, loss = 0.00808929\n",
      "Iteration 3472, loss = 0.00808571\n",
      "Iteration 3473, loss = 0.00808278\n",
      "Iteration 3474, loss = 0.00807886\n",
      "Iteration 3475, loss = 0.00807570\n",
      "Iteration 3476, loss = 0.00807261\n",
      "Iteration 3477, loss = 0.00806972\n",
      "Iteration 3478, loss = 0.00806649\n",
      "Iteration 3479, loss = 0.00806350\n",
      "Iteration 3480, loss = 0.00806016\n",
      "Iteration 3481, loss = 0.00805727\n",
      "Iteration 3482, loss = 0.00805490\n",
      "Iteration 3483, loss = 0.00805210\n",
      "Iteration 3484, loss = 0.00804879\n",
      "Iteration 3485, loss = 0.00804649\n",
      "Iteration 3486, loss = 0.00804292\n",
      "Iteration 3487, loss = 0.00804004\n",
      "Iteration 3488, loss = 0.00803688\n",
      "Iteration 3489, loss = 0.00803399\n",
      "Iteration 3490, loss = 0.00803186\n",
      "Iteration 3491, loss = 0.00802869\n",
      "Iteration 3492, loss = 0.00802599\n",
      "Iteration 3493, loss = 0.00802258\n",
      "Iteration 3494, loss = 0.00801916\n",
      "Iteration 3495, loss = 0.00801573\n",
      "Iteration 3496, loss = 0.00801391\n",
      "Iteration 3497, loss = 0.00800934\n",
      "Iteration 3498, loss = 0.00800711\n",
      "Iteration 3499, loss = 0.00800317\n",
      "Iteration 3500, loss = 0.00799977\n",
      "Iteration 3501, loss = 0.00799570\n",
      "Iteration 3502, loss = 0.00799247\n",
      "Iteration 3503, loss = 0.00798938\n",
      "Iteration 3504, loss = 0.00798570\n",
      "Iteration 3505, loss = 0.00798313\n",
      "Iteration 3506, loss = 0.00797914\n",
      "Iteration 3507, loss = 0.00797566\n",
      "Iteration 3508, loss = 0.00797264\n",
      "Iteration 3509, loss = 0.00796881\n",
      "Iteration 3510, loss = 0.00796670\n",
      "Iteration 3511, loss = 0.00796306\n",
      "Iteration 3512, loss = 0.00795929\n",
      "Iteration 3513, loss = 0.00795684\n",
      "Iteration 3514, loss = 0.00795372\n",
      "Iteration 3515, loss = 0.00795050\n",
      "Iteration 3516, loss = 0.00794713\n",
      "Iteration 3517, loss = 0.00794451\n",
      "Iteration 3518, loss = 0.00794141\n",
      "Iteration 3519, loss = 0.00793841\n",
      "Iteration 3520, loss = 0.00793556\n",
      "Iteration 3521, loss = 0.00793254\n",
      "Iteration 3522, loss = 0.00792972\n",
      "Iteration 3523, loss = 0.00792691\n",
      "Iteration 3524, loss = 0.00792464\n",
      "Iteration 3525, loss = 0.00792102\n",
      "Iteration 3526, loss = 0.00791832\n",
      "Iteration 3527, loss = 0.00791543\n",
      "Iteration 3528, loss = 0.00791259\n",
      "Iteration 3529, loss = 0.00790934\n",
      "Iteration 3530, loss = 0.00790745\n",
      "Iteration 3531, loss = 0.00790305\n",
      "Iteration 3532, loss = 0.00790133\n",
      "Iteration 3533, loss = 0.00789757\n",
      "Iteration 3534, loss = 0.00789484\n",
      "Iteration 3535, loss = 0.00789204\n",
      "Iteration 3536, loss = 0.00788953\n",
      "Iteration 3537, loss = 0.00788713\n",
      "Iteration 3538, loss = 0.00788378\n",
      "Iteration 3539, loss = 0.00788030\n",
      "Iteration 3540, loss = 0.00787736\n",
      "Iteration 3541, loss = 0.00787456\n",
      "Iteration 3542, loss = 0.00787099\n",
      "Iteration 3543, loss = 0.00786810\n",
      "Iteration 3544, loss = 0.00786465\n",
      "Iteration 3545, loss = 0.00786095\n",
      "Iteration 3546, loss = 0.00785846\n",
      "Iteration 3547, loss = 0.00785454\n",
      "Iteration 3548, loss = 0.00785152\n",
      "Iteration 3549, loss = 0.00784817\n",
      "Iteration 3550, loss = 0.00784563\n",
      "Iteration 3551, loss = 0.00784253\n",
      "Iteration 3552, loss = 0.00783909\n",
      "Iteration 3553, loss = 0.00783530\n",
      "Iteration 3554, loss = 0.00783215\n",
      "Iteration 3555, loss = 0.00782838\n",
      "Iteration 3556, loss = 0.00782539\n",
      "Iteration 3557, loss = 0.00782227\n",
      "Iteration 3558, loss = 0.00781914\n",
      "Iteration 3559, loss = 0.00781619\n",
      "Iteration 3560, loss = 0.00781364\n",
      "Iteration 3561, loss = 0.00781033\n",
      "Iteration 3562, loss = 0.00780769\n",
      "Iteration 3563, loss = 0.00780466\n",
      "Iteration 3564, loss = 0.00780130\n",
      "Iteration 3565, loss = 0.00779871\n",
      "Iteration 3566, loss = 0.00779540\n",
      "Iteration 3567, loss = 0.00779259\n",
      "Iteration 3568, loss = 0.00778979\n",
      "Iteration 3569, loss = 0.00778653\n",
      "Iteration 3570, loss = 0.00778321\n",
      "Iteration 3571, loss = 0.00778024\n",
      "Iteration 3572, loss = 0.00777709\n",
      "Iteration 3573, loss = 0.00777405\n",
      "Iteration 3574, loss = 0.00777133\n",
      "Iteration 3575, loss = 0.00776797\n",
      "Iteration 3576, loss = 0.00776513\n",
      "Iteration 3577, loss = 0.00776231\n",
      "Iteration 3578, loss = 0.00775910\n",
      "Iteration 3579, loss = 0.00775597\n",
      "Iteration 3580, loss = 0.00775336\n",
      "Iteration 3581, loss = 0.00775073\n",
      "Iteration 3582, loss = 0.00774777\n",
      "Iteration 3583, loss = 0.00774482\n",
      "Iteration 3584, loss = 0.00774198\n",
      "Iteration 3585, loss = 0.00773922\n",
      "Iteration 3586, loss = 0.00773683\n",
      "Iteration 3587, loss = 0.00773450\n",
      "Iteration 3588, loss = 0.00773168\n",
      "Iteration 3589, loss = 0.00772960\n",
      "Iteration 3590, loss = 0.00772749\n",
      "Iteration 3591, loss = 0.00772471\n",
      "Iteration 3592, loss = 0.00772147\n",
      "Iteration 3593, loss = 0.00771890\n",
      "Iteration 3594, loss = 0.00771634\n",
      "Iteration 3595, loss = 0.00771352\n",
      "Iteration 3596, loss = 0.00771045\n",
      "Iteration 3597, loss = 0.00770915\n",
      "Iteration 3598, loss = 0.00770590\n",
      "Iteration 3599, loss = 0.00770306\n",
      "Iteration 3600, loss = 0.00770043\n",
      "Iteration 3601, loss = 0.00769814\n",
      "Iteration 3602, loss = 0.00769528\n",
      "Iteration 3603, loss = 0.00769286\n",
      "Iteration 3604, loss = 0.00769045\n",
      "Iteration 3605, loss = 0.00768751\n",
      "Iteration 3606, loss = 0.00768481\n",
      "Iteration 3607, loss = 0.00768171\n",
      "Iteration 3608, loss = 0.00767956\n",
      "Iteration 3609, loss = 0.00767588\n",
      "Iteration 3610, loss = 0.00767273\n",
      "Iteration 3611, loss = 0.00766967\n",
      "Iteration 3612, loss = 0.00766687\n",
      "Iteration 3613, loss = 0.00766451\n",
      "Iteration 3614, loss = 0.00766174\n",
      "Iteration 3615, loss = 0.00765908\n",
      "Iteration 3616, loss = 0.00765638\n",
      "Iteration 3617, loss = 0.00765308\n",
      "Iteration 3618, loss = 0.00765001\n",
      "Iteration 3619, loss = 0.00764679\n",
      "Iteration 3620, loss = 0.00764349\n",
      "Iteration 3621, loss = 0.00764042\n",
      "Iteration 3622, loss = 0.00763807\n",
      "Iteration 3623, loss = 0.00763429\n",
      "Iteration 3624, loss = 0.00763140\n",
      "Iteration 3625, loss = 0.00762864\n",
      "Iteration 3626, loss = 0.00762523\n",
      "Iteration 3627, loss = 0.00762272\n",
      "Iteration 3628, loss = 0.00762055\n",
      "Iteration 3629, loss = 0.00761698\n",
      "Iteration 3630, loss = 0.00761449\n",
      "Iteration 3631, loss = 0.00761177\n",
      "Iteration 3632, loss = 0.00760879\n",
      "Iteration 3633, loss = 0.00760591\n",
      "Iteration 3634, loss = 0.00760274\n",
      "Iteration 3635, loss = 0.00759983\n",
      "Iteration 3636, loss = 0.00759694\n",
      "Iteration 3637, loss = 0.00759404\n",
      "Iteration 3638, loss = 0.00759120\n",
      "Iteration 3639, loss = 0.00758816\n",
      "Iteration 3640, loss = 0.00758607\n",
      "Iteration 3641, loss = 0.00758286\n",
      "Iteration 3642, loss = 0.00758055\n",
      "Iteration 3643, loss = 0.00757792\n",
      "Iteration 3644, loss = 0.00757532\n",
      "Iteration 3645, loss = 0.00757232\n",
      "Iteration 3646, loss = 0.00756933\n",
      "Iteration 3647, loss = 0.00756671\n",
      "Iteration 3648, loss = 0.00756385\n",
      "Iteration 3649, loss = 0.00756111\n",
      "Iteration 3650, loss = 0.00755818\n",
      "Iteration 3651, loss = 0.00755548\n",
      "Iteration 3652, loss = 0.00755264\n",
      "Iteration 3653, loss = 0.00755061\n",
      "Iteration 3654, loss = 0.00754751\n",
      "Iteration 3655, loss = 0.00754370\n",
      "Iteration 3656, loss = 0.00754141\n",
      "Iteration 3657, loss = 0.00753733\n",
      "Iteration 3658, loss = 0.00753432\n",
      "Iteration 3659, loss = 0.00753182\n",
      "Iteration 3660, loss = 0.00752839\n",
      "Iteration 3661, loss = 0.00752589\n",
      "Iteration 3662, loss = 0.00752267\n",
      "Iteration 3663, loss = 0.00751994\n",
      "Iteration 3664, loss = 0.00751693\n",
      "Iteration 3665, loss = 0.00751398\n",
      "Iteration 3666, loss = 0.00751180\n",
      "Iteration 3667, loss = 0.00750875\n",
      "Iteration 3668, loss = 0.00750559\n",
      "Iteration 3669, loss = 0.00750278\n",
      "Iteration 3670, loss = 0.00750007\n",
      "Iteration 3671, loss = 0.00749738\n",
      "Iteration 3672, loss = 0.00749448\n",
      "Iteration 3673, loss = 0.00749161\n",
      "Iteration 3674, loss = 0.00748933\n",
      "Iteration 3675, loss = 0.00748670\n",
      "Iteration 3676, loss = 0.00748453\n",
      "Iteration 3677, loss = 0.00748137\n",
      "Iteration 3678, loss = 0.00747880\n",
      "Iteration 3679, loss = 0.00747624\n",
      "Iteration 3680, loss = 0.00747280\n",
      "Iteration 3681, loss = 0.00747108\n",
      "Iteration 3682, loss = 0.00746748\n",
      "Iteration 3683, loss = 0.00746503\n",
      "Iteration 3684, loss = 0.00746204\n",
      "Iteration 3685, loss = 0.00745959\n",
      "Iteration 3686, loss = 0.00745636\n",
      "Iteration 3687, loss = 0.00745365\n",
      "Iteration 3688, loss = 0.00745086\n",
      "Iteration 3689, loss = 0.00744754\n",
      "Iteration 3690, loss = 0.00744502\n",
      "Iteration 3691, loss = 0.00744280\n",
      "Iteration 3692, loss = 0.00744024\n",
      "Iteration 3693, loss = 0.00743723\n",
      "Iteration 3694, loss = 0.00743497\n",
      "Iteration 3695, loss = 0.00743313\n",
      "Iteration 3696, loss = 0.00743100\n",
      "Iteration 3697, loss = 0.00742721\n",
      "Iteration 3698, loss = 0.00742410\n",
      "Iteration 3699, loss = 0.00742129\n",
      "Iteration 3700, loss = 0.00741823\n",
      "Iteration 3701, loss = 0.00741561\n",
      "Iteration 3702, loss = 0.00741274\n",
      "Iteration 3703, loss = 0.00740955\n",
      "Iteration 3704, loss = 0.00740635\n",
      "Iteration 3705, loss = 0.00740364\n",
      "Iteration 3706, loss = 0.00740127\n",
      "Iteration 3707, loss = 0.00739785\n",
      "Iteration 3708, loss = 0.00739481\n",
      "Iteration 3709, loss = 0.00739174\n",
      "Iteration 3710, loss = 0.00738887\n",
      "Iteration 3711, loss = 0.00738727\n",
      "Iteration 3712, loss = 0.00738397\n",
      "Iteration 3713, loss = 0.00738119\n",
      "Iteration 3714, loss = 0.00737804\n",
      "Iteration 3715, loss = 0.00737528\n",
      "Iteration 3716, loss = 0.00737263\n",
      "Iteration 3717, loss = 0.00736916\n",
      "Iteration 3718, loss = 0.00736613\n",
      "Iteration 3719, loss = 0.00736408\n",
      "Iteration 3720, loss = 0.00736066\n",
      "Iteration 3721, loss = 0.00735813\n",
      "Iteration 3722, loss = 0.00735550\n",
      "Iteration 3723, loss = 0.00735263\n",
      "Iteration 3724, loss = 0.00734972\n",
      "Iteration 3725, loss = 0.00734690\n",
      "Iteration 3726, loss = 0.00734503\n",
      "Iteration 3727, loss = 0.00734137\n",
      "Iteration 3728, loss = 0.00733902\n",
      "Iteration 3729, loss = 0.00733635\n",
      "Iteration 3730, loss = 0.00733327\n",
      "Iteration 3731, loss = 0.00733069\n",
      "Iteration 3732, loss = 0.00732799\n",
      "Iteration 3733, loss = 0.00732511\n",
      "Iteration 3734, loss = 0.00732288\n",
      "Iteration 3735, loss = 0.00731953\n",
      "Iteration 3736, loss = 0.00731663\n",
      "Iteration 3737, loss = 0.00731395\n",
      "Iteration 3738, loss = 0.00731131\n",
      "Iteration 3739, loss = 0.00730846\n",
      "Iteration 3740, loss = 0.00730594\n",
      "Iteration 3741, loss = 0.00730285\n",
      "Iteration 3742, loss = 0.00730019\n",
      "Iteration 3743, loss = 0.00729890\n",
      "Iteration 3744, loss = 0.00729469\n",
      "Iteration 3745, loss = 0.00729209\n",
      "Iteration 3746, loss = 0.00728946\n",
      "Iteration 3747, loss = 0.00728685\n",
      "Iteration 3748, loss = 0.00728428\n",
      "Iteration 3749, loss = 0.00728153\n",
      "Iteration 3750, loss = 0.00727894\n",
      "Iteration 3751, loss = 0.00727637\n",
      "Iteration 3752, loss = 0.00727412\n",
      "Iteration 3753, loss = 0.00727129\n",
      "Iteration 3754, loss = 0.00726870\n",
      "Iteration 3755, loss = 0.00726657\n",
      "Iteration 3756, loss = 0.00726401\n",
      "Iteration 3757, loss = 0.00726129\n",
      "Iteration 3758, loss = 0.00725852\n",
      "Iteration 3759, loss = 0.00725601\n",
      "Iteration 3760, loss = 0.00725400\n",
      "Iteration 3761, loss = 0.00725083\n",
      "Iteration 3762, loss = 0.00724844\n",
      "Iteration 3763, loss = 0.00724554\n",
      "Iteration 3764, loss = 0.00724266\n",
      "Iteration 3765, loss = 0.00724053\n",
      "Iteration 3766, loss = 0.00723784\n",
      "Iteration 3767, loss = 0.00723505\n",
      "Iteration 3768, loss = 0.00723228\n",
      "Iteration 3769, loss = 0.00722940\n",
      "Iteration 3770, loss = 0.00722703\n",
      "Iteration 3771, loss = 0.00722543\n",
      "Iteration 3772, loss = 0.00722157\n",
      "Iteration 3773, loss = 0.00721871\n",
      "Iteration 3774, loss = 0.00721607\n",
      "Iteration 3775, loss = 0.00721373\n",
      "Iteration 3776, loss = 0.00721054\n",
      "Iteration 3777, loss = 0.00720775\n",
      "Iteration 3778, loss = 0.00720515\n",
      "Iteration 3779, loss = 0.00720360\n",
      "Iteration 3780, loss = 0.00720033\n",
      "Iteration 3781, loss = 0.00719808\n",
      "Iteration 3782, loss = 0.00719667\n",
      "Iteration 3783, loss = 0.00719335\n",
      "Iteration 3784, loss = 0.00719039\n",
      "Iteration 3785, loss = 0.00718804\n",
      "Iteration 3786, loss = 0.00718763\n",
      "Iteration 3787, loss = 0.00718344\n",
      "Iteration 3788, loss = 0.00718014\n",
      "Iteration 3789, loss = 0.00717771\n",
      "Iteration 3790, loss = 0.00717521\n",
      "Iteration 3791, loss = 0.00717250\n",
      "Iteration 3792, loss = 0.00716987\n",
      "Iteration 3793, loss = 0.00716754\n",
      "Iteration 3794, loss = 0.00716477\n",
      "Iteration 3795, loss = 0.00716248\n",
      "Iteration 3796, loss = 0.00715993\n",
      "Iteration 3797, loss = 0.00715739\n",
      "Iteration 3798, loss = 0.00715489\n",
      "Iteration 3799, loss = 0.00715263\n",
      "Iteration 3800, loss = 0.00715052\n",
      "Iteration 3801, loss = 0.00714801\n",
      "Iteration 3802, loss = 0.00714582\n",
      "Iteration 3803, loss = 0.00714356\n",
      "Iteration 3804, loss = 0.00714130\n",
      "Iteration 3805, loss = 0.00713888\n",
      "Iteration 3806, loss = 0.00713594\n",
      "Iteration 3807, loss = 0.00713321\n",
      "Iteration 3808, loss = 0.00713155\n",
      "Iteration 3809, loss = 0.00712924\n",
      "Iteration 3810, loss = 0.00712576\n",
      "Iteration 3811, loss = 0.00712407\n",
      "Iteration 3812, loss = 0.00712109\n",
      "Iteration 3813, loss = 0.00711882\n",
      "Iteration 3814, loss = 0.00711617\n",
      "Iteration 3815, loss = 0.00711357\n",
      "Iteration 3816, loss = 0.00711238\n",
      "Iteration 3817, loss = 0.00710889\n",
      "Iteration 3818, loss = 0.00710622\n",
      "Iteration 3819, loss = 0.00710350\n",
      "Iteration 3820, loss = 0.00710118\n",
      "Iteration 3821, loss = 0.00709850\n",
      "Iteration 3822, loss = 0.00709600\n",
      "Iteration 3823, loss = 0.00709324\n",
      "Iteration 3824, loss = 0.00709091\n",
      "Iteration 3825, loss = 0.00708830\n",
      "Iteration 3826, loss = 0.00708625\n",
      "Iteration 3827, loss = 0.00708352\n",
      "Iteration 3828, loss = 0.00708145\n",
      "Iteration 3829, loss = 0.00707860\n",
      "Iteration 3830, loss = 0.00707614\n",
      "Iteration 3831, loss = 0.00707344\n",
      "Iteration 3832, loss = 0.00707122\n",
      "Iteration 3833, loss = 0.00706826\n",
      "Iteration 3834, loss = 0.00706569\n",
      "Iteration 3835, loss = 0.00706285\n",
      "Iteration 3836, loss = 0.00706055\n",
      "Iteration 3837, loss = 0.00705932\n",
      "Iteration 3838, loss = 0.00705517\n",
      "Iteration 3839, loss = 0.00705242\n",
      "Iteration 3840, loss = 0.00704995\n",
      "Iteration 3841, loss = 0.00704748\n",
      "Iteration 3842, loss = 0.00704539\n",
      "Iteration 3843, loss = 0.00704182\n",
      "Iteration 3844, loss = 0.00703902\n",
      "Iteration 3845, loss = 0.00703644\n",
      "Iteration 3846, loss = 0.00703353\n",
      "Iteration 3847, loss = 0.00703142\n",
      "Iteration 3848, loss = 0.00702831\n",
      "Iteration 3849, loss = 0.00702601\n",
      "Iteration 3850, loss = 0.00702317\n",
      "Iteration 3851, loss = 0.00702126\n",
      "Iteration 3852, loss = 0.00701878\n",
      "Iteration 3853, loss = 0.00701620\n",
      "Iteration 3854, loss = 0.00701401\n",
      "Iteration 3855, loss = 0.00701182\n",
      "Iteration 3856, loss = 0.00700934\n",
      "Iteration 3857, loss = 0.00700690\n",
      "Iteration 3858, loss = 0.00700523\n",
      "Iteration 3859, loss = 0.00700248\n",
      "Iteration 3860, loss = 0.00700051\n",
      "Iteration 3861, loss = 0.00699772\n",
      "Iteration 3862, loss = 0.00699561\n",
      "Iteration 3863, loss = 0.00699287\n",
      "Iteration 3864, loss = 0.00699018\n",
      "Iteration 3865, loss = 0.00698781\n",
      "Iteration 3866, loss = 0.00698527\n",
      "Iteration 3867, loss = 0.00698229\n",
      "Iteration 3868, loss = 0.00698012\n",
      "Iteration 3869, loss = 0.00697740\n",
      "Iteration 3870, loss = 0.00697486\n",
      "Iteration 3871, loss = 0.00697239\n",
      "Iteration 3872, loss = 0.00696975\n",
      "Iteration 3873, loss = 0.00696752\n",
      "Iteration 3874, loss = 0.00696483\n",
      "Iteration 3875, loss = 0.00696235\n",
      "Iteration 3876, loss = 0.00696012\n",
      "Iteration 3877, loss = 0.00695765\n",
      "Iteration 3878, loss = 0.00695523\n",
      "Iteration 3879, loss = 0.00695284\n",
      "Iteration 3880, loss = 0.00695064\n",
      "Iteration 3881, loss = 0.00694804\n",
      "Iteration 3882, loss = 0.00694582\n",
      "Iteration 3883, loss = 0.00694315\n",
      "Iteration 3884, loss = 0.00694066\n",
      "Iteration 3885, loss = 0.00693813\n",
      "Iteration 3886, loss = 0.00693585\n",
      "Iteration 3887, loss = 0.00693337\n",
      "Iteration 3888, loss = 0.00693074\n",
      "Iteration 3889, loss = 0.00692849\n",
      "Iteration 3890, loss = 0.00692675\n",
      "Iteration 3891, loss = 0.00692375\n",
      "Iteration 3892, loss = 0.00692125\n",
      "Iteration 3893, loss = 0.00691860\n",
      "Iteration 3894, loss = 0.00691666\n",
      "Iteration 3895, loss = 0.00691373\n",
      "Iteration 3896, loss = 0.00691177\n",
      "Iteration 3897, loss = 0.00690897\n",
      "Iteration 3898, loss = 0.00690703\n",
      "Iteration 3899, loss = 0.00690430\n",
      "Iteration 3900, loss = 0.00690175\n",
      "Iteration 3901, loss = 0.00689971\n",
      "Iteration 3902, loss = 0.00689794\n",
      "Iteration 3903, loss = 0.00689465\n",
      "Iteration 3904, loss = 0.00689224\n",
      "Iteration 3905, loss = 0.00689057\n",
      "Iteration 3906, loss = 0.00688800\n",
      "Iteration 3907, loss = 0.00688595\n",
      "Iteration 3908, loss = 0.00688345\n",
      "Iteration 3909, loss = 0.00688096\n",
      "Iteration 3910, loss = 0.00687878\n",
      "Iteration 3911, loss = 0.00687697\n",
      "Iteration 3912, loss = 0.00687417\n",
      "Iteration 3913, loss = 0.00687197\n",
      "Iteration 3914, loss = 0.00686920\n",
      "Iteration 3915, loss = 0.00686665\n",
      "Iteration 3916, loss = 0.00686459\n",
      "Iteration 3917, loss = 0.00686171\n",
      "Iteration 3918, loss = 0.00685959\n",
      "Iteration 3919, loss = 0.00685751\n",
      "Iteration 3920, loss = 0.00685495\n",
      "Iteration 3921, loss = 0.00685283\n",
      "Iteration 3922, loss = 0.00685036\n",
      "Iteration 3923, loss = 0.00684818\n",
      "Iteration 3924, loss = 0.00684573\n",
      "Iteration 3925, loss = 0.00684306\n",
      "Iteration 3926, loss = 0.00684103\n",
      "Iteration 3927, loss = 0.00683859\n",
      "Iteration 3928, loss = 0.00683683\n",
      "Iteration 3929, loss = 0.00683476\n",
      "Iteration 3930, loss = 0.00683141\n",
      "Iteration 3931, loss = 0.00682940\n",
      "Iteration 3932, loss = 0.00682739\n",
      "Iteration 3933, loss = 0.00682475\n",
      "Iteration 3934, loss = 0.00682239\n",
      "Iteration 3935, loss = 0.00682030\n",
      "Iteration 3936, loss = 0.00681832\n",
      "Iteration 3937, loss = 0.00681748\n",
      "Iteration 3938, loss = 0.00681382\n",
      "Iteration 3939, loss = 0.00681158\n",
      "Iteration 3940, loss = 0.00680907\n",
      "Iteration 3941, loss = 0.00680650\n",
      "Iteration 3942, loss = 0.00680432\n",
      "Iteration 3943, loss = 0.00680167\n",
      "Iteration 3944, loss = 0.00679927\n",
      "Iteration 3945, loss = 0.00679713\n",
      "Iteration 3946, loss = 0.00679485\n",
      "Iteration 3947, loss = 0.00679289\n",
      "Iteration 3948, loss = 0.00679074\n",
      "Iteration 3949, loss = 0.00678819\n",
      "Iteration 3950, loss = 0.00678611\n",
      "Iteration 3951, loss = 0.00678360\n",
      "Iteration 3952, loss = 0.00678153\n",
      "Iteration 3953, loss = 0.00677948\n",
      "Iteration 3954, loss = 0.00677819\n",
      "Iteration 3955, loss = 0.00677537\n",
      "Iteration 3956, loss = 0.00677358\n",
      "Iteration 3957, loss = 0.00677153\n",
      "Iteration 3958, loss = 0.00676931\n",
      "Iteration 3959, loss = 0.00676717\n",
      "Iteration 3960, loss = 0.00676482\n",
      "Iteration 3961, loss = 0.00676238\n",
      "Iteration 3962, loss = 0.00675998\n",
      "Iteration 3963, loss = 0.00675746\n",
      "Iteration 3964, loss = 0.00675512\n",
      "Iteration 3965, loss = 0.00675228\n",
      "Iteration 3966, loss = 0.00675012\n",
      "Iteration 3967, loss = 0.00674727\n",
      "Iteration 3968, loss = 0.00674490\n",
      "Iteration 3969, loss = 0.00674212\n",
      "Iteration 3970, loss = 0.00673949\n",
      "Iteration 3971, loss = 0.00673794\n",
      "Iteration 3972, loss = 0.00673471\n",
      "Iteration 3973, loss = 0.00673244\n",
      "Iteration 3974, loss = 0.00673031\n",
      "Iteration 3975, loss = 0.00672736\n",
      "Iteration 3976, loss = 0.00672534\n",
      "Iteration 3977, loss = 0.00672310\n",
      "Iteration 3978, loss = 0.00672091\n",
      "Iteration 3979, loss = 0.00671824\n",
      "Iteration 3980, loss = 0.00671623\n",
      "Iteration 3981, loss = 0.00671395\n",
      "Iteration 3982, loss = 0.00671215\n",
      "Iteration 3983, loss = 0.00670970\n",
      "Iteration 3984, loss = 0.00670864\n",
      "Iteration 3985, loss = 0.00670545\n",
      "Iteration 3986, loss = 0.00670305\n",
      "Iteration 3987, loss = 0.00670103\n",
      "Iteration 3988, loss = 0.00669873\n",
      "Iteration 3989, loss = 0.00669640\n",
      "Iteration 3990, loss = 0.00669445\n",
      "Iteration 3991, loss = 0.00669198\n",
      "Iteration 3992, loss = 0.00668968\n",
      "Iteration 3993, loss = 0.00668791\n",
      "Iteration 3994, loss = 0.00668552\n",
      "Iteration 3995, loss = 0.00668332\n",
      "Iteration 3996, loss = 0.00668138\n",
      "Iteration 3997, loss = 0.00667930\n",
      "Iteration 3998, loss = 0.00667733\n",
      "Iteration 3999, loss = 0.00667547\n",
      "Iteration 4000, loss = 0.00667330\n",
      "Iteration 4001, loss = 0.00667152\n",
      "Iteration 4002, loss = 0.00666925\n",
      "Iteration 4003, loss = 0.00666703\n",
      "Iteration 4004, loss = 0.00666493\n",
      "Iteration 4005, loss = 0.00666318\n",
      "Iteration 4006, loss = 0.00666068\n",
      "Iteration 4007, loss = 0.00665841\n",
      "Iteration 4008, loss = 0.00665644\n",
      "Iteration 4009, loss = 0.00665386\n",
      "Iteration 4010, loss = 0.00665135\n",
      "Iteration 4011, loss = 0.00664878\n",
      "Iteration 4012, loss = 0.00664720\n",
      "Iteration 4013, loss = 0.00664406\n",
      "Iteration 4014, loss = 0.00664290\n",
      "Iteration 4015, loss = 0.00663994\n",
      "Iteration 4016, loss = 0.00663764\n",
      "Iteration 4017, loss = 0.00663594\n",
      "Iteration 4018, loss = 0.00663334\n",
      "Iteration 4019, loss = 0.00663090\n",
      "Iteration 4020, loss = 0.00662929\n",
      "Iteration 4021, loss = 0.00662688\n",
      "Iteration 4022, loss = 0.00662481\n",
      "Iteration 4023, loss = 0.00662263\n",
      "Iteration 4024, loss = 0.00662022\n",
      "Iteration 4025, loss = 0.00661843\n",
      "Iteration 4026, loss = 0.00661644\n",
      "Iteration 4027, loss = 0.00661436\n",
      "Iteration 4028, loss = 0.00661240\n",
      "Iteration 4029, loss = 0.00661048\n",
      "Iteration 4030, loss = 0.00660818\n",
      "Iteration 4031, loss = 0.00660635\n",
      "Iteration 4032, loss = 0.00660417\n",
      "Iteration 4033, loss = 0.00660196\n",
      "Iteration 4034, loss = 0.00660017\n",
      "Iteration 4035, loss = 0.00659796\n",
      "Iteration 4036, loss = 0.00659613\n",
      "Iteration 4037, loss = 0.00659369\n",
      "Iteration 4038, loss = 0.00659157\n",
      "Iteration 4039, loss = 0.00658910\n",
      "Iteration 4040, loss = 0.00658675\n",
      "Iteration 4041, loss = 0.00658447\n",
      "Iteration 4042, loss = 0.00658178\n",
      "Iteration 4043, loss = 0.00657986\n",
      "Iteration 4044, loss = 0.00657752\n",
      "Iteration 4045, loss = 0.00657520\n",
      "Iteration 4046, loss = 0.00657292\n",
      "Iteration 4047, loss = 0.00657074\n",
      "Iteration 4048, loss = 0.00656863\n",
      "Iteration 4049, loss = 0.00656652\n",
      "Iteration 4050, loss = 0.00656431\n",
      "Iteration 4051, loss = 0.00656206\n",
      "Iteration 4052, loss = 0.00656000\n",
      "Iteration 4053, loss = 0.00655774\n",
      "Iteration 4054, loss = 0.00655524\n",
      "Iteration 4055, loss = 0.00655350\n",
      "Iteration 4056, loss = 0.00655066\n",
      "Iteration 4057, loss = 0.00654888\n",
      "Iteration 4058, loss = 0.00654616\n",
      "Iteration 4059, loss = 0.00654389\n",
      "Iteration 4060, loss = 0.00654187\n",
      "Iteration 4061, loss = 0.00653976\n",
      "Iteration 4062, loss = 0.00653783\n",
      "Iteration 4063, loss = 0.00653548\n",
      "Iteration 4064, loss = 0.00653324\n",
      "Iteration 4065, loss = 0.00653117\n",
      "Iteration 4066, loss = 0.00652910\n",
      "Iteration 4067, loss = 0.00652705\n",
      "Iteration 4068, loss = 0.00652527\n",
      "Iteration 4069, loss = 0.00652337\n",
      "Iteration 4070, loss = 0.00652124\n",
      "Iteration 4071, loss = 0.00651923\n",
      "Iteration 4072, loss = 0.00651756\n",
      "Iteration 4073, loss = 0.00651609\n",
      "Iteration 4074, loss = 0.00651408\n",
      "Iteration 4075, loss = 0.00651210\n",
      "Iteration 4076, loss = 0.00650944\n",
      "Iteration 4077, loss = 0.00650722\n",
      "Iteration 4078, loss = 0.00650484\n",
      "Iteration 4079, loss = 0.00650277\n",
      "Iteration 4080, loss = 0.00650049\n",
      "Iteration 4081, loss = 0.00649851\n",
      "Iteration 4082, loss = 0.00649617\n",
      "Iteration 4083, loss = 0.00649359\n",
      "Iteration 4084, loss = 0.00649167\n",
      "Iteration 4085, loss = 0.00648871\n",
      "Iteration 4086, loss = 0.00648672\n",
      "Iteration 4087, loss = 0.00648452\n",
      "Iteration 4088, loss = 0.00648258\n",
      "Iteration 4089, loss = 0.00648067\n",
      "Iteration 4090, loss = 0.00647886\n",
      "Iteration 4091, loss = 0.00647648\n",
      "Iteration 4092, loss = 0.00647456\n",
      "Iteration 4093, loss = 0.00647272\n",
      "Iteration 4094, loss = 0.00647130\n",
      "Iteration 4095, loss = 0.00646930\n",
      "Iteration 4096, loss = 0.00646714\n",
      "Iteration 4097, loss = 0.00646582\n",
      "Iteration 4098, loss = 0.00646353\n",
      "Iteration 4099, loss = 0.00646141\n",
      "Iteration 4100, loss = 0.00645943\n",
      "Iteration 4101, loss = 0.00645765\n",
      "Iteration 4102, loss = 0.00645564\n",
      "Iteration 4103, loss = 0.00645359\n",
      "Iteration 4104, loss = 0.00645175\n",
      "Iteration 4105, loss = 0.00644998\n",
      "Iteration 4106, loss = 0.00644990\n",
      "Iteration 4107, loss = 0.00644600\n",
      "Iteration 4108, loss = 0.00644384\n",
      "Iteration 4109, loss = 0.00644116\n",
      "Iteration 4110, loss = 0.00643920\n",
      "Iteration 4111, loss = 0.00643662\n",
      "Iteration 4112, loss = 0.00643450\n",
      "Iteration 4113, loss = 0.00643309\n",
      "Iteration 4114, loss = 0.00643006\n",
      "Iteration 4115, loss = 0.00642841\n",
      "Iteration 4116, loss = 0.00642421\n",
      "Iteration 4117, loss = 0.00642309\n",
      "Iteration 4118, loss = 0.00642154\n",
      "Iteration 4119, loss = 0.00641752\n",
      "Iteration 4120, loss = 0.00641516\n",
      "Iteration 4121, loss = 0.00641296\n",
      "Iteration 4122, loss = 0.00641076\n",
      "Iteration 4123, loss = 0.00640983\n",
      "Iteration 4124, loss = 0.00640660\n",
      "Iteration 4125, loss = 0.00640414\n",
      "Iteration 4126, loss = 0.00640200\n",
      "Iteration 4127, loss = 0.00639977\n",
      "Iteration 4128, loss = 0.00639750\n",
      "Iteration 4129, loss = 0.00639553\n",
      "Iteration 4130, loss = 0.00639321\n",
      "Iteration 4131, loss = 0.00639132\n",
      "Iteration 4132, loss = 0.00638899\n",
      "Iteration 4133, loss = 0.00638767\n",
      "Iteration 4134, loss = 0.00638539\n",
      "Iteration 4135, loss = 0.00638363\n",
      "Iteration 4136, loss = 0.00638162\n",
      "Iteration 4137, loss = 0.00637950\n",
      "Iteration 4138, loss = 0.00637741\n",
      "Iteration 4139, loss = 0.00637520\n",
      "Iteration 4140, loss = 0.00637290\n",
      "Iteration 4141, loss = 0.00637124\n",
      "Iteration 4142, loss = 0.00636841\n",
      "Iteration 4143, loss = 0.00636602\n",
      "Iteration 4144, loss = 0.00636361\n",
      "Iteration 4145, loss = 0.00636142\n",
      "Iteration 4146, loss = 0.00635946\n",
      "Iteration 4147, loss = 0.00635685\n",
      "Iteration 4148, loss = 0.00635458\n",
      "Iteration 4149, loss = 0.00635265\n",
      "Iteration 4150, loss = 0.00635029\n",
      "Iteration 4151, loss = 0.00634861\n",
      "Iteration 4152, loss = 0.00634615\n",
      "Iteration 4153, loss = 0.00634422\n",
      "Iteration 4154, loss = 0.00634194\n",
      "Iteration 4155, loss = 0.00634002\n",
      "Iteration 4156, loss = 0.00633803\n",
      "Iteration 4157, loss = 0.00633605\n",
      "Iteration 4158, loss = 0.00633402\n",
      "Iteration 4159, loss = 0.00633217\n",
      "Iteration 4160, loss = 0.00633032\n",
      "Iteration 4161, loss = 0.00632838\n",
      "Iteration 4162, loss = 0.00632643\n",
      "Iteration 4163, loss = 0.00632443\n",
      "Iteration 4164, loss = 0.00632285\n",
      "Iteration 4165, loss = 0.00632084\n",
      "Iteration 4166, loss = 0.00631880\n",
      "Iteration 4167, loss = 0.00631725\n",
      "Iteration 4168, loss = 0.00631537\n",
      "Iteration 4169, loss = 0.00631396\n",
      "Iteration 4170, loss = 0.00631127\n",
      "Iteration 4171, loss = 0.00630923\n",
      "Iteration 4172, loss = 0.00630806\n",
      "Iteration 4173, loss = 0.00630601\n",
      "Iteration 4174, loss = 0.00630390\n",
      "Iteration 4175, loss = 0.00630141\n",
      "Iteration 4176, loss = 0.00629910\n",
      "Iteration 4177, loss = 0.00629682\n",
      "Iteration 4178, loss = 0.00629549\n",
      "Iteration 4179, loss = 0.00629285\n",
      "Iteration 4180, loss = 0.00629083\n",
      "Iteration 4181, loss = 0.00628855\n",
      "Iteration 4182, loss = 0.00628689\n",
      "Iteration 4183, loss = 0.00628471\n",
      "Iteration 4184, loss = 0.00628254\n",
      "Iteration 4185, loss = 0.00628033\n",
      "Iteration 4186, loss = 0.00627800\n",
      "Iteration 4187, loss = 0.00627598\n",
      "Iteration 4188, loss = 0.00627385\n",
      "Iteration 4189, loss = 0.00627162\n",
      "Iteration 4190, loss = 0.00626958\n",
      "Iteration 4191, loss = 0.00626789\n",
      "Iteration 4192, loss = 0.00626574\n",
      "Iteration 4193, loss = 0.00626385\n",
      "Iteration 4194, loss = 0.00626163\n",
      "Iteration 4195, loss = 0.00625984\n",
      "Iteration 4196, loss = 0.00625891\n",
      "Iteration 4197, loss = 0.00625538\n",
      "Iteration 4198, loss = 0.00625316\n",
      "Iteration 4199, loss = 0.00625080\n",
      "Iteration 4200, loss = 0.00624950\n",
      "Iteration 4201, loss = 0.00624673\n",
      "Iteration 4202, loss = 0.00624488\n",
      "Iteration 4203, loss = 0.00624285\n",
      "Iteration 4204, loss = 0.00624087\n",
      "Iteration 4205, loss = 0.00623842\n",
      "Iteration 4206, loss = 0.00623647\n",
      "Iteration 4207, loss = 0.00623440\n",
      "Iteration 4208, loss = 0.00623249\n",
      "Iteration 4209, loss = 0.00623068\n",
      "Iteration 4210, loss = 0.00622881\n",
      "Iteration 4211, loss = 0.00622762\n",
      "Iteration 4212, loss = 0.00622486\n",
      "Iteration 4213, loss = 0.00622316\n",
      "Iteration 4214, loss = 0.00622114\n",
      "Iteration 4215, loss = 0.00621875\n",
      "Iteration 4216, loss = 0.00621650\n",
      "Iteration 4217, loss = 0.00621457\n",
      "Iteration 4218, loss = 0.00621215\n",
      "Iteration 4219, loss = 0.00621056\n",
      "Iteration 4220, loss = 0.00620837\n",
      "Iteration 4221, loss = 0.00620757\n",
      "Iteration 4222, loss = 0.00620453\n",
      "Iteration 4223, loss = 0.00620249\n",
      "Iteration 4224, loss = 0.00620041\n",
      "Iteration 4225, loss = 0.00619817\n",
      "Iteration 4226, loss = 0.00619611\n",
      "Iteration 4227, loss = 0.00619638\n",
      "Iteration 4228, loss = 0.00619293\n",
      "Iteration 4229, loss = 0.00619062\n",
      "Iteration 4230, loss = 0.00618893\n",
      "Iteration 4231, loss = 0.00618708\n",
      "Iteration 4232, loss = 0.00618479\n",
      "Iteration 4233, loss = 0.00618266\n",
      "Iteration 4234, loss = 0.00618072\n",
      "Iteration 4235, loss = 0.00617869\n",
      "Iteration 4236, loss = 0.00617678\n",
      "Iteration 4237, loss = 0.00617460\n",
      "Iteration 4238, loss = 0.00617257\n",
      "Iteration 4239, loss = 0.00617089\n",
      "Iteration 4240, loss = 0.00616882\n",
      "Iteration 4241, loss = 0.00616668\n",
      "Iteration 4242, loss = 0.00616501\n",
      "Iteration 4243, loss = 0.00616274\n",
      "Iteration 4244, loss = 0.00616085\n",
      "Iteration 4245, loss = 0.00615869\n",
      "Iteration 4246, loss = 0.00615651\n",
      "Iteration 4247, loss = 0.00615451\n",
      "Iteration 4248, loss = 0.00615229\n",
      "Iteration 4249, loss = 0.00615171\n",
      "Iteration 4250, loss = 0.00614849\n",
      "Iteration 4251, loss = 0.00614648\n",
      "Iteration 4252, loss = 0.00614435\n",
      "Iteration 4253, loss = 0.00614295\n",
      "Iteration 4254, loss = 0.00614042\n",
      "Iteration 4255, loss = 0.00613856\n",
      "Iteration 4256, loss = 0.00613649\n",
      "Iteration 4257, loss = 0.00613443\n",
      "Iteration 4258, loss = 0.00613248\n",
      "Iteration 4259, loss = 0.00613062\n",
      "Iteration 4260, loss = 0.00612873\n",
      "Iteration 4261, loss = 0.00612678\n",
      "Iteration 4262, loss = 0.00612507\n",
      "Iteration 4263, loss = 0.00612301\n",
      "Iteration 4264, loss = 0.00612082\n",
      "Iteration 4265, loss = 0.00611864\n",
      "Iteration 4266, loss = 0.00611680\n",
      "Iteration 4267, loss = 0.00611530\n",
      "Iteration 4268, loss = 0.00611278\n",
      "Iteration 4269, loss = 0.00611069\n",
      "Iteration 4270, loss = 0.00610843\n",
      "Iteration 4271, loss = 0.00610686\n",
      "Iteration 4272, loss = 0.00610460\n",
      "Iteration 4273, loss = 0.00610274\n",
      "Iteration 4274, loss = 0.00610089\n",
      "Iteration 4275, loss = 0.00609867\n",
      "Iteration 4276, loss = 0.00609732\n",
      "Iteration 4277, loss = 0.00609460\n",
      "Iteration 4278, loss = 0.00609241\n",
      "Iteration 4279, loss = 0.00609035\n",
      "Iteration 4280, loss = 0.00608825\n",
      "Iteration 4281, loss = 0.00608630\n",
      "Iteration 4282, loss = 0.00608391\n",
      "Iteration 4283, loss = 0.00608174\n",
      "Iteration 4284, loss = 0.00608001\n",
      "Iteration 4285, loss = 0.00607769\n",
      "Iteration 4286, loss = 0.00607658\n",
      "Iteration 4287, loss = 0.00607404\n",
      "Iteration 4288, loss = 0.00607242\n",
      "Iteration 4289, loss = 0.00607080\n",
      "Iteration 4290, loss = 0.00606853\n",
      "Iteration 4291, loss = 0.00606649\n",
      "Iteration 4292, loss = 0.00606472\n",
      "Iteration 4293, loss = 0.00606302\n",
      "Iteration 4294, loss = 0.00606297\n",
      "Iteration 4295, loss = 0.00606058\n",
      "Iteration 4296, loss = 0.00605803\n",
      "Iteration 4297, loss = 0.00605612\n",
      "Iteration 4298, loss = 0.00605387\n",
      "Iteration 4299, loss = 0.00605217\n",
      "Iteration 4300, loss = 0.00605001\n",
      "Iteration 4301, loss = 0.00604803\n",
      "Iteration 4302, loss = 0.00604611\n",
      "Iteration 4303, loss = 0.00604421\n",
      "Iteration 4304, loss = 0.00604216\n",
      "Iteration 4305, loss = 0.00604033\n",
      "Iteration 4306, loss = 0.00603874\n",
      "Iteration 4307, loss = 0.00603709\n",
      "Iteration 4308, loss = 0.00603535\n",
      "Iteration 4309, loss = 0.00603368\n",
      "Iteration 4310, loss = 0.00603170\n",
      "Iteration 4311, loss = 0.00602989\n",
      "Iteration 4312, loss = 0.00602809\n",
      "Iteration 4313, loss = 0.00602647\n",
      "Iteration 4314, loss = 0.00602435\n",
      "Iteration 4315, loss = 0.00602270\n",
      "Iteration 4316, loss = 0.00602095\n",
      "Iteration 4317, loss = 0.00601901\n",
      "Iteration 4318, loss = 0.00601723\n",
      "Iteration 4319, loss = 0.00601543\n",
      "Iteration 4320, loss = 0.00601370\n",
      "Iteration 4321, loss = 0.00601199\n",
      "Iteration 4322, loss = 0.00601027\n",
      "Iteration 4323, loss = 0.00600842\n",
      "Iteration 4324, loss = 0.00600669\n",
      "Iteration 4325, loss = 0.00600518\n",
      "Iteration 4326, loss = 0.00600349\n",
      "Iteration 4327, loss = 0.00600129\n",
      "Iteration 4328, loss = 0.00599952\n",
      "Iteration 4329, loss = 0.00599758\n",
      "Iteration 4330, loss = 0.00599615\n",
      "Iteration 4331, loss = 0.00599378\n",
      "Iteration 4332, loss = 0.00599220\n",
      "Iteration 4333, loss = 0.00598971\n",
      "Iteration 4334, loss = 0.00598766\n",
      "Iteration 4335, loss = 0.00598603\n",
      "Iteration 4336, loss = 0.00598410\n",
      "Iteration 4337, loss = 0.00598263\n",
      "Iteration 4338, loss = 0.00598057\n",
      "Iteration 4339, loss = 0.00597860\n",
      "Iteration 4340, loss = 0.00597707\n",
      "Iteration 4341, loss = 0.00597505\n",
      "Iteration 4342, loss = 0.00597338\n",
      "Iteration 4343, loss = 0.00597143\n",
      "Iteration 4344, loss = 0.00596989\n",
      "Iteration 4345, loss = 0.00596917\n",
      "Iteration 4346, loss = 0.00596668\n",
      "Iteration 4347, loss = 0.00596483\n",
      "Iteration 4348, loss = 0.00596300\n",
      "Iteration 4349, loss = 0.00596104\n",
      "Iteration 4350, loss = 0.00595916\n",
      "Iteration 4351, loss = 0.00595741\n",
      "Iteration 4352, loss = 0.00595568\n",
      "Iteration 4353, loss = 0.00595383\n",
      "Iteration 4354, loss = 0.00595174\n",
      "Iteration 4355, loss = 0.00595027\n",
      "Iteration 4356, loss = 0.00594849\n",
      "Iteration 4357, loss = 0.00594682\n",
      "Iteration 4358, loss = 0.00594511\n",
      "Iteration 4359, loss = 0.00594306\n",
      "Iteration 4360, loss = 0.00594109\n",
      "Iteration 4361, loss = 0.00593966\n",
      "Iteration 4362, loss = 0.00593751\n",
      "Iteration 4363, loss = 0.00593560\n",
      "Iteration 4364, loss = 0.00593341\n",
      "Iteration 4365, loss = 0.00593170\n",
      "Iteration 4366, loss = 0.00592984\n",
      "Iteration 4367, loss = 0.00592786\n",
      "Iteration 4368, loss = 0.00592617\n",
      "Iteration 4369, loss = 0.00592412\n",
      "Iteration 4370, loss = 0.00592217\n",
      "Iteration 4371, loss = 0.00592009\n",
      "Iteration 4372, loss = 0.00591821\n",
      "Iteration 4373, loss = 0.00591674\n",
      "Iteration 4374, loss = 0.00591507\n",
      "Iteration 4375, loss = 0.00591293\n",
      "Iteration 4376, loss = 0.00591164\n",
      "Iteration 4377, loss = 0.00590966\n",
      "Iteration 4378, loss = 0.00590745\n",
      "Iteration 4379, loss = 0.00590573\n",
      "Iteration 4380, loss = 0.00590382\n",
      "Iteration 4381, loss = 0.00590202\n",
      "Iteration 4382, loss = 0.00590005\n",
      "Iteration 4383, loss = 0.00589840\n",
      "Iteration 4384, loss = 0.00589662\n",
      "Iteration 4385, loss = 0.00589463\n",
      "Iteration 4386, loss = 0.00589257\n",
      "Iteration 4387, loss = 0.00589088\n",
      "Iteration 4388, loss = 0.00588901\n",
      "Iteration 4389, loss = 0.00588691\n",
      "Iteration 4390, loss = 0.00588546\n",
      "Iteration 4391, loss = 0.00588306\n",
      "Iteration 4392, loss = 0.00588108\n",
      "Iteration 4393, loss = 0.00587894\n",
      "Iteration 4394, loss = 0.00587748\n",
      "Iteration 4395, loss = 0.00587515\n",
      "Iteration 4396, loss = 0.00587338\n",
      "Iteration 4397, loss = 0.00587148\n",
      "Iteration 4398, loss = 0.00586981\n",
      "Iteration 4399, loss = 0.00586787\n",
      "Iteration 4400, loss = 0.00586600\n",
      "Iteration 4401, loss = 0.00586409\n",
      "Iteration 4402, loss = 0.00586232\n",
      "Iteration 4403, loss = 0.00586050\n",
      "Iteration 4404, loss = 0.00585877\n",
      "Iteration 4405, loss = 0.00585682\n",
      "Iteration 4406, loss = 0.00585464\n",
      "Iteration 4407, loss = 0.00585287\n",
      "Iteration 4408, loss = 0.00585116\n",
      "Iteration 4409, loss = 0.00584916\n",
      "Iteration 4410, loss = 0.00584729\n",
      "Iteration 4411, loss = 0.00584562\n",
      "Iteration 4412, loss = 0.00584364\n",
      "Iteration 4413, loss = 0.00584222\n",
      "Iteration 4414, loss = 0.00584032\n",
      "Iteration 4415, loss = 0.00583865\n",
      "Iteration 4416, loss = 0.00583695\n",
      "Iteration 4417, loss = 0.00583531\n",
      "Iteration 4418, loss = 0.00583356\n",
      "Iteration 4419, loss = 0.00583228\n",
      "Iteration 4420, loss = 0.00583017\n",
      "Iteration 4421, loss = 0.00582853\n",
      "Iteration 4422, loss = 0.00582684\n",
      "Iteration 4423, loss = 0.00582509\n",
      "Iteration 4424, loss = 0.00582313\n",
      "Iteration 4425, loss = 0.00582203\n",
      "Iteration 4426, loss = 0.00581982\n",
      "Iteration 4427, loss = 0.00581773\n",
      "Iteration 4428, loss = 0.00581602\n",
      "Iteration 4429, loss = 0.00581406\n",
      "Iteration 4430, loss = 0.00581233\n",
      "Iteration 4431, loss = 0.00581050\n",
      "Iteration 4432, loss = 0.00580892\n",
      "Iteration 4433, loss = 0.00580687\n",
      "Iteration 4434, loss = 0.00580510\n",
      "Iteration 4435, loss = 0.00580332\n",
      "Iteration 4436, loss = 0.00580173\n",
      "Iteration 4437, loss = 0.00579997\n",
      "Iteration 4438, loss = 0.00579848\n",
      "Iteration 4439, loss = 0.00579636\n",
      "Iteration 4440, loss = 0.00579444\n",
      "Iteration 4441, loss = 0.00579286\n",
      "Iteration 4442, loss = 0.00579076\n",
      "Iteration 4443, loss = 0.00578899\n",
      "Iteration 4444, loss = 0.00578716\n",
      "Iteration 4445, loss = 0.00578530\n",
      "Iteration 4446, loss = 0.00578366\n",
      "Iteration 4447, loss = 0.00578173\n",
      "Iteration 4448, loss = 0.00578032\n",
      "Iteration 4449, loss = 0.00577842\n",
      "Iteration 4450, loss = 0.00577641\n",
      "Iteration 4451, loss = 0.00577496\n",
      "Iteration 4452, loss = 0.00577311\n",
      "Iteration 4453, loss = 0.00577141\n",
      "Iteration 4454, loss = 0.00576938\n",
      "Iteration 4455, loss = 0.00576771\n",
      "Iteration 4456, loss = 0.00576578\n",
      "Iteration 4457, loss = 0.00576395\n",
      "Iteration 4458, loss = 0.00576225\n",
      "Iteration 4459, loss = 0.00576091\n",
      "Iteration 4460, loss = 0.00575846\n",
      "Iteration 4461, loss = 0.00575677\n",
      "Iteration 4462, loss = 0.00575466\n",
      "Iteration 4463, loss = 0.00575340\n",
      "Iteration 4464, loss = 0.00575143\n",
      "Iteration 4465, loss = 0.00574975\n",
      "Iteration 4466, loss = 0.00574819\n",
      "Iteration 4467, loss = 0.00574663\n",
      "Iteration 4468, loss = 0.00574502\n",
      "Iteration 4469, loss = 0.00574332\n",
      "Iteration 4470, loss = 0.00574172\n",
      "Iteration 4471, loss = 0.00573988\n",
      "Iteration 4472, loss = 0.00573829\n",
      "Iteration 4473, loss = 0.00573663\n",
      "Iteration 4474, loss = 0.00573499\n",
      "Iteration 4475, loss = 0.00573333\n",
      "Iteration 4476, loss = 0.00573171\n",
      "Iteration 4477, loss = 0.00572996\n",
      "Iteration 4478, loss = 0.00572829\n",
      "Iteration 4479, loss = 0.00572658\n",
      "Iteration 4480, loss = 0.00572546\n",
      "Iteration 4481, loss = 0.00572363\n",
      "Iteration 4482, loss = 0.00572188\n",
      "Iteration 4483, loss = 0.00572024\n",
      "Iteration 4484, loss = 0.00571863\n",
      "Iteration 4485, loss = 0.00571721\n",
      "Iteration 4486, loss = 0.00571533\n",
      "Iteration 4487, loss = 0.00571370\n",
      "Iteration 4488, loss = 0.00571222\n",
      "Iteration 4489, loss = 0.00571056\n",
      "Iteration 4490, loss = 0.00570884\n",
      "Iteration 4491, loss = 0.00570680\n",
      "Iteration 4492, loss = 0.00570545\n",
      "Iteration 4493, loss = 0.00570348\n",
      "Iteration 4494, loss = 0.00570193\n",
      "Iteration 4495, loss = 0.00570007\n",
      "Iteration 4496, loss = 0.00569838\n",
      "Iteration 4497, loss = 0.00569653\n",
      "Iteration 4498, loss = 0.00569501\n",
      "Iteration 4499, loss = 0.00569300\n",
      "Iteration 4500, loss = 0.00569240\n",
      "Iteration 4501, loss = 0.00568976\n",
      "Iteration 4502, loss = 0.00568792\n",
      "Iteration 4503, loss = 0.00568640\n",
      "Iteration 4504, loss = 0.00568441\n",
      "Iteration 4505, loss = 0.00568236\n",
      "Iteration 4506, loss = 0.00568086\n",
      "Iteration 4507, loss = 0.00567891\n",
      "Iteration 4508, loss = 0.00567689\n",
      "Iteration 4509, loss = 0.00567530\n",
      "Iteration 4510, loss = 0.00567353\n",
      "Iteration 4511, loss = 0.00567168\n",
      "Iteration 4512, loss = 0.00566962\n",
      "Iteration 4513, loss = 0.00566762\n",
      "Iteration 4514, loss = 0.00566708\n",
      "Iteration 4515, loss = 0.00566479\n",
      "Iteration 4516, loss = 0.00566291\n",
      "Iteration 4517, loss = 0.00566148\n",
      "Iteration 4518, loss = 0.00565954\n",
      "Iteration 4519, loss = 0.00565803\n",
      "Iteration 4520, loss = 0.00565613\n",
      "Iteration 4521, loss = 0.00565449\n",
      "Iteration 4522, loss = 0.00565306\n",
      "Iteration 4523, loss = 0.00565118\n",
      "Iteration 4524, loss = 0.00564933\n",
      "Iteration 4525, loss = 0.00564748\n",
      "Iteration 4526, loss = 0.00564603\n",
      "Iteration 4527, loss = 0.00564394\n",
      "Iteration 4528, loss = 0.00564237\n",
      "Iteration 4529, loss = 0.00564069\n",
      "Iteration 4530, loss = 0.00563870\n",
      "Iteration 4531, loss = 0.00563702\n",
      "Iteration 4532, loss = 0.00563514\n",
      "Iteration 4533, loss = 0.00563364\n",
      "Iteration 4534, loss = 0.00563177\n",
      "Iteration 4535, loss = 0.00563003\n",
      "Iteration 4536, loss = 0.00562898\n",
      "Iteration 4537, loss = 0.00562784\n",
      "Iteration 4538, loss = 0.00562562\n",
      "Iteration 4539, loss = 0.00562376\n",
      "Iteration 4540, loss = 0.00562191\n",
      "Iteration 4541, loss = 0.00562022\n",
      "Iteration 4542, loss = 0.00561868\n",
      "Iteration 4543, loss = 0.00561708\n",
      "Iteration 4544, loss = 0.00561559\n",
      "Iteration 4545, loss = 0.00561385\n",
      "Iteration 4546, loss = 0.00561225\n",
      "Iteration 4547, loss = 0.00561046\n",
      "Iteration 4548, loss = 0.00560869\n",
      "Iteration 4549, loss = 0.00560699\n",
      "Iteration 4550, loss = 0.00560549\n",
      "Iteration 4551, loss = 0.00560368\n",
      "Iteration 4552, loss = 0.00560192\n",
      "Iteration 4553, loss = 0.00560028\n",
      "Iteration 4554, loss = 0.00559867\n",
      "Iteration 4555, loss = 0.00559688\n",
      "Iteration 4556, loss = 0.00559520\n",
      "Iteration 4557, loss = 0.00559365\n",
      "Iteration 4558, loss = 0.00559194\n",
      "Iteration 4559, loss = 0.00559038\n",
      "Iteration 4560, loss = 0.00558872\n",
      "Iteration 4561, loss = 0.00558718\n",
      "Iteration 4562, loss = 0.00558566\n",
      "Iteration 4563, loss = 0.00558370\n",
      "Iteration 4564, loss = 0.00558239\n",
      "Iteration 4565, loss = 0.00558055\n",
      "Iteration 4566, loss = 0.00557916\n",
      "Iteration 4567, loss = 0.00557728\n",
      "Iteration 4568, loss = 0.00557594\n",
      "Iteration 4569, loss = 0.00557439\n",
      "Iteration 4570, loss = 0.00557246\n",
      "Iteration 4571, loss = 0.00557070\n",
      "Iteration 4572, loss = 0.00556947\n",
      "Iteration 4573, loss = 0.00556728\n",
      "Iteration 4574, loss = 0.00556554\n",
      "Iteration 4575, loss = 0.00556388\n",
      "Iteration 4576, loss = 0.00556218\n",
      "Iteration 4577, loss = 0.00555991\n",
      "Iteration 4578, loss = 0.00555878\n",
      "Iteration 4579, loss = 0.00555698\n",
      "Iteration 4580, loss = 0.00555473\n",
      "Iteration 4581, loss = 0.00555274\n",
      "Iteration 4582, loss = 0.00555089\n",
      "Iteration 4583, loss = 0.00554930\n",
      "Iteration 4584, loss = 0.00554779\n",
      "Iteration 4585, loss = 0.00554618\n",
      "Iteration 4586, loss = 0.00554436\n",
      "Iteration 4587, loss = 0.00554312\n",
      "Iteration 4588, loss = 0.00554150\n",
      "Iteration 4589, loss = 0.00554031\n",
      "Iteration 4590, loss = 0.00553808\n",
      "Iteration 4591, loss = 0.00553656\n",
      "Iteration 4592, loss = 0.00553488\n",
      "Iteration 4593, loss = 0.00553353\n",
      "Iteration 4594, loss = 0.00553182\n",
      "Iteration 4595, loss = 0.00553019\n",
      "Iteration 4596, loss = 0.00552871\n",
      "Iteration 4597, loss = 0.00552645\n",
      "Iteration 4598, loss = 0.00552508\n",
      "Iteration 4599, loss = 0.00552272\n",
      "Iteration 4600, loss = 0.00552194\n",
      "Iteration 4601, loss = 0.00552003\n",
      "Iteration 4602, loss = 0.00551814\n",
      "Iteration 4603, loss = 0.00551648\n",
      "Iteration 4604, loss = 0.00551498\n",
      "Iteration 4605, loss = 0.00551340\n",
      "Iteration 4606, loss = 0.00551158\n",
      "Iteration 4607, loss = 0.00551006\n",
      "Iteration 4608, loss = 0.00550810\n",
      "Iteration 4609, loss = 0.00550650\n",
      "Iteration 4610, loss = 0.00550496\n",
      "Iteration 4611, loss = 0.00550331\n",
      "Iteration 4612, loss = 0.00550159\n",
      "Iteration 4613, loss = 0.00550019\n",
      "Iteration 4614, loss = 0.00549855\n",
      "Iteration 4615, loss = 0.00549694\n",
      "Iteration 4616, loss = 0.00549544\n",
      "Iteration 4617, loss = 0.00549370\n",
      "Iteration 4618, loss = 0.00549234\n",
      "Iteration 4619, loss = 0.00549060\n",
      "Iteration 4620, loss = 0.00548856\n",
      "Iteration 4621, loss = 0.00548652\n",
      "Iteration 4622, loss = 0.00548479\n",
      "Iteration 4623, loss = 0.00548307\n",
      "Iteration 4624, loss = 0.00548134\n",
      "Iteration 4625, loss = 0.00547977\n",
      "Iteration 4626, loss = 0.00547849\n",
      "Iteration 4627, loss = 0.00547662\n",
      "Iteration 4628, loss = 0.00547500\n",
      "Iteration 4629, loss = 0.00547341\n",
      "Iteration 4630, loss = 0.00547175\n",
      "Iteration 4631, loss = 0.00547015\n",
      "Iteration 4632, loss = 0.00546845\n",
      "Iteration 4633, loss = 0.00546663\n",
      "Iteration 4634, loss = 0.00546529\n",
      "Iteration 4635, loss = 0.00546342\n",
      "Iteration 4636, loss = 0.00546183\n",
      "Iteration 4637, loss = 0.00546011\n",
      "Iteration 4638, loss = 0.00545832\n",
      "Iteration 4639, loss = 0.00545663\n",
      "Iteration 4640, loss = 0.00545498\n",
      "Iteration 4641, loss = 0.00545339\n",
      "Iteration 4642, loss = 0.00545178\n",
      "Iteration 4643, loss = 0.00545010\n",
      "Iteration 4644, loss = 0.00544858\n",
      "Iteration 4645, loss = 0.00544691\n",
      "Iteration 4646, loss = 0.00544532\n",
      "Iteration 4647, loss = 0.00544358\n",
      "Iteration 4648, loss = 0.00544214\n",
      "Iteration 4649, loss = 0.00544068\n",
      "Iteration 4650, loss = 0.00543907\n",
      "Iteration 4651, loss = 0.00543753\n",
      "Iteration 4652, loss = 0.00543619\n",
      "Iteration 4653, loss = 0.00543522\n",
      "Iteration 4654, loss = 0.00543335\n",
      "Iteration 4655, loss = 0.00543180\n",
      "Iteration 4656, loss = 0.00543032\n",
      "Iteration 4657, loss = 0.00542890\n",
      "Iteration 4658, loss = 0.00542721\n",
      "Iteration 4659, loss = 0.00542571\n",
      "Iteration 4660, loss = 0.00542415\n",
      "Iteration 4661, loss = 0.00542260\n",
      "Iteration 4662, loss = 0.00542097\n",
      "Iteration 4663, loss = 0.00541950\n",
      "Iteration 4664, loss = 0.00541792\n",
      "Iteration 4665, loss = 0.00541637\n",
      "Iteration 4666, loss = 0.00541502\n",
      "Iteration 4667, loss = 0.00541343\n",
      "Iteration 4668, loss = 0.00541212\n",
      "Iteration 4669, loss = 0.00541048\n",
      "Iteration 4670, loss = 0.00540886\n",
      "Iteration 4671, loss = 0.00540718\n",
      "Iteration 4672, loss = 0.00540563\n",
      "Iteration 4673, loss = 0.00540399\n",
      "Iteration 4674, loss = 0.00540266\n",
      "Iteration 4675, loss = 0.00540090\n",
      "Iteration 4676, loss = 0.00539937\n",
      "Iteration 4677, loss = 0.00539771\n",
      "Iteration 4678, loss = 0.00539623\n",
      "Iteration 4679, loss = 0.00539484\n",
      "Iteration 4680, loss = 0.00539321\n",
      "Iteration 4681, loss = 0.00539194\n",
      "Iteration 4682, loss = 0.00539023\n",
      "Iteration 4683, loss = 0.00538898\n",
      "Iteration 4684, loss = 0.00538731\n",
      "Iteration 4685, loss = 0.00538577\n",
      "Iteration 4686, loss = 0.00538429\n",
      "Iteration 4687, loss = 0.00538308\n",
      "Iteration 4688, loss = 0.00538141\n",
      "Iteration 4689, loss = 0.00538005\n",
      "Iteration 4690, loss = 0.00537863\n",
      "Iteration 4691, loss = 0.00537719\n",
      "Iteration 4692, loss = 0.00537569\n",
      "Iteration 4693, loss = 0.00537441\n",
      "Iteration 4694, loss = 0.00537259\n",
      "Iteration 4695, loss = 0.00537112\n",
      "Iteration 4696, loss = 0.00536924\n",
      "Iteration 4697, loss = 0.00536769\n",
      "Iteration 4698, loss = 0.00536641\n",
      "Iteration 4699, loss = 0.00536440\n",
      "Iteration 4700, loss = 0.00536264\n",
      "Iteration 4701, loss = 0.00536104\n",
      "Iteration 4702, loss = 0.00535975\n",
      "Iteration 4703, loss = 0.00535768\n",
      "Iteration 4704, loss = 0.00535592\n",
      "Iteration 4705, loss = 0.00535442\n",
      "Iteration 4706, loss = 0.00535273\n",
      "Iteration 4707, loss = 0.00535087\n",
      "Iteration 4708, loss = 0.00534924\n",
      "Iteration 4709, loss = 0.00534806\n",
      "Iteration 4710, loss = 0.00534610\n",
      "Iteration 4711, loss = 0.00534514\n",
      "Iteration 4712, loss = 0.00534308\n",
      "Iteration 4713, loss = 0.00534154\n",
      "Iteration 4714, loss = 0.00534015\n",
      "Iteration 4715, loss = 0.00533862\n",
      "Iteration 4716, loss = 0.00533718\n",
      "Iteration 4717, loss = 0.00533575\n",
      "Iteration 4718, loss = 0.00533419\n",
      "Iteration 4719, loss = 0.00533277\n",
      "Iteration 4720, loss = 0.00533138\n",
      "Iteration 4721, loss = 0.00533015\n",
      "Iteration 4722, loss = 0.00532859\n",
      "Iteration 4723, loss = 0.00532741\n",
      "Iteration 4724, loss = 0.00532598\n",
      "Iteration 4725, loss = 0.00532489\n",
      "Iteration 4726, loss = 0.00532302\n",
      "Iteration 4727, loss = 0.00532158\n",
      "Iteration 4728, loss = 0.00532008\n",
      "Iteration 4729, loss = 0.00531959\n",
      "Iteration 4730, loss = 0.00531777\n",
      "Iteration 4731, loss = 0.00531617\n",
      "Iteration 4732, loss = 0.00531482\n",
      "Iteration 4733, loss = 0.00531319\n",
      "Iteration 4734, loss = 0.00531164\n",
      "Iteration 4735, loss = 0.00531001\n",
      "Iteration 4736, loss = 0.00530864\n",
      "Iteration 4737, loss = 0.00530709\n",
      "Iteration 4738, loss = 0.00530567\n",
      "Iteration 4739, loss = 0.00530400\n",
      "Iteration 4740, loss = 0.00530248\n",
      "Iteration 4741, loss = 0.00530052\n",
      "Iteration 4742, loss = 0.00529919\n",
      "Iteration 4743, loss = 0.00529775\n",
      "Iteration 4744, loss = 0.00529605\n",
      "Iteration 4745, loss = 0.00529441\n",
      "Iteration 4746, loss = 0.00529274\n",
      "Iteration 4747, loss = 0.00529142\n",
      "Iteration 4748, loss = 0.00529044\n",
      "Iteration 4749, loss = 0.00528833\n",
      "Iteration 4750, loss = 0.00528690\n",
      "Iteration 4751, loss = 0.00528541\n",
      "Iteration 4752, loss = 0.00528410\n",
      "Iteration 4753, loss = 0.00528253\n",
      "Iteration 4754, loss = 0.00528112\n",
      "Iteration 4755, loss = 0.00527960\n",
      "Iteration 4756, loss = 0.00527821\n",
      "Iteration 4757, loss = 0.00527717\n",
      "Iteration 4758, loss = 0.00527513\n",
      "Iteration 4759, loss = 0.00527369\n",
      "Iteration 4760, loss = 0.00527209\n",
      "Iteration 4761, loss = 0.00527048\n",
      "Iteration 4762, loss = 0.00526894\n",
      "Iteration 4763, loss = 0.00526755\n",
      "Iteration 4764, loss = 0.00526585\n",
      "Iteration 4765, loss = 0.00526419\n",
      "Iteration 4766, loss = 0.00526294\n",
      "Iteration 4767, loss = 0.00526115\n",
      "Iteration 4768, loss = 0.00525946\n",
      "Iteration 4769, loss = 0.00525797\n",
      "Iteration 4770, loss = 0.00525635\n",
      "Iteration 4771, loss = 0.00525481\n",
      "Iteration 4772, loss = 0.00525365\n",
      "Iteration 4773, loss = 0.00525198\n",
      "Iteration 4774, loss = 0.00525039\n",
      "Iteration 4775, loss = 0.00524896\n",
      "Iteration 4776, loss = 0.00524745\n",
      "Iteration 4777, loss = 0.00524572\n",
      "Iteration 4778, loss = 0.00524440\n",
      "Iteration 4779, loss = 0.00524308\n",
      "Iteration 4780, loss = 0.00524133\n",
      "Iteration 4781, loss = 0.00523999\n",
      "Iteration 4782, loss = 0.00523846\n",
      "Iteration 4783, loss = 0.00523677\n",
      "Iteration 4784, loss = 0.00523507\n",
      "Iteration 4785, loss = 0.00523338\n",
      "Iteration 4786, loss = 0.00523214\n",
      "Iteration 4787, loss = 0.00523038\n",
      "Iteration 4788, loss = 0.00522861\n",
      "Iteration 4789, loss = 0.00522671\n",
      "Iteration 4790, loss = 0.00522666\n",
      "Iteration 4791, loss = 0.00522433\n",
      "Iteration 4792, loss = 0.00522261\n",
      "Iteration 4793, loss = 0.00522072\n",
      "Iteration 4794, loss = 0.00521939\n",
      "Iteration 4795, loss = 0.00521767\n",
      "Iteration 4796, loss = 0.00521603\n",
      "Iteration 4797, loss = 0.00521430\n",
      "Iteration 4798, loss = 0.00521281\n",
      "Iteration 4799, loss = 0.00521132\n",
      "Iteration 4800, loss = 0.00520951\n",
      "Iteration 4801, loss = 0.00520824\n",
      "Iteration 4802, loss = 0.00520657\n",
      "Iteration 4803, loss = 0.00520494\n",
      "Iteration 4804, loss = 0.00520333\n",
      "Iteration 4805, loss = 0.00520207\n",
      "Iteration 4806, loss = 0.00520034\n",
      "Iteration 4807, loss = 0.00519935\n",
      "Iteration 4808, loss = 0.00519796\n",
      "Iteration 4809, loss = 0.00519619\n",
      "Iteration 4810, loss = 0.00519476\n",
      "Iteration 4811, loss = 0.00519361\n",
      "Iteration 4812, loss = 0.00519214\n",
      "Iteration 4813, loss = 0.00519047\n",
      "Iteration 4814, loss = 0.00518931\n",
      "Iteration 4815, loss = 0.00518743\n",
      "Iteration 4816, loss = 0.00518611\n",
      "Iteration 4817, loss = 0.00518463\n",
      "Iteration 4818, loss = 0.00518302\n",
      "Iteration 4819, loss = 0.00518169\n",
      "Iteration 4820, loss = 0.00518021\n",
      "Iteration 4821, loss = 0.00517889\n",
      "Iteration 4822, loss = 0.00517741\n",
      "Iteration 4823, loss = 0.00517619\n",
      "Iteration 4824, loss = 0.00517469\n",
      "Iteration 4825, loss = 0.00517351\n",
      "Iteration 4826, loss = 0.00517199\n",
      "Iteration 4827, loss = 0.00517049\n",
      "Iteration 4828, loss = 0.00516912\n",
      "Iteration 4829, loss = 0.00516775\n",
      "Iteration 4830, loss = 0.00516658\n",
      "Iteration 4831, loss = 0.00516508\n",
      "Iteration 4832, loss = 0.00516355\n",
      "Iteration 4833, loss = 0.00516197\n",
      "Iteration 4834, loss = 0.00516064\n",
      "Iteration 4835, loss = 0.00515926\n",
      "Iteration 4836, loss = 0.00515826\n",
      "Iteration 4837, loss = 0.00515649\n",
      "Iteration 4838, loss = 0.00515506\n",
      "Iteration 4839, loss = 0.00515354\n",
      "Iteration 4840, loss = 0.00515206\n",
      "Iteration 4841, loss = 0.00515090\n",
      "Iteration 4842, loss = 0.00514952\n",
      "Iteration 4843, loss = 0.00514825\n",
      "Iteration 4844, loss = 0.00514667\n",
      "Iteration 4845, loss = 0.00514541\n",
      "Iteration 4846, loss = 0.00514379\n",
      "Iteration 4847, loss = 0.00514232\n",
      "Iteration 4848, loss = 0.00514080\n",
      "Iteration 4849, loss = 0.00513951\n",
      "Iteration 4850, loss = 0.00513798\n",
      "Iteration 4851, loss = 0.00513661\n",
      "Iteration 4852, loss = 0.00513529\n",
      "Iteration 4853, loss = 0.00513384\n",
      "Iteration 4854, loss = 0.00513252\n",
      "Iteration 4855, loss = 0.00513133\n",
      "Iteration 4856, loss = 0.00512983\n",
      "Iteration 4857, loss = 0.00512838\n",
      "Iteration 4858, loss = 0.00512699\n",
      "Iteration 4859, loss = 0.00512576\n",
      "Iteration 4860, loss = 0.00512452\n",
      "Iteration 4861, loss = 0.00512257\n",
      "Iteration 4862, loss = 0.00512134\n",
      "Iteration 4863, loss = 0.00511974\n",
      "Iteration 4864, loss = 0.00511840\n",
      "Iteration 4865, loss = 0.00511681\n",
      "Iteration 4866, loss = 0.00511524\n",
      "Iteration 4867, loss = 0.00511382\n",
      "Iteration 4868, loss = 0.00511238\n",
      "Iteration 4869, loss = 0.00511115\n",
      "Iteration 4870, loss = 0.00510944\n",
      "Iteration 4871, loss = 0.00510801\n",
      "Iteration 4872, loss = 0.00510676\n",
      "Iteration 4873, loss = 0.00510512\n",
      "Iteration 4874, loss = 0.00510386\n",
      "Iteration 4875, loss = 0.00510233\n",
      "Iteration 4876, loss = 0.00510079\n",
      "Iteration 4877, loss = 0.00509987\n",
      "Iteration 4878, loss = 0.00509807\n",
      "Iteration 4879, loss = 0.00509659\n",
      "Iteration 4880, loss = 0.00509533\n",
      "Iteration 4881, loss = 0.00509372\n",
      "Iteration 4882, loss = 0.00509267\n",
      "Iteration 4883, loss = 0.00509114\n",
      "Iteration 4884, loss = 0.00508969\n",
      "Iteration 4885, loss = 0.00508835\n",
      "Iteration 4886, loss = 0.00508686\n",
      "Iteration 4887, loss = 0.00508552\n",
      "Iteration 4888, loss = 0.00508422\n",
      "Iteration 4889, loss = 0.00508294\n",
      "Iteration 4890, loss = 0.00508167\n",
      "Iteration 4891, loss = 0.00508017\n",
      "Iteration 4892, loss = 0.00507877\n",
      "Iteration 4893, loss = 0.00507780\n",
      "Iteration 4894, loss = 0.00507655\n",
      "Iteration 4895, loss = 0.00507499\n",
      "Iteration 4896, loss = 0.00507361\n",
      "Iteration 4897, loss = 0.00507219\n",
      "Iteration 4898, loss = 0.00507071\n",
      "Iteration 4899, loss = 0.00506936\n",
      "Iteration 4900, loss = 0.00506793\n",
      "Iteration 4901, loss = 0.00506643\n",
      "Iteration 4902, loss = 0.00506504\n",
      "Iteration 4903, loss = 0.00506336\n",
      "Iteration 4904, loss = 0.00506196\n",
      "Iteration 4905, loss = 0.00506054\n",
      "Iteration 4906, loss = 0.00505905\n",
      "Iteration 4907, loss = 0.00505757\n",
      "Iteration 4908, loss = 0.00505610\n",
      "Iteration 4909, loss = 0.00505472\n",
      "Iteration 4910, loss = 0.00505321\n",
      "Iteration 4911, loss = 0.00505173\n",
      "Iteration 4912, loss = 0.00505053\n",
      "Iteration 4913, loss = 0.00504889\n",
      "Iteration 4914, loss = 0.00504776\n",
      "Iteration 4915, loss = 0.00504643\n",
      "Iteration 4916, loss = 0.00504500\n",
      "Iteration 4917, loss = 0.00504367\n",
      "Iteration 4918, loss = 0.00504243\n",
      "Iteration 4919, loss = 0.00504087\n",
      "Iteration 4920, loss = 0.00503989\n",
      "Iteration 4921, loss = 0.00503813\n",
      "Iteration 4922, loss = 0.00503686\n",
      "Iteration 4923, loss = 0.00503548\n",
      "Iteration 4924, loss = 0.00503408\n",
      "Iteration 4925, loss = 0.00503283\n",
      "Iteration 4926, loss = 0.00503196\n",
      "Iteration 4927, loss = 0.00503030\n",
      "Iteration 4928, loss = 0.00502876\n",
      "Iteration 4929, loss = 0.00502739\n",
      "Iteration 4930, loss = 0.00502593\n",
      "Iteration 4931, loss = 0.00502427\n",
      "Iteration 4932, loss = 0.00502299\n",
      "Iteration 4933, loss = 0.00502146\n",
      "Iteration 4934, loss = 0.00502012\n",
      "Iteration 4935, loss = 0.00501893\n",
      "Iteration 4936, loss = 0.00501743\n",
      "Iteration 4937, loss = 0.00501616\n",
      "Iteration 4938, loss = 0.00501486\n",
      "Iteration 4939, loss = 0.00501357\n",
      "Iteration 4940, loss = 0.00501268\n",
      "Iteration 4941, loss = 0.00501084\n",
      "Iteration 4942, loss = 0.00500952\n",
      "Iteration 4943, loss = 0.00500816\n",
      "Iteration 4944, loss = 0.00500684\n",
      "Iteration 4945, loss = 0.00500536\n",
      "Iteration 4946, loss = 0.00500410\n",
      "Iteration 4947, loss = 0.00500243\n",
      "Iteration 4948, loss = 0.00500133\n",
      "Iteration 4949, loss = 0.00499972\n",
      "Iteration 4950, loss = 0.00499859\n",
      "Iteration 4951, loss = 0.00499708\n",
      "Iteration 4952, loss = 0.00499589\n",
      "Iteration 4953, loss = 0.00499450\n",
      "Iteration 4954, loss = 0.00499316\n",
      "Iteration 4955, loss = 0.00499198\n",
      "Iteration 4956, loss = 0.00499072\n",
      "Iteration 4957, loss = 0.00498963\n",
      "Iteration 4958, loss = 0.00498838\n",
      "Iteration 4959, loss = 0.00498708\n",
      "Iteration 4960, loss = 0.00498578\n",
      "Iteration 4961, loss = 0.00498459\n",
      "Iteration 4962, loss = 0.00498332\n",
      "Iteration 4963, loss = 0.00498223\n",
      "Iteration 4964, loss = 0.00498102\n",
      "Iteration 4965, loss = 0.00497965\n",
      "Iteration 4966, loss = 0.00497832\n",
      "Iteration 4967, loss = 0.00497717\n",
      "Iteration 4968, loss = 0.00497593\n",
      "Iteration 4969, loss = 0.00497496\n",
      "Iteration 4970, loss = 0.00497327\n",
      "Iteration 4971, loss = 0.00497193\n",
      "Iteration 4972, loss = 0.00497049\n",
      "Iteration 4973, loss = 0.00496911\n",
      "Iteration 4974, loss = 0.00496753\n",
      "Iteration 4975, loss = 0.00496630\n",
      "Iteration 4976, loss = 0.00496482\n",
      "Iteration 4977, loss = 0.00496350\n",
      "Iteration 4978, loss = 0.00496210\n",
      "Iteration 4979, loss = 0.00496065\n",
      "Iteration 4980, loss = 0.00495970\n",
      "Iteration 4981, loss = 0.00495806\n",
      "Iteration 4982, loss = 0.00495651\n",
      "Iteration 4983, loss = 0.00495491\n",
      "Iteration 4984, loss = 0.00495435\n",
      "Iteration 4985, loss = 0.00495236\n",
      "Iteration 4986, loss = 0.00495105\n",
      "Iteration 4987, loss = 0.00494956\n",
      "Iteration 4988, loss = 0.00494802\n",
      "Iteration 4989, loss = 0.00494659\n",
      "Iteration 4990, loss = 0.00494519\n",
      "Iteration 4991, loss = 0.00494380\n",
      "Iteration 4992, loss = 0.00494247\n",
      "Iteration 4993, loss = 0.00494082\n",
      "Iteration 4994, loss = 0.00493977\n",
      "Iteration 4995, loss = 0.00493807\n",
      "Iteration 4996, loss = 0.00493644\n",
      "Iteration 4997, loss = 0.00493521\n",
      "Iteration 4998, loss = 0.00493388\n",
      "Iteration 4999, loss = 0.00493204\n",
      "Iteration 5000, loss = 0.00493120\n",
      "Iteration 5001, loss = 0.00492922\n",
      "Iteration 5002, loss = 0.00492790\n",
      "Iteration 5003, loss = 0.00492645\n",
      "Iteration 5004, loss = 0.00492517\n",
      "Iteration 5005, loss = 0.00492381\n",
      "Iteration 5006, loss = 0.00492242\n",
      "Iteration 5007, loss = 0.00492111\n",
      "Iteration 5008, loss = 0.00491985\n",
      "Iteration 5009, loss = 0.00491881\n",
      "Iteration 5010, loss = 0.00491756\n",
      "Iteration 5011, loss = 0.00491584\n",
      "Iteration 5012, loss = 0.00491446\n",
      "Iteration 5013, loss = 0.00491327\n",
      "Iteration 5014, loss = 0.00491181\n",
      "Iteration 5015, loss = 0.00491021\n",
      "Iteration 5016, loss = 0.00490884\n",
      "Iteration 5017, loss = 0.00490751\n",
      "Iteration 5018, loss = 0.00490611\n",
      "Iteration 5019, loss = 0.00490528\n",
      "Iteration 5020, loss = 0.00490362\n",
      "Iteration 5021, loss = 0.00490207\n",
      "Iteration 5022, loss = 0.00490072\n",
      "Iteration 5023, loss = 0.00489962\n",
      "Iteration 5024, loss = 0.00489802\n",
      "Iteration 5025, loss = 0.00489691\n",
      "Iteration 5026, loss = 0.00489547\n",
      "Iteration 5027, loss = 0.00489469\n",
      "Iteration 5028, loss = 0.00489280\n",
      "Iteration 5029, loss = 0.00489179\n",
      "Iteration 5030, loss = 0.00489015\n",
      "Iteration 5031, loss = 0.00488873\n",
      "Iteration 5032, loss = 0.00488738\n",
      "Iteration 5033, loss = 0.00488615\n",
      "Iteration 5034, loss = 0.00488470\n",
      "Iteration 5035, loss = 0.00488338\n",
      "Iteration 5036, loss = 0.00488196\n",
      "Iteration 5037, loss = 0.00488076\n",
      "Iteration 5038, loss = 0.00487948\n",
      "Iteration 5039, loss = 0.00487856\n",
      "Iteration 5040, loss = 0.00487683\n",
      "Iteration 5041, loss = 0.00487566\n",
      "Iteration 5042, loss = 0.00487427\n",
      "Iteration 5043, loss = 0.00487291\n",
      "Iteration 5044, loss = 0.00487166\n",
      "Iteration 5045, loss = 0.00487055\n",
      "Iteration 5046, loss = 0.00486917\n",
      "Iteration 5047, loss = 0.00486777\n",
      "Iteration 5048, loss = 0.00486652\n",
      "Iteration 5049, loss = 0.00486512\n",
      "Iteration 5050, loss = 0.00486382\n",
      "Iteration 5051, loss = 0.00486260\n",
      "Iteration 5052, loss = 0.00486109\n",
      "Iteration 5053, loss = 0.00486013\n",
      "Iteration 5054, loss = 0.00485861\n",
      "Iteration 5055, loss = 0.00485734\n",
      "Iteration 5056, loss = 0.00485650\n",
      "Iteration 5057, loss = 0.00485509\n",
      "Iteration 5058, loss = 0.00485371\n",
      "Iteration 5059, loss = 0.00485220\n",
      "Iteration 5060, loss = 0.00485090\n",
      "Iteration 5061, loss = 0.00484960\n",
      "Iteration 5062, loss = 0.00484848\n",
      "Iteration 5063, loss = 0.00484715\n",
      "Iteration 5064, loss = 0.00484609\n",
      "Iteration 5065, loss = 0.00484474\n",
      "Iteration 5066, loss = 0.00484319\n",
      "Iteration 5067, loss = 0.00484193\n",
      "Iteration 5068, loss = 0.00484064\n",
      "Iteration 5069, loss = 0.00483922\n",
      "Iteration 5070, loss = 0.00483786\n",
      "Iteration 5071, loss = 0.00483672\n",
      "Iteration 5072, loss = 0.00483568\n",
      "Iteration 5073, loss = 0.00483443\n",
      "Iteration 5074, loss = 0.00483281\n",
      "Iteration 5075, loss = 0.00483167\n",
      "Iteration 5076, loss = 0.00483033\n",
      "Iteration 5077, loss = 0.00482921\n",
      "Iteration 5078, loss = 0.00482784\n",
      "Iteration 5079, loss = 0.00482655\n",
      "Iteration 5080, loss = 0.00482526\n",
      "Iteration 5081, loss = 0.00482416\n",
      "Iteration 5082, loss = 0.00482307\n",
      "Iteration 5083, loss = 0.00482152\n",
      "Iteration 5084, loss = 0.00482031\n",
      "Iteration 5085, loss = 0.00481916\n",
      "Iteration 5086, loss = 0.00481743\n",
      "Iteration 5087, loss = 0.00481664\n",
      "Iteration 5088, loss = 0.00481535\n",
      "Iteration 5089, loss = 0.00481404\n",
      "Iteration 5090, loss = 0.00481274\n",
      "Iteration 5091, loss = 0.00481163\n",
      "Iteration 5092, loss = 0.00481033\n",
      "Iteration 5093, loss = 0.00480921\n",
      "Iteration 5094, loss = 0.00480792\n",
      "Iteration 5095, loss = 0.00480690\n",
      "Iteration 5096, loss = 0.00480561\n",
      "Iteration 5097, loss = 0.00480425\n",
      "Iteration 5098, loss = 0.00480317\n",
      "Iteration 5099, loss = 0.00480163\n",
      "Iteration 5100, loss = 0.00480048\n",
      "Iteration 5101, loss = 0.00479923\n",
      "Iteration 5102, loss = 0.00479771\n",
      "Iteration 5103, loss = 0.00479638\n",
      "Iteration 5104, loss = 0.00479502\n",
      "Iteration 5105, loss = 0.00479362\n",
      "Iteration 5106, loss = 0.00479224\n",
      "Iteration 5107, loss = 0.00479147\n",
      "Iteration 5108, loss = 0.00478979\n",
      "Iteration 5109, loss = 0.00478956\n",
      "Iteration 5110, loss = 0.00478756\n",
      "Iteration 5111, loss = 0.00478590\n",
      "Iteration 5112, loss = 0.00478460\n",
      "Iteration 5113, loss = 0.00478320\n",
      "Iteration 5114, loss = 0.00478180\n",
      "Iteration 5115, loss = 0.00478037\n",
      "Iteration 5116, loss = 0.00477900\n",
      "Iteration 5117, loss = 0.00477800\n",
      "Iteration 5118, loss = 0.00477730\n",
      "Iteration 5119, loss = 0.00477557\n",
      "Iteration 5120, loss = 0.00477419\n",
      "Iteration 5121, loss = 0.00477290\n",
      "Iteration 5122, loss = 0.00477179\n",
      "Iteration 5123, loss = 0.00477055\n",
      "Iteration 5124, loss = 0.00476900\n",
      "Iteration 5125, loss = 0.00476793\n",
      "Iteration 5126, loss = 0.00476650\n",
      "Iteration 5127, loss = 0.00476543\n",
      "Iteration 5128, loss = 0.00476427\n",
      "Iteration 5129, loss = 0.00476296\n",
      "Iteration 5130, loss = 0.00476178\n",
      "Iteration 5131, loss = 0.00476048\n",
      "Iteration 5132, loss = 0.00475944\n",
      "Iteration 5133, loss = 0.00475883\n",
      "Iteration 5134, loss = 0.00475711\n",
      "Iteration 5135, loss = 0.00475581\n",
      "Iteration 5136, loss = 0.00475439\n",
      "Iteration 5137, loss = 0.00475321\n",
      "Iteration 5138, loss = 0.00475190\n",
      "Iteration 5139, loss = 0.00475061\n",
      "Iteration 5140, loss = 0.00474923\n",
      "Iteration 5141, loss = 0.00474824\n",
      "Iteration 5142, loss = 0.00474685\n",
      "Iteration 5143, loss = 0.00474580\n",
      "Iteration 5144, loss = 0.00474404\n",
      "Iteration 5145, loss = 0.00474279\n",
      "Iteration 5146, loss = 0.00474152\n",
      "Iteration 5147, loss = 0.00474062\n",
      "Iteration 5148, loss = 0.00473904\n",
      "Iteration 5149, loss = 0.00473771\n",
      "Iteration 5150, loss = 0.00473641\n",
      "Iteration 5151, loss = 0.00473521\n",
      "Iteration 5152, loss = 0.00473392\n",
      "Iteration 5153, loss = 0.00473261\n",
      "Iteration 5154, loss = 0.00473116\n",
      "Iteration 5155, loss = 0.00473010\n",
      "Iteration 5156, loss = 0.00472844\n",
      "Iteration 5157, loss = 0.00472742\n",
      "Iteration 5158, loss = 0.00472621\n",
      "Iteration 5159, loss = 0.00472546\n",
      "Iteration 5160, loss = 0.00472363\n",
      "Iteration 5161, loss = 0.00472241\n",
      "Iteration 5162, loss = 0.00472103\n",
      "Iteration 5163, loss = 0.00471966\n",
      "Iteration 5164, loss = 0.00471840\n",
      "Iteration 5165, loss = 0.00471719\n",
      "Iteration 5166, loss = 0.00471603\n",
      "Iteration 5167, loss = 0.00471473\n",
      "Iteration 5168, loss = 0.00471358\n",
      "Iteration 5169, loss = 0.00471243\n",
      "Iteration 5170, loss = 0.00471130\n",
      "Iteration 5171, loss = 0.00470978\n",
      "Iteration 5172, loss = 0.00470902\n",
      "Iteration 5173, loss = 0.00470786\n",
      "Iteration 5174, loss = 0.00470671\n",
      "Iteration 5175, loss = 0.00470545\n",
      "Iteration 5176, loss = 0.00470444\n",
      "Iteration 5177, loss = 0.00470318\n",
      "Iteration 5178, loss = 0.00470197\n",
      "Iteration 5179, loss = 0.00470094\n",
      "Iteration 5180, loss = 0.00469990\n",
      "Iteration 5181, loss = 0.00469844\n",
      "Iteration 5182, loss = 0.00469723\n",
      "Iteration 5183, loss = 0.00469613\n",
      "Iteration 5184, loss = 0.00469498\n",
      "Iteration 5185, loss = 0.00469355\n",
      "Iteration 5186, loss = 0.00469237\n",
      "Iteration 5187, loss = 0.00469105\n",
      "Iteration 5188, loss = 0.00468987\n",
      "Iteration 5189, loss = 0.00468874\n",
      "Iteration 5190, loss = 0.00468761\n",
      "Iteration 5191, loss = 0.00468621\n",
      "Iteration 5192, loss = 0.00468506\n",
      "Iteration 5193, loss = 0.00468399\n",
      "Iteration 5194, loss = 0.00468252\n",
      "Iteration 5195, loss = 0.00468164\n",
      "Iteration 5196, loss = 0.00468039\n",
      "Iteration 5197, loss = 0.00467931\n",
      "Iteration 5198, loss = 0.00467770\n",
      "Iteration 5199, loss = 0.00467654\n",
      "Iteration 5200, loss = 0.00467542\n",
      "Iteration 5201, loss = 0.00467376\n",
      "Iteration 5202, loss = 0.00467290\n",
      "Iteration 5203, loss = 0.00467120\n",
      "Iteration 5204, loss = 0.00467007\n",
      "Iteration 5205, loss = 0.00466914\n",
      "Iteration 5206, loss = 0.00466729\n",
      "Iteration 5207, loss = 0.00466616\n",
      "Iteration 5208, loss = 0.00466460\n",
      "Iteration 5209, loss = 0.00466341\n",
      "Iteration 5210, loss = 0.00466201\n",
      "Iteration 5211, loss = 0.00466066\n",
      "Iteration 5212, loss = 0.00465950\n",
      "Iteration 5213, loss = 0.00465827\n",
      "Iteration 5214, loss = 0.00465701\n",
      "Iteration 5215, loss = 0.00465589\n",
      "Iteration 5216, loss = 0.00465471\n",
      "Iteration 5217, loss = 0.00465364\n",
      "Iteration 5218, loss = 0.00465271\n",
      "Iteration 5219, loss = 0.00465169\n",
      "Iteration 5220, loss = 0.00465037\n",
      "Iteration 5221, loss = 0.00464929\n",
      "Iteration 5222, loss = 0.00464884\n",
      "Iteration 5223, loss = 0.00464686\n",
      "Iteration 5224, loss = 0.00464586\n",
      "Iteration 5225, loss = 0.00464469\n",
      "Iteration 5226, loss = 0.00464348\n",
      "Iteration 5227, loss = 0.00464260\n",
      "Iteration 5228, loss = 0.00464162\n",
      "Iteration 5229, loss = 0.00464027\n",
      "Iteration 5230, loss = 0.00463906\n",
      "Iteration 5231, loss = 0.00463810\n",
      "Iteration 5232, loss = 0.00463701\n",
      "Iteration 5233, loss = 0.00463578\n",
      "Iteration 5234, loss = 0.00463478\n",
      "Iteration 5235, loss = 0.00463360\n",
      "Iteration 5236, loss = 0.00463171\n",
      "Iteration 5237, loss = 0.00463054\n",
      "Iteration 5238, loss = 0.00462952\n",
      "Iteration 5239, loss = 0.00462833\n",
      "Iteration 5240, loss = 0.00462703\n",
      "Iteration 5241, loss = 0.00462640\n",
      "Iteration 5242, loss = 0.00462534\n",
      "Iteration 5243, loss = 0.00462390\n",
      "Iteration 5244, loss = 0.00462276\n",
      "Iteration 5245, loss = 0.00462192\n",
      "Iteration 5246, loss = 0.00462065\n",
      "Iteration 5247, loss = 0.00461973\n",
      "Iteration 5248, loss = 0.00461932\n",
      "Iteration 5249, loss = 0.00461756\n",
      "Iteration 5250, loss = 0.00461642\n",
      "Iteration 5251, loss = 0.00461552\n",
      "Iteration 5252, loss = 0.00461412\n",
      "Iteration 5253, loss = 0.00461325\n",
      "Iteration 5254, loss = 0.00461213\n",
      "Iteration 5255, loss = 0.00461098\n",
      "Iteration 5256, loss = 0.00460996\n",
      "Iteration 5257, loss = 0.00460875\n",
      "Iteration 5258, loss = 0.00460759\n",
      "Iteration 5259, loss = 0.00460634\n",
      "Iteration 5260, loss = 0.00460514\n",
      "Iteration 5261, loss = 0.00460359\n",
      "Iteration 5262, loss = 0.00460237\n",
      "Iteration 5263, loss = 0.00460132\n",
      "Iteration 5264, loss = 0.00460005\n",
      "Iteration 5265, loss = 0.00459888\n",
      "Iteration 5266, loss = 0.00459763\n",
      "Iteration 5267, loss = 0.00459651\n",
      "Iteration 5268, loss = 0.00459526\n",
      "Iteration 5269, loss = 0.00459404\n",
      "Iteration 5270, loss = 0.00459327\n",
      "Iteration 5271, loss = 0.00459203\n",
      "Iteration 5272, loss = 0.00459061\n",
      "Iteration 5273, loss = 0.00458932\n",
      "Iteration 5274, loss = 0.00458816\n",
      "Iteration 5275, loss = 0.00458714\n",
      "Iteration 5276, loss = 0.00458628\n",
      "Iteration 5277, loss = 0.00458510\n",
      "Iteration 5278, loss = 0.00458396\n",
      "Iteration 5279, loss = 0.00458270\n",
      "Iteration 5280, loss = 0.00458160\n",
      "Iteration 5281, loss = 0.00458037\n",
      "Iteration 5282, loss = 0.00457913\n",
      "Iteration 5283, loss = 0.00457807\n",
      "Iteration 5284, loss = 0.00457688\n",
      "Iteration 5285, loss = 0.00457578\n",
      "Iteration 5286, loss = 0.00457474\n",
      "Iteration 5287, loss = 0.00457402\n",
      "Iteration 5288, loss = 0.00457286\n",
      "Iteration 5289, loss = 0.00457147\n",
      "Iteration 5290, loss = 0.00457023\n",
      "Iteration 5291, loss = 0.00456923\n",
      "Iteration 5292, loss = 0.00456797\n",
      "Iteration 5293, loss = 0.00456685\n",
      "Iteration 5294, loss = 0.00456577\n",
      "Iteration 5295, loss = 0.00456467\n",
      "Iteration 5296, loss = 0.00456355\n",
      "Iteration 5297, loss = 0.00456216\n",
      "Iteration 5298, loss = 0.00456138\n",
      "Iteration 5299, loss = 0.00456002\n",
      "Iteration 5300, loss = 0.00455935\n",
      "Iteration 5301, loss = 0.00455849\n",
      "Iteration 5302, loss = 0.00455695\n",
      "Iteration 5303, loss = 0.00455578\n",
      "Iteration 5304, loss = 0.00455462\n",
      "Iteration 5305, loss = 0.00455396\n",
      "Iteration 5306, loss = 0.00455268\n",
      "Iteration 5307, loss = 0.00455135\n",
      "Iteration 5308, loss = 0.00454990\n",
      "Iteration 5309, loss = 0.00454893\n",
      "Iteration 5310, loss = 0.00454775\n",
      "Iteration 5311, loss = 0.00454634\n",
      "Iteration 5312, loss = 0.00454501\n",
      "Iteration 5313, loss = 0.00454374\n",
      "Iteration 5314, loss = 0.00454278\n",
      "Iteration 5315, loss = 0.00454145\n",
      "Iteration 5316, loss = 0.00454029\n",
      "Iteration 5317, loss = 0.00453941\n",
      "Iteration 5318, loss = 0.00453919\n",
      "Iteration 5319, loss = 0.00453710\n",
      "Iteration 5320, loss = 0.00453596\n",
      "Iteration 5321, loss = 0.00453491\n",
      "Iteration 5322, loss = 0.00453393\n",
      "Iteration 5323, loss = 0.00453275\n",
      "Iteration 5324, loss = 0.00453197\n",
      "Iteration 5325, loss = 0.00453079\n",
      "Iteration 5326, loss = 0.00453031\n",
      "Iteration 5327, loss = 0.00452848\n",
      "Iteration 5328, loss = 0.00452784\n",
      "Iteration 5329, loss = 0.00452620\n",
      "Iteration 5330, loss = 0.00452524\n",
      "Iteration 5331, loss = 0.00452419\n",
      "Iteration 5332, loss = 0.00452305\n",
      "Iteration 5333, loss = 0.00452194\n",
      "Iteration 5334, loss = 0.00452076\n",
      "Iteration 5335, loss = 0.00451974\n",
      "Iteration 5336, loss = 0.00451881\n",
      "Iteration 5337, loss = 0.00451732\n",
      "Iteration 5338, loss = 0.00451601\n",
      "Iteration 5339, loss = 0.00451514\n",
      "Iteration 5340, loss = 0.00451366\n",
      "Iteration 5341, loss = 0.00451254\n",
      "Iteration 5342, loss = 0.00451147\n",
      "Iteration 5343, loss = 0.00451039\n",
      "Iteration 5344, loss = 0.00450921\n",
      "Iteration 5345, loss = 0.00450822\n",
      "Iteration 5346, loss = 0.00450686\n",
      "Iteration 5347, loss = 0.00450594\n",
      "Iteration 5348, loss = 0.00450464\n",
      "Iteration 5349, loss = 0.00450368\n",
      "Iteration 5350, loss = 0.00450286\n",
      "Iteration 5351, loss = 0.00450137\n",
      "Iteration 5352, loss = 0.00450040\n",
      "Iteration 5353, loss = 0.00449904\n",
      "Iteration 5354, loss = 0.00449792\n",
      "Iteration 5355, loss = 0.00449710\n",
      "Iteration 5356, loss = 0.00449550\n",
      "Iteration 5357, loss = 0.00449461\n",
      "Iteration 5358, loss = 0.00449303\n",
      "Iteration 5359, loss = 0.00449187\n",
      "Iteration 5360, loss = 0.00449071\n",
      "Iteration 5361, loss = 0.00448992\n",
      "Iteration 5362, loss = 0.00448853\n",
      "Iteration 5363, loss = 0.00448759\n",
      "Iteration 5364, loss = 0.00448633\n",
      "Iteration 5365, loss = 0.00448509\n",
      "Iteration 5366, loss = 0.00448389\n",
      "Iteration 5367, loss = 0.00448281\n",
      "Iteration 5368, loss = 0.00448172\n",
      "Iteration 5369, loss = 0.00448073\n",
      "Iteration 5370, loss = 0.00447946\n",
      "Iteration 5371, loss = 0.00447859\n",
      "Iteration 5372, loss = 0.00447717\n",
      "Iteration 5373, loss = 0.00447594\n",
      "Iteration 5374, loss = 0.00447545\n",
      "Iteration 5375, loss = 0.00447395\n",
      "Iteration 5376, loss = 0.00447293\n",
      "Iteration 5377, loss = 0.00447148\n",
      "Iteration 5378, loss = 0.00447040\n",
      "Iteration 5379, loss = 0.00446916\n",
      "Iteration 5380, loss = 0.00446827\n",
      "Iteration 5381, loss = 0.00446696\n",
      "Iteration 5382, loss = 0.00446544\n",
      "Iteration 5383, loss = 0.00446436\n",
      "Iteration 5384, loss = 0.00446321\n",
      "Iteration 5385, loss = 0.00446209\n",
      "Iteration 5386, loss = 0.00446081\n",
      "Iteration 5387, loss = 0.00445982\n",
      "Iteration 5388, loss = 0.00445851\n",
      "Iteration 5389, loss = 0.00445715\n",
      "Iteration 5390, loss = 0.00445588\n",
      "Iteration 5391, loss = 0.00445479\n",
      "Iteration 5392, loss = 0.00445358\n",
      "Iteration 5393, loss = 0.00445242\n",
      "Iteration 5394, loss = 0.00445129\n",
      "Iteration 5395, loss = 0.00445008\n",
      "Iteration 5396, loss = 0.00444933\n",
      "Iteration 5397, loss = 0.00444806\n",
      "Iteration 5398, loss = 0.00444708\n",
      "Iteration 5399, loss = 0.00444605\n",
      "Iteration 5400, loss = 0.00444499\n",
      "Iteration 5401, loss = 0.00444400\n",
      "Iteration 5402, loss = 0.00444292\n",
      "Iteration 5403, loss = 0.00444171\n",
      "Iteration 5404, loss = 0.00444108\n",
      "Iteration 5405, loss = 0.00443968\n",
      "Iteration 5406, loss = 0.00443849\n",
      "Iteration 5407, loss = 0.00443750\n",
      "Iteration 5408, loss = 0.00443640\n",
      "Iteration 5409, loss = 0.00443538\n",
      "Iteration 5410, loss = 0.00443457\n",
      "Iteration 5411, loss = 0.00443325\n",
      "Iteration 5412, loss = 0.00443225\n",
      "Iteration 5413, loss = 0.00443145\n",
      "Iteration 5414, loss = 0.00442994\n",
      "Iteration 5415, loss = 0.00442883\n",
      "Iteration 5416, loss = 0.00442759\n",
      "Iteration 5417, loss = 0.00442805\n",
      "Iteration 5418, loss = 0.00442575\n",
      "Iteration 5419, loss = 0.00442484\n",
      "Iteration 5420, loss = 0.00442359\n",
      "Iteration 5421, loss = 0.00442252\n",
      "Iteration 5422, loss = 0.00442145\n",
      "Iteration 5423, loss = 0.00442048\n",
      "Iteration 5424, loss = 0.00441967\n",
      "Iteration 5425, loss = 0.00441801\n",
      "Iteration 5426, loss = 0.00441682\n",
      "Iteration 5427, loss = 0.00441595\n",
      "Iteration 5428, loss = 0.00441488\n",
      "Iteration 5429, loss = 0.00441371\n",
      "Iteration 5430, loss = 0.00441276\n",
      "Iteration 5431, loss = 0.00441156\n",
      "Iteration 5432, loss = 0.00441073\n",
      "Iteration 5433, loss = 0.00440988\n",
      "Iteration 5434, loss = 0.00440864\n",
      "Iteration 5435, loss = 0.00440784\n",
      "Iteration 5436, loss = 0.00440723\n",
      "Iteration 5437, loss = 0.00440593\n",
      "Iteration 5438, loss = 0.00440506\n",
      "Iteration 5439, loss = 0.00440405\n",
      "Iteration 5440, loss = 0.00440292\n",
      "Iteration 5441, loss = 0.00440241\n",
      "Iteration 5442, loss = 0.00440095\n",
      "Iteration 5443, loss = 0.00440012\n",
      "Iteration 5444, loss = 0.00439915\n",
      "Iteration 5445, loss = 0.00439799\n",
      "Iteration 5446, loss = 0.00439669\n",
      "Iteration 5447, loss = 0.00439565\n",
      "Iteration 5448, loss = 0.00439455\n",
      "Iteration 5449, loss = 0.00439347\n",
      "Iteration 5450, loss = 0.00439240\n",
      "Iteration 5451, loss = 0.00439136\n",
      "Iteration 5452, loss = 0.00439026\n",
      "Iteration 5453, loss = 0.00438892\n",
      "Iteration 5454, loss = 0.00438887\n",
      "Iteration 5455, loss = 0.00438708\n",
      "Iteration 5456, loss = 0.00438594\n",
      "Iteration 5457, loss = 0.00438489\n",
      "Iteration 5458, loss = 0.00438388\n",
      "Iteration 5459, loss = 0.00438284\n",
      "Iteration 5460, loss = 0.00438179\n",
      "Iteration 5461, loss = 0.00438075\n",
      "Iteration 5462, loss = 0.00437986\n",
      "Iteration 5463, loss = 0.00437932\n",
      "Iteration 5464, loss = 0.00437804\n",
      "Iteration 5465, loss = 0.00437693\n",
      "Iteration 5466, loss = 0.00437597\n",
      "Iteration 5467, loss = 0.00437498\n",
      "Iteration 5468, loss = 0.00437408\n",
      "Iteration 5469, loss = 0.00437310\n",
      "Iteration 5470, loss = 0.00437213\n",
      "Iteration 5471, loss = 0.00437119\n",
      "Iteration 5472, loss = 0.00437021\n",
      "Iteration 5473, loss = 0.00436913\n",
      "Iteration 5474, loss = 0.00436807\n",
      "Iteration 5475, loss = 0.00436750\n",
      "Iteration 5476, loss = 0.00436637\n",
      "Iteration 5477, loss = 0.00436582\n",
      "Iteration 5478, loss = 0.00436453\n",
      "Iteration 5479, loss = 0.00436374\n",
      "Iteration 5480, loss = 0.00436249\n",
      "Iteration 5481, loss = 0.00436157\n",
      "Iteration 5482, loss = 0.00436087\n",
      "Iteration 5483, loss = 0.00435961\n",
      "Iteration 5484, loss = 0.00435865\n",
      "Iteration 5485, loss = 0.00435757\n",
      "Iteration 5486, loss = 0.00435668\n",
      "Iteration 5487, loss = 0.00435560\n",
      "Iteration 5488, loss = 0.00435577\n",
      "Iteration 5489, loss = 0.00435421\n",
      "Iteration 5490, loss = 0.00435265\n",
      "Iteration 5491, loss = 0.00435162\n",
      "Iteration 5492, loss = 0.00435059\n",
      "Iteration 5493, loss = 0.00434951\n",
      "Iteration 5494, loss = 0.00434843\n",
      "Iteration 5495, loss = 0.00434737\n",
      "Iteration 5496, loss = 0.00434626\n",
      "Iteration 5497, loss = 0.00434531\n",
      "Iteration 5498, loss = 0.00434443\n",
      "Iteration 5499, loss = 0.00434312\n",
      "Iteration 5500, loss = 0.00434197\n",
      "Iteration 5501, loss = 0.00434094\n",
      "Iteration 5502, loss = 0.00433968\n",
      "Iteration 5503, loss = 0.00433853\n",
      "Iteration 5504, loss = 0.00433752\n",
      "Iteration 5505, loss = 0.00433627\n",
      "Iteration 5506, loss = 0.00433537\n",
      "Iteration 5507, loss = 0.00433424\n",
      "Iteration 5508, loss = 0.00433308\n",
      "Iteration 5509, loss = 0.00433186\n",
      "Iteration 5510, loss = 0.00433081\n",
      "Iteration 5511, loss = 0.00432985\n",
      "Iteration 5512, loss = 0.00432857\n",
      "Iteration 5513, loss = 0.00432773\n",
      "Iteration 5514, loss = 0.00432649\n",
      "Iteration 5515, loss = 0.00432560\n",
      "Iteration 5516, loss = 0.00432453\n",
      "Iteration 5517, loss = 0.00432347\n",
      "Iteration 5518, loss = 0.00432260\n",
      "Iteration 5519, loss = 0.00432152\n",
      "Iteration 5520, loss = 0.00432073\n",
      "Iteration 5521, loss = 0.00431939\n",
      "Iteration 5522, loss = 0.00431824\n",
      "Iteration 5523, loss = 0.00431712\n",
      "Iteration 5524, loss = 0.00431620\n",
      "Iteration 5525, loss = 0.00431521\n",
      "Iteration 5526, loss = 0.00431403\n",
      "Iteration 5527, loss = 0.00431307\n",
      "Iteration 5528, loss = 0.00431218\n",
      "Iteration 5529, loss = 0.00431118\n",
      "Iteration 5530, loss = 0.00431026\n",
      "Iteration 5531, loss = 0.00430909\n",
      "Iteration 5532, loss = 0.00430797\n",
      "Iteration 5533, loss = 0.00430676\n",
      "Iteration 5534, loss = 0.00430578\n",
      "Iteration 5535, loss = 0.00430471\n",
      "Iteration 5536, loss = 0.00430370\n",
      "Iteration 5537, loss = 0.00430267\n",
      "Iteration 5538, loss = 0.00430150\n",
      "Iteration 5539, loss = 0.00430103\n",
      "Iteration 5540, loss = 0.00429962\n",
      "Iteration 5541, loss = 0.00429863\n",
      "Iteration 5542, loss = 0.00429763\n",
      "Iteration 5543, loss = 0.00429679\n",
      "Iteration 5544, loss = 0.00429590\n",
      "Iteration 5545, loss = 0.00429468\n",
      "Iteration 5546, loss = 0.00429399\n",
      "Iteration 5547, loss = 0.00429280\n",
      "Iteration 5548, loss = 0.00429174\n",
      "Iteration 5549, loss = 0.00429075\n",
      "Iteration 5550, loss = 0.00428965\n",
      "Iteration 5551, loss = 0.00428876\n",
      "Iteration 5552, loss = 0.00428756\n",
      "Iteration 5553, loss = 0.00428697\n",
      "Iteration 5554, loss = 0.00428542\n",
      "Iteration 5555, loss = 0.00428440\n",
      "Iteration 5556, loss = 0.00428322\n",
      "Iteration 5557, loss = 0.00428220\n",
      "Iteration 5558, loss = 0.00428123\n",
      "Iteration 5559, loss = 0.00428007\n",
      "Iteration 5560, loss = 0.00427930\n",
      "Iteration 5561, loss = 0.00427808\n",
      "Iteration 5562, loss = 0.00427712\n",
      "Iteration 5563, loss = 0.00427612\n",
      "Iteration 5564, loss = 0.00427504\n",
      "Iteration 5565, loss = 0.00427414\n",
      "Iteration 5566, loss = 0.00427327\n",
      "Iteration 5567, loss = 0.00427214\n",
      "Iteration 5568, loss = 0.00427111\n",
      "Iteration 5569, loss = 0.00427015\n",
      "Iteration 5570, loss = 0.00426925\n",
      "Iteration 5571, loss = 0.00426800\n",
      "Iteration 5572, loss = 0.00426682\n",
      "Iteration 5573, loss = 0.00426593\n",
      "Iteration 5574, loss = 0.00426456\n",
      "Iteration 5575, loss = 0.00426371\n",
      "Iteration 5576, loss = 0.00426285\n",
      "Iteration 5577, loss = 0.00426159\n",
      "Iteration 5578, loss = 0.00426082\n",
      "Iteration 5579, loss = 0.00426034\n",
      "Iteration 5580, loss = 0.00425898\n",
      "Iteration 5581, loss = 0.00425811\n",
      "Iteration 5582, loss = 0.00425723\n",
      "Iteration 5583, loss = 0.00425624\n",
      "Iteration 5584, loss = 0.00425535\n",
      "Iteration 5585, loss = 0.00425434\n",
      "Iteration 5586, loss = 0.00425340\n",
      "Iteration 5587, loss = 0.00425257\n",
      "Iteration 5588, loss = 0.00425188\n",
      "Iteration 5589, loss = 0.00425062\n",
      "Iteration 5590, loss = 0.00424965\n",
      "Iteration 5591, loss = 0.00424883\n",
      "Iteration 5592, loss = 0.00424798\n",
      "Iteration 5593, loss = 0.00424673\n",
      "Iteration 5594, loss = 0.00424566\n",
      "Iteration 5595, loss = 0.00424452\n",
      "Iteration 5596, loss = 0.00424354\n",
      "Iteration 5597, loss = 0.00424257\n",
      "Iteration 5598, loss = 0.00424140\n",
      "Iteration 5599, loss = 0.00424051\n",
      "Iteration 5600, loss = 0.00423959\n",
      "Iteration 5601, loss = 0.00423851\n",
      "Iteration 5602, loss = 0.00423760\n",
      "Iteration 5603, loss = 0.00423622\n",
      "Iteration 5604, loss = 0.00423578\n",
      "Iteration 5605, loss = 0.00423411\n",
      "Iteration 5606, loss = 0.00423297\n",
      "Iteration 5607, loss = 0.00423206\n",
      "Iteration 5608, loss = 0.00423108\n",
      "Iteration 5609, loss = 0.00423013\n",
      "Iteration 5610, loss = 0.00422893\n",
      "Iteration 5611, loss = 0.00422786\n",
      "Iteration 5612, loss = 0.00422713\n",
      "Iteration 5613, loss = 0.00422578\n",
      "Iteration 5614, loss = 0.00422483\n",
      "Iteration 5615, loss = 0.00422394\n",
      "Iteration 5616, loss = 0.00422283\n",
      "Iteration 5617, loss = 0.00422195\n",
      "Iteration 5618, loss = 0.00422076\n",
      "Iteration 5619, loss = 0.00421963\n",
      "Iteration 5620, loss = 0.00421866\n",
      "Iteration 5621, loss = 0.00421744\n",
      "Iteration 5622, loss = 0.00421640\n",
      "Iteration 5623, loss = 0.00421543\n",
      "Iteration 5624, loss = 0.00421434\n",
      "Iteration 5625, loss = 0.00421319\n",
      "Iteration 5626, loss = 0.00421223\n",
      "Iteration 5627, loss = 0.00421122\n",
      "Iteration 5628, loss = 0.00421004\n",
      "Iteration 5629, loss = 0.00420916\n",
      "Iteration 5630, loss = 0.00420808\n",
      "Iteration 5631, loss = 0.00420746\n",
      "Iteration 5632, loss = 0.00420598\n",
      "Iteration 5633, loss = 0.00420470\n",
      "Iteration 5634, loss = 0.00420402\n",
      "Iteration 5635, loss = 0.00420300\n",
      "Iteration 5636, loss = 0.00420200\n",
      "Iteration 5637, loss = 0.00420085\n",
      "Iteration 5638, loss = 0.00420058\n",
      "Iteration 5639, loss = 0.00419919\n",
      "Iteration 5640, loss = 0.00419822\n",
      "Iteration 5641, loss = 0.00419708\n",
      "Iteration 5642, loss = 0.00419604\n",
      "Iteration 5643, loss = 0.00419505\n",
      "Iteration 5644, loss = 0.00419405\n",
      "Iteration 5645, loss = 0.00419293\n",
      "Iteration 5646, loss = 0.00419232\n",
      "Iteration 5647, loss = 0.00419097\n",
      "Iteration 5648, loss = 0.00418984\n",
      "Iteration 5649, loss = 0.00418894\n",
      "Iteration 5650, loss = 0.00418812\n",
      "Iteration 5651, loss = 0.00418695\n",
      "Iteration 5652, loss = 0.00418588\n",
      "Iteration 5653, loss = 0.00418495\n",
      "Iteration 5654, loss = 0.00418389\n",
      "Iteration 5655, loss = 0.00418290\n",
      "Iteration 5656, loss = 0.00418198\n",
      "Iteration 5657, loss = 0.00418095\n",
      "Iteration 5658, loss = 0.00418007\n",
      "Iteration 5659, loss = 0.00417925\n",
      "Iteration 5660, loss = 0.00417810\n",
      "Iteration 5661, loss = 0.00417712\n",
      "Iteration 5662, loss = 0.00417638\n",
      "Iteration 5663, loss = 0.00417531\n",
      "Iteration 5664, loss = 0.00417447\n",
      "Iteration 5665, loss = 0.00417344\n",
      "Iteration 5666, loss = 0.00417231\n",
      "Iteration 5667, loss = 0.00417120\n",
      "Iteration 5668, loss = 0.00417076\n",
      "Iteration 5669, loss = 0.00416949\n",
      "Iteration 5670, loss = 0.00416839\n",
      "Iteration 5671, loss = 0.00416762\n",
      "Iteration 5672, loss = 0.00416694\n",
      "Iteration 5673, loss = 0.00416559\n",
      "Iteration 5674, loss = 0.00416469\n",
      "Iteration 5675, loss = 0.00416368\n",
      "Iteration 5676, loss = 0.00416264\n",
      "Iteration 5677, loss = 0.00416170\n",
      "Iteration 5678, loss = 0.00416100\n",
      "Iteration 5679, loss = 0.00415976\n",
      "Iteration 5680, loss = 0.00415897\n",
      "Iteration 5681, loss = 0.00415763\n",
      "Iteration 5682, loss = 0.00415657\n",
      "Iteration 5683, loss = 0.00415549\n",
      "Iteration 5684, loss = 0.00415438\n",
      "Iteration 5685, loss = 0.00415335\n",
      "Iteration 5686, loss = 0.00415233\n",
      "Iteration 5687, loss = 0.00415105\n",
      "Iteration 5688, loss = 0.00415045\n",
      "Iteration 5689, loss = 0.00414917\n",
      "Iteration 5690, loss = 0.00414823\n",
      "Iteration 5691, loss = 0.00414707\n",
      "Iteration 5692, loss = 0.00414608\n",
      "Iteration 5693, loss = 0.00414505\n",
      "Iteration 5694, loss = 0.00414415\n",
      "Iteration 5695, loss = 0.00414320\n",
      "Iteration 5696, loss = 0.00414217\n",
      "Iteration 5697, loss = 0.00414111\n",
      "Iteration 5698, loss = 0.00414055\n",
      "Iteration 5699, loss = 0.00413959\n",
      "Iteration 5700, loss = 0.00413829\n",
      "Iteration 5701, loss = 0.00413731\n",
      "Iteration 5702, loss = 0.00413650\n",
      "Iteration 5703, loss = 0.00413572\n",
      "Iteration 5704, loss = 0.00413417\n",
      "Iteration 5705, loss = 0.00413305\n",
      "Iteration 5706, loss = 0.00413220\n",
      "Iteration 5707, loss = 0.00413158\n",
      "Iteration 5708, loss = 0.00413122\n",
      "Iteration 5709, loss = 0.00412966\n",
      "Iteration 5710, loss = 0.00412895\n",
      "Iteration 5711, loss = 0.00412776\n",
      "Iteration 5712, loss = 0.00412679\n",
      "Iteration 5713, loss = 0.00412574\n",
      "Iteration 5714, loss = 0.00412484\n",
      "Iteration 5715, loss = 0.00412369\n",
      "Iteration 5716, loss = 0.00412252\n",
      "Iteration 5717, loss = 0.00412150\n",
      "Iteration 5718, loss = 0.00412046\n",
      "Iteration 5719, loss = 0.00411940\n",
      "Iteration 5720, loss = 0.00411833\n",
      "Iteration 5721, loss = 0.00411761\n",
      "Iteration 5722, loss = 0.00411660\n",
      "Iteration 5723, loss = 0.00411635\n",
      "Iteration 5724, loss = 0.00411496\n",
      "Iteration 5725, loss = 0.00411384\n",
      "Iteration 5726, loss = 0.00411260\n",
      "Iteration 5727, loss = 0.00411157\n",
      "Iteration 5728, loss = 0.00411154\n",
      "Iteration 5729, loss = 0.00410996\n",
      "Iteration 5730, loss = 0.00410884\n",
      "Iteration 5731, loss = 0.00410775\n",
      "Iteration 5732, loss = 0.00410675\n",
      "Iteration 5733, loss = 0.00410579\n",
      "Iteration 5734, loss = 0.00410478\n",
      "Iteration 5735, loss = 0.00410384\n",
      "Iteration 5736, loss = 0.00410305\n",
      "Iteration 5737, loss = 0.00410209\n",
      "Iteration 5738, loss = 0.00410118\n",
      "Iteration 5739, loss = 0.00410027\n",
      "Iteration 5740, loss = 0.00409925\n",
      "Iteration 5741, loss = 0.00409833\n",
      "Iteration 5742, loss = 0.00409770\n",
      "Iteration 5743, loss = 0.00409655\n",
      "Iteration 5744, loss = 0.00409556\n",
      "Iteration 5745, loss = 0.00409459\n",
      "Iteration 5746, loss = 0.00409373\n",
      "Iteration 5747, loss = 0.00409262\n",
      "Iteration 5748, loss = 0.00409166\n",
      "Iteration 5749, loss = 0.00409076\n",
      "Iteration 5750, loss = 0.00409020\n",
      "Iteration 5751, loss = 0.00408895\n",
      "Iteration 5752, loss = 0.00408806\n",
      "Iteration 5753, loss = 0.00408714\n",
      "Iteration 5754, loss = 0.00408614\n",
      "Iteration 5755, loss = 0.00408520\n",
      "Iteration 5756, loss = 0.00408412\n",
      "Iteration 5757, loss = 0.00408319\n",
      "Iteration 5758, loss = 0.00408223\n",
      "Iteration 5759, loss = 0.00408148\n",
      "Iteration 5760, loss = 0.00408062\n",
      "Iteration 5761, loss = 0.00407973\n",
      "Iteration 5762, loss = 0.00407846\n",
      "Iteration 5763, loss = 0.00407757\n",
      "Iteration 5764, loss = 0.00407669\n",
      "Iteration 5765, loss = 0.00407568\n",
      "Iteration 5766, loss = 0.00407457\n",
      "Iteration 5767, loss = 0.00407386\n",
      "Iteration 5768, loss = 0.00407274\n",
      "Iteration 5769, loss = 0.00407204\n",
      "Iteration 5770, loss = 0.00407103\n",
      "Iteration 5771, loss = 0.00407010\n",
      "Iteration 5772, loss = 0.00406921\n",
      "Iteration 5773, loss = 0.00406879\n",
      "Iteration 5774, loss = 0.00406743\n",
      "Iteration 5775, loss = 0.00406656\n",
      "Iteration 5776, loss = 0.00406549\n",
      "Iteration 5777, loss = 0.00406447\n",
      "Iteration 5778, loss = 0.00406390\n",
      "Iteration 5779, loss = 0.00406254\n",
      "Iteration 5780, loss = 0.00406159\n",
      "Iteration 5781, loss = 0.00406070\n",
      "Iteration 5782, loss = 0.00405966\n",
      "Iteration 5783, loss = 0.00405862\n",
      "Iteration 5784, loss = 0.00405779\n",
      "Iteration 5785, loss = 0.00405700\n",
      "Iteration 5786, loss = 0.00405585\n",
      "Iteration 5787, loss = 0.00405501\n",
      "Iteration 5788, loss = 0.00405409\n",
      "Iteration 5789, loss = 0.00405315\n",
      "Iteration 5790, loss = 0.00405216\n",
      "Iteration 5791, loss = 0.00405131\n",
      "Iteration 5792, loss = 0.00405153\n",
      "Iteration 5793, loss = 0.00404969\n",
      "Iteration 5794, loss = 0.00404871\n",
      "Iteration 5795, loss = 0.00404767\n",
      "Iteration 5796, loss = 0.00404670\n",
      "Iteration 5797, loss = 0.00404607\n",
      "Iteration 5798, loss = 0.00404489\n",
      "Iteration 5799, loss = 0.00404385\n",
      "Iteration 5800, loss = 0.00404291\n",
      "Iteration 5801, loss = 0.00404198\n",
      "Iteration 5802, loss = 0.00404107\n",
      "Iteration 5803, loss = 0.00404032\n",
      "Iteration 5804, loss = 0.00403933\n",
      "Iteration 5805, loss = 0.00403836\n",
      "Iteration 5806, loss = 0.00403735\n",
      "Iteration 5807, loss = 0.00403709\n",
      "Iteration 5808, loss = 0.00403594\n",
      "Iteration 5809, loss = 0.00403503\n",
      "Iteration 5810, loss = 0.00403399\n",
      "Iteration 5811, loss = 0.00403306\n",
      "Iteration 5812, loss = 0.00403224\n",
      "Iteration 5813, loss = 0.00403133\n",
      "Iteration 5814, loss = 0.00403045\n",
      "Iteration 5815, loss = 0.00402996\n",
      "Iteration 5816, loss = 0.00402875\n",
      "Iteration 5817, loss = 0.00402785\n",
      "Iteration 5818, loss = 0.00402719\n",
      "Iteration 5819, loss = 0.00402629\n",
      "Iteration 5820, loss = 0.00402542\n",
      "Iteration 5821, loss = 0.00402461\n",
      "Iteration 5822, loss = 0.00402393\n",
      "Iteration 5823, loss = 0.00402274\n",
      "Iteration 5824, loss = 0.00402200\n",
      "Iteration 5825, loss = 0.00402090\n",
      "Iteration 5826, loss = 0.00402022\n",
      "Iteration 5827, loss = 0.00401907\n",
      "Iteration 5828, loss = 0.00401827\n",
      "Iteration 5829, loss = 0.00401805\n",
      "Iteration 5830, loss = 0.00401623\n",
      "Iteration 5831, loss = 0.00401532\n",
      "Iteration 5832, loss = 0.00401436\n",
      "Iteration 5833, loss = 0.00401331\n",
      "Iteration 5834, loss = 0.00401238\n",
      "Iteration 5835, loss = 0.00401155\n",
      "Iteration 5836, loss = 0.00401060\n",
      "Iteration 5837, loss = 0.00400957\n",
      "Iteration 5838, loss = 0.00400856\n",
      "Iteration 5839, loss = 0.00400771\n",
      "Iteration 5840, loss = 0.00400689\n",
      "Iteration 5841, loss = 0.00400590\n",
      "Iteration 5842, loss = 0.00400499\n",
      "Iteration 5843, loss = 0.00400411\n",
      "Iteration 5844, loss = 0.00400321\n",
      "Iteration 5845, loss = 0.00400266\n",
      "Iteration 5846, loss = 0.00400185\n",
      "Iteration 5847, loss = 0.00400060\n",
      "Iteration 5848, loss = 0.00399966\n",
      "Iteration 5849, loss = 0.00399879\n",
      "Iteration 5850, loss = 0.00399780\n",
      "Iteration 5851, loss = 0.00399687\n",
      "Iteration 5852, loss = 0.00399622\n",
      "Iteration 5853, loss = 0.00399547\n",
      "Iteration 5854, loss = 0.00399447\n",
      "Iteration 5855, loss = 0.00399348\n",
      "Iteration 5856, loss = 0.00399290\n",
      "Iteration 5857, loss = 0.00399181\n",
      "Iteration 5858, loss = 0.00399094\n",
      "Iteration 5859, loss = 0.00399029\n",
      "Iteration 5860, loss = 0.00398903\n",
      "Iteration 5861, loss = 0.00398822\n",
      "Iteration 5862, loss = 0.00398708\n",
      "Iteration 5863, loss = 0.00398630\n",
      "Iteration 5864, loss = 0.00398554\n",
      "Iteration 5865, loss = 0.00398439\n",
      "Iteration 5866, loss = 0.00398382\n",
      "Iteration 5867, loss = 0.00398271\n",
      "Iteration 5868, loss = 0.00398188\n",
      "Iteration 5869, loss = 0.00398095\n",
      "Iteration 5870, loss = 0.00398013\n",
      "Iteration 5871, loss = 0.00397911\n",
      "Iteration 5872, loss = 0.00397814\n",
      "Iteration 5873, loss = 0.00397720\n",
      "Iteration 5874, loss = 0.00397662\n",
      "Iteration 5875, loss = 0.00397550\n",
      "Iteration 5876, loss = 0.00397462\n",
      "Iteration 5877, loss = 0.00397349\n",
      "Iteration 5878, loss = 0.00397251\n",
      "Iteration 5879, loss = 0.00397165\n",
      "Iteration 5880, loss = 0.00397098\n",
      "Iteration 5881, loss = 0.00396992\n",
      "Iteration 5882, loss = 0.00396912\n",
      "Iteration 5883, loss = 0.00396844\n",
      "Iteration 5884, loss = 0.00396735\n",
      "Iteration 5885, loss = 0.00396653\n",
      "Iteration 5886, loss = 0.00396564\n",
      "Iteration 5887, loss = 0.00396471\n",
      "Iteration 5888, loss = 0.00396378\n",
      "Iteration 5889, loss = 0.00396314\n",
      "Iteration 5890, loss = 0.00396257\n",
      "Iteration 5891, loss = 0.00396129\n",
      "Iteration 5892, loss = 0.00396122\n",
      "Iteration 5893, loss = 0.00395968\n",
      "Iteration 5894, loss = 0.00395873\n",
      "Iteration 5895, loss = 0.00395806\n",
      "Iteration 5896, loss = 0.00395702\n",
      "Iteration 5897, loss = 0.00395601\n",
      "Iteration 5898, loss = 0.00395540\n",
      "Iteration 5899, loss = 0.00395437\n",
      "Iteration 5900, loss = 0.00395335\n",
      "Iteration 5901, loss = 0.00395248\n",
      "Iteration 5902, loss = 0.00395161\n",
      "Iteration 5903, loss = 0.00395100\n",
      "Iteration 5904, loss = 0.00394994\n",
      "Iteration 5905, loss = 0.00394896\n",
      "Iteration 5906, loss = 0.00394855\n",
      "Iteration 5907, loss = 0.00394748\n",
      "Iteration 5908, loss = 0.00394655\n",
      "Iteration 5909, loss = 0.00394572\n",
      "Iteration 5910, loss = 0.00394482\n",
      "Iteration 5911, loss = 0.00394410\n",
      "Iteration 5912, loss = 0.00394285\n",
      "Iteration 5913, loss = 0.00394220\n",
      "Iteration 5914, loss = 0.00394132\n",
      "Iteration 5915, loss = 0.00394058\n",
      "Iteration 5916, loss = 0.00393956\n",
      "Iteration 5917, loss = 0.00393873\n",
      "Iteration 5918, loss = 0.00393777\n",
      "Iteration 5919, loss = 0.00393731\n",
      "Iteration 5920, loss = 0.00393641\n",
      "Iteration 5921, loss = 0.00393523\n",
      "Iteration 5922, loss = 0.00393431\n",
      "Iteration 5923, loss = 0.00393354\n",
      "Iteration 5924, loss = 0.00393277\n",
      "Iteration 5925, loss = 0.00393185\n",
      "Iteration 5926, loss = 0.00393092\n",
      "Iteration 5927, loss = 0.00393022\n",
      "Iteration 5928, loss = 0.00392913\n",
      "Iteration 5929, loss = 0.00392817\n",
      "Iteration 5930, loss = 0.00392724\n",
      "Iteration 5931, loss = 0.00392637\n",
      "Iteration 5932, loss = 0.00392541\n",
      "Iteration 5933, loss = 0.00392434\n",
      "Iteration 5934, loss = 0.00392328\n",
      "Iteration 5935, loss = 0.00392221\n",
      "Iteration 5936, loss = 0.00392123\n",
      "Iteration 5937, loss = 0.00392093\n",
      "Iteration 5938, loss = 0.00391998\n",
      "Iteration 5939, loss = 0.00391932\n",
      "Iteration 5940, loss = 0.00391810\n",
      "Iteration 5941, loss = 0.00391722\n",
      "Iteration 5942, loss = 0.00391637\n",
      "Iteration 5943, loss = 0.00391549\n",
      "Iteration 5944, loss = 0.00391472\n",
      "Iteration 5945, loss = 0.00391384\n",
      "Iteration 5946, loss = 0.00391298\n",
      "Iteration 5947, loss = 0.00391218\n",
      "Iteration 5948, loss = 0.00391126\n",
      "Iteration 5949, loss = 0.00391059\n",
      "Iteration 5950, loss = 0.00390953\n",
      "Iteration 5951, loss = 0.00390877\n",
      "Iteration 5952, loss = 0.00390793\n",
      "Iteration 5953, loss = 0.00390709\n",
      "Iteration 5954, loss = 0.00390628\n",
      "Iteration 5955, loss = 0.00390546\n",
      "Iteration 5956, loss = 0.00390462\n",
      "Iteration 5957, loss = 0.00390380\n",
      "Iteration 5958, loss = 0.00390296\n",
      "Iteration 5959, loss = 0.00390221\n",
      "Iteration 5960, loss = 0.00390122\n",
      "Iteration 5961, loss = 0.00390046\n",
      "Iteration 5962, loss = 0.00389970\n",
      "Iteration 5963, loss = 0.00389901\n",
      "Iteration 5964, loss = 0.00389799\n",
      "Iteration 5965, loss = 0.00389712\n",
      "Iteration 5966, loss = 0.00389612\n",
      "Iteration 5967, loss = 0.00389543\n",
      "Iteration 5968, loss = 0.00389439\n",
      "Iteration 5969, loss = 0.00389344\n",
      "Iteration 5970, loss = 0.00389259\n",
      "Iteration 5971, loss = 0.00389205\n",
      "Iteration 5972, loss = 0.00389078\n",
      "Iteration 5973, loss = 0.00388994\n",
      "Iteration 5974, loss = 0.00388940\n",
      "Iteration 5975, loss = 0.00388839\n",
      "Iteration 5976, loss = 0.00388767\n",
      "Iteration 5977, loss = 0.00388662\n",
      "Iteration 5978, loss = 0.00388584\n",
      "Iteration 5979, loss = 0.00388490\n",
      "Iteration 5980, loss = 0.00388426\n",
      "Iteration 5981, loss = 0.00388326\n",
      "Iteration 5982, loss = 0.00388238\n",
      "Iteration 5983, loss = 0.00388150\n",
      "Iteration 5984, loss = 0.00388064\n",
      "Iteration 5985, loss = 0.00388003\n",
      "Iteration 5986, loss = 0.00387906\n",
      "Iteration 5987, loss = 0.00387848\n",
      "Iteration 5988, loss = 0.00387727\n",
      "Iteration 5989, loss = 0.00387645\n",
      "Iteration 5990, loss = 0.00387569\n",
      "Iteration 5991, loss = 0.00387477\n",
      "Iteration 5992, loss = 0.00387380\n",
      "Iteration 5993, loss = 0.00387296\n",
      "Iteration 5994, loss = 0.00387201\n",
      "Iteration 5995, loss = 0.00387102\n",
      "Iteration 5996, loss = 0.00387038\n",
      "Iteration 5997, loss = 0.00386931\n",
      "Iteration 5998, loss = 0.00386848\n",
      "Iteration 5999, loss = 0.00386799\n",
      "Iteration 6000, loss = 0.00386695\n",
      "Iteration 6001, loss = 0.00386603\n",
      "Iteration 6002, loss = 0.00386498\n",
      "Iteration 6003, loss = 0.00386436\n",
      "Iteration 6004, loss = 0.00386332\n",
      "Iteration 6005, loss = 0.00386264\n",
      "Iteration 6006, loss = 0.00386189\n",
      "Iteration 6007, loss = 0.00386109\n",
      "Iteration 6008, loss = 0.00386028\n",
      "Iteration 6009, loss = 0.00385952\n",
      "Iteration 6010, loss = 0.00385882\n",
      "Iteration 6011, loss = 0.00385805\n",
      "Iteration 6012, loss = 0.00385764\n",
      "Iteration 6013, loss = 0.00385671\n",
      "Iteration 6014, loss = 0.00385582\n",
      "Iteration 6015, loss = 0.00385494\n",
      "Iteration 6016, loss = 0.00385422\n",
      "Iteration 6017, loss = 0.00385347\n",
      "Iteration 6018, loss = 0.00385284\n",
      "Iteration 6019, loss = 0.00385174\n",
      "Iteration 6020, loss = 0.00385084\n",
      "Iteration 6021, loss = 0.00384999\n",
      "Iteration 6022, loss = 0.00384911\n",
      "Iteration 6023, loss = 0.00384830\n",
      "Iteration 6024, loss = 0.00384773\n",
      "Iteration 6025, loss = 0.00384692\n",
      "Iteration 6026, loss = 0.00384611\n",
      "Iteration 6027, loss = 0.00384530\n",
      "Iteration 6028, loss = 0.00384446\n",
      "Iteration 6029, loss = 0.00384387\n",
      "Iteration 6030, loss = 0.00384301\n",
      "Iteration 6031, loss = 0.00384220\n",
      "Iteration 6032, loss = 0.00384143\n",
      "Iteration 6033, loss = 0.00384064\n",
      "Iteration 6034, loss = 0.00383988\n",
      "Iteration 6035, loss = 0.00383920\n",
      "Iteration 6036, loss = 0.00383835\n",
      "Iteration 6037, loss = 0.00383754\n",
      "Iteration 6038, loss = 0.00383669\n",
      "Iteration 6039, loss = 0.00383580\n",
      "Iteration 6040, loss = 0.00383489\n",
      "Iteration 6041, loss = 0.00383413\n",
      "Iteration 6042, loss = 0.00383365\n",
      "Iteration 6043, loss = 0.00383231\n",
      "Iteration 6044, loss = 0.00383180\n",
      "Iteration 6045, loss = 0.00383089\n",
      "Iteration 6046, loss = 0.00382972\n",
      "Iteration 6047, loss = 0.00382876\n",
      "Iteration 6048, loss = 0.00382789\n",
      "Iteration 6049, loss = 0.00382696\n",
      "Iteration 6050, loss = 0.00382604\n",
      "Iteration 6051, loss = 0.00382539\n",
      "Iteration 6052, loss = 0.00382467\n",
      "Iteration 6053, loss = 0.00382371\n",
      "Iteration 6054, loss = 0.00382283\n",
      "Iteration 6055, loss = 0.00382236\n",
      "Iteration 6056, loss = 0.00382133\n",
      "Iteration 6057, loss = 0.00382068\n",
      "Iteration 6058, loss = 0.00382011\n",
      "Iteration 6059, loss = 0.00381957\n",
      "Iteration 6060, loss = 0.00381862\n",
      "Iteration 6061, loss = 0.00381758\n",
      "Iteration 6062, loss = 0.00381680\n",
      "Iteration 6063, loss = 0.00381656\n",
      "Iteration 6064, loss = 0.00381503\n",
      "Iteration 6065, loss = 0.00381429\n",
      "Iteration 6066, loss = 0.00381347\n",
      "Iteration 6067, loss = 0.00381255\n",
      "Iteration 6068, loss = 0.00381172\n",
      "Iteration 6069, loss = 0.00381105\n",
      "Iteration 6070, loss = 0.00381019\n",
      "Iteration 6071, loss = 0.00380939\n",
      "Iteration 6072, loss = 0.00380868\n",
      "Iteration 6073, loss = 0.00380799\n",
      "Iteration 6074, loss = 0.00380744\n",
      "Iteration 6075, loss = 0.00380641\n",
      "Iteration 6076, loss = 0.00380549\n",
      "Iteration 6077, loss = 0.00380471\n",
      "Iteration 6078, loss = 0.00380384\n",
      "Iteration 6079, loss = 0.00380292\n",
      "Iteration 6080, loss = 0.00380189\n",
      "Iteration 6081, loss = 0.00380104\n",
      "Iteration 6082, loss = 0.00380041\n",
      "Iteration 6083, loss = 0.00379953\n",
      "Iteration 6084, loss = 0.00379846\n",
      "Iteration 6085, loss = 0.00379758\n",
      "Iteration 6086, loss = 0.00379672\n",
      "Iteration 6087, loss = 0.00379590\n",
      "Iteration 6088, loss = 0.00379505\n",
      "Iteration 6089, loss = 0.00379423\n",
      "Iteration 6090, loss = 0.00379328\n",
      "Iteration 6091, loss = 0.00379246\n",
      "Iteration 6092, loss = 0.00379151\n",
      "Iteration 6093, loss = 0.00379076\n",
      "Iteration 6094, loss = 0.00378970\n",
      "Iteration 6095, loss = 0.00378909\n",
      "Iteration 6096, loss = 0.00378817\n",
      "Iteration 6097, loss = 0.00378705\n",
      "Iteration 6098, loss = 0.00378628\n",
      "Iteration 6099, loss = 0.00378542\n",
      "Iteration 6100, loss = 0.00378454\n",
      "Iteration 6101, loss = 0.00378366\n",
      "Iteration 6102, loss = 0.00378271\n",
      "Iteration 6103, loss = 0.00378211\n",
      "Iteration 6104, loss = 0.00378096\n",
      "Iteration 6105, loss = 0.00378006\n",
      "Iteration 6106, loss = 0.00377938\n",
      "Iteration 6107, loss = 0.00377840\n",
      "Iteration 6108, loss = 0.00377769\n",
      "Iteration 6109, loss = 0.00377680\n",
      "Iteration 6110, loss = 0.00377600\n",
      "Iteration 6111, loss = 0.00377527\n",
      "Iteration 6112, loss = 0.00377440\n",
      "Iteration 6113, loss = 0.00377365\n",
      "Iteration 6114, loss = 0.00377251\n",
      "Iteration 6115, loss = 0.00377232\n",
      "Iteration 6116, loss = 0.00377150\n",
      "Iteration 6117, loss = 0.00377037\n",
      "Iteration 6118, loss = 0.00376943\n",
      "Iteration 6119, loss = 0.00376866\n",
      "Iteration 6120, loss = 0.00376770\n",
      "Iteration 6121, loss = 0.00376721\n",
      "Iteration 6122, loss = 0.00376623\n",
      "Iteration 6123, loss = 0.00376546\n",
      "Iteration 6124, loss = 0.00376470\n",
      "Iteration 6125, loss = 0.00376412\n",
      "Iteration 6126, loss = 0.00376310\n",
      "Iteration 6127, loss = 0.00376228\n",
      "Iteration 6128, loss = 0.00376139\n",
      "Iteration 6129, loss = 0.00376040\n",
      "Iteration 6130, loss = 0.00375995\n",
      "Iteration 6131, loss = 0.00375992\n",
      "Iteration 6132, loss = 0.00375822\n",
      "Iteration 6133, loss = 0.00375763\n",
      "Iteration 6134, loss = 0.00375663\n",
      "Iteration 6135, loss = 0.00375552\n",
      "Iteration 6136, loss = 0.00375489\n",
      "Iteration 6137, loss = 0.00375379\n",
      "Iteration 6138, loss = 0.00375310\n",
      "Iteration 6139, loss = 0.00375213\n",
      "Iteration 6140, loss = 0.00375142\n",
      "Iteration 6141, loss = 0.00375051\n",
      "Iteration 6142, loss = 0.00374964\n",
      "Iteration 6143, loss = 0.00374868\n",
      "Iteration 6144, loss = 0.00374767\n",
      "Iteration 6145, loss = 0.00374694\n",
      "Iteration 6146, loss = 0.00374642\n",
      "Iteration 6147, loss = 0.00374517\n",
      "Iteration 6148, loss = 0.00374432\n",
      "Iteration 6149, loss = 0.00374352\n",
      "Iteration 6150, loss = 0.00374275\n",
      "Iteration 6151, loss = 0.00374201\n",
      "Iteration 6152, loss = 0.00374119\n",
      "Iteration 6153, loss = 0.00374049\n",
      "Iteration 6154, loss = 0.00373974\n",
      "Iteration 6155, loss = 0.00373913\n",
      "Iteration 6156, loss = 0.00373828\n",
      "Iteration 6157, loss = 0.00373735\n",
      "Iteration 6158, loss = 0.00373657\n",
      "Iteration 6159, loss = 0.00373580\n",
      "Iteration 6160, loss = 0.00373493\n",
      "Iteration 6161, loss = 0.00373388\n",
      "Iteration 6162, loss = 0.00373301\n",
      "Iteration 6163, loss = 0.00373203\n",
      "Iteration 6164, loss = 0.00373205\n",
      "Iteration 6165, loss = 0.00373028\n",
      "Iteration 6166, loss = 0.00372944\n",
      "Iteration 6167, loss = 0.00372857\n",
      "Iteration 6168, loss = 0.00372805\n",
      "Iteration 6169, loss = 0.00372729\n",
      "Iteration 6170, loss = 0.00372608\n",
      "Iteration 6171, loss = 0.00372516\n",
      "Iteration 6172, loss = 0.00372449\n",
      "Iteration 6173, loss = 0.00372359\n",
      "Iteration 6174, loss = 0.00372262\n",
      "Iteration 6175, loss = 0.00372166\n",
      "Iteration 6176, loss = 0.00372125\n",
      "Iteration 6177, loss = 0.00372005\n",
      "Iteration 6178, loss = 0.00371919\n",
      "Iteration 6179, loss = 0.00371838\n",
      "Iteration 6180, loss = 0.00371765\n",
      "Iteration 6181, loss = 0.00371678\n",
      "Iteration 6182, loss = 0.00371603\n",
      "Iteration 6183, loss = 0.00371577\n",
      "Iteration 6184, loss = 0.00371454\n",
      "Iteration 6185, loss = 0.00371359\n",
      "Iteration 6186, loss = 0.00371297\n",
      "Iteration 6187, loss = 0.00371210\n",
      "Iteration 6188, loss = 0.00371138\n",
      "Iteration 6189, loss = 0.00371065\n",
      "Iteration 6190, loss = 0.00370983\n",
      "Iteration 6191, loss = 0.00370920\n",
      "Iteration 6192, loss = 0.00370839\n",
      "Iteration 6193, loss = 0.00370803\n",
      "Iteration 6194, loss = 0.00370688\n",
      "Iteration 6195, loss = 0.00370618\n",
      "Iteration 6196, loss = 0.00370551\n",
      "Iteration 6197, loss = 0.00370462\n",
      "Iteration 6198, loss = 0.00370394\n",
      "Iteration 6199, loss = 0.00370317\n",
      "Iteration 6200, loss = 0.00370253\n",
      "Iteration 6201, loss = 0.00370190\n",
      "Iteration 6202, loss = 0.00370105\n",
      "Iteration 6203, loss = 0.00370022\n",
      "Iteration 6204, loss = 0.00369944\n",
      "Iteration 6205, loss = 0.00369863\n",
      "Iteration 6206, loss = 0.00369787\n",
      "Iteration 6207, loss = 0.00369719\n",
      "Iteration 6208, loss = 0.00369655\n",
      "Iteration 6209, loss = 0.00369601\n",
      "Iteration 6210, loss = 0.00369512\n",
      "Iteration 6211, loss = 0.00369445\n",
      "Iteration 6212, loss = 0.00369388\n",
      "Iteration 6213, loss = 0.00369324\n",
      "Iteration 6214, loss = 0.00369245\n",
      "Iteration 6215, loss = 0.00369186\n",
      "Iteration 6216, loss = 0.00369110\n",
      "Iteration 6217, loss = 0.00369039\n",
      "Iteration 6218, loss = 0.00368970\n",
      "Iteration 6219, loss = 0.00368896\n",
      "Iteration 6220, loss = 0.00368855\n",
      "Iteration 6221, loss = 0.00368818\n",
      "Iteration 6222, loss = 0.00368705\n",
      "Iteration 6223, loss = 0.00368625\n",
      "Iteration 6224, loss = 0.00368549\n",
      "Iteration 6225, loss = 0.00368455\n",
      "Iteration 6226, loss = 0.00368363\n",
      "Iteration 6227, loss = 0.00368320\n",
      "Iteration 6228, loss = 0.00368196\n",
      "Iteration 6229, loss = 0.00368174\n",
      "Iteration 6230, loss = 0.00368047\n",
      "Iteration 6231, loss = 0.00367961\n",
      "Iteration 6232, loss = 0.00367880\n",
      "Iteration 6233, loss = 0.00367802\n",
      "Iteration 6234, loss = 0.00367720\n",
      "Iteration 6235, loss = 0.00367622\n",
      "Iteration 6236, loss = 0.00367565\n",
      "Iteration 6237, loss = 0.00367455\n",
      "Iteration 6238, loss = 0.00367377\n",
      "Iteration 6239, loss = 0.00367308\n",
      "Iteration 6240, loss = 0.00367219\n",
      "Iteration 6241, loss = 0.00367139\n",
      "Iteration 6242, loss = 0.00367077\n",
      "Iteration 6243, loss = 0.00366994\n",
      "Iteration 6244, loss = 0.00366921\n",
      "Iteration 6245, loss = 0.00366869\n",
      "Iteration 6246, loss = 0.00366789\n",
      "Iteration 6247, loss = 0.00366713\n",
      "Iteration 6248, loss = 0.00366648\n",
      "Iteration 6249, loss = 0.00366577\n",
      "Iteration 6250, loss = 0.00366491\n",
      "Iteration 6251, loss = 0.00366422\n",
      "Iteration 6252, loss = 0.00366341\n",
      "Iteration 6253, loss = 0.00366263\n",
      "Iteration 6254, loss = 0.00366183\n",
      "Iteration 6255, loss = 0.00366110\n",
      "Iteration 6256, loss = 0.00366019\n",
      "Iteration 6257, loss = 0.00365989\n",
      "Iteration 6258, loss = 0.00365878\n",
      "Iteration 6259, loss = 0.00365788\n",
      "Iteration 6260, loss = 0.00365716\n",
      "Iteration 6261, loss = 0.00365630\n",
      "Iteration 6262, loss = 0.00365546\n",
      "Iteration 6263, loss = 0.00365467\n",
      "Iteration 6264, loss = 0.00365421\n",
      "Iteration 6265, loss = 0.00365316\n",
      "Iteration 6266, loss = 0.00365263\n",
      "Iteration 6267, loss = 0.00365166\n",
      "Iteration 6268, loss = 0.00365081\n",
      "Iteration 6269, loss = 0.00365012\n",
      "Iteration 6270, loss = 0.00364930\n",
      "Iteration 6271, loss = 0.00364854\n",
      "Iteration 6272, loss = 0.00364777\n",
      "Iteration 6273, loss = 0.00364708\n",
      "Iteration 6274, loss = 0.00364627\n",
      "Iteration 6275, loss = 0.00364547\n",
      "Iteration 6276, loss = 0.00364479\n",
      "Iteration 6277, loss = 0.00364381\n",
      "Iteration 6278, loss = 0.00364307\n",
      "Iteration 6279, loss = 0.00364240\n",
      "Iteration 6280, loss = 0.00364147\n",
      "Iteration 6281, loss = 0.00364082\n",
      "Iteration 6282, loss = 0.00364001\n",
      "Iteration 6283, loss = 0.00363941\n",
      "Iteration 6284, loss = 0.00363891\n",
      "Iteration 6285, loss = 0.00363780\n",
      "Iteration 6286, loss = 0.00363702\n",
      "Iteration 6287, loss = 0.00363693\n",
      "Iteration 6288, loss = 0.00363567\n",
      "Iteration 6289, loss = 0.00363490\n",
      "Iteration 6290, loss = 0.00363398\n",
      "Iteration 6291, loss = 0.00363313\n",
      "Iteration 6292, loss = 0.00363233\n",
      "Iteration 6293, loss = 0.00363226\n",
      "Iteration 6294, loss = 0.00363116\n",
      "Iteration 6295, loss = 0.00363024\n",
      "Iteration 6296, loss = 0.00362954\n",
      "Iteration 6297, loss = 0.00362875\n",
      "Iteration 6298, loss = 0.00362786\n",
      "Iteration 6299, loss = 0.00362732\n",
      "Iteration 6300, loss = 0.00362642\n",
      "Iteration 6301, loss = 0.00362559\n",
      "Iteration 6302, loss = 0.00362484\n",
      "Iteration 6303, loss = 0.00362407\n",
      "Iteration 6304, loss = 0.00362301\n",
      "Iteration 6305, loss = 0.00362280\n",
      "Iteration 6306, loss = 0.00362153\n",
      "Iteration 6307, loss = 0.00362089\n",
      "Iteration 6308, loss = 0.00362000\n",
      "Iteration 6309, loss = 0.00361924\n",
      "Iteration 6310, loss = 0.00361849\n",
      "Iteration 6311, loss = 0.00361784\n",
      "Iteration 6312, loss = 0.00361701\n",
      "Iteration 6313, loss = 0.00361660\n",
      "Iteration 6314, loss = 0.00361565\n",
      "Iteration 6315, loss = 0.00361532\n",
      "Iteration 6316, loss = 0.00361409\n",
      "Iteration 6317, loss = 0.00361326\n",
      "Iteration 6318, loss = 0.00361244\n",
      "Iteration 6319, loss = 0.00361193\n",
      "Iteration 6320, loss = 0.00361094\n",
      "Iteration 6321, loss = 0.00361019\n",
      "Iteration 6322, loss = 0.00360941\n",
      "Iteration 6323, loss = 0.00360868\n",
      "Iteration 6324, loss = 0.00360773\n",
      "Iteration 6325, loss = 0.00360720\n",
      "Iteration 6326, loss = 0.00360611\n",
      "Iteration 6327, loss = 0.00360553\n",
      "Iteration 6328, loss = 0.00360458\n",
      "Iteration 6329, loss = 0.00360378\n",
      "Iteration 6330, loss = 0.00360323\n",
      "Iteration 6331, loss = 0.00360227\n",
      "Iteration 6332, loss = 0.00360148\n",
      "Iteration 6333, loss = 0.00360080\n",
      "Iteration 6334, loss = 0.00360005\n",
      "Iteration 6335, loss = 0.00359927\n",
      "Iteration 6336, loss = 0.00359857\n",
      "Iteration 6337, loss = 0.00359789\n",
      "Iteration 6338, loss = 0.00359714\n",
      "Iteration 6339, loss = 0.00359651\n",
      "Iteration 6340, loss = 0.00359579\n",
      "Iteration 6341, loss = 0.00359510\n",
      "Iteration 6342, loss = 0.00359452\n",
      "Iteration 6343, loss = 0.00359371\n",
      "Iteration 6344, loss = 0.00359311\n",
      "Iteration 6345, loss = 0.00359234\n",
      "Iteration 6346, loss = 0.00359179\n",
      "Iteration 6347, loss = 0.00359092\n",
      "Iteration 6348, loss = 0.00359023\n",
      "Iteration 6349, loss = 0.00358956\n",
      "Iteration 6350, loss = 0.00358906\n",
      "Iteration 6351, loss = 0.00358831\n",
      "Iteration 6352, loss = 0.00358758\n",
      "Iteration 6353, loss = 0.00358693\n",
      "Iteration 6354, loss = 0.00358629\n",
      "Iteration 6355, loss = 0.00358564\n",
      "Iteration 6356, loss = 0.00358473\n",
      "Iteration 6357, loss = 0.00358413\n",
      "Iteration 6358, loss = 0.00358327\n",
      "Iteration 6359, loss = 0.00358261\n",
      "Iteration 6360, loss = 0.00358177\n",
      "Iteration 6361, loss = 0.00358102\n",
      "Iteration 6362, loss = 0.00358038\n",
      "Iteration 6363, loss = 0.00357968\n",
      "Iteration 6364, loss = 0.00357891\n",
      "Iteration 6365, loss = 0.00357849\n",
      "Iteration 6366, loss = 0.00357737\n",
      "Iteration 6367, loss = 0.00357673\n",
      "Iteration 6368, loss = 0.00357591\n",
      "Iteration 6369, loss = 0.00357507\n",
      "Iteration 6370, loss = 0.00357467\n",
      "Iteration 6371, loss = 0.00357421\n",
      "Iteration 6372, loss = 0.00357320\n",
      "Iteration 6373, loss = 0.00357248\n",
      "Iteration 6374, loss = 0.00357200\n",
      "Iteration 6375, loss = 0.00357163\n",
      "Iteration 6376, loss = 0.00357067\n",
      "Iteration 6377, loss = 0.00357003\n",
      "Iteration 6378, loss = 0.00356918\n",
      "Iteration 6379, loss = 0.00356839\n",
      "Iteration 6380, loss = 0.00356772\n",
      "Iteration 6381, loss = 0.00356705\n",
      "Iteration 6382, loss = 0.00356614\n",
      "Iteration 6383, loss = 0.00356543\n",
      "Iteration 6384, loss = 0.00356477\n",
      "Iteration 6385, loss = 0.00356414\n",
      "Iteration 6386, loss = 0.00356361\n",
      "Iteration 6387, loss = 0.00356272\n",
      "Iteration 6388, loss = 0.00356197\n",
      "Iteration 6389, loss = 0.00356106\n",
      "Iteration 6390, loss = 0.00356076\n",
      "Iteration 6391, loss = 0.00356016\n",
      "Iteration 6392, loss = 0.00355927\n",
      "Iteration 6393, loss = 0.00355826\n",
      "Iteration 6394, loss = 0.00355735\n",
      "Iteration 6395, loss = 0.00355661\n",
      "Iteration 6396, loss = 0.00355587\n",
      "Iteration 6397, loss = 0.00355504\n",
      "Iteration 6398, loss = 0.00355448\n",
      "Iteration 6399, loss = 0.00355376\n",
      "Iteration 6400, loss = 0.00355304\n",
      "Iteration 6401, loss = 0.00355246\n",
      "Iteration 6402, loss = 0.00355170\n",
      "Iteration 6403, loss = 0.00355110\n",
      "Iteration 6404, loss = 0.00355053\n",
      "Iteration 6405, loss = 0.00354992\n",
      "Iteration 6406, loss = 0.00354926\n",
      "Iteration 6407, loss = 0.00354862\n",
      "Iteration 6408, loss = 0.00354811\n",
      "Iteration 6409, loss = 0.00354740\n",
      "Iteration 6410, loss = 0.00354678\n",
      "Iteration 6411, loss = 0.00354614\n",
      "Iteration 6412, loss = 0.00354537\n",
      "Iteration 6413, loss = 0.00354472\n",
      "Iteration 6414, loss = 0.00354417\n",
      "Iteration 6415, loss = 0.00354394\n",
      "Iteration 6416, loss = 0.00354286\n",
      "Iteration 6417, loss = 0.00354235\n",
      "Iteration 6418, loss = 0.00354143\n",
      "Iteration 6419, loss = 0.00354110\n",
      "Iteration 6420, loss = 0.00353992\n",
      "Iteration 6421, loss = 0.00353906\n",
      "Iteration 6422, loss = 0.00353841\n",
      "Iteration 6423, loss = 0.00353773\n",
      "Iteration 6424, loss = 0.00353683\n",
      "Iteration 6425, loss = 0.00353610\n",
      "Iteration 6426, loss = 0.00353525\n",
      "Iteration 6427, loss = 0.00353446\n",
      "Iteration 6428, loss = 0.00353358\n",
      "Iteration 6429, loss = 0.00353330\n",
      "Iteration 6430, loss = 0.00353222\n",
      "Iteration 6431, loss = 0.00353160\n",
      "Iteration 6432, loss = 0.00353064\n",
      "Iteration 6433, loss = 0.00352991\n",
      "Iteration 6434, loss = 0.00352907\n",
      "Iteration 6435, loss = 0.00352809\n",
      "Iteration 6436, loss = 0.00352767\n",
      "Iteration 6437, loss = 0.00352624\n",
      "Iteration 6438, loss = 0.00352564\n",
      "Iteration 6439, loss = 0.00352457\n",
      "Iteration 6440, loss = 0.00352408\n",
      "Iteration 6441, loss = 0.00352313\n",
      "Iteration 6442, loss = 0.00352235\n",
      "Iteration 6443, loss = 0.00352140\n",
      "Iteration 6444, loss = 0.00352059\n",
      "Iteration 6445, loss = 0.00351972\n",
      "Iteration 6446, loss = 0.00351932\n",
      "Iteration 6447, loss = 0.00351844\n",
      "Iteration 6448, loss = 0.00351756\n",
      "Iteration 6449, loss = 0.00351742\n",
      "Iteration 6450, loss = 0.00351622\n",
      "Iteration 6451, loss = 0.00351544\n",
      "Iteration 6452, loss = 0.00351481\n",
      "Iteration 6453, loss = 0.00351415\n",
      "Iteration 6454, loss = 0.00351346\n",
      "Iteration 6455, loss = 0.00351280\n",
      "Iteration 6456, loss = 0.00351225\n",
      "Iteration 6457, loss = 0.00351154\n",
      "Iteration 6458, loss = 0.00351092\n",
      "Iteration 6459, loss = 0.00351027\n",
      "Iteration 6460, loss = 0.00350978\n",
      "Iteration 6461, loss = 0.00350905\n",
      "Iteration 6462, loss = 0.00350828\n",
      "Iteration 6463, loss = 0.00350759\n",
      "Iteration 6464, loss = 0.00350684\n",
      "Iteration 6465, loss = 0.00350626\n",
      "Iteration 6466, loss = 0.00350579\n",
      "Iteration 6467, loss = 0.00350509\n",
      "Iteration 6468, loss = 0.00350428\n",
      "Iteration 6469, loss = 0.00350361\n",
      "Iteration 6470, loss = 0.00350283\n",
      "Iteration 6471, loss = 0.00350216\n",
      "Iteration 6472, loss = 0.00350145\n",
      "Iteration 6473, loss = 0.00350080\n",
      "Iteration 6474, loss = 0.00350002\n",
      "Iteration 6475, loss = 0.00349942\n",
      "Iteration 6476, loss = 0.00349874\n",
      "Iteration 6477, loss = 0.00349800\n",
      "Iteration 6478, loss = 0.00349732\n",
      "Iteration 6479, loss = 0.00349683\n",
      "Iteration 6480, loss = 0.00349603\n",
      "Iteration 6481, loss = 0.00349515\n",
      "Iteration 6482, loss = 0.00349458\n",
      "Iteration 6483, loss = 0.00349402\n",
      "Iteration 6484, loss = 0.00349327\n",
      "Iteration 6485, loss = 0.00349241\n",
      "Iteration 6486, loss = 0.00349185\n",
      "Iteration 6487, loss = 0.00349104\n",
      "Iteration 6488, loss = 0.00349034\n",
      "Iteration 6489, loss = 0.00348985\n",
      "Iteration 6490, loss = 0.00348931\n",
      "Iteration 6491, loss = 0.00348833\n",
      "Iteration 6492, loss = 0.00348727\n",
      "Iteration 6493, loss = 0.00348656\n",
      "Iteration 6494, loss = 0.00348610\n",
      "Iteration 6495, loss = 0.00348510\n",
      "Iteration 6496, loss = 0.00348434\n",
      "Iteration 6497, loss = 0.00348369\n",
      "Iteration 6498, loss = 0.00348292\n",
      "Iteration 6499, loss = 0.00348200\n",
      "Iteration 6500, loss = 0.00348114\n",
      "Iteration 6501, loss = 0.00348113\n",
      "Iteration 6502, loss = 0.00347994\n",
      "Iteration 6503, loss = 0.00347931\n",
      "Iteration 6504, loss = 0.00347858\n",
      "Iteration 6505, loss = 0.00347790\n",
      "Iteration 6506, loss = 0.00347726\n",
      "Iteration 6507, loss = 0.00347654\n",
      "Iteration 6508, loss = 0.00347582\n",
      "Iteration 6509, loss = 0.00347534\n",
      "Iteration 6510, loss = 0.00347466\n",
      "Iteration 6511, loss = 0.00347400\n",
      "Iteration 6512, loss = 0.00347329\n",
      "Iteration 6513, loss = 0.00347279\n",
      "Iteration 6514, loss = 0.00347197\n",
      "Iteration 6515, loss = 0.00347131\n",
      "Iteration 6516, loss = 0.00347071\n",
      "Iteration 6517, loss = 0.00347012\n",
      "Iteration 6518, loss = 0.00346940\n",
      "Iteration 6519, loss = 0.00346877\n",
      "Iteration 6520, loss = 0.00346806\n",
      "Iteration 6521, loss = 0.00346736\n",
      "Iteration 6522, loss = 0.00346670\n",
      "Iteration 6523, loss = 0.00346626\n",
      "Iteration 6524, loss = 0.00346528\n",
      "Iteration 6525, loss = 0.00346451\n",
      "Iteration 6526, loss = 0.00346389\n",
      "Iteration 6527, loss = 0.00346311\n",
      "Iteration 6528, loss = 0.00346241\n",
      "Iteration 6529, loss = 0.00346171\n",
      "Iteration 6530, loss = 0.00346144\n",
      "Iteration 6531, loss = 0.00346034\n",
      "Iteration 6532, loss = 0.00345963\n",
      "Iteration 6533, loss = 0.00345890\n",
      "Iteration 6534, loss = 0.00345822\n",
      "Iteration 6535, loss = 0.00345752\n",
      "Iteration 6536, loss = 0.00345693\n",
      "Iteration 6537, loss = 0.00345616\n",
      "Iteration 6538, loss = 0.00345547\n",
      "Iteration 6539, loss = 0.00345474\n",
      "Iteration 6540, loss = 0.00345405\n",
      "Iteration 6541, loss = 0.00345339\n",
      "Iteration 6542, loss = 0.00345300\n",
      "Iteration 6543, loss = 0.00345206\n",
      "Iteration 6544, loss = 0.00345145\n",
      "Iteration 6545, loss = 0.00345074\n",
      "Iteration 6546, loss = 0.00345017\n",
      "Iteration 6547, loss = 0.00344934\n",
      "Iteration 6548, loss = 0.00344867\n",
      "Iteration 6549, loss = 0.00344793\n",
      "Iteration 6550, loss = 0.00344725\n",
      "Iteration 6551, loss = 0.00344657\n",
      "Iteration 6552, loss = 0.00344585\n",
      "Iteration 6553, loss = 0.00344517\n",
      "Iteration 6554, loss = 0.00344449\n",
      "Iteration 6555, loss = 0.00344374\n",
      "Iteration 6556, loss = 0.00344341\n",
      "Iteration 6557, loss = 0.00344226\n",
      "Iteration 6558, loss = 0.00344169\n",
      "Iteration 6559, loss = 0.00344090\n",
      "Iteration 6560, loss = 0.00344017\n",
      "Iteration 6561, loss = 0.00343936\n",
      "Iteration 6562, loss = 0.00343884\n",
      "Iteration 6563, loss = 0.00343797\n",
      "Iteration 6564, loss = 0.00343786\n",
      "Iteration 6565, loss = 0.00343656\n",
      "Iteration 6566, loss = 0.00343576\n",
      "Iteration 6567, loss = 0.00343541\n",
      "Iteration 6568, loss = 0.00343442\n",
      "Iteration 6569, loss = 0.00343378\n",
      "Iteration 6570, loss = 0.00343309\n",
      "Iteration 6571, loss = 0.00343242\n",
      "Iteration 6572, loss = 0.00343185\n",
      "Iteration 6573, loss = 0.00343123\n",
      "Iteration 6574, loss = 0.00343043\n",
      "Iteration 6575, loss = 0.00342982\n",
      "Iteration 6576, loss = 0.00342914\n",
      "Iteration 6577, loss = 0.00342847\n",
      "Iteration 6578, loss = 0.00342773\n",
      "Iteration 6579, loss = 0.00342711\n",
      "Iteration 6580, loss = 0.00342642\n",
      "Iteration 6581, loss = 0.00342573\n",
      "Iteration 6582, loss = 0.00342511\n",
      "Iteration 6583, loss = 0.00342454\n",
      "Iteration 6584, loss = 0.00342390\n",
      "Iteration 6585, loss = 0.00342320\n",
      "Iteration 6586, loss = 0.00342231\n",
      "Iteration 6587, loss = 0.00342168\n",
      "Iteration 6588, loss = 0.00342110\n",
      "Iteration 6589, loss = 0.00342032\n",
      "Iteration 6590, loss = 0.00341964\n",
      "Iteration 6591, loss = 0.00341904\n",
      "Iteration 6592, loss = 0.00341822\n",
      "Iteration 6593, loss = 0.00341787\n",
      "Iteration 6594, loss = 0.00341706\n",
      "Iteration 6595, loss = 0.00341629\n",
      "Iteration 6596, loss = 0.00341570\n",
      "Iteration 6597, loss = 0.00341523\n",
      "Iteration 6598, loss = 0.00341450\n",
      "Iteration 6599, loss = 0.00341364\n",
      "Iteration 6600, loss = 0.00341304\n",
      "Iteration 6601, loss = 0.00341228\n",
      "Iteration 6602, loss = 0.00341156\n",
      "Iteration 6603, loss = 0.00341084\n",
      "Iteration 6604, loss = 0.00341009\n",
      "Iteration 6605, loss = 0.00340941\n",
      "Iteration 6606, loss = 0.00340869\n",
      "Iteration 6607, loss = 0.00340815\n",
      "Iteration 6608, loss = 0.00340738\n",
      "Iteration 6609, loss = 0.00340677\n",
      "Iteration 6610, loss = 0.00340605\n",
      "Iteration 6611, loss = 0.00340554\n",
      "Iteration 6612, loss = 0.00340488\n",
      "Iteration 6613, loss = 0.00340408\n",
      "Iteration 6614, loss = 0.00340328\n",
      "Iteration 6615, loss = 0.00340265\n",
      "Iteration 6616, loss = 0.00340197\n",
      "Iteration 6617, loss = 0.00340139\n",
      "Iteration 6618, loss = 0.00340073\n",
      "Iteration 6619, loss = 0.00340010\n",
      "Iteration 6620, loss = 0.00339937\n",
      "Iteration 6621, loss = 0.00339855\n",
      "Iteration 6622, loss = 0.00339797\n",
      "Iteration 6623, loss = 0.00339728\n",
      "Iteration 6624, loss = 0.00339644\n",
      "Iteration 6625, loss = 0.00339573\n",
      "Iteration 6626, loss = 0.00339505\n",
      "Iteration 6627, loss = 0.00339450\n",
      "Iteration 6628, loss = 0.00339371\n",
      "Iteration 6629, loss = 0.00339311\n",
      "Iteration 6630, loss = 0.00339247\n",
      "Iteration 6631, loss = 0.00339182\n",
      "Iteration 6632, loss = 0.00339143\n",
      "Iteration 6633, loss = 0.00339049\n",
      "Iteration 6634, loss = 0.00338980\n",
      "Iteration 6635, loss = 0.00338916\n",
      "Iteration 6636, loss = 0.00338843\n",
      "Iteration 6637, loss = 0.00338817\n",
      "Iteration 6638, loss = 0.00338723\n",
      "Iteration 6639, loss = 0.00338657\n",
      "Iteration 6640, loss = 0.00338576\n",
      "Iteration 6641, loss = 0.00338514\n",
      "Iteration 6642, loss = 0.00338454\n",
      "Iteration 6643, loss = 0.00338381\n",
      "Iteration 6644, loss = 0.00338326\n",
      "Iteration 6645, loss = 0.00338266\n",
      "Iteration 6646, loss = 0.00338207\n",
      "Iteration 6647, loss = 0.00338133\n",
      "Iteration 6648, loss = 0.00338087\n",
      "Iteration 6649, loss = 0.00338002\n",
      "Iteration 6650, loss = 0.00337942\n",
      "Iteration 6651, loss = 0.00337887\n",
      "Iteration 6652, loss = 0.00337811\n",
      "Iteration 6653, loss = 0.00337777\n",
      "Iteration 6654, loss = 0.00337707\n",
      "Iteration 6655, loss = 0.00337636\n",
      "Iteration 6656, loss = 0.00337574\n",
      "Iteration 6657, loss = 0.00337518\n",
      "Iteration 6658, loss = 0.00337477\n",
      "Iteration 6659, loss = 0.00337397\n",
      "Iteration 6660, loss = 0.00337335\n",
      "Iteration 6661, loss = 0.00337287\n",
      "Iteration 6662, loss = 0.00337195\n",
      "Iteration 6663, loss = 0.00337140\n",
      "Iteration 6664, loss = 0.00337064\n",
      "Iteration 6665, loss = 0.00336998\n",
      "Iteration 6666, loss = 0.00336920\n",
      "Iteration 6667, loss = 0.00336858\n",
      "Iteration 6668, loss = 0.00336789\n",
      "Iteration 6669, loss = 0.00336720\n",
      "Iteration 6670, loss = 0.00336664\n",
      "Iteration 6671, loss = 0.00336604\n",
      "Iteration 6672, loss = 0.00336539\n",
      "Iteration 6673, loss = 0.00336466\n",
      "Iteration 6674, loss = 0.00336409\n",
      "Iteration 6675, loss = 0.00336345\n",
      "Iteration 6676, loss = 0.00336270\n",
      "Iteration 6677, loss = 0.00336200\n",
      "Iteration 6678, loss = 0.00336141\n",
      "Iteration 6679, loss = 0.00336069\n",
      "Iteration 6680, loss = 0.00335999\n",
      "Iteration 6681, loss = 0.00335939\n",
      "Iteration 6682, loss = 0.00335867\n",
      "Iteration 6683, loss = 0.00335799\n",
      "Iteration 6684, loss = 0.00335735\n",
      "Iteration 6685, loss = 0.00335669\n",
      "Iteration 6686, loss = 0.00335609\n",
      "Iteration 6687, loss = 0.00335577\n",
      "Iteration 6688, loss = 0.00335486\n",
      "Iteration 6689, loss = 0.00335426\n",
      "Iteration 6690, loss = 0.00335369\n",
      "Iteration 6691, loss = 0.00335308\n",
      "Iteration 6692, loss = 0.00335259\n",
      "Iteration 6693, loss = 0.00335207\n",
      "Iteration 6694, loss = 0.00335138\n",
      "Iteration 6695, loss = 0.00335075\n",
      "Iteration 6696, loss = 0.00335014\n",
      "Iteration 6697, loss = 0.00334963\n",
      "Iteration 6698, loss = 0.00334920\n",
      "Iteration 6699, loss = 0.00334844\n",
      "Iteration 6700, loss = 0.00334764\n",
      "Iteration 6701, loss = 0.00334694\n",
      "Iteration 6702, loss = 0.00334643\n",
      "Iteration 6703, loss = 0.00334567\n",
      "Iteration 6704, loss = 0.00334504\n",
      "Iteration 6705, loss = 0.00334435\n",
      "Iteration 6706, loss = 0.00334366\n",
      "Iteration 6707, loss = 0.00334299\n",
      "Iteration 6708, loss = 0.00334235\n",
      "Iteration 6709, loss = 0.00334166\n",
      "Iteration 6710, loss = 0.00334098\n",
      "Iteration 6711, loss = 0.00334049\n",
      "Iteration 6712, loss = 0.00333949\n",
      "Iteration 6713, loss = 0.00333882\n",
      "Iteration 6714, loss = 0.00333820\n",
      "Iteration 6715, loss = 0.00333757\n",
      "Iteration 6716, loss = 0.00333702\n",
      "Iteration 6717, loss = 0.00333643\n",
      "Iteration 6718, loss = 0.00333583\n",
      "Iteration 6719, loss = 0.00333506\n",
      "Iteration 6720, loss = 0.00333451\n",
      "Iteration 6721, loss = 0.00333362\n",
      "Iteration 6722, loss = 0.00333298\n",
      "Iteration 6723, loss = 0.00333226\n",
      "Iteration 6724, loss = 0.00333155\n",
      "Iteration 6725, loss = 0.00333122\n",
      "Iteration 6726, loss = 0.00333037\n",
      "Iteration 6727, loss = 0.00332961\n",
      "Iteration 6728, loss = 0.00332889\n",
      "Iteration 6729, loss = 0.00332847\n",
      "Iteration 6730, loss = 0.00332758\n",
      "Iteration 6731, loss = 0.00332707\n",
      "Iteration 6732, loss = 0.00332639\n",
      "Iteration 6733, loss = 0.00332594\n",
      "Iteration 6734, loss = 0.00332496\n",
      "Iteration 6735, loss = 0.00332428\n",
      "Iteration 6736, loss = 0.00332356\n",
      "Iteration 6737, loss = 0.00332316\n",
      "Iteration 6738, loss = 0.00332248\n",
      "Iteration 6739, loss = 0.00332163\n",
      "Iteration 6740, loss = 0.00332105\n",
      "Iteration 6741, loss = 0.00332037\n",
      "Iteration 6742, loss = 0.00331975\n",
      "Iteration 6743, loss = 0.00331922\n",
      "Iteration 6744, loss = 0.00331851\n",
      "Iteration 6745, loss = 0.00331794\n",
      "Iteration 6746, loss = 0.00331769\n",
      "Iteration 6747, loss = 0.00331683\n",
      "Iteration 6748, loss = 0.00331653\n",
      "Iteration 6749, loss = 0.00331564\n",
      "Iteration 6750, loss = 0.00331471\n",
      "Iteration 6751, loss = 0.00331382\n",
      "Iteration 6752, loss = 0.00331328\n",
      "Iteration 6753, loss = 0.00331285\n",
      "Iteration 6754, loss = 0.00331181\n",
      "Iteration 6755, loss = 0.00331115\n",
      "Iteration 6756, loss = 0.00331053\n",
      "Iteration 6757, loss = 0.00330985\n",
      "Iteration 6758, loss = 0.00330919\n",
      "Iteration 6759, loss = 0.00330857\n",
      "Iteration 6760, loss = 0.00330797\n",
      "Iteration 6761, loss = 0.00330733\n",
      "Iteration 6762, loss = 0.00330680\n",
      "Iteration 6763, loss = 0.00330627\n",
      "Iteration 6764, loss = 0.00330554\n",
      "Iteration 6765, loss = 0.00330493\n",
      "Iteration 6766, loss = 0.00330426\n",
      "Iteration 6767, loss = 0.00330367\n",
      "Iteration 6768, loss = 0.00330298\n",
      "Iteration 6769, loss = 0.00330260\n",
      "Iteration 6770, loss = 0.00330175\n",
      "Iteration 6771, loss = 0.00330103\n",
      "Iteration 6772, loss = 0.00330066\n",
      "Iteration 6773, loss = 0.00329980\n",
      "Iteration 6774, loss = 0.00329930\n",
      "Iteration 6775, loss = 0.00329882\n",
      "Iteration 6776, loss = 0.00329796\n",
      "Iteration 6777, loss = 0.00329728\n",
      "Iteration 6778, loss = 0.00329659\n",
      "Iteration 6779, loss = 0.00329601\n",
      "Iteration 6780, loss = 0.00329550\n",
      "Iteration 6781, loss = 0.00329476\n",
      "Iteration 6782, loss = 0.00329411\n",
      "Iteration 6783, loss = 0.00329360\n",
      "Iteration 6784, loss = 0.00329290\n",
      "Iteration 6785, loss = 0.00329240\n",
      "Iteration 6786, loss = 0.00329161\n",
      "Iteration 6787, loss = 0.00329094\n",
      "Iteration 6788, loss = 0.00329053\n",
      "Iteration 6789, loss = 0.00328990\n",
      "Iteration 6790, loss = 0.00328910\n",
      "Iteration 6791, loss = 0.00328831\n",
      "Iteration 6792, loss = 0.00328767\n",
      "Iteration 6793, loss = 0.00328703\n",
      "Iteration 6794, loss = 0.00328669\n",
      "Iteration 6795, loss = 0.00328577\n",
      "Iteration 6796, loss = 0.00328508\n",
      "Iteration 6797, loss = 0.00328451\n",
      "Iteration 6798, loss = 0.00328388\n",
      "Iteration 6799, loss = 0.00328327\n",
      "Iteration 6800, loss = 0.00328263\n",
      "Iteration 6801, loss = 0.00328204\n",
      "Iteration 6802, loss = 0.00328144\n",
      "Iteration 6803, loss = 0.00328079\n",
      "Iteration 6804, loss = 0.00328022\n",
      "Iteration 6805, loss = 0.00327963\n",
      "Iteration 6806, loss = 0.00327918\n",
      "Iteration 6807, loss = 0.00327839\n",
      "Iteration 6808, loss = 0.00327831\n",
      "Iteration 6809, loss = 0.00327738\n",
      "Iteration 6810, loss = 0.00327654\n",
      "Iteration 6811, loss = 0.00327597\n",
      "Iteration 6812, loss = 0.00327530\n",
      "Iteration 6813, loss = 0.00327455\n",
      "Iteration 6814, loss = 0.00327388\n",
      "Iteration 6815, loss = 0.00327318\n",
      "Iteration 6816, loss = 0.00327264\n",
      "Iteration 6817, loss = 0.00327184\n",
      "Iteration 6818, loss = 0.00327125\n",
      "Iteration 6819, loss = 0.00327061\n",
      "Iteration 6820, loss = 0.00327050\n",
      "Iteration 6821, loss = 0.00326912\n",
      "Iteration 6822, loss = 0.00326844\n",
      "Iteration 6823, loss = 0.00326766\n",
      "Iteration 6824, loss = 0.00326715\n",
      "Iteration 6825, loss = 0.00326649\n",
      "Iteration 6826, loss = 0.00326593\n",
      "Iteration 6827, loss = 0.00326507\n",
      "Iteration 6828, loss = 0.00326460\n",
      "Iteration 6829, loss = 0.00326376\n",
      "Iteration 6830, loss = 0.00326313\n",
      "Iteration 6831, loss = 0.00326273\n",
      "Iteration 6832, loss = 0.00326173\n",
      "Iteration 6833, loss = 0.00326095\n",
      "Iteration 6834, loss = 0.00326045\n",
      "Iteration 6835, loss = 0.00325947\n",
      "Iteration 6836, loss = 0.00325878\n",
      "Iteration 6837, loss = 0.00325809\n",
      "Iteration 6838, loss = 0.00325731\n",
      "Iteration 6839, loss = 0.00325679\n",
      "Iteration 6840, loss = 0.00325624\n",
      "Iteration 6841, loss = 0.00325569\n",
      "Iteration 6842, loss = 0.00325498\n",
      "Iteration 6843, loss = 0.00325416\n",
      "Iteration 6844, loss = 0.00325379\n",
      "Iteration 6845, loss = 0.00325283\n",
      "Iteration 6846, loss = 0.00325224\n",
      "Iteration 6847, loss = 0.00325149\n",
      "Iteration 6848, loss = 0.00325105\n",
      "Iteration 6849, loss = 0.00325030\n",
      "Iteration 6850, loss = 0.00324947\n",
      "Iteration 6851, loss = 0.00324892\n",
      "Iteration 6852, loss = 0.00324824\n",
      "Iteration 6853, loss = 0.00324760\n",
      "Iteration 6854, loss = 0.00324705\n",
      "Iteration 6855, loss = 0.00324631\n",
      "Iteration 6856, loss = 0.00324565\n",
      "Iteration 6857, loss = 0.00324500\n",
      "Iteration 6858, loss = 0.00324436\n",
      "Iteration 6859, loss = 0.00324373\n",
      "Iteration 6860, loss = 0.00324312\n",
      "Iteration 6861, loss = 0.00324238\n",
      "Iteration 6862, loss = 0.00324207\n",
      "Iteration 6863, loss = 0.00324127\n",
      "Iteration 6864, loss = 0.00324053\n",
      "Iteration 6865, loss = 0.00323989\n",
      "Iteration 6866, loss = 0.00323926\n",
      "Iteration 6867, loss = 0.00323860\n",
      "Iteration 6868, loss = 0.00323803\n",
      "Iteration 6869, loss = 0.00323745\n",
      "Iteration 6870, loss = 0.00323684\n",
      "Iteration 6871, loss = 0.00323642\n",
      "Iteration 6872, loss = 0.00323581\n",
      "Iteration 6873, loss = 0.00323508\n",
      "Iteration 6874, loss = 0.00323449\n",
      "Iteration 6875, loss = 0.00323395\n",
      "Iteration 6876, loss = 0.00323342\n",
      "Iteration 6877, loss = 0.00323286\n",
      "Iteration 6878, loss = 0.00323230\n",
      "Iteration 6879, loss = 0.00323177\n",
      "Iteration 6880, loss = 0.00323128\n",
      "Iteration 6881, loss = 0.00323080\n",
      "Iteration 6882, loss = 0.00323021\n",
      "Iteration 6883, loss = 0.00322968\n",
      "Iteration 6884, loss = 0.00322911\n",
      "Iteration 6885, loss = 0.00322870\n",
      "Iteration 6886, loss = 0.00322804\n",
      "Iteration 6887, loss = 0.00322759\n",
      "Iteration 6888, loss = 0.00322688\n",
      "Iteration 6889, loss = 0.00322633\n",
      "Iteration 6890, loss = 0.00322572\n",
      "Iteration 6891, loss = 0.00322510\n",
      "Iteration 6892, loss = 0.00322434\n",
      "Iteration 6893, loss = 0.00322369\n",
      "Iteration 6894, loss = 0.00322333\n",
      "Iteration 6895, loss = 0.00322252\n",
      "Iteration 6896, loss = 0.00322210\n",
      "Iteration 6897, loss = 0.00322147\n",
      "Iteration 6898, loss = 0.00322074\n",
      "Iteration 6899, loss = 0.00322009\n",
      "Iteration 6900, loss = 0.00321935\n",
      "Iteration 6901, loss = 0.00321857\n",
      "Iteration 6902, loss = 0.00321835\n",
      "Iteration 6903, loss = 0.00321783\n",
      "Iteration 6904, loss = 0.00321726\n",
      "Iteration 6905, loss = 0.00321647\n",
      "Iteration 6906, loss = 0.00321564\n",
      "Iteration 6907, loss = 0.00321524\n",
      "Iteration 6908, loss = 0.00321445\n",
      "Iteration 6909, loss = 0.00321380\n",
      "Iteration 6910, loss = 0.00321354\n",
      "Iteration 6911, loss = 0.00321262\n",
      "Iteration 6912, loss = 0.00321185\n",
      "Iteration 6913, loss = 0.00321124\n",
      "Iteration 6914, loss = 0.00321066\n",
      "Iteration 6915, loss = 0.00320999\n",
      "Iteration 6916, loss = 0.00320935\n",
      "Iteration 6917, loss = 0.00320895\n",
      "Iteration 6918, loss = 0.00320824\n",
      "Iteration 6919, loss = 0.00320757\n",
      "Iteration 6920, loss = 0.00320693\n",
      "Iteration 6921, loss = 0.00320636\n",
      "Iteration 6922, loss = 0.00320568\n",
      "Iteration 6923, loss = 0.00320498\n",
      "Iteration 6924, loss = 0.00320447\n",
      "Iteration 6925, loss = 0.00320372\n",
      "Iteration 6926, loss = 0.00320302\n",
      "Iteration 6927, loss = 0.00320232\n",
      "Iteration 6928, loss = 0.00320214\n",
      "Iteration 6929, loss = 0.00320104\n",
      "Iteration 6930, loss = 0.00320056\n",
      "Iteration 6931, loss = 0.00319996\n",
      "Iteration 6932, loss = 0.00319923\n",
      "Iteration 6933, loss = 0.00319861\n",
      "Iteration 6934, loss = 0.00319809\n",
      "Iteration 6935, loss = 0.00319741\n",
      "Iteration 6936, loss = 0.00319679\n",
      "Iteration 6937, loss = 0.00319615\n",
      "Iteration 6938, loss = 0.00319553\n",
      "Iteration 6939, loss = 0.00319506\n",
      "Iteration 6940, loss = 0.00319431\n",
      "Iteration 6941, loss = 0.00319377\n",
      "Iteration 6942, loss = 0.00319321\n",
      "Iteration 6943, loss = 0.00319271\n",
      "Iteration 6944, loss = 0.00319237\n",
      "Iteration 6945, loss = 0.00319160\n",
      "Iteration 6946, loss = 0.00319120\n",
      "Iteration 6947, loss = 0.00319057\n",
      "Iteration 6948, loss = 0.00318981\n",
      "Iteration 6949, loss = 0.00318911\n",
      "Iteration 6950, loss = 0.00318863\n",
      "Iteration 6951, loss = 0.00318795\n",
      "Iteration 6952, loss = 0.00318745\n",
      "Iteration 6953, loss = 0.00318683\n",
      "Iteration 6954, loss = 0.00318645\n",
      "Iteration 6955, loss = 0.00318567\n",
      "Iteration 6956, loss = 0.00318510\n",
      "Iteration 6957, loss = 0.00318451\n",
      "Iteration 6958, loss = 0.00318395\n",
      "Iteration 6959, loss = 0.00318347\n",
      "Iteration 6960, loss = 0.00318274\n",
      "Iteration 6961, loss = 0.00318225\n",
      "Iteration 6962, loss = 0.00318164\n",
      "Iteration 6963, loss = 0.00318102\n",
      "Iteration 6964, loss = 0.00318047\n",
      "Iteration 6965, loss = 0.00318011\n",
      "Iteration 6966, loss = 0.00317937\n",
      "Iteration 6967, loss = 0.00317886\n",
      "Iteration 6968, loss = 0.00317829\n",
      "Iteration 6969, loss = 0.00317810\n",
      "Iteration 6970, loss = 0.00317741\n",
      "Iteration 6971, loss = 0.00317674\n",
      "Iteration 6972, loss = 0.00317619\n",
      "Iteration 6973, loss = 0.00317567\n",
      "Iteration 6974, loss = 0.00317520\n",
      "Iteration 6975, loss = 0.00317459\n",
      "Iteration 6976, loss = 0.00317401\n",
      "Iteration 6977, loss = 0.00317343\n",
      "Iteration 6978, loss = 0.00317276\n",
      "Iteration 6979, loss = 0.00317207\n",
      "Iteration 6980, loss = 0.00317154\n",
      "Iteration 6981, loss = 0.00317080\n",
      "Iteration 6982, loss = 0.00317008\n",
      "Iteration 6983, loss = 0.00316953\n",
      "Iteration 6984, loss = 0.00316887\n",
      "Iteration 6985, loss = 0.00316821\n",
      "Iteration 6986, loss = 0.00316748\n",
      "Iteration 6987, loss = 0.00316717\n",
      "Iteration 6988, loss = 0.00316628\n",
      "Iteration 6989, loss = 0.00316576\n",
      "Iteration 6990, loss = 0.00316510\n",
      "Iteration 6991, loss = 0.00316437\n",
      "Iteration 6992, loss = 0.00316369\n",
      "Iteration 6993, loss = 0.00316308\n",
      "Iteration 6994, loss = 0.00316248\n",
      "Iteration 6995, loss = 0.00316186\n",
      "Iteration 6996, loss = 0.00316117\n",
      "Iteration 6997, loss = 0.00316067\n",
      "Iteration 6998, loss = 0.00316008\n",
      "Iteration 6999, loss = 0.00315936\n",
      "Iteration 7000, loss = 0.00315875\n",
      "Iteration 7001, loss = 0.00315822\n",
      "Iteration 7002, loss = 0.00315768\n",
      "Iteration 7003, loss = 0.00315700\n",
      "Iteration 7004, loss = 0.00315645\n",
      "Iteration 7005, loss = 0.00315585\n",
      "Iteration 7006, loss = 0.00315504\n",
      "Iteration 7007, loss = 0.00315477\n",
      "Iteration 7008, loss = 0.00315397\n",
      "Iteration 7009, loss = 0.00315370\n",
      "Iteration 7010, loss = 0.00315282\n",
      "Iteration 7011, loss = 0.00315222\n",
      "Iteration 7012, loss = 0.00315165\n",
      "Iteration 7013, loss = 0.00315117\n",
      "Iteration 7014, loss = 0.00315048\n",
      "Iteration 7015, loss = 0.00315008\n",
      "Iteration 7016, loss = 0.00314943\n",
      "Iteration 7017, loss = 0.00314886\n",
      "Iteration 7018, loss = 0.00314832\n",
      "Iteration 7019, loss = 0.00314786\n",
      "Iteration 7020, loss = 0.00314726\n",
      "Iteration 7021, loss = 0.00314675\n",
      "Iteration 7022, loss = 0.00314616\n",
      "Iteration 7023, loss = 0.00314568\n",
      "Iteration 7024, loss = 0.00314515\n",
      "Iteration 7025, loss = 0.00314463\n",
      "Iteration 7026, loss = 0.00314418\n",
      "Iteration 7027, loss = 0.00314356\n",
      "Iteration 7028, loss = 0.00314298\n",
      "Iteration 7029, loss = 0.00314282\n",
      "Iteration 7030, loss = 0.00314183\n",
      "Iteration 7031, loss = 0.00314107\n",
      "Iteration 7032, loss = 0.00314049\n",
      "Iteration 7033, loss = 0.00314003\n",
      "Iteration 7034, loss = 0.00313931\n",
      "Iteration 7035, loss = 0.00313874\n",
      "Iteration 7036, loss = 0.00313813\n",
      "Iteration 7037, loss = 0.00313758\n",
      "Iteration 7038, loss = 0.00313706\n",
      "Iteration 7039, loss = 0.00313650\n",
      "Iteration 7040, loss = 0.00313605\n",
      "Iteration 7041, loss = 0.00313536\n",
      "Iteration 7042, loss = 0.00313495\n",
      "Iteration 7043, loss = 0.00313430\n",
      "Iteration 7044, loss = 0.00313371\n",
      "Iteration 7045, loss = 0.00313322\n",
      "Iteration 7046, loss = 0.00313267\n",
      "Iteration 7047, loss = 0.00313218\n",
      "Iteration 7048, loss = 0.00313168\n",
      "Iteration 7049, loss = 0.00313111\n",
      "Iteration 7050, loss = 0.00313106\n",
      "Iteration 7051, loss = 0.00312998\n",
      "Iteration 7052, loss = 0.00312925\n",
      "Iteration 7053, loss = 0.00312866\n",
      "Iteration 7054, loss = 0.00312807\n",
      "Iteration 7055, loss = 0.00312751\n",
      "Iteration 7056, loss = 0.00312676\n",
      "Iteration 7057, loss = 0.00312614\n",
      "Iteration 7058, loss = 0.00312546\n",
      "Iteration 7059, loss = 0.00312468\n",
      "Iteration 7060, loss = 0.00312405\n",
      "Iteration 7061, loss = 0.00312342\n",
      "Iteration 7062, loss = 0.00312344\n",
      "Iteration 7063, loss = 0.00312218\n",
      "Iteration 7064, loss = 0.00312156\n",
      "Iteration 7065, loss = 0.00312087\n",
      "Iteration 7066, loss = 0.00312024\n",
      "Iteration 7067, loss = 0.00311968\n",
      "Iteration 7068, loss = 0.00311909\n",
      "Iteration 7069, loss = 0.00311835\n",
      "Iteration 7070, loss = 0.00311779\n",
      "Iteration 7071, loss = 0.00311727\n",
      "Iteration 7072, loss = 0.00311667\n",
      "Iteration 7073, loss = 0.00311607\n",
      "Iteration 7074, loss = 0.00311551\n",
      "Iteration 7075, loss = 0.00311502\n",
      "Iteration 7076, loss = 0.00311437\n",
      "Iteration 7077, loss = 0.00311387\n",
      "Iteration 7078, loss = 0.00311324\n",
      "Iteration 7079, loss = 0.00311260\n",
      "Iteration 7080, loss = 0.00311202\n",
      "Iteration 7081, loss = 0.00311145\n",
      "Iteration 7082, loss = 0.00311096\n",
      "Iteration 7083, loss = 0.00311034\n",
      "Iteration 7084, loss = 0.00310990\n",
      "Iteration 7085, loss = 0.00310931\n",
      "Iteration 7086, loss = 0.00310868\n",
      "Iteration 7087, loss = 0.00310805\n",
      "Iteration 7088, loss = 0.00310736\n",
      "Iteration 7089, loss = 0.00310664\n",
      "Iteration 7090, loss = 0.00310642\n",
      "Iteration 7091, loss = 0.00310548\n",
      "Iteration 7092, loss = 0.00310500\n",
      "Iteration 7093, loss = 0.00310443\n",
      "Iteration 7094, loss = 0.00310358\n",
      "Iteration 7095, loss = 0.00310304\n",
      "Iteration 7096, loss = 0.00310247\n",
      "Iteration 7097, loss = 0.00310170\n",
      "Iteration 7098, loss = 0.00310118\n",
      "Iteration 7099, loss = 0.00310048\n",
      "Iteration 7100, loss = 0.00309987\n",
      "Iteration 7101, loss = 0.00309954\n",
      "Iteration 7102, loss = 0.00309866\n",
      "Iteration 7103, loss = 0.00309799\n",
      "Iteration 7104, loss = 0.00309760\n",
      "Iteration 7105, loss = 0.00309686\n",
      "Iteration 7106, loss = 0.00309637\n",
      "Iteration 7107, loss = 0.00309582\n",
      "Iteration 7108, loss = 0.00309540\n",
      "Iteration 7109, loss = 0.00309479\n",
      "Iteration 7110, loss = 0.00309410\n",
      "Iteration 7111, loss = 0.00309353\n",
      "Iteration 7112, loss = 0.00309301\n",
      "Iteration 7113, loss = 0.00309234\n",
      "Iteration 7114, loss = 0.00309177\n",
      "Iteration 7115, loss = 0.00309119\n",
      "Iteration 7116, loss = 0.00309085\n",
      "Iteration 7117, loss = 0.00309018\n",
      "Iteration 7118, loss = 0.00308975\n",
      "Iteration 7119, loss = 0.00308916\n",
      "Iteration 7120, loss = 0.00308843\n",
      "Iteration 7121, loss = 0.00308790\n",
      "Iteration 7122, loss = 0.00308726\n",
      "Iteration 7123, loss = 0.00308681\n",
      "Iteration 7124, loss = 0.00308613\n",
      "Iteration 7125, loss = 0.00308546\n",
      "Iteration 7126, loss = 0.00308476\n",
      "Iteration 7127, loss = 0.00308403\n",
      "Iteration 7128, loss = 0.00308343\n",
      "Iteration 7129, loss = 0.00308276\n",
      "Iteration 7130, loss = 0.00308216\n",
      "Iteration 7131, loss = 0.00308163\n",
      "Iteration 7132, loss = 0.00308132\n",
      "Iteration 7133, loss = 0.00308050\n",
      "Iteration 7134, loss = 0.00307995\n",
      "Iteration 7135, loss = 0.00307953\n",
      "Iteration 7136, loss = 0.00307877\n",
      "Iteration 7137, loss = 0.00307816\n",
      "Iteration 7138, loss = 0.00307758\n",
      "Iteration 7139, loss = 0.00307700\n",
      "Iteration 7140, loss = 0.00307648\n",
      "Iteration 7141, loss = 0.00307653\n",
      "Iteration 7142, loss = 0.00307542\n",
      "Iteration 7143, loss = 0.00307490\n",
      "Iteration 7144, loss = 0.00307439\n",
      "Iteration 7145, loss = 0.00307398\n",
      "Iteration 7146, loss = 0.00307316\n",
      "Iteration 7147, loss = 0.00307288\n",
      "Iteration 7148, loss = 0.00307216\n",
      "Iteration 7149, loss = 0.00307164\n",
      "Iteration 7150, loss = 0.00307113\n",
      "Iteration 7151, loss = 0.00307073\n",
      "Iteration 7152, loss = 0.00307027\n",
      "Iteration 7153, loss = 0.00306986\n",
      "Iteration 7154, loss = 0.00306915\n",
      "Iteration 7155, loss = 0.00306865\n",
      "Iteration 7156, loss = 0.00306806\n",
      "Iteration 7157, loss = 0.00306766\n",
      "Iteration 7158, loss = 0.00306700\n",
      "Iteration 7159, loss = 0.00306653\n",
      "Iteration 7160, loss = 0.00306600\n",
      "Iteration 7161, loss = 0.00306519\n",
      "Iteration 7162, loss = 0.00306458\n",
      "Iteration 7163, loss = 0.00306406\n",
      "Iteration 7164, loss = 0.00306352\n",
      "Iteration 7165, loss = 0.00306293\n",
      "Iteration 7166, loss = 0.00306229\n",
      "Iteration 7167, loss = 0.00306175\n",
      "Iteration 7168, loss = 0.00306133\n",
      "Iteration 7169, loss = 0.00306058\n",
      "Iteration 7170, loss = 0.00306012\n",
      "Iteration 7171, loss = 0.00305947\n",
      "Iteration 7172, loss = 0.00305902\n",
      "Iteration 7173, loss = 0.00305838\n",
      "Iteration 7174, loss = 0.00305782\n",
      "Iteration 7175, loss = 0.00305720\n",
      "Iteration 7176, loss = 0.00305660\n",
      "Iteration 7177, loss = 0.00305606\n",
      "Iteration 7178, loss = 0.00305556\n",
      "Iteration 7179, loss = 0.00305532\n",
      "Iteration 7180, loss = 0.00305438\n",
      "Iteration 7181, loss = 0.00305385\n",
      "Iteration 7182, loss = 0.00305325\n",
      "Iteration 7183, loss = 0.00305285\n",
      "Iteration 7184, loss = 0.00305244\n",
      "Iteration 7185, loss = 0.00305154\n",
      "Iteration 7186, loss = 0.00305110\n",
      "Iteration 7187, loss = 0.00305055\n",
      "Iteration 7188, loss = 0.00304987\n",
      "Iteration 7189, loss = 0.00304936\n",
      "Iteration 7190, loss = 0.00304878\n",
      "Iteration 7191, loss = 0.00304838\n",
      "Iteration 7192, loss = 0.00304770\n",
      "Iteration 7193, loss = 0.00304724\n",
      "Iteration 7194, loss = 0.00304659\n",
      "Iteration 7195, loss = 0.00304609\n",
      "Iteration 7196, loss = 0.00304593\n",
      "Iteration 7197, loss = 0.00304473\n",
      "Iteration 7198, loss = 0.00304414\n",
      "Iteration 7199, loss = 0.00304363\n",
      "Iteration 7200, loss = 0.00304304\n",
      "Iteration 7201, loss = 0.00304241\n",
      "Iteration 7202, loss = 0.00304188\n",
      "Iteration 7203, loss = 0.00304134\n",
      "Iteration 7204, loss = 0.00304055\n",
      "Iteration 7205, loss = 0.00303999\n",
      "Iteration 7206, loss = 0.00303928\n",
      "Iteration 7207, loss = 0.00303862\n",
      "Iteration 7208, loss = 0.00303811\n",
      "Iteration 7209, loss = 0.00303751\n",
      "Iteration 7210, loss = 0.00303723\n",
      "Iteration 7211, loss = 0.00303638\n",
      "Iteration 7212, loss = 0.00303587\n",
      "Iteration 7213, loss = 0.00303524\n",
      "Iteration 7214, loss = 0.00303469\n",
      "Iteration 7215, loss = 0.00303414\n",
      "Iteration 7216, loss = 0.00303363\n",
      "Iteration 7217, loss = 0.00303310\n",
      "Iteration 7218, loss = 0.00303257\n",
      "Iteration 7219, loss = 0.00303198\n",
      "Iteration 7220, loss = 0.00303147\n",
      "Iteration 7221, loss = 0.00303091\n",
      "Iteration 7222, loss = 0.00303047\n",
      "Iteration 7223, loss = 0.00302981\n",
      "Iteration 7224, loss = 0.00302932\n",
      "Iteration 7225, loss = 0.00302891\n",
      "Iteration 7226, loss = 0.00302830\n",
      "Iteration 7227, loss = 0.00302777\n",
      "Iteration 7228, loss = 0.00302724\n",
      "Iteration 7229, loss = 0.00302673\n",
      "Iteration 7230, loss = 0.00302625\n",
      "Iteration 7231, loss = 0.00302563\n",
      "Iteration 7232, loss = 0.00302522\n",
      "Iteration 7233, loss = 0.00302482\n",
      "Iteration 7234, loss = 0.00302410\n",
      "Iteration 7235, loss = 0.00302349\n",
      "Iteration 7236, loss = 0.00302289\n",
      "Iteration 7237, loss = 0.00302235\n",
      "Iteration 7238, loss = 0.00302183\n",
      "Iteration 7239, loss = 0.00302126\n",
      "Iteration 7240, loss = 0.00302061\n",
      "Iteration 7241, loss = 0.00302020\n",
      "Iteration 7242, loss = 0.00301957\n",
      "Iteration 7243, loss = 0.00301922\n",
      "Iteration 7244, loss = 0.00301892\n",
      "Iteration 7245, loss = 0.00301814\n",
      "Iteration 7246, loss = 0.00301759\n",
      "Iteration 7247, loss = 0.00301715\n",
      "Iteration 7248, loss = 0.00301656\n",
      "Iteration 7249, loss = 0.00301617\n",
      "Iteration 7250, loss = 0.00301561\n",
      "Iteration 7251, loss = 0.00301499\n",
      "Iteration 7252, loss = 0.00301445\n",
      "Iteration 7253, loss = 0.00301403\n",
      "Iteration 7254, loss = 0.00301342\n",
      "Iteration 7255, loss = 0.00301281\n",
      "Iteration 7256, loss = 0.00301217\n",
      "Iteration 7257, loss = 0.00301175\n",
      "Iteration 7258, loss = 0.00301148\n",
      "Iteration 7259, loss = 0.00301084\n",
      "Iteration 7260, loss = 0.00301054\n",
      "Iteration 7261, loss = 0.00300989\n",
      "Iteration 7262, loss = 0.00300936\n",
      "Iteration 7263, loss = 0.00300869\n",
      "Iteration 7264, loss = 0.00300806\n",
      "Iteration 7265, loss = 0.00300761\n",
      "Iteration 7266, loss = 0.00300705\n",
      "Iteration 7267, loss = 0.00300653\n",
      "Iteration 7268, loss = 0.00300601\n",
      "Iteration 7269, loss = 0.00300542\n",
      "Iteration 7270, loss = 0.00300490\n",
      "Iteration 7271, loss = 0.00300443\n",
      "Iteration 7272, loss = 0.00300405\n",
      "Iteration 7273, loss = 0.00300364\n",
      "Iteration 7274, loss = 0.00300303\n",
      "Iteration 7275, loss = 0.00300231\n",
      "Iteration 7276, loss = 0.00300195\n",
      "Iteration 7277, loss = 0.00300150\n",
      "Iteration 7278, loss = 0.00300078\n",
      "Iteration 7279, loss = 0.00300031\n",
      "Iteration 7280, loss = 0.00299961\n",
      "Iteration 7281, loss = 0.00299904\n",
      "Iteration 7282, loss = 0.00299839\n",
      "Iteration 7283, loss = 0.00299796\n",
      "Iteration 7284, loss = 0.00299726\n",
      "Iteration 7285, loss = 0.00299661\n",
      "Iteration 7286, loss = 0.00299595\n",
      "Iteration 7287, loss = 0.00299532\n",
      "Iteration 7288, loss = 0.00299480\n",
      "Iteration 7289, loss = 0.00299462\n",
      "Iteration 7290, loss = 0.00299392\n",
      "Iteration 7291, loss = 0.00299365\n",
      "Iteration 7292, loss = 0.00299337\n",
      "Iteration 7293, loss = 0.00299233\n",
      "Iteration 7294, loss = 0.00299177\n",
      "Iteration 7295, loss = 0.00299105\n",
      "Iteration 7296, loss = 0.00299055\n",
      "Iteration 7297, loss = 0.00298989\n",
      "Iteration 7298, loss = 0.00298921\n",
      "Iteration 7299, loss = 0.00298860\n",
      "Iteration 7300, loss = 0.00298797\n",
      "Iteration 7301, loss = 0.00298744\n",
      "Iteration 7302, loss = 0.00298705\n",
      "Iteration 7303, loss = 0.00298641\n",
      "Iteration 7304, loss = 0.00298615\n",
      "Iteration 7305, loss = 0.00298528\n",
      "Iteration 7306, loss = 0.00298472\n",
      "Iteration 7307, loss = 0.00298411\n",
      "Iteration 7308, loss = 0.00298347\n",
      "Iteration 7309, loss = 0.00298315\n",
      "Iteration 7310, loss = 0.00298257\n",
      "Iteration 7311, loss = 0.00298216\n",
      "Iteration 7312, loss = 0.00298142\n",
      "Iteration 7313, loss = 0.00298071\n",
      "Iteration 7314, loss = 0.00298019\n",
      "Iteration 7315, loss = 0.00297950\n",
      "Iteration 7316, loss = 0.00297891\n",
      "Iteration 7317, loss = 0.00297840\n",
      "Iteration 7318, loss = 0.00297756\n",
      "Iteration 7319, loss = 0.00297687\n",
      "Iteration 7320, loss = 0.00297621\n",
      "Iteration 7321, loss = 0.00297573\n",
      "Iteration 7322, loss = 0.00297547\n",
      "Iteration 7323, loss = 0.00297473\n",
      "Iteration 7324, loss = 0.00297421\n",
      "Iteration 7325, loss = 0.00297370\n",
      "Iteration 7326, loss = 0.00297335\n",
      "Iteration 7327, loss = 0.00297277\n",
      "Iteration 7328, loss = 0.00297206\n",
      "Iteration 7329, loss = 0.00297155\n",
      "Iteration 7330, loss = 0.00297100\n",
      "Iteration 7331, loss = 0.00297038\n",
      "Iteration 7332, loss = 0.00296979\n",
      "Iteration 7333, loss = 0.00296926\n",
      "Iteration 7334, loss = 0.00296850\n",
      "Iteration 7335, loss = 0.00296793\n",
      "Iteration 7336, loss = 0.00296758\n",
      "Iteration 7337, loss = 0.00296676\n",
      "Iteration 7338, loss = 0.00296612\n",
      "Iteration 7339, loss = 0.00296557\n",
      "Iteration 7340, loss = 0.00296517\n",
      "Iteration 7341, loss = 0.00296454\n",
      "Iteration 7342, loss = 0.00296380\n",
      "Iteration 7343, loss = 0.00296327\n",
      "Iteration 7344, loss = 0.00296284\n",
      "Iteration 7345, loss = 0.00296233\n",
      "Iteration 7346, loss = 0.00296166\n",
      "Iteration 7347, loss = 0.00296128\n",
      "Iteration 7348, loss = 0.00296066\n",
      "Iteration 7349, loss = 0.00296016\n",
      "Iteration 7350, loss = 0.00295964\n",
      "Iteration 7351, loss = 0.00295919\n",
      "Iteration 7352, loss = 0.00295869\n",
      "Iteration 7353, loss = 0.00295824\n",
      "Iteration 7354, loss = 0.00295778\n",
      "Iteration 7355, loss = 0.00295730\n",
      "Iteration 7356, loss = 0.00295675\n",
      "Iteration 7357, loss = 0.00295628\n",
      "Iteration 7358, loss = 0.00295570\n",
      "Iteration 7359, loss = 0.00295521\n",
      "Iteration 7360, loss = 0.00295470\n",
      "Iteration 7361, loss = 0.00295418\n",
      "Iteration 7362, loss = 0.00295370\n",
      "Iteration 7363, loss = 0.00295330\n",
      "Iteration 7364, loss = 0.00295270\n",
      "Iteration 7365, loss = 0.00295217\n",
      "Iteration 7366, loss = 0.00295157\n",
      "Iteration 7367, loss = 0.00295104\n",
      "Iteration 7368, loss = 0.00295039\n",
      "Iteration 7369, loss = 0.00295000\n",
      "Iteration 7370, loss = 0.00294941\n",
      "Iteration 7371, loss = 0.00294898\n",
      "Iteration 7372, loss = 0.00294828\n",
      "Iteration 7373, loss = 0.00294798\n",
      "Iteration 7374, loss = 0.00294719\n",
      "Iteration 7375, loss = 0.00294671\n",
      "Iteration 7376, loss = 0.00294618\n",
      "Iteration 7377, loss = 0.00294568\n",
      "Iteration 7378, loss = 0.00294512\n",
      "Iteration 7379, loss = 0.00294491\n",
      "Iteration 7380, loss = 0.00294418\n",
      "Iteration 7381, loss = 0.00294350\n",
      "Iteration 7382, loss = 0.00294302\n",
      "Iteration 7383, loss = 0.00294247\n",
      "Iteration 7384, loss = 0.00294194\n",
      "Iteration 7385, loss = 0.00294141\n",
      "Iteration 7386, loss = 0.00294093\n",
      "Iteration 7387, loss = 0.00294042\n",
      "Iteration 7388, loss = 0.00293981\n",
      "Iteration 7389, loss = 0.00293938\n",
      "Iteration 7390, loss = 0.00293876\n",
      "Iteration 7391, loss = 0.00293830\n",
      "Iteration 7392, loss = 0.00293795\n",
      "Iteration 7393, loss = 0.00293736\n",
      "Iteration 7394, loss = 0.00293694\n",
      "Iteration 7395, loss = 0.00293628\n",
      "Iteration 7396, loss = 0.00293583\n",
      "Iteration 7397, loss = 0.00293528\n",
      "Iteration 7398, loss = 0.00293471\n",
      "Iteration 7399, loss = 0.00293426\n",
      "Iteration 7400, loss = 0.00293366\n",
      "Iteration 7401, loss = 0.00293314\n",
      "Iteration 7402, loss = 0.00293269\n",
      "Iteration 7403, loss = 0.00293207\n",
      "Iteration 7404, loss = 0.00293152\n",
      "Iteration 7405, loss = 0.00293101\n",
      "Iteration 7406, loss = 0.00293047\n",
      "Iteration 7407, loss = 0.00293012\n",
      "Iteration 7408, loss = 0.00292955\n",
      "Iteration 7409, loss = 0.00292891\n",
      "Iteration 7410, loss = 0.00292820\n",
      "Iteration 7411, loss = 0.00292831\n",
      "Iteration 7412, loss = 0.00292730\n",
      "Iteration 7413, loss = 0.00292663\n",
      "Iteration 7414, loss = 0.00292624\n",
      "Iteration 7415, loss = 0.00292545\n",
      "Iteration 7416, loss = 0.00292493\n",
      "Iteration 7417, loss = 0.00292436\n",
      "Iteration 7418, loss = 0.00292376\n",
      "Iteration 7419, loss = 0.00292308\n",
      "Iteration 7420, loss = 0.00292244\n",
      "Iteration 7421, loss = 0.00292186\n",
      "Iteration 7422, loss = 0.00292166\n",
      "Iteration 7423, loss = 0.00292083\n",
      "Iteration 7424, loss = 0.00292045\n",
      "Iteration 7425, loss = 0.00291976\n",
      "Iteration 7426, loss = 0.00291922\n",
      "Iteration 7427, loss = 0.00291861\n",
      "Iteration 7428, loss = 0.00291808\n",
      "Iteration 7429, loss = 0.00291752\n",
      "Iteration 7430, loss = 0.00291706\n",
      "Iteration 7431, loss = 0.00291632\n",
      "Iteration 7432, loss = 0.00291573\n",
      "Iteration 7433, loss = 0.00291507\n",
      "Iteration 7434, loss = 0.00291445\n",
      "Iteration 7435, loss = 0.00291410\n",
      "Iteration 7436, loss = 0.00291344\n",
      "Iteration 7437, loss = 0.00291296\n",
      "Iteration 7438, loss = 0.00291238\n",
      "Iteration 7439, loss = 0.00291182\n",
      "Iteration 7440, loss = 0.00291151\n",
      "Iteration 7441, loss = 0.00291075\n",
      "Iteration 7442, loss = 0.00291026\n",
      "Iteration 7443, loss = 0.00290976\n",
      "Iteration 7444, loss = 0.00290919\n",
      "Iteration 7445, loss = 0.00290868\n",
      "Iteration 7446, loss = 0.00290816\n",
      "Iteration 7447, loss = 0.00290769\n",
      "Iteration 7448, loss = 0.00290720\n",
      "Iteration 7449, loss = 0.00290672\n",
      "Iteration 7450, loss = 0.00290631\n",
      "Iteration 7451, loss = 0.00290587\n",
      "Iteration 7452, loss = 0.00290547\n",
      "Iteration 7453, loss = 0.00290496\n",
      "Iteration 7454, loss = 0.00290466\n",
      "Iteration 7455, loss = 0.00290423\n",
      "Iteration 7456, loss = 0.00290368\n",
      "Iteration 7457, loss = 0.00290312\n",
      "Iteration 7458, loss = 0.00290275\n",
      "Iteration 7459, loss = 0.00290224\n",
      "Iteration 7460, loss = 0.00290166\n",
      "Iteration 7461, loss = 0.00290128\n",
      "Iteration 7462, loss = 0.00290077\n",
      "Iteration 7463, loss = 0.00290014\n",
      "Iteration 7464, loss = 0.00289963\n",
      "Iteration 7465, loss = 0.00289906\n",
      "Iteration 7466, loss = 0.00289871\n",
      "Iteration 7467, loss = 0.00289806\n",
      "Iteration 7468, loss = 0.00289764\n",
      "Iteration 7469, loss = 0.00289700\n",
      "Iteration 7470, loss = 0.00289646\n",
      "Iteration 7471, loss = 0.00289615\n",
      "Iteration 7472, loss = 0.00289546\n",
      "Iteration 7473, loss = 0.00289493\n",
      "Iteration 7474, loss = 0.00289440\n",
      "Iteration 7475, loss = 0.00289396\n",
      "Iteration 7476, loss = 0.00289343\n",
      "Iteration 7477, loss = 0.00289316\n",
      "Iteration 7478, loss = 0.00289255\n",
      "Iteration 7479, loss = 0.00289213\n",
      "Iteration 7480, loss = 0.00289154\n",
      "Iteration 7481, loss = 0.00289104\n",
      "Iteration 7482, loss = 0.00289048\n",
      "Iteration 7483, loss = 0.00289020\n",
      "Iteration 7484, loss = 0.00288961\n",
      "Iteration 7485, loss = 0.00288909\n",
      "Iteration 7486, loss = 0.00288876\n",
      "Iteration 7487, loss = 0.00288815\n",
      "Iteration 7488, loss = 0.00288769\n",
      "Iteration 7489, loss = 0.00288717\n",
      "Iteration 7490, loss = 0.00288678\n",
      "Iteration 7491, loss = 0.00288621\n",
      "Iteration 7492, loss = 0.00288574\n",
      "Iteration 7493, loss = 0.00288527\n",
      "Iteration 7494, loss = 0.00288472\n",
      "Iteration 7495, loss = 0.00288437\n",
      "Iteration 7496, loss = 0.00288382\n",
      "Iteration 7497, loss = 0.00288353\n",
      "Iteration 7498, loss = 0.00288313\n",
      "Iteration 7499, loss = 0.00288247\n",
      "Iteration 7500, loss = 0.00288204\n",
      "Iteration 7501, loss = 0.00288152\n",
      "Iteration 7502, loss = 0.00288110\n",
      "Iteration 7503, loss = 0.00288053\n",
      "Iteration 7504, loss = 0.00287994\n",
      "Iteration 7505, loss = 0.00287945\n",
      "Iteration 7506, loss = 0.00287896\n",
      "Iteration 7507, loss = 0.00287837\n",
      "Iteration 7508, loss = 0.00287790\n",
      "Iteration 7509, loss = 0.00287732\n",
      "Iteration 7510, loss = 0.00287671\n",
      "Iteration 7511, loss = 0.00287628\n",
      "Iteration 7512, loss = 0.00287570\n",
      "Iteration 7513, loss = 0.00287514\n",
      "Iteration 7514, loss = 0.00287456\n",
      "Iteration 7515, loss = 0.00287416\n",
      "Iteration 7516, loss = 0.00287363\n",
      "Iteration 7517, loss = 0.00287325\n",
      "Iteration 7518, loss = 0.00287261\n",
      "Iteration 7519, loss = 0.00287211\n",
      "Iteration 7520, loss = 0.00287163\n",
      "Iteration 7521, loss = 0.00287119\n",
      "Iteration 7522, loss = 0.00287080\n",
      "Iteration 7523, loss = 0.00287031\n",
      "Iteration 7524, loss = 0.00286977\n",
      "Iteration 7525, loss = 0.00286928\n",
      "Iteration 7526, loss = 0.00286886\n",
      "Iteration 7527, loss = 0.00286836\n",
      "Iteration 7528, loss = 0.00286785\n",
      "Iteration 7529, loss = 0.00286745\n",
      "Iteration 7530, loss = 0.00286690\n",
      "Iteration 7531, loss = 0.00286652\n",
      "Iteration 7532, loss = 0.00286598\n",
      "Iteration 7533, loss = 0.00286550\n",
      "Iteration 7534, loss = 0.00286509\n",
      "Iteration 7535, loss = 0.00286460\n",
      "Iteration 7536, loss = 0.00286404\n",
      "Iteration 7537, loss = 0.00286337\n",
      "Iteration 7538, loss = 0.00286283\n",
      "Iteration 7539, loss = 0.00286234\n",
      "Iteration 7540, loss = 0.00286170\n",
      "Iteration 7541, loss = 0.00286118\n",
      "Iteration 7542, loss = 0.00286064\n",
      "Iteration 7543, loss = 0.00286042\n",
      "Iteration 7544, loss = 0.00285985\n",
      "Iteration 7545, loss = 0.00285944\n",
      "Iteration 7546, loss = 0.00285921\n",
      "Iteration 7547, loss = 0.00285876\n",
      "Iteration 7548, loss = 0.00285814\n",
      "Iteration 7549, loss = 0.00285754\n",
      "Iteration 7550, loss = 0.00285703\n",
      "Iteration 7551, loss = 0.00285652\n",
      "Iteration 7552, loss = 0.00285602\n",
      "Iteration 7553, loss = 0.00285552\n",
      "Iteration 7554, loss = 0.00285517\n",
      "Iteration 7555, loss = 0.00285460\n",
      "Iteration 7556, loss = 0.00285417\n",
      "Iteration 7557, loss = 0.00285364\n",
      "Iteration 7558, loss = 0.00285306\n",
      "Iteration 7559, loss = 0.00285254\n",
      "Iteration 7560, loss = 0.00285201\n",
      "Iteration 7561, loss = 0.00285165\n",
      "Iteration 7562, loss = 0.00285112\n",
      "Iteration 7563, loss = 0.00285057\n",
      "Iteration 7564, loss = 0.00285008\n",
      "Iteration 7565, loss = 0.00284965\n",
      "Iteration 7566, loss = 0.00284919\n",
      "Iteration 7567, loss = 0.00284878\n",
      "Iteration 7568, loss = 0.00284820\n",
      "Iteration 7569, loss = 0.00284772\n",
      "Iteration 7570, loss = 0.00284721\n",
      "Iteration 7571, loss = 0.00284669\n",
      "Iteration 7572, loss = 0.00284623\n",
      "Iteration 7573, loss = 0.00284573\n",
      "Iteration 7574, loss = 0.00284532\n",
      "Iteration 7575, loss = 0.00284484\n",
      "Iteration 7576, loss = 0.00284429\n",
      "Iteration 7577, loss = 0.00284376\n",
      "Iteration 7578, loss = 0.00284324\n",
      "Iteration 7579, loss = 0.00284282\n",
      "Iteration 7580, loss = 0.00284226\n",
      "Iteration 7581, loss = 0.00284162\n",
      "Iteration 7582, loss = 0.00284111\n",
      "Iteration 7583, loss = 0.00284058\n",
      "Iteration 7584, loss = 0.00284013\n",
      "Iteration 7585, loss = 0.00283946\n",
      "Iteration 7586, loss = 0.00283887\n",
      "Iteration 7587, loss = 0.00283847\n",
      "Iteration 7588, loss = 0.00283800\n",
      "Iteration 7589, loss = 0.00283726\n",
      "Iteration 7590, loss = 0.00283679\n",
      "Iteration 7591, loss = 0.00283635\n",
      "Iteration 7592, loss = 0.00283573\n",
      "Iteration 7593, loss = 0.00283513\n",
      "Iteration 7594, loss = 0.00283461\n",
      "Iteration 7595, loss = 0.00283415\n",
      "Iteration 7596, loss = 0.00283357\n",
      "Iteration 7597, loss = 0.00283326\n",
      "Iteration 7598, loss = 0.00283257\n",
      "Iteration 7599, loss = 0.00283216\n",
      "Iteration 7600, loss = 0.00283161\n",
      "Iteration 7601, loss = 0.00283118\n",
      "Iteration 7602, loss = 0.00283063\n",
      "Iteration 7603, loss = 0.00283022\n",
      "Iteration 7604, loss = 0.00282968\n",
      "Iteration 7605, loss = 0.00282924\n",
      "Iteration 7606, loss = 0.00282867\n",
      "Iteration 7607, loss = 0.00282826\n",
      "Iteration 7608, loss = 0.00282777\n",
      "Iteration 7609, loss = 0.00282729\n",
      "Iteration 7610, loss = 0.00282691\n",
      "Iteration 7611, loss = 0.00282638\n",
      "Iteration 7612, loss = 0.00282580\n",
      "Iteration 7613, loss = 0.00282545\n",
      "Iteration 7614, loss = 0.00282487\n",
      "Iteration 7615, loss = 0.00282451\n",
      "Iteration 7616, loss = 0.00282391\n",
      "Iteration 7617, loss = 0.00282342\n",
      "Iteration 7618, loss = 0.00282292\n",
      "Iteration 7619, loss = 0.00282249\n",
      "Iteration 7620, loss = 0.00282207\n",
      "Iteration 7621, loss = 0.00282188\n",
      "Iteration 7622, loss = 0.00282117\n",
      "Iteration 7623, loss = 0.00282065\n",
      "Iteration 7624, loss = 0.00282022\n",
      "Iteration 7625, loss = 0.00282018\n",
      "Iteration 7626, loss = 0.00281933\n",
      "Iteration 7627, loss = 0.00281884\n",
      "Iteration 7628, loss = 0.00281833\n",
      "Iteration 7629, loss = 0.00281785\n",
      "Iteration 7630, loss = 0.00281742\n",
      "Iteration 7631, loss = 0.00281699\n",
      "Iteration 7632, loss = 0.00281628\n",
      "Iteration 7633, loss = 0.00281560\n",
      "Iteration 7634, loss = 0.00281511\n",
      "Iteration 7635, loss = 0.00281459\n",
      "Iteration 7636, loss = 0.00281419\n",
      "Iteration 7637, loss = 0.00281354\n",
      "Iteration 7638, loss = 0.00281314\n",
      "Iteration 7639, loss = 0.00281248\n",
      "Iteration 7640, loss = 0.00281193\n",
      "Iteration 7641, loss = 0.00281153\n",
      "Iteration 7642, loss = 0.00281105\n",
      "Iteration 7643, loss = 0.00281036\n",
      "Iteration 7644, loss = 0.00281001\n",
      "Iteration 7645, loss = 0.00280943\n",
      "Iteration 7646, loss = 0.00280882\n",
      "Iteration 7647, loss = 0.00280828\n",
      "Iteration 7648, loss = 0.00280769\n",
      "Iteration 7649, loss = 0.00280722\n",
      "Iteration 7650, loss = 0.00280665\n",
      "Iteration 7651, loss = 0.00280623\n",
      "Iteration 7652, loss = 0.00280561\n",
      "Iteration 7653, loss = 0.00280513\n",
      "Iteration 7654, loss = 0.00280469\n",
      "Iteration 7655, loss = 0.00280420\n",
      "Iteration 7656, loss = 0.00280374\n",
      "Iteration 7657, loss = 0.00280317\n",
      "Iteration 7658, loss = 0.00280278\n",
      "Iteration 7659, loss = 0.00280218\n",
      "Iteration 7660, loss = 0.00280180\n",
      "Iteration 7661, loss = 0.00280144\n",
      "Iteration 7662, loss = 0.00280080\n",
      "Iteration 7663, loss = 0.00280035\n",
      "Iteration 7664, loss = 0.00279980\n",
      "Iteration 7665, loss = 0.00279985\n",
      "Iteration 7666, loss = 0.00279900\n",
      "Iteration 7667, loss = 0.00279844\n",
      "Iteration 7668, loss = 0.00279794\n",
      "Iteration 7669, loss = 0.00279748\n",
      "Iteration 7670, loss = 0.00279695\n",
      "Iteration 7671, loss = 0.00279639\n",
      "Iteration 7672, loss = 0.00279592\n",
      "Iteration 7673, loss = 0.00279538\n",
      "Iteration 7674, loss = 0.00279486\n",
      "Iteration 7675, loss = 0.00279434\n",
      "Iteration 7676, loss = 0.00279385\n",
      "Iteration 7677, loss = 0.00279343\n",
      "Iteration 7678, loss = 0.00279290\n",
      "Iteration 7679, loss = 0.00279257\n",
      "Iteration 7680, loss = 0.00279210\n",
      "Iteration 7681, loss = 0.00279154\n",
      "Iteration 7682, loss = 0.00279096\n",
      "Iteration 7683, loss = 0.00279051\n",
      "Iteration 7684, loss = 0.00279001\n",
      "Iteration 7685, loss = 0.00278955\n",
      "Iteration 7686, loss = 0.00278913\n",
      "Iteration 7687, loss = 0.00278866\n",
      "Iteration 7688, loss = 0.00278819\n",
      "Iteration 7689, loss = 0.00278769\n",
      "Iteration 7690, loss = 0.00278729\n",
      "Iteration 7691, loss = 0.00278681\n",
      "Iteration 7692, loss = 0.00278639\n",
      "Iteration 7693, loss = 0.00278591\n",
      "Iteration 7694, loss = 0.00278551\n",
      "Iteration 7695, loss = 0.00278505\n",
      "Iteration 7696, loss = 0.00278466\n",
      "Iteration 7697, loss = 0.00278423\n",
      "Iteration 7698, loss = 0.00278382\n",
      "Iteration 7699, loss = 0.00278355\n",
      "Iteration 7700, loss = 0.00278306\n",
      "Iteration 7701, loss = 0.00278269\n",
      "Iteration 7702, loss = 0.00278231\n",
      "Iteration 7703, loss = 0.00278188\n",
      "Iteration 7704, loss = 0.00278124\n",
      "Iteration 7705, loss = 0.00278083\n",
      "Iteration 7706, loss = 0.00278032\n",
      "Iteration 7707, loss = 0.00277987\n",
      "Iteration 7708, loss = 0.00278006\n",
      "Iteration 7709, loss = 0.00277904\n",
      "Iteration 7710, loss = 0.00277859\n",
      "Iteration 7711, loss = 0.00277807\n",
      "Iteration 7712, loss = 0.00277768\n",
      "Iteration 7713, loss = 0.00277707\n",
      "Iteration 7714, loss = 0.00277661\n",
      "Iteration 7715, loss = 0.00277613\n",
      "Iteration 7716, loss = 0.00277559\n",
      "Iteration 7717, loss = 0.00277517\n",
      "Iteration 7718, loss = 0.00277469\n",
      "Iteration 7719, loss = 0.00277419\n",
      "Iteration 7720, loss = 0.00277387\n",
      "Iteration 7721, loss = 0.00277369\n",
      "Iteration 7722, loss = 0.00277286\n",
      "Iteration 7723, loss = 0.00277237\n",
      "Iteration 7724, loss = 0.00277197\n",
      "Iteration 7725, loss = 0.00277137\n",
      "Iteration 7726, loss = 0.00277090\n",
      "Iteration 7727, loss = 0.00277041\n",
      "Iteration 7728, loss = 0.00276975\n",
      "Iteration 7729, loss = 0.00276953\n",
      "Iteration 7730, loss = 0.00276873\n",
      "Iteration 7731, loss = 0.00276811\n",
      "Iteration 7732, loss = 0.00276769\n",
      "Iteration 7733, loss = 0.00276708\n",
      "Iteration 7734, loss = 0.00276662\n",
      "Iteration 7735, loss = 0.00276619\n",
      "Iteration 7736, loss = 0.00276571\n",
      "Iteration 7737, loss = 0.00276540\n",
      "Iteration 7738, loss = 0.00276496\n",
      "Iteration 7739, loss = 0.00276456\n",
      "Iteration 7740, loss = 0.00276419\n",
      "Iteration 7741, loss = 0.00276382\n",
      "Iteration 7742, loss = 0.00276362\n",
      "Iteration 7743, loss = 0.00276299\n",
      "Iteration 7744, loss = 0.00276274\n",
      "Iteration 7745, loss = 0.00276193\n",
      "Iteration 7746, loss = 0.00276151\n",
      "Iteration 7747, loss = 0.00276112\n",
      "Iteration 7748, loss = 0.00276055\n",
      "Iteration 7749, loss = 0.00276000\n",
      "Iteration 7750, loss = 0.00275941\n",
      "Iteration 7751, loss = 0.00275892\n",
      "Iteration 7752, loss = 0.00275895\n",
      "Iteration 7753, loss = 0.00275797\n",
      "Iteration 7754, loss = 0.00275747\n",
      "Iteration 7755, loss = 0.00275713\n",
      "Iteration 7756, loss = 0.00275671\n",
      "Iteration 7757, loss = 0.00275615\n",
      "Iteration 7758, loss = 0.00275567\n",
      "Iteration 7759, loss = 0.00275541\n",
      "Iteration 7760, loss = 0.00275479\n",
      "Iteration 7761, loss = 0.00275428\n",
      "Iteration 7762, loss = 0.00275372\n",
      "Iteration 7763, loss = 0.00275310\n",
      "Iteration 7764, loss = 0.00275276\n",
      "Iteration 7765, loss = 0.00275206\n",
      "Iteration 7766, loss = 0.00275151\n",
      "Iteration 7767, loss = 0.00275116\n",
      "Iteration 7768, loss = 0.00275056\n",
      "Iteration 7769, loss = 0.00275009\n",
      "Iteration 7770, loss = 0.00274963\n",
      "Iteration 7771, loss = 0.00274910\n",
      "Iteration 7772, loss = 0.00274853\n",
      "Iteration 7773, loss = 0.00274797\n",
      "Iteration 7774, loss = 0.00274740\n",
      "Iteration 7775, loss = 0.00274722\n",
      "Iteration 7776, loss = 0.00274654\n",
      "Iteration 7777, loss = 0.00274635\n",
      "Iteration 7778, loss = 0.00274552\n",
      "Iteration 7779, loss = 0.00274505\n",
      "Iteration 7780, loss = 0.00274469\n",
      "Iteration 7781, loss = 0.00274418\n",
      "Iteration 7782, loss = 0.00274369\n",
      "Iteration 7783, loss = 0.00274320\n",
      "Iteration 7784, loss = 0.00274290\n",
      "Iteration 7785, loss = 0.00274222\n",
      "Iteration 7786, loss = 0.00274169\n",
      "Iteration 7787, loss = 0.00274112\n",
      "Iteration 7788, loss = 0.00274069\n",
      "Iteration 7789, loss = 0.00274016\n",
      "Iteration 7790, loss = 0.00273959\n",
      "Iteration 7791, loss = 0.00273900\n",
      "Iteration 7792, loss = 0.00273865\n",
      "Iteration 7793, loss = 0.00273813\n",
      "Iteration 7794, loss = 0.00273778\n",
      "Iteration 7795, loss = 0.00273716\n",
      "Iteration 7796, loss = 0.00273694\n",
      "Iteration 7797, loss = 0.00273617\n",
      "Iteration 7798, loss = 0.00273571\n",
      "Iteration 7799, loss = 0.00273521\n",
      "Iteration 7800, loss = 0.00273477\n",
      "Iteration 7801, loss = 0.00273435\n",
      "Iteration 7802, loss = 0.00273402\n",
      "Iteration 7803, loss = 0.00273329\n",
      "Iteration 7804, loss = 0.00273304\n",
      "Iteration 7805, loss = 0.00273242\n",
      "Iteration 7806, loss = 0.00273196\n",
      "Iteration 7807, loss = 0.00273170\n",
      "Iteration 7808, loss = 0.00273105\n",
      "Iteration 7809, loss = 0.00273069\n",
      "Iteration 7810, loss = 0.00273022\n",
      "Iteration 7811, loss = 0.00272972\n",
      "Iteration 7812, loss = 0.00272934\n",
      "Iteration 7813, loss = 0.00272899\n",
      "Iteration 7814, loss = 0.00272845\n",
      "Iteration 7815, loss = 0.00272796\n",
      "Iteration 7816, loss = 0.00272762\n",
      "Iteration 7817, loss = 0.00272713\n",
      "Iteration 7818, loss = 0.00272676\n",
      "Iteration 7819, loss = 0.00272624\n",
      "Iteration 7820, loss = 0.00272589\n",
      "Iteration 7821, loss = 0.00272542\n",
      "Iteration 7822, loss = 0.00272483\n",
      "Iteration 7823, loss = 0.00272430\n",
      "Iteration 7824, loss = 0.00272385\n",
      "Iteration 7825, loss = 0.00272346\n",
      "Iteration 7826, loss = 0.00272284\n",
      "Iteration 7827, loss = 0.00272233\n",
      "Iteration 7828, loss = 0.00272191\n",
      "Iteration 7829, loss = 0.00272149\n",
      "Iteration 7830, loss = 0.00272100\n",
      "Iteration 7831, loss = 0.00272053\n",
      "Iteration 7832, loss = 0.00272006\n",
      "Iteration 7833, loss = 0.00271978\n",
      "Iteration 7834, loss = 0.00271916\n",
      "Iteration 7835, loss = 0.00271902\n",
      "Iteration 7836, loss = 0.00271822\n",
      "Iteration 7837, loss = 0.00271773\n",
      "Iteration 7838, loss = 0.00271716\n",
      "Iteration 7839, loss = 0.00271725\n",
      "Iteration 7840, loss = 0.00271649\n",
      "Iteration 7841, loss = 0.00271579\n",
      "Iteration 7842, loss = 0.00271529\n",
      "Iteration 7843, loss = 0.00271490\n",
      "Iteration 7844, loss = 0.00271428\n",
      "Iteration 7845, loss = 0.00271366\n",
      "Iteration 7846, loss = 0.00271314\n",
      "Iteration 7847, loss = 0.00271268\n",
      "Iteration 7848, loss = 0.00271220\n",
      "Iteration 7849, loss = 0.00271159\n",
      "Iteration 7850, loss = 0.00271139\n",
      "Iteration 7851, loss = 0.00271067\n",
      "Iteration 7852, loss = 0.00271015\n",
      "Iteration 7853, loss = 0.00270952\n",
      "Iteration 7854, loss = 0.00270935\n",
      "Iteration 7855, loss = 0.00270876\n",
      "Iteration 7856, loss = 0.00270820\n",
      "Iteration 7857, loss = 0.00270814\n",
      "Iteration 7858, loss = 0.00270739\n",
      "Iteration 7859, loss = 0.00270696\n",
      "Iteration 7860, loss = 0.00270642\n",
      "Iteration 7861, loss = 0.00270604\n",
      "Iteration 7862, loss = 0.00270562\n",
      "Iteration 7863, loss = 0.00270518\n",
      "Iteration 7864, loss = 0.00270484\n",
      "Iteration 7865, loss = 0.00270430\n",
      "Iteration 7866, loss = 0.00270387\n",
      "Iteration 7867, loss = 0.00270345\n",
      "Iteration 7868, loss = 0.00270309\n",
      "Iteration 7869, loss = 0.00270261\n",
      "Iteration 7870, loss = 0.00270211\n",
      "Iteration 7871, loss = 0.00270169\n",
      "Iteration 7872, loss = 0.00270142\n",
      "Iteration 7873, loss = 0.00270075\n",
      "Iteration 7874, loss = 0.00270040\n",
      "Iteration 7875, loss = 0.00270005\n",
      "Iteration 7876, loss = 0.00269941\n",
      "Iteration 7877, loss = 0.00269898\n",
      "Iteration 7878, loss = 0.00269855\n",
      "Iteration 7879, loss = 0.00269814\n",
      "Iteration 7880, loss = 0.00269764\n",
      "Iteration 7881, loss = 0.00269720\n",
      "Iteration 7882, loss = 0.00269695\n",
      "Iteration 7883, loss = 0.00269625\n",
      "Iteration 7884, loss = 0.00269573\n",
      "Iteration 7885, loss = 0.00269521\n",
      "Iteration 7886, loss = 0.00269474\n",
      "Iteration 7887, loss = 0.00269428\n",
      "Iteration 7888, loss = 0.00269393\n",
      "Iteration 7889, loss = 0.00269335\n",
      "Iteration 7890, loss = 0.00269287\n",
      "Iteration 7891, loss = 0.00269253\n",
      "Iteration 7892, loss = 0.00269217\n",
      "Iteration 7893, loss = 0.00269159\n",
      "Iteration 7894, loss = 0.00269101\n",
      "Iteration 7895, loss = 0.00269056\n",
      "Iteration 7896, loss = 0.00269011\n",
      "Iteration 7897, loss = 0.00268959\n",
      "Iteration 7898, loss = 0.00268916\n",
      "Iteration 7899, loss = 0.00268874\n",
      "Iteration 7900, loss = 0.00268832\n",
      "Iteration 7901, loss = 0.00268794\n",
      "Iteration 7902, loss = 0.00268763\n",
      "Iteration 7903, loss = 0.00268720\n",
      "Iteration 7904, loss = 0.00268671\n",
      "Iteration 7905, loss = 0.00268627\n",
      "Iteration 7906, loss = 0.00268579\n",
      "Iteration 7907, loss = 0.00268574\n",
      "Iteration 7908, loss = 0.00268492\n",
      "Iteration 7909, loss = 0.00268453\n",
      "Iteration 7910, loss = 0.00268418\n",
      "Iteration 7911, loss = 0.00268364\n",
      "Iteration 7912, loss = 0.00268331\n",
      "Iteration 7913, loss = 0.00268276\n",
      "Iteration 7914, loss = 0.00268233\n",
      "Iteration 7915, loss = 0.00268225\n",
      "Iteration 7916, loss = 0.00268129\n",
      "Iteration 7917, loss = 0.00268093\n",
      "Iteration 7918, loss = 0.00268026\n",
      "Iteration 7919, loss = 0.00267976\n",
      "Iteration 7920, loss = 0.00267943\n",
      "Iteration 7921, loss = 0.00267882\n",
      "Iteration 7922, loss = 0.00267827\n",
      "Iteration 7923, loss = 0.00267832\n",
      "Iteration 7924, loss = 0.00267744\n",
      "Iteration 7925, loss = 0.00267698\n",
      "Iteration 7926, loss = 0.00267681\n",
      "Iteration 7927, loss = 0.00267616\n",
      "Iteration 7928, loss = 0.00267587\n",
      "Iteration 7929, loss = 0.00267519\n",
      "Iteration 7930, loss = 0.00267468\n",
      "Iteration 7931, loss = 0.00267426\n",
      "Iteration 7932, loss = 0.00267372\n",
      "Iteration 7933, loss = 0.00267345\n",
      "Iteration 7934, loss = 0.00267282\n",
      "Iteration 7935, loss = 0.00267233\n",
      "Iteration 7936, loss = 0.00267193\n",
      "Iteration 7937, loss = 0.00267146\n",
      "Iteration 7938, loss = 0.00267112\n",
      "Iteration 7939, loss = 0.00267052\n",
      "Iteration 7940, loss = 0.00267005\n",
      "Iteration 7941, loss = 0.00266956\n",
      "Iteration 7942, loss = 0.00266924\n",
      "Iteration 7943, loss = 0.00266863\n",
      "Iteration 7944, loss = 0.00266828\n",
      "Iteration 7945, loss = 0.00266769\n",
      "Iteration 7946, loss = 0.00266710\n",
      "Iteration 7947, loss = 0.00266718\n",
      "Iteration 7948, loss = 0.00266634\n",
      "Iteration 7949, loss = 0.00266583\n",
      "Iteration 7950, loss = 0.00266548\n",
      "Iteration 7951, loss = 0.00266499\n",
      "Iteration 7952, loss = 0.00266452\n",
      "Iteration 7953, loss = 0.00266411\n",
      "Iteration 7954, loss = 0.00266363\n",
      "Iteration 7955, loss = 0.00266309\n",
      "Iteration 7956, loss = 0.00266267\n",
      "Iteration 7957, loss = 0.00266219\n",
      "Iteration 7958, loss = 0.00266181\n",
      "Iteration 7959, loss = 0.00266134\n",
      "Iteration 7960, loss = 0.00266088\n",
      "Iteration 7961, loss = 0.00266045\n",
      "Iteration 7962, loss = 0.00266005\n",
      "Iteration 7963, loss = 0.00265964\n",
      "Iteration 7964, loss = 0.00265921\n",
      "Iteration 7965, loss = 0.00265889\n",
      "Iteration 7966, loss = 0.00265839\n",
      "Iteration 7967, loss = 0.00265794\n",
      "Iteration 7968, loss = 0.00265769\n",
      "Iteration 7969, loss = 0.00265719\n",
      "Iteration 7970, loss = 0.00265681\n",
      "Iteration 7971, loss = 0.00265635\n",
      "Iteration 7972, loss = 0.00265588\n",
      "Iteration 7973, loss = 0.00265566\n",
      "Iteration 7974, loss = 0.00265509\n",
      "Iteration 7975, loss = 0.00265466\n",
      "Iteration 7976, loss = 0.00265421\n",
      "Iteration 7977, loss = 0.00265377\n",
      "Iteration 7978, loss = 0.00265361\n",
      "Iteration 7979, loss = 0.00265285\n",
      "Iteration 7980, loss = 0.00265245\n",
      "Iteration 7981, loss = 0.00265199\n",
      "Iteration 7982, loss = 0.00265140\n",
      "Iteration 7983, loss = 0.00265090\n",
      "Iteration 7984, loss = 0.00265053\n",
      "Iteration 7985, loss = 0.00265012\n",
      "Iteration 7986, loss = 0.00264962\n",
      "Iteration 7987, loss = 0.00264933\n",
      "Iteration 7988, loss = 0.00264880\n",
      "Iteration 7989, loss = 0.00264842\n",
      "Iteration 7990, loss = 0.00264799\n",
      "Iteration 7991, loss = 0.00264756\n",
      "Iteration 7992, loss = 0.00264719\n",
      "Iteration 7993, loss = 0.00264674\n",
      "Iteration 7994, loss = 0.00264636\n",
      "Iteration 7995, loss = 0.00264601\n",
      "Iteration 7996, loss = 0.00264554\n",
      "Iteration 7997, loss = 0.00264508\n",
      "Iteration 7998, loss = 0.00264471\n",
      "Iteration 7999, loss = 0.00264433\n",
      "Iteration 8000, loss = 0.00264387\n",
      "Iteration 1, loss = 1.03405397\n",
      "Iteration 2, loss = 1.03092738\n",
      "Iteration 3, loss = 1.02591808\n",
      "Iteration 4, loss = 1.01959973\n",
      "Iteration 5, loss = 1.01228054\n",
      "Iteration 6, loss = 1.00428423\n",
      "Iteration 7, loss = 0.99573087\n",
      "Iteration 8, loss = 0.98695789\n",
      "Iteration 9, loss = 0.97789539\n",
      "Iteration 10, loss = 0.96867451\n",
      "Iteration 11, loss = 0.95939687\n",
      "Iteration 12, loss = 0.95011569\n",
      "Iteration 13, loss = 0.94087278\n",
      "Iteration 14, loss = 0.93181132\n",
      "Iteration 15, loss = 0.92284435\n",
      "Iteration 16, loss = 0.91413243\n",
      "Iteration 17, loss = 0.90524882\n",
      "Iteration 18, loss = 0.89702600\n",
      "Iteration 19, loss = 0.88875335\n",
      "Iteration 20, loss = 0.88088577\n",
      "Iteration 21, loss = 0.87304847\n",
      "Iteration 22, loss = 0.86549587\n",
      "Iteration 23, loss = 0.85819801\n",
      "Iteration 24, loss = 0.85102521\n",
      "Iteration 25, loss = 0.84406787\n",
      "Iteration 26, loss = 0.83720036\n",
      "Iteration 27, loss = 0.83055886\n",
      "Iteration 28, loss = 0.82407992\n",
      "Iteration 29, loss = 0.81800124\n",
      "Iteration 30, loss = 0.81198423\n",
      "Iteration 31, loss = 0.80605609\n",
      "Iteration 32, loss = 0.80044078\n",
      "Iteration 33, loss = 0.79490537\n",
      "Iteration 34, loss = 0.78957087\n",
      "Iteration 35, loss = 0.78434741\n",
      "Iteration 36, loss = 0.77910320\n",
      "Iteration 37, loss = 0.77430973\n",
      "Iteration 38, loss = 0.76941754\n",
      "Iteration 39, loss = 0.76470232\n",
      "Iteration 40, loss = 0.76028809\n",
      "Iteration 41, loss = 0.75593366\n",
      "Iteration 42, loss = 0.75168476\n",
      "Iteration 43, loss = 0.74767097\n",
      "Iteration 44, loss = 0.74371771\n",
      "Iteration 45, loss = 0.73986400\n",
      "Iteration 46, loss = 0.73615912\n",
      "Iteration 47, loss = 0.73241831\n",
      "Iteration 48, loss = 0.72878250\n",
      "Iteration 49, loss = 0.72516339\n",
      "Iteration 50, loss = 0.72159567\n",
      "Iteration 51, loss = 0.71816732\n",
      "Iteration 52, loss = 0.71467540\n",
      "Iteration 53, loss = 0.71132474\n",
      "Iteration 54, loss = 0.70789506\n",
      "Iteration 55, loss = 0.70460342\n",
      "Iteration 56, loss = 0.70128541\n",
      "Iteration 57, loss = 0.69791647\n",
      "Iteration 58, loss = 0.69467571\n",
      "Iteration 59, loss = 0.69143790\n",
      "Iteration 60, loss = 0.68815847\n",
      "Iteration 61, loss = 0.68491364\n",
      "Iteration 62, loss = 0.68188443\n",
      "Iteration 63, loss = 0.67881353\n",
      "Iteration 64, loss = 0.67570579\n",
      "Iteration 65, loss = 0.67284629\n",
      "Iteration 66, loss = 0.66988260\n",
      "Iteration 67, loss = 0.66694398\n",
      "Iteration 68, loss = 0.66415956\n",
      "Iteration 69, loss = 0.66120044\n",
      "Iteration 70, loss = 0.65844231\n",
      "Iteration 71, loss = 0.65552965\n",
      "Iteration 72, loss = 0.65278005\n",
      "Iteration 73, loss = 0.64993692\n",
      "Iteration 74, loss = 0.64723615\n",
      "Iteration 75, loss = 0.64445022\n",
      "Iteration 76, loss = 0.64177421\n",
      "Iteration 77, loss = 0.63908470\n",
      "Iteration 78, loss = 0.63642463\n",
      "Iteration 79, loss = 0.63377489\n",
      "Iteration 80, loss = 0.63115308\n",
      "Iteration 81, loss = 0.62854508\n",
      "Iteration 82, loss = 0.62594972\n",
      "Iteration 83, loss = 0.62339925\n",
      "Iteration 84, loss = 0.62076854\n",
      "Iteration 85, loss = 0.61827916\n",
      "Iteration 86, loss = 0.61567494\n",
      "Iteration 87, loss = 0.61313996\n",
      "Iteration 88, loss = 0.61059889\n",
      "Iteration 89, loss = 0.60808783\n",
      "Iteration 90, loss = 0.60553090\n",
      "Iteration 91, loss = 0.60301449\n",
      "Iteration 92, loss = 0.60053106\n",
      "Iteration 93, loss = 0.59804460\n",
      "Iteration 94, loss = 0.59553680\n",
      "Iteration 95, loss = 0.59307131\n",
      "Iteration 96, loss = 0.59062755\n",
      "Iteration 97, loss = 0.58816346\n",
      "Iteration 98, loss = 0.58572524\n",
      "Iteration 99, loss = 0.58328052\n",
      "Iteration 100, loss = 0.58087042\n",
      "Iteration 101, loss = 0.57850968\n",
      "Iteration 102, loss = 0.57610532\n",
      "Iteration 103, loss = 0.57372262\n",
      "Iteration 104, loss = 0.57141257\n",
      "Iteration 105, loss = 0.56903580\n",
      "Iteration 106, loss = 0.56671339\n",
      "Iteration 107, loss = 0.56438730\n",
      "Iteration 108, loss = 0.56213872\n",
      "Iteration 109, loss = 0.55982037\n",
      "Iteration 110, loss = 0.55754204\n",
      "Iteration 111, loss = 0.55528064\n",
      "Iteration 112, loss = 0.55299935\n",
      "Iteration 113, loss = 0.55080818\n",
      "Iteration 114, loss = 0.54847670\n",
      "Iteration 115, loss = 0.54622981\n",
      "Iteration 116, loss = 0.54399534\n",
      "Iteration 117, loss = 0.54169152\n",
      "Iteration 118, loss = 0.53948323\n",
      "Iteration 119, loss = 0.53717530\n",
      "Iteration 120, loss = 0.53492646\n",
      "Iteration 121, loss = 0.53269987\n",
      "Iteration 122, loss = 0.53049493\n",
      "Iteration 123, loss = 0.52827072\n",
      "Iteration 124, loss = 0.52606128\n",
      "Iteration 125, loss = 0.52388394\n",
      "Iteration 126, loss = 0.52172404\n",
      "Iteration 127, loss = 0.51955974\n",
      "Iteration 128, loss = 0.51743562\n",
      "Iteration 129, loss = 0.51525857\n",
      "Iteration 130, loss = 0.51316093\n",
      "Iteration 131, loss = 0.51102793\n",
      "Iteration 132, loss = 0.50892044\n",
      "Iteration 133, loss = 0.50689137\n",
      "Iteration 134, loss = 0.50483608\n",
      "Iteration 135, loss = 0.50279278\n",
      "Iteration 136, loss = 0.50078395\n",
      "Iteration 137, loss = 0.49875647\n",
      "Iteration 138, loss = 0.49671074\n",
      "Iteration 139, loss = 0.49469800\n",
      "Iteration 140, loss = 0.49263871\n",
      "Iteration 141, loss = 0.49060421\n",
      "Iteration 142, loss = 0.48856933\n",
      "Iteration 143, loss = 0.48653678\n",
      "Iteration 144, loss = 0.48449476\n",
      "Iteration 145, loss = 0.48245228\n",
      "Iteration 146, loss = 0.48042363\n",
      "Iteration 147, loss = 0.47838130\n",
      "Iteration 148, loss = 0.47635817\n",
      "Iteration 149, loss = 0.47427773\n",
      "Iteration 150, loss = 0.47224756\n",
      "Iteration 151, loss = 0.47020233\n",
      "Iteration 152, loss = 0.46813479\n",
      "Iteration 153, loss = 0.46608711\n",
      "Iteration 154, loss = 0.46404807\n",
      "Iteration 155, loss = 0.46205430\n",
      "Iteration 156, loss = 0.45999077\n",
      "Iteration 157, loss = 0.45797582\n",
      "Iteration 158, loss = 0.45594168\n",
      "Iteration 159, loss = 0.45389570\n",
      "Iteration 160, loss = 0.45180340\n",
      "Iteration 161, loss = 0.44975410\n",
      "Iteration 162, loss = 0.44766173\n",
      "Iteration 163, loss = 0.44557295\n",
      "Iteration 164, loss = 0.44349921\n",
      "Iteration 165, loss = 0.44142720\n",
      "Iteration 166, loss = 0.43933640\n",
      "Iteration 167, loss = 0.43727408\n",
      "Iteration 168, loss = 0.43522230\n",
      "Iteration 169, loss = 0.43314412\n",
      "Iteration 170, loss = 0.43111123\n",
      "Iteration 171, loss = 0.42904540\n",
      "Iteration 172, loss = 0.42700140\n",
      "Iteration 173, loss = 0.42496326\n",
      "Iteration 174, loss = 0.42293415\n",
      "Iteration 175, loss = 0.42087769\n",
      "Iteration 176, loss = 0.41887883\n",
      "Iteration 177, loss = 0.41684585\n",
      "Iteration 178, loss = 0.41482723\n",
      "Iteration 179, loss = 0.41280001\n",
      "Iteration 180, loss = 0.41080414\n",
      "Iteration 181, loss = 0.40872956\n",
      "Iteration 182, loss = 0.40671609\n",
      "Iteration 183, loss = 0.40470108\n",
      "Iteration 184, loss = 0.40262478\n",
      "Iteration 185, loss = 0.40059082\n",
      "Iteration 186, loss = 0.39856658\n",
      "Iteration 187, loss = 0.39650609\n",
      "Iteration 188, loss = 0.39448363\n",
      "Iteration 189, loss = 0.39249492\n",
      "Iteration 190, loss = 0.39046370\n",
      "Iteration 191, loss = 0.38849468\n",
      "Iteration 192, loss = 0.38652500\n",
      "Iteration 193, loss = 0.38455140\n",
      "Iteration 194, loss = 0.38258329\n",
      "Iteration 195, loss = 0.38065995\n",
      "Iteration 196, loss = 0.37865975\n",
      "Iteration 197, loss = 0.37672865\n",
      "Iteration 198, loss = 0.37476495\n",
      "Iteration 199, loss = 0.37282087\n",
      "Iteration 200, loss = 0.37086516\n",
      "Iteration 201, loss = 0.36893205\n",
      "Iteration 202, loss = 0.36700585\n",
      "Iteration 203, loss = 0.36508267\n",
      "Iteration 204, loss = 0.36316870\n",
      "Iteration 205, loss = 0.36124677\n",
      "Iteration 206, loss = 0.35935385\n",
      "Iteration 207, loss = 0.35742259\n",
      "Iteration 208, loss = 0.35550420\n",
      "Iteration 209, loss = 0.35358020\n",
      "Iteration 210, loss = 0.35164434\n",
      "Iteration 211, loss = 0.34971443\n",
      "Iteration 212, loss = 0.34775304\n",
      "Iteration 213, loss = 0.34582219\n",
      "Iteration 214, loss = 0.34386939\n",
      "Iteration 215, loss = 0.34191437\n",
      "Iteration 216, loss = 0.33996640\n",
      "Iteration 217, loss = 0.33802419\n",
      "Iteration 218, loss = 0.33609451\n",
      "Iteration 219, loss = 0.33416051\n",
      "Iteration 220, loss = 0.33224895\n",
      "Iteration 221, loss = 0.33035791\n",
      "Iteration 222, loss = 0.32846331\n",
      "Iteration 223, loss = 0.32659385\n",
      "Iteration 224, loss = 0.32470121\n",
      "Iteration 225, loss = 0.32284696\n",
      "Iteration 226, loss = 0.32096738\n",
      "Iteration 227, loss = 0.31908744\n",
      "Iteration 228, loss = 0.31721305\n",
      "Iteration 229, loss = 0.31535078\n",
      "Iteration 230, loss = 0.31347464\n",
      "Iteration 231, loss = 0.31164907\n",
      "Iteration 232, loss = 0.30979271\n",
      "Iteration 233, loss = 0.30794889\n",
      "Iteration 234, loss = 0.30613170\n",
      "Iteration 235, loss = 0.30431949\n",
      "Iteration 236, loss = 0.30250423\n",
      "Iteration 237, loss = 0.30070142\n",
      "Iteration 238, loss = 0.29891261\n",
      "Iteration 239, loss = 0.29711866\n",
      "Iteration 240, loss = 0.29532673\n",
      "Iteration 241, loss = 0.29355068\n",
      "Iteration 242, loss = 0.29178149\n",
      "Iteration 243, loss = 0.28999882\n",
      "Iteration 244, loss = 0.28823585\n",
      "Iteration 245, loss = 0.28649069\n",
      "Iteration 246, loss = 0.28473489\n",
      "Iteration 247, loss = 0.28302894\n",
      "Iteration 248, loss = 0.28129010\n",
      "Iteration 249, loss = 0.27957907\n",
      "Iteration 250, loss = 0.27791400\n",
      "Iteration 251, loss = 0.27624425\n",
      "Iteration 252, loss = 0.27457082\n",
      "Iteration 253, loss = 0.27291878\n",
      "Iteration 254, loss = 0.27128986\n",
      "Iteration 255, loss = 0.26965518\n",
      "Iteration 256, loss = 0.26804832\n",
      "Iteration 257, loss = 0.26641579\n",
      "Iteration 258, loss = 0.26482931\n",
      "Iteration 259, loss = 0.26322967\n",
      "Iteration 260, loss = 0.26164156\n",
      "Iteration 261, loss = 0.26005230\n",
      "Iteration 262, loss = 0.25849246\n",
      "Iteration 263, loss = 0.25691914\n",
      "Iteration 264, loss = 0.25535946\n",
      "Iteration 265, loss = 0.25382460\n",
      "Iteration 266, loss = 0.25229759\n",
      "Iteration 267, loss = 0.25077102\n",
      "Iteration 268, loss = 0.24926234\n",
      "Iteration 269, loss = 0.24777145\n",
      "Iteration 270, loss = 0.24629296\n",
      "Iteration 271, loss = 0.24482194\n",
      "Iteration 272, loss = 0.24338126\n",
      "Iteration 273, loss = 0.24191999\n",
      "Iteration 274, loss = 0.24049311\n",
      "Iteration 275, loss = 0.23906547\n",
      "Iteration 276, loss = 0.23765768\n",
      "Iteration 277, loss = 0.23624638\n",
      "Iteration 278, loss = 0.23485035\n",
      "Iteration 279, loss = 0.23349154\n",
      "Iteration 280, loss = 0.23210352\n",
      "Iteration 281, loss = 0.23075539\n",
      "Iteration 282, loss = 0.22939360\n",
      "Iteration 283, loss = 0.22805448\n",
      "Iteration 284, loss = 0.22671074\n",
      "Iteration 285, loss = 0.22537633\n",
      "Iteration 286, loss = 0.22405381\n",
      "Iteration 287, loss = 0.22274027\n",
      "Iteration 288, loss = 0.22143806\n",
      "Iteration 289, loss = 0.22014117\n",
      "Iteration 290, loss = 0.21884720\n",
      "Iteration 291, loss = 0.21756733\n",
      "Iteration 292, loss = 0.21630657\n",
      "Iteration 293, loss = 0.21504027\n",
      "Iteration 294, loss = 0.21378403\n",
      "Iteration 295, loss = 0.21256513\n",
      "Iteration 296, loss = 0.21132050\n",
      "Iteration 297, loss = 0.21010739\n",
      "Iteration 298, loss = 0.20887849\n",
      "Iteration 299, loss = 0.20769052\n",
      "Iteration 300, loss = 0.20648354\n",
      "Iteration 301, loss = 0.20528327\n",
      "Iteration 302, loss = 0.20409242\n",
      "Iteration 303, loss = 0.20292811\n",
      "Iteration 304, loss = 0.20175552\n",
      "Iteration 305, loss = 0.20060457\n",
      "Iteration 306, loss = 0.19946149\n",
      "Iteration 307, loss = 0.19833169\n",
      "Iteration 308, loss = 0.19720929\n",
      "Iteration 309, loss = 0.19610200\n",
      "Iteration 310, loss = 0.19500959\n",
      "Iteration 311, loss = 0.19391812\n",
      "Iteration 312, loss = 0.19284897\n",
      "Iteration 313, loss = 0.19178033\n",
      "Iteration 314, loss = 0.19071486\n",
      "Iteration 315, loss = 0.18966367\n",
      "Iteration 316, loss = 0.18861395\n",
      "Iteration 317, loss = 0.18758322\n",
      "Iteration 318, loss = 0.18654886\n",
      "Iteration 319, loss = 0.18553334\n",
      "Iteration 320, loss = 0.18451464\n",
      "Iteration 321, loss = 0.18350591\n",
      "Iteration 322, loss = 0.18251146\n",
      "Iteration 323, loss = 0.18152682\n",
      "Iteration 324, loss = 0.18054904\n",
      "Iteration 325, loss = 0.17956625\n",
      "Iteration 326, loss = 0.17860130\n",
      "Iteration 327, loss = 0.17764945\n",
      "Iteration 328, loss = 0.17669657\n",
      "Iteration 329, loss = 0.17574730\n",
      "Iteration 330, loss = 0.17481610\n",
      "Iteration 331, loss = 0.17387712\n",
      "Iteration 332, loss = 0.17295042\n",
      "Iteration 333, loss = 0.17204492\n",
      "Iteration 334, loss = 0.17113330\n",
      "Iteration 335, loss = 0.17023307\n",
      "Iteration 336, loss = 0.16934756\n",
      "Iteration 337, loss = 0.16845087\n",
      "Iteration 338, loss = 0.16756797\n",
      "Iteration 339, loss = 0.16668639\n",
      "Iteration 340, loss = 0.16580129\n",
      "Iteration 341, loss = 0.16493048\n",
      "Iteration 342, loss = 0.16405770\n",
      "Iteration 343, loss = 0.16320911\n",
      "Iteration 344, loss = 0.16234816\n",
      "Iteration 345, loss = 0.16151105\n",
      "Iteration 346, loss = 0.16067381\n",
      "Iteration 347, loss = 0.15984141\n",
      "Iteration 348, loss = 0.15901700\n",
      "Iteration 349, loss = 0.15818349\n",
      "Iteration 350, loss = 0.15736680\n",
      "Iteration 351, loss = 0.15655317\n",
      "Iteration 352, loss = 0.15574402\n",
      "Iteration 353, loss = 0.15495790\n",
      "Iteration 354, loss = 0.15416762\n",
      "Iteration 355, loss = 0.15339319\n",
      "Iteration 356, loss = 0.15263197\n",
      "Iteration 357, loss = 0.15187687\n",
      "Iteration 358, loss = 0.15112174\n",
      "Iteration 359, loss = 0.15037899\n",
      "Iteration 360, loss = 0.14964206\n",
      "Iteration 361, loss = 0.14891444\n",
      "Iteration 362, loss = 0.14818699\n",
      "Iteration 363, loss = 0.14746599\n",
      "Iteration 364, loss = 0.14674959\n",
      "Iteration 365, loss = 0.14603955\n",
      "Iteration 366, loss = 0.14532776\n",
      "Iteration 367, loss = 0.14464045\n",
      "Iteration 368, loss = 0.14394602\n",
      "Iteration 369, loss = 0.14326250\n",
      "Iteration 370, loss = 0.14258648\n",
      "Iteration 371, loss = 0.14191854\n",
      "Iteration 372, loss = 0.14125875\n",
      "Iteration 373, loss = 0.14059625\n",
      "Iteration 374, loss = 0.13993515\n",
      "Iteration 375, loss = 0.13927957\n",
      "Iteration 376, loss = 0.13863286\n",
      "Iteration 377, loss = 0.13799045\n",
      "Iteration 378, loss = 0.13734792\n",
      "Iteration 379, loss = 0.13671213\n",
      "Iteration 380, loss = 0.13608186\n",
      "Iteration 381, loss = 0.13546114\n",
      "Iteration 382, loss = 0.13484402\n",
      "Iteration 383, loss = 0.13423170\n",
      "Iteration 384, loss = 0.13361422\n",
      "Iteration 385, loss = 0.13301401\n",
      "Iteration 386, loss = 0.13241254\n",
      "Iteration 387, loss = 0.13180832\n",
      "Iteration 388, loss = 0.13120755\n",
      "Iteration 389, loss = 0.13062180\n",
      "Iteration 390, loss = 0.13003173\n",
      "Iteration 391, loss = 0.12944887\n",
      "Iteration 392, loss = 0.12887015\n",
      "Iteration 393, loss = 0.12830118\n",
      "Iteration 394, loss = 0.12773867\n",
      "Iteration 395, loss = 0.12717176\n",
      "Iteration 396, loss = 0.12662037\n",
      "Iteration 397, loss = 0.12607474\n",
      "Iteration 398, loss = 0.12552598\n",
      "Iteration 399, loss = 0.12498531\n",
      "Iteration 400, loss = 0.12444885\n",
      "Iteration 401, loss = 0.12391258\n",
      "Iteration 402, loss = 0.12338845\n",
      "Iteration 403, loss = 0.12286275\n",
      "Iteration 404, loss = 0.12234350\n",
      "Iteration 405, loss = 0.12182690\n",
      "Iteration 406, loss = 0.12131830\n",
      "Iteration 407, loss = 0.12081217\n",
      "Iteration 408, loss = 0.12030489\n",
      "Iteration 409, loss = 0.11980782\n",
      "Iteration 410, loss = 0.11931120\n",
      "Iteration 411, loss = 0.11881719\n",
      "Iteration 412, loss = 0.11833016\n",
      "Iteration 413, loss = 0.11785347\n",
      "Iteration 414, loss = 0.11737459\n",
      "Iteration 415, loss = 0.11689432\n",
      "Iteration 416, loss = 0.11642979\n",
      "Iteration 417, loss = 0.11595745\n",
      "Iteration 418, loss = 0.11549875\n",
      "Iteration 419, loss = 0.11503370\n",
      "Iteration 420, loss = 0.11457630\n",
      "Iteration 421, loss = 0.11411931\n",
      "Iteration 422, loss = 0.11366809\n",
      "Iteration 423, loss = 0.11321213\n",
      "Iteration 424, loss = 0.11276691\n",
      "Iteration 425, loss = 0.11231861\n",
      "Iteration 426, loss = 0.11187916\n",
      "Iteration 427, loss = 0.11144138\n",
      "Iteration 428, loss = 0.11101308\n",
      "Iteration 429, loss = 0.11058377\n",
      "Iteration 430, loss = 0.11015997\n",
      "Iteration 431, loss = 0.10974573\n",
      "Iteration 432, loss = 0.10933069\n",
      "Iteration 433, loss = 0.10890809\n",
      "Iteration 434, loss = 0.10848925\n",
      "Iteration 435, loss = 0.10808569\n",
      "Iteration 436, loss = 0.10767148\n",
      "Iteration 437, loss = 0.10726592\n",
      "Iteration 438, loss = 0.10685901\n",
      "Iteration 439, loss = 0.10646390\n",
      "Iteration 440, loss = 0.10605848\n",
      "Iteration 441, loss = 0.10566369\n",
      "Iteration 442, loss = 0.10527552\n",
      "Iteration 443, loss = 0.10488945\n",
      "Iteration 444, loss = 0.10450707\n",
      "Iteration 445, loss = 0.10412428\n",
      "Iteration 446, loss = 0.10374862\n",
      "Iteration 447, loss = 0.10337948\n",
      "Iteration 448, loss = 0.10299809\n",
      "Iteration 449, loss = 0.10261945\n",
      "Iteration 450, loss = 0.10224779\n",
      "Iteration 451, loss = 0.10187708\n",
      "Iteration 452, loss = 0.10151353\n",
      "Iteration 453, loss = 0.10115242\n",
      "Iteration 454, loss = 0.10079293\n",
      "Iteration 455, loss = 0.10044193\n",
      "Iteration 456, loss = 0.10008178\n",
      "Iteration 457, loss = 0.09972873\n",
      "Iteration 458, loss = 0.09937384\n",
      "Iteration 459, loss = 0.09902029\n",
      "Iteration 460, loss = 0.09868084\n",
      "Iteration 461, loss = 0.09832993\n",
      "Iteration 462, loss = 0.09799287\n",
      "Iteration 463, loss = 0.09765815\n",
      "Iteration 464, loss = 0.09732549\n",
      "Iteration 465, loss = 0.09699402\n",
      "Iteration 466, loss = 0.09667259\n",
      "Iteration 467, loss = 0.09634481\n",
      "Iteration 468, loss = 0.09602344\n",
      "Iteration 469, loss = 0.09570619\n",
      "Iteration 470, loss = 0.09537918\n",
      "Iteration 471, loss = 0.09506393\n",
      "Iteration 472, loss = 0.09474379\n",
      "Iteration 473, loss = 0.09442454\n",
      "Iteration 474, loss = 0.09410655\n",
      "Iteration 475, loss = 0.09378953\n",
      "Iteration 476, loss = 0.09348391\n",
      "Iteration 477, loss = 0.09316918\n",
      "Iteration 478, loss = 0.09285851\n",
      "Iteration 479, loss = 0.09255286\n",
      "Iteration 480, loss = 0.09225441\n",
      "Iteration 481, loss = 0.09195435\n",
      "Iteration 482, loss = 0.09164929\n",
      "Iteration 483, loss = 0.09136200\n",
      "Iteration 484, loss = 0.09106556\n",
      "Iteration 485, loss = 0.09076779\n",
      "Iteration 486, loss = 0.09047682\n",
      "Iteration 487, loss = 0.09018117\n",
      "Iteration 488, loss = 0.08989933\n",
      "Iteration 489, loss = 0.08961518\n",
      "Iteration 490, loss = 0.08932931\n",
      "Iteration 491, loss = 0.08905661\n",
      "Iteration 492, loss = 0.08877848\n",
      "Iteration 493, loss = 0.08850680\n",
      "Iteration 494, loss = 0.08823397\n",
      "Iteration 495, loss = 0.08796567\n",
      "Iteration 496, loss = 0.08769987\n",
      "Iteration 497, loss = 0.08742601\n",
      "Iteration 498, loss = 0.08717611\n",
      "Iteration 499, loss = 0.08689427\n",
      "Iteration 500, loss = 0.08662475\n",
      "Iteration 501, loss = 0.08636807\n",
      "Iteration 502, loss = 0.08609787\n",
      "Iteration 503, loss = 0.08583916\n",
      "Iteration 504, loss = 0.08557717\n",
      "Iteration 505, loss = 0.08532174\n",
      "Iteration 506, loss = 0.08506543\n",
      "Iteration 507, loss = 0.08481383\n",
      "Iteration 508, loss = 0.08456819\n",
      "Iteration 509, loss = 0.08431849\n",
      "Iteration 510, loss = 0.08407250\n",
      "Iteration 511, loss = 0.08382938\n",
      "Iteration 512, loss = 0.08358394\n",
      "Iteration 513, loss = 0.08335532\n",
      "Iteration 514, loss = 0.08311343\n",
      "Iteration 515, loss = 0.08286508\n",
      "Iteration 516, loss = 0.08262520\n",
      "Iteration 517, loss = 0.08238174\n",
      "Iteration 518, loss = 0.08214020\n",
      "Iteration 519, loss = 0.08189984\n",
      "Iteration 520, loss = 0.08166343\n",
      "Iteration 521, loss = 0.08142845\n",
      "Iteration 522, loss = 0.08118892\n",
      "Iteration 523, loss = 0.08095964\n",
      "Iteration 524, loss = 0.08072584\n",
      "Iteration 525, loss = 0.08050050\n",
      "Iteration 526, loss = 0.08027773\n",
      "Iteration 527, loss = 0.08005096\n",
      "Iteration 528, loss = 0.07982680\n",
      "Iteration 529, loss = 0.07960956\n",
      "Iteration 530, loss = 0.07938450\n",
      "Iteration 531, loss = 0.07916871\n",
      "Iteration 532, loss = 0.07895156\n",
      "Iteration 533, loss = 0.07873600\n",
      "Iteration 534, loss = 0.07852602\n",
      "Iteration 535, loss = 0.07831472\n",
      "Iteration 536, loss = 0.07810589\n",
      "Iteration 537, loss = 0.07789877\n",
      "Iteration 538, loss = 0.07769137\n",
      "Iteration 539, loss = 0.07748832\n",
      "Iteration 540, loss = 0.07728554\n",
      "Iteration 541, loss = 0.07708383\n",
      "Iteration 542, loss = 0.07688601\n",
      "Iteration 543, loss = 0.07668264\n",
      "Iteration 544, loss = 0.07649155\n",
      "Iteration 545, loss = 0.07629098\n",
      "Iteration 546, loss = 0.07608975\n",
      "Iteration 547, loss = 0.07589741\n",
      "Iteration 548, loss = 0.07569757\n",
      "Iteration 549, loss = 0.07550582\n",
      "Iteration 550, loss = 0.07531016\n",
      "Iteration 551, loss = 0.07511548\n",
      "Iteration 552, loss = 0.07492644\n",
      "Iteration 553, loss = 0.07473234\n",
      "Iteration 554, loss = 0.07454720\n",
      "Iteration 555, loss = 0.07435805\n",
      "Iteration 556, loss = 0.07417780\n",
      "Iteration 557, loss = 0.07398953\n",
      "Iteration 558, loss = 0.07380532\n",
      "Iteration 559, loss = 0.07361712\n",
      "Iteration 560, loss = 0.07343942\n",
      "Iteration 561, loss = 0.07325241\n",
      "Iteration 562, loss = 0.07307299\n",
      "Iteration 563, loss = 0.07288946\n",
      "Iteration 564, loss = 0.07270723\n",
      "Iteration 565, loss = 0.07253140\n",
      "Iteration 566, loss = 0.07235297\n",
      "Iteration 567, loss = 0.07217074\n",
      "Iteration 568, loss = 0.07199567\n",
      "Iteration 569, loss = 0.07182027\n",
      "Iteration 570, loss = 0.07164594\n",
      "Iteration 571, loss = 0.07147399\n",
      "Iteration 572, loss = 0.07130127\n",
      "Iteration 573, loss = 0.07114257\n",
      "Iteration 574, loss = 0.07096811\n",
      "Iteration 575, loss = 0.07080052\n",
      "Iteration 576, loss = 0.07062736\n",
      "Iteration 577, loss = 0.07046381\n",
      "Iteration 578, loss = 0.07029618\n",
      "Iteration 579, loss = 0.07013471\n",
      "Iteration 580, loss = 0.06996652\n",
      "Iteration 581, loss = 0.06980509\n",
      "Iteration 582, loss = 0.06964324\n",
      "Iteration 583, loss = 0.06948009\n",
      "Iteration 584, loss = 0.06931862\n",
      "Iteration 585, loss = 0.06917155\n",
      "Iteration 586, loss = 0.06899984\n",
      "Iteration 587, loss = 0.06884285\n",
      "Iteration 588, loss = 0.06868397\n",
      "Iteration 589, loss = 0.06852522\n",
      "Iteration 590, loss = 0.06836826\n",
      "Iteration 591, loss = 0.06821515\n",
      "Iteration 592, loss = 0.06805471\n",
      "Iteration 593, loss = 0.06790196\n",
      "Iteration 594, loss = 0.06774884\n",
      "Iteration 595, loss = 0.06759572\n",
      "Iteration 596, loss = 0.06744328\n",
      "Iteration 597, loss = 0.06729281\n",
      "Iteration 598, loss = 0.06714496\n",
      "Iteration 599, loss = 0.06699773\n",
      "Iteration 600, loss = 0.06685073\n",
      "Iteration 601, loss = 0.06670311\n",
      "Iteration 602, loss = 0.06655615\n",
      "Iteration 603, loss = 0.06640772\n",
      "Iteration 604, loss = 0.06625945\n",
      "Iteration 605, loss = 0.06611141\n",
      "Iteration 606, loss = 0.06596386\n",
      "Iteration 607, loss = 0.06581523\n",
      "Iteration 608, loss = 0.06567452\n",
      "Iteration 609, loss = 0.06552769\n",
      "Iteration 610, loss = 0.06538273\n",
      "Iteration 611, loss = 0.06523518\n",
      "Iteration 612, loss = 0.06508844\n",
      "Iteration 613, loss = 0.06494536\n",
      "Iteration 614, loss = 0.06480305\n",
      "Iteration 615, loss = 0.06466174\n",
      "Iteration 616, loss = 0.06451757\n",
      "Iteration 617, loss = 0.06437578\n",
      "Iteration 618, loss = 0.06424112\n",
      "Iteration 619, loss = 0.06409653\n",
      "Iteration 620, loss = 0.06395839\n",
      "Iteration 621, loss = 0.06382421\n",
      "Iteration 622, loss = 0.06368669\n",
      "Iteration 623, loss = 0.06355760\n",
      "Iteration 624, loss = 0.06342615\n",
      "Iteration 625, loss = 0.06328716\n",
      "Iteration 626, loss = 0.06315189\n",
      "Iteration 627, loss = 0.06301707\n",
      "Iteration 628, loss = 0.06288285\n",
      "Iteration 629, loss = 0.06275182\n",
      "Iteration 630, loss = 0.06262032\n",
      "Iteration 631, loss = 0.06249087\n",
      "Iteration 632, loss = 0.06236416\n",
      "Iteration 633, loss = 0.06223914\n",
      "Iteration 634, loss = 0.06211300\n",
      "Iteration 635, loss = 0.06199215\n",
      "Iteration 636, loss = 0.06186479\n",
      "Iteration 637, loss = 0.06173535\n",
      "Iteration 638, loss = 0.06161002\n",
      "Iteration 639, loss = 0.06148545\n",
      "Iteration 640, loss = 0.06136206\n",
      "Iteration 641, loss = 0.06123577\n",
      "Iteration 642, loss = 0.06111741\n",
      "Iteration 643, loss = 0.06098994\n",
      "Iteration 644, loss = 0.06086720\n",
      "Iteration 645, loss = 0.06074498\n",
      "Iteration 646, loss = 0.06062074\n",
      "Iteration 647, loss = 0.06049703\n",
      "Iteration 648, loss = 0.06037809\n",
      "Iteration 649, loss = 0.06025965\n",
      "Iteration 650, loss = 0.06014243\n",
      "Iteration 651, loss = 0.06002967\n",
      "Iteration 652, loss = 0.05991075\n",
      "Iteration 653, loss = 0.05979670\n",
      "Iteration 654, loss = 0.05967829\n",
      "Iteration 655, loss = 0.05956652\n",
      "Iteration 656, loss = 0.05944643\n",
      "Iteration 657, loss = 0.05932739\n",
      "Iteration 658, loss = 0.05921035\n",
      "Iteration 659, loss = 0.05909588\n",
      "Iteration 660, loss = 0.05897690\n",
      "Iteration 661, loss = 0.05886667\n",
      "Iteration 662, loss = 0.05875137\n",
      "Iteration 663, loss = 0.05864189\n",
      "Iteration 664, loss = 0.05852641\n",
      "Iteration 665, loss = 0.05841566\n",
      "Iteration 666, loss = 0.05830751\n",
      "Iteration 667, loss = 0.05819548\n",
      "Iteration 668, loss = 0.05808794\n",
      "Iteration 669, loss = 0.05798079\n",
      "Iteration 670, loss = 0.05786920\n",
      "Iteration 671, loss = 0.05776042\n",
      "Iteration 672, loss = 0.05765148\n",
      "Iteration 673, loss = 0.05754349\n",
      "Iteration 674, loss = 0.05743799\n",
      "Iteration 675, loss = 0.05733423\n",
      "Iteration 676, loss = 0.05722744\n",
      "Iteration 677, loss = 0.05712329\n",
      "Iteration 678, loss = 0.05701590\n",
      "Iteration 679, loss = 0.05691949\n",
      "Iteration 680, loss = 0.05681233\n",
      "Iteration 681, loss = 0.05670636\n",
      "Iteration 682, loss = 0.05660303\n",
      "Iteration 683, loss = 0.05649864\n",
      "Iteration 684, loss = 0.05639439\n",
      "Iteration 685, loss = 0.05628873\n",
      "Iteration 686, loss = 0.05618454\n",
      "Iteration 687, loss = 0.05608605\n",
      "Iteration 688, loss = 0.05598067\n",
      "Iteration 689, loss = 0.05587919\n",
      "Iteration 690, loss = 0.05577806\n",
      "Iteration 691, loss = 0.05567566\n",
      "Iteration 692, loss = 0.05557847\n",
      "Iteration 693, loss = 0.05547403\n",
      "Iteration 694, loss = 0.05537844\n",
      "Iteration 695, loss = 0.05527544\n",
      "Iteration 696, loss = 0.05517883\n",
      "Iteration 697, loss = 0.05508134\n",
      "Iteration 698, loss = 0.05498516\n",
      "Iteration 699, loss = 0.05489415\n",
      "Iteration 700, loss = 0.05479415\n",
      "Iteration 701, loss = 0.05470029\n",
      "Iteration 702, loss = 0.05460499\n",
      "Iteration 703, loss = 0.05451568\n",
      "Iteration 704, loss = 0.05441345\n",
      "Iteration 705, loss = 0.05431899\n",
      "Iteration 706, loss = 0.05422866\n",
      "Iteration 707, loss = 0.05413541\n",
      "Iteration 708, loss = 0.05404125\n",
      "Iteration 709, loss = 0.05394973\n",
      "Iteration 710, loss = 0.05385726\n",
      "Iteration 711, loss = 0.05376896\n",
      "Iteration 712, loss = 0.05367553\n",
      "Iteration 713, loss = 0.05358410\n",
      "Iteration 714, loss = 0.05349291\n",
      "Iteration 715, loss = 0.05339850\n",
      "Iteration 716, loss = 0.05330722\n",
      "Iteration 717, loss = 0.05321033\n",
      "Iteration 718, loss = 0.05312000\n",
      "Iteration 719, loss = 0.05302799\n",
      "Iteration 720, loss = 0.05293106\n",
      "Iteration 721, loss = 0.05284100\n",
      "Iteration 722, loss = 0.05274982\n",
      "Iteration 723, loss = 0.05265899\n",
      "Iteration 724, loss = 0.05257186\n",
      "Iteration 725, loss = 0.05248163\n",
      "Iteration 726, loss = 0.05239111\n",
      "Iteration 727, loss = 0.05230360\n",
      "Iteration 728, loss = 0.05222011\n",
      "Iteration 729, loss = 0.05212687\n",
      "Iteration 730, loss = 0.05204122\n",
      "Iteration 731, loss = 0.05195259\n",
      "Iteration 732, loss = 0.05186391\n",
      "Iteration 733, loss = 0.05177967\n",
      "Iteration 734, loss = 0.05169287\n",
      "Iteration 735, loss = 0.05160729\n",
      "Iteration 736, loss = 0.05152613\n",
      "Iteration 737, loss = 0.05144006\n",
      "Iteration 738, loss = 0.05135230\n",
      "Iteration 739, loss = 0.05126999\n",
      "Iteration 740, loss = 0.05118765\n",
      "Iteration 741, loss = 0.05110204\n",
      "Iteration 742, loss = 0.05101727\n",
      "Iteration 743, loss = 0.05093710\n",
      "Iteration 744, loss = 0.05085428\n",
      "Iteration 745, loss = 0.05077568\n",
      "Iteration 746, loss = 0.05069471\n",
      "Iteration 747, loss = 0.05061131\n",
      "Iteration 748, loss = 0.05053292\n",
      "Iteration 749, loss = 0.05045169\n",
      "Iteration 750, loss = 0.05037266\n",
      "Iteration 751, loss = 0.05028912\n",
      "Iteration 752, loss = 0.05021058\n",
      "Iteration 753, loss = 0.05013087\n",
      "Iteration 754, loss = 0.05005478\n",
      "Iteration 755, loss = 0.04997517\n",
      "Iteration 756, loss = 0.04989823\n",
      "Iteration 757, loss = 0.04981929\n",
      "Iteration 758, loss = 0.04974290\n",
      "Iteration 759, loss = 0.04966671\n",
      "Iteration 760, loss = 0.04959604\n",
      "Iteration 761, loss = 0.04951805\n",
      "Iteration 762, loss = 0.04944358\n",
      "Iteration 763, loss = 0.04936655\n",
      "Iteration 764, loss = 0.04929150\n",
      "Iteration 765, loss = 0.04921522\n",
      "Iteration 766, loss = 0.04914244\n",
      "Iteration 767, loss = 0.04906461\n",
      "Iteration 768, loss = 0.04899144\n",
      "Iteration 769, loss = 0.04891448\n",
      "Iteration 770, loss = 0.04884060\n",
      "Iteration 771, loss = 0.04876947\n",
      "Iteration 772, loss = 0.04869359\n",
      "Iteration 773, loss = 0.04861721\n",
      "Iteration 774, loss = 0.04854474\n",
      "Iteration 775, loss = 0.04846779\n",
      "Iteration 776, loss = 0.04839747\n",
      "Iteration 777, loss = 0.04832563\n",
      "Iteration 778, loss = 0.04825097\n",
      "Iteration 779, loss = 0.04818275\n",
      "Iteration 780, loss = 0.04810798\n",
      "Iteration 781, loss = 0.04803221\n",
      "Iteration 782, loss = 0.04795869\n",
      "Iteration 783, loss = 0.04788378\n",
      "Iteration 784, loss = 0.04781026\n",
      "Iteration 785, loss = 0.04773387\n",
      "Iteration 786, loss = 0.04766207\n",
      "Iteration 787, loss = 0.04759206\n",
      "Iteration 788, loss = 0.04751735\n",
      "Iteration 789, loss = 0.04744276\n",
      "Iteration 790, loss = 0.04737356\n",
      "Iteration 791, loss = 0.04730462\n",
      "Iteration 792, loss = 0.04723443\n",
      "Iteration 793, loss = 0.04716411\n",
      "Iteration 794, loss = 0.04709488\n",
      "Iteration 795, loss = 0.04702609\n",
      "Iteration 796, loss = 0.04695683\n",
      "Iteration 797, loss = 0.04689627\n",
      "Iteration 798, loss = 0.04682471\n",
      "Iteration 799, loss = 0.04675559\n",
      "Iteration 800, loss = 0.04669106\n",
      "Iteration 801, loss = 0.04662131\n",
      "Iteration 802, loss = 0.04655432\n",
      "Iteration 803, loss = 0.04648720\n",
      "Iteration 804, loss = 0.04642053\n",
      "Iteration 805, loss = 0.04635547\n",
      "Iteration 806, loss = 0.04628978\n",
      "Iteration 807, loss = 0.04622554\n",
      "Iteration 808, loss = 0.04615941\n",
      "Iteration 809, loss = 0.04609647\n",
      "Iteration 810, loss = 0.04603149\n",
      "Iteration 811, loss = 0.04597040\n",
      "Iteration 812, loss = 0.04589929\n",
      "Iteration 813, loss = 0.04583356\n",
      "Iteration 814, loss = 0.04576993\n",
      "Iteration 815, loss = 0.04570906\n",
      "Iteration 816, loss = 0.04563930\n",
      "Iteration 817, loss = 0.04557357\n",
      "Iteration 818, loss = 0.04551008\n",
      "Iteration 819, loss = 0.04544229\n",
      "Iteration 820, loss = 0.04537890\n",
      "Iteration 821, loss = 0.04531162\n",
      "Iteration 822, loss = 0.04524869\n",
      "Iteration 823, loss = 0.04518623\n",
      "Iteration 824, loss = 0.04512031\n",
      "Iteration 825, loss = 0.04505540\n",
      "Iteration 826, loss = 0.04499260\n",
      "Iteration 827, loss = 0.04492967\n",
      "Iteration 828, loss = 0.04486271\n",
      "Iteration 829, loss = 0.04480237\n",
      "Iteration 830, loss = 0.04473781\n",
      "Iteration 831, loss = 0.04467490\n",
      "Iteration 832, loss = 0.04461419\n",
      "Iteration 833, loss = 0.04455293\n",
      "Iteration 834, loss = 0.04449335\n",
      "Iteration 835, loss = 0.04442985\n",
      "Iteration 836, loss = 0.04437030\n",
      "Iteration 837, loss = 0.04430938\n",
      "Iteration 838, loss = 0.04424840\n",
      "Iteration 839, loss = 0.04418601\n",
      "Iteration 840, loss = 0.04412912\n",
      "Iteration 841, loss = 0.04406593\n",
      "Iteration 842, loss = 0.04400584\n",
      "Iteration 843, loss = 0.04394662\n",
      "Iteration 844, loss = 0.04388881\n",
      "Iteration 845, loss = 0.04382936\n",
      "Iteration 846, loss = 0.04377094\n",
      "Iteration 847, loss = 0.04371424\n",
      "Iteration 848, loss = 0.04365612\n",
      "Iteration 849, loss = 0.04359940\n",
      "Iteration 850, loss = 0.04354282\n",
      "Iteration 851, loss = 0.04348430\n",
      "Iteration 852, loss = 0.04342624\n",
      "Iteration 853, loss = 0.04336855\n",
      "Iteration 854, loss = 0.04331233\n",
      "Iteration 855, loss = 0.04325413\n",
      "Iteration 856, loss = 0.04319689\n",
      "Iteration 857, loss = 0.04314379\n",
      "Iteration 858, loss = 0.04308512\n",
      "Iteration 859, loss = 0.04303129\n",
      "Iteration 860, loss = 0.04297350\n",
      "Iteration 861, loss = 0.04291622\n",
      "Iteration 862, loss = 0.04285656\n",
      "Iteration 863, loss = 0.04279890\n",
      "Iteration 864, loss = 0.04273945\n",
      "Iteration 865, loss = 0.04268194\n",
      "Iteration 866, loss = 0.04262779\n",
      "Iteration 867, loss = 0.04257192\n",
      "Iteration 868, loss = 0.04251587\n",
      "Iteration 869, loss = 0.04246174\n",
      "Iteration 870, loss = 0.04240822\n",
      "Iteration 871, loss = 0.04235792\n",
      "Iteration 872, loss = 0.04230254\n",
      "Iteration 873, loss = 0.04224629\n",
      "Iteration 874, loss = 0.04219247\n",
      "Iteration 875, loss = 0.04213872\n",
      "Iteration 876, loss = 0.04208132\n",
      "Iteration 877, loss = 0.04203508\n",
      "Iteration 878, loss = 0.04197752\n",
      "Iteration 879, loss = 0.04192308\n",
      "Iteration 880, loss = 0.04186856\n",
      "Iteration 881, loss = 0.04182061\n",
      "Iteration 882, loss = 0.04176290\n",
      "Iteration 883, loss = 0.04170998\n",
      "Iteration 884, loss = 0.04165602\n",
      "Iteration 885, loss = 0.04160247\n",
      "Iteration 886, loss = 0.04154821\n",
      "Iteration 887, loss = 0.04149695\n",
      "Iteration 888, loss = 0.04144295\n",
      "Iteration 889, loss = 0.04138851\n",
      "Iteration 890, loss = 0.04133836\n",
      "Iteration 891, loss = 0.04128178\n",
      "Iteration 892, loss = 0.04122772\n",
      "Iteration 893, loss = 0.04117380\n",
      "Iteration 894, loss = 0.04112284\n",
      "Iteration 895, loss = 0.04106503\n",
      "Iteration 896, loss = 0.04101176\n",
      "Iteration 897, loss = 0.04095856\n",
      "Iteration 898, loss = 0.04090550\n",
      "Iteration 899, loss = 0.04085264\n",
      "Iteration 900, loss = 0.04079872\n",
      "Iteration 901, loss = 0.04074792\n",
      "Iteration 902, loss = 0.04069561\n",
      "Iteration 903, loss = 0.04064352\n",
      "Iteration 904, loss = 0.04059493\n",
      "Iteration 905, loss = 0.04053664\n",
      "Iteration 906, loss = 0.04048599\n",
      "Iteration 907, loss = 0.04043284\n",
      "Iteration 908, loss = 0.04038308\n",
      "Iteration 909, loss = 0.04033263\n",
      "Iteration 910, loss = 0.04028302\n",
      "Iteration 911, loss = 0.04023173\n",
      "Iteration 912, loss = 0.04018359\n",
      "Iteration 913, loss = 0.04013135\n",
      "Iteration 914, loss = 0.04008052\n",
      "Iteration 915, loss = 0.04003403\n",
      "Iteration 916, loss = 0.03997972\n",
      "Iteration 917, loss = 0.03993304\n",
      "Iteration 918, loss = 0.03988185\n",
      "Iteration 919, loss = 0.03983274\n",
      "Iteration 920, loss = 0.03978498\n",
      "Iteration 921, loss = 0.03973605\n",
      "Iteration 922, loss = 0.03968563\n",
      "Iteration 923, loss = 0.03963630\n",
      "Iteration 924, loss = 0.03958838\n",
      "Iteration 925, loss = 0.03953935\n",
      "Iteration 926, loss = 0.03949010\n",
      "Iteration 927, loss = 0.03943993\n",
      "Iteration 928, loss = 0.03939130\n",
      "Iteration 929, loss = 0.03934472\n",
      "Iteration 930, loss = 0.03929215\n",
      "Iteration 931, loss = 0.03924171\n",
      "Iteration 932, loss = 0.03919371\n",
      "Iteration 933, loss = 0.03914237\n",
      "Iteration 934, loss = 0.03909740\n",
      "Iteration 935, loss = 0.03905198\n",
      "Iteration 936, loss = 0.03900239\n",
      "Iteration 937, loss = 0.03896196\n",
      "Iteration 938, loss = 0.03891233\n",
      "Iteration 939, loss = 0.03886431\n",
      "Iteration 940, loss = 0.03881892\n",
      "Iteration 941, loss = 0.03877185\n",
      "Iteration 942, loss = 0.03872730\n",
      "Iteration 943, loss = 0.03868026\n",
      "Iteration 944, loss = 0.03863624\n",
      "Iteration 945, loss = 0.03858866\n",
      "Iteration 946, loss = 0.03854236\n",
      "Iteration 947, loss = 0.03849957\n",
      "Iteration 948, loss = 0.03845454\n",
      "Iteration 949, loss = 0.03840483\n",
      "Iteration 950, loss = 0.03835873\n",
      "Iteration 951, loss = 0.03830809\n",
      "Iteration 952, loss = 0.03826154\n",
      "Iteration 953, loss = 0.03821412\n",
      "Iteration 954, loss = 0.03816627\n",
      "Iteration 955, loss = 0.03812190\n",
      "Iteration 956, loss = 0.03807771\n",
      "Iteration 957, loss = 0.03803098\n",
      "Iteration 958, loss = 0.03798574\n",
      "Iteration 959, loss = 0.03794288\n",
      "Iteration 960, loss = 0.03789911\n",
      "Iteration 961, loss = 0.03785368\n",
      "Iteration 962, loss = 0.03781103\n",
      "Iteration 963, loss = 0.03776654\n",
      "Iteration 964, loss = 0.03772273\n",
      "Iteration 965, loss = 0.03767991\n",
      "Iteration 966, loss = 0.03763788\n",
      "Iteration 967, loss = 0.03759567\n",
      "Iteration 968, loss = 0.03755384\n",
      "Iteration 969, loss = 0.03751060\n",
      "Iteration 970, loss = 0.03746872\n",
      "Iteration 971, loss = 0.03742959\n",
      "Iteration 972, loss = 0.03738530\n",
      "Iteration 973, loss = 0.03734107\n",
      "Iteration 974, loss = 0.03729983\n",
      "Iteration 975, loss = 0.03725783\n",
      "Iteration 976, loss = 0.03721447\n",
      "Iteration 977, loss = 0.03716992\n",
      "Iteration 978, loss = 0.03712809\n",
      "Iteration 979, loss = 0.03708591\n",
      "Iteration 980, loss = 0.03704592\n",
      "Iteration 981, loss = 0.03700753\n",
      "Iteration 982, loss = 0.03696389\n",
      "Iteration 983, loss = 0.03692397\n",
      "Iteration 984, loss = 0.03688348\n",
      "Iteration 985, loss = 0.03684371\n",
      "Iteration 986, loss = 0.03680085\n",
      "Iteration 987, loss = 0.03676040\n",
      "Iteration 988, loss = 0.03672102\n",
      "Iteration 989, loss = 0.03668334\n",
      "Iteration 990, loss = 0.03664727\n",
      "Iteration 991, loss = 0.03660750\n",
      "Iteration 992, loss = 0.03656688\n",
      "Iteration 993, loss = 0.03652786\n",
      "Iteration 994, loss = 0.03648513\n",
      "Iteration 995, loss = 0.03644282\n",
      "Iteration 996, loss = 0.03640443\n",
      "Iteration 997, loss = 0.03636342\n",
      "Iteration 998, loss = 0.03632351\n",
      "Iteration 999, loss = 0.03628354\n",
      "Iteration 1000, loss = 0.03624206\n",
      "Iteration 1001, loss = 0.03620554\n",
      "Iteration 1002, loss = 0.03616349\n",
      "Iteration 1003, loss = 0.03612370\n",
      "Iteration 1004, loss = 0.03608648\n",
      "Iteration 1005, loss = 0.03604916\n",
      "Iteration 1006, loss = 0.03601187\n",
      "Iteration 1007, loss = 0.03597442\n",
      "Iteration 1008, loss = 0.03593461\n",
      "Iteration 1009, loss = 0.03589607\n",
      "Iteration 1010, loss = 0.03585928\n",
      "Iteration 1011, loss = 0.03582007\n",
      "Iteration 1012, loss = 0.03578355\n",
      "Iteration 1013, loss = 0.03574397\n",
      "Iteration 1014, loss = 0.03570729\n",
      "Iteration 1015, loss = 0.03567236\n",
      "Iteration 1016, loss = 0.03563605\n",
      "Iteration 1017, loss = 0.03559896\n",
      "Iteration 1018, loss = 0.03556417\n",
      "Iteration 1019, loss = 0.03552813\n",
      "Iteration 1020, loss = 0.03549199\n",
      "Iteration 1021, loss = 0.03545763\n",
      "Iteration 1022, loss = 0.03542286\n",
      "Iteration 1023, loss = 0.03538118\n",
      "Iteration 1024, loss = 0.03534469\n",
      "Iteration 1025, loss = 0.03530618\n",
      "Iteration 1026, loss = 0.03526707\n",
      "Iteration 1027, loss = 0.03522920\n",
      "Iteration 1028, loss = 0.03519225\n",
      "Iteration 1029, loss = 0.03515786\n",
      "Iteration 1030, loss = 0.03512002\n",
      "Iteration 1031, loss = 0.03508290\n",
      "Iteration 1032, loss = 0.03504715\n",
      "Iteration 1033, loss = 0.03501136\n",
      "Iteration 1034, loss = 0.03497329\n",
      "Iteration 1035, loss = 0.03493702\n",
      "Iteration 1036, loss = 0.03490029\n",
      "Iteration 1037, loss = 0.03486436\n",
      "Iteration 1038, loss = 0.03482721\n",
      "Iteration 1039, loss = 0.03479170\n",
      "Iteration 1040, loss = 0.03475253\n",
      "Iteration 1041, loss = 0.03471752\n",
      "Iteration 1042, loss = 0.03467749\n",
      "Iteration 1043, loss = 0.03464322\n",
      "Iteration 1044, loss = 0.03460695\n",
      "Iteration 1045, loss = 0.03456980\n",
      "Iteration 1046, loss = 0.03453571\n",
      "Iteration 1047, loss = 0.03449887\n",
      "Iteration 1048, loss = 0.03446314\n",
      "Iteration 1049, loss = 0.03442818\n",
      "Iteration 1050, loss = 0.03439196\n",
      "Iteration 1051, loss = 0.03435640\n",
      "Iteration 1052, loss = 0.03432176\n",
      "Iteration 1053, loss = 0.03428910\n",
      "Iteration 1054, loss = 0.03425297\n",
      "Iteration 1055, loss = 0.03421896\n",
      "Iteration 1056, loss = 0.03418341\n",
      "Iteration 1057, loss = 0.03415052\n",
      "Iteration 1058, loss = 0.03411595\n",
      "Iteration 1059, loss = 0.03408027\n",
      "Iteration 1060, loss = 0.03404608\n",
      "Iteration 1061, loss = 0.03401079\n",
      "Iteration 1062, loss = 0.03397464\n",
      "Iteration 1063, loss = 0.03393729\n",
      "Iteration 1064, loss = 0.03390391\n",
      "Iteration 1065, loss = 0.03386887\n",
      "Iteration 1066, loss = 0.03383196\n",
      "Iteration 1067, loss = 0.03379538\n",
      "Iteration 1068, loss = 0.03376368\n",
      "Iteration 1069, loss = 0.03372755\n",
      "Iteration 1070, loss = 0.03369256\n",
      "Iteration 1071, loss = 0.03366029\n",
      "Iteration 1072, loss = 0.03362514\n",
      "Iteration 1073, loss = 0.03358990\n",
      "Iteration 1074, loss = 0.03355765\n",
      "Iteration 1075, loss = 0.03352291\n",
      "Iteration 1076, loss = 0.03348852\n",
      "Iteration 1077, loss = 0.03345733\n",
      "Iteration 1078, loss = 0.03342029\n",
      "Iteration 1079, loss = 0.03338486\n",
      "Iteration 1080, loss = 0.03334917\n",
      "Iteration 1081, loss = 0.03331552\n",
      "Iteration 1082, loss = 0.03328413\n",
      "Iteration 1083, loss = 0.03324389\n",
      "Iteration 1084, loss = 0.03321066\n",
      "Iteration 1085, loss = 0.03317734\n",
      "Iteration 1086, loss = 0.03314221\n",
      "Iteration 1087, loss = 0.03311158\n",
      "Iteration 1088, loss = 0.03308102\n",
      "Iteration 1089, loss = 0.03304669\n",
      "Iteration 1090, loss = 0.03301524\n",
      "Iteration 1091, loss = 0.03298525\n",
      "Iteration 1092, loss = 0.03295270\n",
      "Iteration 1093, loss = 0.03292078\n",
      "Iteration 1094, loss = 0.03289300\n",
      "Iteration 1095, loss = 0.03285882\n",
      "Iteration 1096, loss = 0.03282959\n",
      "Iteration 1097, loss = 0.03279609\n",
      "Iteration 1098, loss = 0.03276504\n",
      "Iteration 1099, loss = 0.03273210\n",
      "Iteration 1100, loss = 0.03270060\n",
      "Iteration 1101, loss = 0.03266766\n",
      "Iteration 1102, loss = 0.03263593\n",
      "Iteration 1103, loss = 0.03260331\n",
      "Iteration 1104, loss = 0.03257129\n",
      "Iteration 1105, loss = 0.03254232\n",
      "Iteration 1106, loss = 0.03250995\n",
      "Iteration 1107, loss = 0.03247873\n",
      "Iteration 1108, loss = 0.03244947\n",
      "Iteration 1109, loss = 0.03241813\n",
      "Iteration 1110, loss = 0.03239005\n",
      "Iteration 1111, loss = 0.03235772\n",
      "Iteration 1112, loss = 0.03232678\n",
      "Iteration 1113, loss = 0.03229602\n",
      "Iteration 1114, loss = 0.03226423\n",
      "Iteration 1115, loss = 0.03223494\n",
      "Iteration 1116, loss = 0.03220186\n",
      "Iteration 1117, loss = 0.03216744\n",
      "Iteration 1118, loss = 0.03213924\n",
      "Iteration 1119, loss = 0.03210635\n",
      "Iteration 1120, loss = 0.03207644\n",
      "Iteration 1121, loss = 0.03204409\n",
      "Iteration 1122, loss = 0.03201622\n",
      "Iteration 1123, loss = 0.03198486\n",
      "Iteration 1124, loss = 0.03195116\n",
      "Iteration 1125, loss = 0.03192146\n",
      "Iteration 1126, loss = 0.03189035\n",
      "Iteration 1127, loss = 0.03185920\n",
      "Iteration 1128, loss = 0.03182898\n",
      "Iteration 1129, loss = 0.03180072\n",
      "Iteration 1130, loss = 0.03176802\n",
      "Iteration 1131, loss = 0.03173825\n",
      "Iteration 1132, loss = 0.03170776\n",
      "Iteration 1133, loss = 0.03167601\n",
      "Iteration 1134, loss = 0.03165094\n",
      "Iteration 1135, loss = 0.03161628\n",
      "Iteration 1136, loss = 0.03158515\n",
      "Iteration 1137, loss = 0.03155529\n",
      "Iteration 1138, loss = 0.03152587\n",
      "Iteration 1139, loss = 0.03149730\n",
      "Iteration 1140, loss = 0.03146947\n",
      "Iteration 1141, loss = 0.03143885\n",
      "Iteration 1142, loss = 0.03141127\n",
      "Iteration 1143, loss = 0.03137916\n",
      "Iteration 1144, loss = 0.03135172\n",
      "Iteration 1145, loss = 0.03132326\n",
      "Iteration 1146, loss = 0.03129608\n",
      "Iteration 1147, loss = 0.03127063\n",
      "Iteration 1148, loss = 0.03123981\n",
      "Iteration 1149, loss = 0.03121199\n",
      "Iteration 1150, loss = 0.03118351\n",
      "Iteration 1151, loss = 0.03115511\n",
      "Iteration 1152, loss = 0.03112727\n",
      "Iteration 1153, loss = 0.03109686\n",
      "Iteration 1154, loss = 0.03107087\n",
      "Iteration 1155, loss = 0.03104225\n",
      "Iteration 1156, loss = 0.03101549\n",
      "Iteration 1157, loss = 0.03098834\n",
      "Iteration 1158, loss = 0.03096128\n",
      "Iteration 1159, loss = 0.03093519\n",
      "Iteration 1160, loss = 0.03090829\n",
      "Iteration 1161, loss = 0.03088218\n",
      "Iteration 1162, loss = 0.03085384\n",
      "Iteration 1163, loss = 0.03082755\n",
      "Iteration 1164, loss = 0.03079950\n",
      "Iteration 1165, loss = 0.03077238\n",
      "Iteration 1166, loss = 0.03074543\n",
      "Iteration 1167, loss = 0.03071798\n",
      "Iteration 1168, loss = 0.03068930\n",
      "Iteration 1169, loss = 0.03066189\n",
      "Iteration 1170, loss = 0.03063450\n",
      "Iteration 1171, loss = 0.03060783\n",
      "Iteration 1172, loss = 0.03057797\n",
      "Iteration 1173, loss = 0.03054602\n",
      "Iteration 1174, loss = 0.03051586\n",
      "Iteration 1175, loss = 0.03048856\n",
      "Iteration 1176, loss = 0.03045865\n",
      "Iteration 1177, loss = 0.03042981\n",
      "Iteration 1178, loss = 0.03040192\n",
      "Iteration 1179, loss = 0.03037184\n",
      "Iteration 1180, loss = 0.03034414\n",
      "Iteration 1181, loss = 0.03031569\n",
      "Iteration 1182, loss = 0.03028763\n",
      "Iteration 1183, loss = 0.03025972\n",
      "Iteration 1184, loss = 0.03023282\n",
      "Iteration 1185, loss = 0.03020541\n",
      "Iteration 1186, loss = 0.03018116\n",
      "Iteration 1187, loss = 0.03015137\n",
      "Iteration 1188, loss = 0.03012645\n",
      "Iteration 1189, loss = 0.03010004\n",
      "Iteration 1190, loss = 0.03007590\n",
      "Iteration 1191, loss = 0.03005165\n",
      "Iteration 1192, loss = 0.03002711\n",
      "Iteration 1193, loss = 0.02999977\n",
      "Iteration 1194, loss = 0.02997378\n",
      "Iteration 1195, loss = 0.02994664\n",
      "Iteration 1196, loss = 0.02991649\n",
      "Iteration 1197, loss = 0.02988910\n",
      "Iteration 1198, loss = 0.02985956\n",
      "Iteration 1199, loss = 0.02983402\n",
      "Iteration 1200, loss = 0.02980627\n",
      "Iteration 1201, loss = 0.02977769\n",
      "Iteration 1202, loss = 0.02975004\n",
      "Iteration 1203, loss = 0.02972570\n",
      "Iteration 1204, loss = 0.02969400\n",
      "Iteration 1205, loss = 0.02966467\n",
      "Iteration 1206, loss = 0.02963618\n",
      "Iteration 1207, loss = 0.02960677\n",
      "Iteration 1208, loss = 0.02958186\n",
      "Iteration 1209, loss = 0.02955237\n",
      "Iteration 1210, loss = 0.02952488\n",
      "Iteration 1211, loss = 0.02949554\n",
      "Iteration 1212, loss = 0.02947096\n",
      "Iteration 1213, loss = 0.02944197\n",
      "Iteration 1214, loss = 0.02941546\n",
      "Iteration 1215, loss = 0.02938798\n",
      "Iteration 1216, loss = 0.02936543\n",
      "Iteration 1217, loss = 0.02933391\n",
      "Iteration 1218, loss = 0.02930847\n",
      "Iteration 1219, loss = 0.02928136\n",
      "Iteration 1220, loss = 0.02925363\n",
      "Iteration 1221, loss = 0.02922800\n",
      "Iteration 1222, loss = 0.02920142\n",
      "Iteration 1223, loss = 0.02917300\n",
      "Iteration 1224, loss = 0.02914722\n",
      "Iteration 1225, loss = 0.02911716\n",
      "Iteration 1226, loss = 0.02909492\n",
      "Iteration 1227, loss = 0.02906696\n",
      "Iteration 1228, loss = 0.02903797\n",
      "Iteration 1229, loss = 0.02901178\n",
      "Iteration 1230, loss = 0.02898550\n",
      "Iteration 1231, loss = 0.02895996\n",
      "Iteration 1232, loss = 0.02893415\n",
      "Iteration 1233, loss = 0.02890812\n",
      "Iteration 1234, loss = 0.02888373\n",
      "Iteration 1235, loss = 0.02885821\n",
      "Iteration 1236, loss = 0.02883347\n",
      "Iteration 1237, loss = 0.02881040\n",
      "Iteration 1238, loss = 0.02878418\n",
      "Iteration 1239, loss = 0.02875749\n",
      "Iteration 1240, loss = 0.02873241\n",
      "Iteration 1241, loss = 0.02870573\n",
      "Iteration 1242, loss = 0.02867736\n",
      "Iteration 1243, loss = 0.02865822\n",
      "Iteration 1244, loss = 0.02863205\n",
      "Iteration 1245, loss = 0.02860223\n",
      "Iteration 1246, loss = 0.02857608\n",
      "Iteration 1247, loss = 0.02855021\n",
      "Iteration 1248, loss = 0.02852438\n",
      "Iteration 1249, loss = 0.02849843\n",
      "Iteration 1250, loss = 0.02847352\n",
      "Iteration 1251, loss = 0.02844619\n",
      "Iteration 1252, loss = 0.02842356\n",
      "Iteration 1253, loss = 0.02839789\n",
      "Iteration 1254, loss = 0.02837618\n",
      "Iteration 1255, loss = 0.02834785\n",
      "Iteration 1256, loss = 0.02832318\n",
      "Iteration 1257, loss = 0.02829750\n",
      "Iteration 1258, loss = 0.02827266\n",
      "Iteration 1259, loss = 0.02825188\n",
      "Iteration 1260, loss = 0.02822418\n",
      "Iteration 1261, loss = 0.02820176\n",
      "Iteration 1262, loss = 0.02817721\n",
      "Iteration 1263, loss = 0.02815216\n",
      "Iteration 1264, loss = 0.02812730\n",
      "Iteration 1265, loss = 0.02810333\n",
      "Iteration 1266, loss = 0.02807826\n",
      "Iteration 1267, loss = 0.02805334\n",
      "Iteration 1268, loss = 0.02802795\n",
      "Iteration 1269, loss = 0.02800351\n",
      "Iteration 1270, loss = 0.02797867\n",
      "Iteration 1271, loss = 0.02795266\n",
      "Iteration 1272, loss = 0.02792969\n",
      "Iteration 1273, loss = 0.02790528\n",
      "Iteration 1274, loss = 0.02788104\n",
      "Iteration 1275, loss = 0.02785832\n",
      "Iteration 1276, loss = 0.02783448\n",
      "Iteration 1277, loss = 0.02781198\n",
      "Iteration 1278, loss = 0.02779040\n",
      "Iteration 1279, loss = 0.02776607\n",
      "Iteration 1280, loss = 0.02774378\n",
      "Iteration 1281, loss = 0.02772258\n",
      "Iteration 1282, loss = 0.02769778\n",
      "Iteration 1283, loss = 0.02767468\n",
      "Iteration 1284, loss = 0.02765110\n",
      "Iteration 1285, loss = 0.02762840\n",
      "Iteration 1286, loss = 0.02760853\n",
      "Iteration 1287, loss = 0.02758467\n",
      "Iteration 1288, loss = 0.02755993\n",
      "Iteration 1289, loss = 0.02753983\n",
      "Iteration 1290, loss = 0.02751411\n",
      "Iteration 1291, loss = 0.02749047\n",
      "Iteration 1292, loss = 0.02746684\n",
      "Iteration 1293, loss = 0.02744259\n",
      "Iteration 1294, loss = 0.02742083\n",
      "Iteration 1295, loss = 0.02739386\n",
      "Iteration 1296, loss = 0.02737321\n",
      "Iteration 1297, loss = 0.02734493\n",
      "Iteration 1298, loss = 0.02732081\n",
      "Iteration 1299, loss = 0.02729500\n",
      "Iteration 1300, loss = 0.02727097\n",
      "Iteration 1301, loss = 0.02724584\n",
      "Iteration 1302, loss = 0.02722234\n",
      "Iteration 1303, loss = 0.02719958\n",
      "Iteration 1304, loss = 0.02717433\n",
      "Iteration 1305, loss = 0.02714889\n",
      "Iteration 1306, loss = 0.02712628\n",
      "Iteration 1307, loss = 0.02710121\n",
      "Iteration 1308, loss = 0.02707701\n",
      "Iteration 1309, loss = 0.02705259\n",
      "Iteration 1310, loss = 0.02702974\n",
      "Iteration 1311, loss = 0.02700574\n",
      "Iteration 1312, loss = 0.02698593\n",
      "Iteration 1313, loss = 0.02695959\n",
      "Iteration 1314, loss = 0.02693544\n",
      "Iteration 1315, loss = 0.02691257\n",
      "Iteration 1316, loss = 0.02689064\n",
      "Iteration 1317, loss = 0.02686612\n",
      "Iteration 1318, loss = 0.02684444\n",
      "Iteration 1319, loss = 0.02682530\n",
      "Iteration 1320, loss = 0.02679842\n",
      "Iteration 1321, loss = 0.02677498\n",
      "Iteration 1322, loss = 0.02675099\n",
      "Iteration 1323, loss = 0.02673091\n",
      "Iteration 1324, loss = 0.02670647\n",
      "Iteration 1325, loss = 0.02668460\n",
      "Iteration 1326, loss = 0.02666211\n",
      "Iteration 1327, loss = 0.02664127\n",
      "Iteration 1328, loss = 0.02661663\n",
      "Iteration 1329, loss = 0.02659105\n",
      "Iteration 1330, loss = 0.02656924\n",
      "Iteration 1331, loss = 0.02655075\n",
      "Iteration 1332, loss = 0.02652331\n",
      "Iteration 1333, loss = 0.02649782\n",
      "Iteration 1334, loss = 0.02648106\n",
      "Iteration 1335, loss = 0.02645658\n",
      "Iteration 1336, loss = 0.02643412\n",
      "Iteration 1337, loss = 0.02641540\n",
      "Iteration 1338, loss = 0.02638987\n",
      "Iteration 1339, loss = 0.02636792\n",
      "Iteration 1340, loss = 0.02634640\n",
      "Iteration 1341, loss = 0.02632361\n",
      "Iteration 1342, loss = 0.02630196\n",
      "Iteration 1343, loss = 0.02628020\n",
      "Iteration 1344, loss = 0.02626187\n",
      "Iteration 1345, loss = 0.02623871\n",
      "Iteration 1346, loss = 0.02621611\n",
      "Iteration 1347, loss = 0.02619724\n",
      "Iteration 1348, loss = 0.02617452\n",
      "Iteration 1349, loss = 0.02615240\n",
      "Iteration 1350, loss = 0.02613113\n",
      "Iteration 1351, loss = 0.02610869\n",
      "Iteration 1352, loss = 0.02608662\n",
      "Iteration 1353, loss = 0.02606410\n",
      "Iteration 1354, loss = 0.02604275\n",
      "Iteration 1355, loss = 0.02602117\n",
      "Iteration 1356, loss = 0.02600122\n",
      "Iteration 1357, loss = 0.02597952\n",
      "Iteration 1358, loss = 0.02595998\n",
      "Iteration 1359, loss = 0.02594021\n",
      "Iteration 1360, loss = 0.02591781\n",
      "Iteration 1361, loss = 0.02589691\n",
      "Iteration 1362, loss = 0.02587677\n",
      "Iteration 1363, loss = 0.02585505\n",
      "Iteration 1364, loss = 0.02583383\n",
      "Iteration 1365, loss = 0.02581317\n",
      "Iteration 1366, loss = 0.02579260\n",
      "Iteration 1367, loss = 0.02576987\n",
      "Iteration 1368, loss = 0.02574827\n",
      "Iteration 1369, loss = 0.02572886\n",
      "Iteration 1370, loss = 0.02570670\n",
      "Iteration 1371, loss = 0.02568661\n",
      "Iteration 1372, loss = 0.02566589\n",
      "Iteration 1373, loss = 0.02564470\n",
      "Iteration 1374, loss = 0.02562515\n",
      "Iteration 1375, loss = 0.02560476\n",
      "Iteration 1376, loss = 0.02558504\n",
      "Iteration 1377, loss = 0.02556613\n",
      "Iteration 1378, loss = 0.02554981\n",
      "Iteration 1379, loss = 0.02552616\n",
      "Iteration 1380, loss = 0.02550508\n",
      "Iteration 1381, loss = 0.02548424\n",
      "Iteration 1382, loss = 0.02546478\n",
      "Iteration 1383, loss = 0.02544190\n",
      "Iteration 1384, loss = 0.02541948\n",
      "Iteration 1385, loss = 0.02539809\n",
      "Iteration 1386, loss = 0.02537383\n",
      "Iteration 1387, loss = 0.02535406\n",
      "Iteration 1388, loss = 0.02533086\n",
      "Iteration 1389, loss = 0.02530815\n",
      "Iteration 1390, loss = 0.02528787\n",
      "Iteration 1391, loss = 0.02526618\n",
      "Iteration 1392, loss = 0.02524516\n",
      "Iteration 1393, loss = 0.02522351\n",
      "Iteration 1394, loss = 0.02520433\n",
      "Iteration 1395, loss = 0.02518444\n",
      "Iteration 1396, loss = 0.02516486\n",
      "Iteration 1397, loss = 0.02514595\n",
      "Iteration 1398, loss = 0.02512451\n",
      "Iteration 1399, loss = 0.02510516\n",
      "Iteration 1400, loss = 0.02508546\n",
      "Iteration 1401, loss = 0.02506733\n",
      "Iteration 1402, loss = 0.02504600\n",
      "Iteration 1403, loss = 0.02502612\n",
      "Iteration 1404, loss = 0.02500668\n",
      "Iteration 1405, loss = 0.02498712\n",
      "Iteration 1406, loss = 0.02496753\n",
      "Iteration 1407, loss = 0.02494831\n",
      "Iteration 1408, loss = 0.02493222\n",
      "Iteration 1409, loss = 0.02491197\n",
      "Iteration 1410, loss = 0.02489183\n",
      "Iteration 1411, loss = 0.02487360\n",
      "Iteration 1412, loss = 0.02485460\n",
      "Iteration 1413, loss = 0.02483696\n",
      "Iteration 1414, loss = 0.02481855\n",
      "Iteration 1415, loss = 0.02479815\n",
      "Iteration 1416, loss = 0.02477964\n",
      "Iteration 1417, loss = 0.02476055\n",
      "Iteration 1418, loss = 0.02474239\n",
      "Iteration 1419, loss = 0.02472244\n",
      "Iteration 1420, loss = 0.02470391\n",
      "Iteration 1421, loss = 0.02468304\n",
      "Iteration 1422, loss = 0.02466293\n",
      "Iteration 1423, loss = 0.02464639\n",
      "Iteration 1424, loss = 0.02462325\n",
      "Iteration 1425, loss = 0.02460410\n",
      "Iteration 1426, loss = 0.02458588\n",
      "Iteration 1427, loss = 0.02456699\n",
      "Iteration 1428, loss = 0.02455132\n",
      "Iteration 1429, loss = 0.02452864\n",
      "Iteration 1430, loss = 0.02450653\n",
      "Iteration 1431, loss = 0.02448870\n",
      "Iteration 1432, loss = 0.02446704\n",
      "Iteration 1433, loss = 0.02444775\n",
      "Iteration 1434, loss = 0.02442780\n",
      "Iteration 1435, loss = 0.02441009\n",
      "Iteration 1436, loss = 0.02438845\n",
      "Iteration 1437, loss = 0.02436883\n",
      "Iteration 1438, loss = 0.02435179\n",
      "Iteration 1439, loss = 0.02433100\n",
      "Iteration 1440, loss = 0.02431648\n",
      "Iteration 1441, loss = 0.02429411\n",
      "Iteration 1442, loss = 0.02427366\n",
      "Iteration 1443, loss = 0.02425495\n",
      "Iteration 1444, loss = 0.02423724\n",
      "Iteration 1445, loss = 0.02421730\n",
      "Iteration 1446, loss = 0.02420011\n",
      "Iteration 1447, loss = 0.02417761\n",
      "Iteration 1448, loss = 0.02416015\n",
      "Iteration 1449, loss = 0.02414160\n",
      "Iteration 1450, loss = 0.02412252\n",
      "Iteration 1451, loss = 0.02410574\n",
      "Iteration 1452, loss = 0.02408517\n",
      "Iteration 1453, loss = 0.02406738\n",
      "Iteration 1454, loss = 0.02404852\n",
      "Iteration 1455, loss = 0.02402909\n",
      "Iteration 1456, loss = 0.02401124\n",
      "Iteration 1457, loss = 0.02399253\n",
      "Iteration 1458, loss = 0.02397373\n",
      "Iteration 1459, loss = 0.02395563\n",
      "Iteration 1460, loss = 0.02393709\n",
      "Iteration 1461, loss = 0.02391857\n",
      "Iteration 1462, loss = 0.02389943\n",
      "Iteration 1463, loss = 0.02388133\n",
      "Iteration 1464, loss = 0.02386241\n",
      "Iteration 1465, loss = 0.02384290\n",
      "Iteration 1466, loss = 0.02382544\n",
      "Iteration 1467, loss = 0.02380627\n",
      "Iteration 1468, loss = 0.02378710\n",
      "Iteration 1469, loss = 0.02376943\n",
      "Iteration 1470, loss = 0.02375059\n",
      "Iteration 1471, loss = 0.02373361\n",
      "Iteration 1472, loss = 0.02371224\n",
      "Iteration 1473, loss = 0.02369335\n",
      "Iteration 1474, loss = 0.02367537\n",
      "Iteration 1475, loss = 0.02365853\n",
      "Iteration 1476, loss = 0.02363810\n",
      "Iteration 1477, loss = 0.02362020\n",
      "Iteration 1478, loss = 0.02360198\n",
      "Iteration 1479, loss = 0.02358321\n",
      "Iteration 1480, loss = 0.02356689\n",
      "Iteration 1481, loss = 0.02354907\n",
      "Iteration 1482, loss = 0.02353239\n",
      "Iteration 1483, loss = 0.02351189\n",
      "Iteration 1484, loss = 0.02349184\n",
      "Iteration 1485, loss = 0.02347640\n",
      "Iteration 1486, loss = 0.02345660\n",
      "Iteration 1487, loss = 0.02343914\n",
      "Iteration 1488, loss = 0.02341977\n",
      "Iteration 1489, loss = 0.02340251\n",
      "Iteration 1490, loss = 0.02338455\n",
      "Iteration 1491, loss = 0.02336703\n",
      "Iteration 1492, loss = 0.02334962\n",
      "Iteration 1493, loss = 0.02333165\n",
      "Iteration 1494, loss = 0.02331395\n",
      "Iteration 1495, loss = 0.02329625\n",
      "Iteration 1496, loss = 0.02327851\n",
      "Iteration 1497, loss = 0.02326098\n",
      "Iteration 1498, loss = 0.02324224\n",
      "Iteration 1499, loss = 0.02322431\n",
      "Iteration 1500, loss = 0.02320457\n",
      "Iteration 1501, loss = 0.02318720\n",
      "Iteration 1502, loss = 0.02316890\n",
      "Iteration 1503, loss = 0.02315202\n",
      "Iteration 1504, loss = 0.02313272\n",
      "Iteration 1505, loss = 0.02311681\n",
      "Iteration 1506, loss = 0.02309810\n",
      "Iteration 1507, loss = 0.02307907\n",
      "Iteration 1508, loss = 0.02305982\n",
      "Iteration 1509, loss = 0.02304274\n",
      "Iteration 1510, loss = 0.02302598\n",
      "Iteration 1511, loss = 0.02300627\n",
      "Iteration 1512, loss = 0.02299172\n",
      "Iteration 1513, loss = 0.02297343\n",
      "Iteration 1514, loss = 0.02295623\n",
      "Iteration 1515, loss = 0.02294060\n",
      "Iteration 1516, loss = 0.02292345\n",
      "Iteration 1517, loss = 0.02290690\n",
      "Iteration 1518, loss = 0.02289062\n",
      "Iteration 1519, loss = 0.02287424\n",
      "Iteration 1520, loss = 0.02285919\n",
      "Iteration 1521, loss = 0.02284311\n",
      "Iteration 1522, loss = 0.02282551\n",
      "Iteration 1523, loss = 0.02280866\n",
      "Iteration 1524, loss = 0.02279217\n",
      "Iteration 1525, loss = 0.02277381\n",
      "Iteration 1526, loss = 0.02275695\n",
      "Iteration 1527, loss = 0.02273888\n",
      "Iteration 1528, loss = 0.02272305\n",
      "Iteration 1529, loss = 0.02270375\n",
      "Iteration 1530, loss = 0.02268807\n",
      "Iteration 1531, loss = 0.02266927\n",
      "Iteration 1532, loss = 0.02265351\n",
      "Iteration 1533, loss = 0.02263933\n",
      "Iteration 1534, loss = 0.02261925\n",
      "Iteration 1535, loss = 0.02260364\n",
      "Iteration 1536, loss = 0.02258701\n",
      "Iteration 1537, loss = 0.02256984\n",
      "Iteration 1538, loss = 0.02255481\n",
      "Iteration 1539, loss = 0.02253837\n",
      "Iteration 1540, loss = 0.02251982\n",
      "Iteration 1541, loss = 0.02250430\n",
      "Iteration 1542, loss = 0.02248789\n",
      "Iteration 1543, loss = 0.02247173\n",
      "Iteration 1544, loss = 0.02245721\n",
      "Iteration 1545, loss = 0.02244014\n",
      "Iteration 1546, loss = 0.02242445\n",
      "Iteration 1547, loss = 0.02241089\n",
      "Iteration 1548, loss = 0.02239252\n",
      "Iteration 1549, loss = 0.02237595\n",
      "Iteration 1550, loss = 0.02236017\n",
      "Iteration 1551, loss = 0.02234411\n",
      "Iteration 1552, loss = 0.02232780\n",
      "Iteration 1553, loss = 0.02231191\n",
      "Iteration 1554, loss = 0.02229439\n",
      "Iteration 1555, loss = 0.02227804\n",
      "Iteration 1556, loss = 0.02226328\n",
      "Iteration 1557, loss = 0.02224531\n",
      "Iteration 1558, loss = 0.02222873\n",
      "Iteration 1559, loss = 0.02221242\n",
      "Iteration 1560, loss = 0.02219736\n",
      "Iteration 1561, loss = 0.02218068\n",
      "Iteration 1562, loss = 0.02216311\n",
      "Iteration 1563, loss = 0.02214646\n",
      "Iteration 1564, loss = 0.02213005\n",
      "Iteration 1565, loss = 0.02211500\n",
      "Iteration 1566, loss = 0.02209852\n",
      "Iteration 1567, loss = 0.02208097\n",
      "Iteration 1568, loss = 0.02206719\n",
      "Iteration 1569, loss = 0.02204911\n",
      "Iteration 1570, loss = 0.02203555\n",
      "Iteration 1571, loss = 0.02201851\n",
      "Iteration 1572, loss = 0.02200225\n",
      "Iteration 1573, loss = 0.02198518\n",
      "Iteration 1574, loss = 0.02196921\n",
      "Iteration 1575, loss = 0.02195511\n",
      "Iteration 1576, loss = 0.02193667\n",
      "Iteration 1577, loss = 0.02192168\n",
      "Iteration 1578, loss = 0.02190465\n",
      "Iteration 1579, loss = 0.02188738\n",
      "Iteration 1580, loss = 0.02187101\n",
      "Iteration 1581, loss = 0.02185495\n",
      "Iteration 1582, loss = 0.02184026\n",
      "Iteration 1583, loss = 0.02182323\n",
      "Iteration 1584, loss = 0.02180801\n",
      "Iteration 1585, loss = 0.02179348\n",
      "Iteration 1586, loss = 0.02177816\n",
      "Iteration 1587, loss = 0.02176469\n",
      "Iteration 1588, loss = 0.02174725\n",
      "Iteration 1589, loss = 0.02173254\n",
      "Iteration 1590, loss = 0.02171801\n",
      "Iteration 1591, loss = 0.02170208\n",
      "Iteration 1592, loss = 0.02168514\n",
      "Iteration 1593, loss = 0.02166910\n",
      "Iteration 1594, loss = 0.02165343\n",
      "Iteration 1595, loss = 0.02163730\n",
      "Iteration 1596, loss = 0.02162338\n",
      "Iteration 1597, loss = 0.02160597\n",
      "Iteration 1598, loss = 0.02158985\n",
      "Iteration 1599, loss = 0.02157186\n",
      "Iteration 1600, loss = 0.02155987\n",
      "Iteration 1601, loss = 0.02154070\n",
      "Iteration 1602, loss = 0.02152464\n",
      "Iteration 1603, loss = 0.02150832\n",
      "Iteration 1604, loss = 0.02149199\n",
      "Iteration 1605, loss = 0.02147585\n",
      "Iteration 1606, loss = 0.02146148\n",
      "Iteration 1607, loss = 0.02144576\n",
      "Iteration 1608, loss = 0.02142832\n",
      "Iteration 1609, loss = 0.02141215\n",
      "Iteration 1610, loss = 0.02139650\n",
      "Iteration 1611, loss = 0.02138228\n",
      "Iteration 1612, loss = 0.02136656\n",
      "Iteration 1613, loss = 0.02135295\n",
      "Iteration 1614, loss = 0.02133800\n",
      "Iteration 1615, loss = 0.02132282\n",
      "Iteration 1616, loss = 0.02130751\n",
      "Iteration 1617, loss = 0.02129677\n",
      "Iteration 1618, loss = 0.02127923\n",
      "Iteration 1619, loss = 0.02126214\n",
      "Iteration 1620, loss = 0.02124770\n",
      "Iteration 1621, loss = 0.02123159\n",
      "Iteration 1622, loss = 0.02121528\n",
      "Iteration 1623, loss = 0.02120031\n",
      "Iteration 1624, loss = 0.02118356\n",
      "Iteration 1625, loss = 0.02116778\n",
      "Iteration 1626, loss = 0.02115363\n",
      "Iteration 1627, loss = 0.02113697\n",
      "Iteration 1628, loss = 0.02112221\n",
      "Iteration 1629, loss = 0.02110601\n",
      "Iteration 1630, loss = 0.02109103\n",
      "Iteration 1631, loss = 0.02107658\n",
      "Iteration 1632, loss = 0.02105968\n",
      "Iteration 1633, loss = 0.02104359\n",
      "Iteration 1634, loss = 0.02102829\n",
      "Iteration 1635, loss = 0.02101141\n",
      "Iteration 1636, loss = 0.02099470\n",
      "Iteration 1637, loss = 0.02098014\n",
      "Iteration 1638, loss = 0.02096330\n",
      "Iteration 1639, loss = 0.02094729\n",
      "Iteration 1640, loss = 0.02093200\n",
      "Iteration 1641, loss = 0.02091541\n",
      "Iteration 1642, loss = 0.02089985\n",
      "Iteration 1643, loss = 0.02088389\n",
      "Iteration 1644, loss = 0.02086871\n",
      "Iteration 1645, loss = 0.02085426\n",
      "Iteration 1646, loss = 0.02083874\n",
      "Iteration 1647, loss = 0.02082303\n",
      "Iteration 1648, loss = 0.02081100\n",
      "Iteration 1649, loss = 0.02079338\n",
      "Iteration 1650, loss = 0.02078035\n",
      "Iteration 1651, loss = 0.02076521\n",
      "Iteration 1652, loss = 0.02075037\n",
      "Iteration 1653, loss = 0.02073617\n",
      "Iteration 1654, loss = 0.02072212\n",
      "Iteration 1655, loss = 0.02071230\n",
      "Iteration 1656, loss = 0.02069533\n",
      "Iteration 1657, loss = 0.02067794\n",
      "Iteration 1658, loss = 0.02066220\n",
      "Iteration 1659, loss = 0.02064869\n",
      "Iteration 1660, loss = 0.02063285\n",
      "Iteration 1661, loss = 0.02061919\n",
      "Iteration 1662, loss = 0.02060342\n",
      "Iteration 1663, loss = 0.02058910\n",
      "Iteration 1664, loss = 0.02057491\n",
      "Iteration 1665, loss = 0.02056128\n",
      "Iteration 1666, loss = 0.02054668\n",
      "Iteration 1667, loss = 0.02053434\n",
      "Iteration 1668, loss = 0.02052157\n",
      "Iteration 1669, loss = 0.02050683\n",
      "Iteration 1670, loss = 0.02049274\n",
      "Iteration 1671, loss = 0.02047908\n",
      "Iteration 1672, loss = 0.02046521\n",
      "Iteration 1673, loss = 0.02045218\n",
      "Iteration 1674, loss = 0.02043945\n",
      "Iteration 1675, loss = 0.02042767\n",
      "Iteration 1676, loss = 0.02041249\n",
      "Iteration 1677, loss = 0.02040029\n",
      "Iteration 1678, loss = 0.02038423\n",
      "Iteration 1679, loss = 0.02037074\n",
      "Iteration 1680, loss = 0.02035527\n",
      "Iteration 1681, loss = 0.02034130\n",
      "Iteration 1682, loss = 0.02032738\n",
      "Iteration 1683, loss = 0.02031486\n",
      "Iteration 1684, loss = 0.02029863\n",
      "Iteration 1685, loss = 0.02028508\n",
      "Iteration 1686, loss = 0.02027118\n",
      "Iteration 1687, loss = 0.02025607\n",
      "Iteration 1688, loss = 0.02024209\n",
      "Iteration 1689, loss = 0.02022866\n",
      "Iteration 1690, loss = 0.02021661\n",
      "Iteration 1691, loss = 0.02020144\n",
      "Iteration 1692, loss = 0.02018806\n",
      "Iteration 1693, loss = 0.02017415\n",
      "Iteration 1694, loss = 0.02016007\n",
      "Iteration 1695, loss = 0.02014634\n",
      "Iteration 1696, loss = 0.02013394\n",
      "Iteration 1697, loss = 0.02011910\n",
      "Iteration 1698, loss = 0.02010555\n",
      "Iteration 1699, loss = 0.02009282\n",
      "Iteration 1700, loss = 0.02007667\n",
      "Iteration 1701, loss = 0.02006237\n",
      "Iteration 1702, loss = 0.02005021\n",
      "Iteration 1703, loss = 0.02003411\n",
      "Iteration 1704, loss = 0.02002398\n",
      "Iteration 1705, loss = 0.02000783\n",
      "Iteration 1706, loss = 0.01999530\n",
      "Iteration 1707, loss = 0.01997946\n",
      "Iteration 1708, loss = 0.01996647\n",
      "Iteration 1709, loss = 0.01995126\n",
      "Iteration 1710, loss = 0.01993936\n",
      "Iteration 1711, loss = 0.01992456\n",
      "Iteration 1712, loss = 0.01991139\n",
      "Iteration 1713, loss = 0.01989704\n",
      "Iteration 1714, loss = 0.01988299\n",
      "Iteration 1715, loss = 0.01987062\n",
      "Iteration 1716, loss = 0.01985795\n",
      "Iteration 1717, loss = 0.01984129\n",
      "Iteration 1718, loss = 0.01983234\n",
      "Iteration 1719, loss = 0.01981512\n",
      "Iteration 1720, loss = 0.01980151\n",
      "Iteration 1721, loss = 0.01978702\n",
      "Iteration 1722, loss = 0.01977471\n",
      "Iteration 1723, loss = 0.01976140\n",
      "Iteration 1724, loss = 0.01974862\n",
      "Iteration 1725, loss = 0.01973298\n",
      "Iteration 1726, loss = 0.01971969\n",
      "Iteration 1727, loss = 0.01970724\n",
      "Iteration 1728, loss = 0.01969482\n",
      "Iteration 1729, loss = 0.01968036\n",
      "Iteration 1730, loss = 0.01966635\n",
      "Iteration 1731, loss = 0.01965261\n",
      "Iteration 1732, loss = 0.01963985\n",
      "Iteration 1733, loss = 0.01962605\n",
      "Iteration 1734, loss = 0.01961328\n",
      "Iteration 1735, loss = 0.01959843\n",
      "Iteration 1736, loss = 0.01958493\n",
      "Iteration 1737, loss = 0.01957121\n",
      "Iteration 1738, loss = 0.01955695\n",
      "Iteration 1739, loss = 0.01954440\n",
      "Iteration 1740, loss = 0.01953036\n",
      "Iteration 1741, loss = 0.01951552\n",
      "Iteration 1742, loss = 0.01950142\n",
      "Iteration 1743, loss = 0.01948789\n",
      "Iteration 1744, loss = 0.01947525\n",
      "Iteration 1745, loss = 0.01946172\n",
      "Iteration 1746, loss = 0.01944766\n",
      "Iteration 1747, loss = 0.01943572\n",
      "Iteration 1748, loss = 0.01942085\n",
      "Iteration 1749, loss = 0.01941093\n",
      "Iteration 1750, loss = 0.01939555\n",
      "Iteration 1751, loss = 0.01938326\n",
      "Iteration 1752, loss = 0.01937052\n",
      "Iteration 1753, loss = 0.01935695\n",
      "Iteration 1754, loss = 0.01934439\n",
      "Iteration 1755, loss = 0.01933190\n",
      "Iteration 1756, loss = 0.01932001\n",
      "Iteration 1757, loss = 0.01930660\n",
      "Iteration 1758, loss = 0.01929452\n",
      "Iteration 1759, loss = 0.01928225\n",
      "Iteration 1760, loss = 0.01926898\n",
      "Iteration 1761, loss = 0.01925768\n",
      "Iteration 1762, loss = 0.01924452\n",
      "Iteration 1763, loss = 0.01923198\n",
      "Iteration 1764, loss = 0.01922097\n",
      "Iteration 1765, loss = 0.01920795\n",
      "Iteration 1766, loss = 0.01919549\n",
      "Iteration 1767, loss = 0.01918137\n",
      "Iteration 1768, loss = 0.01916842\n",
      "Iteration 1769, loss = 0.01915533\n",
      "Iteration 1770, loss = 0.01914231\n",
      "Iteration 1771, loss = 0.01912965\n",
      "Iteration 1772, loss = 0.01911684\n",
      "Iteration 1773, loss = 0.01910422\n",
      "Iteration 1774, loss = 0.01909215\n",
      "Iteration 1775, loss = 0.01907829\n",
      "Iteration 1776, loss = 0.01906524\n",
      "Iteration 1777, loss = 0.01905223\n",
      "Iteration 1778, loss = 0.01904038\n",
      "Iteration 1779, loss = 0.01902723\n",
      "Iteration 1780, loss = 0.01901555\n",
      "Iteration 1781, loss = 0.01899911\n",
      "Iteration 1782, loss = 0.01898346\n",
      "Iteration 1783, loss = 0.01897323\n",
      "Iteration 1784, loss = 0.01896031\n",
      "Iteration 1785, loss = 0.01894549\n",
      "Iteration 1786, loss = 0.01893249\n",
      "Iteration 1787, loss = 0.01891870\n",
      "Iteration 1788, loss = 0.01890416\n",
      "Iteration 1789, loss = 0.01889226\n",
      "Iteration 1790, loss = 0.01888055\n",
      "Iteration 1791, loss = 0.01887070\n",
      "Iteration 1792, loss = 0.01885798\n",
      "Iteration 1793, loss = 0.01884760\n",
      "Iteration 1794, loss = 0.01883406\n",
      "Iteration 1795, loss = 0.01882101\n",
      "Iteration 1796, loss = 0.01880956\n",
      "Iteration 1797, loss = 0.01879670\n",
      "Iteration 1798, loss = 0.01878371\n",
      "Iteration 1799, loss = 0.01877195\n",
      "Iteration 1800, loss = 0.01875800\n",
      "Iteration 1801, loss = 0.01874471\n",
      "Iteration 1802, loss = 0.01873256\n",
      "Iteration 1803, loss = 0.01871996\n",
      "Iteration 1804, loss = 0.01870676\n",
      "Iteration 1805, loss = 0.01869774\n",
      "Iteration 1806, loss = 0.01868198\n",
      "Iteration 1807, loss = 0.01866964\n",
      "Iteration 1808, loss = 0.01865772\n",
      "Iteration 1809, loss = 0.01864548\n",
      "Iteration 1810, loss = 0.01863334\n",
      "Iteration 1811, loss = 0.01862034\n",
      "Iteration 1812, loss = 0.01860902\n",
      "Iteration 1813, loss = 0.01859556\n",
      "Iteration 1814, loss = 0.01858258\n",
      "Iteration 1815, loss = 0.01857123\n",
      "Iteration 1816, loss = 0.01855929\n",
      "Iteration 1817, loss = 0.01854855\n",
      "Iteration 1818, loss = 0.01853365\n",
      "Iteration 1819, loss = 0.01852348\n",
      "Iteration 1820, loss = 0.01850874\n",
      "Iteration 1821, loss = 0.01849840\n",
      "Iteration 1822, loss = 0.01848668\n",
      "Iteration 1823, loss = 0.01847428\n",
      "Iteration 1824, loss = 0.01846263\n",
      "Iteration 1825, loss = 0.01845071\n",
      "Iteration 1826, loss = 0.01844016\n",
      "Iteration 1827, loss = 0.01842869\n",
      "Iteration 1828, loss = 0.01841491\n",
      "Iteration 1829, loss = 0.01840277\n",
      "Iteration 1830, loss = 0.01839105\n",
      "Iteration 1831, loss = 0.01837926\n",
      "Iteration 1832, loss = 0.01836889\n",
      "Iteration 1833, loss = 0.01835805\n",
      "Iteration 1834, loss = 0.01834559\n",
      "Iteration 1835, loss = 0.01833410\n",
      "Iteration 1836, loss = 0.01832296\n",
      "Iteration 1837, loss = 0.01831295\n",
      "Iteration 1838, loss = 0.01830180\n",
      "Iteration 1839, loss = 0.01829094\n",
      "Iteration 1840, loss = 0.01828383\n",
      "Iteration 1841, loss = 0.01826923\n",
      "Iteration 1842, loss = 0.01825800\n",
      "Iteration 1843, loss = 0.01824557\n",
      "Iteration 1844, loss = 0.01823420\n",
      "Iteration 1845, loss = 0.01822173\n",
      "Iteration 1846, loss = 0.01821035\n",
      "Iteration 1847, loss = 0.01819886\n",
      "Iteration 1848, loss = 0.01818896\n",
      "Iteration 1849, loss = 0.01817655\n",
      "Iteration 1850, loss = 0.01816532\n",
      "Iteration 1851, loss = 0.01815620\n",
      "Iteration 1852, loss = 0.01814305\n",
      "Iteration 1853, loss = 0.01813160\n",
      "Iteration 1854, loss = 0.01812094\n",
      "Iteration 1855, loss = 0.01810855\n",
      "Iteration 1856, loss = 0.01809628\n",
      "Iteration 1857, loss = 0.01808504\n",
      "Iteration 1858, loss = 0.01807356\n",
      "Iteration 1859, loss = 0.01806234\n",
      "Iteration 1860, loss = 0.01805050\n",
      "Iteration 1861, loss = 0.01804149\n",
      "Iteration 1862, loss = 0.01802945\n",
      "Iteration 1863, loss = 0.01801860\n",
      "Iteration 1864, loss = 0.01800792\n",
      "Iteration 1865, loss = 0.01799503\n",
      "Iteration 1866, loss = 0.01798329\n",
      "Iteration 1867, loss = 0.01797115\n",
      "Iteration 1868, loss = 0.01795951\n",
      "Iteration 1869, loss = 0.01794672\n",
      "Iteration 1870, loss = 0.01793398\n",
      "Iteration 1871, loss = 0.01792440\n",
      "Iteration 1872, loss = 0.01791215\n",
      "Iteration 1873, loss = 0.01789904\n",
      "Iteration 1874, loss = 0.01788807\n",
      "Iteration 1875, loss = 0.01787773\n",
      "Iteration 1876, loss = 0.01786608\n",
      "Iteration 1877, loss = 0.01785557\n",
      "Iteration 1878, loss = 0.01784520\n",
      "Iteration 1879, loss = 0.01783428\n",
      "Iteration 1880, loss = 0.01782363\n",
      "Iteration 1881, loss = 0.01781240\n",
      "Iteration 1882, loss = 0.01780213\n",
      "Iteration 1883, loss = 0.01779259\n",
      "Iteration 1884, loss = 0.01778019\n",
      "Iteration 1885, loss = 0.01777149\n",
      "Iteration 1886, loss = 0.01775820\n",
      "Iteration 1887, loss = 0.01774844\n",
      "Iteration 1888, loss = 0.01773712\n",
      "Iteration 1889, loss = 0.01772595\n",
      "Iteration 1890, loss = 0.01771714\n",
      "Iteration 1891, loss = 0.01770733\n",
      "Iteration 1892, loss = 0.01769442\n",
      "Iteration 1893, loss = 0.01768291\n",
      "Iteration 1894, loss = 0.01767234\n",
      "Iteration 1895, loss = 0.01766231\n",
      "Iteration 1896, loss = 0.01765166\n",
      "Iteration 1897, loss = 0.01764144\n",
      "Iteration 1898, loss = 0.01763049\n",
      "Iteration 1899, loss = 0.01762041\n",
      "Iteration 1900, loss = 0.01761044\n",
      "Iteration 1901, loss = 0.01760034\n",
      "Iteration 1902, loss = 0.01759068\n",
      "Iteration 1903, loss = 0.01758068\n",
      "Iteration 1904, loss = 0.01757012\n",
      "Iteration 1905, loss = 0.01756015\n",
      "Iteration 1906, loss = 0.01754772\n",
      "Iteration 1907, loss = 0.01753727\n",
      "Iteration 1908, loss = 0.01752483\n",
      "Iteration 1909, loss = 0.01751401\n",
      "Iteration 1910, loss = 0.01750161\n",
      "Iteration 1911, loss = 0.01749097\n",
      "Iteration 1912, loss = 0.01748039\n",
      "Iteration 1913, loss = 0.01746903\n",
      "Iteration 1914, loss = 0.01745963\n",
      "Iteration 1915, loss = 0.01744705\n",
      "Iteration 1916, loss = 0.01743725\n",
      "Iteration 1917, loss = 0.01742638\n",
      "Iteration 1918, loss = 0.01741628\n",
      "Iteration 1919, loss = 0.01740495\n",
      "Iteration 1920, loss = 0.01739391\n",
      "Iteration 1921, loss = 0.01738284\n",
      "Iteration 1922, loss = 0.01737155\n",
      "Iteration 1923, loss = 0.01736164\n",
      "Iteration 1924, loss = 0.01734821\n",
      "Iteration 1925, loss = 0.01733719\n",
      "Iteration 1926, loss = 0.01732528\n",
      "Iteration 1927, loss = 0.01731370\n",
      "Iteration 1928, loss = 0.01730248\n",
      "Iteration 1929, loss = 0.01729150\n",
      "Iteration 1930, loss = 0.01728014\n",
      "Iteration 1931, loss = 0.01726900\n",
      "Iteration 1932, loss = 0.01725835\n",
      "Iteration 1933, loss = 0.01724790\n",
      "Iteration 1934, loss = 0.01723592\n",
      "Iteration 1935, loss = 0.01722679\n",
      "Iteration 1936, loss = 0.01721490\n",
      "Iteration 1937, loss = 0.01720607\n",
      "Iteration 1938, loss = 0.01719588\n",
      "Iteration 1939, loss = 0.01718365\n",
      "Iteration 1940, loss = 0.01717354\n",
      "Iteration 1941, loss = 0.01716277\n",
      "Iteration 1942, loss = 0.01715245\n",
      "Iteration 1943, loss = 0.01714106\n",
      "Iteration 1944, loss = 0.01713305\n",
      "Iteration 1945, loss = 0.01711948\n",
      "Iteration 1946, loss = 0.01710933\n",
      "Iteration 1947, loss = 0.01709778\n",
      "Iteration 1948, loss = 0.01708608\n",
      "Iteration 1949, loss = 0.01707439\n",
      "Iteration 1950, loss = 0.01706281\n",
      "Iteration 1951, loss = 0.01705397\n",
      "Iteration 1952, loss = 0.01704241\n",
      "Iteration 1953, loss = 0.01703197\n",
      "Iteration 1954, loss = 0.01702162\n",
      "Iteration 1955, loss = 0.01701135\n",
      "Iteration 1956, loss = 0.01700128\n",
      "Iteration 1957, loss = 0.01699136\n",
      "Iteration 1958, loss = 0.01698205\n",
      "Iteration 1959, loss = 0.01697093\n",
      "Iteration 1960, loss = 0.01696085\n",
      "Iteration 1961, loss = 0.01695043\n",
      "Iteration 1962, loss = 0.01694079\n",
      "Iteration 1963, loss = 0.01692922\n",
      "Iteration 1964, loss = 0.01691978\n",
      "Iteration 1965, loss = 0.01691060\n",
      "Iteration 1966, loss = 0.01690002\n",
      "Iteration 1967, loss = 0.01688975\n",
      "Iteration 1968, loss = 0.01687933\n",
      "Iteration 1969, loss = 0.01686807\n",
      "Iteration 1970, loss = 0.01685924\n",
      "Iteration 1971, loss = 0.01684796\n",
      "Iteration 1972, loss = 0.01683828\n",
      "Iteration 1973, loss = 0.01682803\n",
      "Iteration 1974, loss = 0.01682191\n",
      "Iteration 1975, loss = 0.01680599\n",
      "Iteration 1976, loss = 0.01679738\n",
      "Iteration 1977, loss = 0.01678415\n",
      "Iteration 1978, loss = 0.01677355\n",
      "Iteration 1979, loss = 0.01676383\n",
      "Iteration 1980, loss = 0.01675209\n",
      "Iteration 1981, loss = 0.01674244\n",
      "Iteration 1982, loss = 0.01673024\n",
      "Iteration 1983, loss = 0.01671809\n",
      "Iteration 1984, loss = 0.01670704\n",
      "Iteration 1985, loss = 0.01669603\n",
      "Iteration 1986, loss = 0.01668796\n",
      "Iteration 1987, loss = 0.01667590\n",
      "Iteration 1988, loss = 0.01666481\n",
      "Iteration 1989, loss = 0.01665588\n",
      "Iteration 1990, loss = 0.01664570\n",
      "Iteration 1991, loss = 0.01663545\n",
      "Iteration 1992, loss = 0.01662527\n",
      "Iteration 1993, loss = 0.01661384\n",
      "Iteration 1994, loss = 0.01660314\n",
      "Iteration 1995, loss = 0.01659282\n",
      "Iteration 1996, loss = 0.01658200\n",
      "Iteration 1997, loss = 0.01657189\n",
      "Iteration 1998, loss = 0.01656233\n",
      "Iteration 1999, loss = 0.01655144\n",
      "Iteration 2000, loss = 0.01654036\n",
      "Iteration 2001, loss = 0.01653042\n",
      "Iteration 2002, loss = 0.01651991\n",
      "Iteration 2003, loss = 0.01650979\n",
      "Iteration 2004, loss = 0.01650014\n",
      "Iteration 2005, loss = 0.01649187\n",
      "Iteration 2006, loss = 0.01648049\n",
      "Iteration 2007, loss = 0.01647034\n",
      "Iteration 2008, loss = 0.01646164\n",
      "Iteration 2009, loss = 0.01645190\n",
      "Iteration 2010, loss = 0.01644214\n",
      "Iteration 2011, loss = 0.01643523\n",
      "Iteration 2012, loss = 0.01642422\n",
      "Iteration 2013, loss = 0.01641414\n",
      "Iteration 2014, loss = 0.01640513\n",
      "Iteration 2015, loss = 0.01639417\n",
      "Iteration 2016, loss = 0.01638395\n",
      "Iteration 2017, loss = 0.01637626\n",
      "Iteration 2018, loss = 0.01636544\n",
      "Iteration 2019, loss = 0.01635424\n",
      "Iteration 2020, loss = 0.01634459\n",
      "Iteration 2021, loss = 0.01633456\n",
      "Iteration 2022, loss = 0.01632510\n",
      "Iteration 2023, loss = 0.01631554\n",
      "Iteration 2024, loss = 0.01630607\n",
      "Iteration 2025, loss = 0.01629717\n",
      "Iteration 2026, loss = 0.01628862\n",
      "Iteration 2027, loss = 0.01627759\n",
      "Iteration 2028, loss = 0.01626792\n",
      "Iteration 2029, loss = 0.01625962\n",
      "Iteration 2030, loss = 0.01624821\n",
      "Iteration 2031, loss = 0.01623946\n",
      "Iteration 2032, loss = 0.01622851\n",
      "Iteration 2033, loss = 0.01621937\n",
      "Iteration 2034, loss = 0.01620986\n",
      "Iteration 2035, loss = 0.01620065\n",
      "Iteration 2036, loss = 0.01619160\n",
      "Iteration 2037, loss = 0.01618184\n",
      "Iteration 2038, loss = 0.01617411\n",
      "Iteration 2039, loss = 0.01616375\n",
      "Iteration 2040, loss = 0.01615419\n",
      "Iteration 2041, loss = 0.01614450\n",
      "Iteration 2042, loss = 0.01613634\n",
      "Iteration 2043, loss = 0.01612679\n",
      "Iteration 2044, loss = 0.01611795\n",
      "Iteration 2045, loss = 0.01610906\n",
      "Iteration 2046, loss = 0.01609974\n",
      "Iteration 2047, loss = 0.01609155\n",
      "Iteration 2048, loss = 0.01608229\n",
      "Iteration 2049, loss = 0.01607181\n",
      "Iteration 2050, loss = 0.01606200\n",
      "Iteration 2051, loss = 0.01605389\n",
      "Iteration 2052, loss = 0.01604373\n",
      "Iteration 2053, loss = 0.01603446\n",
      "Iteration 2054, loss = 0.01602548\n",
      "Iteration 2055, loss = 0.01601661\n",
      "Iteration 2056, loss = 0.01600773\n",
      "Iteration 2057, loss = 0.01599831\n",
      "Iteration 2058, loss = 0.01599007\n",
      "Iteration 2059, loss = 0.01597968\n",
      "Iteration 2060, loss = 0.01596930\n",
      "Iteration 2061, loss = 0.01596000\n",
      "Iteration 2062, loss = 0.01594981\n",
      "Iteration 2063, loss = 0.01594034\n",
      "Iteration 2064, loss = 0.01592917\n",
      "Iteration 2065, loss = 0.01591925\n",
      "Iteration 2066, loss = 0.01590929\n",
      "Iteration 2067, loss = 0.01589857\n",
      "Iteration 2068, loss = 0.01589254\n",
      "Iteration 2069, loss = 0.01587999\n",
      "Iteration 2070, loss = 0.01587103\n",
      "Iteration 2071, loss = 0.01586063\n",
      "Iteration 2072, loss = 0.01585105\n",
      "Iteration 2073, loss = 0.01584253\n",
      "Iteration 2074, loss = 0.01583241\n",
      "Iteration 2075, loss = 0.01582195\n",
      "Iteration 2076, loss = 0.01581344\n",
      "Iteration 2077, loss = 0.01580299\n",
      "Iteration 2078, loss = 0.01579344\n",
      "Iteration 2079, loss = 0.01578579\n",
      "Iteration 2080, loss = 0.01577539\n",
      "Iteration 2081, loss = 0.01576589\n",
      "Iteration 2082, loss = 0.01575655\n",
      "Iteration 2083, loss = 0.01574774\n",
      "Iteration 2084, loss = 0.01573870\n",
      "Iteration 2085, loss = 0.01572964\n",
      "Iteration 2086, loss = 0.01572088\n",
      "Iteration 2087, loss = 0.01571152\n",
      "Iteration 2088, loss = 0.01570112\n",
      "Iteration 2089, loss = 0.01569236\n",
      "Iteration 2090, loss = 0.01568254\n",
      "Iteration 2091, loss = 0.01567393\n",
      "Iteration 2092, loss = 0.01566468\n",
      "Iteration 2093, loss = 0.01565567\n",
      "Iteration 2094, loss = 0.01564607\n",
      "Iteration 2095, loss = 0.01563677\n",
      "Iteration 2096, loss = 0.01562729\n",
      "Iteration 2097, loss = 0.01561858\n",
      "Iteration 2098, loss = 0.01560936\n",
      "Iteration 2099, loss = 0.01559994\n",
      "Iteration 2100, loss = 0.01559091\n",
      "Iteration 2101, loss = 0.01558275\n",
      "Iteration 2102, loss = 0.01557341\n",
      "Iteration 2103, loss = 0.01556313\n",
      "Iteration 2104, loss = 0.01555460\n",
      "Iteration 2105, loss = 0.01554621\n",
      "Iteration 2106, loss = 0.01553703\n",
      "Iteration 2107, loss = 0.01552762\n",
      "Iteration 2108, loss = 0.01551812\n",
      "Iteration 2109, loss = 0.01550911\n",
      "Iteration 2110, loss = 0.01549992\n",
      "Iteration 2111, loss = 0.01549029\n",
      "Iteration 2112, loss = 0.01548132\n",
      "Iteration 2113, loss = 0.01547245\n",
      "Iteration 2114, loss = 0.01546409\n",
      "Iteration 2115, loss = 0.01545475\n",
      "Iteration 2116, loss = 0.01544505\n",
      "Iteration 2117, loss = 0.01543574\n",
      "Iteration 2118, loss = 0.01542748\n",
      "Iteration 2119, loss = 0.01541955\n",
      "Iteration 2120, loss = 0.01540878\n",
      "Iteration 2121, loss = 0.01539995\n",
      "Iteration 2122, loss = 0.01538992\n",
      "Iteration 2123, loss = 0.01538117\n",
      "Iteration 2124, loss = 0.01537063\n",
      "Iteration 2125, loss = 0.01536335\n",
      "Iteration 2126, loss = 0.01535652\n",
      "Iteration 2127, loss = 0.01534690\n",
      "Iteration 2128, loss = 0.01533715\n",
      "Iteration 2129, loss = 0.01532904\n",
      "Iteration 2130, loss = 0.01532072\n",
      "Iteration 2131, loss = 0.01531249\n",
      "Iteration 2132, loss = 0.01530363\n",
      "Iteration 2133, loss = 0.01529464\n",
      "Iteration 2134, loss = 0.01528746\n",
      "Iteration 2135, loss = 0.01527852\n",
      "Iteration 2136, loss = 0.01527042\n",
      "Iteration 2137, loss = 0.01526140\n",
      "Iteration 2138, loss = 0.01525400\n",
      "Iteration 2139, loss = 0.01524510\n",
      "Iteration 2140, loss = 0.01523636\n",
      "Iteration 2141, loss = 0.01522707\n",
      "Iteration 2142, loss = 0.01521812\n",
      "Iteration 2143, loss = 0.01521044\n",
      "Iteration 2144, loss = 0.01520144\n",
      "Iteration 2145, loss = 0.01519315\n",
      "Iteration 2146, loss = 0.01518359\n",
      "Iteration 2147, loss = 0.01517509\n",
      "Iteration 2148, loss = 0.01516609\n",
      "Iteration 2149, loss = 0.01515737\n",
      "Iteration 2150, loss = 0.01514794\n",
      "Iteration 2151, loss = 0.01513852\n",
      "Iteration 2152, loss = 0.01512958\n",
      "Iteration 2153, loss = 0.01511929\n",
      "Iteration 2154, loss = 0.01511078\n",
      "Iteration 2155, loss = 0.01510124\n",
      "Iteration 2156, loss = 0.01509227\n",
      "Iteration 2157, loss = 0.01508345\n",
      "Iteration 2158, loss = 0.01507435\n",
      "Iteration 2159, loss = 0.01506586\n",
      "Iteration 2160, loss = 0.01505784\n",
      "Iteration 2161, loss = 0.01504880\n",
      "Iteration 2162, loss = 0.01504046\n",
      "Iteration 2163, loss = 0.01503093\n",
      "Iteration 2164, loss = 0.01502198\n",
      "Iteration 2165, loss = 0.01501445\n",
      "Iteration 2166, loss = 0.01500580\n",
      "Iteration 2167, loss = 0.01499787\n",
      "Iteration 2168, loss = 0.01498814\n",
      "Iteration 2169, loss = 0.01497906\n",
      "Iteration 2170, loss = 0.01497067\n",
      "Iteration 2171, loss = 0.01496172\n",
      "Iteration 2172, loss = 0.01495549\n",
      "Iteration 2173, loss = 0.01494650\n",
      "Iteration 2174, loss = 0.01493758\n",
      "Iteration 2175, loss = 0.01493064\n",
      "Iteration 2176, loss = 0.01492185\n",
      "Iteration 2177, loss = 0.01491425\n",
      "Iteration 2178, loss = 0.01490583\n",
      "Iteration 2179, loss = 0.01489829\n",
      "Iteration 2180, loss = 0.01488921\n",
      "Iteration 2181, loss = 0.01488137\n",
      "Iteration 2182, loss = 0.01487332\n",
      "Iteration 2183, loss = 0.01486521\n",
      "Iteration 2184, loss = 0.01485651\n",
      "Iteration 2185, loss = 0.01484949\n",
      "Iteration 2186, loss = 0.01484232\n",
      "Iteration 2187, loss = 0.01483302\n",
      "Iteration 2188, loss = 0.01482608\n",
      "Iteration 2189, loss = 0.01481672\n",
      "Iteration 2190, loss = 0.01480872\n",
      "Iteration 2191, loss = 0.01479894\n",
      "Iteration 2192, loss = 0.01479067\n",
      "Iteration 2193, loss = 0.01478196\n",
      "Iteration 2194, loss = 0.01477247\n",
      "Iteration 2195, loss = 0.01476505\n",
      "Iteration 2196, loss = 0.01475686\n",
      "Iteration 2197, loss = 0.01474906\n",
      "Iteration 2198, loss = 0.01474085\n",
      "Iteration 2199, loss = 0.01473254\n",
      "Iteration 2200, loss = 0.01472768\n",
      "Iteration 2201, loss = 0.01471899\n",
      "Iteration 2202, loss = 0.01471205\n",
      "Iteration 2203, loss = 0.01470432\n",
      "Iteration 2204, loss = 0.01469558\n",
      "Iteration 2205, loss = 0.01468847\n",
      "Iteration 2206, loss = 0.01467886\n",
      "Iteration 2207, loss = 0.01467039\n",
      "Iteration 2208, loss = 0.01466302\n",
      "Iteration 2209, loss = 0.01465589\n",
      "Iteration 2210, loss = 0.01464849\n",
      "Iteration 2211, loss = 0.01463807\n",
      "Iteration 2212, loss = 0.01463011\n",
      "Iteration 2213, loss = 0.01461986\n",
      "Iteration 2214, loss = 0.01461106\n",
      "Iteration 2215, loss = 0.01460153\n",
      "Iteration 2216, loss = 0.01459230\n",
      "Iteration 2217, loss = 0.01458174\n",
      "Iteration 2218, loss = 0.01457363\n",
      "Iteration 2219, loss = 0.01456662\n",
      "Iteration 2220, loss = 0.01455574\n",
      "Iteration 2221, loss = 0.01454776\n",
      "Iteration 2222, loss = 0.01453937\n",
      "Iteration 2223, loss = 0.01453017\n",
      "Iteration 2224, loss = 0.01452271\n",
      "Iteration 2225, loss = 0.01451401\n",
      "Iteration 2226, loss = 0.01450566\n",
      "Iteration 2227, loss = 0.01449929\n",
      "Iteration 2228, loss = 0.01448944\n",
      "Iteration 2229, loss = 0.01448121\n",
      "Iteration 2230, loss = 0.01447325\n",
      "Iteration 2231, loss = 0.01446541\n",
      "Iteration 2232, loss = 0.01445794\n",
      "Iteration 2233, loss = 0.01444985\n",
      "Iteration 2234, loss = 0.01444105\n",
      "Iteration 2235, loss = 0.01443305\n",
      "Iteration 2236, loss = 0.01442353\n",
      "Iteration 2237, loss = 0.01441652\n",
      "Iteration 2238, loss = 0.01440665\n",
      "Iteration 2239, loss = 0.01439830\n",
      "Iteration 2240, loss = 0.01438977\n",
      "Iteration 2241, loss = 0.01438189\n",
      "Iteration 2242, loss = 0.01437304\n",
      "Iteration 2243, loss = 0.01436444\n",
      "Iteration 2244, loss = 0.01435668\n",
      "Iteration 2245, loss = 0.01434796\n",
      "Iteration 2246, loss = 0.01434034\n",
      "Iteration 2247, loss = 0.01433235\n",
      "Iteration 2248, loss = 0.01432400\n",
      "Iteration 2249, loss = 0.01431619\n",
      "Iteration 2250, loss = 0.01430820\n",
      "Iteration 2251, loss = 0.01430041\n",
      "Iteration 2252, loss = 0.01429262\n",
      "Iteration 2253, loss = 0.01428529\n",
      "Iteration 2254, loss = 0.01427676\n",
      "Iteration 2255, loss = 0.01426911\n",
      "Iteration 2256, loss = 0.01426097\n",
      "Iteration 2257, loss = 0.01425308\n",
      "Iteration 2258, loss = 0.01424615\n",
      "Iteration 2259, loss = 0.01423710\n",
      "Iteration 2260, loss = 0.01422947\n",
      "Iteration 2261, loss = 0.01422113\n",
      "Iteration 2262, loss = 0.01421355\n",
      "Iteration 2263, loss = 0.01420528\n",
      "Iteration 2264, loss = 0.01419776\n",
      "Iteration 2265, loss = 0.01419058\n",
      "Iteration 2266, loss = 0.01418222\n",
      "Iteration 2267, loss = 0.01417497\n",
      "Iteration 2268, loss = 0.01416787\n",
      "Iteration 2269, loss = 0.01415965\n",
      "Iteration 2270, loss = 0.01415162\n",
      "Iteration 2271, loss = 0.01414506\n",
      "Iteration 2272, loss = 0.01413608\n",
      "Iteration 2273, loss = 0.01412836\n",
      "Iteration 2274, loss = 0.01412055\n",
      "Iteration 2275, loss = 0.01411143\n",
      "Iteration 2276, loss = 0.01410485\n",
      "Iteration 2277, loss = 0.01409476\n",
      "Iteration 2278, loss = 0.01408561\n",
      "Iteration 2279, loss = 0.01408017\n",
      "Iteration 2280, loss = 0.01407120\n",
      "Iteration 2281, loss = 0.01406195\n",
      "Iteration 2282, loss = 0.01405326\n",
      "Iteration 2283, loss = 0.01404447\n",
      "Iteration 2284, loss = 0.01403717\n",
      "Iteration 2285, loss = 0.01402767\n",
      "Iteration 2286, loss = 0.01402020\n",
      "Iteration 2287, loss = 0.01401142\n",
      "Iteration 2288, loss = 0.01400278\n",
      "Iteration 2289, loss = 0.01399627\n",
      "Iteration 2290, loss = 0.01398962\n",
      "Iteration 2291, loss = 0.01398128\n",
      "Iteration 2292, loss = 0.01397299\n",
      "Iteration 2293, loss = 0.01396568\n",
      "Iteration 2294, loss = 0.01395836\n",
      "Iteration 2295, loss = 0.01395054\n",
      "Iteration 2296, loss = 0.01394239\n",
      "Iteration 2297, loss = 0.01393526\n",
      "Iteration 2298, loss = 0.01392631\n",
      "Iteration 2299, loss = 0.01391882\n",
      "Iteration 2300, loss = 0.01391101\n",
      "Iteration 2301, loss = 0.01390329\n",
      "Iteration 2302, loss = 0.01389559\n",
      "Iteration 2303, loss = 0.01388799\n",
      "Iteration 2304, loss = 0.01388055\n",
      "Iteration 2305, loss = 0.01387280\n",
      "Iteration 2306, loss = 0.01386780\n",
      "Iteration 2307, loss = 0.01385793\n",
      "Iteration 2308, loss = 0.01385096\n",
      "Iteration 2309, loss = 0.01384233\n",
      "Iteration 2310, loss = 0.01383604\n",
      "Iteration 2311, loss = 0.01382734\n",
      "Iteration 2312, loss = 0.01381926\n",
      "Iteration 2313, loss = 0.01381383\n",
      "Iteration 2314, loss = 0.01380462\n",
      "Iteration 2315, loss = 0.01379782\n",
      "Iteration 2316, loss = 0.01378886\n",
      "Iteration 2317, loss = 0.01378067\n",
      "Iteration 2318, loss = 0.01377257\n",
      "Iteration 2319, loss = 0.01376554\n",
      "Iteration 2320, loss = 0.01375957\n",
      "Iteration 2321, loss = 0.01374988\n",
      "Iteration 2322, loss = 0.01374244\n",
      "Iteration 2323, loss = 0.01373456\n",
      "Iteration 2324, loss = 0.01372689\n",
      "Iteration 2325, loss = 0.01371906\n",
      "Iteration 2326, loss = 0.01371164\n",
      "Iteration 2327, loss = 0.01370443\n",
      "Iteration 2328, loss = 0.01369773\n",
      "Iteration 2329, loss = 0.01368992\n",
      "Iteration 2330, loss = 0.01368362\n",
      "Iteration 2331, loss = 0.01367514\n",
      "Iteration 2332, loss = 0.01366988\n",
      "Iteration 2333, loss = 0.01366126\n",
      "Iteration 2334, loss = 0.01365364\n",
      "Iteration 2335, loss = 0.01364643\n",
      "Iteration 2336, loss = 0.01363889\n",
      "Iteration 2337, loss = 0.01363203\n",
      "Iteration 2338, loss = 0.01362469\n",
      "Iteration 2339, loss = 0.01361691\n",
      "Iteration 2340, loss = 0.01360921\n",
      "Iteration 2341, loss = 0.01360176\n",
      "Iteration 2342, loss = 0.01359409\n",
      "Iteration 2343, loss = 0.01358553\n",
      "Iteration 2344, loss = 0.01357840\n",
      "Iteration 2345, loss = 0.01357206\n",
      "Iteration 2346, loss = 0.01356299\n",
      "Iteration 2347, loss = 0.01355493\n",
      "Iteration 2348, loss = 0.01354730\n",
      "Iteration 2349, loss = 0.01354011\n",
      "Iteration 2350, loss = 0.01353347\n",
      "Iteration 2351, loss = 0.01352568\n",
      "Iteration 2352, loss = 0.01351953\n",
      "Iteration 2353, loss = 0.01351175\n",
      "Iteration 2354, loss = 0.01350410\n",
      "Iteration 2355, loss = 0.01349752\n",
      "Iteration 2356, loss = 0.01348817\n",
      "Iteration 2357, loss = 0.01348043\n",
      "Iteration 2358, loss = 0.01347338\n",
      "Iteration 2359, loss = 0.01346579\n",
      "Iteration 2360, loss = 0.01345794\n",
      "Iteration 2361, loss = 0.01345012\n",
      "Iteration 2362, loss = 0.01344203\n",
      "Iteration 2363, loss = 0.01343488\n",
      "Iteration 2364, loss = 0.01342760\n",
      "Iteration 2365, loss = 0.01342082\n",
      "Iteration 2366, loss = 0.01341353\n",
      "Iteration 2367, loss = 0.01340595\n",
      "Iteration 2368, loss = 0.01339884\n",
      "Iteration 2369, loss = 0.01339188\n",
      "Iteration 2370, loss = 0.01338417\n",
      "Iteration 2371, loss = 0.01337777\n",
      "Iteration 2372, loss = 0.01337060\n",
      "Iteration 2373, loss = 0.01336261\n",
      "Iteration 2374, loss = 0.01335456\n",
      "Iteration 2375, loss = 0.01334673\n",
      "Iteration 2376, loss = 0.01334048\n",
      "Iteration 2377, loss = 0.01333184\n",
      "Iteration 2378, loss = 0.01332469\n",
      "Iteration 2379, loss = 0.01331709\n",
      "Iteration 2380, loss = 0.01330964\n",
      "Iteration 2381, loss = 0.01330201\n",
      "Iteration 2382, loss = 0.01329472\n",
      "Iteration 2383, loss = 0.01328784\n",
      "Iteration 2384, loss = 0.01328055\n",
      "Iteration 2385, loss = 0.01327426\n",
      "Iteration 2386, loss = 0.01326740\n",
      "Iteration 2387, loss = 0.01325978\n",
      "Iteration 2388, loss = 0.01325438\n",
      "Iteration 2389, loss = 0.01324802\n",
      "Iteration 2390, loss = 0.01323937\n",
      "Iteration 2391, loss = 0.01323219\n",
      "Iteration 2392, loss = 0.01322549\n",
      "Iteration 2393, loss = 0.01321877\n",
      "Iteration 2394, loss = 0.01321249\n",
      "Iteration 2395, loss = 0.01320491\n",
      "Iteration 2396, loss = 0.01319806\n",
      "Iteration 2397, loss = 0.01319092\n",
      "Iteration 2398, loss = 0.01318446\n",
      "Iteration 2399, loss = 0.01317786\n",
      "Iteration 2400, loss = 0.01317175\n",
      "Iteration 2401, loss = 0.01316498\n",
      "Iteration 2402, loss = 0.01315643\n",
      "Iteration 2403, loss = 0.01315027\n",
      "Iteration 2404, loss = 0.01314182\n",
      "Iteration 2405, loss = 0.01313672\n",
      "Iteration 2406, loss = 0.01312827\n",
      "Iteration 2407, loss = 0.01312145\n",
      "Iteration 2408, loss = 0.01311546\n",
      "Iteration 2409, loss = 0.01310770\n",
      "Iteration 2410, loss = 0.01309998\n",
      "Iteration 2411, loss = 0.01309327\n",
      "Iteration 2412, loss = 0.01308644\n",
      "Iteration 2413, loss = 0.01307975\n",
      "Iteration 2414, loss = 0.01307296\n",
      "Iteration 2415, loss = 0.01306579\n",
      "Iteration 2416, loss = 0.01306151\n",
      "Iteration 2417, loss = 0.01305263\n",
      "Iteration 2418, loss = 0.01304709\n",
      "Iteration 2419, loss = 0.01303877\n",
      "Iteration 2420, loss = 0.01303193\n",
      "Iteration 2421, loss = 0.01302511\n",
      "Iteration 2422, loss = 0.01301818\n",
      "Iteration 2423, loss = 0.01301277\n",
      "Iteration 2424, loss = 0.01300484\n",
      "Iteration 2425, loss = 0.01299823\n",
      "Iteration 2426, loss = 0.01299355\n",
      "Iteration 2427, loss = 0.01298584\n",
      "Iteration 2428, loss = 0.01297858\n",
      "Iteration 2429, loss = 0.01297577\n",
      "Iteration 2430, loss = 0.01296652\n",
      "Iteration 2431, loss = 0.01295933\n",
      "Iteration 2432, loss = 0.01295205\n",
      "Iteration 2433, loss = 0.01294543\n",
      "Iteration 2434, loss = 0.01293792\n",
      "Iteration 2435, loss = 0.01293148\n",
      "Iteration 2436, loss = 0.01292350\n",
      "Iteration 2437, loss = 0.01291756\n",
      "Iteration 2438, loss = 0.01291013\n",
      "Iteration 2439, loss = 0.01290372\n",
      "Iteration 2440, loss = 0.01289659\n",
      "Iteration 2441, loss = 0.01289076\n",
      "Iteration 2442, loss = 0.01288351\n",
      "Iteration 2443, loss = 0.01287694\n",
      "Iteration 2444, loss = 0.01287052\n",
      "Iteration 2445, loss = 0.01286371\n",
      "Iteration 2446, loss = 0.01285680\n",
      "Iteration 2447, loss = 0.01284986\n",
      "Iteration 2448, loss = 0.01284287\n",
      "Iteration 2449, loss = 0.01283562\n",
      "Iteration 2450, loss = 0.01282900\n",
      "Iteration 2451, loss = 0.01282317\n",
      "Iteration 2452, loss = 0.01281627\n",
      "Iteration 2453, loss = 0.01280987\n",
      "Iteration 2454, loss = 0.01280233\n",
      "Iteration 2455, loss = 0.01279521\n",
      "Iteration 2456, loss = 0.01278854\n",
      "Iteration 2457, loss = 0.01278198\n",
      "Iteration 2458, loss = 0.01277765\n",
      "Iteration 2459, loss = 0.01276974\n",
      "Iteration 2460, loss = 0.01276353\n",
      "Iteration 2461, loss = 0.01275706\n",
      "Iteration 2462, loss = 0.01275250\n",
      "Iteration 2463, loss = 0.01274382\n",
      "Iteration 2464, loss = 0.01273653\n",
      "Iteration 2465, loss = 0.01273008\n",
      "Iteration 2466, loss = 0.01272286\n",
      "Iteration 2467, loss = 0.01271494\n",
      "Iteration 2468, loss = 0.01270990\n",
      "Iteration 2469, loss = 0.01270175\n",
      "Iteration 2470, loss = 0.01269598\n",
      "Iteration 2471, loss = 0.01268915\n",
      "Iteration 2472, loss = 0.01268327\n",
      "Iteration 2473, loss = 0.01267762\n",
      "Iteration 2474, loss = 0.01267166\n",
      "Iteration 2475, loss = 0.01266521\n",
      "Iteration 2476, loss = 0.01266026\n",
      "Iteration 2477, loss = 0.01265359\n",
      "Iteration 2478, loss = 0.01264681\n",
      "Iteration 2479, loss = 0.01264117\n",
      "Iteration 2480, loss = 0.01263424\n",
      "Iteration 2481, loss = 0.01262744\n",
      "Iteration 2482, loss = 0.01262051\n",
      "Iteration 2483, loss = 0.01261266\n",
      "Iteration 2484, loss = 0.01260738\n",
      "Iteration 2485, loss = 0.01259920\n",
      "Iteration 2486, loss = 0.01259211\n",
      "Iteration 2487, loss = 0.01258648\n",
      "Iteration 2488, loss = 0.01257849\n",
      "Iteration 2489, loss = 0.01257225\n",
      "Iteration 2490, loss = 0.01256568\n",
      "Iteration 2491, loss = 0.01256097\n",
      "Iteration 2492, loss = 0.01255141\n",
      "Iteration 2493, loss = 0.01254544\n",
      "Iteration 2494, loss = 0.01253734\n",
      "Iteration 2495, loss = 0.01253093\n",
      "Iteration 2496, loss = 0.01252420\n",
      "Iteration 2497, loss = 0.01251802\n",
      "Iteration 2498, loss = 0.01251222\n",
      "Iteration 2499, loss = 0.01250395\n",
      "Iteration 2500, loss = 0.01249779\n",
      "Iteration 2501, loss = 0.01249050\n",
      "Iteration 2502, loss = 0.01248484\n",
      "Iteration 2503, loss = 0.01247866\n",
      "Iteration 2504, loss = 0.01247063\n",
      "Iteration 2505, loss = 0.01246456\n",
      "Iteration 2506, loss = 0.01245765\n",
      "Iteration 2507, loss = 0.01245180\n",
      "Iteration 2508, loss = 0.01244458\n",
      "Iteration 2509, loss = 0.01243736\n",
      "Iteration 2510, loss = 0.01243023\n",
      "Iteration 2511, loss = 0.01242420\n",
      "Iteration 2512, loss = 0.01241654\n",
      "Iteration 2513, loss = 0.01240965\n",
      "Iteration 2514, loss = 0.01240311\n",
      "Iteration 2515, loss = 0.01239687\n",
      "Iteration 2516, loss = 0.01239005\n",
      "Iteration 2517, loss = 0.01238321\n",
      "Iteration 2518, loss = 0.01237574\n",
      "Iteration 2519, loss = 0.01236997\n",
      "Iteration 2520, loss = 0.01236277\n",
      "Iteration 2521, loss = 0.01235716\n",
      "Iteration 2522, loss = 0.01234996\n",
      "Iteration 2523, loss = 0.01234397\n",
      "Iteration 2524, loss = 0.01233683\n",
      "Iteration 2525, loss = 0.01233021\n",
      "Iteration 2526, loss = 0.01232552\n",
      "Iteration 2527, loss = 0.01231792\n",
      "Iteration 2528, loss = 0.01231146\n",
      "Iteration 2529, loss = 0.01230519\n",
      "Iteration 2530, loss = 0.01229816\n",
      "Iteration 2531, loss = 0.01229062\n",
      "Iteration 2532, loss = 0.01228702\n",
      "Iteration 2533, loss = 0.01227995\n",
      "Iteration 2534, loss = 0.01227330\n",
      "Iteration 2535, loss = 0.01226696\n",
      "Iteration 2536, loss = 0.01226082\n",
      "Iteration 2537, loss = 0.01225599\n",
      "Iteration 2538, loss = 0.01224858\n",
      "Iteration 2539, loss = 0.01224259\n",
      "Iteration 2540, loss = 0.01223638\n",
      "Iteration 2541, loss = 0.01222989\n",
      "Iteration 2542, loss = 0.01222395\n",
      "Iteration 2543, loss = 0.01221780\n",
      "Iteration 2544, loss = 0.01221166\n",
      "Iteration 2545, loss = 0.01220739\n",
      "Iteration 2546, loss = 0.01220067\n",
      "Iteration 2547, loss = 0.01219561\n",
      "Iteration 2548, loss = 0.01218887\n",
      "Iteration 2549, loss = 0.01218305\n",
      "Iteration 2550, loss = 0.01217671\n",
      "Iteration 2551, loss = 0.01217078\n",
      "Iteration 2552, loss = 0.01216440\n",
      "Iteration 2553, loss = 0.01215849\n",
      "Iteration 2554, loss = 0.01215270\n",
      "Iteration 2555, loss = 0.01214719\n",
      "Iteration 2556, loss = 0.01214095\n",
      "Iteration 2557, loss = 0.01213488\n",
      "Iteration 2558, loss = 0.01212882\n",
      "Iteration 2559, loss = 0.01212288\n",
      "Iteration 2560, loss = 0.01211717\n",
      "Iteration 2561, loss = 0.01211155\n",
      "Iteration 2562, loss = 0.01210604\n",
      "Iteration 2563, loss = 0.01210123\n",
      "Iteration 2564, loss = 0.01209588\n",
      "Iteration 2565, loss = 0.01208964\n",
      "Iteration 2566, loss = 0.01208386\n",
      "Iteration 2567, loss = 0.01207976\n",
      "Iteration 2568, loss = 0.01207173\n",
      "Iteration 2569, loss = 0.01206598\n",
      "Iteration 2570, loss = 0.01206029\n",
      "Iteration 2571, loss = 0.01205180\n",
      "Iteration 2572, loss = 0.01204702\n",
      "Iteration 2573, loss = 0.01203914\n",
      "Iteration 2574, loss = 0.01203249\n",
      "Iteration 2575, loss = 0.01202624\n",
      "Iteration 2576, loss = 0.01201878\n",
      "Iteration 2577, loss = 0.01201254\n",
      "Iteration 2578, loss = 0.01200546\n",
      "Iteration 2579, loss = 0.01199980\n",
      "Iteration 2580, loss = 0.01199443\n",
      "Iteration 2581, loss = 0.01198676\n",
      "Iteration 2582, loss = 0.01197966\n",
      "Iteration 2583, loss = 0.01197307\n",
      "Iteration 2584, loss = 0.01196702\n",
      "Iteration 2585, loss = 0.01196319\n",
      "Iteration 2586, loss = 0.01195504\n",
      "Iteration 2587, loss = 0.01194931\n",
      "Iteration 2588, loss = 0.01194239\n",
      "Iteration 2589, loss = 0.01193695\n",
      "Iteration 2590, loss = 0.01193182\n",
      "Iteration 2591, loss = 0.01192494\n",
      "Iteration 2592, loss = 0.01191951\n",
      "Iteration 2593, loss = 0.01191549\n",
      "Iteration 2594, loss = 0.01190813\n",
      "Iteration 2595, loss = 0.01190222\n",
      "Iteration 2596, loss = 0.01189677\n",
      "Iteration 2597, loss = 0.01189061\n",
      "Iteration 2598, loss = 0.01188482\n",
      "Iteration 2599, loss = 0.01187907\n",
      "Iteration 2600, loss = 0.01187366\n",
      "Iteration 2601, loss = 0.01186690\n",
      "Iteration 2602, loss = 0.01186175\n",
      "Iteration 2603, loss = 0.01185636\n",
      "Iteration 2604, loss = 0.01185097\n",
      "Iteration 2605, loss = 0.01184561\n",
      "Iteration 2606, loss = 0.01183953\n",
      "Iteration 2607, loss = 0.01183409\n",
      "Iteration 2608, loss = 0.01182933\n",
      "Iteration 2609, loss = 0.01182370\n",
      "Iteration 2610, loss = 0.01181743\n",
      "Iteration 2611, loss = 0.01181225\n",
      "Iteration 2612, loss = 0.01180644\n",
      "Iteration 2613, loss = 0.01180099\n",
      "Iteration 2614, loss = 0.01179478\n",
      "Iteration 2615, loss = 0.01178919\n",
      "Iteration 2616, loss = 0.01178250\n",
      "Iteration 2617, loss = 0.01177715\n",
      "Iteration 2618, loss = 0.01177032\n",
      "Iteration 2619, loss = 0.01176491\n",
      "Iteration 2620, loss = 0.01175810\n",
      "Iteration 2621, loss = 0.01175232\n",
      "Iteration 2622, loss = 0.01174620\n",
      "Iteration 2623, loss = 0.01174045\n",
      "Iteration 2624, loss = 0.01173408\n",
      "Iteration 2625, loss = 0.01172902\n",
      "Iteration 2626, loss = 0.01172246\n",
      "Iteration 2627, loss = 0.01171644\n",
      "Iteration 2628, loss = 0.01171064\n",
      "Iteration 2629, loss = 0.01170434\n",
      "Iteration 2630, loss = 0.01169847\n",
      "Iteration 2631, loss = 0.01169126\n",
      "Iteration 2632, loss = 0.01168627\n",
      "Iteration 2633, loss = 0.01167909\n",
      "Iteration 2634, loss = 0.01167346\n",
      "Iteration 2635, loss = 0.01166651\n",
      "Iteration 2636, loss = 0.01166048\n",
      "Iteration 2637, loss = 0.01165422\n",
      "Iteration 2638, loss = 0.01164988\n",
      "Iteration 2639, loss = 0.01164238\n",
      "Iteration 2640, loss = 0.01163659\n",
      "Iteration 2641, loss = 0.01163038\n",
      "Iteration 2642, loss = 0.01162414\n",
      "Iteration 2643, loss = 0.01161825\n",
      "Iteration 2644, loss = 0.01161194\n",
      "Iteration 2645, loss = 0.01160620\n",
      "Iteration 2646, loss = 0.01160093\n",
      "Iteration 2647, loss = 0.01159535\n",
      "Iteration 2648, loss = 0.01158959\n",
      "Iteration 2649, loss = 0.01158384\n",
      "Iteration 2650, loss = 0.01157839\n",
      "Iteration 2651, loss = 0.01157158\n",
      "Iteration 2652, loss = 0.01156571\n",
      "Iteration 2653, loss = 0.01156047\n",
      "Iteration 2654, loss = 0.01155363\n",
      "Iteration 2655, loss = 0.01154857\n",
      "Iteration 2656, loss = 0.01154269\n",
      "Iteration 2657, loss = 0.01153740\n",
      "Iteration 2658, loss = 0.01153080\n",
      "Iteration 2659, loss = 0.01152549\n",
      "Iteration 2660, loss = 0.01151895\n",
      "Iteration 2661, loss = 0.01151337\n",
      "Iteration 2662, loss = 0.01150771\n",
      "Iteration 2663, loss = 0.01150226\n",
      "Iteration 2664, loss = 0.01149679\n",
      "Iteration 2665, loss = 0.01149121\n",
      "Iteration 2666, loss = 0.01148649\n",
      "Iteration 2667, loss = 0.01148017\n",
      "Iteration 2668, loss = 0.01147500\n",
      "Iteration 2669, loss = 0.01146949\n",
      "Iteration 2670, loss = 0.01146334\n",
      "Iteration 2671, loss = 0.01145766\n",
      "Iteration 2672, loss = 0.01145407\n",
      "Iteration 2673, loss = 0.01144815\n",
      "Iteration 2674, loss = 0.01144314\n",
      "Iteration 2675, loss = 0.01143657\n",
      "Iteration 2676, loss = 0.01143111\n",
      "Iteration 2677, loss = 0.01142570\n",
      "Iteration 2678, loss = 0.01142044\n",
      "Iteration 2679, loss = 0.01141454\n",
      "Iteration 2680, loss = 0.01140887\n",
      "Iteration 2681, loss = 0.01140399\n",
      "Iteration 2682, loss = 0.01139890\n",
      "Iteration 2683, loss = 0.01139394\n",
      "Iteration 2684, loss = 0.01138741\n",
      "Iteration 2685, loss = 0.01138217\n",
      "Iteration 2686, loss = 0.01137685\n",
      "Iteration 2687, loss = 0.01137160\n",
      "Iteration 2688, loss = 0.01136726\n",
      "Iteration 2689, loss = 0.01136158\n",
      "Iteration 2690, loss = 0.01135611\n",
      "Iteration 2691, loss = 0.01135187\n",
      "Iteration 2692, loss = 0.01134624\n",
      "Iteration 2693, loss = 0.01134111\n",
      "Iteration 2694, loss = 0.01133790\n",
      "Iteration 2695, loss = 0.01133094\n",
      "Iteration 2696, loss = 0.01132533\n",
      "Iteration 2697, loss = 0.01132015\n",
      "Iteration 2698, loss = 0.01131475\n",
      "Iteration 2699, loss = 0.01130950\n",
      "Iteration 2700, loss = 0.01130410\n",
      "Iteration 2701, loss = 0.01129835\n",
      "Iteration 2702, loss = 0.01129252\n",
      "Iteration 2703, loss = 0.01128687\n",
      "Iteration 2704, loss = 0.01128215\n",
      "Iteration 2705, loss = 0.01127614\n",
      "Iteration 2706, loss = 0.01127135\n",
      "Iteration 2707, loss = 0.01126584\n",
      "Iteration 2708, loss = 0.01126046\n",
      "Iteration 2709, loss = 0.01125588\n",
      "Iteration 2710, loss = 0.01125134\n",
      "Iteration 2711, loss = 0.01124529\n",
      "Iteration 2712, loss = 0.01124044\n",
      "Iteration 2713, loss = 0.01123581\n",
      "Iteration 2714, loss = 0.01123469\n",
      "Iteration 2715, loss = 0.01122897\n",
      "Iteration 2716, loss = 0.01122210\n",
      "Iteration 2717, loss = 0.01121648\n",
      "Iteration 2718, loss = 0.01121089\n",
      "Iteration 2719, loss = 0.01120513\n",
      "Iteration 2720, loss = 0.01120061\n",
      "Iteration 2721, loss = 0.01119419\n",
      "Iteration 2722, loss = 0.01118860\n",
      "Iteration 2723, loss = 0.01118289\n",
      "Iteration 2724, loss = 0.01117755\n",
      "Iteration 2725, loss = 0.01117202\n",
      "Iteration 2726, loss = 0.01116649\n",
      "Iteration 2727, loss = 0.01116058\n",
      "Iteration 2728, loss = 0.01115461\n",
      "Iteration 2729, loss = 0.01115044\n",
      "Iteration 2730, loss = 0.01114417\n",
      "Iteration 2731, loss = 0.01113867\n",
      "Iteration 2732, loss = 0.01113221\n",
      "Iteration 2733, loss = 0.01112654\n",
      "Iteration 2734, loss = 0.01112022\n",
      "Iteration 2735, loss = 0.01111416\n",
      "Iteration 2736, loss = 0.01110974\n",
      "Iteration 2737, loss = 0.01110234\n",
      "Iteration 2738, loss = 0.01109801\n",
      "Iteration 2739, loss = 0.01109318\n",
      "Iteration 2740, loss = 0.01108594\n",
      "Iteration 2741, loss = 0.01108138\n",
      "Iteration 2742, loss = 0.01107583\n",
      "Iteration 2743, loss = 0.01107021\n",
      "Iteration 2744, loss = 0.01106504\n",
      "Iteration 2745, loss = 0.01106052\n",
      "Iteration 2746, loss = 0.01105465\n",
      "Iteration 2747, loss = 0.01105067\n",
      "Iteration 2748, loss = 0.01104642\n",
      "Iteration 2749, loss = 0.01103956\n",
      "Iteration 2750, loss = 0.01103397\n",
      "Iteration 2751, loss = 0.01102902\n",
      "Iteration 2752, loss = 0.01102304\n",
      "Iteration 2753, loss = 0.01101831\n",
      "Iteration 2754, loss = 0.01101246\n",
      "Iteration 2755, loss = 0.01100756\n",
      "Iteration 2756, loss = 0.01100235\n",
      "Iteration 2757, loss = 0.01099637\n",
      "Iteration 2758, loss = 0.01099105\n",
      "Iteration 2759, loss = 0.01098520\n",
      "Iteration 2760, loss = 0.01098169\n",
      "Iteration 2761, loss = 0.01097519\n",
      "Iteration 2762, loss = 0.01096995\n",
      "Iteration 2763, loss = 0.01096437\n",
      "Iteration 2764, loss = 0.01095984\n",
      "Iteration 2765, loss = 0.01095497\n",
      "Iteration 2766, loss = 0.01094932\n",
      "Iteration 2767, loss = 0.01094448\n",
      "Iteration 2768, loss = 0.01093918\n",
      "Iteration 2769, loss = 0.01093436\n",
      "Iteration 2770, loss = 0.01092937\n",
      "Iteration 2771, loss = 0.01092386\n",
      "Iteration 2772, loss = 0.01091890\n",
      "Iteration 2773, loss = 0.01091373\n",
      "Iteration 2774, loss = 0.01090909\n",
      "Iteration 2775, loss = 0.01090441\n",
      "Iteration 2776, loss = 0.01089889\n",
      "Iteration 2777, loss = 0.01089387\n",
      "Iteration 2778, loss = 0.01088875\n",
      "Iteration 2779, loss = 0.01088444\n",
      "Iteration 2780, loss = 0.01087931\n",
      "Iteration 2781, loss = 0.01087573\n",
      "Iteration 2782, loss = 0.01086932\n",
      "Iteration 2783, loss = 0.01086374\n",
      "Iteration 2784, loss = 0.01085924\n",
      "Iteration 2785, loss = 0.01085401\n",
      "Iteration 2786, loss = 0.01084821\n",
      "Iteration 2787, loss = 0.01084296\n",
      "Iteration 2788, loss = 0.01083765\n",
      "Iteration 2789, loss = 0.01083240\n",
      "Iteration 2790, loss = 0.01082753\n",
      "Iteration 2791, loss = 0.01082213\n",
      "Iteration 2792, loss = 0.01081664\n",
      "Iteration 2793, loss = 0.01081150\n",
      "Iteration 2794, loss = 0.01080566\n",
      "Iteration 2795, loss = 0.01080114\n",
      "Iteration 2796, loss = 0.01079564\n",
      "Iteration 2797, loss = 0.01079097\n",
      "Iteration 2798, loss = 0.01078606\n",
      "Iteration 2799, loss = 0.01078149\n",
      "Iteration 2800, loss = 0.01077611\n",
      "Iteration 2801, loss = 0.01077185\n",
      "Iteration 2802, loss = 0.01076618\n",
      "Iteration 2803, loss = 0.01076094\n",
      "Iteration 2804, loss = 0.01075571\n",
      "Iteration 2805, loss = 0.01075142\n",
      "Iteration 2806, loss = 0.01074538\n",
      "Iteration 2807, loss = 0.01073965\n",
      "Iteration 2808, loss = 0.01073365\n",
      "Iteration 2809, loss = 0.01072869\n",
      "Iteration 2810, loss = 0.01072259\n",
      "Iteration 2811, loss = 0.01071921\n",
      "Iteration 2812, loss = 0.01071291\n",
      "Iteration 2813, loss = 0.01070869\n",
      "Iteration 2814, loss = 0.01070234\n",
      "Iteration 2815, loss = 0.01069759\n",
      "Iteration 2816, loss = 0.01069458\n",
      "Iteration 2817, loss = 0.01068776\n",
      "Iteration 2818, loss = 0.01068313\n",
      "Iteration 2819, loss = 0.01067793\n",
      "Iteration 2820, loss = 0.01067369\n",
      "Iteration 2821, loss = 0.01066831\n",
      "Iteration 2822, loss = 0.01066369\n",
      "Iteration 2823, loss = 0.01065876\n",
      "Iteration 2824, loss = 0.01065416\n",
      "Iteration 2825, loss = 0.01064996\n",
      "Iteration 2826, loss = 0.01064726\n",
      "Iteration 2827, loss = 0.01064107\n",
      "Iteration 2828, loss = 0.01063651\n",
      "Iteration 2829, loss = 0.01063211\n",
      "Iteration 2830, loss = 0.01062779\n",
      "Iteration 2831, loss = 0.01062351\n",
      "Iteration 2832, loss = 0.01062108\n",
      "Iteration 2833, loss = 0.01061516\n",
      "Iteration 2834, loss = 0.01061177\n",
      "Iteration 2835, loss = 0.01060708\n",
      "Iteration 2836, loss = 0.01060182\n",
      "Iteration 2837, loss = 0.01059743\n",
      "Iteration 2838, loss = 0.01059308\n",
      "Iteration 2839, loss = 0.01058880\n",
      "Iteration 2840, loss = 0.01058535\n",
      "Iteration 2841, loss = 0.01058009\n",
      "Iteration 2842, loss = 0.01057498\n",
      "Iteration 2843, loss = 0.01057025\n",
      "Iteration 2844, loss = 0.01056598\n",
      "Iteration 2845, loss = 0.01056089\n",
      "Iteration 2846, loss = 0.01055603\n",
      "Iteration 2847, loss = 0.01055042\n",
      "Iteration 2848, loss = 0.01054532\n",
      "Iteration 2849, loss = 0.01054055\n",
      "Iteration 2850, loss = 0.01053512\n",
      "Iteration 2851, loss = 0.01052948\n",
      "Iteration 2852, loss = 0.01052314\n",
      "Iteration 2853, loss = 0.01051852\n",
      "Iteration 2854, loss = 0.01051420\n",
      "Iteration 2855, loss = 0.01050783\n",
      "Iteration 2856, loss = 0.01050263\n",
      "Iteration 2857, loss = 0.01049711\n",
      "Iteration 2858, loss = 0.01049299\n",
      "Iteration 2859, loss = 0.01048739\n",
      "Iteration 2860, loss = 0.01048231\n",
      "Iteration 2861, loss = 0.01047759\n",
      "Iteration 2862, loss = 0.01047370\n",
      "Iteration 2863, loss = 0.01046869\n",
      "Iteration 2864, loss = 0.01046479\n",
      "Iteration 2865, loss = 0.01045995\n",
      "Iteration 2866, loss = 0.01045530\n",
      "Iteration 2867, loss = 0.01045102\n",
      "Iteration 2868, loss = 0.01044628\n",
      "Iteration 2869, loss = 0.01044182\n",
      "Iteration 2870, loss = 0.01043713\n",
      "Iteration 2871, loss = 0.01043221\n",
      "Iteration 2872, loss = 0.01042740\n",
      "Iteration 2873, loss = 0.01042296\n",
      "Iteration 2874, loss = 0.01041843\n",
      "Iteration 2875, loss = 0.01041465\n",
      "Iteration 2876, loss = 0.01040912\n",
      "Iteration 2877, loss = 0.01040548\n",
      "Iteration 2878, loss = 0.01040097\n",
      "Iteration 2879, loss = 0.01039625\n",
      "Iteration 2880, loss = 0.01039160\n",
      "Iteration 2881, loss = 0.01038633\n",
      "Iteration 2882, loss = 0.01038197\n",
      "Iteration 2883, loss = 0.01037643\n",
      "Iteration 2884, loss = 0.01037261\n",
      "Iteration 2885, loss = 0.01036735\n",
      "Iteration 2886, loss = 0.01036303\n",
      "Iteration 2887, loss = 0.01035848\n",
      "Iteration 2888, loss = 0.01035407\n",
      "Iteration 2889, loss = 0.01035018\n",
      "Iteration 2890, loss = 0.01034562\n",
      "Iteration 2891, loss = 0.01034240\n",
      "Iteration 2892, loss = 0.01033657\n",
      "Iteration 2893, loss = 0.01033333\n",
      "Iteration 2894, loss = 0.01032707\n",
      "Iteration 2895, loss = 0.01032331\n",
      "Iteration 2896, loss = 0.01031861\n",
      "Iteration 2897, loss = 0.01031371\n",
      "Iteration 2898, loss = 0.01030973\n",
      "Iteration 2899, loss = 0.01030550\n",
      "Iteration 2900, loss = 0.01030083\n",
      "Iteration 2901, loss = 0.01029558\n",
      "Iteration 2902, loss = 0.01029124\n",
      "Iteration 2903, loss = 0.01028737\n",
      "Iteration 2904, loss = 0.01028211\n",
      "Iteration 2905, loss = 0.01027736\n",
      "Iteration 2906, loss = 0.01027283\n",
      "Iteration 2907, loss = 0.01026804\n",
      "Iteration 2908, loss = 0.01026348\n",
      "Iteration 2909, loss = 0.01025869\n",
      "Iteration 2910, loss = 0.01025418\n",
      "Iteration 2911, loss = 0.01025011\n",
      "Iteration 2912, loss = 0.01024519\n",
      "Iteration 2913, loss = 0.01024034\n",
      "Iteration 2914, loss = 0.01023635\n",
      "Iteration 2915, loss = 0.01023146\n",
      "Iteration 2916, loss = 0.01022671\n",
      "Iteration 2917, loss = 0.01022281\n",
      "Iteration 2918, loss = 0.01021828\n",
      "Iteration 2919, loss = 0.01021377\n",
      "Iteration 2920, loss = 0.01021005\n",
      "Iteration 2921, loss = 0.01020571\n",
      "Iteration 2922, loss = 0.01020128\n",
      "Iteration 2923, loss = 0.01019783\n",
      "Iteration 2924, loss = 0.01019334\n",
      "Iteration 2925, loss = 0.01019051\n",
      "Iteration 2926, loss = 0.01018516\n",
      "Iteration 2927, loss = 0.01018044\n",
      "Iteration 2928, loss = 0.01017618\n",
      "Iteration 2929, loss = 0.01017215\n",
      "Iteration 2930, loss = 0.01016633\n",
      "Iteration 2931, loss = 0.01016110\n",
      "Iteration 2932, loss = 0.01015756\n",
      "Iteration 2933, loss = 0.01015234\n",
      "Iteration 2934, loss = 0.01014790\n",
      "Iteration 2935, loss = 0.01014307\n",
      "Iteration 2936, loss = 0.01013756\n",
      "Iteration 2937, loss = 0.01013342\n",
      "Iteration 2938, loss = 0.01012806\n",
      "Iteration 2939, loss = 0.01012472\n",
      "Iteration 2940, loss = 0.01011898\n",
      "Iteration 2941, loss = 0.01011489\n",
      "Iteration 2942, loss = 0.01010988\n",
      "Iteration 2943, loss = 0.01010551\n",
      "Iteration 2944, loss = 0.01010089\n",
      "Iteration 2945, loss = 0.01009662\n",
      "Iteration 2946, loss = 0.01009326\n",
      "Iteration 2947, loss = 0.01008836\n",
      "Iteration 2948, loss = 0.01008431\n",
      "Iteration 2949, loss = 0.01008098\n",
      "Iteration 2950, loss = 0.01007641\n",
      "Iteration 2951, loss = 0.01007208\n",
      "Iteration 2952, loss = 0.01006825\n",
      "Iteration 2953, loss = 0.01006348\n",
      "Iteration 2954, loss = 0.01005858\n",
      "Iteration 2955, loss = 0.01005457\n",
      "Iteration 2956, loss = 0.01005044\n",
      "Iteration 2957, loss = 0.01004531\n",
      "Iteration 2958, loss = 0.01004108\n",
      "Iteration 2959, loss = 0.01003653\n",
      "Iteration 2960, loss = 0.01003222\n",
      "Iteration 2961, loss = 0.01002820\n",
      "Iteration 2962, loss = 0.01002382\n",
      "Iteration 2963, loss = 0.01001926\n",
      "Iteration 2964, loss = 0.01001461\n",
      "Iteration 2965, loss = 0.01001069\n",
      "Iteration 2966, loss = 0.01000690\n",
      "Iteration 2967, loss = 0.01000499\n",
      "Iteration 2968, loss = 0.00999895\n",
      "Iteration 2969, loss = 0.00999580\n",
      "Iteration 2970, loss = 0.00999039\n",
      "Iteration 2971, loss = 0.00998599\n",
      "Iteration 2972, loss = 0.00998158\n",
      "Iteration 2973, loss = 0.00997739\n",
      "Iteration 2974, loss = 0.00997295\n",
      "Iteration 2975, loss = 0.00996886\n",
      "Iteration 2976, loss = 0.00996469\n",
      "Iteration 2977, loss = 0.00996073\n",
      "Iteration 2978, loss = 0.00995688\n",
      "Iteration 2979, loss = 0.00995328\n",
      "Iteration 2980, loss = 0.00994958\n",
      "Iteration 2981, loss = 0.00994594\n",
      "Iteration 2982, loss = 0.00994289\n",
      "Iteration 2983, loss = 0.00993864\n",
      "Iteration 2984, loss = 0.00993450\n",
      "Iteration 2985, loss = 0.00993006\n",
      "Iteration 2986, loss = 0.00992600\n",
      "Iteration 2987, loss = 0.00992211\n",
      "Iteration 2988, loss = 0.00991782\n",
      "Iteration 2989, loss = 0.00991375\n",
      "Iteration 2990, loss = 0.00990946\n",
      "Iteration 2991, loss = 0.00990537\n",
      "Iteration 2992, loss = 0.00990108\n",
      "Iteration 2993, loss = 0.00989646\n",
      "Iteration 2994, loss = 0.00989213\n",
      "Iteration 2995, loss = 0.00988777\n",
      "Iteration 2996, loss = 0.00988374\n",
      "Iteration 2997, loss = 0.00987945\n",
      "Iteration 2998, loss = 0.00987445\n",
      "Iteration 2999, loss = 0.00987014\n",
      "Iteration 3000, loss = 0.00986557\n",
      "Iteration 3001, loss = 0.00986331\n",
      "Iteration 3002, loss = 0.00985709\n",
      "Iteration 3003, loss = 0.00985254\n",
      "Iteration 3004, loss = 0.00984821\n",
      "Iteration 3005, loss = 0.00984380\n",
      "Iteration 3006, loss = 0.00983928\n",
      "Iteration 3007, loss = 0.00983535\n",
      "Iteration 3008, loss = 0.00983138\n",
      "Iteration 3009, loss = 0.00982784\n",
      "Iteration 3010, loss = 0.00982466\n",
      "Iteration 3011, loss = 0.00981964\n",
      "Iteration 3012, loss = 0.00981385\n",
      "Iteration 3013, loss = 0.00980961\n",
      "Iteration 3014, loss = 0.00980484\n",
      "Iteration 3015, loss = 0.00980128\n",
      "Iteration 3016, loss = 0.00979718\n",
      "Iteration 3017, loss = 0.00979242\n",
      "Iteration 3018, loss = 0.00978723\n",
      "Iteration 3019, loss = 0.00978275\n",
      "Iteration 3020, loss = 0.00977832\n",
      "Iteration 3021, loss = 0.00977351\n",
      "Iteration 3022, loss = 0.00976880\n",
      "Iteration 3023, loss = 0.00976311\n",
      "Iteration 3024, loss = 0.00975907\n",
      "Iteration 3025, loss = 0.00975454\n",
      "Iteration 3026, loss = 0.00975087\n",
      "Iteration 3027, loss = 0.00974677\n",
      "Iteration 3028, loss = 0.00974135\n",
      "Iteration 3029, loss = 0.00973711\n",
      "Iteration 3030, loss = 0.00973308\n",
      "Iteration 3031, loss = 0.00972961\n",
      "Iteration 3032, loss = 0.00972464\n",
      "Iteration 3033, loss = 0.00972006\n",
      "Iteration 3034, loss = 0.00971537\n",
      "Iteration 3035, loss = 0.00971107\n",
      "Iteration 3036, loss = 0.00970620\n",
      "Iteration 3037, loss = 0.00970181\n",
      "Iteration 3038, loss = 0.00969691\n",
      "Iteration 3039, loss = 0.00969206\n",
      "Iteration 3040, loss = 0.00968776\n",
      "Iteration 3041, loss = 0.00968326\n",
      "Iteration 3042, loss = 0.00967847\n",
      "Iteration 3043, loss = 0.00967344\n",
      "Iteration 3044, loss = 0.00966939\n",
      "Iteration 3045, loss = 0.00966540\n",
      "Iteration 3046, loss = 0.00966181\n",
      "Iteration 3047, loss = 0.00965672\n",
      "Iteration 3048, loss = 0.00965422\n",
      "Iteration 3049, loss = 0.00964905\n",
      "Iteration 3050, loss = 0.00964549\n",
      "Iteration 3051, loss = 0.00964103\n",
      "Iteration 3052, loss = 0.00963722\n",
      "Iteration 3053, loss = 0.00963274\n",
      "Iteration 3054, loss = 0.00962864\n",
      "Iteration 3055, loss = 0.00962455\n",
      "Iteration 3056, loss = 0.00962049\n",
      "Iteration 3057, loss = 0.00961624\n",
      "Iteration 3058, loss = 0.00961216\n",
      "Iteration 3059, loss = 0.00960795\n",
      "Iteration 3060, loss = 0.00960459\n",
      "Iteration 3061, loss = 0.00960164\n",
      "Iteration 3062, loss = 0.00959692\n",
      "Iteration 3063, loss = 0.00959244\n",
      "Iteration 3064, loss = 0.00958856\n",
      "Iteration 3065, loss = 0.00958417\n",
      "Iteration 3066, loss = 0.00958006\n",
      "Iteration 3067, loss = 0.00957604\n",
      "Iteration 3068, loss = 0.00957203\n",
      "Iteration 3069, loss = 0.00956839\n",
      "Iteration 3070, loss = 0.00956435\n",
      "Iteration 3071, loss = 0.00956024\n",
      "Iteration 3072, loss = 0.00955680\n",
      "Iteration 3073, loss = 0.00955233\n",
      "Iteration 3074, loss = 0.00954874\n",
      "Iteration 3075, loss = 0.00954416\n",
      "Iteration 3076, loss = 0.00954030\n",
      "Iteration 3077, loss = 0.00953718\n",
      "Iteration 3078, loss = 0.00953179\n",
      "Iteration 3079, loss = 0.00952761\n",
      "Iteration 3080, loss = 0.00952469\n",
      "Iteration 3081, loss = 0.00952016\n",
      "Iteration 3082, loss = 0.00951645\n",
      "Iteration 3083, loss = 0.00951331\n",
      "Iteration 3084, loss = 0.00950880\n",
      "Iteration 3085, loss = 0.00950465\n",
      "Iteration 3086, loss = 0.00950171\n",
      "Iteration 3087, loss = 0.00949715\n",
      "Iteration 3088, loss = 0.00949301\n",
      "Iteration 3089, loss = 0.00948968\n",
      "Iteration 3090, loss = 0.00948505\n",
      "Iteration 3091, loss = 0.00948144\n",
      "Iteration 3092, loss = 0.00947699\n",
      "Iteration 3093, loss = 0.00947305\n",
      "Iteration 3094, loss = 0.00946927\n",
      "Iteration 3095, loss = 0.00946520\n",
      "Iteration 3096, loss = 0.00946089\n",
      "Iteration 3097, loss = 0.00945653\n",
      "Iteration 3098, loss = 0.00945183\n",
      "Iteration 3099, loss = 0.00944758\n",
      "Iteration 3100, loss = 0.00944359\n",
      "Iteration 3101, loss = 0.00943966\n",
      "Iteration 3102, loss = 0.00943554\n",
      "Iteration 3103, loss = 0.00943101\n",
      "Iteration 3104, loss = 0.00942765\n",
      "Iteration 3105, loss = 0.00942262\n",
      "Iteration 3106, loss = 0.00941938\n",
      "Iteration 3107, loss = 0.00941484\n",
      "Iteration 3108, loss = 0.00941166\n",
      "Iteration 3109, loss = 0.00940705\n",
      "Iteration 3110, loss = 0.00940309\n",
      "Iteration 3111, loss = 0.00939998\n",
      "Iteration 3112, loss = 0.00939549\n",
      "Iteration 3113, loss = 0.00939156\n",
      "Iteration 3114, loss = 0.00938763\n",
      "Iteration 3115, loss = 0.00938317\n",
      "Iteration 3116, loss = 0.00937899\n",
      "Iteration 3117, loss = 0.00937531\n",
      "Iteration 3118, loss = 0.00937111\n",
      "Iteration 3119, loss = 0.00936771\n",
      "Iteration 3120, loss = 0.00936312\n",
      "Iteration 3121, loss = 0.00935885\n",
      "Iteration 3122, loss = 0.00935508\n",
      "Iteration 3123, loss = 0.00935109\n",
      "Iteration 3124, loss = 0.00934696\n",
      "Iteration 3125, loss = 0.00934330\n",
      "Iteration 3126, loss = 0.00933935\n",
      "Iteration 3127, loss = 0.00933508\n",
      "Iteration 3128, loss = 0.00933087\n",
      "Iteration 3129, loss = 0.00932726\n",
      "Iteration 3130, loss = 0.00932293\n",
      "Iteration 3131, loss = 0.00931885\n",
      "Iteration 3132, loss = 0.00931506\n",
      "Iteration 3133, loss = 0.00931126\n",
      "Iteration 3134, loss = 0.00930704\n",
      "Iteration 3135, loss = 0.00930349\n",
      "Iteration 3136, loss = 0.00929925\n",
      "Iteration 3137, loss = 0.00929543\n",
      "Iteration 3138, loss = 0.00929340\n",
      "Iteration 3139, loss = 0.00928807\n",
      "Iteration 3140, loss = 0.00928387\n",
      "Iteration 3141, loss = 0.00927979\n",
      "Iteration 3142, loss = 0.00927575\n",
      "Iteration 3143, loss = 0.00927156\n",
      "Iteration 3144, loss = 0.00926893\n",
      "Iteration 3145, loss = 0.00926316\n",
      "Iteration 3146, loss = 0.00925913\n",
      "Iteration 3147, loss = 0.00925489\n",
      "Iteration 3148, loss = 0.00925066\n",
      "Iteration 3149, loss = 0.00924672\n",
      "Iteration 3150, loss = 0.00924281\n",
      "Iteration 3151, loss = 0.00924028\n",
      "Iteration 3152, loss = 0.00923540\n",
      "Iteration 3153, loss = 0.00923121\n",
      "Iteration 3154, loss = 0.00922779\n",
      "Iteration 3155, loss = 0.00922382\n",
      "Iteration 3156, loss = 0.00921982\n",
      "Iteration 3157, loss = 0.00921655\n",
      "Iteration 3158, loss = 0.00921258\n",
      "Iteration 3159, loss = 0.00920851\n",
      "Iteration 3160, loss = 0.00920469\n",
      "Iteration 3161, loss = 0.00920076\n",
      "Iteration 3162, loss = 0.00919683\n",
      "Iteration 3163, loss = 0.00919238\n",
      "Iteration 3164, loss = 0.00918825\n",
      "Iteration 3165, loss = 0.00918409\n",
      "Iteration 3166, loss = 0.00918132\n",
      "Iteration 3167, loss = 0.00917627\n",
      "Iteration 3168, loss = 0.00917276\n",
      "Iteration 3169, loss = 0.00916939\n",
      "Iteration 3170, loss = 0.00916650\n",
      "Iteration 3171, loss = 0.00916082\n",
      "Iteration 3172, loss = 0.00915625\n",
      "Iteration 3173, loss = 0.00915291\n",
      "Iteration 3174, loss = 0.00914924\n",
      "Iteration 3175, loss = 0.00914559\n",
      "Iteration 3176, loss = 0.00914090\n",
      "Iteration 3177, loss = 0.00913692\n",
      "Iteration 3178, loss = 0.00913353\n",
      "Iteration 3179, loss = 0.00912934\n",
      "Iteration 3180, loss = 0.00912558\n",
      "Iteration 3181, loss = 0.00912222\n",
      "Iteration 3182, loss = 0.00911732\n",
      "Iteration 3183, loss = 0.00911397\n",
      "Iteration 3184, loss = 0.00910929\n",
      "Iteration 3185, loss = 0.00910549\n",
      "Iteration 3186, loss = 0.00910131\n",
      "Iteration 3187, loss = 0.00909786\n",
      "Iteration 3188, loss = 0.00909349\n",
      "Iteration 3189, loss = 0.00908936\n",
      "Iteration 3190, loss = 0.00908582\n",
      "Iteration 3191, loss = 0.00908142\n",
      "Iteration 3192, loss = 0.00907751\n",
      "Iteration 3193, loss = 0.00907356\n",
      "Iteration 3194, loss = 0.00907003\n",
      "Iteration 3195, loss = 0.00906604\n",
      "Iteration 3196, loss = 0.00906246\n",
      "Iteration 3197, loss = 0.00905914\n",
      "Iteration 3198, loss = 0.00905493\n",
      "Iteration 3199, loss = 0.00905097\n",
      "Iteration 3200, loss = 0.00904807\n",
      "Iteration 3201, loss = 0.00904397\n",
      "Iteration 3202, loss = 0.00903990\n",
      "Iteration 3203, loss = 0.00903629\n",
      "Iteration 3204, loss = 0.00903248\n",
      "Iteration 3205, loss = 0.00902877\n",
      "Iteration 3206, loss = 0.00902503\n",
      "Iteration 3207, loss = 0.00902139\n",
      "Iteration 3208, loss = 0.00901711\n",
      "Iteration 3209, loss = 0.00901525\n",
      "Iteration 3210, loss = 0.00901032\n",
      "Iteration 3211, loss = 0.00900647\n",
      "Iteration 3212, loss = 0.00900251\n",
      "Iteration 3213, loss = 0.00899875\n",
      "Iteration 3214, loss = 0.00899425\n",
      "Iteration 3215, loss = 0.00899044\n",
      "Iteration 3216, loss = 0.00898670\n",
      "Iteration 3217, loss = 0.00898255\n",
      "Iteration 3218, loss = 0.00897824\n",
      "Iteration 3219, loss = 0.00897496\n",
      "Iteration 3220, loss = 0.00897126\n",
      "Iteration 3221, loss = 0.00896829\n",
      "Iteration 3222, loss = 0.00896395\n",
      "Iteration 3223, loss = 0.00896089\n",
      "Iteration 3224, loss = 0.00895705\n",
      "Iteration 3225, loss = 0.00895369\n",
      "Iteration 3226, loss = 0.00895002\n",
      "Iteration 3227, loss = 0.00894616\n",
      "Iteration 3228, loss = 0.00894300\n",
      "Iteration 3229, loss = 0.00893940\n",
      "Iteration 3230, loss = 0.00893572\n",
      "Iteration 3231, loss = 0.00893184\n",
      "Iteration 3232, loss = 0.00892841\n",
      "Iteration 3233, loss = 0.00892469\n",
      "Iteration 3234, loss = 0.00892067\n",
      "Iteration 3235, loss = 0.00891756\n",
      "Iteration 3236, loss = 0.00891377\n",
      "Iteration 3237, loss = 0.00890951\n",
      "Iteration 3238, loss = 0.00890501\n",
      "Iteration 3239, loss = 0.00890215\n",
      "Iteration 3240, loss = 0.00889837\n",
      "Iteration 3241, loss = 0.00889465\n",
      "Iteration 3242, loss = 0.00889039\n",
      "Iteration 3243, loss = 0.00888666\n",
      "Iteration 3244, loss = 0.00888300\n",
      "Iteration 3245, loss = 0.00887954\n",
      "Iteration 3246, loss = 0.00887564\n",
      "Iteration 3247, loss = 0.00887193\n",
      "Iteration 3248, loss = 0.00886758\n",
      "Iteration 3249, loss = 0.00886400\n",
      "Iteration 3250, loss = 0.00886021\n",
      "Iteration 3251, loss = 0.00885653\n",
      "Iteration 3252, loss = 0.00885269\n",
      "Iteration 3253, loss = 0.00884894\n",
      "Iteration 3254, loss = 0.00884565\n",
      "Iteration 3255, loss = 0.00884215\n",
      "Iteration 3256, loss = 0.00883827\n",
      "Iteration 3257, loss = 0.00883454\n",
      "Iteration 3258, loss = 0.00883077\n",
      "Iteration 3259, loss = 0.00882783\n",
      "Iteration 3260, loss = 0.00882417\n",
      "Iteration 3261, loss = 0.00882052\n",
      "Iteration 3262, loss = 0.00881691\n",
      "Iteration 3263, loss = 0.00881302\n",
      "Iteration 3264, loss = 0.00880960\n",
      "Iteration 3265, loss = 0.00880617\n",
      "Iteration 3266, loss = 0.00880255\n",
      "Iteration 3267, loss = 0.00879904\n",
      "Iteration 3268, loss = 0.00879500\n",
      "Iteration 3269, loss = 0.00879126\n",
      "Iteration 3270, loss = 0.00878794\n",
      "Iteration 3271, loss = 0.00878447\n",
      "Iteration 3272, loss = 0.00878059\n",
      "Iteration 3273, loss = 0.00877777\n",
      "Iteration 3274, loss = 0.00877334\n",
      "Iteration 3275, loss = 0.00877002\n",
      "Iteration 3276, loss = 0.00876630\n",
      "Iteration 3277, loss = 0.00876351\n",
      "Iteration 3278, loss = 0.00876009\n",
      "Iteration 3279, loss = 0.00875621\n",
      "Iteration 3280, loss = 0.00875229\n",
      "Iteration 3281, loss = 0.00874919\n",
      "Iteration 3282, loss = 0.00874530\n",
      "Iteration 3283, loss = 0.00874165\n",
      "Iteration 3284, loss = 0.00873827\n",
      "Iteration 3285, loss = 0.00873437\n",
      "Iteration 3286, loss = 0.00873051\n",
      "Iteration 3287, loss = 0.00872683\n",
      "Iteration 3288, loss = 0.00872384\n",
      "Iteration 3289, loss = 0.00872000\n",
      "Iteration 3290, loss = 0.00871646\n",
      "Iteration 3291, loss = 0.00871240\n",
      "Iteration 3292, loss = 0.00870871\n",
      "Iteration 3293, loss = 0.00870530\n",
      "Iteration 3294, loss = 0.00870136\n",
      "Iteration 3295, loss = 0.00869844\n",
      "Iteration 3296, loss = 0.00869455\n",
      "Iteration 3297, loss = 0.00869039\n",
      "Iteration 3298, loss = 0.00868658\n",
      "Iteration 3299, loss = 0.00868307\n",
      "Iteration 3300, loss = 0.00867958\n",
      "Iteration 3301, loss = 0.00867619\n",
      "Iteration 3302, loss = 0.00867206\n",
      "Iteration 3303, loss = 0.00866870\n",
      "Iteration 3304, loss = 0.00866520\n",
      "Iteration 3305, loss = 0.00866168\n",
      "Iteration 3306, loss = 0.00865817\n",
      "Iteration 3307, loss = 0.00865429\n",
      "Iteration 3308, loss = 0.00865095\n",
      "Iteration 3309, loss = 0.00864711\n",
      "Iteration 3310, loss = 0.00864359\n",
      "Iteration 3311, loss = 0.00863988\n",
      "Iteration 3312, loss = 0.00863664\n",
      "Iteration 3313, loss = 0.00863314\n",
      "Iteration 3314, loss = 0.00862981\n",
      "Iteration 3315, loss = 0.00862637\n",
      "Iteration 3316, loss = 0.00862308\n",
      "Iteration 3317, loss = 0.00861917\n",
      "Iteration 3318, loss = 0.00861593\n",
      "Iteration 3319, loss = 0.00861238\n",
      "Iteration 3320, loss = 0.00860894\n",
      "Iteration 3321, loss = 0.00860498\n",
      "Iteration 3322, loss = 0.00860233\n",
      "Iteration 3323, loss = 0.00859836\n",
      "Iteration 3324, loss = 0.00859495\n",
      "Iteration 3325, loss = 0.00859161\n",
      "Iteration 3326, loss = 0.00858802\n",
      "Iteration 3327, loss = 0.00858513\n",
      "Iteration 3328, loss = 0.00858252\n",
      "Iteration 3329, loss = 0.00857894\n",
      "Iteration 3330, loss = 0.00857580\n",
      "Iteration 3331, loss = 0.00857258\n",
      "Iteration 3332, loss = 0.00856918\n",
      "Iteration 3333, loss = 0.00856584\n",
      "Iteration 3334, loss = 0.00856254\n",
      "Iteration 3335, loss = 0.00855927\n",
      "Iteration 3336, loss = 0.00855624\n",
      "Iteration 3337, loss = 0.00855327\n",
      "Iteration 3338, loss = 0.00855031\n",
      "Iteration 3339, loss = 0.00854849\n",
      "Iteration 3340, loss = 0.00854464\n",
      "Iteration 3341, loss = 0.00854123\n",
      "Iteration 3342, loss = 0.00853817\n",
      "Iteration 3343, loss = 0.00853486\n",
      "Iteration 3344, loss = 0.00853173\n",
      "Iteration 3345, loss = 0.00852848\n",
      "Iteration 3346, loss = 0.00852555\n",
      "Iteration 3347, loss = 0.00852171\n",
      "Iteration 3348, loss = 0.00851872\n",
      "Iteration 3349, loss = 0.00851526\n",
      "Iteration 3350, loss = 0.00851181\n",
      "Iteration 3351, loss = 0.00850817\n",
      "Iteration 3352, loss = 0.00850454\n",
      "Iteration 3353, loss = 0.00850138\n",
      "Iteration 3354, loss = 0.00849772\n",
      "Iteration 3355, loss = 0.00849421\n",
      "Iteration 3356, loss = 0.00849130\n",
      "Iteration 3357, loss = 0.00848770\n",
      "Iteration 3358, loss = 0.00848349\n",
      "Iteration 3359, loss = 0.00848014\n",
      "Iteration 3360, loss = 0.00847637\n",
      "Iteration 3361, loss = 0.00847257\n",
      "Iteration 3362, loss = 0.00846989\n",
      "Iteration 3363, loss = 0.00846571\n",
      "Iteration 3364, loss = 0.00846270\n",
      "Iteration 3365, loss = 0.00845874\n",
      "Iteration 3366, loss = 0.00845541\n",
      "Iteration 3367, loss = 0.00845215\n",
      "Iteration 3368, loss = 0.00844846\n",
      "Iteration 3369, loss = 0.00844441\n",
      "Iteration 3370, loss = 0.00844066\n",
      "Iteration 3371, loss = 0.00843740\n",
      "Iteration 3372, loss = 0.00843289\n",
      "Iteration 3373, loss = 0.00843045\n",
      "Iteration 3374, loss = 0.00842612\n",
      "Iteration 3375, loss = 0.00842258\n",
      "Iteration 3376, loss = 0.00841949\n",
      "Iteration 3377, loss = 0.00841595\n",
      "Iteration 3378, loss = 0.00841221\n",
      "Iteration 3379, loss = 0.00840857\n",
      "Iteration 3380, loss = 0.00840524\n",
      "Iteration 3381, loss = 0.00840127\n",
      "Iteration 3382, loss = 0.00839873\n",
      "Iteration 3383, loss = 0.00839580\n",
      "Iteration 3384, loss = 0.00839139\n",
      "Iteration 3385, loss = 0.00838816\n",
      "Iteration 3386, loss = 0.00838480\n",
      "Iteration 3387, loss = 0.00838165\n",
      "Iteration 3388, loss = 0.00837844\n",
      "Iteration 3389, loss = 0.00837574\n",
      "Iteration 3390, loss = 0.00837274\n",
      "Iteration 3391, loss = 0.00836919\n",
      "Iteration 3392, loss = 0.00836615\n",
      "Iteration 3393, loss = 0.00836315\n",
      "Iteration 3394, loss = 0.00835990\n",
      "Iteration 3395, loss = 0.00835674\n",
      "Iteration 3396, loss = 0.00835360\n",
      "Iteration 3397, loss = 0.00835217\n",
      "Iteration 3398, loss = 0.00834911\n",
      "Iteration 3399, loss = 0.00834495\n",
      "Iteration 3400, loss = 0.00834161\n",
      "Iteration 3401, loss = 0.00833845\n",
      "Iteration 3402, loss = 0.00833502\n",
      "Iteration 3403, loss = 0.00833181\n",
      "Iteration 3404, loss = 0.00832866\n",
      "Iteration 3405, loss = 0.00832576\n",
      "Iteration 3406, loss = 0.00832240\n",
      "Iteration 3407, loss = 0.00831883\n",
      "Iteration 3408, loss = 0.00831581\n",
      "Iteration 3409, loss = 0.00831274\n",
      "Iteration 3410, loss = 0.00830984\n",
      "Iteration 3411, loss = 0.00830692\n",
      "Iteration 3412, loss = 0.00830358\n",
      "Iteration 3413, loss = 0.00830056\n",
      "Iteration 3414, loss = 0.00829769\n",
      "Iteration 3415, loss = 0.00829499\n",
      "Iteration 3416, loss = 0.00829207\n",
      "Iteration 3417, loss = 0.00828939\n",
      "Iteration 3418, loss = 0.00828551\n",
      "Iteration 3419, loss = 0.00828221\n",
      "Iteration 3420, loss = 0.00827937\n",
      "Iteration 3421, loss = 0.00827597\n",
      "Iteration 3422, loss = 0.00827298\n",
      "Iteration 3423, loss = 0.00826990\n",
      "Iteration 3424, loss = 0.00826688\n",
      "Iteration 3425, loss = 0.00826420\n",
      "Iteration 3426, loss = 0.00826220\n",
      "Iteration 3427, loss = 0.00826016\n",
      "Iteration 3428, loss = 0.00825597\n",
      "Iteration 3429, loss = 0.00825257\n",
      "Iteration 3430, loss = 0.00825001\n",
      "Iteration 3431, loss = 0.00824685\n",
      "Iteration 3432, loss = 0.00824371\n",
      "Iteration 3433, loss = 0.00823975\n",
      "Iteration 3434, loss = 0.00823626\n",
      "Iteration 3435, loss = 0.00823216\n",
      "Iteration 3436, loss = 0.00822948\n",
      "Iteration 3437, loss = 0.00822520\n",
      "Iteration 3438, loss = 0.00822207\n",
      "Iteration 3439, loss = 0.00821823\n",
      "Iteration 3440, loss = 0.00821500\n",
      "Iteration 3441, loss = 0.00821167\n",
      "Iteration 3442, loss = 0.00820842\n",
      "Iteration 3443, loss = 0.00820531\n",
      "Iteration 3444, loss = 0.00820216\n",
      "Iteration 3445, loss = 0.00819932\n",
      "Iteration 3446, loss = 0.00819631\n",
      "Iteration 3447, loss = 0.00819312\n",
      "Iteration 3448, loss = 0.00819012\n",
      "Iteration 3449, loss = 0.00818740\n",
      "Iteration 3450, loss = 0.00818431\n",
      "Iteration 3451, loss = 0.00818167\n",
      "Iteration 3452, loss = 0.00817890\n",
      "Iteration 3453, loss = 0.00817621\n",
      "Iteration 3454, loss = 0.00817343\n",
      "Iteration 3455, loss = 0.00817048\n",
      "Iteration 3456, loss = 0.00816898\n",
      "Iteration 3457, loss = 0.00816529\n",
      "Iteration 3458, loss = 0.00816153\n",
      "Iteration 3459, loss = 0.00815833\n",
      "Iteration 3460, loss = 0.00815496\n",
      "Iteration 3461, loss = 0.00815159\n",
      "Iteration 3462, loss = 0.00814846\n",
      "Iteration 3463, loss = 0.00814561\n",
      "Iteration 3464, loss = 0.00814237\n",
      "Iteration 3465, loss = 0.00813870\n",
      "Iteration 3466, loss = 0.00813610\n",
      "Iteration 3467, loss = 0.00813245\n",
      "Iteration 3468, loss = 0.00812895\n",
      "Iteration 3469, loss = 0.00812544\n",
      "Iteration 3470, loss = 0.00812326\n",
      "Iteration 3471, loss = 0.00811895\n",
      "Iteration 3472, loss = 0.00811542\n",
      "Iteration 3473, loss = 0.00811331\n",
      "Iteration 3474, loss = 0.00810874\n",
      "Iteration 3475, loss = 0.00810565\n",
      "Iteration 3476, loss = 0.00810245\n",
      "Iteration 3477, loss = 0.00809909\n",
      "Iteration 3478, loss = 0.00809627\n",
      "Iteration 3479, loss = 0.00809318\n",
      "Iteration 3480, loss = 0.00808998\n",
      "Iteration 3481, loss = 0.00808722\n",
      "Iteration 3482, loss = 0.00808412\n",
      "Iteration 3483, loss = 0.00808165\n",
      "Iteration 3484, loss = 0.00807847\n",
      "Iteration 3485, loss = 0.00807656\n",
      "Iteration 3486, loss = 0.00807336\n",
      "Iteration 3487, loss = 0.00807021\n",
      "Iteration 3488, loss = 0.00806740\n",
      "Iteration 3489, loss = 0.00806450\n",
      "Iteration 3490, loss = 0.00806240\n",
      "Iteration 3491, loss = 0.00805971\n",
      "Iteration 3492, loss = 0.00805670\n",
      "Iteration 3493, loss = 0.00805331\n",
      "Iteration 3494, loss = 0.00805042\n",
      "Iteration 3495, loss = 0.00804721\n",
      "Iteration 3496, loss = 0.00804432\n",
      "Iteration 3497, loss = 0.00804089\n",
      "Iteration 3498, loss = 0.00803875\n",
      "Iteration 3499, loss = 0.00803511\n",
      "Iteration 3500, loss = 0.00803153\n",
      "Iteration 3501, loss = 0.00802717\n",
      "Iteration 3502, loss = 0.00802366\n",
      "Iteration 3503, loss = 0.00802088\n",
      "Iteration 3504, loss = 0.00801690\n",
      "Iteration 3505, loss = 0.00801416\n",
      "Iteration 3506, loss = 0.00800997\n",
      "Iteration 3507, loss = 0.00800636\n",
      "Iteration 3508, loss = 0.00800297\n",
      "Iteration 3509, loss = 0.00799922\n",
      "Iteration 3510, loss = 0.00799691\n",
      "Iteration 3511, loss = 0.00799291\n",
      "Iteration 3512, loss = 0.00798931\n",
      "Iteration 3513, loss = 0.00798636\n",
      "Iteration 3514, loss = 0.00798351\n",
      "Iteration 3515, loss = 0.00798015\n",
      "Iteration 3516, loss = 0.00797702\n",
      "Iteration 3517, loss = 0.00797378\n",
      "Iteration 3518, loss = 0.00797102\n",
      "Iteration 3519, loss = 0.00796793\n",
      "Iteration 3520, loss = 0.00796512\n",
      "Iteration 3521, loss = 0.00796185\n",
      "Iteration 3522, loss = 0.00795920\n",
      "Iteration 3523, loss = 0.00795612\n",
      "Iteration 3524, loss = 0.00795368\n",
      "Iteration 3525, loss = 0.00795024\n",
      "Iteration 3526, loss = 0.00794745\n",
      "Iteration 3527, loss = 0.00794463\n",
      "Iteration 3528, loss = 0.00794143\n",
      "Iteration 3529, loss = 0.00793808\n",
      "Iteration 3530, loss = 0.00793569\n",
      "Iteration 3531, loss = 0.00793165\n",
      "Iteration 3532, loss = 0.00792951\n",
      "Iteration 3533, loss = 0.00792609\n",
      "Iteration 3534, loss = 0.00792309\n",
      "Iteration 3535, loss = 0.00792034\n",
      "Iteration 3536, loss = 0.00791833\n",
      "Iteration 3537, loss = 0.00791571\n",
      "Iteration 3538, loss = 0.00791220\n",
      "Iteration 3539, loss = 0.00790850\n",
      "Iteration 3540, loss = 0.00790548\n",
      "Iteration 3541, loss = 0.00790268\n",
      "Iteration 3542, loss = 0.00789915\n",
      "Iteration 3543, loss = 0.00789592\n",
      "Iteration 3544, loss = 0.00789260\n",
      "Iteration 3545, loss = 0.00788887\n",
      "Iteration 3546, loss = 0.00788613\n",
      "Iteration 3547, loss = 0.00788254\n",
      "Iteration 3548, loss = 0.00787936\n",
      "Iteration 3549, loss = 0.00787576\n",
      "Iteration 3550, loss = 0.00787277\n",
      "Iteration 3551, loss = 0.00786926\n",
      "Iteration 3552, loss = 0.00786628\n",
      "Iteration 3553, loss = 0.00786164\n",
      "Iteration 3554, loss = 0.00785847\n",
      "Iteration 3555, loss = 0.00785486\n",
      "Iteration 3556, loss = 0.00785180\n",
      "Iteration 3557, loss = 0.00784827\n",
      "Iteration 3558, loss = 0.00784497\n",
      "Iteration 3559, loss = 0.00784194\n",
      "Iteration 3560, loss = 0.00783887\n",
      "Iteration 3561, loss = 0.00783588\n",
      "Iteration 3562, loss = 0.00783326\n",
      "Iteration 3563, loss = 0.00783006\n",
      "Iteration 3564, loss = 0.00782668\n",
      "Iteration 3565, loss = 0.00782376\n",
      "Iteration 3566, loss = 0.00782048\n",
      "Iteration 3567, loss = 0.00781753\n",
      "Iteration 3568, loss = 0.00781464\n",
      "Iteration 3569, loss = 0.00781179\n",
      "Iteration 3570, loss = 0.00780774\n",
      "Iteration 3571, loss = 0.00780471\n",
      "Iteration 3572, loss = 0.00780195\n",
      "Iteration 3573, loss = 0.00779824\n",
      "Iteration 3574, loss = 0.00779532\n",
      "Iteration 3575, loss = 0.00779216\n",
      "Iteration 3576, loss = 0.00778901\n",
      "Iteration 3577, loss = 0.00778680\n",
      "Iteration 3578, loss = 0.00778321\n",
      "Iteration 3579, loss = 0.00777989\n",
      "Iteration 3580, loss = 0.00777725\n",
      "Iteration 3581, loss = 0.00777425\n",
      "Iteration 3582, loss = 0.00777149\n",
      "Iteration 3583, loss = 0.00776845\n",
      "Iteration 3584, loss = 0.00776579\n",
      "Iteration 3585, loss = 0.00776300\n",
      "Iteration 3586, loss = 0.00776035\n",
      "Iteration 3587, loss = 0.00775790\n",
      "Iteration 3588, loss = 0.00775550\n",
      "Iteration 3589, loss = 0.00775311\n",
      "Iteration 3590, loss = 0.00775068\n",
      "Iteration 3591, loss = 0.00774777\n",
      "Iteration 3592, loss = 0.00774515\n",
      "Iteration 3593, loss = 0.00774243\n",
      "Iteration 3594, loss = 0.00773965\n",
      "Iteration 3595, loss = 0.00773687\n",
      "Iteration 3596, loss = 0.00773460\n",
      "Iteration 3597, loss = 0.00773308\n",
      "Iteration 3598, loss = 0.00773002\n",
      "Iteration 3599, loss = 0.00772720\n",
      "Iteration 3600, loss = 0.00772495\n",
      "Iteration 3601, loss = 0.00772284\n",
      "Iteration 3602, loss = 0.00772012\n",
      "Iteration 3603, loss = 0.00771774\n",
      "Iteration 3604, loss = 0.00771558\n",
      "Iteration 3605, loss = 0.00771223\n",
      "Iteration 3606, loss = 0.00770936\n",
      "Iteration 3607, loss = 0.00770626\n",
      "Iteration 3608, loss = 0.00770380\n",
      "Iteration 3609, loss = 0.00770070\n",
      "Iteration 3610, loss = 0.00769744\n",
      "Iteration 3611, loss = 0.00769483\n",
      "Iteration 3612, loss = 0.00769194\n",
      "Iteration 3613, loss = 0.00768894\n",
      "Iteration 3614, loss = 0.00768633\n",
      "Iteration 3615, loss = 0.00768341\n",
      "Iteration 3616, loss = 0.00768101\n",
      "Iteration 3617, loss = 0.00767733\n",
      "Iteration 3618, loss = 0.00767422\n",
      "Iteration 3619, loss = 0.00767095\n",
      "Iteration 3620, loss = 0.00766755\n",
      "Iteration 3621, loss = 0.00766433\n",
      "Iteration 3622, loss = 0.00766160\n",
      "Iteration 3623, loss = 0.00765779\n",
      "Iteration 3624, loss = 0.00765583\n",
      "Iteration 3625, loss = 0.00765198\n",
      "Iteration 3626, loss = 0.00764879\n",
      "Iteration 3627, loss = 0.00764637\n",
      "Iteration 3628, loss = 0.00764344\n",
      "Iteration 3629, loss = 0.00764033\n",
      "Iteration 3630, loss = 0.00763792\n",
      "Iteration 3631, loss = 0.00763493\n",
      "Iteration 3632, loss = 0.00763206\n",
      "Iteration 3633, loss = 0.00763033\n",
      "Iteration 3634, loss = 0.00762629\n",
      "Iteration 3635, loss = 0.00762345\n",
      "Iteration 3636, loss = 0.00762045\n",
      "Iteration 3637, loss = 0.00761748\n",
      "Iteration 3638, loss = 0.00761546\n",
      "Iteration 3639, loss = 0.00761197\n",
      "Iteration 3640, loss = 0.00760923\n",
      "Iteration 3641, loss = 0.00760638\n",
      "Iteration 3642, loss = 0.00760395\n",
      "Iteration 3643, loss = 0.00760100\n",
      "Iteration 3644, loss = 0.00759842\n",
      "Iteration 3645, loss = 0.00759538\n",
      "Iteration 3646, loss = 0.00759250\n",
      "Iteration 3647, loss = 0.00758972\n",
      "Iteration 3648, loss = 0.00758704\n",
      "Iteration 3649, loss = 0.00758422\n",
      "Iteration 3650, loss = 0.00758105\n",
      "Iteration 3651, loss = 0.00757811\n",
      "Iteration 3652, loss = 0.00757568\n",
      "Iteration 3653, loss = 0.00757278\n",
      "Iteration 3654, loss = 0.00756972\n",
      "Iteration 3655, loss = 0.00756560\n",
      "Iteration 3656, loss = 0.00756270\n",
      "Iteration 3657, loss = 0.00755954\n",
      "Iteration 3658, loss = 0.00755603\n",
      "Iteration 3659, loss = 0.00755338\n",
      "Iteration 3660, loss = 0.00755036\n",
      "Iteration 3661, loss = 0.00754751\n",
      "Iteration 3662, loss = 0.00754440\n",
      "Iteration 3663, loss = 0.00754192\n",
      "Iteration 3664, loss = 0.00753887\n",
      "Iteration 3665, loss = 0.00753587\n",
      "Iteration 3666, loss = 0.00753376\n",
      "Iteration 3667, loss = 0.00753050\n",
      "Iteration 3668, loss = 0.00752781\n",
      "Iteration 3669, loss = 0.00752452\n",
      "Iteration 3670, loss = 0.00752168\n",
      "Iteration 3671, loss = 0.00751901\n",
      "Iteration 3672, loss = 0.00751602\n",
      "Iteration 3673, loss = 0.00751311\n",
      "Iteration 3674, loss = 0.00751071\n",
      "Iteration 3675, loss = 0.00750801\n",
      "Iteration 3676, loss = 0.00750531\n",
      "Iteration 3677, loss = 0.00750247\n",
      "Iteration 3678, loss = 0.00750008\n",
      "Iteration 3679, loss = 0.00749695\n",
      "Iteration 3680, loss = 0.00749388\n",
      "Iteration 3681, loss = 0.00749140\n",
      "Iteration 3682, loss = 0.00748834\n",
      "Iteration 3683, loss = 0.00748565\n",
      "Iteration 3684, loss = 0.00748284\n",
      "Iteration 3685, loss = 0.00748038\n",
      "Iteration 3686, loss = 0.00747688\n",
      "Iteration 3687, loss = 0.00747411\n",
      "Iteration 3688, loss = 0.00747124\n",
      "Iteration 3689, loss = 0.00746868\n",
      "Iteration 3690, loss = 0.00746544\n",
      "Iteration 3691, loss = 0.00746321\n",
      "Iteration 3692, loss = 0.00746047\n",
      "Iteration 3693, loss = 0.00745760\n",
      "Iteration 3694, loss = 0.00745525\n",
      "Iteration 3695, loss = 0.00745347\n",
      "Iteration 3696, loss = 0.00745138\n",
      "Iteration 3697, loss = 0.00744765\n",
      "Iteration 3698, loss = 0.00744423\n",
      "Iteration 3699, loss = 0.00744181\n",
      "Iteration 3700, loss = 0.00743832\n",
      "Iteration 3701, loss = 0.00743562\n",
      "Iteration 3702, loss = 0.00743253\n",
      "Iteration 3703, loss = 0.00742956\n",
      "Iteration 3704, loss = 0.00742611\n",
      "Iteration 3705, loss = 0.00742350\n",
      "Iteration 3706, loss = 0.00742093\n",
      "Iteration 3707, loss = 0.00741768\n",
      "Iteration 3708, loss = 0.00741431\n",
      "Iteration 3709, loss = 0.00741140\n",
      "Iteration 3710, loss = 0.00740845\n",
      "Iteration 3711, loss = 0.00740629\n",
      "Iteration 3712, loss = 0.00740312\n",
      "Iteration 3713, loss = 0.00740024\n",
      "Iteration 3714, loss = 0.00739710\n",
      "Iteration 3715, loss = 0.00739423\n",
      "Iteration 3716, loss = 0.00739144\n",
      "Iteration 3717, loss = 0.00738798\n",
      "Iteration 3718, loss = 0.00738498\n",
      "Iteration 3719, loss = 0.00738307\n",
      "Iteration 3720, loss = 0.00737930\n",
      "Iteration 3721, loss = 0.00737664\n",
      "Iteration 3722, loss = 0.00737408\n",
      "Iteration 3723, loss = 0.00737124\n",
      "Iteration 3724, loss = 0.00736829\n",
      "Iteration 3725, loss = 0.00736584\n",
      "Iteration 3726, loss = 0.00736370\n",
      "Iteration 3727, loss = 0.00735979\n",
      "Iteration 3728, loss = 0.00735745\n",
      "Iteration 3729, loss = 0.00735431\n",
      "Iteration 3730, loss = 0.00735161\n",
      "Iteration 3731, loss = 0.00734855\n",
      "Iteration 3732, loss = 0.00734615\n",
      "Iteration 3733, loss = 0.00734335\n",
      "Iteration 3734, loss = 0.00734069\n",
      "Iteration 3735, loss = 0.00733784\n",
      "Iteration 3736, loss = 0.00733504\n",
      "Iteration 3737, loss = 0.00733238\n",
      "Iteration 3738, loss = 0.00732936\n",
      "Iteration 3739, loss = 0.00732635\n",
      "Iteration 3740, loss = 0.00732376\n",
      "Iteration 3741, loss = 0.00732064\n",
      "Iteration 3742, loss = 0.00731793\n",
      "Iteration 3743, loss = 0.00731568\n",
      "Iteration 3744, loss = 0.00731226\n",
      "Iteration 3745, loss = 0.00730979\n",
      "Iteration 3746, loss = 0.00730689\n",
      "Iteration 3747, loss = 0.00730412\n",
      "Iteration 3748, loss = 0.00730148\n",
      "Iteration 3749, loss = 0.00729870\n",
      "Iteration 3750, loss = 0.00729606\n",
      "Iteration 3751, loss = 0.00729341\n",
      "Iteration 3752, loss = 0.00729165\n",
      "Iteration 3753, loss = 0.00728834\n",
      "Iteration 3754, loss = 0.00728575\n",
      "Iteration 3755, loss = 0.00728348\n",
      "Iteration 3756, loss = 0.00728071\n",
      "Iteration 3757, loss = 0.00727799\n",
      "Iteration 3758, loss = 0.00727503\n",
      "Iteration 3759, loss = 0.00727269\n",
      "Iteration 3760, loss = 0.00727083\n",
      "Iteration 3761, loss = 0.00726744\n",
      "Iteration 3762, loss = 0.00726523\n",
      "Iteration 3763, loss = 0.00726234\n",
      "Iteration 3764, loss = 0.00725974\n",
      "Iteration 3765, loss = 0.00725713\n",
      "Iteration 3766, loss = 0.00725473\n",
      "Iteration 3767, loss = 0.00725212\n",
      "Iteration 3768, loss = 0.00724934\n",
      "Iteration 3769, loss = 0.00724635\n",
      "Iteration 3770, loss = 0.00724449\n",
      "Iteration 3771, loss = 0.00724184\n",
      "Iteration 3772, loss = 0.00723857\n",
      "Iteration 3773, loss = 0.00723542\n",
      "Iteration 3774, loss = 0.00723327\n",
      "Iteration 3775, loss = 0.00723064\n",
      "Iteration 3776, loss = 0.00722742\n",
      "Iteration 3777, loss = 0.00722486\n",
      "Iteration 3778, loss = 0.00722218\n",
      "Iteration 3779, loss = 0.00722026\n",
      "Iteration 3780, loss = 0.00721728\n",
      "Iteration 3781, loss = 0.00721442\n",
      "Iteration 3782, loss = 0.00721245\n",
      "Iteration 3783, loss = 0.00720927\n",
      "Iteration 3784, loss = 0.00720628\n",
      "Iteration 3785, loss = 0.00720387\n",
      "Iteration 3786, loss = 0.00720283\n",
      "Iteration 3787, loss = 0.00719864\n",
      "Iteration 3788, loss = 0.00719561\n",
      "Iteration 3789, loss = 0.00719278\n",
      "Iteration 3790, loss = 0.00719018\n",
      "Iteration 3791, loss = 0.00718736\n",
      "Iteration 3792, loss = 0.00718477\n",
      "Iteration 3793, loss = 0.00718254\n",
      "Iteration 3794, loss = 0.00717957\n",
      "Iteration 3795, loss = 0.00717701\n",
      "Iteration 3796, loss = 0.00717432\n",
      "Iteration 3797, loss = 0.00717168\n",
      "Iteration 3798, loss = 0.00716903\n",
      "Iteration 3799, loss = 0.00716677\n",
      "Iteration 3800, loss = 0.00716439\n",
      "Iteration 3801, loss = 0.00716176\n",
      "Iteration 3802, loss = 0.00715991\n",
      "Iteration 3803, loss = 0.00715704\n",
      "Iteration 3804, loss = 0.00715457\n",
      "Iteration 3805, loss = 0.00715250\n",
      "Iteration 3806, loss = 0.00715015\n",
      "Iteration 3807, loss = 0.00714690\n",
      "Iteration 3808, loss = 0.00714489\n",
      "Iteration 3809, loss = 0.00714273\n",
      "Iteration 3810, loss = 0.00713899\n",
      "Iteration 3811, loss = 0.00713725\n",
      "Iteration 3812, loss = 0.00713399\n",
      "Iteration 3813, loss = 0.00713159\n",
      "Iteration 3814, loss = 0.00712884\n",
      "Iteration 3815, loss = 0.00712589\n",
      "Iteration 3816, loss = 0.00712486\n",
      "Iteration 3817, loss = 0.00712081\n",
      "Iteration 3818, loss = 0.00711797\n",
      "Iteration 3819, loss = 0.00711518\n",
      "Iteration 3820, loss = 0.00711309\n",
      "Iteration 3821, loss = 0.00711002\n",
      "Iteration 3822, loss = 0.00710746\n",
      "Iteration 3823, loss = 0.00710479\n",
      "Iteration 3824, loss = 0.00710237\n",
      "Iteration 3825, loss = 0.00709990\n",
      "Iteration 3826, loss = 0.00709851\n",
      "Iteration 3827, loss = 0.00709562\n",
      "Iteration 3828, loss = 0.00709310\n",
      "Iteration 3829, loss = 0.00709084\n",
      "Iteration 3830, loss = 0.00708814\n",
      "Iteration 3831, loss = 0.00708571\n",
      "Iteration 3832, loss = 0.00708353\n",
      "Iteration 3833, loss = 0.00708065\n",
      "Iteration 3834, loss = 0.00707806\n",
      "Iteration 3835, loss = 0.00707547\n",
      "Iteration 3836, loss = 0.00707304\n",
      "Iteration 3837, loss = 0.00707132\n",
      "Iteration 3838, loss = 0.00706751\n",
      "Iteration 3839, loss = 0.00706495\n",
      "Iteration 3840, loss = 0.00706265\n",
      "Iteration 3841, loss = 0.00705937\n",
      "Iteration 3842, loss = 0.00705713\n",
      "Iteration 3843, loss = 0.00705383\n",
      "Iteration 3844, loss = 0.00705091\n",
      "Iteration 3845, loss = 0.00704837\n",
      "Iteration 3846, loss = 0.00704522\n",
      "Iteration 3847, loss = 0.00704307\n",
      "Iteration 3848, loss = 0.00704063\n",
      "Iteration 3849, loss = 0.00703820\n",
      "Iteration 3850, loss = 0.00703521\n",
      "Iteration 3851, loss = 0.00703340\n",
      "Iteration 3852, loss = 0.00703079\n",
      "Iteration 3853, loss = 0.00702857\n",
      "Iteration 3854, loss = 0.00702607\n",
      "Iteration 3855, loss = 0.00702375\n",
      "Iteration 3856, loss = 0.00702133\n",
      "Iteration 3857, loss = 0.00701905\n",
      "Iteration 3858, loss = 0.00701665\n",
      "Iteration 3859, loss = 0.00701421\n",
      "Iteration 3860, loss = 0.00701192\n",
      "Iteration 3861, loss = 0.00700943\n",
      "Iteration 3862, loss = 0.00700758\n",
      "Iteration 3863, loss = 0.00700468\n",
      "Iteration 3864, loss = 0.00700201\n",
      "Iteration 3865, loss = 0.00699957\n",
      "Iteration 3866, loss = 0.00699740\n",
      "Iteration 3867, loss = 0.00699438\n",
      "Iteration 3868, loss = 0.00699195\n",
      "Iteration 3869, loss = 0.00698957\n",
      "Iteration 3870, loss = 0.00698669\n",
      "Iteration 3871, loss = 0.00698414\n",
      "Iteration 3872, loss = 0.00698163\n",
      "Iteration 3873, loss = 0.00697915\n",
      "Iteration 3874, loss = 0.00697672\n",
      "Iteration 3875, loss = 0.00697410\n",
      "Iteration 3876, loss = 0.00697169\n",
      "Iteration 3877, loss = 0.00696915\n",
      "Iteration 3878, loss = 0.00696652\n",
      "Iteration 3879, loss = 0.00696489\n",
      "Iteration 3880, loss = 0.00696212\n",
      "Iteration 3881, loss = 0.00695932\n",
      "Iteration 3882, loss = 0.00695702\n",
      "Iteration 3883, loss = 0.00695440\n",
      "Iteration 3884, loss = 0.00695196\n",
      "Iteration 3885, loss = 0.00694910\n",
      "Iteration 3886, loss = 0.00694680\n",
      "Iteration 3887, loss = 0.00694429\n",
      "Iteration 3888, loss = 0.00694157\n",
      "Iteration 3889, loss = 0.00693915\n",
      "Iteration 3890, loss = 0.00693706\n",
      "Iteration 3891, loss = 0.00693425\n",
      "Iteration 3892, loss = 0.00693209\n",
      "Iteration 3893, loss = 0.00692940\n",
      "Iteration 3894, loss = 0.00692721\n",
      "Iteration 3895, loss = 0.00692427\n",
      "Iteration 3896, loss = 0.00692201\n",
      "Iteration 3897, loss = 0.00691943\n",
      "Iteration 3898, loss = 0.00691709\n",
      "Iteration 3899, loss = 0.00691446\n",
      "Iteration 3900, loss = 0.00691199\n",
      "Iteration 3901, loss = 0.00690981\n",
      "Iteration 3902, loss = 0.00690791\n",
      "Iteration 3903, loss = 0.00690485\n",
      "Iteration 3904, loss = 0.00690228\n",
      "Iteration 3905, loss = 0.00690048\n",
      "Iteration 3906, loss = 0.00689766\n",
      "Iteration 3907, loss = 0.00689618\n",
      "Iteration 3908, loss = 0.00689330\n",
      "Iteration 3909, loss = 0.00689076\n",
      "Iteration 3910, loss = 0.00688877\n",
      "Iteration 3911, loss = 0.00688668\n",
      "Iteration 3912, loss = 0.00688344\n",
      "Iteration 3913, loss = 0.00688123\n",
      "Iteration 3914, loss = 0.00687833\n",
      "Iteration 3915, loss = 0.00687565\n",
      "Iteration 3916, loss = 0.00687349\n",
      "Iteration 3917, loss = 0.00687070\n",
      "Iteration 3918, loss = 0.00686834\n",
      "Iteration 3919, loss = 0.00686592\n",
      "Iteration 3920, loss = 0.00686356\n",
      "Iteration 3921, loss = 0.00686157\n",
      "Iteration 3922, loss = 0.00685890\n",
      "Iteration 3923, loss = 0.00685678\n",
      "Iteration 3924, loss = 0.00685405\n",
      "Iteration 3925, loss = 0.00685148\n",
      "Iteration 3926, loss = 0.00684906\n",
      "Iteration 3927, loss = 0.00684654\n",
      "Iteration 3928, loss = 0.00684525\n",
      "Iteration 3929, loss = 0.00684235\n",
      "Iteration 3930, loss = 0.00683946\n",
      "Iteration 3931, loss = 0.00683752\n",
      "Iteration 3932, loss = 0.00683486\n",
      "Iteration 3933, loss = 0.00683246\n",
      "Iteration 3934, loss = 0.00683003\n",
      "Iteration 3935, loss = 0.00682784\n",
      "Iteration 3936, loss = 0.00682577\n",
      "Iteration 3937, loss = 0.00682479\n",
      "Iteration 3938, loss = 0.00682089\n",
      "Iteration 3939, loss = 0.00681854\n",
      "Iteration 3940, loss = 0.00681559\n",
      "Iteration 3941, loss = 0.00681349\n",
      "Iteration 3942, loss = 0.00681114\n",
      "Iteration 3943, loss = 0.00680858\n",
      "Iteration 3944, loss = 0.00680586\n",
      "Iteration 3945, loss = 0.00680349\n",
      "Iteration 3946, loss = 0.00680124\n",
      "Iteration 3947, loss = 0.00679910\n",
      "Iteration 3948, loss = 0.00679671\n",
      "Iteration 3949, loss = 0.00679405\n",
      "Iteration 3950, loss = 0.00679216\n",
      "Iteration 3951, loss = 0.00678958\n",
      "Iteration 3952, loss = 0.00678750\n",
      "Iteration 3953, loss = 0.00678525\n",
      "Iteration 3954, loss = 0.00678388\n",
      "Iteration 3955, loss = 0.00678118\n",
      "Iteration 3956, loss = 0.00677919\n",
      "Iteration 3957, loss = 0.00677702\n",
      "Iteration 3958, loss = 0.00677459\n",
      "Iteration 3959, loss = 0.00677237\n",
      "Iteration 3960, loss = 0.00677077\n",
      "Iteration 3961, loss = 0.00676772\n",
      "Iteration 3962, loss = 0.00676540\n",
      "Iteration 3963, loss = 0.00676278\n",
      "Iteration 3964, loss = 0.00676056\n",
      "Iteration 3965, loss = 0.00675787\n",
      "Iteration 3966, loss = 0.00675551\n",
      "Iteration 3967, loss = 0.00675292\n",
      "Iteration 3968, loss = 0.00675027\n",
      "Iteration 3969, loss = 0.00674741\n",
      "Iteration 3970, loss = 0.00674488\n",
      "Iteration 3971, loss = 0.00674348\n",
      "Iteration 3972, loss = 0.00674008\n",
      "Iteration 3973, loss = 0.00673793\n",
      "Iteration 3974, loss = 0.00673581\n",
      "Iteration 3975, loss = 0.00673276\n",
      "Iteration 3976, loss = 0.00673041\n",
      "Iteration 3977, loss = 0.00672846\n",
      "Iteration 3978, loss = 0.00672577\n",
      "Iteration 3979, loss = 0.00672327\n",
      "Iteration 3980, loss = 0.00672122\n",
      "Iteration 3981, loss = 0.00671902\n",
      "Iteration 3982, loss = 0.00671711\n",
      "Iteration 3983, loss = 0.00671477\n",
      "Iteration 3984, loss = 0.00671335\n",
      "Iteration 3985, loss = 0.00671036\n",
      "Iteration 3986, loss = 0.00670788\n",
      "Iteration 3987, loss = 0.00670567\n",
      "Iteration 3988, loss = 0.00670358\n",
      "Iteration 3989, loss = 0.00670107\n",
      "Iteration 3990, loss = 0.00669903\n",
      "Iteration 3991, loss = 0.00669643\n",
      "Iteration 3992, loss = 0.00669403\n",
      "Iteration 3993, loss = 0.00669202\n",
      "Iteration 3994, loss = 0.00668966\n",
      "Iteration 3995, loss = 0.00668732\n",
      "Iteration 3996, loss = 0.00668543\n",
      "Iteration 3997, loss = 0.00668315\n",
      "Iteration 3998, loss = 0.00668122\n",
      "Iteration 3999, loss = 0.00667935\n",
      "Iteration 4000, loss = 0.00667696\n",
      "Iteration 4001, loss = 0.00667500\n",
      "Iteration 4002, loss = 0.00667275\n",
      "Iteration 4003, loss = 0.00667060\n",
      "Iteration 4004, loss = 0.00666847\n",
      "Iteration 4005, loss = 0.00666650\n",
      "Iteration 4006, loss = 0.00666401\n",
      "Iteration 4007, loss = 0.00666182\n",
      "Iteration 4008, loss = 0.00665953\n",
      "Iteration 4009, loss = 0.00665699\n",
      "Iteration 4010, loss = 0.00665449\n",
      "Iteration 4011, loss = 0.00665184\n",
      "Iteration 4012, loss = 0.00665037\n",
      "Iteration 4013, loss = 0.00664718\n",
      "Iteration 4014, loss = 0.00664557\n",
      "Iteration 4015, loss = 0.00664318\n",
      "Iteration 4016, loss = 0.00664102\n",
      "Iteration 4017, loss = 0.00663920\n",
      "Iteration 4018, loss = 0.00663662\n",
      "Iteration 4019, loss = 0.00663415\n",
      "Iteration 4020, loss = 0.00663243\n",
      "Iteration 4021, loss = 0.00663007\n",
      "Iteration 4022, loss = 0.00662814\n",
      "Iteration 4023, loss = 0.00662590\n",
      "Iteration 4024, loss = 0.00662336\n",
      "Iteration 4025, loss = 0.00662136\n",
      "Iteration 4026, loss = 0.00661938\n",
      "Iteration 4027, loss = 0.00661691\n",
      "Iteration 4028, loss = 0.00661511\n",
      "Iteration 4029, loss = 0.00661310\n",
      "Iteration 4030, loss = 0.00661072\n",
      "Iteration 4031, loss = 0.00660873\n",
      "Iteration 4032, loss = 0.00660651\n",
      "Iteration 4033, loss = 0.00660428\n",
      "Iteration 4034, loss = 0.00660308\n",
      "Iteration 4035, loss = 0.00660018\n",
      "Iteration 4036, loss = 0.00659829\n",
      "Iteration 4037, loss = 0.00659552\n",
      "Iteration 4038, loss = 0.00659311\n",
      "Iteration 4039, loss = 0.00659114\n",
      "Iteration 4040, loss = 0.00658874\n",
      "Iteration 4041, loss = 0.00658669\n",
      "Iteration 4042, loss = 0.00658390\n",
      "Iteration 4043, loss = 0.00658175\n",
      "Iteration 4044, loss = 0.00657945\n",
      "Iteration 4045, loss = 0.00657726\n",
      "Iteration 4046, loss = 0.00657495\n",
      "Iteration 4047, loss = 0.00657268\n",
      "Iteration 4048, loss = 0.00657055\n",
      "Iteration 4049, loss = 0.00656851\n",
      "Iteration 4050, loss = 0.00656616\n",
      "Iteration 4051, loss = 0.00656397\n",
      "Iteration 4052, loss = 0.00656171\n",
      "Iteration 4053, loss = 0.00655947\n",
      "Iteration 4054, loss = 0.00655694\n",
      "Iteration 4055, loss = 0.00655494\n",
      "Iteration 4056, loss = 0.00655234\n",
      "Iteration 4057, loss = 0.00655090\n",
      "Iteration 4058, loss = 0.00654790\n",
      "Iteration 4059, loss = 0.00654548\n",
      "Iteration 4060, loss = 0.00654354\n",
      "Iteration 4061, loss = 0.00654119\n",
      "Iteration 4062, loss = 0.00653892\n",
      "Iteration 4063, loss = 0.00653667\n",
      "Iteration 4064, loss = 0.00653464\n",
      "Iteration 4065, loss = 0.00653238\n",
      "Iteration 4066, loss = 0.00653029\n",
      "Iteration 4067, loss = 0.00652824\n",
      "Iteration 4068, loss = 0.00652622\n",
      "Iteration 4069, loss = 0.00652422\n",
      "Iteration 4070, loss = 0.00652205\n",
      "Iteration 4071, loss = 0.00652005\n",
      "Iteration 4072, loss = 0.00651814\n",
      "Iteration 4073, loss = 0.00651707\n",
      "Iteration 4074, loss = 0.00651497\n",
      "Iteration 4075, loss = 0.00651242\n",
      "Iteration 4076, loss = 0.00651000\n",
      "Iteration 4077, loss = 0.00650771\n",
      "Iteration 4078, loss = 0.00650564\n",
      "Iteration 4079, loss = 0.00650332\n",
      "Iteration 4080, loss = 0.00650103\n",
      "Iteration 4081, loss = 0.00649887\n",
      "Iteration 4082, loss = 0.00649678\n",
      "Iteration 4083, loss = 0.00649393\n",
      "Iteration 4084, loss = 0.00649220\n",
      "Iteration 4085, loss = 0.00648967\n",
      "Iteration 4086, loss = 0.00648720\n",
      "Iteration 4087, loss = 0.00648507\n",
      "Iteration 4088, loss = 0.00648291\n",
      "Iteration 4089, loss = 0.00648063\n",
      "Iteration 4090, loss = 0.00647877\n",
      "Iteration 4091, loss = 0.00647626\n",
      "Iteration 4092, loss = 0.00647463\n",
      "Iteration 4093, loss = 0.00647276\n",
      "Iteration 4094, loss = 0.00647100\n",
      "Iteration 4095, loss = 0.00646887\n",
      "Iteration 4096, loss = 0.00646652\n",
      "Iteration 4097, loss = 0.00646616\n",
      "Iteration 4098, loss = 0.00646311\n",
      "Iteration 4099, loss = 0.00646091\n",
      "Iteration 4100, loss = 0.00645878\n",
      "Iteration 4101, loss = 0.00645698\n",
      "Iteration 4102, loss = 0.00645488\n",
      "Iteration 4103, loss = 0.00645273\n",
      "Iteration 4104, loss = 0.00645082\n",
      "Iteration 4105, loss = 0.00644884\n",
      "Iteration 4106, loss = 0.00644753\n",
      "Iteration 4107, loss = 0.00644459\n",
      "Iteration 4108, loss = 0.00644235\n",
      "Iteration 4109, loss = 0.00643973\n",
      "Iteration 4110, loss = 0.00643795\n",
      "Iteration 4111, loss = 0.00643504\n",
      "Iteration 4112, loss = 0.00643283\n",
      "Iteration 4113, loss = 0.00643085\n",
      "Iteration 4114, loss = 0.00642828\n",
      "Iteration 4115, loss = 0.00642629\n",
      "Iteration 4116, loss = 0.00642238\n",
      "Iteration 4117, loss = 0.00642081\n",
      "Iteration 4118, loss = 0.00641915\n",
      "Iteration 4119, loss = 0.00641530\n",
      "Iteration 4120, loss = 0.00641284\n",
      "Iteration 4121, loss = 0.00641080\n",
      "Iteration 4122, loss = 0.00640868\n",
      "Iteration 4123, loss = 0.00640750\n",
      "Iteration 4124, loss = 0.00640412\n",
      "Iteration 4125, loss = 0.00640192\n",
      "Iteration 4126, loss = 0.00639941\n",
      "Iteration 4127, loss = 0.00639731\n",
      "Iteration 4128, loss = 0.00639512\n",
      "Iteration 4129, loss = 0.00639315\n",
      "Iteration 4130, loss = 0.00639079\n",
      "Iteration 4131, loss = 0.00638899\n",
      "Iteration 4132, loss = 0.00638679\n",
      "Iteration 4133, loss = 0.00638509\n",
      "Iteration 4134, loss = 0.00638289\n",
      "Iteration 4135, loss = 0.00638083\n",
      "Iteration 4136, loss = 0.00637891\n",
      "Iteration 4137, loss = 0.00637684\n",
      "Iteration 4138, loss = 0.00637466\n",
      "Iteration 4139, loss = 0.00637249\n",
      "Iteration 4140, loss = 0.00637013\n",
      "Iteration 4141, loss = 0.00636823\n",
      "Iteration 4142, loss = 0.00636550\n",
      "Iteration 4143, loss = 0.00636324\n",
      "Iteration 4144, loss = 0.00636087\n",
      "Iteration 4145, loss = 0.00635863\n",
      "Iteration 4146, loss = 0.00635651\n",
      "Iteration 4147, loss = 0.00635388\n",
      "Iteration 4148, loss = 0.00635182\n",
      "Iteration 4149, loss = 0.00635010\n",
      "Iteration 4150, loss = 0.00634747\n",
      "Iteration 4151, loss = 0.00634620\n",
      "Iteration 4152, loss = 0.00634336\n",
      "Iteration 4153, loss = 0.00634121\n",
      "Iteration 4154, loss = 0.00633890\n",
      "Iteration 4155, loss = 0.00633695\n",
      "Iteration 4156, loss = 0.00633469\n",
      "Iteration 4157, loss = 0.00633264\n",
      "Iteration 4158, loss = 0.00633042\n",
      "Iteration 4159, loss = 0.00632845\n",
      "Iteration 4160, loss = 0.00632662\n",
      "Iteration 4161, loss = 0.00632480\n",
      "Iteration 4162, loss = 0.00632249\n",
      "Iteration 4163, loss = 0.00632063\n",
      "Iteration 4164, loss = 0.00631872\n",
      "Iteration 4165, loss = 0.00631658\n",
      "Iteration 4166, loss = 0.00631457\n",
      "Iteration 4167, loss = 0.00631292\n",
      "Iteration 4168, loss = 0.00631110\n",
      "Iteration 4169, loss = 0.00630924\n",
      "Iteration 4170, loss = 0.00630693\n",
      "Iteration 4171, loss = 0.00630498\n",
      "Iteration 4172, loss = 0.00630354\n",
      "Iteration 4173, loss = 0.00630128\n",
      "Iteration 4174, loss = 0.00629934\n",
      "Iteration 4175, loss = 0.00629689\n",
      "Iteration 4176, loss = 0.00629454\n",
      "Iteration 4177, loss = 0.00629251\n",
      "Iteration 4178, loss = 0.00629099\n",
      "Iteration 4179, loss = 0.00628794\n",
      "Iteration 4180, loss = 0.00628563\n",
      "Iteration 4181, loss = 0.00628352\n",
      "Iteration 4182, loss = 0.00628179\n",
      "Iteration 4183, loss = 0.00627955\n",
      "Iteration 4184, loss = 0.00627698\n",
      "Iteration 4185, loss = 0.00627493\n",
      "Iteration 4186, loss = 0.00627251\n",
      "Iteration 4187, loss = 0.00627040\n",
      "Iteration 4188, loss = 0.00626812\n",
      "Iteration 4189, loss = 0.00626615\n",
      "Iteration 4190, loss = 0.00626393\n",
      "Iteration 4191, loss = 0.00626200\n",
      "Iteration 4192, loss = 0.00626001\n",
      "Iteration 4193, loss = 0.00625778\n",
      "Iteration 4194, loss = 0.00625567\n",
      "Iteration 4195, loss = 0.00625387\n",
      "Iteration 4196, loss = 0.00625313\n",
      "Iteration 4197, loss = 0.00624925\n",
      "Iteration 4198, loss = 0.00624701\n",
      "Iteration 4199, loss = 0.00624467\n",
      "Iteration 4200, loss = 0.00624291\n",
      "Iteration 4201, loss = 0.00624029\n",
      "Iteration 4202, loss = 0.00623803\n",
      "Iteration 4203, loss = 0.00623632\n",
      "Iteration 4204, loss = 0.00623457\n",
      "Iteration 4205, loss = 0.00623194\n",
      "Iteration 4206, loss = 0.00622968\n",
      "Iteration 4207, loss = 0.00622770\n",
      "Iteration 4208, loss = 0.00622575\n",
      "Iteration 4209, loss = 0.00622396\n",
      "Iteration 4210, loss = 0.00622201\n",
      "Iteration 4211, loss = 0.00622063\n",
      "Iteration 4212, loss = 0.00621801\n",
      "Iteration 4213, loss = 0.00621609\n",
      "Iteration 4214, loss = 0.00621460\n",
      "Iteration 4215, loss = 0.00621189\n",
      "Iteration 4216, loss = 0.00621002\n",
      "Iteration 4217, loss = 0.00620767\n",
      "Iteration 4218, loss = 0.00620530\n",
      "Iteration 4219, loss = 0.00620324\n",
      "Iteration 4220, loss = 0.00620110\n",
      "Iteration 4221, loss = 0.00619993\n",
      "Iteration 4222, loss = 0.00619726\n",
      "Iteration 4223, loss = 0.00619519\n",
      "Iteration 4224, loss = 0.00619305\n",
      "Iteration 4225, loss = 0.00619083\n",
      "Iteration 4226, loss = 0.00618907\n",
      "Iteration 4227, loss = 0.00618926\n",
      "Iteration 4228, loss = 0.00618543\n",
      "Iteration 4229, loss = 0.00618326\n",
      "Iteration 4230, loss = 0.00618165\n",
      "Iteration 4231, loss = 0.00617969\n",
      "Iteration 4232, loss = 0.00617796\n",
      "Iteration 4233, loss = 0.00617549\n",
      "Iteration 4234, loss = 0.00617346\n",
      "Iteration 4235, loss = 0.00617145\n",
      "Iteration 4236, loss = 0.00616963\n",
      "Iteration 4237, loss = 0.00616737\n",
      "Iteration 4238, loss = 0.00616538\n",
      "Iteration 4239, loss = 0.00616418\n",
      "Iteration 4240, loss = 0.00616165\n",
      "Iteration 4241, loss = 0.00615961\n",
      "Iteration 4242, loss = 0.00615799\n",
      "Iteration 4243, loss = 0.00615547\n",
      "Iteration 4244, loss = 0.00615360\n",
      "Iteration 4245, loss = 0.00615148\n",
      "Iteration 4246, loss = 0.00614938\n",
      "Iteration 4247, loss = 0.00614723\n",
      "Iteration 4248, loss = 0.00614520\n",
      "Iteration 4249, loss = 0.00614366\n",
      "Iteration 4250, loss = 0.00614110\n",
      "Iteration 4251, loss = 0.00613907\n",
      "Iteration 4252, loss = 0.00613691\n",
      "Iteration 4253, loss = 0.00613500\n",
      "Iteration 4254, loss = 0.00613289\n",
      "Iteration 4255, loss = 0.00613081\n",
      "Iteration 4256, loss = 0.00612866\n",
      "Iteration 4257, loss = 0.00612652\n",
      "Iteration 4258, loss = 0.00612452\n",
      "Iteration 4259, loss = 0.00612266\n",
      "Iteration 4260, loss = 0.00612070\n",
      "Iteration 4261, loss = 0.00611863\n",
      "Iteration 4262, loss = 0.00611712\n",
      "Iteration 4263, loss = 0.00611517\n",
      "Iteration 4264, loss = 0.00611297\n",
      "Iteration 4265, loss = 0.00611124\n",
      "Iteration 4266, loss = 0.00610910\n",
      "Iteration 4267, loss = 0.00610711\n",
      "Iteration 4268, loss = 0.00610476\n",
      "Iteration 4269, loss = 0.00610281\n",
      "Iteration 4270, loss = 0.00610065\n",
      "Iteration 4271, loss = 0.00609848\n",
      "Iteration 4272, loss = 0.00609622\n",
      "Iteration 4273, loss = 0.00609430\n",
      "Iteration 4274, loss = 0.00609253\n",
      "Iteration 4275, loss = 0.00609026\n",
      "Iteration 4276, loss = 0.00608838\n",
      "Iteration 4277, loss = 0.00608561\n",
      "Iteration 4278, loss = 0.00608343\n",
      "Iteration 4279, loss = 0.00608136\n",
      "Iteration 4280, loss = 0.00607938\n",
      "Iteration 4281, loss = 0.00607730\n",
      "Iteration 4282, loss = 0.00607505\n",
      "Iteration 4283, loss = 0.00607299\n",
      "Iteration 4284, loss = 0.00607079\n",
      "Iteration 4285, loss = 0.00606862\n",
      "Iteration 4286, loss = 0.00606760\n",
      "Iteration 4287, loss = 0.00606474\n",
      "Iteration 4288, loss = 0.00606298\n",
      "Iteration 4289, loss = 0.00606175\n",
      "Iteration 4290, loss = 0.00605903\n",
      "Iteration 4291, loss = 0.00605709\n",
      "Iteration 4292, loss = 0.00605492\n",
      "Iteration 4293, loss = 0.00605356\n",
      "Iteration 4294, loss = 0.00605292\n",
      "Iteration 4295, loss = 0.00605019\n",
      "Iteration 4296, loss = 0.00604810\n",
      "Iteration 4297, loss = 0.00604605\n",
      "Iteration 4298, loss = 0.00604381\n",
      "Iteration 4299, loss = 0.00604219\n",
      "Iteration 4300, loss = 0.00604010\n",
      "Iteration 4301, loss = 0.00603795\n",
      "Iteration 4302, loss = 0.00603611\n",
      "Iteration 4303, loss = 0.00603406\n",
      "Iteration 4304, loss = 0.00603207\n",
      "Iteration 4305, loss = 0.00603033\n",
      "Iteration 4306, loss = 0.00602844\n",
      "Iteration 4307, loss = 0.00602686\n",
      "Iteration 4308, loss = 0.00602502\n",
      "Iteration 4309, loss = 0.00602357\n",
      "Iteration 4310, loss = 0.00602157\n",
      "Iteration 4311, loss = 0.00601970\n",
      "Iteration 4312, loss = 0.00601805\n",
      "Iteration 4313, loss = 0.00601618\n",
      "Iteration 4314, loss = 0.00601420\n",
      "Iteration 4315, loss = 0.00601230\n",
      "Iteration 4316, loss = 0.00601050\n",
      "Iteration 4317, loss = 0.00600878\n",
      "Iteration 4318, loss = 0.00600685\n",
      "Iteration 4319, loss = 0.00600500\n",
      "Iteration 4320, loss = 0.00600323\n",
      "Iteration 4321, loss = 0.00600140\n",
      "Iteration 4322, loss = 0.00599967\n",
      "Iteration 4323, loss = 0.00599791\n",
      "Iteration 4324, loss = 0.00599614\n",
      "Iteration 4325, loss = 0.00599467\n",
      "Iteration 4326, loss = 0.00599294\n",
      "Iteration 4327, loss = 0.00599057\n",
      "Iteration 4328, loss = 0.00598864\n",
      "Iteration 4329, loss = 0.00598673\n",
      "Iteration 4330, loss = 0.00598514\n",
      "Iteration 4331, loss = 0.00598287\n",
      "Iteration 4332, loss = 0.00598142\n",
      "Iteration 4333, loss = 0.00597891\n",
      "Iteration 4334, loss = 0.00597674\n",
      "Iteration 4335, loss = 0.00597485\n",
      "Iteration 4336, loss = 0.00597309\n",
      "Iteration 4337, loss = 0.00597165\n",
      "Iteration 4338, loss = 0.00596950\n",
      "Iteration 4339, loss = 0.00596754\n",
      "Iteration 4340, loss = 0.00596597\n",
      "Iteration 4341, loss = 0.00596376\n",
      "Iteration 4342, loss = 0.00596194\n",
      "Iteration 4343, loss = 0.00596018\n",
      "Iteration 4344, loss = 0.00595848\n",
      "Iteration 4345, loss = 0.00595768\n",
      "Iteration 4346, loss = 0.00595514\n",
      "Iteration 4347, loss = 0.00595319\n",
      "Iteration 4348, loss = 0.00595134\n",
      "Iteration 4349, loss = 0.00594945\n",
      "Iteration 4350, loss = 0.00594760\n",
      "Iteration 4351, loss = 0.00594553\n",
      "Iteration 4352, loss = 0.00594392\n",
      "Iteration 4353, loss = 0.00594190\n",
      "Iteration 4354, loss = 0.00593993\n",
      "Iteration 4355, loss = 0.00593832\n",
      "Iteration 4356, loss = 0.00593640\n",
      "Iteration 4357, loss = 0.00593456\n",
      "Iteration 4358, loss = 0.00593313\n",
      "Iteration 4359, loss = 0.00593083\n",
      "Iteration 4360, loss = 0.00592877\n",
      "Iteration 4361, loss = 0.00592721\n",
      "Iteration 4362, loss = 0.00592497\n",
      "Iteration 4363, loss = 0.00592289\n",
      "Iteration 4364, loss = 0.00592091\n",
      "Iteration 4365, loss = 0.00591913\n",
      "Iteration 4366, loss = 0.00591708\n",
      "Iteration 4367, loss = 0.00591515\n",
      "Iteration 4368, loss = 0.00591357\n",
      "Iteration 4369, loss = 0.00591149\n",
      "Iteration 4370, loss = 0.00590962\n",
      "Iteration 4371, loss = 0.00590743\n",
      "Iteration 4372, loss = 0.00590571\n",
      "Iteration 4373, loss = 0.00590382\n",
      "Iteration 4374, loss = 0.00590202\n",
      "Iteration 4375, loss = 0.00589972\n",
      "Iteration 4376, loss = 0.00589855\n",
      "Iteration 4377, loss = 0.00589656\n",
      "Iteration 4378, loss = 0.00589422\n",
      "Iteration 4379, loss = 0.00589255\n",
      "Iteration 4380, loss = 0.00589109\n",
      "Iteration 4381, loss = 0.00588878\n",
      "Iteration 4382, loss = 0.00588690\n",
      "Iteration 4383, loss = 0.00588525\n",
      "Iteration 4384, loss = 0.00588354\n",
      "Iteration 4385, loss = 0.00588161\n",
      "Iteration 4386, loss = 0.00587940\n",
      "Iteration 4387, loss = 0.00587753\n",
      "Iteration 4388, loss = 0.00587581\n",
      "Iteration 4389, loss = 0.00587345\n",
      "Iteration 4390, loss = 0.00587169\n",
      "Iteration 4391, loss = 0.00586969\n",
      "Iteration 4392, loss = 0.00586754\n",
      "Iteration 4393, loss = 0.00586565\n",
      "Iteration 4394, loss = 0.00586447\n",
      "Iteration 4395, loss = 0.00586177\n",
      "Iteration 4396, loss = 0.00585984\n",
      "Iteration 4397, loss = 0.00585795\n",
      "Iteration 4398, loss = 0.00585624\n",
      "Iteration 4399, loss = 0.00585423\n",
      "Iteration 4400, loss = 0.00585230\n",
      "Iteration 4401, loss = 0.00585042\n",
      "Iteration 4402, loss = 0.00584878\n",
      "Iteration 4403, loss = 0.00584728\n",
      "Iteration 4404, loss = 0.00584503\n",
      "Iteration 4405, loss = 0.00584339\n",
      "Iteration 4406, loss = 0.00584099\n",
      "Iteration 4407, loss = 0.00583914\n",
      "Iteration 4408, loss = 0.00583730\n",
      "Iteration 4409, loss = 0.00583533\n",
      "Iteration 4410, loss = 0.00583357\n",
      "Iteration 4411, loss = 0.00583189\n",
      "Iteration 4412, loss = 0.00582993\n",
      "Iteration 4413, loss = 0.00582840\n",
      "Iteration 4414, loss = 0.00582643\n",
      "Iteration 4415, loss = 0.00582471\n",
      "Iteration 4416, loss = 0.00582289\n",
      "Iteration 4417, loss = 0.00582127\n",
      "Iteration 4418, loss = 0.00581966\n",
      "Iteration 4419, loss = 0.00581815\n",
      "Iteration 4420, loss = 0.00581610\n",
      "Iteration 4421, loss = 0.00581439\n",
      "Iteration 4422, loss = 0.00581300\n",
      "Iteration 4423, loss = 0.00581094\n",
      "Iteration 4424, loss = 0.00580905\n",
      "Iteration 4425, loss = 0.00580782\n",
      "Iteration 4426, loss = 0.00580548\n",
      "Iteration 4427, loss = 0.00580352\n",
      "Iteration 4428, loss = 0.00580177\n",
      "Iteration 4429, loss = 0.00579964\n",
      "Iteration 4430, loss = 0.00579791\n",
      "Iteration 4431, loss = 0.00579626\n",
      "Iteration 4432, loss = 0.00579455\n",
      "Iteration 4433, loss = 0.00579257\n",
      "Iteration 4434, loss = 0.00579086\n",
      "Iteration 4435, loss = 0.00578899\n",
      "Iteration 4436, loss = 0.00578734\n",
      "Iteration 4437, loss = 0.00578614\n",
      "Iteration 4438, loss = 0.00578395\n",
      "Iteration 4439, loss = 0.00578178\n",
      "Iteration 4440, loss = 0.00577981\n",
      "Iteration 4441, loss = 0.00577819\n",
      "Iteration 4442, loss = 0.00577592\n",
      "Iteration 4443, loss = 0.00577406\n",
      "Iteration 4444, loss = 0.00577204\n",
      "Iteration 4445, loss = 0.00577027\n",
      "Iteration 4446, loss = 0.00576884\n",
      "Iteration 4447, loss = 0.00576648\n",
      "Iteration 4448, loss = 0.00576502\n",
      "Iteration 4449, loss = 0.00576291\n",
      "Iteration 4450, loss = 0.00576098\n",
      "Iteration 4451, loss = 0.00575936\n",
      "Iteration 4452, loss = 0.00575736\n",
      "Iteration 4453, loss = 0.00575589\n",
      "Iteration 4454, loss = 0.00575363\n",
      "Iteration 4455, loss = 0.00575207\n",
      "Iteration 4456, loss = 0.00574998\n",
      "Iteration 4457, loss = 0.00574815\n",
      "Iteration 4458, loss = 0.00574622\n",
      "Iteration 4459, loss = 0.00574541\n",
      "Iteration 4460, loss = 0.00574238\n",
      "Iteration 4461, loss = 0.00574067\n",
      "Iteration 4462, loss = 0.00573845\n",
      "Iteration 4463, loss = 0.00573780\n",
      "Iteration 4464, loss = 0.00573498\n",
      "Iteration 4465, loss = 0.00573388\n",
      "Iteration 4466, loss = 0.00573164\n",
      "Iteration 4467, loss = 0.00573025\n",
      "Iteration 4468, loss = 0.00572815\n",
      "Iteration 4469, loss = 0.00572638\n",
      "Iteration 4470, loss = 0.00572476\n",
      "Iteration 4471, loss = 0.00572303\n",
      "Iteration 4472, loss = 0.00572118\n",
      "Iteration 4473, loss = 0.00571949\n",
      "Iteration 4474, loss = 0.00571777\n",
      "Iteration 4475, loss = 0.00571617\n",
      "Iteration 4476, loss = 0.00571467\n",
      "Iteration 4477, loss = 0.00571286\n",
      "Iteration 4478, loss = 0.00571118\n",
      "Iteration 4479, loss = 0.00570976\n",
      "Iteration 4480, loss = 0.00570845\n",
      "Iteration 4481, loss = 0.00570676\n",
      "Iteration 4482, loss = 0.00570506\n",
      "Iteration 4483, loss = 0.00570336\n",
      "Iteration 4484, loss = 0.00570167\n",
      "Iteration 4485, loss = 0.00570021\n",
      "Iteration 4486, loss = 0.00569827\n",
      "Iteration 4487, loss = 0.00569654\n",
      "Iteration 4488, loss = 0.00569496\n",
      "Iteration 4489, loss = 0.00569325\n",
      "Iteration 4490, loss = 0.00569151\n",
      "Iteration 4491, loss = 0.00568966\n",
      "Iteration 4492, loss = 0.00568806\n",
      "Iteration 4493, loss = 0.00568623\n",
      "Iteration 4494, loss = 0.00568460\n",
      "Iteration 4495, loss = 0.00568264\n",
      "Iteration 4496, loss = 0.00568089\n",
      "Iteration 4497, loss = 0.00567907\n",
      "Iteration 4498, loss = 0.00567812\n",
      "Iteration 4499, loss = 0.00567583\n",
      "Iteration 4500, loss = 0.00567523\n",
      "Iteration 4501, loss = 0.00567247\n",
      "Iteration 4502, loss = 0.00567067\n",
      "Iteration 4503, loss = 0.00566895\n",
      "Iteration 4504, loss = 0.00566718\n",
      "Iteration 4505, loss = 0.00566476\n",
      "Iteration 4506, loss = 0.00566326\n",
      "Iteration 4507, loss = 0.00566141\n",
      "Iteration 4508, loss = 0.00565940\n",
      "Iteration 4509, loss = 0.00565770\n",
      "Iteration 4510, loss = 0.00565611\n",
      "Iteration 4511, loss = 0.00565399\n",
      "Iteration 4512, loss = 0.00565192\n",
      "Iteration 4513, loss = 0.00564969\n",
      "Iteration 4514, loss = 0.00564912\n",
      "Iteration 4515, loss = 0.00564687\n",
      "Iteration 4516, loss = 0.00564466\n",
      "Iteration 4517, loss = 0.00564297\n",
      "Iteration 4518, loss = 0.00564135\n",
      "Iteration 4519, loss = 0.00563959\n",
      "Iteration 4520, loss = 0.00563793\n",
      "Iteration 4521, loss = 0.00563620\n",
      "Iteration 4522, loss = 0.00563486\n",
      "Iteration 4523, loss = 0.00563294\n",
      "Iteration 4524, loss = 0.00563126\n",
      "Iteration 4525, loss = 0.00562913\n",
      "Iteration 4526, loss = 0.00562795\n",
      "Iteration 4527, loss = 0.00562567\n",
      "Iteration 4528, loss = 0.00562457\n",
      "Iteration 4529, loss = 0.00562266\n",
      "Iteration 4530, loss = 0.00562065\n",
      "Iteration 4531, loss = 0.00561899\n",
      "Iteration 4532, loss = 0.00561731\n",
      "Iteration 4533, loss = 0.00561572\n",
      "Iteration 4534, loss = 0.00561399\n",
      "Iteration 4535, loss = 0.00561261\n",
      "Iteration 4536, loss = 0.00561168\n",
      "Iteration 4537, loss = 0.00560989\n",
      "Iteration 4538, loss = 0.00560807\n",
      "Iteration 4539, loss = 0.00560612\n",
      "Iteration 4540, loss = 0.00560442\n",
      "Iteration 4541, loss = 0.00560292\n",
      "Iteration 4542, loss = 0.00560105\n",
      "Iteration 4543, loss = 0.00559943\n",
      "Iteration 4544, loss = 0.00559788\n",
      "Iteration 4545, loss = 0.00559622\n",
      "Iteration 4546, loss = 0.00559459\n",
      "Iteration 4547, loss = 0.00559288\n",
      "Iteration 4548, loss = 0.00559090\n",
      "Iteration 4549, loss = 0.00558950\n",
      "Iteration 4550, loss = 0.00558784\n",
      "Iteration 4551, loss = 0.00558595\n",
      "Iteration 4552, loss = 0.00558408\n",
      "Iteration 4553, loss = 0.00558230\n",
      "Iteration 4554, loss = 0.00558083\n",
      "Iteration 4555, loss = 0.00557896\n",
      "Iteration 4556, loss = 0.00557731\n",
      "Iteration 4557, loss = 0.00557563\n",
      "Iteration 4558, loss = 0.00557406\n",
      "Iteration 4559, loss = 0.00557252\n",
      "Iteration 4560, loss = 0.00557086\n",
      "Iteration 4561, loss = 0.00556927\n",
      "Iteration 4562, loss = 0.00556807\n",
      "Iteration 4563, loss = 0.00556603\n",
      "Iteration 4564, loss = 0.00556451\n",
      "Iteration 4565, loss = 0.00556287\n",
      "Iteration 4566, loss = 0.00556162\n",
      "Iteration 4567, loss = 0.00555954\n",
      "Iteration 4568, loss = 0.00555813\n",
      "Iteration 4569, loss = 0.00555622\n",
      "Iteration 4570, loss = 0.00555436\n",
      "Iteration 4571, loss = 0.00555262\n",
      "Iteration 4572, loss = 0.00555096\n",
      "Iteration 4573, loss = 0.00554904\n",
      "Iteration 4574, loss = 0.00554751\n",
      "Iteration 4575, loss = 0.00554580\n",
      "Iteration 4576, loss = 0.00554435\n",
      "Iteration 4577, loss = 0.00554160\n",
      "Iteration 4578, loss = 0.00554069\n",
      "Iteration 4579, loss = 0.00553872\n",
      "Iteration 4580, loss = 0.00553631\n",
      "Iteration 4581, loss = 0.00553444\n",
      "Iteration 4582, loss = 0.00553268\n",
      "Iteration 4583, loss = 0.00553120\n",
      "Iteration 4584, loss = 0.00552969\n",
      "Iteration 4585, loss = 0.00552801\n",
      "Iteration 4586, loss = 0.00552632\n",
      "Iteration 4587, loss = 0.00552485\n",
      "Iteration 4588, loss = 0.00552326\n",
      "Iteration 4589, loss = 0.00552223\n",
      "Iteration 4590, loss = 0.00551990\n",
      "Iteration 4591, loss = 0.00551827\n",
      "Iteration 4592, loss = 0.00551656\n",
      "Iteration 4593, loss = 0.00551500\n",
      "Iteration 4594, loss = 0.00551337\n",
      "Iteration 4595, loss = 0.00551199\n",
      "Iteration 4596, loss = 0.00551019\n",
      "Iteration 4597, loss = 0.00550773\n",
      "Iteration 4598, loss = 0.00550633\n",
      "Iteration 4599, loss = 0.00550391\n",
      "Iteration 4600, loss = 0.00550275\n",
      "Iteration 4601, loss = 0.00550144\n",
      "Iteration 4602, loss = 0.00549951\n",
      "Iteration 4603, loss = 0.00549775\n",
      "Iteration 4604, loss = 0.00549605\n",
      "Iteration 4605, loss = 0.00549448\n",
      "Iteration 4606, loss = 0.00549320\n",
      "Iteration 4607, loss = 0.00549133\n",
      "Iteration 4608, loss = 0.00548950\n",
      "Iteration 4609, loss = 0.00548784\n",
      "Iteration 4610, loss = 0.00548630\n",
      "Iteration 4611, loss = 0.00548457\n",
      "Iteration 4612, loss = 0.00548279\n",
      "Iteration 4613, loss = 0.00548157\n",
      "Iteration 4614, loss = 0.00547960\n",
      "Iteration 4615, loss = 0.00547783\n",
      "Iteration 4616, loss = 0.00547654\n",
      "Iteration 4617, loss = 0.00547472\n",
      "Iteration 4618, loss = 0.00547306\n",
      "Iteration 4619, loss = 0.00547125\n",
      "Iteration 4620, loss = 0.00546941\n",
      "Iteration 4621, loss = 0.00546721\n",
      "Iteration 4622, loss = 0.00546541\n",
      "Iteration 4623, loss = 0.00546368\n",
      "Iteration 4624, loss = 0.00546182\n",
      "Iteration 4625, loss = 0.00546020\n",
      "Iteration 4626, loss = 0.00545849\n",
      "Iteration 4627, loss = 0.00545682\n",
      "Iteration 4628, loss = 0.00545522\n",
      "Iteration 4629, loss = 0.00545381\n",
      "Iteration 4630, loss = 0.00545235\n",
      "Iteration 4631, loss = 0.00545064\n",
      "Iteration 4632, loss = 0.00544911\n",
      "Iteration 4633, loss = 0.00544751\n",
      "Iteration 4634, loss = 0.00544597\n",
      "Iteration 4635, loss = 0.00544446\n",
      "Iteration 4636, loss = 0.00544296\n",
      "Iteration 4637, loss = 0.00544110\n",
      "Iteration 4638, loss = 0.00543962\n",
      "Iteration 4639, loss = 0.00543801\n",
      "Iteration 4640, loss = 0.00543625\n",
      "Iteration 4641, loss = 0.00543458\n",
      "Iteration 4642, loss = 0.00543300\n",
      "Iteration 4643, loss = 0.00543117\n",
      "Iteration 4644, loss = 0.00542989\n",
      "Iteration 4645, loss = 0.00542796\n",
      "Iteration 4646, loss = 0.00542626\n",
      "Iteration 4647, loss = 0.00542458\n",
      "Iteration 4648, loss = 0.00542313\n",
      "Iteration 4649, loss = 0.00542157\n",
      "Iteration 4650, loss = 0.00542014\n",
      "Iteration 4651, loss = 0.00541847\n",
      "Iteration 4652, loss = 0.00541715\n",
      "Iteration 4653, loss = 0.00541575\n",
      "Iteration 4654, loss = 0.00541438\n",
      "Iteration 4655, loss = 0.00541250\n",
      "Iteration 4656, loss = 0.00541111\n",
      "Iteration 4657, loss = 0.00540948\n",
      "Iteration 4658, loss = 0.00540773\n",
      "Iteration 4659, loss = 0.00540614\n",
      "Iteration 4660, loss = 0.00540452\n",
      "Iteration 4661, loss = 0.00540304\n",
      "Iteration 4662, loss = 0.00540122\n",
      "Iteration 4663, loss = 0.00539965\n",
      "Iteration 4664, loss = 0.00539820\n",
      "Iteration 4665, loss = 0.00539626\n",
      "Iteration 4666, loss = 0.00539498\n",
      "Iteration 4667, loss = 0.00539317\n",
      "Iteration 4668, loss = 0.00539179\n",
      "Iteration 4669, loss = 0.00539033\n",
      "Iteration 4670, loss = 0.00538829\n",
      "Iteration 4671, loss = 0.00538665\n",
      "Iteration 4672, loss = 0.00538507\n",
      "Iteration 4673, loss = 0.00538346\n",
      "Iteration 4674, loss = 0.00538175\n",
      "Iteration 4675, loss = 0.00538007\n",
      "Iteration 4676, loss = 0.00537856\n",
      "Iteration 4677, loss = 0.00537710\n",
      "Iteration 4678, loss = 0.00537538\n",
      "Iteration 4679, loss = 0.00537395\n",
      "Iteration 4680, loss = 0.00537241\n",
      "Iteration 4681, loss = 0.00537088\n",
      "Iteration 4682, loss = 0.00536933\n",
      "Iteration 4683, loss = 0.00536790\n",
      "Iteration 4684, loss = 0.00536633\n",
      "Iteration 4685, loss = 0.00536477\n",
      "Iteration 4686, loss = 0.00536332\n",
      "Iteration 4687, loss = 0.00536200\n",
      "Iteration 4688, loss = 0.00536044\n",
      "Iteration 4689, loss = 0.00535905\n",
      "Iteration 4690, loss = 0.00535756\n",
      "Iteration 4691, loss = 0.00535622\n",
      "Iteration 4692, loss = 0.00535466\n",
      "Iteration 4693, loss = 0.00535379\n",
      "Iteration 4694, loss = 0.00535155\n",
      "Iteration 4695, loss = 0.00534987\n",
      "Iteration 4696, loss = 0.00534813\n",
      "Iteration 4697, loss = 0.00534648\n",
      "Iteration 4698, loss = 0.00534519\n",
      "Iteration 4699, loss = 0.00534319\n",
      "Iteration 4700, loss = 0.00534127\n",
      "Iteration 4701, loss = 0.00533992\n",
      "Iteration 4702, loss = 0.00533826\n",
      "Iteration 4703, loss = 0.00533643\n",
      "Iteration 4704, loss = 0.00533460\n",
      "Iteration 4705, loss = 0.00533300\n",
      "Iteration 4706, loss = 0.00533138\n",
      "Iteration 4707, loss = 0.00532961\n",
      "Iteration 4708, loss = 0.00532806\n",
      "Iteration 4709, loss = 0.00532657\n",
      "Iteration 4710, loss = 0.00532482\n",
      "Iteration 4711, loss = 0.00532346\n",
      "Iteration 4712, loss = 0.00532169\n",
      "Iteration 4713, loss = 0.00532016\n",
      "Iteration 4714, loss = 0.00531872\n",
      "Iteration 4715, loss = 0.00531703\n",
      "Iteration 4716, loss = 0.00531564\n",
      "Iteration 4717, loss = 0.00531404\n",
      "Iteration 4718, loss = 0.00531263\n",
      "Iteration 4719, loss = 0.00531110\n",
      "Iteration 4720, loss = 0.00530958\n",
      "Iteration 4721, loss = 0.00530825\n",
      "Iteration 4722, loss = 0.00530681\n",
      "Iteration 4723, loss = 0.00530549\n",
      "Iteration 4724, loss = 0.00530416\n",
      "Iteration 4725, loss = 0.00530262\n",
      "Iteration 4726, loss = 0.00530096\n",
      "Iteration 4727, loss = 0.00529970\n",
      "Iteration 4728, loss = 0.00529825\n",
      "Iteration 4729, loss = 0.00529756\n",
      "Iteration 4730, loss = 0.00529555\n",
      "Iteration 4731, loss = 0.00529409\n",
      "Iteration 4732, loss = 0.00529286\n",
      "Iteration 4733, loss = 0.00529108\n",
      "Iteration 4734, loss = 0.00528950\n",
      "Iteration 4735, loss = 0.00528784\n",
      "Iteration 4736, loss = 0.00528639\n",
      "Iteration 4737, loss = 0.00528480\n",
      "Iteration 4738, loss = 0.00528319\n",
      "Iteration 4739, loss = 0.00528157\n",
      "Iteration 4740, loss = 0.00528010\n",
      "Iteration 4741, loss = 0.00527865\n",
      "Iteration 4742, loss = 0.00527649\n",
      "Iteration 4743, loss = 0.00527450\n",
      "Iteration 4744, loss = 0.00527296\n",
      "Iteration 4745, loss = 0.00527106\n",
      "Iteration 4746, loss = 0.00526955\n",
      "Iteration 4747, loss = 0.00526788\n",
      "Iteration 4748, loss = 0.00526670\n",
      "Iteration 4749, loss = 0.00526463\n",
      "Iteration 4750, loss = 0.00526318\n",
      "Iteration 4751, loss = 0.00526170\n",
      "Iteration 4752, loss = 0.00526033\n",
      "Iteration 4753, loss = 0.00525871\n",
      "Iteration 4754, loss = 0.00525722\n",
      "Iteration 4755, loss = 0.00525578\n",
      "Iteration 4756, loss = 0.00525443\n",
      "Iteration 4757, loss = 0.00525372\n",
      "Iteration 4758, loss = 0.00525136\n",
      "Iteration 4759, loss = 0.00524980\n",
      "Iteration 4760, loss = 0.00524833\n",
      "Iteration 4761, loss = 0.00524673\n",
      "Iteration 4762, loss = 0.00524507\n",
      "Iteration 4763, loss = 0.00524387\n",
      "Iteration 4764, loss = 0.00524195\n",
      "Iteration 4765, loss = 0.00524011\n",
      "Iteration 4766, loss = 0.00523883\n",
      "Iteration 4767, loss = 0.00523723\n",
      "Iteration 4768, loss = 0.00523545\n",
      "Iteration 4769, loss = 0.00523427\n",
      "Iteration 4770, loss = 0.00523251\n",
      "Iteration 4771, loss = 0.00523107\n",
      "Iteration 4772, loss = 0.00522956\n",
      "Iteration 4773, loss = 0.00522819\n",
      "Iteration 4774, loss = 0.00522659\n",
      "Iteration 4775, loss = 0.00522510\n",
      "Iteration 4776, loss = 0.00522347\n",
      "Iteration 4777, loss = 0.00522181\n",
      "Iteration 4778, loss = 0.00522049\n",
      "Iteration 4779, loss = 0.00521922\n",
      "Iteration 4780, loss = 0.00521743\n",
      "Iteration 4781, loss = 0.00521593\n",
      "Iteration 4782, loss = 0.00521429\n",
      "Iteration 4783, loss = 0.00521286\n",
      "Iteration 4784, loss = 0.00521094\n",
      "Iteration 4785, loss = 0.00520924\n",
      "Iteration 4786, loss = 0.00520787\n",
      "Iteration 4787, loss = 0.00520613\n",
      "Iteration 4788, loss = 0.00520426\n",
      "Iteration 4789, loss = 0.00520230\n",
      "Iteration 4790, loss = 0.00520186\n",
      "Iteration 4791, loss = 0.00520010\n",
      "Iteration 4792, loss = 0.00519821\n",
      "Iteration 4793, loss = 0.00519628\n",
      "Iteration 4794, loss = 0.00519513\n",
      "Iteration 4795, loss = 0.00519350\n",
      "Iteration 4796, loss = 0.00519186\n",
      "Iteration 4797, loss = 0.00519019\n",
      "Iteration 4798, loss = 0.00518869\n",
      "Iteration 4799, loss = 0.00518702\n",
      "Iteration 4800, loss = 0.00518529\n",
      "Iteration 4801, loss = 0.00518397\n",
      "Iteration 4802, loss = 0.00518239\n",
      "Iteration 4803, loss = 0.00518076\n",
      "Iteration 4804, loss = 0.00517911\n",
      "Iteration 4805, loss = 0.00517788\n",
      "Iteration 4806, loss = 0.00517613\n",
      "Iteration 4807, loss = 0.00517489\n",
      "Iteration 4808, loss = 0.00517340\n",
      "Iteration 4809, loss = 0.00517182\n",
      "Iteration 4810, loss = 0.00517047\n",
      "Iteration 4811, loss = 0.00516887\n",
      "Iteration 4812, loss = 0.00516763\n",
      "Iteration 4813, loss = 0.00516578\n",
      "Iteration 4814, loss = 0.00516445\n",
      "Iteration 4815, loss = 0.00516274\n",
      "Iteration 4816, loss = 0.00516127\n",
      "Iteration 4817, loss = 0.00515970\n",
      "Iteration 4818, loss = 0.00515802\n",
      "Iteration 4819, loss = 0.00515654\n",
      "Iteration 4820, loss = 0.00515498\n",
      "Iteration 4821, loss = 0.00515353\n",
      "Iteration 4822, loss = 0.00515214\n",
      "Iteration 4823, loss = 0.00515089\n",
      "Iteration 4824, loss = 0.00514905\n",
      "Iteration 4825, loss = 0.00514769\n",
      "Iteration 4826, loss = 0.00514641\n",
      "Iteration 4827, loss = 0.00514475\n",
      "Iteration 4828, loss = 0.00514334\n",
      "Iteration 4829, loss = 0.00514209\n",
      "Iteration 4830, loss = 0.00514096\n",
      "Iteration 4831, loss = 0.00513931\n",
      "Iteration 4832, loss = 0.00513783\n",
      "Iteration 4833, loss = 0.00513642\n",
      "Iteration 4834, loss = 0.00513509\n",
      "Iteration 4835, loss = 0.00513370\n",
      "Iteration 4836, loss = 0.00513263\n",
      "Iteration 4837, loss = 0.00513099\n",
      "Iteration 4838, loss = 0.00512950\n",
      "Iteration 4839, loss = 0.00512808\n",
      "Iteration 4840, loss = 0.00512652\n",
      "Iteration 4841, loss = 0.00512517\n",
      "Iteration 4842, loss = 0.00512378\n",
      "Iteration 4843, loss = 0.00512271\n",
      "Iteration 4844, loss = 0.00512078\n",
      "Iteration 4845, loss = 0.00511955\n",
      "Iteration 4846, loss = 0.00511780\n",
      "Iteration 4847, loss = 0.00511625\n",
      "Iteration 4848, loss = 0.00511475\n",
      "Iteration 4849, loss = 0.00511338\n",
      "Iteration 4850, loss = 0.00511196\n",
      "Iteration 4851, loss = 0.00511046\n",
      "Iteration 4852, loss = 0.00510907\n",
      "Iteration 4853, loss = 0.00510760\n",
      "Iteration 4854, loss = 0.00510629\n",
      "Iteration 4855, loss = 0.00510482\n",
      "Iteration 4856, loss = 0.00510352\n",
      "Iteration 4857, loss = 0.00510226\n",
      "Iteration 4858, loss = 0.00510056\n",
      "Iteration 4859, loss = 0.00509937\n",
      "Iteration 4860, loss = 0.00509806\n",
      "Iteration 4861, loss = 0.00509615\n",
      "Iteration 4862, loss = 0.00509478\n",
      "Iteration 4863, loss = 0.00509314\n",
      "Iteration 4864, loss = 0.00509187\n",
      "Iteration 4865, loss = 0.00509034\n",
      "Iteration 4866, loss = 0.00508876\n",
      "Iteration 4867, loss = 0.00508708\n",
      "Iteration 4868, loss = 0.00508553\n",
      "Iteration 4869, loss = 0.00508406\n",
      "Iteration 4870, loss = 0.00508238\n",
      "Iteration 4871, loss = 0.00508092\n",
      "Iteration 4872, loss = 0.00507958\n",
      "Iteration 4873, loss = 0.00507799\n",
      "Iteration 4874, loss = 0.00507646\n",
      "Iteration 4875, loss = 0.00507512\n",
      "Iteration 4876, loss = 0.00507353\n",
      "Iteration 4877, loss = 0.00507261\n",
      "Iteration 4878, loss = 0.00507079\n",
      "Iteration 4879, loss = 0.00506933\n",
      "Iteration 4880, loss = 0.00506797\n",
      "Iteration 4881, loss = 0.00506643\n",
      "Iteration 4882, loss = 0.00506545\n",
      "Iteration 4883, loss = 0.00506379\n",
      "Iteration 4884, loss = 0.00506236\n",
      "Iteration 4885, loss = 0.00506126\n",
      "Iteration 4886, loss = 0.00505958\n",
      "Iteration 4887, loss = 0.00505823\n",
      "Iteration 4888, loss = 0.00505694\n",
      "Iteration 4889, loss = 0.00505567\n",
      "Iteration 4890, loss = 0.00505423\n",
      "Iteration 4891, loss = 0.00505271\n",
      "Iteration 4892, loss = 0.00505129\n",
      "Iteration 4893, loss = 0.00505045\n",
      "Iteration 4894, loss = 0.00504899\n",
      "Iteration 4895, loss = 0.00504765\n",
      "Iteration 4896, loss = 0.00504612\n",
      "Iteration 4897, loss = 0.00504463\n",
      "Iteration 4898, loss = 0.00504336\n",
      "Iteration 4899, loss = 0.00504185\n",
      "Iteration 4900, loss = 0.00504066\n",
      "Iteration 4901, loss = 0.00503894\n",
      "Iteration 4902, loss = 0.00503760\n",
      "Iteration 4903, loss = 0.00503608\n",
      "Iteration 4904, loss = 0.00503468\n",
      "Iteration 4905, loss = 0.00503306\n",
      "Iteration 4906, loss = 0.00503168\n",
      "Iteration 4907, loss = 0.00503025\n",
      "Iteration 4908, loss = 0.00502851\n",
      "Iteration 4909, loss = 0.00502737\n",
      "Iteration 4910, loss = 0.00502577\n",
      "Iteration 4911, loss = 0.00502408\n",
      "Iteration 4912, loss = 0.00502276\n",
      "Iteration 4913, loss = 0.00502137\n",
      "Iteration 4914, loss = 0.00501996\n",
      "Iteration 4915, loss = 0.00501869\n",
      "Iteration 4916, loss = 0.00501735\n",
      "Iteration 4917, loss = 0.00501615\n",
      "Iteration 4918, loss = 0.00501458\n",
      "Iteration 4919, loss = 0.00501301\n",
      "Iteration 4920, loss = 0.00501192\n",
      "Iteration 4921, loss = 0.00501014\n",
      "Iteration 4922, loss = 0.00500879\n",
      "Iteration 4923, loss = 0.00500742\n",
      "Iteration 4924, loss = 0.00500601\n",
      "Iteration 4925, loss = 0.00500471\n",
      "Iteration 4926, loss = 0.00500414\n",
      "Iteration 4927, loss = 0.00500200\n",
      "Iteration 4928, loss = 0.00500040\n",
      "Iteration 4929, loss = 0.00499890\n",
      "Iteration 4930, loss = 0.00499765\n",
      "Iteration 4931, loss = 0.00499586\n",
      "Iteration 4932, loss = 0.00499456\n",
      "Iteration 4933, loss = 0.00499314\n",
      "Iteration 4934, loss = 0.00499158\n",
      "Iteration 4935, loss = 0.00499029\n",
      "Iteration 4936, loss = 0.00498896\n",
      "Iteration 4937, loss = 0.00498762\n",
      "Iteration 4938, loss = 0.00498621\n",
      "Iteration 4939, loss = 0.00498490\n",
      "Iteration 4940, loss = 0.00498363\n",
      "Iteration 4941, loss = 0.00498210\n",
      "Iteration 4942, loss = 0.00498071\n",
      "Iteration 4943, loss = 0.00497927\n",
      "Iteration 4944, loss = 0.00497834\n",
      "Iteration 4945, loss = 0.00497648\n",
      "Iteration 4946, loss = 0.00497512\n",
      "Iteration 4947, loss = 0.00497347\n",
      "Iteration 4948, loss = 0.00497230\n",
      "Iteration 4949, loss = 0.00497077\n",
      "Iteration 4950, loss = 0.00496973\n",
      "Iteration 4951, loss = 0.00496797\n",
      "Iteration 4952, loss = 0.00496665\n",
      "Iteration 4953, loss = 0.00496539\n",
      "Iteration 4954, loss = 0.00496399\n",
      "Iteration 4955, loss = 0.00496293\n",
      "Iteration 4956, loss = 0.00496154\n",
      "Iteration 4957, loss = 0.00496030\n",
      "Iteration 4958, loss = 0.00495917\n",
      "Iteration 4959, loss = 0.00495784\n",
      "Iteration 4960, loss = 0.00495661\n",
      "Iteration 4961, loss = 0.00495529\n",
      "Iteration 4962, loss = 0.00495394\n",
      "Iteration 4963, loss = 0.00495282\n",
      "Iteration 4964, loss = 0.00495154\n",
      "Iteration 4965, loss = 0.00495016\n",
      "Iteration 4966, loss = 0.00494874\n",
      "Iteration 4967, loss = 0.00494748\n",
      "Iteration 4968, loss = 0.00494637\n",
      "Iteration 4969, loss = 0.00494512\n",
      "Iteration 4970, loss = 0.00494384\n",
      "Iteration 4971, loss = 0.00494258\n",
      "Iteration 4972, loss = 0.00494080\n",
      "Iteration 4973, loss = 0.00493938\n",
      "Iteration 4974, loss = 0.00493783\n",
      "Iteration 4975, loss = 0.00493664\n",
      "Iteration 4976, loss = 0.00493501\n",
      "Iteration 4977, loss = 0.00493379\n",
      "Iteration 4978, loss = 0.00493239\n",
      "Iteration 4979, loss = 0.00493073\n",
      "Iteration 4980, loss = 0.00492963\n",
      "Iteration 4981, loss = 0.00492793\n",
      "Iteration 4982, loss = 0.00492632\n",
      "Iteration 4983, loss = 0.00492495\n",
      "Iteration 4984, loss = 0.00492424\n",
      "Iteration 4985, loss = 0.00492227\n",
      "Iteration 4986, loss = 0.00492071\n",
      "Iteration 4987, loss = 0.00491933\n",
      "Iteration 4988, loss = 0.00491777\n",
      "Iteration 4989, loss = 0.00491642\n",
      "Iteration 4990, loss = 0.00491528\n",
      "Iteration 4991, loss = 0.00491352\n",
      "Iteration 4992, loss = 0.00491208\n",
      "Iteration 4993, loss = 0.00491059\n",
      "Iteration 4994, loss = 0.00490938\n",
      "Iteration 4995, loss = 0.00490779\n",
      "Iteration 4996, loss = 0.00490630\n",
      "Iteration 4997, loss = 0.00490516\n",
      "Iteration 4998, loss = 0.00490322\n",
      "Iteration 4999, loss = 0.00490160\n",
      "Iteration 5000, loss = 0.00490048\n",
      "Iteration 5001, loss = 0.00489881\n",
      "Iteration 5002, loss = 0.00489761\n",
      "Iteration 5003, loss = 0.00489601\n",
      "Iteration 5004, loss = 0.00489446\n",
      "Iteration 5005, loss = 0.00489319\n",
      "Iteration 5006, loss = 0.00489179\n",
      "Iteration 5007, loss = 0.00489044\n",
      "Iteration 5008, loss = 0.00488907\n",
      "Iteration 5009, loss = 0.00488775\n",
      "Iteration 5010, loss = 0.00488672\n",
      "Iteration 5011, loss = 0.00488495\n",
      "Iteration 5012, loss = 0.00488360\n",
      "Iteration 5013, loss = 0.00488228\n",
      "Iteration 5014, loss = 0.00488083\n",
      "Iteration 5015, loss = 0.00487936\n",
      "Iteration 5016, loss = 0.00487794\n",
      "Iteration 5017, loss = 0.00487664\n",
      "Iteration 5018, loss = 0.00487513\n",
      "Iteration 5019, loss = 0.00487392\n",
      "Iteration 5020, loss = 0.00487236\n",
      "Iteration 5021, loss = 0.00487096\n",
      "Iteration 5022, loss = 0.00486950\n",
      "Iteration 5023, loss = 0.00486813\n",
      "Iteration 5024, loss = 0.00486663\n",
      "Iteration 5025, loss = 0.00486535\n",
      "Iteration 5026, loss = 0.00486384\n",
      "Iteration 5027, loss = 0.00486268\n",
      "Iteration 5028, loss = 0.00486100\n",
      "Iteration 5029, loss = 0.00485965\n",
      "Iteration 5030, loss = 0.00485829\n",
      "Iteration 5031, loss = 0.00485692\n",
      "Iteration 5032, loss = 0.00485553\n",
      "Iteration 5033, loss = 0.00485444\n",
      "Iteration 5034, loss = 0.00485287\n",
      "Iteration 5035, loss = 0.00485155\n",
      "Iteration 5036, loss = 0.00485020\n",
      "Iteration 5037, loss = 0.00484890\n",
      "Iteration 5038, loss = 0.00484777\n",
      "Iteration 5039, loss = 0.00484665\n",
      "Iteration 5040, loss = 0.00484522\n",
      "Iteration 5041, loss = 0.00484384\n",
      "Iteration 5042, loss = 0.00484235\n",
      "Iteration 5043, loss = 0.00484118\n",
      "Iteration 5044, loss = 0.00483992\n",
      "Iteration 5045, loss = 0.00483851\n",
      "Iteration 5046, loss = 0.00483723\n",
      "Iteration 5047, loss = 0.00483611\n",
      "Iteration 5048, loss = 0.00483459\n",
      "Iteration 5049, loss = 0.00483335\n",
      "Iteration 5050, loss = 0.00483200\n",
      "Iteration 5051, loss = 0.00483081\n",
      "Iteration 5052, loss = 0.00482930\n",
      "Iteration 5053, loss = 0.00482799\n",
      "Iteration 5054, loss = 0.00482672\n",
      "Iteration 5055, loss = 0.00482549\n",
      "Iteration 5056, loss = 0.00482472\n",
      "Iteration 5057, loss = 0.00482291\n",
      "Iteration 5058, loss = 0.00482152\n",
      "Iteration 5059, loss = 0.00482020\n",
      "Iteration 5060, loss = 0.00481898\n",
      "Iteration 5061, loss = 0.00481762\n",
      "Iteration 5062, loss = 0.00481649\n",
      "Iteration 5063, loss = 0.00481516\n",
      "Iteration 5064, loss = 0.00481406\n",
      "Iteration 5065, loss = 0.00481268\n",
      "Iteration 5066, loss = 0.00481125\n",
      "Iteration 5067, loss = 0.00481025\n",
      "Iteration 5068, loss = 0.00480864\n",
      "Iteration 5069, loss = 0.00480726\n",
      "Iteration 5070, loss = 0.00480591\n",
      "Iteration 5071, loss = 0.00480482\n",
      "Iteration 5072, loss = 0.00480348\n",
      "Iteration 5073, loss = 0.00480241\n",
      "Iteration 5074, loss = 0.00480108\n",
      "Iteration 5075, loss = 0.00479962\n",
      "Iteration 5076, loss = 0.00479829\n",
      "Iteration 5077, loss = 0.00479708\n",
      "Iteration 5078, loss = 0.00479619\n",
      "Iteration 5079, loss = 0.00479446\n",
      "Iteration 5080, loss = 0.00479315\n",
      "Iteration 5081, loss = 0.00479196\n",
      "Iteration 5082, loss = 0.00479071\n",
      "Iteration 5083, loss = 0.00478934\n",
      "Iteration 5084, loss = 0.00478796\n",
      "Iteration 5085, loss = 0.00478706\n",
      "Iteration 5086, loss = 0.00478527\n",
      "Iteration 5087, loss = 0.00478382\n",
      "Iteration 5088, loss = 0.00478321\n",
      "Iteration 5089, loss = 0.00478150\n",
      "Iteration 5090, loss = 0.00478018\n",
      "Iteration 5091, loss = 0.00477907\n",
      "Iteration 5092, loss = 0.00477775\n",
      "Iteration 5093, loss = 0.00477657\n",
      "Iteration 5094, loss = 0.00477534\n",
      "Iteration 5095, loss = 0.00477428\n",
      "Iteration 5096, loss = 0.00477308\n",
      "Iteration 5097, loss = 0.00477184\n",
      "Iteration 5098, loss = 0.00477053\n",
      "Iteration 5099, loss = 0.00476886\n",
      "Iteration 5100, loss = 0.00476800\n",
      "Iteration 5101, loss = 0.00476675\n",
      "Iteration 5102, loss = 0.00476510\n",
      "Iteration 5103, loss = 0.00476362\n",
      "Iteration 5104, loss = 0.00476228\n",
      "Iteration 5105, loss = 0.00476096\n",
      "Iteration 5106, loss = 0.00475950\n",
      "Iteration 5107, loss = 0.00475840\n",
      "Iteration 5108, loss = 0.00475687\n",
      "Iteration 5109, loss = 0.00475627\n",
      "Iteration 5110, loss = 0.00475437\n",
      "Iteration 5111, loss = 0.00475281\n",
      "Iteration 5112, loss = 0.00475142\n",
      "Iteration 5113, loss = 0.00475005\n",
      "Iteration 5114, loss = 0.00474866\n",
      "Iteration 5115, loss = 0.00474727\n",
      "Iteration 5116, loss = 0.00474579\n",
      "Iteration 5117, loss = 0.00474483\n",
      "Iteration 5118, loss = 0.00474393\n",
      "Iteration 5119, loss = 0.00474232\n",
      "Iteration 5120, loss = 0.00474086\n",
      "Iteration 5121, loss = 0.00473960\n",
      "Iteration 5122, loss = 0.00473837\n",
      "Iteration 5123, loss = 0.00473718\n",
      "Iteration 5124, loss = 0.00473568\n",
      "Iteration 5125, loss = 0.00473466\n",
      "Iteration 5126, loss = 0.00473306\n",
      "Iteration 5127, loss = 0.00473197\n",
      "Iteration 5128, loss = 0.00473083\n",
      "Iteration 5129, loss = 0.00472951\n",
      "Iteration 5130, loss = 0.00472819\n",
      "Iteration 5131, loss = 0.00472686\n",
      "Iteration 5132, loss = 0.00472577\n",
      "Iteration 5133, loss = 0.00472488\n",
      "Iteration 5134, loss = 0.00472319\n",
      "Iteration 5135, loss = 0.00472203\n",
      "Iteration 5136, loss = 0.00472035\n",
      "Iteration 5137, loss = 0.00471919\n",
      "Iteration 5138, loss = 0.00471781\n",
      "Iteration 5139, loss = 0.00471652\n",
      "Iteration 5140, loss = 0.00471504\n",
      "Iteration 5141, loss = 0.00471384\n",
      "Iteration 5142, loss = 0.00471266\n",
      "Iteration 5143, loss = 0.00471128\n",
      "Iteration 5144, loss = 0.00470964\n",
      "Iteration 5145, loss = 0.00470831\n",
      "Iteration 5146, loss = 0.00470685\n",
      "Iteration 5147, loss = 0.00470585\n",
      "Iteration 5148, loss = 0.00470443\n",
      "Iteration 5149, loss = 0.00470306\n",
      "Iteration 5150, loss = 0.00470181\n",
      "Iteration 5151, loss = 0.00470075\n",
      "Iteration 5152, loss = 0.00469922\n",
      "Iteration 5153, loss = 0.00469803\n",
      "Iteration 5154, loss = 0.00469665\n",
      "Iteration 5155, loss = 0.00469520\n",
      "Iteration 5156, loss = 0.00469386\n",
      "Iteration 5157, loss = 0.00469247\n",
      "Iteration 5158, loss = 0.00469160\n",
      "Iteration 5159, loss = 0.00469039\n",
      "Iteration 5160, loss = 0.00468856\n",
      "Iteration 5161, loss = 0.00468728\n",
      "Iteration 5162, loss = 0.00468589\n",
      "Iteration 5163, loss = 0.00468445\n",
      "Iteration 5164, loss = 0.00468320\n",
      "Iteration 5165, loss = 0.00468183\n",
      "Iteration 5166, loss = 0.00468061\n",
      "Iteration 5167, loss = 0.00467931\n",
      "Iteration 5168, loss = 0.00467807\n",
      "Iteration 5169, loss = 0.00467694\n",
      "Iteration 5170, loss = 0.00467584\n",
      "Iteration 5171, loss = 0.00467440\n",
      "Iteration 5172, loss = 0.00467328\n",
      "Iteration 5173, loss = 0.00467211\n",
      "Iteration 5174, loss = 0.00467095\n",
      "Iteration 5175, loss = 0.00466968\n",
      "Iteration 5176, loss = 0.00466890\n",
      "Iteration 5177, loss = 0.00466749\n",
      "Iteration 5178, loss = 0.00466609\n",
      "Iteration 5179, loss = 0.00466481\n",
      "Iteration 5180, loss = 0.00466356\n",
      "Iteration 5181, loss = 0.00466218\n",
      "Iteration 5182, loss = 0.00466098\n",
      "Iteration 5183, loss = 0.00466001\n",
      "Iteration 5184, loss = 0.00465858\n",
      "Iteration 5185, loss = 0.00465716\n",
      "Iteration 5186, loss = 0.00465597\n",
      "Iteration 5187, loss = 0.00465462\n",
      "Iteration 5188, loss = 0.00465331\n",
      "Iteration 5189, loss = 0.00465219\n",
      "Iteration 5190, loss = 0.00465104\n",
      "Iteration 5191, loss = 0.00464969\n",
      "Iteration 5192, loss = 0.00464848\n",
      "Iteration 5193, loss = 0.00464711\n",
      "Iteration 5194, loss = 0.00464573\n",
      "Iteration 5195, loss = 0.00464470\n",
      "Iteration 5196, loss = 0.00464348\n",
      "Iteration 5197, loss = 0.00464254\n",
      "Iteration 5198, loss = 0.00464098\n",
      "Iteration 5199, loss = 0.00463957\n",
      "Iteration 5200, loss = 0.00463846\n",
      "Iteration 5201, loss = 0.00463680\n",
      "Iteration 5202, loss = 0.00463569\n",
      "Iteration 5203, loss = 0.00463416\n",
      "Iteration 5204, loss = 0.00463323\n",
      "Iteration 5205, loss = 0.00463187\n",
      "Iteration 5206, loss = 0.00463023\n",
      "Iteration 5207, loss = 0.00462883\n",
      "Iteration 5208, loss = 0.00462741\n",
      "Iteration 5209, loss = 0.00462659\n",
      "Iteration 5210, loss = 0.00462480\n",
      "Iteration 5211, loss = 0.00462354\n",
      "Iteration 5212, loss = 0.00462221\n",
      "Iteration 5213, loss = 0.00462088\n",
      "Iteration 5214, loss = 0.00461959\n",
      "Iteration 5215, loss = 0.00461846\n",
      "Iteration 5216, loss = 0.00461742\n",
      "Iteration 5217, loss = 0.00461610\n",
      "Iteration 5218, loss = 0.00461520\n",
      "Iteration 5219, loss = 0.00461390\n",
      "Iteration 5220, loss = 0.00461268\n",
      "Iteration 5221, loss = 0.00461155\n",
      "Iteration 5222, loss = 0.00461093\n",
      "Iteration 5223, loss = 0.00460904\n",
      "Iteration 5224, loss = 0.00460811\n",
      "Iteration 5225, loss = 0.00460681\n",
      "Iteration 5226, loss = 0.00460542\n",
      "Iteration 5227, loss = 0.00460456\n",
      "Iteration 5228, loss = 0.00460310\n",
      "Iteration 5229, loss = 0.00460188\n",
      "Iteration 5230, loss = 0.00460069\n",
      "Iteration 5231, loss = 0.00459952\n",
      "Iteration 5232, loss = 0.00459818\n",
      "Iteration 5233, loss = 0.00459687\n",
      "Iteration 5234, loss = 0.00459588\n",
      "Iteration 5235, loss = 0.00459456\n",
      "Iteration 5236, loss = 0.00459251\n",
      "Iteration 5237, loss = 0.00459133\n",
      "Iteration 5238, loss = 0.00459054\n",
      "Iteration 5239, loss = 0.00458874\n",
      "Iteration 5240, loss = 0.00458758\n",
      "Iteration 5241, loss = 0.00458681\n",
      "Iteration 5242, loss = 0.00458574\n",
      "Iteration 5243, loss = 0.00458414\n",
      "Iteration 5244, loss = 0.00458285\n",
      "Iteration 5245, loss = 0.00458177\n",
      "Iteration 5246, loss = 0.00458047\n",
      "Iteration 5247, loss = 0.00457948\n",
      "Iteration 5248, loss = 0.00457872\n",
      "Iteration 5249, loss = 0.00457715\n",
      "Iteration 5250, loss = 0.00457613\n",
      "Iteration 5251, loss = 0.00457499\n",
      "Iteration 5252, loss = 0.00457355\n",
      "Iteration 5253, loss = 0.00457249\n",
      "Iteration 5254, loss = 0.00457128\n",
      "Iteration 5255, loss = 0.00457006\n",
      "Iteration 5256, loss = 0.00456899\n",
      "Iteration 5257, loss = 0.00456771\n",
      "Iteration 5258, loss = 0.00456643\n",
      "Iteration 5259, loss = 0.00456517\n",
      "Iteration 5260, loss = 0.00456403\n",
      "Iteration 5261, loss = 0.00456273\n",
      "Iteration 5262, loss = 0.00456134\n",
      "Iteration 5263, loss = 0.00456005\n",
      "Iteration 5264, loss = 0.00455891\n",
      "Iteration 5265, loss = 0.00455755\n",
      "Iteration 5266, loss = 0.00455628\n",
      "Iteration 5267, loss = 0.00455518\n",
      "Iteration 5268, loss = 0.00455384\n",
      "Iteration 5269, loss = 0.00455236\n",
      "Iteration 5270, loss = 0.00455162\n",
      "Iteration 5271, loss = 0.00455051\n",
      "Iteration 5272, loss = 0.00454891\n",
      "Iteration 5273, loss = 0.00454762\n",
      "Iteration 5274, loss = 0.00454638\n",
      "Iteration 5275, loss = 0.00454531\n",
      "Iteration 5276, loss = 0.00454427\n",
      "Iteration 5277, loss = 0.00454305\n",
      "Iteration 5278, loss = 0.00454194\n",
      "Iteration 5279, loss = 0.00454033\n",
      "Iteration 5280, loss = 0.00453921\n",
      "Iteration 5281, loss = 0.00453808\n",
      "Iteration 5282, loss = 0.00453676\n",
      "Iteration 5283, loss = 0.00453560\n",
      "Iteration 5284, loss = 0.00453431\n",
      "Iteration 5285, loss = 0.00453315\n",
      "Iteration 5286, loss = 0.00453201\n",
      "Iteration 5287, loss = 0.00453110\n",
      "Iteration 5288, loss = 0.00452987\n",
      "Iteration 5289, loss = 0.00452853\n",
      "Iteration 5290, loss = 0.00452733\n",
      "Iteration 5291, loss = 0.00452633\n",
      "Iteration 5292, loss = 0.00452493\n",
      "Iteration 5293, loss = 0.00452382\n",
      "Iteration 5294, loss = 0.00452259\n",
      "Iteration 5295, loss = 0.00452172\n",
      "Iteration 5296, loss = 0.00452026\n",
      "Iteration 5297, loss = 0.00451866\n",
      "Iteration 5298, loss = 0.00451815\n",
      "Iteration 5299, loss = 0.00451653\n",
      "Iteration 5300, loss = 0.00451551\n",
      "Iteration 5301, loss = 0.00451417\n",
      "Iteration 5302, loss = 0.00451269\n",
      "Iteration 5303, loss = 0.00451155\n",
      "Iteration 5304, loss = 0.00451022\n",
      "Iteration 5305, loss = 0.00450912\n",
      "Iteration 5306, loss = 0.00450801\n",
      "Iteration 5307, loss = 0.00450659\n",
      "Iteration 5308, loss = 0.00450516\n",
      "Iteration 5309, loss = 0.00450396\n",
      "Iteration 5310, loss = 0.00450269\n",
      "Iteration 5311, loss = 0.00450151\n",
      "Iteration 5312, loss = 0.00450003\n",
      "Iteration 5313, loss = 0.00449881\n",
      "Iteration 5314, loss = 0.00449777\n",
      "Iteration 5315, loss = 0.00449642\n",
      "Iteration 5316, loss = 0.00449521\n",
      "Iteration 5317, loss = 0.00449421\n",
      "Iteration 5318, loss = 0.00449342\n",
      "Iteration 5319, loss = 0.00449164\n",
      "Iteration 5320, loss = 0.00449057\n",
      "Iteration 5321, loss = 0.00448938\n",
      "Iteration 5322, loss = 0.00448815\n",
      "Iteration 5323, loss = 0.00448712\n",
      "Iteration 5324, loss = 0.00448596\n",
      "Iteration 5325, loss = 0.00448486\n",
      "Iteration 5326, loss = 0.00448403\n",
      "Iteration 5327, loss = 0.00448253\n",
      "Iteration 5328, loss = 0.00448155\n",
      "Iteration 5329, loss = 0.00448007\n",
      "Iteration 5330, loss = 0.00447899\n",
      "Iteration 5331, loss = 0.00447778\n",
      "Iteration 5332, loss = 0.00447661\n",
      "Iteration 5333, loss = 0.00447554\n",
      "Iteration 5334, loss = 0.00447432\n",
      "Iteration 5335, loss = 0.00447328\n",
      "Iteration 5336, loss = 0.00447226\n",
      "Iteration 5337, loss = 0.00447074\n",
      "Iteration 5338, loss = 0.00446962\n",
      "Iteration 5339, loss = 0.00446842\n",
      "Iteration 5340, loss = 0.00446706\n",
      "Iteration 5341, loss = 0.00446602\n",
      "Iteration 5342, loss = 0.00446483\n",
      "Iteration 5343, loss = 0.00446370\n",
      "Iteration 5344, loss = 0.00446233\n",
      "Iteration 5345, loss = 0.00446150\n",
      "Iteration 5346, loss = 0.00445993\n",
      "Iteration 5347, loss = 0.00445884\n",
      "Iteration 5348, loss = 0.00445735\n",
      "Iteration 5349, loss = 0.00445633\n",
      "Iteration 5350, loss = 0.00445560\n",
      "Iteration 5351, loss = 0.00445401\n",
      "Iteration 5352, loss = 0.00445273\n",
      "Iteration 5353, loss = 0.00445147\n",
      "Iteration 5354, loss = 0.00445033\n",
      "Iteration 5355, loss = 0.00444912\n",
      "Iteration 5356, loss = 0.00444786\n",
      "Iteration 5357, loss = 0.00444676\n",
      "Iteration 5358, loss = 0.00444548\n",
      "Iteration 5359, loss = 0.00444440\n",
      "Iteration 5360, loss = 0.00444329\n",
      "Iteration 5361, loss = 0.00444228\n",
      "Iteration 5362, loss = 0.00444128\n",
      "Iteration 5363, loss = 0.00444008\n",
      "Iteration 5364, loss = 0.00443919\n",
      "Iteration 5365, loss = 0.00443794\n",
      "Iteration 5366, loss = 0.00443684\n",
      "Iteration 5367, loss = 0.00443606\n",
      "Iteration 5368, loss = 0.00443468\n",
      "Iteration 5369, loss = 0.00443391\n",
      "Iteration 5370, loss = 0.00443257\n",
      "Iteration 5371, loss = 0.00443169\n",
      "Iteration 5372, loss = 0.00443036\n",
      "Iteration 5373, loss = 0.00442918\n",
      "Iteration 5374, loss = 0.00442843\n",
      "Iteration 5375, loss = 0.00442694\n",
      "Iteration 5376, loss = 0.00442609\n",
      "Iteration 5377, loss = 0.00442472\n",
      "Iteration 5378, loss = 0.00442362\n",
      "Iteration 5379, loss = 0.00442239\n",
      "Iteration 5380, loss = 0.00442144\n",
      "Iteration 5381, loss = 0.00442036\n",
      "Iteration 5382, loss = 0.00441881\n",
      "Iteration 5383, loss = 0.00441778\n",
      "Iteration 5384, loss = 0.00441656\n",
      "Iteration 5385, loss = 0.00441537\n",
      "Iteration 5386, loss = 0.00441421\n",
      "Iteration 5387, loss = 0.00441293\n",
      "Iteration 5388, loss = 0.00441167\n",
      "Iteration 5389, loss = 0.00441047\n",
      "Iteration 5390, loss = 0.00440922\n",
      "Iteration 5391, loss = 0.00440820\n",
      "Iteration 5392, loss = 0.00440676\n",
      "Iteration 5393, loss = 0.00440555\n",
      "Iteration 5394, loss = 0.00440429\n",
      "Iteration 5395, loss = 0.00440310\n",
      "Iteration 5396, loss = 0.00440205\n",
      "Iteration 5397, loss = 0.00440073\n",
      "Iteration 5398, loss = 0.00439958\n",
      "Iteration 5399, loss = 0.00439851\n",
      "Iteration 5400, loss = 0.00439772\n",
      "Iteration 5401, loss = 0.00439628\n",
      "Iteration 5402, loss = 0.00439523\n",
      "Iteration 5403, loss = 0.00439392\n",
      "Iteration 5404, loss = 0.00439313\n",
      "Iteration 5405, loss = 0.00439180\n",
      "Iteration 5406, loss = 0.00439055\n",
      "Iteration 5407, loss = 0.00438946\n",
      "Iteration 5408, loss = 0.00438838\n",
      "Iteration 5409, loss = 0.00438728\n",
      "Iteration 5410, loss = 0.00438638\n",
      "Iteration 5411, loss = 0.00438513\n",
      "Iteration 5412, loss = 0.00438406\n",
      "Iteration 5413, loss = 0.00438317\n",
      "Iteration 5414, loss = 0.00438187\n",
      "Iteration 5415, loss = 0.00438067\n",
      "Iteration 5416, loss = 0.00437949\n",
      "Iteration 5417, loss = 0.00437959\n",
      "Iteration 5418, loss = 0.00437764\n",
      "Iteration 5419, loss = 0.00437670\n",
      "Iteration 5420, loss = 0.00437516\n",
      "Iteration 5421, loss = 0.00437393\n",
      "Iteration 5422, loss = 0.00437273\n",
      "Iteration 5423, loss = 0.00437146\n",
      "Iteration 5424, loss = 0.00437077\n",
      "Iteration 5425, loss = 0.00436896\n",
      "Iteration 5426, loss = 0.00436785\n",
      "Iteration 5427, loss = 0.00436689\n",
      "Iteration 5428, loss = 0.00436580\n",
      "Iteration 5429, loss = 0.00436450\n",
      "Iteration 5430, loss = 0.00436357\n",
      "Iteration 5431, loss = 0.00436220\n",
      "Iteration 5432, loss = 0.00436146\n",
      "Iteration 5433, loss = 0.00436022\n",
      "Iteration 5434, loss = 0.00435907\n",
      "Iteration 5435, loss = 0.00435798\n",
      "Iteration 5436, loss = 0.00435730\n",
      "Iteration 5437, loss = 0.00435582\n",
      "Iteration 5438, loss = 0.00435478\n",
      "Iteration 5439, loss = 0.00435392\n",
      "Iteration 5440, loss = 0.00435253\n",
      "Iteration 5441, loss = 0.00435206\n",
      "Iteration 5442, loss = 0.00435038\n",
      "Iteration 5443, loss = 0.00434936\n",
      "Iteration 5444, loss = 0.00434824\n",
      "Iteration 5445, loss = 0.00434699\n",
      "Iteration 5446, loss = 0.00434578\n",
      "Iteration 5447, loss = 0.00434469\n",
      "Iteration 5448, loss = 0.00434353\n",
      "Iteration 5449, loss = 0.00434245\n",
      "Iteration 5450, loss = 0.00434123\n",
      "Iteration 5451, loss = 0.00434017\n",
      "Iteration 5452, loss = 0.00433907\n",
      "Iteration 5453, loss = 0.00433777\n",
      "Iteration 5454, loss = 0.00433741\n",
      "Iteration 5455, loss = 0.00433578\n",
      "Iteration 5456, loss = 0.00433461\n",
      "Iteration 5457, loss = 0.00433360\n",
      "Iteration 5458, loss = 0.00433240\n",
      "Iteration 5459, loss = 0.00433122\n",
      "Iteration 5460, loss = 0.00433006\n",
      "Iteration 5461, loss = 0.00432889\n",
      "Iteration 5462, loss = 0.00432800\n",
      "Iteration 5463, loss = 0.00432741\n",
      "Iteration 5464, loss = 0.00432597\n",
      "Iteration 5465, loss = 0.00432482\n",
      "Iteration 5466, loss = 0.00432372\n",
      "Iteration 5467, loss = 0.00432277\n",
      "Iteration 5468, loss = 0.00432187\n",
      "Iteration 5469, loss = 0.00432077\n",
      "Iteration 5470, loss = 0.00431968\n",
      "Iteration 5471, loss = 0.00431864\n",
      "Iteration 5472, loss = 0.00431754\n",
      "Iteration 5473, loss = 0.00431652\n",
      "Iteration 5474, loss = 0.00431550\n",
      "Iteration 5475, loss = 0.00431481\n",
      "Iteration 5476, loss = 0.00431368\n",
      "Iteration 5477, loss = 0.00431339\n",
      "Iteration 5478, loss = 0.00431174\n",
      "Iteration 5479, loss = 0.00431077\n",
      "Iteration 5480, loss = 0.00430958\n",
      "Iteration 5481, loss = 0.00430861\n",
      "Iteration 5482, loss = 0.00430796\n",
      "Iteration 5483, loss = 0.00430656\n",
      "Iteration 5484, loss = 0.00430566\n",
      "Iteration 5485, loss = 0.00430444\n",
      "Iteration 5486, loss = 0.00430350\n",
      "Iteration 5487, loss = 0.00430235\n",
      "Iteration 5488, loss = 0.00430267\n",
      "Iteration 5489, loss = 0.00430059\n",
      "Iteration 5490, loss = 0.00429929\n",
      "Iteration 5491, loss = 0.00429818\n",
      "Iteration 5492, loss = 0.00429709\n",
      "Iteration 5493, loss = 0.00429599\n",
      "Iteration 5494, loss = 0.00429490\n",
      "Iteration 5495, loss = 0.00429380\n",
      "Iteration 5496, loss = 0.00429268\n",
      "Iteration 5497, loss = 0.00429170\n",
      "Iteration 5498, loss = 0.00429064\n",
      "Iteration 5499, loss = 0.00428953\n",
      "Iteration 5500, loss = 0.00428814\n",
      "Iteration 5501, loss = 0.00428707\n",
      "Iteration 5502, loss = 0.00428591\n",
      "Iteration 5503, loss = 0.00428472\n",
      "Iteration 5504, loss = 0.00428357\n",
      "Iteration 5505, loss = 0.00428240\n",
      "Iteration 5506, loss = 0.00428141\n",
      "Iteration 5507, loss = 0.00428043\n",
      "Iteration 5508, loss = 0.00427912\n",
      "Iteration 5509, loss = 0.00427789\n",
      "Iteration 5510, loss = 0.00427685\n",
      "Iteration 5511, loss = 0.00427566\n",
      "Iteration 5512, loss = 0.00427455\n",
      "Iteration 5513, loss = 0.00427350\n",
      "Iteration 5514, loss = 0.00427237\n",
      "Iteration 5515, loss = 0.00427133\n",
      "Iteration 5516, loss = 0.00427037\n",
      "Iteration 5517, loss = 0.00426920\n",
      "Iteration 5518, loss = 0.00426827\n",
      "Iteration 5519, loss = 0.00426713\n",
      "Iteration 5520, loss = 0.00426633\n",
      "Iteration 5521, loss = 0.00426493\n",
      "Iteration 5522, loss = 0.00426361\n",
      "Iteration 5523, loss = 0.00426253\n",
      "Iteration 5524, loss = 0.00426190\n",
      "Iteration 5525, loss = 0.00426053\n",
      "Iteration 5526, loss = 0.00425944\n",
      "Iteration 5527, loss = 0.00425849\n",
      "Iteration 5528, loss = 0.00425734\n",
      "Iteration 5529, loss = 0.00425633\n",
      "Iteration 5530, loss = 0.00425536\n",
      "Iteration 5531, loss = 0.00425421\n",
      "Iteration 5532, loss = 0.00425326\n",
      "Iteration 5533, loss = 0.00425204\n",
      "Iteration 5534, loss = 0.00425097\n",
      "Iteration 5535, loss = 0.00424983\n",
      "Iteration 5536, loss = 0.00424873\n",
      "Iteration 5537, loss = 0.00424760\n",
      "Iteration 5538, loss = 0.00424648\n",
      "Iteration 5539, loss = 0.00424565\n",
      "Iteration 5540, loss = 0.00424443\n",
      "Iteration 5541, loss = 0.00424342\n",
      "Iteration 5542, loss = 0.00424248\n",
      "Iteration 5543, loss = 0.00424155\n",
      "Iteration 5544, loss = 0.00424036\n",
      "Iteration 5545, loss = 0.00423928\n",
      "Iteration 5546, loss = 0.00423845\n",
      "Iteration 5547, loss = 0.00423718\n",
      "Iteration 5548, loss = 0.00423610\n",
      "Iteration 5549, loss = 0.00423496\n",
      "Iteration 5550, loss = 0.00423371\n",
      "Iteration 5551, loss = 0.00423279\n",
      "Iteration 5552, loss = 0.00423157\n",
      "Iteration 5553, loss = 0.00423094\n",
      "Iteration 5554, loss = 0.00422932\n",
      "Iteration 5555, loss = 0.00422816\n",
      "Iteration 5556, loss = 0.00422698\n",
      "Iteration 5557, loss = 0.00422588\n",
      "Iteration 5558, loss = 0.00422474\n",
      "Iteration 5559, loss = 0.00422373\n",
      "Iteration 5560, loss = 0.00422264\n",
      "Iteration 5561, loss = 0.00422139\n",
      "Iteration 5562, loss = 0.00422038\n",
      "Iteration 5563, loss = 0.00421940\n",
      "Iteration 5564, loss = 0.00421830\n",
      "Iteration 5565, loss = 0.00421732\n",
      "Iteration 5566, loss = 0.00421643\n",
      "Iteration 5567, loss = 0.00421514\n",
      "Iteration 5568, loss = 0.00421407\n",
      "Iteration 5569, loss = 0.00421318\n",
      "Iteration 5570, loss = 0.00421215\n",
      "Iteration 5571, loss = 0.00421097\n",
      "Iteration 5572, loss = 0.00420983\n",
      "Iteration 5573, loss = 0.00420913\n",
      "Iteration 5574, loss = 0.00420767\n",
      "Iteration 5575, loss = 0.00420669\n",
      "Iteration 5576, loss = 0.00420581\n",
      "Iteration 5577, loss = 0.00420455\n",
      "Iteration 5578, loss = 0.00420385\n",
      "Iteration 5579, loss = 0.00420314\n",
      "Iteration 5580, loss = 0.00420173\n",
      "Iteration 5581, loss = 0.00420082\n",
      "Iteration 5582, loss = 0.00419983\n",
      "Iteration 5583, loss = 0.00419879\n",
      "Iteration 5584, loss = 0.00419791\n",
      "Iteration 5585, loss = 0.00419678\n",
      "Iteration 5586, loss = 0.00419584\n",
      "Iteration 5587, loss = 0.00419489\n",
      "Iteration 5588, loss = 0.00419427\n",
      "Iteration 5589, loss = 0.00419291\n",
      "Iteration 5590, loss = 0.00419182\n",
      "Iteration 5591, loss = 0.00419082\n",
      "Iteration 5592, loss = 0.00419038\n",
      "Iteration 5593, loss = 0.00418892\n",
      "Iteration 5594, loss = 0.00418776\n",
      "Iteration 5595, loss = 0.00418662\n",
      "Iteration 5596, loss = 0.00418580\n",
      "Iteration 5597, loss = 0.00418451\n",
      "Iteration 5598, loss = 0.00418334\n",
      "Iteration 5599, loss = 0.00418237\n",
      "Iteration 5600, loss = 0.00418149\n",
      "Iteration 5601, loss = 0.00418025\n",
      "Iteration 5602, loss = 0.00417907\n",
      "Iteration 5603, loss = 0.00417775\n",
      "Iteration 5604, loss = 0.00417739\n",
      "Iteration 5605, loss = 0.00417569\n",
      "Iteration 5606, loss = 0.00417443\n",
      "Iteration 5607, loss = 0.00417353\n",
      "Iteration 5608, loss = 0.00417238\n",
      "Iteration 5609, loss = 0.00417138\n",
      "Iteration 5610, loss = 0.00417006\n",
      "Iteration 5611, loss = 0.00416889\n",
      "Iteration 5612, loss = 0.00416817\n",
      "Iteration 5613, loss = 0.00416671\n",
      "Iteration 5614, loss = 0.00416559\n",
      "Iteration 5615, loss = 0.00416481\n",
      "Iteration 5616, loss = 0.00416346\n",
      "Iteration 5617, loss = 0.00416282\n",
      "Iteration 5618, loss = 0.00416115\n",
      "Iteration 5619, loss = 0.00416014\n",
      "Iteration 5620, loss = 0.00415915\n",
      "Iteration 5621, loss = 0.00415776\n",
      "Iteration 5622, loss = 0.00415671\n",
      "Iteration 5623, loss = 0.00415555\n",
      "Iteration 5624, loss = 0.00415457\n",
      "Iteration 5625, loss = 0.00415337\n",
      "Iteration 5626, loss = 0.00415232\n",
      "Iteration 5627, loss = 0.00415121\n",
      "Iteration 5628, loss = 0.00415007\n",
      "Iteration 5629, loss = 0.00414907\n",
      "Iteration 5630, loss = 0.00414811\n",
      "Iteration 5631, loss = 0.00414698\n",
      "Iteration 5632, loss = 0.00414571\n",
      "Iteration 5633, loss = 0.00414460\n",
      "Iteration 5634, loss = 0.00414338\n",
      "Iteration 5635, loss = 0.00414245\n",
      "Iteration 5636, loss = 0.00414129\n",
      "Iteration 5637, loss = 0.00414018\n",
      "Iteration 5638, loss = 0.00413933\n",
      "Iteration 5639, loss = 0.00413800\n",
      "Iteration 5640, loss = 0.00413706\n",
      "Iteration 5641, loss = 0.00413594\n",
      "Iteration 5642, loss = 0.00413468\n",
      "Iteration 5643, loss = 0.00413381\n",
      "Iteration 5644, loss = 0.00413279\n",
      "Iteration 5645, loss = 0.00413143\n",
      "Iteration 5646, loss = 0.00413052\n",
      "Iteration 5647, loss = 0.00412938\n",
      "Iteration 5648, loss = 0.00412825\n",
      "Iteration 5649, loss = 0.00412713\n",
      "Iteration 5650, loss = 0.00412654\n",
      "Iteration 5651, loss = 0.00412515\n",
      "Iteration 5652, loss = 0.00412426\n",
      "Iteration 5653, loss = 0.00412298\n",
      "Iteration 5654, loss = 0.00412198\n",
      "Iteration 5655, loss = 0.00412101\n",
      "Iteration 5656, loss = 0.00412002\n",
      "Iteration 5657, loss = 0.00411904\n",
      "Iteration 5658, loss = 0.00411804\n",
      "Iteration 5659, loss = 0.00411714\n",
      "Iteration 5660, loss = 0.00411600\n",
      "Iteration 5661, loss = 0.00411507\n",
      "Iteration 5662, loss = 0.00411417\n",
      "Iteration 5663, loss = 0.00411303\n",
      "Iteration 5664, loss = 0.00411189\n",
      "Iteration 5665, loss = 0.00411123\n",
      "Iteration 5666, loss = 0.00410995\n",
      "Iteration 5667, loss = 0.00410890\n",
      "Iteration 5668, loss = 0.00410818\n",
      "Iteration 5669, loss = 0.00410710\n",
      "Iteration 5670, loss = 0.00410610\n",
      "Iteration 5671, loss = 0.00410503\n",
      "Iteration 5672, loss = 0.00410463\n",
      "Iteration 5673, loss = 0.00410302\n",
      "Iteration 5674, loss = 0.00410203\n",
      "Iteration 5675, loss = 0.00410101\n",
      "Iteration 5676, loss = 0.00409993\n",
      "Iteration 5677, loss = 0.00409900\n",
      "Iteration 5678, loss = 0.00409803\n",
      "Iteration 5679, loss = 0.00409685\n",
      "Iteration 5680, loss = 0.00409624\n",
      "Iteration 5681, loss = 0.00409479\n",
      "Iteration 5682, loss = 0.00409358\n",
      "Iteration 5683, loss = 0.00409229\n",
      "Iteration 5684, loss = 0.00409123\n",
      "Iteration 5685, loss = 0.00409017\n",
      "Iteration 5686, loss = 0.00408901\n",
      "Iteration 5687, loss = 0.00408768\n",
      "Iteration 5688, loss = 0.00408728\n",
      "Iteration 5689, loss = 0.00408567\n",
      "Iteration 5690, loss = 0.00408461\n",
      "Iteration 5691, loss = 0.00408347\n",
      "Iteration 5692, loss = 0.00408245\n",
      "Iteration 5693, loss = 0.00408139\n",
      "Iteration 5694, loss = 0.00408043\n",
      "Iteration 5695, loss = 0.00407938\n",
      "Iteration 5696, loss = 0.00407839\n",
      "Iteration 5697, loss = 0.00407716\n",
      "Iteration 5698, loss = 0.00407658\n",
      "Iteration 5699, loss = 0.00407527\n",
      "Iteration 5700, loss = 0.00407417\n",
      "Iteration 5701, loss = 0.00407311\n",
      "Iteration 5702, loss = 0.00407227\n",
      "Iteration 5703, loss = 0.00407141\n",
      "Iteration 5704, loss = 0.00406993\n",
      "Iteration 5705, loss = 0.00406872\n",
      "Iteration 5706, loss = 0.00406782\n",
      "Iteration 5707, loss = 0.00406703\n",
      "Iteration 5708, loss = 0.00406654\n",
      "Iteration 5709, loss = 0.00406512\n",
      "Iteration 5710, loss = 0.00406432\n",
      "Iteration 5711, loss = 0.00406306\n",
      "Iteration 5712, loss = 0.00406195\n",
      "Iteration 5713, loss = 0.00406097\n",
      "Iteration 5714, loss = 0.00406002\n",
      "Iteration 5715, loss = 0.00405889\n",
      "Iteration 5716, loss = 0.00405769\n",
      "Iteration 5717, loss = 0.00405657\n",
      "Iteration 5718, loss = 0.00405544\n",
      "Iteration 5719, loss = 0.00405443\n",
      "Iteration 5720, loss = 0.00405325\n",
      "Iteration 5721, loss = 0.00405280\n",
      "Iteration 5722, loss = 0.00405143\n",
      "Iteration 5723, loss = 0.00405100\n",
      "Iteration 5724, loss = 0.00404968\n",
      "Iteration 5725, loss = 0.00404848\n",
      "Iteration 5726, loss = 0.00404714\n",
      "Iteration 5727, loss = 0.00404626\n",
      "Iteration 5728, loss = 0.00404609\n",
      "Iteration 5729, loss = 0.00404448\n",
      "Iteration 5730, loss = 0.00404354\n",
      "Iteration 5731, loss = 0.00404232\n",
      "Iteration 5732, loss = 0.00404162\n",
      "Iteration 5733, loss = 0.00404051\n",
      "Iteration 5734, loss = 0.00403935\n",
      "Iteration 5735, loss = 0.00403835\n",
      "Iteration 5736, loss = 0.00403741\n",
      "Iteration 5737, loss = 0.00403661\n",
      "Iteration 5738, loss = 0.00403548\n",
      "Iteration 5739, loss = 0.00403449\n",
      "Iteration 5740, loss = 0.00403348\n",
      "Iteration 5741, loss = 0.00403240\n",
      "Iteration 5742, loss = 0.00403174\n",
      "Iteration 5743, loss = 0.00403049\n",
      "Iteration 5744, loss = 0.00402953\n",
      "Iteration 5745, loss = 0.00402844\n",
      "Iteration 5746, loss = 0.00402740\n",
      "Iteration 5747, loss = 0.00402638\n",
      "Iteration 5748, loss = 0.00402537\n",
      "Iteration 5749, loss = 0.00402443\n",
      "Iteration 5750, loss = 0.00402382\n",
      "Iteration 5751, loss = 0.00402260\n",
      "Iteration 5752, loss = 0.00402162\n",
      "Iteration 5753, loss = 0.00402085\n",
      "Iteration 5754, loss = 0.00401968\n",
      "Iteration 5755, loss = 0.00401869\n",
      "Iteration 5756, loss = 0.00401773\n",
      "Iteration 5757, loss = 0.00401667\n",
      "Iteration 5758, loss = 0.00401570\n",
      "Iteration 5759, loss = 0.00401472\n",
      "Iteration 5760, loss = 0.00401362\n",
      "Iteration 5761, loss = 0.00401285\n",
      "Iteration 5762, loss = 0.00401165\n",
      "Iteration 5763, loss = 0.00401098\n",
      "Iteration 5764, loss = 0.00400968\n",
      "Iteration 5765, loss = 0.00400868\n",
      "Iteration 5766, loss = 0.00400767\n",
      "Iteration 5767, loss = 0.00400690\n",
      "Iteration 5768, loss = 0.00400579\n",
      "Iteration 5769, loss = 0.00400501\n",
      "Iteration 5770, loss = 0.00400399\n",
      "Iteration 5771, loss = 0.00400300\n",
      "Iteration 5772, loss = 0.00400210\n",
      "Iteration 5773, loss = 0.00400162\n",
      "Iteration 5774, loss = 0.00400023\n",
      "Iteration 5775, loss = 0.00399940\n",
      "Iteration 5776, loss = 0.00399845\n",
      "Iteration 5777, loss = 0.00399733\n",
      "Iteration 5778, loss = 0.00399715\n",
      "Iteration 5779, loss = 0.00399549\n",
      "Iteration 5780, loss = 0.00399450\n",
      "Iteration 5781, loss = 0.00399345\n",
      "Iteration 5782, loss = 0.00399244\n",
      "Iteration 5783, loss = 0.00399135\n",
      "Iteration 5784, loss = 0.00399033\n",
      "Iteration 5785, loss = 0.00398948\n",
      "Iteration 5786, loss = 0.00398834\n",
      "Iteration 5787, loss = 0.00398760\n",
      "Iteration 5788, loss = 0.00398641\n",
      "Iteration 5789, loss = 0.00398552\n",
      "Iteration 5790, loss = 0.00398451\n",
      "Iteration 5791, loss = 0.00398337\n",
      "Iteration 5792, loss = 0.00398300\n",
      "Iteration 5793, loss = 0.00398154\n",
      "Iteration 5794, loss = 0.00398050\n",
      "Iteration 5795, loss = 0.00397943\n",
      "Iteration 5796, loss = 0.00397849\n",
      "Iteration 5797, loss = 0.00397766\n",
      "Iteration 5798, loss = 0.00397641\n",
      "Iteration 5799, loss = 0.00397536\n",
      "Iteration 5800, loss = 0.00397446\n",
      "Iteration 5801, loss = 0.00397336\n",
      "Iteration 5802, loss = 0.00397225\n",
      "Iteration 5803, loss = 0.00397137\n",
      "Iteration 5804, loss = 0.00397040\n",
      "Iteration 5805, loss = 0.00396953\n",
      "Iteration 5806, loss = 0.00396843\n",
      "Iteration 5807, loss = 0.00396806\n",
      "Iteration 5808, loss = 0.00396682\n",
      "Iteration 5809, loss = 0.00396598\n",
      "Iteration 5810, loss = 0.00396496\n",
      "Iteration 5811, loss = 0.00396389\n",
      "Iteration 5812, loss = 0.00396316\n",
      "Iteration 5813, loss = 0.00396213\n",
      "Iteration 5814, loss = 0.00396124\n",
      "Iteration 5815, loss = 0.00396061\n",
      "Iteration 5816, loss = 0.00395948\n",
      "Iteration 5817, loss = 0.00395846\n",
      "Iteration 5818, loss = 0.00395771\n",
      "Iteration 5819, loss = 0.00395688\n",
      "Iteration 5820, loss = 0.00395584\n",
      "Iteration 5821, loss = 0.00395501\n",
      "Iteration 5822, loss = 0.00395429\n",
      "Iteration 5823, loss = 0.00395303\n",
      "Iteration 5824, loss = 0.00395238\n",
      "Iteration 5825, loss = 0.00395118\n",
      "Iteration 5826, loss = 0.00395031\n",
      "Iteration 5827, loss = 0.00394917\n",
      "Iteration 5828, loss = 0.00394854\n",
      "Iteration 5829, loss = 0.00394780\n",
      "Iteration 5830, loss = 0.00394613\n",
      "Iteration 5831, loss = 0.00394505\n",
      "Iteration 5832, loss = 0.00394416\n",
      "Iteration 5833, loss = 0.00394308\n",
      "Iteration 5834, loss = 0.00394211\n",
      "Iteration 5835, loss = 0.00394117\n",
      "Iteration 5836, loss = 0.00394016\n",
      "Iteration 5837, loss = 0.00393919\n",
      "Iteration 5838, loss = 0.00393818\n",
      "Iteration 5839, loss = 0.00393731\n",
      "Iteration 5840, loss = 0.00393637\n",
      "Iteration 5841, loss = 0.00393536\n",
      "Iteration 5842, loss = 0.00393440\n",
      "Iteration 5843, loss = 0.00393353\n",
      "Iteration 5844, loss = 0.00393249\n",
      "Iteration 5845, loss = 0.00393173\n",
      "Iteration 5846, loss = 0.00393081\n",
      "Iteration 5847, loss = 0.00392964\n",
      "Iteration 5848, loss = 0.00392866\n",
      "Iteration 5849, loss = 0.00392780\n",
      "Iteration 5850, loss = 0.00392675\n",
      "Iteration 5851, loss = 0.00392579\n",
      "Iteration 5852, loss = 0.00392508\n",
      "Iteration 5853, loss = 0.00392411\n",
      "Iteration 5854, loss = 0.00392319\n",
      "Iteration 5855, loss = 0.00392210\n",
      "Iteration 5856, loss = 0.00392137\n",
      "Iteration 5857, loss = 0.00392052\n",
      "Iteration 5858, loss = 0.00391939\n",
      "Iteration 5859, loss = 0.00391871\n",
      "Iteration 5860, loss = 0.00391771\n",
      "Iteration 5861, loss = 0.00391655\n",
      "Iteration 5862, loss = 0.00391559\n",
      "Iteration 5863, loss = 0.00391468\n",
      "Iteration 5864, loss = 0.00391385\n",
      "Iteration 5865, loss = 0.00391277\n",
      "Iteration 5866, loss = 0.00391194\n",
      "Iteration 5867, loss = 0.00391105\n",
      "Iteration 5868, loss = 0.00391003\n",
      "Iteration 5869, loss = 0.00390909\n",
      "Iteration 5870, loss = 0.00390846\n",
      "Iteration 5871, loss = 0.00390711\n",
      "Iteration 5872, loss = 0.00390612\n",
      "Iteration 5873, loss = 0.00390512\n",
      "Iteration 5874, loss = 0.00390438\n",
      "Iteration 5875, loss = 0.00390320\n",
      "Iteration 5876, loss = 0.00390259\n",
      "Iteration 5877, loss = 0.00390142\n",
      "Iteration 5878, loss = 0.00390037\n",
      "Iteration 5879, loss = 0.00389945\n",
      "Iteration 5880, loss = 0.00389847\n",
      "Iteration 5881, loss = 0.00389764\n",
      "Iteration 5882, loss = 0.00389654\n",
      "Iteration 5883, loss = 0.00389589\n",
      "Iteration 5884, loss = 0.00389467\n",
      "Iteration 5885, loss = 0.00389383\n",
      "Iteration 5886, loss = 0.00389288\n",
      "Iteration 5887, loss = 0.00389200\n",
      "Iteration 5888, loss = 0.00389097\n",
      "Iteration 5889, loss = 0.00389038\n",
      "Iteration 5890, loss = 0.00388933\n",
      "Iteration 5891, loss = 0.00388837\n",
      "Iteration 5892, loss = 0.00388816\n",
      "Iteration 5893, loss = 0.00388665\n",
      "Iteration 5894, loss = 0.00388575\n",
      "Iteration 5895, loss = 0.00388484\n",
      "Iteration 5896, loss = 0.00388379\n",
      "Iteration 5897, loss = 0.00388288\n",
      "Iteration 5898, loss = 0.00388198\n",
      "Iteration 5899, loss = 0.00388103\n",
      "Iteration 5900, loss = 0.00388012\n",
      "Iteration 5901, loss = 0.00387929\n",
      "Iteration 5902, loss = 0.00387836\n",
      "Iteration 5903, loss = 0.00387753\n",
      "Iteration 5904, loss = 0.00387660\n",
      "Iteration 5905, loss = 0.00387560\n",
      "Iteration 5906, loss = 0.00387504\n",
      "Iteration 5907, loss = 0.00387400\n",
      "Iteration 5908, loss = 0.00387306\n",
      "Iteration 5909, loss = 0.00387214\n",
      "Iteration 5910, loss = 0.00387136\n",
      "Iteration 5911, loss = 0.00387036\n",
      "Iteration 5912, loss = 0.00386915\n",
      "Iteration 5913, loss = 0.00386859\n",
      "Iteration 5914, loss = 0.00386746\n",
      "Iteration 5915, loss = 0.00386658\n",
      "Iteration 5916, loss = 0.00386554\n",
      "Iteration 5917, loss = 0.00386466\n",
      "Iteration 5918, loss = 0.00386366\n",
      "Iteration 5919, loss = 0.00386315\n",
      "Iteration 5920, loss = 0.00386193\n",
      "Iteration 5921, loss = 0.00386094\n",
      "Iteration 5922, loss = 0.00386005\n",
      "Iteration 5923, loss = 0.00385912\n",
      "Iteration 5924, loss = 0.00385829\n",
      "Iteration 5925, loss = 0.00385720\n",
      "Iteration 5926, loss = 0.00385629\n",
      "Iteration 5927, loss = 0.00385558\n",
      "Iteration 5928, loss = 0.00385440\n",
      "Iteration 5929, loss = 0.00385341\n",
      "Iteration 5930, loss = 0.00385245\n",
      "Iteration 5931, loss = 0.00385159\n",
      "Iteration 5932, loss = 0.00385052\n",
      "Iteration 5933, loss = 0.00384941\n",
      "Iteration 5934, loss = 0.00384834\n",
      "Iteration 5935, loss = 0.00384726\n",
      "Iteration 5936, loss = 0.00384610\n",
      "Iteration 5937, loss = 0.00384550\n",
      "Iteration 5938, loss = 0.00384452\n",
      "Iteration 5939, loss = 0.00384364\n",
      "Iteration 5940, loss = 0.00384246\n",
      "Iteration 5941, loss = 0.00384150\n",
      "Iteration 5942, loss = 0.00384062\n",
      "Iteration 5943, loss = 0.00383974\n",
      "Iteration 5944, loss = 0.00383899\n",
      "Iteration 5945, loss = 0.00383801\n",
      "Iteration 5946, loss = 0.00383721\n",
      "Iteration 5947, loss = 0.00383629\n",
      "Iteration 5948, loss = 0.00383551\n",
      "Iteration 5949, loss = 0.00383451\n",
      "Iteration 5950, loss = 0.00383366\n",
      "Iteration 5951, loss = 0.00383301\n",
      "Iteration 5952, loss = 0.00383199\n",
      "Iteration 5953, loss = 0.00383100\n",
      "Iteration 5954, loss = 0.00383009\n",
      "Iteration 5955, loss = 0.00382923\n",
      "Iteration 5956, loss = 0.00382830\n",
      "Iteration 5957, loss = 0.00382741\n",
      "Iteration 5958, loss = 0.00382646\n",
      "Iteration 5959, loss = 0.00382584\n",
      "Iteration 5960, loss = 0.00382464\n",
      "Iteration 5961, loss = 0.00382387\n",
      "Iteration 5962, loss = 0.00382305\n",
      "Iteration 5963, loss = 0.00382235\n",
      "Iteration 5964, loss = 0.00382131\n",
      "Iteration 5965, loss = 0.00382042\n",
      "Iteration 5966, loss = 0.00381945\n",
      "Iteration 5967, loss = 0.00381868\n",
      "Iteration 5968, loss = 0.00381786\n",
      "Iteration 5969, loss = 0.00381676\n",
      "Iteration 5970, loss = 0.00381593\n",
      "Iteration 5971, loss = 0.00381539\n",
      "Iteration 5972, loss = 0.00381423\n",
      "Iteration 5973, loss = 0.00381347\n",
      "Iteration 5974, loss = 0.00381277\n",
      "Iteration 5975, loss = 0.00381187\n",
      "Iteration 5976, loss = 0.00381090\n",
      "Iteration 5977, loss = 0.00381004\n",
      "Iteration 5978, loss = 0.00380920\n",
      "Iteration 5979, loss = 0.00380826\n",
      "Iteration 5980, loss = 0.00380753\n",
      "Iteration 5981, loss = 0.00380640\n",
      "Iteration 5982, loss = 0.00380546\n",
      "Iteration 5983, loss = 0.00380458\n",
      "Iteration 5984, loss = 0.00380361\n",
      "Iteration 5985, loss = 0.00380292\n",
      "Iteration 5986, loss = 0.00380190\n",
      "Iteration 5987, loss = 0.00380123\n",
      "Iteration 5988, loss = 0.00379997\n",
      "Iteration 5989, loss = 0.00379899\n",
      "Iteration 5990, loss = 0.00379828\n",
      "Iteration 5991, loss = 0.00379721\n",
      "Iteration 5992, loss = 0.00379621\n",
      "Iteration 5993, loss = 0.00379538\n",
      "Iteration 5994, loss = 0.00379444\n",
      "Iteration 5995, loss = 0.00379349\n",
      "Iteration 5996, loss = 0.00379282\n",
      "Iteration 5997, loss = 0.00379186\n",
      "Iteration 5998, loss = 0.00379101\n",
      "Iteration 5999, loss = 0.00379031\n",
      "Iteration 6000, loss = 0.00378935\n",
      "Iteration 6001, loss = 0.00378839\n",
      "Iteration 6002, loss = 0.00378743\n",
      "Iteration 6003, loss = 0.00378665\n",
      "Iteration 6004, loss = 0.00378566\n",
      "Iteration 6005, loss = 0.00378492\n",
      "Iteration 6006, loss = 0.00378400\n",
      "Iteration 6007, loss = 0.00378308\n",
      "Iteration 6008, loss = 0.00378214\n",
      "Iteration 6009, loss = 0.00378136\n",
      "Iteration 6010, loss = 0.00378055\n",
      "Iteration 6011, loss = 0.00377971\n",
      "Iteration 6012, loss = 0.00377912\n",
      "Iteration 6013, loss = 0.00377816\n",
      "Iteration 6014, loss = 0.00377725\n",
      "Iteration 6015, loss = 0.00377624\n",
      "Iteration 6016, loss = 0.00377540\n",
      "Iteration 6017, loss = 0.00377445\n",
      "Iteration 6018, loss = 0.00377386\n",
      "Iteration 6019, loss = 0.00377270\n",
      "Iteration 6020, loss = 0.00377175\n",
      "Iteration 6021, loss = 0.00377084\n",
      "Iteration 6022, loss = 0.00376996\n",
      "Iteration 6023, loss = 0.00376913\n",
      "Iteration 6024, loss = 0.00376857\n",
      "Iteration 6025, loss = 0.00376744\n",
      "Iteration 6026, loss = 0.00376664\n",
      "Iteration 6027, loss = 0.00376581\n",
      "Iteration 6028, loss = 0.00376499\n",
      "Iteration 6029, loss = 0.00376412\n",
      "Iteration 6030, loss = 0.00376339\n",
      "Iteration 6031, loss = 0.00376251\n",
      "Iteration 6032, loss = 0.00376173\n",
      "Iteration 6033, loss = 0.00376078\n",
      "Iteration 6034, loss = 0.00375991\n",
      "Iteration 6035, loss = 0.00375913\n",
      "Iteration 6036, loss = 0.00375815\n",
      "Iteration 6037, loss = 0.00375722\n",
      "Iteration 6038, loss = 0.00375633\n",
      "Iteration 6039, loss = 0.00375533\n",
      "Iteration 6040, loss = 0.00375432\n",
      "Iteration 6041, loss = 0.00375383\n",
      "Iteration 6042, loss = 0.00375291\n",
      "Iteration 6043, loss = 0.00375162\n",
      "Iteration 6044, loss = 0.00375102\n",
      "Iteration 6045, loss = 0.00375002\n",
      "Iteration 6046, loss = 0.00374898\n",
      "Iteration 6047, loss = 0.00374796\n",
      "Iteration 6048, loss = 0.00374706\n",
      "Iteration 6049, loss = 0.00374611\n",
      "Iteration 6050, loss = 0.00374521\n",
      "Iteration 6051, loss = 0.00374462\n",
      "Iteration 6052, loss = 0.00374361\n",
      "Iteration 6053, loss = 0.00374275\n",
      "Iteration 6054, loss = 0.00374176\n",
      "Iteration 6055, loss = 0.00374093\n",
      "Iteration 6056, loss = 0.00374007\n",
      "Iteration 6057, loss = 0.00373932\n",
      "Iteration 6058, loss = 0.00373849\n",
      "Iteration 6059, loss = 0.00373799\n",
      "Iteration 6060, loss = 0.00373684\n",
      "Iteration 6061, loss = 0.00373584\n",
      "Iteration 6062, loss = 0.00373494\n",
      "Iteration 6063, loss = 0.00373430\n",
      "Iteration 6064, loss = 0.00373308\n",
      "Iteration 6065, loss = 0.00373230\n",
      "Iteration 6066, loss = 0.00373137\n",
      "Iteration 6067, loss = 0.00373042\n",
      "Iteration 6068, loss = 0.00372953\n",
      "Iteration 6069, loss = 0.00372880\n",
      "Iteration 6070, loss = 0.00372798\n",
      "Iteration 6071, loss = 0.00372699\n",
      "Iteration 6072, loss = 0.00372622\n",
      "Iteration 6073, loss = 0.00372538\n",
      "Iteration 6074, loss = 0.00372462\n",
      "Iteration 6075, loss = 0.00372382\n",
      "Iteration 6076, loss = 0.00372292\n",
      "Iteration 6077, loss = 0.00372218\n",
      "Iteration 6078, loss = 0.00372123\n",
      "Iteration 6079, loss = 0.00372030\n",
      "Iteration 6080, loss = 0.00371936\n",
      "Iteration 6081, loss = 0.00371856\n",
      "Iteration 6082, loss = 0.00371775\n",
      "Iteration 6083, loss = 0.00371690\n",
      "Iteration 6084, loss = 0.00371589\n",
      "Iteration 6085, loss = 0.00371496\n",
      "Iteration 6086, loss = 0.00371416\n",
      "Iteration 6087, loss = 0.00371327\n",
      "Iteration 6088, loss = 0.00371240\n",
      "Iteration 6089, loss = 0.00371153\n",
      "Iteration 6090, loss = 0.00371064\n",
      "Iteration 6091, loss = 0.00370969\n",
      "Iteration 6092, loss = 0.00370871\n",
      "Iteration 6093, loss = 0.00370804\n",
      "Iteration 6094, loss = 0.00370704\n",
      "Iteration 6095, loss = 0.00370660\n",
      "Iteration 6096, loss = 0.00370535\n",
      "Iteration 6097, loss = 0.00370435\n",
      "Iteration 6098, loss = 0.00370358\n",
      "Iteration 6099, loss = 0.00370272\n",
      "Iteration 6100, loss = 0.00370187\n",
      "Iteration 6101, loss = 0.00370106\n",
      "Iteration 6102, loss = 0.00370021\n",
      "Iteration 6103, loss = 0.00369967\n",
      "Iteration 6104, loss = 0.00369857\n",
      "Iteration 6105, loss = 0.00369769\n",
      "Iteration 6106, loss = 0.00369680\n",
      "Iteration 6107, loss = 0.00369593\n",
      "Iteration 6108, loss = 0.00369513\n",
      "Iteration 6109, loss = 0.00369419\n",
      "Iteration 6110, loss = 0.00369331\n",
      "Iteration 6111, loss = 0.00369248\n",
      "Iteration 6112, loss = 0.00369162\n",
      "Iteration 6113, loss = 0.00369080\n",
      "Iteration 6114, loss = 0.00368997\n",
      "Iteration 6115, loss = 0.00368949\n",
      "Iteration 6116, loss = 0.00368859\n",
      "Iteration 6117, loss = 0.00368762\n",
      "Iteration 6118, loss = 0.00368678\n",
      "Iteration 6119, loss = 0.00368602\n",
      "Iteration 6120, loss = 0.00368510\n",
      "Iteration 6121, loss = 0.00368454\n",
      "Iteration 6122, loss = 0.00368349\n",
      "Iteration 6123, loss = 0.00368275\n",
      "Iteration 6124, loss = 0.00368196\n",
      "Iteration 6125, loss = 0.00368132\n",
      "Iteration 6126, loss = 0.00368032\n",
      "Iteration 6127, loss = 0.00367952\n",
      "Iteration 6128, loss = 0.00367855\n",
      "Iteration 6129, loss = 0.00367770\n",
      "Iteration 6130, loss = 0.00367708\n",
      "Iteration 6131, loss = 0.00367709\n",
      "Iteration 6132, loss = 0.00367543\n",
      "Iteration 6133, loss = 0.00367485\n",
      "Iteration 6134, loss = 0.00367372\n",
      "Iteration 6135, loss = 0.00367267\n",
      "Iteration 6136, loss = 0.00367196\n",
      "Iteration 6137, loss = 0.00367089\n",
      "Iteration 6138, loss = 0.00367030\n",
      "Iteration 6139, loss = 0.00366930\n",
      "Iteration 6140, loss = 0.00366852\n",
      "Iteration 6141, loss = 0.00366762\n",
      "Iteration 6142, loss = 0.00366701\n",
      "Iteration 6143, loss = 0.00366587\n",
      "Iteration 6144, loss = 0.00366514\n",
      "Iteration 6145, loss = 0.00366412\n",
      "Iteration 6146, loss = 0.00366355\n",
      "Iteration 6147, loss = 0.00366257\n",
      "Iteration 6148, loss = 0.00366164\n",
      "Iteration 6149, loss = 0.00366077\n",
      "Iteration 6150, loss = 0.00365998\n",
      "Iteration 6151, loss = 0.00365915\n",
      "Iteration 6152, loss = 0.00365843\n",
      "Iteration 6153, loss = 0.00365758\n",
      "Iteration 6154, loss = 0.00365683\n",
      "Iteration 6155, loss = 0.00365610\n",
      "Iteration 6156, loss = 0.00365541\n",
      "Iteration 6157, loss = 0.00365433\n",
      "Iteration 6158, loss = 0.00365335\n",
      "Iteration 6159, loss = 0.00365272\n",
      "Iteration 6160, loss = 0.00365188\n",
      "Iteration 6161, loss = 0.00365079\n",
      "Iteration 6162, loss = 0.00364984\n",
      "Iteration 6163, loss = 0.00364883\n",
      "Iteration 6164, loss = 0.00364857\n",
      "Iteration 6165, loss = 0.00364718\n",
      "Iteration 6166, loss = 0.00364615\n",
      "Iteration 6167, loss = 0.00364526\n",
      "Iteration 6168, loss = 0.00364458\n",
      "Iteration 6169, loss = 0.00364378\n",
      "Iteration 6170, loss = 0.00364268\n",
      "Iteration 6171, loss = 0.00364169\n",
      "Iteration 6172, loss = 0.00364081\n",
      "Iteration 6173, loss = 0.00364002\n",
      "Iteration 6174, loss = 0.00363898\n",
      "Iteration 6175, loss = 0.00363799\n",
      "Iteration 6176, loss = 0.00363758\n",
      "Iteration 6177, loss = 0.00363641\n",
      "Iteration 6178, loss = 0.00363546\n",
      "Iteration 6179, loss = 0.00363455\n",
      "Iteration 6180, loss = 0.00363397\n",
      "Iteration 6181, loss = 0.00363275\n",
      "Iteration 6182, loss = 0.00363236\n",
      "Iteration 6183, loss = 0.00363163\n",
      "Iteration 6184, loss = 0.00363054\n",
      "Iteration 6185, loss = 0.00362950\n",
      "Iteration 6186, loss = 0.00362872\n",
      "Iteration 6187, loss = 0.00362786\n",
      "Iteration 6188, loss = 0.00362718\n",
      "Iteration 6189, loss = 0.00362629\n",
      "Iteration 6190, loss = 0.00362550\n",
      "Iteration 6191, loss = 0.00362491\n",
      "Iteration 6192, loss = 0.00362401\n",
      "Iteration 6193, loss = 0.00362351\n",
      "Iteration 6194, loss = 0.00362241\n",
      "Iteration 6195, loss = 0.00362180\n",
      "Iteration 6196, loss = 0.00362090\n",
      "Iteration 6197, loss = 0.00362006\n",
      "Iteration 6198, loss = 0.00361937\n",
      "Iteration 6199, loss = 0.00361855\n",
      "Iteration 6200, loss = 0.00361767\n",
      "Iteration 6201, loss = 0.00361694\n",
      "Iteration 6202, loss = 0.00361614\n",
      "Iteration 6203, loss = 0.00361534\n",
      "Iteration 6204, loss = 0.00361454\n",
      "Iteration 6205, loss = 0.00361376\n",
      "Iteration 6206, loss = 0.00361299\n",
      "Iteration 6207, loss = 0.00361235\n",
      "Iteration 6208, loss = 0.00361156\n",
      "Iteration 6209, loss = 0.00361089\n",
      "Iteration 6210, loss = 0.00361015\n",
      "Iteration 6211, loss = 0.00360944\n",
      "Iteration 6212, loss = 0.00360877\n",
      "Iteration 6213, loss = 0.00360806\n",
      "Iteration 6214, loss = 0.00360727\n",
      "Iteration 6215, loss = 0.00360654\n",
      "Iteration 6216, loss = 0.00360593\n",
      "Iteration 6217, loss = 0.00360529\n",
      "Iteration 6218, loss = 0.00360446\n",
      "Iteration 6219, loss = 0.00360371\n",
      "Iteration 6220, loss = 0.00360317\n",
      "Iteration 6221, loss = 0.00360255\n",
      "Iteration 6222, loss = 0.00360166\n",
      "Iteration 6223, loss = 0.00360089\n",
      "Iteration 6224, loss = 0.00360003\n",
      "Iteration 6225, loss = 0.00359904\n",
      "Iteration 6226, loss = 0.00359807\n",
      "Iteration 6227, loss = 0.00359761\n",
      "Iteration 6228, loss = 0.00359632\n",
      "Iteration 6229, loss = 0.00359584\n",
      "Iteration 6230, loss = 0.00359470\n",
      "Iteration 6231, loss = 0.00359377\n",
      "Iteration 6232, loss = 0.00359294\n",
      "Iteration 6233, loss = 0.00359210\n",
      "Iteration 6234, loss = 0.00359134\n",
      "Iteration 6235, loss = 0.00359023\n",
      "Iteration 6236, loss = 0.00358946\n",
      "Iteration 6237, loss = 0.00358855\n",
      "Iteration 6238, loss = 0.00358772\n",
      "Iteration 6239, loss = 0.00358697\n",
      "Iteration 6240, loss = 0.00358604\n",
      "Iteration 6241, loss = 0.00358524\n",
      "Iteration 6242, loss = 0.00358453\n",
      "Iteration 6243, loss = 0.00358369\n",
      "Iteration 6244, loss = 0.00358289\n",
      "Iteration 6245, loss = 0.00358220\n",
      "Iteration 6246, loss = 0.00358141\n",
      "Iteration 6247, loss = 0.00358061\n",
      "Iteration 6248, loss = 0.00357997\n",
      "Iteration 6249, loss = 0.00357909\n",
      "Iteration 6250, loss = 0.00357825\n",
      "Iteration 6251, loss = 0.00357751\n",
      "Iteration 6252, loss = 0.00357682\n",
      "Iteration 6253, loss = 0.00357590\n",
      "Iteration 6254, loss = 0.00357503\n",
      "Iteration 6255, loss = 0.00357421\n",
      "Iteration 6256, loss = 0.00357332\n",
      "Iteration 6257, loss = 0.00357280\n",
      "Iteration 6258, loss = 0.00357175\n",
      "Iteration 6259, loss = 0.00357084\n",
      "Iteration 6260, loss = 0.00357004\n",
      "Iteration 6261, loss = 0.00356918\n",
      "Iteration 6262, loss = 0.00356830\n",
      "Iteration 6263, loss = 0.00356739\n",
      "Iteration 6264, loss = 0.00356680\n",
      "Iteration 6265, loss = 0.00356592\n",
      "Iteration 6266, loss = 0.00356550\n",
      "Iteration 6267, loss = 0.00356437\n",
      "Iteration 6268, loss = 0.00356362\n",
      "Iteration 6269, loss = 0.00356283\n",
      "Iteration 6270, loss = 0.00356206\n",
      "Iteration 6271, loss = 0.00356126\n",
      "Iteration 6272, loss = 0.00356044\n",
      "Iteration 6273, loss = 0.00355969\n",
      "Iteration 6274, loss = 0.00355887\n",
      "Iteration 6275, loss = 0.00355811\n",
      "Iteration 6276, loss = 0.00355735\n",
      "Iteration 6277, loss = 0.00355654\n",
      "Iteration 6278, loss = 0.00355573\n",
      "Iteration 6279, loss = 0.00355501\n",
      "Iteration 6280, loss = 0.00355417\n",
      "Iteration 6281, loss = 0.00355345\n",
      "Iteration 6282, loss = 0.00355267\n",
      "Iteration 6283, loss = 0.00355194\n",
      "Iteration 6284, loss = 0.00355158\n",
      "Iteration 6285, loss = 0.00355043\n",
      "Iteration 6286, loss = 0.00354961\n",
      "Iteration 6287, loss = 0.00354935\n",
      "Iteration 6288, loss = 0.00354819\n",
      "Iteration 6289, loss = 0.00354730\n",
      "Iteration 6290, loss = 0.00354634\n",
      "Iteration 6291, loss = 0.00354551\n",
      "Iteration 6292, loss = 0.00354485\n",
      "Iteration 6293, loss = 0.00354444\n",
      "Iteration 6294, loss = 0.00354361\n",
      "Iteration 6295, loss = 0.00354254\n",
      "Iteration 6296, loss = 0.00354183\n",
      "Iteration 6297, loss = 0.00354109\n",
      "Iteration 6298, loss = 0.00354015\n",
      "Iteration 6299, loss = 0.00353941\n",
      "Iteration 6300, loss = 0.00353857\n",
      "Iteration 6301, loss = 0.00353769\n",
      "Iteration 6302, loss = 0.00353688\n",
      "Iteration 6303, loss = 0.00353617\n",
      "Iteration 6304, loss = 0.00353519\n",
      "Iteration 6305, loss = 0.00353465\n",
      "Iteration 6306, loss = 0.00353359\n",
      "Iteration 6307, loss = 0.00353272\n",
      "Iteration 6308, loss = 0.00353202\n",
      "Iteration 6309, loss = 0.00353103\n",
      "Iteration 6310, loss = 0.00353036\n",
      "Iteration 6311, loss = 0.00352943\n",
      "Iteration 6312, loss = 0.00352870\n",
      "Iteration 6313, loss = 0.00352814\n",
      "Iteration 6314, loss = 0.00352711\n",
      "Iteration 6315, loss = 0.00352675\n",
      "Iteration 6316, loss = 0.00352547\n",
      "Iteration 6317, loss = 0.00352451\n",
      "Iteration 6318, loss = 0.00352375\n",
      "Iteration 6319, loss = 0.00352304\n",
      "Iteration 6320, loss = 0.00352210\n",
      "Iteration 6321, loss = 0.00352121\n",
      "Iteration 6322, loss = 0.00352041\n",
      "Iteration 6323, loss = 0.00351940\n",
      "Iteration 6324, loss = 0.00351879\n",
      "Iteration 6325, loss = 0.00351803\n",
      "Iteration 6326, loss = 0.00351699\n",
      "Iteration 6327, loss = 0.00351634\n",
      "Iteration 6328, loss = 0.00351546\n",
      "Iteration 6329, loss = 0.00351462\n",
      "Iteration 6330, loss = 0.00351387\n",
      "Iteration 6331, loss = 0.00351300\n",
      "Iteration 6332, loss = 0.00351213\n",
      "Iteration 6333, loss = 0.00351131\n",
      "Iteration 6334, loss = 0.00351064\n",
      "Iteration 6335, loss = 0.00350974\n",
      "Iteration 6336, loss = 0.00350905\n",
      "Iteration 6337, loss = 0.00350824\n",
      "Iteration 6338, loss = 0.00350749\n",
      "Iteration 6339, loss = 0.00350686\n",
      "Iteration 6340, loss = 0.00350593\n",
      "Iteration 6341, loss = 0.00350521\n",
      "Iteration 6342, loss = 0.00350456\n",
      "Iteration 6343, loss = 0.00350376\n",
      "Iteration 6344, loss = 0.00350305\n",
      "Iteration 6345, loss = 0.00350240\n",
      "Iteration 6346, loss = 0.00350181\n",
      "Iteration 6347, loss = 0.00350078\n",
      "Iteration 6348, loss = 0.00350011\n",
      "Iteration 6349, loss = 0.00349941\n",
      "Iteration 6350, loss = 0.00349893\n",
      "Iteration 6351, loss = 0.00349820\n",
      "Iteration 6352, loss = 0.00349738\n",
      "Iteration 6353, loss = 0.00349667\n",
      "Iteration 6354, loss = 0.00349601\n",
      "Iteration 6355, loss = 0.00349520\n",
      "Iteration 6356, loss = 0.00349439\n",
      "Iteration 6357, loss = 0.00349375\n",
      "Iteration 6358, loss = 0.00349291\n",
      "Iteration 6359, loss = 0.00349217\n",
      "Iteration 6360, loss = 0.00349137\n",
      "Iteration 6361, loss = 0.00349060\n",
      "Iteration 6362, loss = 0.00348993\n",
      "Iteration 6363, loss = 0.00348922\n",
      "Iteration 6364, loss = 0.00348846\n",
      "Iteration 6365, loss = 0.00348788\n",
      "Iteration 6366, loss = 0.00348707\n",
      "Iteration 6367, loss = 0.00348625\n",
      "Iteration 6368, loss = 0.00348557\n",
      "Iteration 6369, loss = 0.00348486\n",
      "Iteration 6370, loss = 0.00348419\n",
      "Iteration 6371, loss = 0.00348371\n",
      "Iteration 6372, loss = 0.00348289\n",
      "Iteration 6373, loss = 0.00348216\n",
      "Iteration 6374, loss = 0.00348138\n",
      "Iteration 6375, loss = 0.00348102\n",
      "Iteration 6376, loss = 0.00348017\n",
      "Iteration 6377, loss = 0.00347952\n",
      "Iteration 6378, loss = 0.00347869\n",
      "Iteration 6379, loss = 0.00347788\n",
      "Iteration 6380, loss = 0.00347714\n",
      "Iteration 6381, loss = 0.00347647\n",
      "Iteration 6382, loss = 0.00347577\n",
      "Iteration 6383, loss = 0.00347489\n",
      "Iteration 6384, loss = 0.00347420\n",
      "Iteration 6385, loss = 0.00347345\n",
      "Iteration 6386, loss = 0.00347277\n",
      "Iteration 6387, loss = 0.00347212\n",
      "Iteration 6388, loss = 0.00347138\n",
      "Iteration 6389, loss = 0.00347051\n",
      "Iteration 6390, loss = 0.00346999\n",
      "Iteration 6391, loss = 0.00346926\n",
      "Iteration 6392, loss = 0.00346835\n",
      "Iteration 6393, loss = 0.00346747\n",
      "Iteration 6394, loss = 0.00346660\n",
      "Iteration 6395, loss = 0.00346575\n",
      "Iteration 6396, loss = 0.00346495\n",
      "Iteration 6397, loss = 0.00346410\n",
      "Iteration 6398, loss = 0.00346358\n",
      "Iteration 6399, loss = 0.00346270\n",
      "Iteration 6400, loss = 0.00346207\n",
      "Iteration 6401, loss = 0.00346136\n",
      "Iteration 6402, loss = 0.00346076\n",
      "Iteration 6403, loss = 0.00345997\n",
      "Iteration 6404, loss = 0.00345950\n",
      "Iteration 6405, loss = 0.00345883\n",
      "Iteration 6406, loss = 0.00345813\n",
      "Iteration 6407, loss = 0.00345747\n",
      "Iteration 6408, loss = 0.00345714\n",
      "Iteration 6409, loss = 0.00345629\n",
      "Iteration 6410, loss = 0.00345568\n",
      "Iteration 6411, loss = 0.00345496\n",
      "Iteration 6412, loss = 0.00345425\n",
      "Iteration 6413, loss = 0.00345367\n",
      "Iteration 6414, loss = 0.00345300\n",
      "Iteration 6415, loss = 0.00345259\n",
      "Iteration 6416, loss = 0.00345164\n",
      "Iteration 6417, loss = 0.00345099\n",
      "Iteration 6418, loss = 0.00345016\n",
      "Iteration 6419, loss = 0.00344979\n",
      "Iteration 6420, loss = 0.00344859\n",
      "Iteration 6421, loss = 0.00344764\n",
      "Iteration 6422, loss = 0.00344707\n",
      "Iteration 6423, loss = 0.00344665\n",
      "Iteration 6424, loss = 0.00344530\n",
      "Iteration 6425, loss = 0.00344459\n",
      "Iteration 6426, loss = 0.00344367\n",
      "Iteration 6427, loss = 0.00344283\n",
      "Iteration 6428, loss = 0.00344194\n",
      "Iteration 6429, loss = 0.00344172\n",
      "Iteration 6430, loss = 0.00344052\n",
      "Iteration 6431, loss = 0.00343980\n",
      "Iteration 6432, loss = 0.00343883\n",
      "Iteration 6433, loss = 0.00343799\n",
      "Iteration 6434, loss = 0.00343719\n",
      "Iteration 6435, loss = 0.00343619\n",
      "Iteration 6436, loss = 0.00343539\n",
      "Iteration 6437, loss = 0.00343419\n",
      "Iteration 6438, loss = 0.00343369\n",
      "Iteration 6439, loss = 0.00343255\n",
      "Iteration 6440, loss = 0.00343194\n",
      "Iteration 6441, loss = 0.00343100\n",
      "Iteration 6442, loss = 0.00343022\n",
      "Iteration 6443, loss = 0.00342919\n",
      "Iteration 6444, loss = 0.00342840\n",
      "Iteration 6445, loss = 0.00342752\n",
      "Iteration 6446, loss = 0.00342688\n",
      "Iteration 6447, loss = 0.00342594\n",
      "Iteration 6448, loss = 0.00342505\n",
      "Iteration 6449, loss = 0.00342452\n",
      "Iteration 6450, loss = 0.00342366\n",
      "Iteration 6451, loss = 0.00342282\n",
      "Iteration 6452, loss = 0.00342218\n",
      "Iteration 6453, loss = 0.00342147\n",
      "Iteration 6454, loss = 0.00342081\n",
      "Iteration 6455, loss = 0.00342008\n",
      "Iteration 6456, loss = 0.00341946\n",
      "Iteration 6457, loss = 0.00341876\n",
      "Iteration 6458, loss = 0.00341809\n",
      "Iteration 6459, loss = 0.00341740\n",
      "Iteration 6460, loss = 0.00341677\n",
      "Iteration 6461, loss = 0.00341608\n",
      "Iteration 6462, loss = 0.00341531\n",
      "Iteration 6463, loss = 0.00341460\n",
      "Iteration 6464, loss = 0.00341383\n",
      "Iteration 6465, loss = 0.00341314\n",
      "Iteration 6466, loss = 0.00341271\n",
      "Iteration 6467, loss = 0.00341202\n",
      "Iteration 6468, loss = 0.00341117\n",
      "Iteration 6469, loss = 0.00341046\n",
      "Iteration 6470, loss = 0.00340961\n",
      "Iteration 6471, loss = 0.00340894\n",
      "Iteration 6472, loss = 0.00340838\n",
      "Iteration 6473, loss = 0.00340743\n",
      "Iteration 6474, loss = 0.00340670\n",
      "Iteration 6475, loss = 0.00340608\n",
      "Iteration 6476, loss = 0.00340539\n",
      "Iteration 6477, loss = 0.00340460\n",
      "Iteration 6478, loss = 0.00340380\n",
      "Iteration 6479, loss = 0.00340316\n",
      "Iteration 6480, loss = 0.00340239\n",
      "Iteration 6481, loss = 0.00340170\n",
      "Iteration 6482, loss = 0.00340112\n",
      "Iteration 6483, loss = 0.00340039\n",
      "Iteration 6484, loss = 0.00339956\n",
      "Iteration 6485, loss = 0.00339879\n",
      "Iteration 6486, loss = 0.00339815\n",
      "Iteration 6487, loss = 0.00339737\n",
      "Iteration 6488, loss = 0.00339662\n",
      "Iteration 6489, loss = 0.00339616\n",
      "Iteration 6490, loss = 0.00339524\n",
      "Iteration 6491, loss = 0.00339443\n",
      "Iteration 6492, loss = 0.00339341\n",
      "Iteration 6493, loss = 0.00339256\n",
      "Iteration 6494, loss = 0.00339221\n",
      "Iteration 6495, loss = 0.00339122\n",
      "Iteration 6496, loss = 0.00339028\n",
      "Iteration 6497, loss = 0.00338956\n",
      "Iteration 6498, loss = 0.00338906\n",
      "Iteration 6499, loss = 0.00338799\n",
      "Iteration 6500, loss = 0.00338721\n",
      "Iteration 6501, loss = 0.00338699\n",
      "Iteration 6502, loss = 0.00338592\n",
      "Iteration 6503, loss = 0.00338517\n",
      "Iteration 6504, loss = 0.00338448\n",
      "Iteration 6505, loss = 0.00338381\n",
      "Iteration 6506, loss = 0.00338313\n",
      "Iteration 6507, loss = 0.00338243\n",
      "Iteration 6508, loss = 0.00338167\n",
      "Iteration 6509, loss = 0.00338117\n",
      "Iteration 6510, loss = 0.00338041\n",
      "Iteration 6511, loss = 0.00337982\n",
      "Iteration 6512, loss = 0.00337919\n",
      "Iteration 6513, loss = 0.00337850\n",
      "Iteration 6514, loss = 0.00337772\n",
      "Iteration 6515, loss = 0.00337699\n",
      "Iteration 6516, loss = 0.00337646\n",
      "Iteration 6517, loss = 0.00337576\n",
      "Iteration 6518, loss = 0.00337499\n",
      "Iteration 6519, loss = 0.00337437\n",
      "Iteration 6520, loss = 0.00337367\n",
      "Iteration 6521, loss = 0.00337290\n",
      "Iteration 6522, loss = 0.00337210\n",
      "Iteration 6523, loss = 0.00337182\n",
      "Iteration 6524, loss = 0.00337071\n",
      "Iteration 6525, loss = 0.00336996\n",
      "Iteration 6526, loss = 0.00336936\n",
      "Iteration 6527, loss = 0.00336854\n",
      "Iteration 6528, loss = 0.00336781\n",
      "Iteration 6529, loss = 0.00336710\n",
      "Iteration 6530, loss = 0.00336648\n",
      "Iteration 6531, loss = 0.00336569\n",
      "Iteration 6532, loss = 0.00336485\n",
      "Iteration 6533, loss = 0.00336419\n",
      "Iteration 6534, loss = 0.00336350\n",
      "Iteration 6535, loss = 0.00336271\n",
      "Iteration 6536, loss = 0.00336213\n",
      "Iteration 6537, loss = 0.00336142\n",
      "Iteration 6538, loss = 0.00336065\n",
      "Iteration 6539, loss = 0.00335980\n",
      "Iteration 6540, loss = 0.00335909\n",
      "Iteration 6541, loss = 0.00335841\n",
      "Iteration 6542, loss = 0.00335786\n",
      "Iteration 6543, loss = 0.00335703\n",
      "Iteration 6544, loss = 0.00335640\n",
      "Iteration 6545, loss = 0.00335564\n",
      "Iteration 6546, loss = 0.00335504\n",
      "Iteration 6547, loss = 0.00335426\n",
      "Iteration 6548, loss = 0.00335348\n",
      "Iteration 6549, loss = 0.00335276\n",
      "Iteration 6550, loss = 0.00335205\n",
      "Iteration 6551, loss = 0.00335135\n",
      "Iteration 6552, loss = 0.00335059\n",
      "Iteration 6553, loss = 0.00334993\n",
      "Iteration 6554, loss = 0.00334917\n",
      "Iteration 6555, loss = 0.00334845\n",
      "Iteration 6556, loss = 0.00334805\n",
      "Iteration 6557, loss = 0.00334702\n",
      "Iteration 6558, loss = 0.00334622\n",
      "Iteration 6559, loss = 0.00334557\n",
      "Iteration 6560, loss = 0.00334467\n",
      "Iteration 6561, loss = 0.00334389\n",
      "Iteration 6562, loss = 0.00334320\n",
      "Iteration 6563, loss = 0.00334237\n",
      "Iteration 6564, loss = 0.00334211\n",
      "Iteration 6565, loss = 0.00334087\n",
      "Iteration 6566, loss = 0.00333999\n",
      "Iteration 6567, loss = 0.00333950\n",
      "Iteration 6568, loss = 0.00333856\n",
      "Iteration 6569, loss = 0.00333778\n",
      "Iteration 6570, loss = 0.00333709\n",
      "Iteration 6571, loss = 0.00333636\n",
      "Iteration 6572, loss = 0.00333578\n",
      "Iteration 6573, loss = 0.00333501\n",
      "Iteration 6574, loss = 0.00333411\n",
      "Iteration 6575, loss = 0.00333344\n",
      "Iteration 6576, loss = 0.00333270\n",
      "Iteration 6577, loss = 0.00333197\n",
      "Iteration 6578, loss = 0.00333120\n",
      "Iteration 6579, loss = 0.00333048\n",
      "Iteration 6580, loss = 0.00332988\n",
      "Iteration 6581, loss = 0.00332917\n",
      "Iteration 6582, loss = 0.00332833\n",
      "Iteration 6583, loss = 0.00332765\n",
      "Iteration 6584, loss = 0.00332687\n",
      "Iteration 6585, loss = 0.00332615\n",
      "Iteration 6586, loss = 0.00332529\n",
      "Iteration 6587, loss = 0.00332467\n",
      "Iteration 6588, loss = 0.00332405\n",
      "Iteration 6589, loss = 0.00332323\n",
      "Iteration 6590, loss = 0.00332253\n",
      "Iteration 6591, loss = 0.00332188\n",
      "Iteration 6592, loss = 0.00332115\n",
      "Iteration 6593, loss = 0.00332058\n",
      "Iteration 6594, loss = 0.00331980\n",
      "Iteration 6595, loss = 0.00331922\n",
      "Iteration 6596, loss = 0.00331850\n",
      "Iteration 6597, loss = 0.00331780\n",
      "Iteration 6598, loss = 0.00331715\n",
      "Iteration 6599, loss = 0.00331626\n",
      "Iteration 6600, loss = 0.00331561\n",
      "Iteration 6601, loss = 0.00331497\n",
      "Iteration 6602, loss = 0.00331413\n",
      "Iteration 6603, loss = 0.00331342\n",
      "Iteration 6604, loss = 0.00331261\n",
      "Iteration 6605, loss = 0.00331210\n",
      "Iteration 6606, loss = 0.00331127\n",
      "Iteration 6607, loss = 0.00331053\n",
      "Iteration 6608, loss = 0.00330980\n",
      "Iteration 6609, loss = 0.00330906\n",
      "Iteration 6610, loss = 0.00330834\n",
      "Iteration 6611, loss = 0.00330792\n",
      "Iteration 6612, loss = 0.00330716\n",
      "Iteration 6613, loss = 0.00330634\n",
      "Iteration 6614, loss = 0.00330553\n",
      "Iteration 6615, loss = 0.00330486\n",
      "Iteration 6616, loss = 0.00330417\n",
      "Iteration 6617, loss = 0.00330351\n",
      "Iteration 6618, loss = 0.00330277\n",
      "Iteration 6619, loss = 0.00330218\n",
      "Iteration 6620, loss = 0.00330130\n",
      "Iteration 6621, loss = 0.00330052\n",
      "Iteration 6622, loss = 0.00329981\n",
      "Iteration 6623, loss = 0.00329914\n",
      "Iteration 6624, loss = 0.00329834\n",
      "Iteration 6625, loss = 0.00329768\n",
      "Iteration 6626, loss = 0.00329691\n",
      "Iteration 6627, loss = 0.00329638\n",
      "Iteration 6628, loss = 0.00329557\n",
      "Iteration 6629, loss = 0.00329490\n",
      "Iteration 6630, loss = 0.00329432\n",
      "Iteration 6631, loss = 0.00329356\n",
      "Iteration 6632, loss = 0.00329324\n",
      "Iteration 6633, loss = 0.00329226\n",
      "Iteration 6634, loss = 0.00329148\n",
      "Iteration 6635, loss = 0.00329104\n",
      "Iteration 6636, loss = 0.00329012\n",
      "Iteration 6637, loss = 0.00328991\n",
      "Iteration 6638, loss = 0.00328885\n",
      "Iteration 6639, loss = 0.00328820\n",
      "Iteration 6640, loss = 0.00328737\n",
      "Iteration 6641, loss = 0.00328670\n",
      "Iteration 6642, loss = 0.00328605\n",
      "Iteration 6643, loss = 0.00328532\n",
      "Iteration 6644, loss = 0.00328463\n",
      "Iteration 6645, loss = 0.00328397\n",
      "Iteration 6646, loss = 0.00328348\n",
      "Iteration 6647, loss = 0.00328272\n",
      "Iteration 6648, loss = 0.00328205\n",
      "Iteration 6649, loss = 0.00328131\n",
      "Iteration 6650, loss = 0.00328067\n",
      "Iteration 6651, loss = 0.00327998\n",
      "Iteration 6652, loss = 0.00327923\n",
      "Iteration 6653, loss = 0.00327878\n",
      "Iteration 6654, loss = 0.00327808\n",
      "Iteration 6655, loss = 0.00327748\n",
      "Iteration 6656, loss = 0.00327675\n",
      "Iteration 6657, loss = 0.00327619\n",
      "Iteration 6658, loss = 0.00327574\n",
      "Iteration 6659, loss = 0.00327487\n",
      "Iteration 6660, loss = 0.00327424\n",
      "Iteration 6661, loss = 0.00327378\n",
      "Iteration 6662, loss = 0.00327280\n",
      "Iteration 6663, loss = 0.00327218\n",
      "Iteration 6664, loss = 0.00327158\n",
      "Iteration 6665, loss = 0.00327112\n",
      "Iteration 6666, loss = 0.00327021\n",
      "Iteration 6667, loss = 0.00326949\n",
      "Iteration 6668, loss = 0.00326889\n",
      "Iteration 6669, loss = 0.00326812\n",
      "Iteration 6670, loss = 0.00326753\n",
      "Iteration 6671, loss = 0.00326696\n",
      "Iteration 6672, loss = 0.00326624\n",
      "Iteration 6673, loss = 0.00326547\n",
      "Iteration 6674, loss = 0.00326490\n",
      "Iteration 6675, loss = 0.00326428\n",
      "Iteration 6676, loss = 0.00326359\n",
      "Iteration 6677, loss = 0.00326290\n",
      "Iteration 6678, loss = 0.00326224\n",
      "Iteration 6679, loss = 0.00326172\n",
      "Iteration 6680, loss = 0.00326090\n",
      "Iteration 6681, loss = 0.00326024\n",
      "Iteration 6682, loss = 0.00325956\n",
      "Iteration 6683, loss = 0.00325890\n",
      "Iteration 6684, loss = 0.00325824\n",
      "Iteration 6685, loss = 0.00325754\n",
      "Iteration 6686, loss = 0.00325690\n",
      "Iteration 6687, loss = 0.00325655\n",
      "Iteration 6688, loss = 0.00325580\n",
      "Iteration 6689, loss = 0.00325498\n",
      "Iteration 6690, loss = 0.00325434\n",
      "Iteration 6691, loss = 0.00325367\n",
      "Iteration 6692, loss = 0.00325312\n",
      "Iteration 6693, loss = 0.00325242\n",
      "Iteration 6694, loss = 0.00325184\n",
      "Iteration 6695, loss = 0.00325117\n",
      "Iteration 6696, loss = 0.00325052\n",
      "Iteration 6697, loss = 0.00324992\n",
      "Iteration 6698, loss = 0.00324948\n",
      "Iteration 6699, loss = 0.00324867\n",
      "Iteration 6700, loss = 0.00324790\n",
      "Iteration 6701, loss = 0.00324712\n",
      "Iteration 6702, loss = 0.00324651\n",
      "Iteration 6703, loss = 0.00324583\n",
      "Iteration 6704, loss = 0.00324519\n",
      "Iteration 6705, loss = 0.00324447\n",
      "Iteration 6706, loss = 0.00324374\n",
      "Iteration 6707, loss = 0.00324319\n",
      "Iteration 6708, loss = 0.00324241\n",
      "Iteration 6709, loss = 0.00324173\n",
      "Iteration 6710, loss = 0.00324103\n",
      "Iteration 6711, loss = 0.00324054\n",
      "Iteration 6712, loss = 0.00323966\n",
      "Iteration 6713, loss = 0.00323893\n",
      "Iteration 6714, loss = 0.00323826\n",
      "Iteration 6715, loss = 0.00323759\n",
      "Iteration 6716, loss = 0.00323698\n",
      "Iteration 6717, loss = 0.00323642\n",
      "Iteration 6718, loss = 0.00323568\n",
      "Iteration 6719, loss = 0.00323511\n",
      "Iteration 6720, loss = 0.00323447\n",
      "Iteration 6721, loss = 0.00323373\n",
      "Iteration 6722, loss = 0.00323301\n",
      "Iteration 6723, loss = 0.00323230\n",
      "Iteration 6724, loss = 0.00323170\n",
      "Iteration 6725, loss = 0.00323117\n",
      "Iteration 6726, loss = 0.00323033\n",
      "Iteration 6727, loss = 0.00322966\n",
      "Iteration 6728, loss = 0.00322893\n",
      "Iteration 6729, loss = 0.00322829\n",
      "Iteration 6730, loss = 0.00322756\n",
      "Iteration 6731, loss = 0.00322692\n",
      "Iteration 6732, loss = 0.00322625\n",
      "Iteration 6733, loss = 0.00322559\n",
      "Iteration 6734, loss = 0.00322477\n",
      "Iteration 6735, loss = 0.00322409\n",
      "Iteration 6736, loss = 0.00322330\n",
      "Iteration 6737, loss = 0.00322295\n",
      "Iteration 6738, loss = 0.00322218\n",
      "Iteration 6739, loss = 0.00322136\n",
      "Iteration 6740, loss = 0.00322073\n",
      "Iteration 6741, loss = 0.00322008\n",
      "Iteration 6742, loss = 0.00321937\n",
      "Iteration 6743, loss = 0.00321872\n",
      "Iteration 6744, loss = 0.00321813\n",
      "Iteration 6745, loss = 0.00321752\n",
      "Iteration 6746, loss = 0.00321726\n",
      "Iteration 6747, loss = 0.00321651\n",
      "Iteration 6748, loss = 0.00321583\n",
      "Iteration 6749, loss = 0.00321498\n",
      "Iteration 6750, loss = 0.00321419\n",
      "Iteration 6751, loss = 0.00321333\n",
      "Iteration 6752, loss = 0.00321264\n",
      "Iteration 6753, loss = 0.00321224\n",
      "Iteration 6754, loss = 0.00321125\n",
      "Iteration 6755, loss = 0.00321043\n",
      "Iteration 6756, loss = 0.00320980\n",
      "Iteration 6757, loss = 0.00320918\n",
      "Iteration 6758, loss = 0.00320848\n",
      "Iteration 6759, loss = 0.00320787\n",
      "Iteration 6760, loss = 0.00320725\n",
      "Iteration 6761, loss = 0.00320663\n",
      "Iteration 6762, loss = 0.00320609\n",
      "Iteration 6763, loss = 0.00320537\n",
      "Iteration 6764, loss = 0.00320467\n",
      "Iteration 6765, loss = 0.00320407\n",
      "Iteration 6766, loss = 0.00320342\n",
      "Iteration 6767, loss = 0.00320268\n",
      "Iteration 6768, loss = 0.00320200\n",
      "Iteration 6769, loss = 0.00320180\n",
      "Iteration 6770, loss = 0.00320073\n",
      "Iteration 6771, loss = 0.00320003\n",
      "Iteration 6772, loss = 0.00319949\n",
      "Iteration 6773, loss = 0.00319874\n",
      "Iteration 6774, loss = 0.00319814\n",
      "Iteration 6775, loss = 0.00319766\n",
      "Iteration 6776, loss = 0.00319683\n",
      "Iteration 6777, loss = 0.00319616\n",
      "Iteration 6778, loss = 0.00319546\n",
      "Iteration 6779, loss = 0.00319488\n",
      "Iteration 6780, loss = 0.00319430\n",
      "Iteration 6781, loss = 0.00319356\n",
      "Iteration 6782, loss = 0.00319291\n",
      "Iteration 6783, loss = 0.00319227\n",
      "Iteration 6784, loss = 0.00319165\n",
      "Iteration 6785, loss = 0.00319111\n",
      "Iteration 6786, loss = 0.00319038\n",
      "Iteration 6787, loss = 0.00318974\n",
      "Iteration 6788, loss = 0.00318923\n",
      "Iteration 6789, loss = 0.00318865\n",
      "Iteration 6790, loss = 0.00318771\n",
      "Iteration 6791, loss = 0.00318696\n",
      "Iteration 6792, loss = 0.00318633\n",
      "Iteration 6793, loss = 0.00318568\n",
      "Iteration 6794, loss = 0.00318511\n",
      "Iteration 6795, loss = 0.00318441\n",
      "Iteration 6796, loss = 0.00318372\n",
      "Iteration 6797, loss = 0.00318314\n",
      "Iteration 6798, loss = 0.00318239\n",
      "Iteration 6799, loss = 0.00318179\n",
      "Iteration 6800, loss = 0.00318114\n",
      "Iteration 6801, loss = 0.00318051\n",
      "Iteration 6802, loss = 0.00317985\n",
      "Iteration 6803, loss = 0.00317925\n",
      "Iteration 6804, loss = 0.00317867\n",
      "Iteration 6805, loss = 0.00317801\n",
      "Iteration 6806, loss = 0.00317749\n",
      "Iteration 6807, loss = 0.00317672\n",
      "Iteration 6808, loss = 0.00317662\n",
      "Iteration 6809, loss = 0.00317567\n",
      "Iteration 6810, loss = 0.00317482\n",
      "Iteration 6811, loss = 0.00317431\n",
      "Iteration 6812, loss = 0.00317344\n",
      "Iteration 6813, loss = 0.00317280\n",
      "Iteration 6814, loss = 0.00317215\n",
      "Iteration 6815, loss = 0.00317158\n",
      "Iteration 6816, loss = 0.00317084\n",
      "Iteration 6817, loss = 0.00316996\n",
      "Iteration 6818, loss = 0.00316913\n",
      "Iteration 6819, loss = 0.00316850\n",
      "Iteration 6820, loss = 0.00316824\n",
      "Iteration 6821, loss = 0.00316705\n",
      "Iteration 6822, loss = 0.00316649\n",
      "Iteration 6823, loss = 0.00316564\n",
      "Iteration 6824, loss = 0.00316501\n",
      "Iteration 6825, loss = 0.00316436\n",
      "Iteration 6826, loss = 0.00316369\n",
      "Iteration 6827, loss = 0.00316295\n",
      "Iteration 6828, loss = 0.00316239\n",
      "Iteration 6829, loss = 0.00316156\n",
      "Iteration 6830, loss = 0.00316083\n",
      "Iteration 6831, loss = 0.00316023\n",
      "Iteration 6832, loss = 0.00315942\n",
      "Iteration 6833, loss = 0.00315866\n",
      "Iteration 6834, loss = 0.00315802\n",
      "Iteration 6835, loss = 0.00315724\n",
      "Iteration 6836, loss = 0.00315658\n",
      "Iteration 6837, loss = 0.00315594\n",
      "Iteration 6838, loss = 0.00315545\n",
      "Iteration 6839, loss = 0.00315443\n",
      "Iteration 6840, loss = 0.00315406\n",
      "Iteration 6841, loss = 0.00315340\n",
      "Iteration 6842, loss = 0.00315271\n",
      "Iteration 6843, loss = 0.00315188\n",
      "Iteration 6844, loss = 0.00315136\n",
      "Iteration 6845, loss = 0.00315061\n",
      "Iteration 6846, loss = 0.00314985\n",
      "Iteration 6847, loss = 0.00314920\n",
      "Iteration 6848, loss = 0.00314863\n",
      "Iteration 6849, loss = 0.00314784\n",
      "Iteration 6850, loss = 0.00314717\n",
      "Iteration 6851, loss = 0.00314655\n",
      "Iteration 6852, loss = 0.00314587\n",
      "Iteration 6853, loss = 0.00314524\n",
      "Iteration 6854, loss = 0.00314463\n",
      "Iteration 6855, loss = 0.00314397\n",
      "Iteration 6856, loss = 0.00314340\n",
      "Iteration 6857, loss = 0.00314265\n",
      "Iteration 6858, loss = 0.00314204\n",
      "Iteration 6859, loss = 0.00314137\n",
      "Iteration 6860, loss = 0.00314082\n",
      "Iteration 6861, loss = 0.00314007\n",
      "Iteration 6862, loss = 0.00313953\n",
      "Iteration 6863, loss = 0.00313883\n",
      "Iteration 6864, loss = 0.00313807\n",
      "Iteration 6865, loss = 0.00313746\n",
      "Iteration 6866, loss = 0.00313684\n",
      "Iteration 6867, loss = 0.00313619\n",
      "Iteration 6868, loss = 0.00313563\n",
      "Iteration 6869, loss = 0.00313493\n",
      "Iteration 6870, loss = 0.00313440\n",
      "Iteration 6871, loss = 0.00313392\n",
      "Iteration 6872, loss = 0.00313324\n",
      "Iteration 6873, loss = 0.00313249\n",
      "Iteration 6874, loss = 0.00313189\n",
      "Iteration 6875, loss = 0.00313125\n",
      "Iteration 6876, loss = 0.00313077\n",
      "Iteration 6877, loss = 0.00313011\n",
      "Iteration 6878, loss = 0.00312950\n",
      "Iteration 6879, loss = 0.00312891\n",
      "Iteration 6880, loss = 0.00312837\n",
      "Iteration 6881, loss = 0.00312781\n",
      "Iteration 6882, loss = 0.00312731\n",
      "Iteration 6883, loss = 0.00312666\n",
      "Iteration 6884, loss = 0.00312608\n",
      "Iteration 6885, loss = 0.00312582\n",
      "Iteration 6886, loss = 0.00312502\n",
      "Iteration 6887, loss = 0.00312452\n",
      "Iteration 6888, loss = 0.00312393\n",
      "Iteration 6889, loss = 0.00312321\n",
      "Iteration 6890, loss = 0.00312265\n",
      "Iteration 6891, loss = 0.00312186\n",
      "Iteration 6892, loss = 0.00312117\n",
      "Iteration 6893, loss = 0.00312042\n",
      "Iteration 6894, loss = 0.00311992\n",
      "Iteration 6895, loss = 0.00311914\n",
      "Iteration 6896, loss = 0.00311858\n",
      "Iteration 6897, loss = 0.00311806\n",
      "Iteration 6898, loss = 0.00311727\n",
      "Iteration 6899, loss = 0.00311657\n",
      "Iteration 6900, loss = 0.00311582\n",
      "Iteration 6901, loss = 0.00311504\n",
      "Iteration 6902, loss = 0.00311502\n",
      "Iteration 6903, loss = 0.00311410\n",
      "Iteration 6904, loss = 0.00311342\n",
      "Iteration 6905, loss = 0.00311289\n",
      "Iteration 6906, loss = 0.00311212\n",
      "Iteration 6907, loss = 0.00311167\n",
      "Iteration 6908, loss = 0.00311095\n",
      "Iteration 6909, loss = 0.00311036\n",
      "Iteration 6910, loss = 0.00310989\n",
      "Iteration 6911, loss = 0.00310927\n",
      "Iteration 6912, loss = 0.00310855\n",
      "Iteration 6913, loss = 0.00310792\n",
      "Iteration 6914, loss = 0.00310727\n",
      "Iteration 6915, loss = 0.00310673\n",
      "Iteration 6916, loss = 0.00310603\n",
      "Iteration 6917, loss = 0.00310570\n",
      "Iteration 6918, loss = 0.00310492\n",
      "Iteration 6919, loss = 0.00310434\n",
      "Iteration 6920, loss = 0.00310355\n",
      "Iteration 6921, loss = 0.00310292\n",
      "Iteration 6922, loss = 0.00310229\n",
      "Iteration 6923, loss = 0.00310158\n",
      "Iteration 6924, loss = 0.00310089\n",
      "Iteration 6925, loss = 0.00310020\n",
      "Iteration 6926, loss = 0.00309945\n",
      "Iteration 6927, loss = 0.00309870\n",
      "Iteration 6928, loss = 0.00309826\n",
      "Iteration 6929, loss = 0.00309740\n",
      "Iteration 6930, loss = 0.00309683\n",
      "Iteration 6931, loss = 0.00309617\n",
      "Iteration 6932, loss = 0.00309548\n",
      "Iteration 6933, loss = 0.00309491\n",
      "Iteration 6934, loss = 0.00309423\n",
      "Iteration 6935, loss = 0.00309361\n",
      "Iteration 6936, loss = 0.00309299\n",
      "Iteration 6937, loss = 0.00309238\n",
      "Iteration 6938, loss = 0.00309176\n",
      "Iteration 6939, loss = 0.00309119\n",
      "Iteration 6940, loss = 0.00309051\n",
      "Iteration 6941, loss = 0.00308995\n",
      "Iteration 6942, loss = 0.00308935\n",
      "Iteration 6943, loss = 0.00308879\n",
      "Iteration 6944, loss = 0.00308855\n",
      "Iteration 6945, loss = 0.00308766\n",
      "Iteration 6946, loss = 0.00308726\n",
      "Iteration 6947, loss = 0.00308659\n",
      "Iteration 6948, loss = 0.00308589\n",
      "Iteration 6949, loss = 0.00308513\n",
      "Iteration 6950, loss = 0.00308470\n",
      "Iteration 6951, loss = 0.00308396\n",
      "Iteration 6952, loss = 0.00308344\n",
      "Iteration 6953, loss = 0.00308279\n",
      "Iteration 6954, loss = 0.00308225\n",
      "Iteration 6955, loss = 0.00308172\n",
      "Iteration 6956, loss = 0.00308103\n",
      "Iteration 6957, loss = 0.00308043\n",
      "Iteration 6958, loss = 0.00307981\n",
      "Iteration 6959, loss = 0.00307930\n",
      "Iteration 6960, loss = 0.00307857\n",
      "Iteration 6961, loss = 0.00307798\n",
      "Iteration 6962, loss = 0.00307738\n",
      "Iteration 6963, loss = 0.00307676\n",
      "Iteration 6964, loss = 0.00307618\n",
      "Iteration 6965, loss = 0.00307582\n",
      "Iteration 6966, loss = 0.00307507\n",
      "Iteration 6967, loss = 0.00307449\n",
      "Iteration 6968, loss = 0.00307383\n",
      "Iteration 6969, loss = 0.00307378\n",
      "Iteration 6970, loss = 0.00307300\n",
      "Iteration 6971, loss = 0.00307230\n",
      "Iteration 6972, loss = 0.00307168\n",
      "Iteration 6973, loss = 0.00307118\n",
      "Iteration 6974, loss = 0.00307066\n",
      "Iteration 6975, loss = 0.00307000\n",
      "Iteration 6976, loss = 0.00306944\n",
      "Iteration 6977, loss = 0.00306875\n",
      "Iteration 6978, loss = 0.00306806\n",
      "Iteration 6979, loss = 0.00306739\n",
      "Iteration 6980, loss = 0.00306688\n",
      "Iteration 6981, loss = 0.00306614\n",
      "Iteration 6982, loss = 0.00306542\n",
      "Iteration 6983, loss = 0.00306473\n",
      "Iteration 6984, loss = 0.00306416\n",
      "Iteration 6985, loss = 0.00306351\n",
      "Iteration 6986, loss = 0.00306271\n",
      "Iteration 6987, loss = 0.00306226\n",
      "Iteration 6988, loss = 0.00306139\n",
      "Iteration 6989, loss = 0.00306078\n",
      "Iteration 6990, loss = 0.00306011\n",
      "Iteration 6991, loss = 0.00305941\n",
      "Iteration 6992, loss = 0.00305876\n",
      "Iteration 6993, loss = 0.00305812\n",
      "Iteration 6994, loss = 0.00305752\n",
      "Iteration 6995, loss = 0.00305695\n",
      "Iteration 6996, loss = 0.00305626\n",
      "Iteration 6997, loss = 0.00305562\n",
      "Iteration 6998, loss = 0.00305503\n",
      "Iteration 6999, loss = 0.00305435\n",
      "Iteration 7000, loss = 0.00305366\n",
      "Iteration 7001, loss = 0.00305317\n",
      "Iteration 7002, loss = 0.00305254\n",
      "Iteration 7003, loss = 0.00305186\n",
      "Iteration 7004, loss = 0.00305124\n",
      "Iteration 7005, loss = 0.00305072\n",
      "Iteration 7006, loss = 0.00304988\n",
      "Iteration 7007, loss = 0.00304942\n",
      "Iteration 7008, loss = 0.00304872\n",
      "Iteration 7009, loss = 0.00304831\n",
      "Iteration 7010, loss = 0.00304758\n",
      "Iteration 7011, loss = 0.00304701\n",
      "Iteration 7012, loss = 0.00304646\n",
      "Iteration 7013, loss = 0.00304589\n",
      "Iteration 7014, loss = 0.00304525\n",
      "Iteration 7015, loss = 0.00304471\n",
      "Iteration 7016, loss = 0.00304414\n",
      "Iteration 7017, loss = 0.00304361\n",
      "Iteration 7018, loss = 0.00304308\n",
      "Iteration 7019, loss = 0.00304257\n",
      "Iteration 7020, loss = 0.00304199\n",
      "Iteration 7021, loss = 0.00304145\n",
      "Iteration 7022, loss = 0.00304092\n",
      "Iteration 7023, loss = 0.00304045\n",
      "Iteration 7024, loss = 0.00303995\n",
      "Iteration 7025, loss = 0.00303936\n",
      "Iteration 7026, loss = 0.00303902\n",
      "Iteration 7027, loss = 0.00303820\n",
      "Iteration 7028, loss = 0.00303770\n",
      "Iteration 7029, loss = 0.00303727\n",
      "Iteration 7030, loss = 0.00303656\n",
      "Iteration 7031, loss = 0.00303573\n",
      "Iteration 7032, loss = 0.00303514\n",
      "Iteration 7033, loss = 0.00303466\n",
      "Iteration 7034, loss = 0.00303392\n",
      "Iteration 7035, loss = 0.00303331\n",
      "Iteration 7036, loss = 0.00303272\n",
      "Iteration 7037, loss = 0.00303220\n",
      "Iteration 7038, loss = 0.00303159\n",
      "Iteration 7039, loss = 0.00303102\n",
      "Iteration 7040, loss = 0.00303054\n",
      "Iteration 7041, loss = 0.00302989\n",
      "Iteration 7042, loss = 0.00302939\n",
      "Iteration 7043, loss = 0.00302881\n",
      "Iteration 7044, loss = 0.00302830\n",
      "Iteration 7045, loss = 0.00302770\n",
      "Iteration 7046, loss = 0.00302711\n",
      "Iteration 7047, loss = 0.00302660\n",
      "Iteration 7048, loss = 0.00302616\n",
      "Iteration 7049, loss = 0.00302550\n",
      "Iteration 7050, loss = 0.00302507\n",
      "Iteration 7051, loss = 0.00302437\n",
      "Iteration 7052, loss = 0.00302368\n",
      "Iteration 7053, loss = 0.00302310\n",
      "Iteration 7054, loss = 0.00302247\n",
      "Iteration 7055, loss = 0.00302189\n",
      "Iteration 7056, loss = 0.00302112\n",
      "Iteration 7057, loss = 0.00302066\n",
      "Iteration 7058, loss = 0.00301988\n",
      "Iteration 7059, loss = 0.00301917\n",
      "Iteration 7060, loss = 0.00301850\n",
      "Iteration 7061, loss = 0.00301804\n",
      "Iteration 7062, loss = 0.00301766\n",
      "Iteration 7063, loss = 0.00301673\n",
      "Iteration 7064, loss = 0.00301598\n",
      "Iteration 7065, loss = 0.00301532\n",
      "Iteration 7066, loss = 0.00301473\n",
      "Iteration 7067, loss = 0.00301412\n",
      "Iteration 7068, loss = 0.00301351\n",
      "Iteration 7069, loss = 0.00301288\n",
      "Iteration 7070, loss = 0.00301230\n",
      "Iteration 7071, loss = 0.00301177\n",
      "Iteration 7072, loss = 0.00301127\n",
      "Iteration 7073, loss = 0.00301068\n",
      "Iteration 7074, loss = 0.00301001\n",
      "Iteration 7075, loss = 0.00300942\n",
      "Iteration 7076, loss = 0.00300894\n",
      "Iteration 7077, loss = 0.00300832\n",
      "Iteration 7078, loss = 0.00300780\n",
      "Iteration 7079, loss = 0.00300708\n",
      "Iteration 7080, loss = 0.00300647\n",
      "Iteration 7081, loss = 0.00300585\n",
      "Iteration 7082, loss = 0.00300527\n",
      "Iteration 7083, loss = 0.00300466\n",
      "Iteration 7084, loss = 0.00300432\n",
      "Iteration 7085, loss = 0.00300355\n",
      "Iteration 7086, loss = 0.00300296\n",
      "Iteration 7087, loss = 0.00300238\n",
      "Iteration 7088, loss = 0.00300158\n",
      "Iteration 7089, loss = 0.00300090\n",
      "Iteration 7090, loss = 0.00300044\n",
      "Iteration 7091, loss = 0.00299969\n",
      "Iteration 7092, loss = 0.00299933\n",
      "Iteration 7093, loss = 0.00299871\n",
      "Iteration 7094, loss = 0.00299783\n",
      "Iteration 7095, loss = 0.00299716\n",
      "Iteration 7096, loss = 0.00299657\n",
      "Iteration 7097, loss = 0.00299582\n",
      "Iteration 7098, loss = 0.00299537\n",
      "Iteration 7099, loss = 0.00299461\n",
      "Iteration 7100, loss = 0.00299397\n",
      "Iteration 7101, loss = 0.00299347\n",
      "Iteration 7102, loss = 0.00299272\n",
      "Iteration 7103, loss = 0.00299207\n",
      "Iteration 7104, loss = 0.00299146\n",
      "Iteration 7105, loss = 0.00299087\n",
      "Iteration 7106, loss = 0.00299029\n",
      "Iteration 7107, loss = 0.00298963\n",
      "Iteration 7108, loss = 0.00298918\n",
      "Iteration 7109, loss = 0.00298843\n",
      "Iteration 7110, loss = 0.00298792\n",
      "Iteration 7111, loss = 0.00298729\n",
      "Iteration 7112, loss = 0.00298675\n",
      "Iteration 7113, loss = 0.00298625\n",
      "Iteration 7114, loss = 0.00298556\n",
      "Iteration 7115, loss = 0.00298495\n",
      "Iteration 7116, loss = 0.00298458\n",
      "Iteration 7117, loss = 0.00298378\n",
      "Iteration 7118, loss = 0.00298346\n",
      "Iteration 7119, loss = 0.00298272\n",
      "Iteration 7120, loss = 0.00298207\n",
      "Iteration 7121, loss = 0.00298146\n",
      "Iteration 7122, loss = 0.00298074\n",
      "Iteration 7123, loss = 0.00298015\n",
      "Iteration 7124, loss = 0.00297953\n",
      "Iteration 7125, loss = 0.00297878\n",
      "Iteration 7126, loss = 0.00297820\n",
      "Iteration 7127, loss = 0.00297764\n",
      "Iteration 7128, loss = 0.00297688\n",
      "Iteration 7129, loss = 0.00297625\n",
      "Iteration 7130, loss = 0.00297562\n",
      "Iteration 7131, loss = 0.00297507\n",
      "Iteration 7132, loss = 0.00297456\n",
      "Iteration 7133, loss = 0.00297389\n",
      "Iteration 7134, loss = 0.00297332\n",
      "Iteration 7135, loss = 0.00297282\n",
      "Iteration 7136, loss = 0.00297213\n",
      "Iteration 7137, loss = 0.00297151\n",
      "Iteration 7138, loss = 0.00297093\n",
      "Iteration 7139, loss = 0.00297032\n",
      "Iteration 7140, loss = 0.00296972\n",
      "Iteration 7141, loss = 0.00296972\n",
      "Iteration 7142, loss = 0.00296863\n",
      "Iteration 7143, loss = 0.00296803\n",
      "Iteration 7144, loss = 0.00296748\n",
      "Iteration 7145, loss = 0.00296694\n",
      "Iteration 7146, loss = 0.00296622\n",
      "Iteration 7147, loss = 0.00296578\n",
      "Iteration 7148, loss = 0.00296518\n",
      "Iteration 7149, loss = 0.00296464\n",
      "Iteration 7150, loss = 0.00296413\n",
      "Iteration 7151, loss = 0.00296369\n",
      "Iteration 7152, loss = 0.00296322\n",
      "Iteration 7153, loss = 0.00296271\n",
      "Iteration 7154, loss = 0.00296211\n",
      "Iteration 7155, loss = 0.00296160\n",
      "Iteration 7156, loss = 0.00296100\n",
      "Iteration 7157, loss = 0.00296065\n",
      "Iteration 7158, loss = 0.00295995\n",
      "Iteration 7159, loss = 0.00295944\n",
      "Iteration 7160, loss = 0.00295907\n",
      "Iteration 7161, loss = 0.00295812\n",
      "Iteration 7162, loss = 0.00295750\n",
      "Iteration 7163, loss = 0.00295698\n",
      "Iteration 7164, loss = 0.00295635\n",
      "Iteration 7165, loss = 0.00295567\n",
      "Iteration 7166, loss = 0.00295499\n",
      "Iteration 7167, loss = 0.00295457\n",
      "Iteration 7168, loss = 0.00295381\n",
      "Iteration 7169, loss = 0.00295319\n",
      "Iteration 7170, loss = 0.00295260\n",
      "Iteration 7171, loss = 0.00295196\n",
      "Iteration 7172, loss = 0.00295154\n",
      "Iteration 7173, loss = 0.00295086\n",
      "Iteration 7174, loss = 0.00295030\n",
      "Iteration 7175, loss = 0.00294968\n",
      "Iteration 7176, loss = 0.00294899\n",
      "Iteration 7177, loss = 0.00294853\n",
      "Iteration 7178, loss = 0.00294789\n",
      "Iteration 7179, loss = 0.00294737\n",
      "Iteration 7180, loss = 0.00294658\n",
      "Iteration 7181, loss = 0.00294601\n",
      "Iteration 7182, loss = 0.00294539\n",
      "Iteration 7183, loss = 0.00294481\n",
      "Iteration 7184, loss = 0.00294441\n",
      "Iteration 7185, loss = 0.00294353\n",
      "Iteration 7186, loss = 0.00294308\n",
      "Iteration 7187, loss = 0.00294256\n",
      "Iteration 7188, loss = 0.00294182\n",
      "Iteration 7189, loss = 0.00294125\n",
      "Iteration 7190, loss = 0.00294066\n",
      "Iteration 7191, loss = 0.00294008\n",
      "Iteration 7192, loss = 0.00293945\n",
      "Iteration 7193, loss = 0.00293897\n",
      "Iteration 7194, loss = 0.00293838\n",
      "Iteration 7195, loss = 0.00293791\n",
      "Iteration 7196, loss = 0.00293755\n",
      "Iteration 7197, loss = 0.00293658\n",
      "Iteration 7198, loss = 0.00293618\n",
      "Iteration 7199, loss = 0.00293555\n",
      "Iteration 7200, loss = 0.00293493\n",
      "Iteration 7201, loss = 0.00293433\n",
      "Iteration 7202, loss = 0.00293377\n",
      "Iteration 7203, loss = 0.00293317\n",
      "Iteration 7204, loss = 0.00293251\n",
      "Iteration 7205, loss = 0.00293184\n",
      "Iteration 7206, loss = 0.00293115\n",
      "Iteration 7207, loss = 0.00293062\n",
      "Iteration 7208, loss = 0.00293023\n",
      "Iteration 7209, loss = 0.00292968\n",
      "Iteration 7210, loss = 0.00292915\n",
      "Iteration 7211, loss = 0.00292834\n",
      "Iteration 7212, loss = 0.00292778\n",
      "Iteration 7213, loss = 0.00292716\n",
      "Iteration 7214, loss = 0.00292663\n",
      "Iteration 7215, loss = 0.00292600\n",
      "Iteration 7216, loss = 0.00292546\n",
      "Iteration 7217, loss = 0.00292485\n",
      "Iteration 7218, loss = 0.00292431\n",
      "Iteration 7219, loss = 0.00292371\n",
      "Iteration 7220, loss = 0.00292318\n",
      "Iteration 7221, loss = 0.00292258\n",
      "Iteration 7222, loss = 0.00292207\n",
      "Iteration 7223, loss = 0.00292147\n",
      "Iteration 7224, loss = 0.00292094\n",
      "Iteration 7225, loss = 0.00292041\n",
      "Iteration 7226, loss = 0.00291995\n",
      "Iteration 7227, loss = 0.00291939\n",
      "Iteration 7228, loss = 0.00291881\n",
      "Iteration 7229, loss = 0.00291826\n",
      "Iteration 7230, loss = 0.00291766\n",
      "Iteration 7231, loss = 0.00291710\n",
      "Iteration 7232, loss = 0.00291661\n",
      "Iteration 7233, loss = 0.00291592\n",
      "Iteration 7234, loss = 0.00291532\n",
      "Iteration 7235, loss = 0.00291472\n",
      "Iteration 7236, loss = 0.00291418\n",
      "Iteration 7237, loss = 0.00291360\n",
      "Iteration 7238, loss = 0.00291304\n",
      "Iteration 7239, loss = 0.00291247\n",
      "Iteration 7240, loss = 0.00291202\n",
      "Iteration 7241, loss = 0.00291140\n",
      "Iteration 7242, loss = 0.00291089\n",
      "Iteration 7243, loss = 0.00291037\n",
      "Iteration 7244, loss = 0.00291021\n",
      "Iteration 7245, loss = 0.00290940\n",
      "Iteration 7246, loss = 0.00290879\n",
      "Iteration 7247, loss = 0.00290834\n",
      "Iteration 7248, loss = 0.00290765\n",
      "Iteration 7249, loss = 0.00290720\n",
      "Iteration 7250, loss = 0.00290670\n",
      "Iteration 7251, loss = 0.00290598\n",
      "Iteration 7252, loss = 0.00290539\n",
      "Iteration 7253, loss = 0.00290486\n",
      "Iteration 7254, loss = 0.00290438\n",
      "Iteration 7255, loss = 0.00290360\n",
      "Iteration 7256, loss = 0.00290296\n",
      "Iteration 7257, loss = 0.00290252\n",
      "Iteration 7258, loss = 0.00290206\n",
      "Iteration 7259, loss = 0.00290146\n",
      "Iteration 7260, loss = 0.00290099\n",
      "Iteration 7261, loss = 0.00290039\n",
      "Iteration 7262, loss = 0.00289969\n",
      "Iteration 7263, loss = 0.00289908\n",
      "Iteration 7264, loss = 0.00289852\n",
      "Iteration 7265, loss = 0.00289796\n",
      "Iteration 7266, loss = 0.00289737\n",
      "Iteration 7267, loss = 0.00289675\n",
      "Iteration 7268, loss = 0.00289623\n",
      "Iteration 7269, loss = 0.00289567\n",
      "Iteration 7270, loss = 0.00289513\n",
      "Iteration 7271, loss = 0.00289457\n",
      "Iteration 7272, loss = 0.00289416\n",
      "Iteration 7273, loss = 0.00289388\n",
      "Iteration 7274, loss = 0.00289317\n",
      "Iteration 7275, loss = 0.00289247\n",
      "Iteration 7276, loss = 0.00289212\n",
      "Iteration 7277, loss = 0.00289165\n",
      "Iteration 7278, loss = 0.00289093\n",
      "Iteration 7279, loss = 0.00289041\n",
      "Iteration 7280, loss = 0.00288964\n",
      "Iteration 7281, loss = 0.00288927\n",
      "Iteration 7282, loss = 0.00288842\n",
      "Iteration 7283, loss = 0.00288820\n",
      "Iteration 7284, loss = 0.00288729\n",
      "Iteration 7285, loss = 0.00288668\n",
      "Iteration 7286, loss = 0.00288596\n",
      "Iteration 7287, loss = 0.00288527\n",
      "Iteration 7288, loss = 0.00288466\n",
      "Iteration 7289, loss = 0.00288441\n",
      "Iteration 7290, loss = 0.00288365\n",
      "Iteration 7291, loss = 0.00288339\n",
      "Iteration 7292, loss = 0.00288290\n",
      "Iteration 7293, loss = 0.00288201\n",
      "Iteration 7294, loss = 0.00288139\n",
      "Iteration 7295, loss = 0.00288080\n",
      "Iteration 7296, loss = 0.00288019\n",
      "Iteration 7297, loss = 0.00287974\n",
      "Iteration 7298, loss = 0.00287905\n",
      "Iteration 7299, loss = 0.00287840\n",
      "Iteration 7300, loss = 0.00287783\n",
      "Iteration 7301, loss = 0.00287728\n",
      "Iteration 7302, loss = 0.00287679\n",
      "Iteration 7303, loss = 0.00287628\n",
      "Iteration 7304, loss = 0.00287597\n",
      "Iteration 7305, loss = 0.00287514\n",
      "Iteration 7306, loss = 0.00287460\n",
      "Iteration 7307, loss = 0.00287401\n",
      "Iteration 7308, loss = 0.00287337\n",
      "Iteration 7309, loss = 0.00287317\n",
      "Iteration 7310, loss = 0.00287243\n",
      "Iteration 7311, loss = 0.00287193\n",
      "Iteration 7312, loss = 0.00287130\n",
      "Iteration 7313, loss = 0.00287064\n",
      "Iteration 7314, loss = 0.00287004\n",
      "Iteration 7315, loss = 0.00286942\n",
      "Iteration 7316, loss = 0.00286878\n",
      "Iteration 7317, loss = 0.00286841\n",
      "Iteration 7318, loss = 0.00286768\n",
      "Iteration 7319, loss = 0.00286708\n",
      "Iteration 7320, loss = 0.00286657\n",
      "Iteration 7321, loss = 0.00286594\n",
      "Iteration 7322, loss = 0.00286559\n",
      "Iteration 7323, loss = 0.00286487\n",
      "Iteration 7324, loss = 0.00286437\n",
      "Iteration 7325, loss = 0.00286379\n",
      "Iteration 7326, loss = 0.00286350\n",
      "Iteration 7327, loss = 0.00286282\n",
      "Iteration 7328, loss = 0.00286222\n",
      "Iteration 7329, loss = 0.00286168\n",
      "Iteration 7330, loss = 0.00286095\n",
      "Iteration 7331, loss = 0.00286042\n",
      "Iteration 7332, loss = 0.00285981\n",
      "Iteration 7333, loss = 0.00285939\n",
      "Iteration 7334, loss = 0.00285878\n",
      "Iteration 7335, loss = 0.00285820\n",
      "Iteration 7336, loss = 0.00285769\n",
      "Iteration 7337, loss = 0.00285709\n",
      "Iteration 7338, loss = 0.00285649\n",
      "Iteration 7339, loss = 0.00285587\n",
      "Iteration 7340, loss = 0.00285580\n",
      "Iteration 7341, loss = 0.00285485\n",
      "Iteration 7342, loss = 0.00285427\n",
      "Iteration 7343, loss = 0.00285373\n",
      "Iteration 7344, loss = 0.00285326\n",
      "Iteration 7345, loss = 0.00285270\n",
      "Iteration 7346, loss = 0.00285213\n",
      "Iteration 7347, loss = 0.00285155\n",
      "Iteration 7348, loss = 0.00285100\n",
      "Iteration 7349, loss = 0.00285048\n",
      "Iteration 7350, loss = 0.00285003\n",
      "Iteration 7351, loss = 0.00284945\n",
      "Iteration 7352, loss = 0.00284891\n",
      "Iteration 7353, loss = 0.00284845\n",
      "Iteration 7354, loss = 0.00284798\n",
      "Iteration 7355, loss = 0.00284748\n",
      "Iteration 7356, loss = 0.00284694\n",
      "Iteration 7357, loss = 0.00284643\n",
      "Iteration 7358, loss = 0.00284580\n",
      "Iteration 7359, loss = 0.00284531\n",
      "Iteration 7360, loss = 0.00284479\n",
      "Iteration 7361, loss = 0.00284424\n",
      "Iteration 7362, loss = 0.00284377\n",
      "Iteration 7363, loss = 0.00284324\n",
      "Iteration 7364, loss = 0.00284267\n",
      "Iteration 7365, loss = 0.00284221\n",
      "Iteration 7366, loss = 0.00284170\n",
      "Iteration 7367, loss = 0.00284104\n",
      "Iteration 7368, loss = 0.00284041\n",
      "Iteration 7369, loss = 0.00284008\n",
      "Iteration 7370, loss = 0.00283941\n",
      "Iteration 7371, loss = 0.00283896\n",
      "Iteration 7372, loss = 0.00283840\n",
      "Iteration 7373, loss = 0.00283788\n",
      "Iteration 7374, loss = 0.00283734\n",
      "Iteration 7375, loss = 0.00283683\n",
      "Iteration 7376, loss = 0.00283627\n",
      "Iteration 7377, loss = 0.00283580\n",
      "Iteration 7378, loss = 0.00283518\n",
      "Iteration 7379, loss = 0.00283484\n",
      "Iteration 7380, loss = 0.00283420\n",
      "Iteration 7381, loss = 0.00283354\n",
      "Iteration 7382, loss = 0.00283307\n",
      "Iteration 7383, loss = 0.00283249\n",
      "Iteration 7384, loss = 0.00283199\n",
      "Iteration 7385, loss = 0.00283144\n",
      "Iteration 7386, loss = 0.00283085\n",
      "Iteration 7387, loss = 0.00283036\n",
      "Iteration 7388, loss = 0.00282972\n",
      "Iteration 7389, loss = 0.00282936\n",
      "Iteration 7390, loss = 0.00282863\n",
      "Iteration 7391, loss = 0.00282811\n",
      "Iteration 7392, loss = 0.00282770\n",
      "Iteration 7393, loss = 0.00282708\n",
      "Iteration 7394, loss = 0.00282675\n",
      "Iteration 7395, loss = 0.00282591\n",
      "Iteration 7396, loss = 0.00282555\n",
      "Iteration 7397, loss = 0.00282485\n",
      "Iteration 7398, loss = 0.00282420\n",
      "Iteration 7399, loss = 0.00282380\n",
      "Iteration 7400, loss = 0.00282314\n",
      "Iteration 7401, loss = 0.00282249\n",
      "Iteration 7402, loss = 0.00282198\n",
      "Iteration 7403, loss = 0.00282139\n",
      "Iteration 7404, loss = 0.00282079\n",
      "Iteration 7405, loss = 0.00282024\n",
      "Iteration 7406, loss = 0.00281963\n",
      "Iteration 7407, loss = 0.00281936\n",
      "Iteration 7408, loss = 0.00281866\n",
      "Iteration 7409, loss = 0.00281808\n",
      "Iteration 7410, loss = 0.00281748\n",
      "Iteration 7411, loss = 0.00281742\n",
      "Iteration 7412, loss = 0.00281647\n",
      "Iteration 7413, loss = 0.00281590\n",
      "Iteration 7414, loss = 0.00281543\n",
      "Iteration 7415, loss = 0.00281472\n",
      "Iteration 7416, loss = 0.00281422\n",
      "Iteration 7417, loss = 0.00281361\n",
      "Iteration 7418, loss = 0.00281306\n",
      "Iteration 7419, loss = 0.00281242\n",
      "Iteration 7420, loss = 0.00281186\n",
      "Iteration 7421, loss = 0.00281134\n",
      "Iteration 7422, loss = 0.00281089\n",
      "Iteration 7423, loss = 0.00281026\n",
      "Iteration 7424, loss = 0.00280979\n",
      "Iteration 7425, loss = 0.00280916\n",
      "Iteration 7426, loss = 0.00280867\n",
      "Iteration 7427, loss = 0.00280806\n",
      "Iteration 7428, loss = 0.00280747\n",
      "Iteration 7429, loss = 0.00280707\n",
      "Iteration 7430, loss = 0.00280648\n",
      "Iteration 7431, loss = 0.00280588\n",
      "Iteration 7432, loss = 0.00280524\n",
      "Iteration 7433, loss = 0.00280480\n",
      "Iteration 7434, loss = 0.00280417\n",
      "Iteration 7435, loss = 0.00280401\n",
      "Iteration 7436, loss = 0.00280329\n",
      "Iteration 7437, loss = 0.00280305\n",
      "Iteration 7438, loss = 0.00280244\n",
      "Iteration 7439, loss = 0.00280187\n",
      "Iteration 7440, loss = 0.00280168\n",
      "Iteration 7441, loss = 0.00280097\n",
      "Iteration 7442, loss = 0.00280040\n",
      "Iteration 7443, loss = 0.00279983\n",
      "Iteration 7444, loss = 0.00279920\n",
      "Iteration 7445, loss = 0.00279867\n",
      "Iteration 7446, loss = 0.00279819\n",
      "Iteration 7447, loss = 0.00279756\n",
      "Iteration 7448, loss = 0.00279706\n",
      "Iteration 7449, loss = 0.00279652\n",
      "Iteration 7450, loss = 0.00279601\n",
      "Iteration 7451, loss = 0.00279555\n",
      "Iteration 7452, loss = 0.00279509\n",
      "Iteration 7453, loss = 0.00279461\n",
      "Iteration 7454, loss = 0.00279416\n",
      "Iteration 7455, loss = 0.00279373\n",
      "Iteration 7456, loss = 0.00279326\n",
      "Iteration 7457, loss = 0.00279270\n",
      "Iteration 7458, loss = 0.00279223\n",
      "Iteration 7459, loss = 0.00279176\n",
      "Iteration 7460, loss = 0.00279118\n",
      "Iteration 7461, loss = 0.00279076\n",
      "Iteration 7462, loss = 0.00279028\n",
      "Iteration 7463, loss = 0.00278974\n",
      "Iteration 7464, loss = 0.00278927\n",
      "Iteration 7465, loss = 0.00278872\n",
      "Iteration 7466, loss = 0.00278824\n",
      "Iteration 7467, loss = 0.00278775\n",
      "Iteration 7468, loss = 0.00278722\n",
      "Iteration 7469, loss = 0.00278674\n",
      "Iteration 7470, loss = 0.00278621\n",
      "Iteration 7471, loss = 0.00278574\n",
      "Iteration 7472, loss = 0.00278518\n",
      "Iteration 7473, loss = 0.00278462\n",
      "Iteration 7474, loss = 0.00278405\n",
      "Iteration 7475, loss = 0.00278358\n",
      "Iteration 7476, loss = 0.00278298\n",
      "Iteration 7477, loss = 0.00278251\n",
      "Iteration 7478, loss = 0.00278200\n",
      "Iteration 7479, loss = 0.00278145\n",
      "Iteration 7480, loss = 0.00278091\n",
      "Iteration 7481, loss = 0.00278035\n",
      "Iteration 7482, loss = 0.00277984\n",
      "Iteration 7483, loss = 0.00277949\n",
      "Iteration 7484, loss = 0.00277879\n",
      "Iteration 7485, loss = 0.00277822\n",
      "Iteration 7486, loss = 0.00277771\n",
      "Iteration 7487, loss = 0.00277715\n",
      "Iteration 7488, loss = 0.00277665\n",
      "Iteration 7489, loss = 0.00277608\n",
      "Iteration 7490, loss = 0.00277558\n",
      "Iteration 7491, loss = 0.00277507\n",
      "Iteration 7492, loss = 0.00277452\n",
      "Iteration 7493, loss = 0.00277403\n",
      "Iteration 7494, loss = 0.00277359\n",
      "Iteration 7495, loss = 0.00277314\n",
      "Iteration 7496, loss = 0.00277264\n",
      "Iteration 7497, loss = 0.00277229\n",
      "Iteration 7498, loss = 0.00277179\n",
      "Iteration 7499, loss = 0.00277120\n",
      "Iteration 7500, loss = 0.00277080\n",
      "Iteration 7501, loss = 0.00277038\n",
      "Iteration 7502, loss = 0.00276988\n",
      "Iteration 7503, loss = 0.00276934\n",
      "Iteration 7504, loss = 0.00276881\n",
      "Iteration 7505, loss = 0.00276834\n",
      "Iteration 7506, loss = 0.00276784\n",
      "Iteration 7507, loss = 0.00276731\n",
      "Iteration 7508, loss = 0.00276672\n",
      "Iteration 7509, loss = 0.00276618\n",
      "Iteration 7510, loss = 0.00276558\n",
      "Iteration 7511, loss = 0.00276508\n",
      "Iteration 7512, loss = 0.00276451\n",
      "Iteration 7513, loss = 0.00276399\n",
      "Iteration 7514, loss = 0.00276340\n",
      "Iteration 7515, loss = 0.00276304\n",
      "Iteration 7516, loss = 0.00276233\n",
      "Iteration 7517, loss = 0.00276184\n",
      "Iteration 7518, loss = 0.00276130\n",
      "Iteration 7519, loss = 0.00276081\n",
      "Iteration 7520, loss = 0.00276030\n",
      "Iteration 7521, loss = 0.00275985\n",
      "Iteration 7522, loss = 0.00275943\n",
      "Iteration 7523, loss = 0.00275892\n",
      "Iteration 7524, loss = 0.00275838\n",
      "Iteration 7525, loss = 0.00275783\n",
      "Iteration 7526, loss = 0.00275746\n",
      "Iteration 7527, loss = 0.00275687\n",
      "Iteration 7528, loss = 0.00275633\n",
      "Iteration 7529, loss = 0.00275587\n",
      "Iteration 7530, loss = 0.00275538\n",
      "Iteration 7531, loss = 0.00275495\n",
      "Iteration 7532, loss = 0.00275446\n",
      "Iteration 7533, loss = 0.00275395\n",
      "Iteration 7534, loss = 0.00275353\n",
      "Iteration 7535, loss = 0.00275313\n",
      "Iteration 7536, loss = 0.00275248\n",
      "Iteration 7537, loss = 0.00275190\n",
      "Iteration 7538, loss = 0.00275130\n",
      "Iteration 7539, loss = 0.00275074\n",
      "Iteration 7540, loss = 0.00275010\n",
      "Iteration 7541, loss = 0.00274959\n",
      "Iteration 7542, loss = 0.00274914\n",
      "Iteration 7543, loss = 0.00274872\n",
      "Iteration 7544, loss = 0.00274813\n",
      "Iteration 7545, loss = 0.00274762\n",
      "Iteration 7546, loss = 0.00274724\n",
      "Iteration 7547, loss = 0.00274713\n",
      "Iteration 7548, loss = 0.00274626\n",
      "Iteration 7549, loss = 0.00274570\n",
      "Iteration 7550, loss = 0.00274517\n",
      "Iteration 7551, loss = 0.00274465\n",
      "Iteration 7552, loss = 0.00274417\n",
      "Iteration 7553, loss = 0.00274368\n",
      "Iteration 7554, loss = 0.00274322\n",
      "Iteration 7555, loss = 0.00274272\n",
      "Iteration 7556, loss = 0.00274223\n",
      "Iteration 7557, loss = 0.00274167\n",
      "Iteration 7558, loss = 0.00274113\n",
      "Iteration 7559, loss = 0.00274061\n",
      "Iteration 7560, loss = 0.00274008\n",
      "Iteration 7561, loss = 0.00273979\n",
      "Iteration 7562, loss = 0.00273912\n",
      "Iteration 7563, loss = 0.00273858\n",
      "Iteration 7564, loss = 0.00273806\n",
      "Iteration 7565, loss = 0.00273768\n",
      "Iteration 7566, loss = 0.00273710\n",
      "Iteration 7567, loss = 0.00273678\n",
      "Iteration 7568, loss = 0.00273615\n",
      "Iteration 7569, loss = 0.00273563\n",
      "Iteration 7570, loss = 0.00273512\n",
      "Iteration 7571, loss = 0.00273463\n",
      "Iteration 7572, loss = 0.00273418\n",
      "Iteration 7573, loss = 0.00273378\n",
      "Iteration 7574, loss = 0.00273321\n",
      "Iteration 7575, loss = 0.00273279\n",
      "Iteration 7576, loss = 0.00273221\n",
      "Iteration 7577, loss = 0.00273167\n",
      "Iteration 7578, loss = 0.00273115\n",
      "Iteration 7579, loss = 0.00273067\n",
      "Iteration 7580, loss = 0.00273018\n",
      "Iteration 7581, loss = 0.00272964\n",
      "Iteration 7582, loss = 0.00272910\n",
      "Iteration 7583, loss = 0.00272857\n",
      "Iteration 7584, loss = 0.00272810\n",
      "Iteration 7585, loss = 0.00272755\n",
      "Iteration 7586, loss = 0.00272693\n",
      "Iteration 7587, loss = 0.00272639\n",
      "Iteration 7588, loss = 0.00272608\n",
      "Iteration 7589, loss = 0.00272540\n",
      "Iteration 7590, loss = 0.00272490\n",
      "Iteration 7591, loss = 0.00272461\n",
      "Iteration 7592, loss = 0.00272389\n",
      "Iteration 7593, loss = 0.00272330\n",
      "Iteration 7594, loss = 0.00272275\n",
      "Iteration 7595, loss = 0.00272235\n",
      "Iteration 7596, loss = 0.00272176\n",
      "Iteration 7597, loss = 0.00272143\n",
      "Iteration 7598, loss = 0.00272071\n",
      "Iteration 7599, loss = 0.00272027\n",
      "Iteration 7600, loss = 0.00271971\n",
      "Iteration 7601, loss = 0.00271926\n",
      "Iteration 7602, loss = 0.00271876\n",
      "Iteration 7603, loss = 0.00271835\n",
      "Iteration 7604, loss = 0.00271781\n",
      "Iteration 7605, loss = 0.00271734\n",
      "Iteration 7606, loss = 0.00271683\n",
      "Iteration 7607, loss = 0.00271631\n",
      "Iteration 7608, loss = 0.00271587\n",
      "Iteration 7609, loss = 0.00271532\n",
      "Iteration 7610, loss = 0.00271490\n",
      "Iteration 7611, loss = 0.00271435\n",
      "Iteration 7612, loss = 0.00271382\n",
      "Iteration 7613, loss = 0.00271344\n",
      "Iteration 7614, loss = 0.00271285\n",
      "Iteration 7615, loss = 0.00271253\n",
      "Iteration 7616, loss = 0.00271185\n",
      "Iteration 7617, loss = 0.00271132\n",
      "Iteration 7618, loss = 0.00271094\n",
      "Iteration 7619, loss = 0.00271046\n",
      "Iteration 7620, loss = 0.00270994\n",
      "Iteration 7621, loss = 0.00270969\n",
      "Iteration 7622, loss = 0.00270909\n",
      "Iteration 7623, loss = 0.00270854\n",
      "Iteration 7624, loss = 0.00270801\n",
      "Iteration 7625, loss = 0.00270798\n",
      "Iteration 7626, loss = 0.00270712\n",
      "Iteration 7627, loss = 0.00270662\n",
      "Iteration 7628, loss = 0.00270610\n",
      "Iteration 7629, loss = 0.00270559\n",
      "Iteration 7630, loss = 0.00270515\n",
      "Iteration 7631, loss = 0.00270479\n",
      "Iteration 7632, loss = 0.00270412\n",
      "Iteration 7633, loss = 0.00270343\n",
      "Iteration 7634, loss = 0.00270292\n",
      "Iteration 7635, loss = 0.00270239\n",
      "Iteration 7636, loss = 0.00270189\n",
      "Iteration 7637, loss = 0.00270129\n",
      "Iteration 7638, loss = 0.00270085\n",
      "Iteration 7639, loss = 0.00270033\n",
      "Iteration 7640, loss = 0.00269982\n",
      "Iteration 7641, loss = 0.00269942\n",
      "Iteration 7642, loss = 0.00269885\n",
      "Iteration 7643, loss = 0.00269826\n",
      "Iteration 7644, loss = 0.00269780\n",
      "Iteration 7645, loss = 0.00269730\n",
      "Iteration 7646, loss = 0.00269662\n",
      "Iteration 7647, loss = 0.00269605\n",
      "Iteration 7648, loss = 0.00269549\n",
      "Iteration 7649, loss = 0.00269501\n",
      "Iteration 7650, loss = 0.00269444\n",
      "Iteration 7651, loss = 0.00269409\n",
      "Iteration 7652, loss = 0.00269340\n",
      "Iteration 7653, loss = 0.00269300\n",
      "Iteration 7654, loss = 0.00269237\n",
      "Iteration 7655, loss = 0.00269192\n",
      "Iteration 7656, loss = 0.00269150\n",
      "Iteration 7657, loss = 0.00269083\n",
      "Iteration 7658, loss = 0.00269030\n",
      "Iteration 7659, loss = 0.00268976\n",
      "Iteration 7660, loss = 0.00268924\n",
      "Iteration 7661, loss = 0.00268889\n",
      "Iteration 7662, loss = 0.00268823\n",
      "Iteration 7663, loss = 0.00268776\n",
      "Iteration 7664, loss = 0.00268733\n",
      "Iteration 7665, loss = 0.00268705\n",
      "Iteration 7666, loss = 0.00268634\n",
      "Iteration 7667, loss = 0.00268584\n",
      "Iteration 7668, loss = 0.00268536\n",
      "Iteration 7669, loss = 0.00268487\n",
      "Iteration 7670, loss = 0.00268433\n",
      "Iteration 7671, loss = 0.00268380\n",
      "Iteration 7672, loss = 0.00268337\n",
      "Iteration 7673, loss = 0.00268283\n",
      "Iteration 7674, loss = 0.00268228\n",
      "Iteration 7675, loss = 0.00268181\n",
      "Iteration 7676, loss = 0.00268142\n",
      "Iteration 7677, loss = 0.00268087\n",
      "Iteration 7678, loss = 0.00268036\n",
      "Iteration 7679, loss = 0.00267990\n",
      "Iteration 7680, loss = 0.00267952\n",
      "Iteration 7681, loss = 0.00267884\n",
      "Iteration 7682, loss = 0.00267836\n",
      "Iteration 7683, loss = 0.00267789\n",
      "Iteration 7684, loss = 0.00267740\n",
      "Iteration 7685, loss = 0.00267691\n",
      "Iteration 7686, loss = 0.00267647\n",
      "Iteration 7687, loss = 0.00267601\n",
      "Iteration 7688, loss = 0.00267551\n",
      "Iteration 7689, loss = 0.00267508\n",
      "Iteration 7690, loss = 0.00267461\n",
      "Iteration 7691, loss = 0.00267413\n",
      "Iteration 7692, loss = 0.00267374\n",
      "Iteration 7693, loss = 0.00267327\n",
      "Iteration 7694, loss = 0.00267286\n",
      "Iteration 7695, loss = 0.00267241\n",
      "Iteration 7696, loss = 0.00267199\n",
      "Iteration 7697, loss = 0.00267160\n",
      "Iteration 7698, loss = 0.00267105\n",
      "Iteration 7699, loss = 0.00267082\n",
      "Iteration 7700, loss = 0.00267032\n",
      "Iteration 7701, loss = 0.00266984\n",
      "Iteration 7702, loss = 0.00266946\n",
      "Iteration 7703, loss = 0.00266894\n",
      "Iteration 7704, loss = 0.00266843\n",
      "Iteration 7705, loss = 0.00266790\n",
      "Iteration 7706, loss = 0.00266738\n",
      "Iteration 7707, loss = 0.00266693\n",
      "Iteration 7708, loss = 0.00266707\n",
      "Iteration 7709, loss = 0.00266608\n",
      "Iteration 7710, loss = 0.00266561\n",
      "Iteration 7711, loss = 0.00266509\n",
      "Iteration 7712, loss = 0.00266467\n",
      "Iteration 7713, loss = 0.00266414\n",
      "Iteration 7714, loss = 0.00266360\n",
      "Iteration 7715, loss = 0.00266309\n",
      "Iteration 7716, loss = 0.00266262\n",
      "Iteration 7717, loss = 0.00266215\n",
      "Iteration 7718, loss = 0.00266169\n",
      "Iteration 7719, loss = 0.00266122\n",
      "Iteration 7720, loss = 0.00266089\n",
      "Iteration 7721, loss = 0.00266045\n",
      "Iteration 7722, loss = 0.00265969\n",
      "Iteration 7723, loss = 0.00265928\n",
      "Iteration 7724, loss = 0.00265868\n",
      "Iteration 7725, loss = 0.00265828\n",
      "Iteration 7726, loss = 0.00265768\n",
      "Iteration 7727, loss = 0.00265709\n",
      "Iteration 7728, loss = 0.00265663\n",
      "Iteration 7729, loss = 0.00265619\n",
      "Iteration 7730, loss = 0.00265548\n",
      "Iteration 7731, loss = 0.00265485\n",
      "Iteration 7732, loss = 0.00265441\n",
      "Iteration 7733, loss = 0.00265391\n",
      "Iteration 7734, loss = 0.00265348\n",
      "Iteration 7735, loss = 0.00265306\n",
      "Iteration 7736, loss = 0.00265252\n",
      "Iteration 7737, loss = 0.00265211\n",
      "Iteration 7738, loss = 0.00265166\n",
      "Iteration 7739, loss = 0.00265121\n",
      "Iteration 7740, loss = 0.00265077\n",
      "Iteration 7741, loss = 0.00265033\n",
      "Iteration 7742, loss = 0.00265033\n",
      "Iteration 7743, loss = 0.00264968\n",
      "Iteration 7744, loss = 0.00264915\n",
      "Iteration 7745, loss = 0.00264860\n",
      "Iteration 7746, loss = 0.00264815\n",
      "Iteration 7747, loss = 0.00264769\n",
      "Iteration 7748, loss = 0.00264721\n",
      "Iteration 7749, loss = 0.00264671\n",
      "Iteration 7750, loss = 0.00264616\n",
      "Iteration 7751, loss = 0.00264565\n",
      "Iteration 7752, loss = 0.00264542\n",
      "Iteration 7753, loss = 0.00264472\n",
      "Iteration 7754, loss = 0.00264426\n",
      "Iteration 7755, loss = 0.00264381\n",
      "Iteration 7756, loss = 0.00264354\n",
      "Iteration 7757, loss = 0.00264278\n",
      "Iteration 7758, loss = 0.00264234\n",
      "Iteration 7759, loss = 0.00264227\n",
      "Iteration 7760, loss = 0.00264148\n",
      "Iteration 7761, loss = 0.00264105\n",
      "Iteration 7762, loss = 0.00264039\n",
      "Iteration 7763, loss = 0.00263985\n",
      "Iteration 7764, loss = 0.00263949\n",
      "Iteration 7765, loss = 0.00263885\n",
      "Iteration 7766, loss = 0.00263831\n",
      "Iteration 7767, loss = 0.00263808\n",
      "Iteration 7768, loss = 0.00263737\n",
      "Iteration 7769, loss = 0.00263693\n",
      "Iteration 7770, loss = 0.00263638\n",
      "Iteration 7771, loss = 0.00263599\n",
      "Iteration 7772, loss = 0.00263538\n",
      "Iteration 7773, loss = 0.00263477\n",
      "Iteration 7774, loss = 0.00263423\n",
      "Iteration 7775, loss = 0.00263378\n",
      "Iteration 7776, loss = 0.00263325\n",
      "Iteration 7777, loss = 0.00263318\n",
      "Iteration 7778, loss = 0.00263227\n",
      "Iteration 7779, loss = 0.00263176\n",
      "Iteration 7780, loss = 0.00263136\n",
      "Iteration 7781, loss = 0.00263086\n",
      "Iteration 7782, loss = 0.00263031\n",
      "Iteration 7783, loss = 0.00262991\n",
      "Iteration 7784, loss = 0.00262928\n",
      "Iteration 7785, loss = 0.00262878\n",
      "Iteration 7786, loss = 0.00262827\n",
      "Iteration 7787, loss = 0.00262767\n",
      "Iteration 7788, loss = 0.00262735\n",
      "Iteration 7789, loss = 0.00262670\n",
      "Iteration 7790, loss = 0.00262619\n",
      "Iteration 7791, loss = 0.00262561\n",
      "Iteration 7792, loss = 0.00262527\n",
      "Iteration 7793, loss = 0.00262466\n",
      "Iteration 7794, loss = 0.00262423\n",
      "Iteration 7795, loss = 0.00262374\n",
      "Iteration 7796, loss = 0.00262355\n",
      "Iteration 7797, loss = 0.00262280\n",
      "Iteration 7798, loss = 0.00262232\n",
      "Iteration 7799, loss = 0.00262187\n",
      "Iteration 7800, loss = 0.00262145\n",
      "Iteration 7801, loss = 0.00262100\n",
      "Iteration 7802, loss = 0.00262054\n",
      "Iteration 7803, loss = 0.00262002\n",
      "Iteration 7804, loss = 0.00261970\n",
      "Iteration 7805, loss = 0.00261915\n",
      "Iteration 7806, loss = 0.00261873\n",
      "Iteration 7807, loss = 0.00261838\n",
      "Iteration 7808, loss = 0.00261784\n",
      "Iteration 7809, loss = 0.00261741\n",
      "Iteration 7810, loss = 0.00261696\n",
      "Iteration 7811, loss = 0.00261649\n",
      "Iteration 7812, loss = 0.00261609\n",
      "Iteration 7813, loss = 0.00261579\n",
      "Iteration 7814, loss = 0.00261529\n",
      "Iteration 7815, loss = 0.00261475\n",
      "Iteration 7816, loss = 0.00261432\n",
      "Iteration 7817, loss = 0.00261393\n",
      "Iteration 7818, loss = 0.00261338\n",
      "Iteration 7819, loss = 0.00261277\n",
      "Iteration 7820, loss = 0.00261251\n",
      "Iteration 7821, loss = 0.00261184\n",
      "Iteration 7822, loss = 0.00261143\n",
      "Iteration 7823, loss = 0.00261090\n",
      "Iteration 7824, loss = 0.00261032\n",
      "Iteration 7825, loss = 0.00260985\n",
      "Iteration 7826, loss = 0.00260949\n",
      "Iteration 7827, loss = 0.00260883\n",
      "Iteration 7828, loss = 0.00260832\n",
      "Iteration 7829, loss = 0.00260793\n",
      "Iteration 7830, loss = 0.00260744\n",
      "Iteration 7831, loss = 0.00260700\n",
      "Iteration 7832, loss = 0.00260654\n",
      "Iteration 7833, loss = 0.00260626\n",
      "Iteration 7834, loss = 0.00260571\n",
      "Iteration 7835, loss = 0.00260532\n",
      "Iteration 7836, loss = 0.00260480\n",
      "Iteration 7837, loss = 0.00260429\n",
      "Iteration 7838, loss = 0.00260376\n",
      "Iteration 7839, loss = 0.00260370\n",
      "Iteration 7840, loss = 0.00260302\n",
      "Iteration 7841, loss = 0.00260232\n",
      "Iteration 7842, loss = 0.00260185\n",
      "Iteration 7843, loss = 0.00260139\n",
      "Iteration 7844, loss = 0.00260082\n",
      "Iteration 7845, loss = 0.00260027\n",
      "Iteration 7846, loss = 0.00259994\n",
      "Iteration 7847, loss = 0.00259929\n",
      "Iteration 7848, loss = 0.00259896\n",
      "Iteration 7849, loss = 0.00259827\n",
      "Iteration 7850, loss = 0.00259794\n",
      "Iteration 7851, loss = 0.00259742\n",
      "Iteration 7852, loss = 0.00259660\n",
      "Iteration 7853, loss = 0.00259604\n",
      "Iteration 7854, loss = 0.00259586\n",
      "Iteration 7855, loss = 0.00259529\n",
      "Iteration 7856, loss = 0.00259468\n",
      "Iteration 7857, loss = 0.00259431\n",
      "Iteration 7858, loss = 0.00259375\n",
      "Iteration 7859, loss = 0.00259332\n",
      "Iteration 7860, loss = 0.00259277\n",
      "Iteration 7861, loss = 0.00259232\n",
      "Iteration 7862, loss = 0.00259189\n",
      "Iteration 7863, loss = 0.00259145\n",
      "Iteration 7864, loss = 0.00259101\n",
      "Iteration 7865, loss = 0.00259047\n",
      "Iteration 7866, loss = 0.00259006\n",
      "Iteration 7867, loss = 0.00258961\n",
      "Iteration 7868, loss = 0.00258930\n",
      "Iteration 7869, loss = 0.00258871\n",
      "Iteration 7870, loss = 0.00258828\n",
      "Iteration 7871, loss = 0.00258788\n",
      "Iteration 7872, loss = 0.00258752\n",
      "Iteration 7873, loss = 0.00258692\n",
      "Iteration 7874, loss = 0.00258654\n",
      "Iteration 7875, loss = 0.00258631\n",
      "Iteration 7876, loss = 0.00258553\n",
      "Iteration 7877, loss = 0.00258525\n",
      "Iteration 7878, loss = 0.00258465\n",
      "Iteration 7879, loss = 0.00258430\n",
      "Iteration 7880, loss = 0.00258374\n",
      "Iteration 7881, loss = 0.00258337\n",
      "Iteration 7882, loss = 0.00258304\n",
      "Iteration 7883, loss = 0.00258239\n",
      "Iteration 7884, loss = 0.00258195\n",
      "Iteration 7885, loss = 0.00258129\n",
      "Iteration 7886, loss = 0.00258087\n",
      "Iteration 7887, loss = 0.00258041\n",
      "Iteration 7888, loss = 0.00257993\n",
      "Iteration 7889, loss = 0.00257947\n",
      "Iteration 7890, loss = 0.00257897\n",
      "Iteration 7891, loss = 0.00257849\n",
      "Iteration 7892, loss = 0.00257826\n",
      "Iteration 7893, loss = 0.00257762\n",
      "Iteration 7894, loss = 0.00257707\n",
      "Iteration 7895, loss = 0.00257660\n",
      "Iteration 7896, loss = 0.00257613\n",
      "Iteration 7897, loss = 0.00257560\n",
      "Iteration 7898, loss = 0.00257519\n",
      "Iteration 7899, loss = 0.00257474\n",
      "Iteration 7900, loss = 0.00257428\n",
      "Iteration 7901, loss = 0.00257387\n",
      "Iteration 7902, loss = 0.00257359\n",
      "Iteration 7903, loss = 0.00257323\n",
      "Iteration 7904, loss = 0.00257258\n",
      "Iteration 7905, loss = 0.00257217\n",
      "Iteration 7906, loss = 0.00257171\n",
      "Iteration 7907, loss = 0.00257161\n",
      "Iteration 7908, loss = 0.00257085\n",
      "Iteration 7909, loss = 0.00257048\n",
      "Iteration 7910, loss = 0.00257001\n",
      "Iteration 7911, loss = 0.00256952\n",
      "Iteration 7912, loss = 0.00256923\n",
      "Iteration 7913, loss = 0.00256866\n",
      "Iteration 7914, loss = 0.00256821\n",
      "Iteration 7915, loss = 0.00256793\n",
      "Iteration 7916, loss = 0.00256723\n",
      "Iteration 7917, loss = 0.00256679\n",
      "Iteration 7918, loss = 0.00256625\n",
      "Iteration 7919, loss = 0.00256575\n",
      "Iteration 7920, loss = 0.00256545\n",
      "Iteration 7921, loss = 0.00256485\n",
      "Iteration 7922, loss = 0.00256435\n",
      "Iteration 7923, loss = 0.00256418\n",
      "Iteration 7924, loss = 0.00256348\n",
      "Iteration 7925, loss = 0.00256300\n",
      "Iteration 7926, loss = 0.00256256\n",
      "Iteration 7927, loss = 0.00256210\n",
      "Iteration 7928, loss = 0.00256193\n",
      "Iteration 7929, loss = 0.00256109\n",
      "Iteration 7930, loss = 0.00256056\n",
      "Iteration 7931, loss = 0.00256018\n",
      "Iteration 7932, loss = 0.00255958\n",
      "Iteration 7933, loss = 0.00255919\n",
      "Iteration 7934, loss = 0.00255867\n",
      "Iteration 7935, loss = 0.00255817\n",
      "Iteration 7936, loss = 0.00255774\n",
      "Iteration 7937, loss = 0.00255733\n",
      "Iteration 7938, loss = 0.00255695\n",
      "Iteration 7939, loss = 0.00255638\n",
      "Iteration 7940, loss = 0.00255588\n",
      "Iteration 7941, loss = 0.00255549\n",
      "Iteration 7942, loss = 0.00255520\n",
      "Iteration 7943, loss = 0.00255457\n",
      "Iteration 7944, loss = 0.00255416\n",
      "Iteration 7945, loss = 0.00255364\n",
      "Iteration 7946, loss = 0.00255308\n",
      "Iteration 7947, loss = 0.00255301\n",
      "Iteration 7948, loss = 0.00255228\n",
      "Iteration 7949, loss = 0.00255177\n",
      "Iteration 7950, loss = 0.00255138\n",
      "Iteration 7951, loss = 0.00255095\n",
      "Iteration 7952, loss = 0.00255052\n",
      "Iteration 7953, loss = 0.00255005\n",
      "Iteration 7954, loss = 0.00254971\n",
      "Iteration 7955, loss = 0.00254920\n",
      "Iteration 7956, loss = 0.00254869\n",
      "Iteration 7957, loss = 0.00254832\n",
      "Iteration 7958, loss = 0.00254785\n",
      "Iteration 7959, loss = 0.00254742\n",
      "Iteration 7960, loss = 0.00254692\n",
      "Iteration 7961, loss = 0.00254642\n",
      "Iteration 7962, loss = 0.00254598\n",
      "Iteration 7963, loss = 0.00254560\n",
      "Iteration 7964, loss = 0.00254509\n",
      "Iteration 7965, loss = 0.00254469\n",
      "Iteration 7966, loss = 0.00254426\n",
      "Iteration 7967, loss = 0.00254378\n",
      "Iteration 7968, loss = 0.00254349\n",
      "Iteration 7969, loss = 0.00254302\n",
      "Iteration 7970, loss = 0.00254257\n",
      "Iteration 7971, loss = 0.00254216\n",
      "Iteration 7972, loss = 0.00254167\n",
      "Iteration 7973, loss = 0.00254162\n",
      "Iteration 7974, loss = 0.00254086\n",
      "Iteration 7975, loss = 0.00254045\n",
      "Iteration 7976, loss = 0.00254005\n",
      "Iteration 7977, loss = 0.00253956\n",
      "Iteration 7978, loss = 0.00253945\n",
      "Iteration 7979, loss = 0.00253864\n",
      "Iteration 7980, loss = 0.00253827\n",
      "Iteration 7981, loss = 0.00253771\n",
      "Iteration 7982, loss = 0.00253719\n",
      "Iteration 7983, loss = 0.00253674\n",
      "Iteration 7984, loss = 0.00253637\n",
      "Iteration 7985, loss = 0.00253598\n",
      "Iteration 7986, loss = 0.00253550\n",
      "Iteration 7987, loss = 0.00253518\n",
      "Iteration 7988, loss = 0.00253468\n",
      "Iteration 7989, loss = 0.00253417\n",
      "Iteration 7990, loss = 0.00253370\n",
      "Iteration 7991, loss = 0.00253327\n",
      "Iteration 7992, loss = 0.00253283\n",
      "Iteration 7993, loss = 0.00253239\n",
      "Iteration 7994, loss = 0.00253201\n",
      "Iteration 7995, loss = 0.00253159\n",
      "Iteration 7996, loss = 0.00253113\n",
      "Iteration 7997, loss = 0.00253066\n",
      "Iteration 7998, loss = 0.00253027\n",
      "Iteration 7999, loss = 0.00252986\n",
      "Iteration 8000, loss = 0.00252941\n",
      "Iteration 1, loss = 1.04050369\n",
      "Iteration 2, loss = 1.03732877\n",
      "Iteration 3, loss = 1.03228782\n",
      "Iteration 4, loss = 1.02590172\n",
      "Iteration 5, loss = 1.01841874\n",
      "Iteration 6, loss = 1.01026513\n",
      "Iteration 7, loss = 1.00150979\n",
      "Iteration 8, loss = 0.99252671\n",
      "Iteration 9, loss = 0.98316333\n",
      "Iteration 10, loss = 0.97383231\n",
      "Iteration 11, loss = 0.96430318\n",
      "Iteration 12, loss = 0.95495240\n",
      "Iteration 13, loss = 0.94546184\n",
      "Iteration 14, loss = 0.93627053\n",
      "Iteration 15, loss = 0.92715300\n",
      "Iteration 16, loss = 0.91819068\n",
      "Iteration 17, loss = 0.90923165\n",
      "Iteration 18, loss = 0.90080869\n",
      "Iteration 19, loss = 0.89245434\n",
      "Iteration 20, loss = 0.88432965\n",
      "Iteration 21, loss = 0.87639910\n",
      "Iteration 22, loss = 0.86877096\n",
      "Iteration 23, loss = 0.86124425\n",
      "Iteration 24, loss = 0.85401993\n",
      "Iteration 25, loss = 0.84695325\n",
      "Iteration 26, loss = 0.83996555\n",
      "Iteration 27, loss = 0.83325237\n",
      "Iteration 28, loss = 0.82664748\n",
      "Iteration 29, loss = 0.82048238\n",
      "Iteration 30, loss = 0.81432739\n",
      "Iteration 31, loss = 0.80834903\n",
      "Iteration 32, loss = 0.80260595\n",
      "Iteration 33, loss = 0.79695936\n",
      "Iteration 34, loss = 0.79144282\n",
      "Iteration 35, loss = 0.78617520\n",
      "Iteration 36, loss = 0.78078628\n",
      "Iteration 37, loss = 0.77586423\n",
      "Iteration 38, loss = 0.77084430\n",
      "Iteration 39, loss = 0.76602151\n",
      "Iteration 40, loss = 0.76146554\n",
      "Iteration 41, loss = 0.75703648\n",
      "Iteration 42, loss = 0.75262616\n",
      "Iteration 43, loss = 0.74855269\n",
      "Iteration 44, loss = 0.74452170\n",
      "Iteration 45, loss = 0.74059894\n",
      "Iteration 46, loss = 0.73682554\n",
      "Iteration 47, loss = 0.73300366\n",
      "Iteration 48, loss = 0.72926156\n",
      "Iteration 49, loss = 0.72558629\n",
      "Iteration 50, loss = 0.72196533\n",
      "Iteration 51, loss = 0.71841017\n",
      "Iteration 52, loss = 0.71486730\n",
      "Iteration 53, loss = 0.71142870\n",
      "Iteration 54, loss = 0.70792348\n",
      "Iteration 55, loss = 0.70454550\n",
      "Iteration 56, loss = 0.70115835\n",
      "Iteration 57, loss = 0.69770108\n",
      "Iteration 58, loss = 0.69440466\n",
      "Iteration 59, loss = 0.69110946\n",
      "Iteration 60, loss = 0.68774565\n",
      "Iteration 61, loss = 0.68449378\n",
      "Iteration 62, loss = 0.68136257\n",
      "Iteration 63, loss = 0.67824092\n",
      "Iteration 64, loss = 0.67511654\n",
      "Iteration 65, loss = 0.67214283\n",
      "Iteration 66, loss = 0.66909436\n",
      "Iteration 67, loss = 0.66608741\n",
      "Iteration 68, loss = 0.66321437\n",
      "Iteration 69, loss = 0.66018039\n",
      "Iteration 70, loss = 0.65735621\n",
      "Iteration 71, loss = 0.65440583\n",
      "Iteration 72, loss = 0.65161792\n",
      "Iteration 73, loss = 0.64876363\n",
      "Iteration 74, loss = 0.64602723\n",
      "Iteration 75, loss = 0.64320289\n",
      "Iteration 76, loss = 0.64050173\n",
      "Iteration 77, loss = 0.63777471\n",
      "Iteration 78, loss = 0.63506111\n",
      "Iteration 79, loss = 0.63238493\n",
      "Iteration 80, loss = 0.62971096\n",
      "Iteration 81, loss = 0.62703738\n",
      "Iteration 82, loss = 0.62438276\n",
      "Iteration 83, loss = 0.62174675\n",
      "Iteration 84, loss = 0.61907970\n",
      "Iteration 85, loss = 0.61653041\n",
      "Iteration 86, loss = 0.61390528\n",
      "Iteration 87, loss = 0.61135124\n",
      "Iteration 88, loss = 0.60879018\n",
      "Iteration 89, loss = 0.60627429\n",
      "Iteration 90, loss = 0.60371012\n",
      "Iteration 91, loss = 0.60122170\n",
      "Iteration 92, loss = 0.59871606\n",
      "Iteration 93, loss = 0.59624942\n",
      "Iteration 94, loss = 0.59375331\n",
      "Iteration 95, loss = 0.59128956\n",
      "Iteration 96, loss = 0.58886827\n",
      "Iteration 97, loss = 0.58645712\n",
      "Iteration 98, loss = 0.58405157\n",
      "Iteration 99, loss = 0.58166256\n",
      "Iteration 100, loss = 0.57925645\n",
      "Iteration 101, loss = 0.57689530\n",
      "Iteration 102, loss = 0.57447861\n",
      "Iteration 103, loss = 0.57209433\n",
      "Iteration 104, loss = 0.56974594\n",
      "Iteration 105, loss = 0.56734843\n",
      "Iteration 106, loss = 0.56498641\n",
      "Iteration 107, loss = 0.56264243\n",
      "Iteration 108, loss = 0.56037006\n",
      "Iteration 109, loss = 0.55802114\n",
      "Iteration 110, loss = 0.55573070\n",
      "Iteration 111, loss = 0.55343688\n",
      "Iteration 112, loss = 0.55113215\n",
      "Iteration 113, loss = 0.54890175\n",
      "Iteration 114, loss = 0.54653680\n",
      "Iteration 115, loss = 0.54425046\n",
      "Iteration 116, loss = 0.54198359\n",
      "Iteration 117, loss = 0.53964646\n",
      "Iteration 118, loss = 0.53740245\n",
      "Iteration 119, loss = 0.53507687\n",
      "Iteration 120, loss = 0.53278699\n",
      "Iteration 121, loss = 0.53056277\n",
      "Iteration 122, loss = 0.52835134\n",
      "Iteration 123, loss = 0.52615455\n",
      "Iteration 124, loss = 0.52395858\n",
      "Iteration 125, loss = 0.52179861\n",
      "Iteration 126, loss = 0.51961305\n",
      "Iteration 127, loss = 0.51745739\n",
      "Iteration 128, loss = 0.51530896\n",
      "Iteration 129, loss = 0.51315606\n",
      "Iteration 130, loss = 0.51107925\n",
      "Iteration 131, loss = 0.50895029\n",
      "Iteration 132, loss = 0.50684954\n",
      "Iteration 133, loss = 0.50478066\n",
      "Iteration 134, loss = 0.50270586\n",
      "Iteration 135, loss = 0.50061679\n",
      "Iteration 136, loss = 0.49856002\n",
      "Iteration 137, loss = 0.49648828\n",
      "Iteration 138, loss = 0.49440478\n",
      "Iteration 139, loss = 0.49234332\n",
      "Iteration 140, loss = 0.49024394\n",
      "Iteration 141, loss = 0.48816485\n",
      "Iteration 142, loss = 0.48609262\n",
      "Iteration 143, loss = 0.48401541\n",
      "Iteration 144, loss = 0.48193948\n",
      "Iteration 145, loss = 0.47986052\n",
      "Iteration 146, loss = 0.47779161\n",
      "Iteration 147, loss = 0.47571234\n",
      "Iteration 148, loss = 0.47363991\n",
      "Iteration 149, loss = 0.47152559\n",
      "Iteration 150, loss = 0.46945036\n",
      "Iteration 151, loss = 0.46735889\n",
      "Iteration 152, loss = 0.46525647\n",
      "Iteration 153, loss = 0.46317572\n",
      "Iteration 154, loss = 0.46109560\n",
      "Iteration 155, loss = 0.45905759\n",
      "Iteration 156, loss = 0.45695587\n",
      "Iteration 157, loss = 0.45489981\n",
      "Iteration 158, loss = 0.45282023\n",
      "Iteration 159, loss = 0.45072873\n",
      "Iteration 160, loss = 0.44859285\n",
      "Iteration 161, loss = 0.44651937\n",
      "Iteration 162, loss = 0.44438360\n",
      "Iteration 163, loss = 0.44226946\n",
      "Iteration 164, loss = 0.44015986\n",
      "Iteration 165, loss = 0.43806560\n",
      "Iteration 166, loss = 0.43593927\n",
      "Iteration 167, loss = 0.43384767\n",
      "Iteration 168, loss = 0.43176160\n",
      "Iteration 169, loss = 0.42964121\n",
      "Iteration 170, loss = 0.42758691\n",
      "Iteration 171, loss = 0.42546987\n",
      "Iteration 172, loss = 0.42339242\n",
      "Iteration 173, loss = 0.42131317\n",
      "Iteration 174, loss = 0.41924299\n",
      "Iteration 175, loss = 0.41715141\n",
      "Iteration 176, loss = 0.41509943\n",
      "Iteration 177, loss = 0.41302535\n",
      "Iteration 178, loss = 0.41097269\n",
      "Iteration 179, loss = 0.40889015\n",
      "Iteration 180, loss = 0.40684336\n",
      "Iteration 181, loss = 0.40473674\n",
      "Iteration 182, loss = 0.40267031\n",
      "Iteration 183, loss = 0.40059942\n",
      "Iteration 184, loss = 0.39847800\n",
      "Iteration 185, loss = 0.39639893\n",
      "Iteration 186, loss = 0.39433036\n",
      "Iteration 187, loss = 0.39223477\n",
      "Iteration 188, loss = 0.39016703\n",
      "Iteration 189, loss = 0.38812468\n",
      "Iteration 190, loss = 0.38604845\n",
      "Iteration 191, loss = 0.38402219\n",
      "Iteration 192, loss = 0.38200042\n",
      "Iteration 193, loss = 0.37997154\n",
      "Iteration 194, loss = 0.37795590\n",
      "Iteration 195, loss = 0.37597188\n",
      "Iteration 196, loss = 0.37392099\n",
      "Iteration 197, loss = 0.37193921\n",
      "Iteration 198, loss = 0.36990943\n",
      "Iteration 199, loss = 0.36791078\n",
      "Iteration 200, loss = 0.36590515\n",
      "Iteration 201, loss = 0.36389314\n",
      "Iteration 202, loss = 0.36192431\n",
      "Iteration 203, loss = 0.35993203\n",
      "Iteration 204, loss = 0.35795379\n",
      "Iteration 205, loss = 0.35597919\n",
      "Iteration 206, loss = 0.35402330\n",
      "Iteration 207, loss = 0.35203421\n",
      "Iteration 208, loss = 0.35006349\n",
      "Iteration 209, loss = 0.34807838\n",
      "Iteration 210, loss = 0.34608904\n",
      "Iteration 211, loss = 0.34409313\n",
      "Iteration 212, loss = 0.34208148\n",
      "Iteration 213, loss = 0.34009109\n",
      "Iteration 214, loss = 0.33809939\n",
      "Iteration 215, loss = 0.33608695\n",
      "Iteration 216, loss = 0.33409292\n",
      "Iteration 217, loss = 0.33210374\n",
      "Iteration 218, loss = 0.33015139\n",
      "Iteration 219, loss = 0.32816725\n",
      "Iteration 220, loss = 0.32622936\n",
      "Iteration 221, loss = 0.32428415\n",
      "Iteration 222, loss = 0.32234212\n",
      "Iteration 223, loss = 0.32042333\n",
      "Iteration 224, loss = 0.31849088\n",
      "Iteration 225, loss = 0.31658940\n",
      "Iteration 226, loss = 0.31467258\n",
      "Iteration 227, loss = 0.31276280\n",
      "Iteration 228, loss = 0.31086811\n",
      "Iteration 229, loss = 0.30897225\n",
      "Iteration 230, loss = 0.30708511\n",
      "Iteration 231, loss = 0.30522719\n",
      "Iteration 232, loss = 0.30334901\n",
      "Iteration 233, loss = 0.30148695\n",
      "Iteration 234, loss = 0.29965071\n",
      "Iteration 235, loss = 0.29781340\n",
      "Iteration 236, loss = 0.29598066\n",
      "Iteration 237, loss = 0.29416490\n",
      "Iteration 238, loss = 0.29234873\n",
      "Iteration 239, loss = 0.29053974\n",
      "Iteration 240, loss = 0.28872911\n",
      "Iteration 241, loss = 0.28694115\n",
      "Iteration 242, loss = 0.28514634\n",
      "Iteration 243, loss = 0.28335403\n",
      "Iteration 244, loss = 0.28157526\n",
      "Iteration 245, loss = 0.27980944\n",
      "Iteration 246, loss = 0.27804301\n",
      "Iteration 247, loss = 0.27630599\n",
      "Iteration 248, loss = 0.27457524\n",
      "Iteration 249, loss = 0.27285168\n",
      "Iteration 250, loss = 0.27115841\n",
      "Iteration 251, loss = 0.26947292\n",
      "Iteration 252, loss = 0.26779688\n",
      "Iteration 253, loss = 0.26611914\n",
      "Iteration 254, loss = 0.26446943\n",
      "Iteration 255, loss = 0.26282260\n",
      "Iteration 256, loss = 0.26119016\n",
      "Iteration 257, loss = 0.25954136\n",
      "Iteration 258, loss = 0.25792686\n",
      "Iteration 259, loss = 0.25630347\n",
      "Iteration 260, loss = 0.25469762\n",
      "Iteration 261, loss = 0.25308288\n",
      "Iteration 262, loss = 0.25148034\n",
      "Iteration 263, loss = 0.24987788\n",
      "Iteration 264, loss = 0.24827459\n",
      "Iteration 265, loss = 0.24669747\n",
      "Iteration 266, loss = 0.24512185\n",
      "Iteration 267, loss = 0.24356133\n",
      "Iteration 268, loss = 0.24201633\n",
      "Iteration 269, loss = 0.24049067\n",
      "Iteration 270, loss = 0.23899141\n",
      "Iteration 271, loss = 0.23749763\n",
      "Iteration 272, loss = 0.23602659\n",
      "Iteration 273, loss = 0.23453910\n",
      "Iteration 274, loss = 0.23308794\n",
      "Iteration 275, loss = 0.23162562\n",
      "Iteration 276, loss = 0.23019575\n",
      "Iteration 277, loss = 0.22875614\n",
      "Iteration 278, loss = 0.22734781\n",
      "Iteration 279, loss = 0.22596201\n",
      "Iteration 280, loss = 0.22455825\n",
      "Iteration 281, loss = 0.22318984\n",
      "Iteration 282, loss = 0.22181868\n",
      "Iteration 283, loss = 0.22046453\n",
      "Iteration 284, loss = 0.21910926\n",
      "Iteration 285, loss = 0.21776962\n",
      "Iteration 286, loss = 0.21643458\n",
      "Iteration 287, loss = 0.21511492\n",
      "Iteration 288, loss = 0.21379611\n",
      "Iteration 289, loss = 0.21249283\n",
      "Iteration 290, loss = 0.21118838\n",
      "Iteration 291, loss = 0.20990256\n",
      "Iteration 292, loss = 0.20863082\n",
      "Iteration 293, loss = 0.20735596\n",
      "Iteration 294, loss = 0.20607892\n",
      "Iteration 295, loss = 0.20485321\n",
      "Iteration 296, loss = 0.20359467\n",
      "Iteration 297, loss = 0.20238812\n",
      "Iteration 298, loss = 0.20114116\n",
      "Iteration 299, loss = 0.19994555\n",
      "Iteration 300, loss = 0.19873478\n",
      "Iteration 301, loss = 0.19752347\n",
      "Iteration 302, loss = 0.19634024\n",
      "Iteration 303, loss = 0.19517112\n",
      "Iteration 304, loss = 0.19399926\n",
      "Iteration 305, loss = 0.19284938\n",
      "Iteration 306, loss = 0.19171146\n",
      "Iteration 307, loss = 0.19058591\n",
      "Iteration 308, loss = 0.18947349\n",
      "Iteration 309, loss = 0.18836609\n",
      "Iteration 310, loss = 0.18727788\n",
      "Iteration 311, loss = 0.18618839\n",
      "Iteration 312, loss = 0.18511530\n",
      "Iteration 313, loss = 0.18404355\n",
      "Iteration 314, loss = 0.18298204\n",
      "Iteration 315, loss = 0.18192386\n",
      "Iteration 316, loss = 0.18087305\n",
      "Iteration 317, loss = 0.17983807\n",
      "Iteration 318, loss = 0.17880307\n",
      "Iteration 319, loss = 0.17778598\n",
      "Iteration 320, loss = 0.17676578\n",
      "Iteration 321, loss = 0.17575861\n",
      "Iteration 322, loss = 0.17477004\n",
      "Iteration 323, loss = 0.17377910\n",
      "Iteration 324, loss = 0.17280309\n",
      "Iteration 325, loss = 0.17182516\n",
      "Iteration 326, loss = 0.17086325\n",
      "Iteration 327, loss = 0.16990814\n",
      "Iteration 328, loss = 0.16895586\n",
      "Iteration 329, loss = 0.16801684\n",
      "Iteration 330, loss = 0.16708164\n",
      "Iteration 331, loss = 0.16615145\n",
      "Iteration 332, loss = 0.16522887\n",
      "Iteration 333, loss = 0.16432700\n",
      "Iteration 334, loss = 0.16341680\n",
      "Iteration 335, loss = 0.16251504\n",
      "Iteration 336, loss = 0.16162549\n",
      "Iteration 337, loss = 0.16072881\n",
      "Iteration 338, loss = 0.15983848\n",
      "Iteration 339, loss = 0.15895395\n",
      "Iteration 340, loss = 0.15807015\n",
      "Iteration 341, loss = 0.15720270\n",
      "Iteration 342, loss = 0.15633458\n",
      "Iteration 343, loss = 0.15549015\n",
      "Iteration 344, loss = 0.15463831\n",
      "Iteration 345, loss = 0.15380581\n",
      "Iteration 346, loss = 0.15298315\n",
      "Iteration 347, loss = 0.15215508\n",
      "Iteration 348, loss = 0.15134302\n",
      "Iteration 349, loss = 0.15052625\n",
      "Iteration 350, loss = 0.14972578\n",
      "Iteration 351, loss = 0.14892379\n",
      "Iteration 352, loss = 0.14813079\n",
      "Iteration 353, loss = 0.14735964\n",
      "Iteration 354, loss = 0.14657907\n",
      "Iteration 355, loss = 0.14581844\n",
      "Iteration 356, loss = 0.14506419\n",
      "Iteration 357, loss = 0.14432059\n",
      "Iteration 358, loss = 0.14358161\n",
      "Iteration 359, loss = 0.14284202\n",
      "Iteration 360, loss = 0.14212132\n",
      "Iteration 361, loss = 0.14139984\n",
      "Iteration 362, loss = 0.14068271\n",
      "Iteration 363, loss = 0.13997937\n",
      "Iteration 364, loss = 0.13926950\n",
      "Iteration 365, loss = 0.13857081\n",
      "Iteration 366, loss = 0.13786939\n",
      "Iteration 367, loss = 0.13717787\n",
      "Iteration 368, loss = 0.13649772\n",
      "Iteration 369, loss = 0.13582229\n",
      "Iteration 370, loss = 0.13514633\n",
      "Iteration 371, loss = 0.13448390\n",
      "Iteration 372, loss = 0.13383269\n",
      "Iteration 373, loss = 0.13317652\n",
      "Iteration 374, loss = 0.13252539\n",
      "Iteration 375, loss = 0.13187872\n",
      "Iteration 376, loss = 0.13124028\n",
      "Iteration 377, loss = 0.13060111\n",
      "Iteration 378, loss = 0.12997480\n",
      "Iteration 379, loss = 0.12934484\n",
      "Iteration 380, loss = 0.12872069\n",
      "Iteration 381, loss = 0.12810932\n",
      "Iteration 382, loss = 0.12750092\n",
      "Iteration 383, loss = 0.12689624\n",
      "Iteration 384, loss = 0.12629191\n",
      "Iteration 385, loss = 0.12569695\n",
      "Iteration 386, loss = 0.12510675\n",
      "Iteration 387, loss = 0.12451001\n",
      "Iteration 388, loss = 0.12391522\n",
      "Iteration 389, loss = 0.12334330\n",
      "Iteration 390, loss = 0.12275818\n",
      "Iteration 391, loss = 0.12218340\n",
      "Iteration 392, loss = 0.12161695\n",
      "Iteration 393, loss = 0.12105214\n",
      "Iteration 394, loss = 0.12049616\n",
      "Iteration 395, loss = 0.11994022\n",
      "Iteration 396, loss = 0.11939457\n",
      "Iteration 397, loss = 0.11885451\n",
      "Iteration 398, loss = 0.11831431\n",
      "Iteration 399, loss = 0.11778581\n",
      "Iteration 400, loss = 0.11725576\n",
      "Iteration 401, loss = 0.11673416\n",
      "Iteration 402, loss = 0.11621832\n",
      "Iteration 403, loss = 0.11570409\n",
      "Iteration 404, loss = 0.11519437\n",
      "Iteration 405, loss = 0.11469413\n",
      "Iteration 406, loss = 0.11419531\n",
      "Iteration 407, loss = 0.11370174\n",
      "Iteration 408, loss = 0.11321119\n",
      "Iteration 409, loss = 0.11272753\n",
      "Iteration 410, loss = 0.11224629\n",
      "Iteration 411, loss = 0.11176932\n",
      "Iteration 412, loss = 0.11129538\n",
      "Iteration 413, loss = 0.11083641\n",
      "Iteration 414, loss = 0.11036463\n",
      "Iteration 415, loss = 0.10989976\n",
      "Iteration 416, loss = 0.10944370\n",
      "Iteration 417, loss = 0.10898011\n",
      "Iteration 418, loss = 0.10852954\n",
      "Iteration 419, loss = 0.10807357\n",
      "Iteration 420, loss = 0.10762607\n",
      "Iteration 421, loss = 0.10717601\n",
      "Iteration 422, loss = 0.10673385\n",
      "Iteration 423, loss = 0.10629016\n",
      "Iteration 424, loss = 0.10585013\n",
      "Iteration 425, loss = 0.10541395\n",
      "Iteration 426, loss = 0.10498587\n",
      "Iteration 427, loss = 0.10456040\n",
      "Iteration 428, loss = 0.10413897\n",
      "Iteration 429, loss = 0.10372252\n",
      "Iteration 430, loss = 0.10330900\n",
      "Iteration 431, loss = 0.10290656\n",
      "Iteration 432, loss = 0.10249898\n",
      "Iteration 433, loss = 0.10209477\n",
      "Iteration 434, loss = 0.10168632\n",
      "Iteration 435, loss = 0.10129639\n",
      "Iteration 436, loss = 0.10089371\n",
      "Iteration 437, loss = 0.10050053\n",
      "Iteration 438, loss = 0.10010838\n",
      "Iteration 439, loss = 0.09972758\n",
      "Iteration 440, loss = 0.09933345\n",
      "Iteration 441, loss = 0.09894870\n",
      "Iteration 442, loss = 0.09857293\n",
      "Iteration 443, loss = 0.09819786\n",
      "Iteration 444, loss = 0.09782734\n",
      "Iteration 445, loss = 0.09745542\n",
      "Iteration 446, loss = 0.09708904\n",
      "Iteration 447, loss = 0.09673197\n",
      "Iteration 448, loss = 0.09636299\n",
      "Iteration 449, loss = 0.09600368\n",
      "Iteration 450, loss = 0.09564293\n",
      "Iteration 451, loss = 0.09528579\n",
      "Iteration 452, loss = 0.09493370\n",
      "Iteration 453, loss = 0.09458206\n",
      "Iteration 454, loss = 0.09423641\n",
      "Iteration 455, loss = 0.09389333\n",
      "Iteration 456, loss = 0.09354737\n",
      "Iteration 457, loss = 0.09320600\n",
      "Iteration 458, loss = 0.09286497\n",
      "Iteration 459, loss = 0.09252314\n",
      "Iteration 460, loss = 0.09219635\n",
      "Iteration 461, loss = 0.09185704\n",
      "Iteration 462, loss = 0.09152813\n",
      "Iteration 463, loss = 0.09120486\n",
      "Iteration 464, loss = 0.09088448\n",
      "Iteration 465, loss = 0.09056228\n",
      "Iteration 466, loss = 0.09024893\n",
      "Iteration 467, loss = 0.08992760\n",
      "Iteration 468, loss = 0.08961621\n",
      "Iteration 469, loss = 0.08930372\n",
      "Iteration 470, loss = 0.08898617\n",
      "Iteration 471, loss = 0.08867672\n",
      "Iteration 472, loss = 0.08836575\n",
      "Iteration 473, loss = 0.08805468\n",
      "Iteration 474, loss = 0.08774280\n",
      "Iteration 475, loss = 0.08743594\n",
      "Iteration 476, loss = 0.08714020\n",
      "Iteration 477, loss = 0.08683694\n",
      "Iteration 478, loss = 0.08653241\n",
      "Iteration 479, loss = 0.08623598\n",
      "Iteration 480, loss = 0.08594429\n",
      "Iteration 481, loss = 0.08565204\n",
      "Iteration 482, loss = 0.08535364\n",
      "Iteration 483, loss = 0.08507550\n",
      "Iteration 484, loss = 0.08478206\n",
      "Iteration 485, loss = 0.08448972\n",
      "Iteration 486, loss = 0.08421209\n",
      "Iteration 487, loss = 0.08392270\n",
      "Iteration 488, loss = 0.08364759\n",
      "Iteration 489, loss = 0.08337232\n",
      "Iteration 490, loss = 0.08308891\n",
      "Iteration 491, loss = 0.08282114\n",
      "Iteration 492, loss = 0.08254955\n",
      "Iteration 493, loss = 0.08228476\n",
      "Iteration 494, loss = 0.08201843\n",
      "Iteration 495, loss = 0.08175460\n",
      "Iteration 496, loss = 0.08150097\n",
      "Iteration 497, loss = 0.08123977\n",
      "Iteration 498, loss = 0.08099441\n",
      "Iteration 499, loss = 0.08072476\n",
      "Iteration 500, loss = 0.08046560\n",
      "Iteration 501, loss = 0.08021084\n",
      "Iteration 502, loss = 0.07995418\n",
      "Iteration 503, loss = 0.07970528\n",
      "Iteration 504, loss = 0.07945279\n",
      "Iteration 505, loss = 0.07920380\n",
      "Iteration 506, loss = 0.07895862\n",
      "Iteration 507, loss = 0.07871452\n",
      "Iteration 508, loss = 0.07847738\n",
      "Iteration 509, loss = 0.07823494\n",
      "Iteration 510, loss = 0.07799836\n",
      "Iteration 511, loss = 0.07776162\n",
      "Iteration 512, loss = 0.07752368\n",
      "Iteration 513, loss = 0.07730168\n",
      "Iteration 514, loss = 0.07706857\n",
      "Iteration 515, loss = 0.07683105\n",
      "Iteration 516, loss = 0.07660464\n",
      "Iteration 517, loss = 0.07636933\n",
      "Iteration 518, loss = 0.07613719\n",
      "Iteration 519, loss = 0.07590712\n",
      "Iteration 520, loss = 0.07568262\n",
      "Iteration 521, loss = 0.07545365\n",
      "Iteration 522, loss = 0.07522741\n",
      "Iteration 523, loss = 0.07500854\n",
      "Iteration 524, loss = 0.07478617\n",
      "Iteration 525, loss = 0.07456934\n",
      "Iteration 526, loss = 0.07435921\n",
      "Iteration 527, loss = 0.07413780\n",
      "Iteration 528, loss = 0.07392057\n",
      "Iteration 529, loss = 0.07371049\n",
      "Iteration 530, loss = 0.07349436\n",
      "Iteration 531, loss = 0.07328620\n",
      "Iteration 532, loss = 0.07307678\n",
      "Iteration 533, loss = 0.07286899\n",
      "Iteration 534, loss = 0.07266512\n",
      "Iteration 535, loss = 0.07246367\n",
      "Iteration 536, loss = 0.07226153\n",
      "Iteration 537, loss = 0.07206289\n",
      "Iteration 538, loss = 0.07186485\n",
      "Iteration 539, loss = 0.07166949\n",
      "Iteration 540, loss = 0.07147467\n",
      "Iteration 541, loss = 0.07128169\n",
      "Iteration 542, loss = 0.07108920\n",
      "Iteration 543, loss = 0.07089660\n",
      "Iteration 544, loss = 0.07070995\n",
      "Iteration 545, loss = 0.07051757\n",
      "Iteration 546, loss = 0.07032510\n",
      "Iteration 547, loss = 0.07014199\n",
      "Iteration 548, loss = 0.06994793\n",
      "Iteration 549, loss = 0.06976446\n",
      "Iteration 550, loss = 0.06957659\n",
      "Iteration 551, loss = 0.06939210\n",
      "Iteration 552, loss = 0.06920890\n",
      "Iteration 553, loss = 0.06902352\n",
      "Iteration 554, loss = 0.06884407\n",
      "Iteration 555, loss = 0.06866228\n",
      "Iteration 556, loss = 0.06848648\n",
      "Iteration 557, loss = 0.06830557\n",
      "Iteration 558, loss = 0.06812940\n",
      "Iteration 559, loss = 0.06794760\n",
      "Iteration 560, loss = 0.06777480\n",
      "Iteration 561, loss = 0.06759360\n",
      "Iteration 562, loss = 0.06742097\n",
      "Iteration 563, loss = 0.06724638\n",
      "Iteration 564, loss = 0.06707038\n",
      "Iteration 565, loss = 0.06690183\n",
      "Iteration 566, loss = 0.06673094\n",
      "Iteration 567, loss = 0.06655820\n",
      "Iteration 568, loss = 0.06639162\n",
      "Iteration 569, loss = 0.06622653\n",
      "Iteration 570, loss = 0.06606042\n",
      "Iteration 571, loss = 0.06589602\n",
      "Iteration 572, loss = 0.06573277\n",
      "Iteration 573, loss = 0.06558154\n",
      "Iteration 574, loss = 0.06541314\n",
      "Iteration 575, loss = 0.06525678\n",
      "Iteration 576, loss = 0.06508840\n",
      "Iteration 577, loss = 0.06493135\n",
      "Iteration 578, loss = 0.06477070\n",
      "Iteration 579, loss = 0.06461947\n",
      "Iteration 580, loss = 0.06445827\n",
      "Iteration 581, loss = 0.06430528\n",
      "Iteration 582, loss = 0.06415078\n",
      "Iteration 583, loss = 0.06399644\n",
      "Iteration 584, loss = 0.06384282\n",
      "Iteration 585, loss = 0.06369575\n",
      "Iteration 586, loss = 0.06353254\n",
      "Iteration 587, loss = 0.06339049\n",
      "Iteration 588, loss = 0.06323391\n",
      "Iteration 589, loss = 0.06308434\n",
      "Iteration 590, loss = 0.06293090\n",
      "Iteration 591, loss = 0.06278871\n",
      "Iteration 592, loss = 0.06263863\n",
      "Iteration 593, loss = 0.06249434\n",
      "Iteration 594, loss = 0.06235135\n",
      "Iteration 595, loss = 0.06220751\n",
      "Iteration 596, loss = 0.06206702\n",
      "Iteration 597, loss = 0.06192722\n",
      "Iteration 598, loss = 0.06178742\n",
      "Iteration 599, loss = 0.06165246\n",
      "Iteration 600, loss = 0.06151416\n",
      "Iteration 601, loss = 0.06137647\n",
      "Iteration 602, loss = 0.06123887\n",
      "Iteration 603, loss = 0.06109758\n",
      "Iteration 604, loss = 0.06096013\n",
      "Iteration 605, loss = 0.06082311\n",
      "Iteration 606, loss = 0.06068137\n",
      "Iteration 607, loss = 0.06053977\n",
      "Iteration 608, loss = 0.06040336\n",
      "Iteration 609, loss = 0.06026302\n",
      "Iteration 610, loss = 0.06012753\n",
      "Iteration 611, loss = 0.05998775\n",
      "Iteration 612, loss = 0.05985270\n",
      "Iteration 613, loss = 0.05971648\n",
      "Iteration 614, loss = 0.05958239\n",
      "Iteration 615, loss = 0.05945041\n",
      "Iteration 616, loss = 0.05931609\n",
      "Iteration 617, loss = 0.05918121\n",
      "Iteration 618, loss = 0.05904850\n",
      "Iteration 619, loss = 0.05891244\n",
      "Iteration 620, loss = 0.05877813\n",
      "Iteration 621, loss = 0.05865396\n",
      "Iteration 622, loss = 0.05851965\n",
      "Iteration 623, loss = 0.05839436\n",
      "Iteration 624, loss = 0.05826812\n",
      "Iteration 625, loss = 0.05813911\n",
      "Iteration 626, loss = 0.05801170\n",
      "Iteration 627, loss = 0.05788452\n",
      "Iteration 628, loss = 0.05775989\n",
      "Iteration 629, loss = 0.05763549\n",
      "Iteration 630, loss = 0.05750878\n",
      "Iteration 631, loss = 0.05738801\n",
      "Iteration 632, loss = 0.05726598\n",
      "Iteration 633, loss = 0.05714507\n",
      "Iteration 634, loss = 0.05702534\n",
      "Iteration 635, loss = 0.05690676\n",
      "Iteration 636, loss = 0.05678490\n",
      "Iteration 637, loss = 0.05666195\n",
      "Iteration 638, loss = 0.05654090\n",
      "Iteration 639, loss = 0.05642478\n",
      "Iteration 640, loss = 0.05630298\n",
      "Iteration 641, loss = 0.05618494\n",
      "Iteration 642, loss = 0.05607095\n",
      "Iteration 643, loss = 0.05594946\n",
      "Iteration 644, loss = 0.05583481\n",
      "Iteration 645, loss = 0.05571850\n",
      "Iteration 646, loss = 0.05560213\n",
      "Iteration 647, loss = 0.05548648\n",
      "Iteration 648, loss = 0.05537533\n",
      "Iteration 649, loss = 0.05526401\n",
      "Iteration 650, loss = 0.05515471\n",
      "Iteration 651, loss = 0.05504560\n",
      "Iteration 652, loss = 0.05493865\n",
      "Iteration 653, loss = 0.05483156\n",
      "Iteration 654, loss = 0.05472164\n",
      "Iteration 655, loss = 0.05461579\n",
      "Iteration 656, loss = 0.05450600\n",
      "Iteration 657, loss = 0.05439408\n",
      "Iteration 658, loss = 0.05428361\n",
      "Iteration 659, loss = 0.05417035\n",
      "Iteration 660, loss = 0.05406161\n",
      "Iteration 661, loss = 0.05395256\n",
      "Iteration 662, loss = 0.05384259\n",
      "Iteration 663, loss = 0.05374046\n",
      "Iteration 664, loss = 0.05362745\n",
      "Iteration 665, loss = 0.05352155\n",
      "Iteration 666, loss = 0.05341709\n",
      "Iteration 667, loss = 0.05331196\n",
      "Iteration 668, loss = 0.05320947\n",
      "Iteration 669, loss = 0.05311189\n",
      "Iteration 670, loss = 0.05300406\n",
      "Iteration 671, loss = 0.05290282\n",
      "Iteration 672, loss = 0.05279900\n",
      "Iteration 673, loss = 0.05269672\n",
      "Iteration 674, loss = 0.05259673\n",
      "Iteration 675, loss = 0.05249779\n",
      "Iteration 676, loss = 0.05239549\n",
      "Iteration 677, loss = 0.05229452\n",
      "Iteration 678, loss = 0.05219248\n",
      "Iteration 679, loss = 0.05209797\n",
      "Iteration 680, loss = 0.05199795\n",
      "Iteration 681, loss = 0.05189693\n",
      "Iteration 682, loss = 0.05180286\n",
      "Iteration 683, loss = 0.05170096\n",
      "Iteration 684, loss = 0.05160421\n",
      "Iteration 685, loss = 0.05150267\n",
      "Iteration 686, loss = 0.05140661\n",
      "Iteration 687, loss = 0.05131016\n",
      "Iteration 688, loss = 0.05121296\n",
      "Iteration 689, loss = 0.05111552\n",
      "Iteration 690, loss = 0.05101899\n",
      "Iteration 691, loss = 0.05092350\n",
      "Iteration 692, loss = 0.05083433\n",
      "Iteration 693, loss = 0.05073339\n",
      "Iteration 694, loss = 0.05064256\n",
      "Iteration 695, loss = 0.05054524\n",
      "Iteration 696, loss = 0.05044976\n",
      "Iteration 697, loss = 0.05035732\n",
      "Iteration 698, loss = 0.05026548\n",
      "Iteration 699, loss = 0.05017915\n",
      "Iteration 700, loss = 0.05008243\n",
      "Iteration 701, loss = 0.04999464\n",
      "Iteration 702, loss = 0.04990247\n",
      "Iteration 703, loss = 0.04981929\n",
      "Iteration 704, loss = 0.04972174\n",
      "Iteration 705, loss = 0.04963297\n",
      "Iteration 706, loss = 0.04954922\n",
      "Iteration 707, loss = 0.04945936\n",
      "Iteration 708, loss = 0.04937198\n",
      "Iteration 709, loss = 0.04928579\n",
      "Iteration 710, loss = 0.04919901\n",
      "Iteration 711, loss = 0.04911069\n",
      "Iteration 712, loss = 0.04902322\n",
      "Iteration 713, loss = 0.04893524\n",
      "Iteration 714, loss = 0.04884979\n",
      "Iteration 715, loss = 0.04876103\n",
      "Iteration 716, loss = 0.04867257\n",
      "Iteration 717, loss = 0.04858244\n",
      "Iteration 718, loss = 0.04849590\n",
      "Iteration 719, loss = 0.04840783\n",
      "Iteration 720, loss = 0.04831636\n",
      "Iteration 721, loss = 0.04823136\n",
      "Iteration 722, loss = 0.04814302\n",
      "Iteration 723, loss = 0.04805965\n",
      "Iteration 724, loss = 0.04797515\n",
      "Iteration 725, loss = 0.04788652\n",
      "Iteration 726, loss = 0.04780248\n",
      "Iteration 727, loss = 0.04771604\n",
      "Iteration 728, loss = 0.04763497\n",
      "Iteration 729, loss = 0.04754732\n",
      "Iteration 730, loss = 0.04746527\n",
      "Iteration 731, loss = 0.04737976\n",
      "Iteration 732, loss = 0.04729623\n",
      "Iteration 733, loss = 0.04721409\n",
      "Iteration 734, loss = 0.04713192\n",
      "Iteration 735, loss = 0.04705131\n",
      "Iteration 736, loss = 0.04697372\n",
      "Iteration 737, loss = 0.04689226\n",
      "Iteration 738, loss = 0.04681190\n",
      "Iteration 739, loss = 0.04673356\n",
      "Iteration 740, loss = 0.04665805\n",
      "Iteration 741, loss = 0.04657630\n",
      "Iteration 742, loss = 0.04650084\n",
      "Iteration 743, loss = 0.04641963\n",
      "Iteration 744, loss = 0.04634455\n",
      "Iteration 745, loss = 0.04627250\n",
      "Iteration 746, loss = 0.04619383\n",
      "Iteration 747, loss = 0.04611603\n",
      "Iteration 748, loss = 0.04604238\n",
      "Iteration 749, loss = 0.04596684\n",
      "Iteration 750, loss = 0.04589408\n",
      "Iteration 751, loss = 0.04581581\n",
      "Iteration 752, loss = 0.04574314\n",
      "Iteration 753, loss = 0.04567219\n",
      "Iteration 754, loss = 0.04559746\n",
      "Iteration 755, loss = 0.04552485\n",
      "Iteration 756, loss = 0.04545256\n",
      "Iteration 757, loss = 0.04537990\n",
      "Iteration 758, loss = 0.04530796\n",
      "Iteration 759, loss = 0.04523772\n",
      "Iteration 760, loss = 0.04516678\n",
      "Iteration 761, loss = 0.04509273\n",
      "Iteration 762, loss = 0.04502101\n",
      "Iteration 763, loss = 0.04495338\n",
      "Iteration 764, loss = 0.04488029\n",
      "Iteration 765, loss = 0.04480713\n",
      "Iteration 766, loss = 0.04473730\n",
      "Iteration 767, loss = 0.04466386\n",
      "Iteration 768, loss = 0.04459387\n",
      "Iteration 769, loss = 0.04452018\n",
      "Iteration 770, loss = 0.04445124\n",
      "Iteration 771, loss = 0.04437915\n",
      "Iteration 772, loss = 0.04430887\n",
      "Iteration 773, loss = 0.04423693\n",
      "Iteration 774, loss = 0.04416850\n",
      "Iteration 775, loss = 0.04409631\n",
      "Iteration 776, loss = 0.04402923\n",
      "Iteration 777, loss = 0.04396057\n",
      "Iteration 778, loss = 0.04389034\n",
      "Iteration 779, loss = 0.04382826\n",
      "Iteration 780, loss = 0.04375778\n",
      "Iteration 781, loss = 0.04368401\n",
      "Iteration 782, loss = 0.04361565\n",
      "Iteration 783, loss = 0.04354612\n",
      "Iteration 784, loss = 0.04347595\n",
      "Iteration 785, loss = 0.04340590\n",
      "Iteration 786, loss = 0.04333781\n",
      "Iteration 787, loss = 0.04327260\n",
      "Iteration 788, loss = 0.04320264\n",
      "Iteration 789, loss = 0.04313359\n",
      "Iteration 790, loss = 0.04306864\n",
      "Iteration 791, loss = 0.04300334\n",
      "Iteration 792, loss = 0.04293904\n",
      "Iteration 793, loss = 0.04287611\n",
      "Iteration 794, loss = 0.04281002\n",
      "Iteration 795, loss = 0.04274982\n",
      "Iteration 796, loss = 0.04268367\n",
      "Iteration 797, loss = 0.04262005\n",
      "Iteration 798, loss = 0.04255494\n",
      "Iteration 799, loss = 0.04249224\n",
      "Iteration 800, loss = 0.04242836\n",
      "Iteration 801, loss = 0.04236292\n",
      "Iteration 802, loss = 0.04230032\n",
      "Iteration 803, loss = 0.04223772\n",
      "Iteration 804, loss = 0.04217533\n",
      "Iteration 805, loss = 0.04211813\n",
      "Iteration 806, loss = 0.04205419\n",
      "Iteration 807, loss = 0.04199210\n",
      "Iteration 808, loss = 0.04192953\n",
      "Iteration 809, loss = 0.04186746\n",
      "Iteration 810, loss = 0.04180764\n",
      "Iteration 811, loss = 0.04175197\n",
      "Iteration 812, loss = 0.04168238\n",
      "Iteration 813, loss = 0.04161731\n",
      "Iteration 814, loss = 0.04155507\n",
      "Iteration 815, loss = 0.04149575\n",
      "Iteration 816, loss = 0.04143136\n",
      "Iteration 817, loss = 0.04136947\n",
      "Iteration 818, loss = 0.04130886\n",
      "Iteration 819, loss = 0.04124333\n",
      "Iteration 820, loss = 0.04118696\n",
      "Iteration 821, loss = 0.04111715\n",
      "Iteration 822, loss = 0.04105839\n",
      "Iteration 823, loss = 0.04100070\n",
      "Iteration 824, loss = 0.04093453\n",
      "Iteration 825, loss = 0.04087562\n",
      "Iteration 826, loss = 0.04081648\n",
      "Iteration 827, loss = 0.04076386\n",
      "Iteration 828, loss = 0.04069880\n",
      "Iteration 829, loss = 0.04064258\n",
      "Iteration 830, loss = 0.04058377\n",
      "Iteration 831, loss = 0.04052698\n",
      "Iteration 832, loss = 0.04046905\n",
      "Iteration 833, loss = 0.04041316\n",
      "Iteration 834, loss = 0.04035936\n",
      "Iteration 835, loss = 0.04029960\n",
      "Iteration 836, loss = 0.04024528\n",
      "Iteration 837, loss = 0.04018902\n",
      "Iteration 838, loss = 0.04013149\n",
      "Iteration 839, loss = 0.04007334\n",
      "Iteration 840, loss = 0.04001919\n",
      "Iteration 841, loss = 0.03995925\n",
      "Iteration 842, loss = 0.03990250\n",
      "Iteration 843, loss = 0.03984750\n",
      "Iteration 844, loss = 0.03979076\n",
      "Iteration 845, loss = 0.03973619\n",
      "Iteration 846, loss = 0.03968230\n",
      "Iteration 847, loss = 0.03962767\n",
      "Iteration 848, loss = 0.03957451\n",
      "Iteration 849, loss = 0.03952125\n",
      "Iteration 850, loss = 0.03947070\n",
      "Iteration 851, loss = 0.03941495\n",
      "Iteration 852, loss = 0.03936007\n",
      "Iteration 853, loss = 0.03930592\n",
      "Iteration 854, loss = 0.03925277\n",
      "Iteration 855, loss = 0.03919903\n",
      "Iteration 856, loss = 0.03914399\n",
      "Iteration 857, loss = 0.03909400\n",
      "Iteration 858, loss = 0.03903981\n",
      "Iteration 859, loss = 0.03898864\n",
      "Iteration 860, loss = 0.03893564\n",
      "Iteration 861, loss = 0.03888091\n",
      "Iteration 862, loss = 0.03882719\n",
      "Iteration 863, loss = 0.03877547\n",
      "Iteration 864, loss = 0.03871802\n",
      "Iteration 865, loss = 0.03866415\n",
      "Iteration 866, loss = 0.03861289\n",
      "Iteration 867, loss = 0.03856039\n",
      "Iteration 868, loss = 0.03850848\n",
      "Iteration 869, loss = 0.03845719\n",
      "Iteration 870, loss = 0.03840770\n",
      "Iteration 871, loss = 0.03835758\n",
      "Iteration 872, loss = 0.03830838\n",
      "Iteration 873, loss = 0.03825725\n",
      "Iteration 874, loss = 0.03820796\n",
      "Iteration 875, loss = 0.03815522\n",
      "Iteration 876, loss = 0.03810432\n",
      "Iteration 877, loss = 0.03805498\n",
      "Iteration 878, loss = 0.03800002\n",
      "Iteration 879, loss = 0.03795063\n",
      "Iteration 880, loss = 0.03789778\n",
      "Iteration 881, loss = 0.03785147\n",
      "Iteration 882, loss = 0.03779704\n",
      "Iteration 883, loss = 0.03774701\n",
      "Iteration 884, loss = 0.03769607\n",
      "Iteration 885, loss = 0.03764561\n",
      "Iteration 886, loss = 0.03759531\n",
      "Iteration 887, loss = 0.03754513\n",
      "Iteration 888, loss = 0.03749634\n",
      "Iteration 889, loss = 0.03744280\n",
      "Iteration 890, loss = 0.03739662\n",
      "Iteration 891, loss = 0.03734343\n",
      "Iteration 892, loss = 0.03729159\n",
      "Iteration 893, loss = 0.03724163\n",
      "Iteration 894, loss = 0.03719306\n",
      "Iteration 895, loss = 0.03713820\n",
      "Iteration 896, loss = 0.03708806\n",
      "Iteration 897, loss = 0.03703783\n",
      "Iteration 898, loss = 0.03698677\n",
      "Iteration 899, loss = 0.03693780\n",
      "Iteration 900, loss = 0.03688609\n",
      "Iteration 901, loss = 0.03683792\n",
      "Iteration 902, loss = 0.03678953\n",
      "Iteration 903, loss = 0.03674071\n",
      "Iteration 904, loss = 0.03669352\n",
      "Iteration 905, loss = 0.03664268\n",
      "Iteration 906, loss = 0.03659479\n",
      "Iteration 907, loss = 0.03654650\n",
      "Iteration 908, loss = 0.03650078\n",
      "Iteration 909, loss = 0.03645321\n",
      "Iteration 910, loss = 0.03640500\n",
      "Iteration 911, loss = 0.03635766\n",
      "Iteration 912, loss = 0.03631344\n",
      "Iteration 913, loss = 0.03626334\n",
      "Iteration 914, loss = 0.03621593\n",
      "Iteration 915, loss = 0.03617057\n",
      "Iteration 916, loss = 0.03612162\n",
      "Iteration 917, loss = 0.03608019\n",
      "Iteration 918, loss = 0.03603143\n",
      "Iteration 919, loss = 0.03598698\n",
      "Iteration 920, loss = 0.03594075\n",
      "Iteration 921, loss = 0.03589536\n",
      "Iteration 922, loss = 0.03584978\n",
      "Iteration 923, loss = 0.03580510\n",
      "Iteration 924, loss = 0.03576028\n",
      "Iteration 925, loss = 0.03571417\n",
      "Iteration 926, loss = 0.03567034\n",
      "Iteration 927, loss = 0.03562373\n",
      "Iteration 928, loss = 0.03558035\n",
      "Iteration 929, loss = 0.03553526\n",
      "Iteration 930, loss = 0.03548748\n",
      "Iteration 931, loss = 0.03544176\n",
      "Iteration 932, loss = 0.03539861\n",
      "Iteration 933, loss = 0.03535117\n",
      "Iteration 934, loss = 0.03530864\n",
      "Iteration 935, loss = 0.03526565\n",
      "Iteration 936, loss = 0.03522169\n",
      "Iteration 937, loss = 0.03518218\n",
      "Iteration 938, loss = 0.03513856\n",
      "Iteration 939, loss = 0.03509505\n",
      "Iteration 940, loss = 0.03505390\n",
      "Iteration 941, loss = 0.03501064\n",
      "Iteration 942, loss = 0.03496870\n",
      "Iteration 943, loss = 0.03492763\n",
      "Iteration 944, loss = 0.03488745\n",
      "Iteration 945, loss = 0.03484545\n",
      "Iteration 946, loss = 0.03480401\n",
      "Iteration 947, loss = 0.03476307\n",
      "Iteration 948, loss = 0.03472457\n",
      "Iteration 949, loss = 0.03468094\n",
      "Iteration 950, loss = 0.03463919\n",
      "Iteration 951, loss = 0.03459371\n",
      "Iteration 952, loss = 0.03455231\n",
      "Iteration 953, loss = 0.03451074\n",
      "Iteration 954, loss = 0.03446681\n",
      "Iteration 955, loss = 0.03442570\n",
      "Iteration 956, loss = 0.03438878\n",
      "Iteration 957, loss = 0.03434464\n",
      "Iteration 958, loss = 0.03430181\n",
      "Iteration 959, loss = 0.03426359\n",
      "Iteration 960, loss = 0.03422053\n",
      "Iteration 961, loss = 0.03417926\n",
      "Iteration 962, loss = 0.03413828\n",
      "Iteration 963, loss = 0.03409558\n",
      "Iteration 964, loss = 0.03405394\n",
      "Iteration 965, loss = 0.03401366\n",
      "Iteration 966, loss = 0.03397499\n",
      "Iteration 967, loss = 0.03393158\n",
      "Iteration 968, loss = 0.03389232\n",
      "Iteration 969, loss = 0.03385103\n",
      "Iteration 970, loss = 0.03380831\n",
      "Iteration 971, loss = 0.03377018\n",
      "Iteration 972, loss = 0.03372989\n",
      "Iteration 973, loss = 0.03368622\n",
      "Iteration 974, loss = 0.03364691\n",
      "Iteration 975, loss = 0.03360873\n",
      "Iteration 976, loss = 0.03356947\n",
      "Iteration 977, loss = 0.03352926\n",
      "Iteration 978, loss = 0.03349013\n",
      "Iteration 979, loss = 0.03345193\n",
      "Iteration 980, loss = 0.03341484\n",
      "Iteration 981, loss = 0.03337962\n",
      "Iteration 982, loss = 0.03333720\n",
      "Iteration 983, loss = 0.03329905\n",
      "Iteration 984, loss = 0.03326011\n",
      "Iteration 985, loss = 0.03322462\n",
      "Iteration 986, loss = 0.03318424\n",
      "Iteration 987, loss = 0.03314661\n",
      "Iteration 988, loss = 0.03311000\n",
      "Iteration 989, loss = 0.03307456\n",
      "Iteration 990, loss = 0.03303668\n",
      "Iteration 991, loss = 0.03300053\n",
      "Iteration 992, loss = 0.03296346\n",
      "Iteration 993, loss = 0.03292244\n",
      "Iteration 994, loss = 0.03288682\n",
      "Iteration 995, loss = 0.03284619\n",
      "Iteration 996, loss = 0.03281045\n",
      "Iteration 997, loss = 0.03277170\n",
      "Iteration 998, loss = 0.03273444\n",
      "Iteration 999, loss = 0.03269763\n",
      "Iteration 1000, loss = 0.03266057\n",
      "Iteration 1001, loss = 0.03262538\n",
      "Iteration 1002, loss = 0.03258720\n",
      "Iteration 1003, loss = 0.03255203\n",
      "Iteration 1004, loss = 0.03251655\n",
      "Iteration 1005, loss = 0.03248194\n",
      "Iteration 1006, loss = 0.03244585\n",
      "Iteration 1007, loss = 0.03241225\n",
      "Iteration 1008, loss = 0.03237564\n",
      "Iteration 1009, loss = 0.03233938\n",
      "Iteration 1010, loss = 0.03230513\n",
      "Iteration 1011, loss = 0.03227085\n",
      "Iteration 1012, loss = 0.03223480\n",
      "Iteration 1013, loss = 0.03219741\n",
      "Iteration 1014, loss = 0.03215833\n",
      "Iteration 1015, loss = 0.03212497\n",
      "Iteration 1016, loss = 0.03209074\n",
      "Iteration 1017, loss = 0.03205252\n",
      "Iteration 1018, loss = 0.03201955\n",
      "Iteration 1019, loss = 0.03198418\n",
      "Iteration 1020, loss = 0.03194841\n",
      "Iteration 1021, loss = 0.03191532\n",
      "Iteration 1022, loss = 0.03188221\n",
      "Iteration 1023, loss = 0.03184502\n",
      "Iteration 1024, loss = 0.03181179\n",
      "Iteration 1025, loss = 0.03177415\n",
      "Iteration 1026, loss = 0.03173905\n",
      "Iteration 1027, loss = 0.03170447\n",
      "Iteration 1028, loss = 0.03166972\n",
      "Iteration 1029, loss = 0.03163618\n",
      "Iteration 1030, loss = 0.03160208\n",
      "Iteration 1031, loss = 0.03156747\n",
      "Iteration 1032, loss = 0.03153424\n",
      "Iteration 1033, loss = 0.03150016\n",
      "Iteration 1034, loss = 0.03146524\n",
      "Iteration 1035, loss = 0.03142948\n",
      "Iteration 1036, loss = 0.03139540\n",
      "Iteration 1037, loss = 0.03135990\n",
      "Iteration 1038, loss = 0.03132440\n",
      "Iteration 1039, loss = 0.03128698\n",
      "Iteration 1040, loss = 0.03125196\n",
      "Iteration 1041, loss = 0.03122194\n",
      "Iteration 1042, loss = 0.03118018\n",
      "Iteration 1043, loss = 0.03114812\n",
      "Iteration 1044, loss = 0.03111337\n",
      "Iteration 1045, loss = 0.03107731\n",
      "Iteration 1046, loss = 0.03104581\n",
      "Iteration 1047, loss = 0.03101128\n",
      "Iteration 1048, loss = 0.03097881\n",
      "Iteration 1049, loss = 0.03094587\n",
      "Iteration 1050, loss = 0.03091155\n",
      "Iteration 1051, loss = 0.03087908\n",
      "Iteration 1052, loss = 0.03084684\n",
      "Iteration 1053, loss = 0.03081490\n",
      "Iteration 1054, loss = 0.03078349\n",
      "Iteration 1055, loss = 0.03075115\n",
      "Iteration 1056, loss = 0.03071810\n",
      "Iteration 1057, loss = 0.03068771\n",
      "Iteration 1058, loss = 0.03065570\n",
      "Iteration 1059, loss = 0.03062321\n",
      "Iteration 1060, loss = 0.03059285\n",
      "Iteration 1061, loss = 0.03055713\n",
      "Iteration 1062, loss = 0.03052332\n",
      "Iteration 1063, loss = 0.03048979\n",
      "Iteration 1064, loss = 0.03045751\n",
      "Iteration 1065, loss = 0.03042902\n",
      "Iteration 1066, loss = 0.03039103\n",
      "Iteration 1067, loss = 0.03035664\n",
      "Iteration 1068, loss = 0.03032810\n",
      "Iteration 1069, loss = 0.03029399\n",
      "Iteration 1070, loss = 0.03026226\n",
      "Iteration 1071, loss = 0.03023278\n",
      "Iteration 1072, loss = 0.03020093\n",
      "Iteration 1073, loss = 0.03017084\n",
      "Iteration 1074, loss = 0.03014072\n",
      "Iteration 1075, loss = 0.03010796\n",
      "Iteration 1076, loss = 0.03007754\n",
      "Iteration 1077, loss = 0.03004695\n",
      "Iteration 1078, loss = 0.03001601\n",
      "Iteration 1079, loss = 0.02998546\n",
      "Iteration 1080, loss = 0.02995117\n",
      "Iteration 1081, loss = 0.02991992\n",
      "Iteration 1082, loss = 0.02989060\n",
      "Iteration 1083, loss = 0.02985546\n",
      "Iteration 1084, loss = 0.02982506\n",
      "Iteration 1085, loss = 0.02979502\n",
      "Iteration 1086, loss = 0.02976279\n",
      "Iteration 1087, loss = 0.02973581\n",
      "Iteration 1088, loss = 0.02970733\n",
      "Iteration 1089, loss = 0.02967638\n",
      "Iteration 1090, loss = 0.02964642\n",
      "Iteration 1091, loss = 0.02961963\n",
      "Iteration 1092, loss = 0.02958990\n",
      "Iteration 1093, loss = 0.02956134\n",
      "Iteration 1094, loss = 0.02953376\n",
      "Iteration 1095, loss = 0.02950257\n",
      "Iteration 1096, loss = 0.02947391\n",
      "Iteration 1097, loss = 0.02944530\n",
      "Iteration 1098, loss = 0.02941561\n",
      "Iteration 1099, loss = 0.02938706\n",
      "Iteration 1100, loss = 0.02935843\n",
      "Iteration 1101, loss = 0.02932847\n",
      "Iteration 1102, loss = 0.02929904\n",
      "Iteration 1103, loss = 0.02927141\n",
      "Iteration 1104, loss = 0.02923976\n",
      "Iteration 1105, loss = 0.02921072\n",
      "Iteration 1106, loss = 0.02918098\n",
      "Iteration 1107, loss = 0.02915156\n",
      "Iteration 1108, loss = 0.02912443\n",
      "Iteration 1109, loss = 0.02909474\n",
      "Iteration 1110, loss = 0.02906705\n",
      "Iteration 1111, loss = 0.02903816\n",
      "Iteration 1112, loss = 0.02901077\n",
      "Iteration 1113, loss = 0.02898231\n",
      "Iteration 1114, loss = 0.02895254\n",
      "Iteration 1115, loss = 0.02892740\n",
      "Iteration 1116, loss = 0.02889933\n",
      "Iteration 1117, loss = 0.02887151\n",
      "Iteration 1118, loss = 0.02884260\n",
      "Iteration 1119, loss = 0.02881466\n",
      "Iteration 1120, loss = 0.02878748\n",
      "Iteration 1121, loss = 0.02875903\n",
      "Iteration 1122, loss = 0.02873248\n",
      "Iteration 1123, loss = 0.02870624\n",
      "Iteration 1124, loss = 0.02867961\n",
      "Iteration 1125, loss = 0.02865026\n",
      "Iteration 1126, loss = 0.02862274\n",
      "Iteration 1127, loss = 0.02859545\n",
      "Iteration 1128, loss = 0.02856690\n",
      "Iteration 1129, loss = 0.02853882\n",
      "Iteration 1130, loss = 0.02850988\n",
      "Iteration 1131, loss = 0.02848117\n",
      "Iteration 1132, loss = 0.02845292\n",
      "Iteration 1133, loss = 0.02842318\n",
      "Iteration 1134, loss = 0.02839694\n",
      "Iteration 1135, loss = 0.02836911\n",
      "Iteration 1136, loss = 0.02834056\n",
      "Iteration 1137, loss = 0.02831350\n",
      "Iteration 1138, loss = 0.02828709\n",
      "Iteration 1139, loss = 0.02826015\n",
      "Iteration 1140, loss = 0.02823388\n",
      "Iteration 1141, loss = 0.02820624\n",
      "Iteration 1142, loss = 0.02818026\n",
      "Iteration 1143, loss = 0.02815193\n",
      "Iteration 1144, loss = 0.02812588\n",
      "Iteration 1145, loss = 0.02810096\n",
      "Iteration 1146, loss = 0.02807629\n",
      "Iteration 1147, loss = 0.02805187\n",
      "Iteration 1148, loss = 0.02802650\n",
      "Iteration 1149, loss = 0.02800196\n",
      "Iteration 1150, loss = 0.02797697\n",
      "Iteration 1151, loss = 0.02795334\n",
      "Iteration 1152, loss = 0.02792963\n",
      "Iteration 1153, loss = 0.02790559\n",
      "Iteration 1154, loss = 0.02788299\n",
      "Iteration 1155, loss = 0.02785850\n",
      "Iteration 1156, loss = 0.02783413\n",
      "Iteration 1157, loss = 0.02781019\n",
      "Iteration 1158, loss = 0.02778496\n",
      "Iteration 1159, loss = 0.02776131\n",
      "Iteration 1160, loss = 0.02773685\n",
      "Iteration 1161, loss = 0.02771252\n",
      "Iteration 1162, loss = 0.02768675\n",
      "Iteration 1163, loss = 0.02766221\n",
      "Iteration 1164, loss = 0.02763658\n",
      "Iteration 1165, loss = 0.02761081\n",
      "Iteration 1166, loss = 0.02758595\n",
      "Iteration 1167, loss = 0.02756125\n",
      "Iteration 1168, loss = 0.02753465\n",
      "Iteration 1169, loss = 0.02751078\n",
      "Iteration 1170, loss = 0.02748773\n",
      "Iteration 1171, loss = 0.02746158\n",
      "Iteration 1172, loss = 0.02743245\n",
      "Iteration 1173, loss = 0.02740114\n",
      "Iteration 1174, loss = 0.02737421\n",
      "Iteration 1175, loss = 0.02734989\n",
      "Iteration 1176, loss = 0.02732131\n",
      "Iteration 1177, loss = 0.02729358\n",
      "Iteration 1178, loss = 0.02726757\n",
      "Iteration 1179, loss = 0.02724194\n",
      "Iteration 1180, loss = 0.02721598\n",
      "Iteration 1181, loss = 0.02718725\n",
      "Iteration 1182, loss = 0.02716169\n",
      "Iteration 1183, loss = 0.02713540\n",
      "Iteration 1184, loss = 0.02711032\n",
      "Iteration 1185, loss = 0.02708567\n",
      "Iteration 1186, loss = 0.02706100\n",
      "Iteration 1187, loss = 0.02703358\n",
      "Iteration 1188, loss = 0.02700937\n",
      "Iteration 1189, loss = 0.02698536\n",
      "Iteration 1190, loss = 0.02696177\n",
      "Iteration 1191, loss = 0.02693789\n",
      "Iteration 1192, loss = 0.02691210\n",
      "Iteration 1193, loss = 0.02688741\n",
      "Iteration 1194, loss = 0.02686188\n",
      "Iteration 1195, loss = 0.02683994\n",
      "Iteration 1196, loss = 0.02681122\n",
      "Iteration 1197, loss = 0.02678910\n",
      "Iteration 1198, loss = 0.02676276\n",
      "Iteration 1199, loss = 0.02673920\n",
      "Iteration 1200, loss = 0.02671422\n",
      "Iteration 1201, loss = 0.02668929\n",
      "Iteration 1202, loss = 0.02666464\n",
      "Iteration 1203, loss = 0.02664142\n",
      "Iteration 1204, loss = 0.02661318\n",
      "Iteration 1205, loss = 0.02658984\n",
      "Iteration 1206, loss = 0.02656283\n",
      "Iteration 1207, loss = 0.02653561\n",
      "Iteration 1208, loss = 0.02651235\n",
      "Iteration 1209, loss = 0.02648592\n",
      "Iteration 1210, loss = 0.02645999\n",
      "Iteration 1211, loss = 0.02643292\n",
      "Iteration 1212, loss = 0.02641219\n",
      "Iteration 1213, loss = 0.02638382\n",
      "Iteration 1214, loss = 0.02636084\n",
      "Iteration 1215, loss = 0.02633517\n",
      "Iteration 1216, loss = 0.02631464\n",
      "Iteration 1217, loss = 0.02628555\n",
      "Iteration 1218, loss = 0.02626186\n",
      "Iteration 1219, loss = 0.02623963\n",
      "Iteration 1220, loss = 0.02621220\n",
      "Iteration 1221, loss = 0.02618894\n",
      "Iteration 1222, loss = 0.02616512\n",
      "Iteration 1223, loss = 0.02614267\n",
      "Iteration 1224, loss = 0.02611847\n",
      "Iteration 1225, loss = 0.02609296\n",
      "Iteration 1226, loss = 0.02607243\n",
      "Iteration 1227, loss = 0.02604847\n",
      "Iteration 1228, loss = 0.02602385\n",
      "Iteration 1229, loss = 0.02600204\n",
      "Iteration 1230, loss = 0.02597913\n",
      "Iteration 1231, loss = 0.02595598\n",
      "Iteration 1232, loss = 0.02593307\n",
      "Iteration 1233, loss = 0.02590991\n",
      "Iteration 1234, loss = 0.02588823\n",
      "Iteration 1235, loss = 0.02586527\n",
      "Iteration 1236, loss = 0.02584288\n",
      "Iteration 1237, loss = 0.02582097\n",
      "Iteration 1238, loss = 0.02580007\n",
      "Iteration 1239, loss = 0.02577263\n",
      "Iteration 1240, loss = 0.02574980\n",
      "Iteration 1241, loss = 0.02572656\n",
      "Iteration 1242, loss = 0.02570274\n",
      "Iteration 1243, loss = 0.02567970\n",
      "Iteration 1244, loss = 0.02565643\n",
      "Iteration 1245, loss = 0.02563315\n",
      "Iteration 1246, loss = 0.02561039\n",
      "Iteration 1247, loss = 0.02558854\n",
      "Iteration 1248, loss = 0.02556901\n",
      "Iteration 1249, loss = 0.02554271\n",
      "Iteration 1250, loss = 0.02552007\n",
      "Iteration 1251, loss = 0.02549659\n",
      "Iteration 1252, loss = 0.02547360\n",
      "Iteration 1253, loss = 0.02545038\n",
      "Iteration 1254, loss = 0.02543072\n",
      "Iteration 1255, loss = 0.02540581\n",
      "Iteration 1256, loss = 0.02538349\n",
      "Iteration 1257, loss = 0.02535956\n",
      "Iteration 1258, loss = 0.02533671\n",
      "Iteration 1259, loss = 0.02531649\n",
      "Iteration 1260, loss = 0.02529310\n",
      "Iteration 1261, loss = 0.02527027\n",
      "Iteration 1262, loss = 0.02524932\n",
      "Iteration 1263, loss = 0.02522702\n",
      "Iteration 1264, loss = 0.02520555\n",
      "Iteration 1265, loss = 0.02518449\n",
      "Iteration 1266, loss = 0.02516316\n",
      "Iteration 1267, loss = 0.02514140\n",
      "Iteration 1268, loss = 0.02511820\n",
      "Iteration 1269, loss = 0.02509661\n",
      "Iteration 1270, loss = 0.02507611\n",
      "Iteration 1271, loss = 0.02505419\n",
      "Iteration 1272, loss = 0.02503281\n",
      "Iteration 1273, loss = 0.02501237\n",
      "Iteration 1274, loss = 0.02499173\n",
      "Iteration 1275, loss = 0.02497156\n",
      "Iteration 1276, loss = 0.02495035\n",
      "Iteration 1277, loss = 0.02492939\n",
      "Iteration 1278, loss = 0.02491107\n",
      "Iteration 1279, loss = 0.02488822\n",
      "Iteration 1280, loss = 0.02486773\n",
      "Iteration 1281, loss = 0.02484811\n",
      "Iteration 1282, loss = 0.02482727\n",
      "Iteration 1283, loss = 0.02480950\n",
      "Iteration 1284, loss = 0.02478735\n",
      "Iteration 1285, loss = 0.02476791\n",
      "Iteration 1286, loss = 0.02474960\n",
      "Iteration 1287, loss = 0.02472889\n",
      "Iteration 1288, loss = 0.02471084\n",
      "Iteration 1289, loss = 0.02468975\n",
      "Iteration 1290, loss = 0.02466962\n",
      "Iteration 1291, loss = 0.02464970\n",
      "Iteration 1292, loss = 0.02462886\n",
      "Iteration 1293, loss = 0.02460829\n",
      "Iteration 1294, loss = 0.02458843\n",
      "Iteration 1295, loss = 0.02456451\n",
      "Iteration 1296, loss = 0.02454639\n",
      "Iteration 1297, loss = 0.02452171\n",
      "Iteration 1298, loss = 0.02449968\n",
      "Iteration 1299, loss = 0.02447772\n",
      "Iteration 1300, loss = 0.02445819\n",
      "Iteration 1301, loss = 0.02443387\n",
      "Iteration 1302, loss = 0.02441375\n",
      "Iteration 1303, loss = 0.02439247\n",
      "Iteration 1304, loss = 0.02437131\n",
      "Iteration 1305, loss = 0.02434942\n",
      "Iteration 1306, loss = 0.02433053\n",
      "Iteration 1307, loss = 0.02430761\n",
      "Iteration 1308, loss = 0.02428651\n",
      "Iteration 1309, loss = 0.02426485\n",
      "Iteration 1310, loss = 0.02424530\n",
      "Iteration 1311, loss = 0.02422397\n",
      "Iteration 1312, loss = 0.02420295\n",
      "Iteration 1313, loss = 0.02418411\n",
      "Iteration 1314, loss = 0.02416217\n",
      "Iteration 1315, loss = 0.02414241\n",
      "Iteration 1316, loss = 0.02412483\n",
      "Iteration 1317, loss = 0.02410337\n",
      "Iteration 1318, loss = 0.02408302\n",
      "Iteration 1319, loss = 0.02406366\n",
      "Iteration 1320, loss = 0.02404209\n",
      "Iteration 1321, loss = 0.02402185\n",
      "Iteration 1322, loss = 0.02400165\n",
      "Iteration 1323, loss = 0.02398224\n",
      "Iteration 1324, loss = 0.02396251\n",
      "Iteration 1325, loss = 0.02394462\n",
      "Iteration 1326, loss = 0.02392322\n",
      "Iteration 1327, loss = 0.02390350\n",
      "Iteration 1328, loss = 0.02388517\n",
      "Iteration 1329, loss = 0.02386340\n",
      "Iteration 1330, loss = 0.02384482\n",
      "Iteration 1331, loss = 0.02382416\n",
      "Iteration 1332, loss = 0.02380280\n",
      "Iteration 1333, loss = 0.02378191\n",
      "Iteration 1334, loss = 0.02376389\n",
      "Iteration 1335, loss = 0.02374117\n",
      "Iteration 1336, loss = 0.02372103\n",
      "Iteration 1337, loss = 0.02370055\n",
      "Iteration 1338, loss = 0.02368021\n",
      "Iteration 1339, loss = 0.02366102\n",
      "Iteration 1340, loss = 0.02364114\n",
      "Iteration 1341, loss = 0.02362073\n",
      "Iteration 1342, loss = 0.02360056\n",
      "Iteration 1343, loss = 0.02358020\n",
      "Iteration 1344, loss = 0.02356297\n",
      "Iteration 1345, loss = 0.02354183\n",
      "Iteration 1346, loss = 0.02352277\n",
      "Iteration 1347, loss = 0.02350488\n",
      "Iteration 1348, loss = 0.02348700\n",
      "Iteration 1349, loss = 0.02346776\n",
      "Iteration 1350, loss = 0.02344940\n",
      "Iteration 1351, loss = 0.02343155\n",
      "Iteration 1352, loss = 0.02341463\n",
      "Iteration 1353, loss = 0.02339462\n",
      "Iteration 1354, loss = 0.02337675\n",
      "Iteration 1355, loss = 0.02335861\n",
      "Iteration 1356, loss = 0.02334111\n",
      "Iteration 1357, loss = 0.02332311\n",
      "Iteration 1358, loss = 0.02330622\n",
      "Iteration 1359, loss = 0.02328974\n",
      "Iteration 1360, loss = 0.02327345\n",
      "Iteration 1361, loss = 0.02325434\n",
      "Iteration 1362, loss = 0.02323586\n",
      "Iteration 1363, loss = 0.02321781\n",
      "Iteration 1364, loss = 0.02319989\n",
      "Iteration 1365, loss = 0.02318144\n",
      "Iteration 1366, loss = 0.02316337\n",
      "Iteration 1367, loss = 0.02314534\n",
      "Iteration 1368, loss = 0.02312752\n",
      "Iteration 1369, loss = 0.02311184\n",
      "Iteration 1370, loss = 0.02309124\n",
      "Iteration 1371, loss = 0.02307328\n",
      "Iteration 1372, loss = 0.02305516\n",
      "Iteration 1373, loss = 0.02303672\n",
      "Iteration 1374, loss = 0.02301869\n",
      "Iteration 1375, loss = 0.02300033\n",
      "Iteration 1376, loss = 0.02298299\n",
      "Iteration 1377, loss = 0.02296767\n",
      "Iteration 1378, loss = 0.02294863\n",
      "Iteration 1379, loss = 0.02292941\n",
      "Iteration 1380, loss = 0.02291150\n",
      "Iteration 1381, loss = 0.02289142\n",
      "Iteration 1382, loss = 0.02287186\n",
      "Iteration 1383, loss = 0.02285219\n",
      "Iteration 1384, loss = 0.02283117\n",
      "Iteration 1385, loss = 0.02281149\n",
      "Iteration 1386, loss = 0.02279034\n",
      "Iteration 1387, loss = 0.02277240\n",
      "Iteration 1388, loss = 0.02275308\n",
      "Iteration 1389, loss = 0.02273120\n",
      "Iteration 1390, loss = 0.02271394\n",
      "Iteration 1391, loss = 0.02269371\n",
      "Iteration 1392, loss = 0.02267440\n",
      "Iteration 1393, loss = 0.02265359\n",
      "Iteration 1394, loss = 0.02263729\n",
      "Iteration 1395, loss = 0.02261803\n",
      "Iteration 1396, loss = 0.02260023\n",
      "Iteration 1397, loss = 0.02258673\n",
      "Iteration 1398, loss = 0.02256599\n",
      "Iteration 1399, loss = 0.02254829\n",
      "Iteration 1400, loss = 0.02253171\n",
      "Iteration 1401, loss = 0.02251624\n",
      "Iteration 1402, loss = 0.02249896\n",
      "Iteration 1403, loss = 0.02248094\n",
      "Iteration 1404, loss = 0.02246463\n",
      "Iteration 1405, loss = 0.02244790\n",
      "Iteration 1406, loss = 0.02243083\n",
      "Iteration 1407, loss = 0.02241535\n",
      "Iteration 1408, loss = 0.02239910\n",
      "Iteration 1409, loss = 0.02238206\n",
      "Iteration 1410, loss = 0.02236554\n",
      "Iteration 1411, loss = 0.02234947\n",
      "Iteration 1412, loss = 0.02233388\n",
      "Iteration 1413, loss = 0.02231894\n",
      "Iteration 1414, loss = 0.02230234\n",
      "Iteration 1415, loss = 0.02228576\n",
      "Iteration 1416, loss = 0.02227124\n",
      "Iteration 1417, loss = 0.02225428\n",
      "Iteration 1418, loss = 0.02223898\n",
      "Iteration 1419, loss = 0.02222086\n",
      "Iteration 1420, loss = 0.02220521\n",
      "Iteration 1421, loss = 0.02218703\n",
      "Iteration 1422, loss = 0.02216991\n",
      "Iteration 1423, loss = 0.02215579\n",
      "Iteration 1424, loss = 0.02213573\n",
      "Iteration 1425, loss = 0.02211972\n",
      "Iteration 1426, loss = 0.02210378\n",
      "Iteration 1427, loss = 0.02208706\n",
      "Iteration 1428, loss = 0.02207154\n",
      "Iteration 1429, loss = 0.02205384\n",
      "Iteration 1430, loss = 0.02203524\n",
      "Iteration 1431, loss = 0.02201945\n",
      "Iteration 1432, loss = 0.02200063\n",
      "Iteration 1433, loss = 0.02198356\n",
      "Iteration 1434, loss = 0.02196548\n",
      "Iteration 1435, loss = 0.02195210\n",
      "Iteration 1436, loss = 0.02193192\n",
      "Iteration 1437, loss = 0.02191432\n",
      "Iteration 1438, loss = 0.02189894\n",
      "Iteration 1439, loss = 0.02188188\n",
      "Iteration 1440, loss = 0.02186756\n",
      "Iteration 1441, loss = 0.02184679\n",
      "Iteration 1442, loss = 0.02182877\n",
      "Iteration 1443, loss = 0.02181167\n",
      "Iteration 1444, loss = 0.02179827\n",
      "Iteration 1445, loss = 0.02177856\n",
      "Iteration 1446, loss = 0.02176285\n",
      "Iteration 1447, loss = 0.02174375\n",
      "Iteration 1448, loss = 0.02172814\n",
      "Iteration 1449, loss = 0.02171217\n",
      "Iteration 1450, loss = 0.02169456\n",
      "Iteration 1451, loss = 0.02167864\n",
      "Iteration 1452, loss = 0.02166143\n",
      "Iteration 1453, loss = 0.02164591\n",
      "Iteration 1454, loss = 0.02162908\n",
      "Iteration 1455, loss = 0.02161321\n",
      "Iteration 1456, loss = 0.02159646\n",
      "Iteration 1457, loss = 0.02157983\n",
      "Iteration 1458, loss = 0.02156508\n",
      "Iteration 1459, loss = 0.02154812\n",
      "Iteration 1460, loss = 0.02152963\n",
      "Iteration 1461, loss = 0.02151493\n",
      "Iteration 1462, loss = 0.02149660\n",
      "Iteration 1463, loss = 0.02147932\n",
      "Iteration 1464, loss = 0.02146357\n",
      "Iteration 1465, loss = 0.02144723\n",
      "Iteration 1466, loss = 0.02143025\n",
      "Iteration 1467, loss = 0.02141412\n",
      "Iteration 1468, loss = 0.02139831\n",
      "Iteration 1469, loss = 0.02138256\n",
      "Iteration 1470, loss = 0.02136725\n",
      "Iteration 1471, loss = 0.02135079\n",
      "Iteration 1472, loss = 0.02133277\n",
      "Iteration 1473, loss = 0.02131721\n",
      "Iteration 1474, loss = 0.02130075\n",
      "Iteration 1475, loss = 0.02128533\n",
      "Iteration 1476, loss = 0.02126912\n",
      "Iteration 1477, loss = 0.02125290\n",
      "Iteration 1478, loss = 0.02123729\n",
      "Iteration 1479, loss = 0.02122021\n",
      "Iteration 1480, loss = 0.02120504\n",
      "Iteration 1481, loss = 0.02119031\n",
      "Iteration 1482, loss = 0.02117582\n",
      "Iteration 1483, loss = 0.02115875\n",
      "Iteration 1484, loss = 0.02114100\n",
      "Iteration 1485, loss = 0.02112506\n",
      "Iteration 1486, loss = 0.02110800\n",
      "Iteration 1487, loss = 0.02109340\n",
      "Iteration 1488, loss = 0.02107699\n",
      "Iteration 1489, loss = 0.02106164\n",
      "Iteration 1490, loss = 0.02104503\n",
      "Iteration 1491, loss = 0.02102828\n",
      "Iteration 1492, loss = 0.02101290\n",
      "Iteration 1493, loss = 0.02099735\n",
      "Iteration 1494, loss = 0.02098152\n",
      "Iteration 1495, loss = 0.02096672\n",
      "Iteration 1496, loss = 0.02095056\n",
      "Iteration 1497, loss = 0.02093585\n",
      "Iteration 1498, loss = 0.02091991\n",
      "Iteration 1499, loss = 0.02090411\n",
      "Iteration 1500, loss = 0.02088634\n",
      "Iteration 1501, loss = 0.02087080\n",
      "Iteration 1502, loss = 0.02085435\n",
      "Iteration 1503, loss = 0.02084048\n",
      "Iteration 1504, loss = 0.02082391\n",
      "Iteration 1505, loss = 0.02081005\n",
      "Iteration 1506, loss = 0.02079527\n",
      "Iteration 1507, loss = 0.02078013\n",
      "Iteration 1508, loss = 0.02076492\n",
      "Iteration 1509, loss = 0.02074970\n",
      "Iteration 1510, loss = 0.02073380\n",
      "Iteration 1511, loss = 0.02071979\n",
      "Iteration 1512, loss = 0.02070420\n",
      "Iteration 1513, loss = 0.02069023\n",
      "Iteration 1514, loss = 0.02067536\n",
      "Iteration 1515, loss = 0.02066090\n",
      "Iteration 1516, loss = 0.02064676\n",
      "Iteration 1517, loss = 0.02063305\n",
      "Iteration 1518, loss = 0.02061888\n",
      "Iteration 1519, loss = 0.02060461\n",
      "Iteration 1520, loss = 0.02059105\n",
      "Iteration 1521, loss = 0.02057767\n",
      "Iteration 1522, loss = 0.02056364\n",
      "Iteration 1523, loss = 0.02054842\n",
      "Iteration 1524, loss = 0.02053433\n",
      "Iteration 1525, loss = 0.02051937\n",
      "Iteration 1526, loss = 0.02050490\n",
      "Iteration 1527, loss = 0.02048976\n",
      "Iteration 1528, loss = 0.02047508\n",
      "Iteration 1529, loss = 0.02045966\n",
      "Iteration 1530, loss = 0.02044726\n",
      "Iteration 1531, loss = 0.02043171\n",
      "Iteration 1532, loss = 0.02041590\n",
      "Iteration 1533, loss = 0.02040435\n",
      "Iteration 1534, loss = 0.02038727\n",
      "Iteration 1535, loss = 0.02037264\n",
      "Iteration 1536, loss = 0.02035862\n",
      "Iteration 1537, loss = 0.02034416\n",
      "Iteration 1538, loss = 0.02033117\n",
      "Iteration 1539, loss = 0.02031680\n",
      "Iteration 1540, loss = 0.02030101\n",
      "Iteration 1541, loss = 0.02028881\n",
      "Iteration 1542, loss = 0.02027350\n",
      "Iteration 1543, loss = 0.02025936\n",
      "Iteration 1544, loss = 0.02024602\n",
      "Iteration 1545, loss = 0.02023183\n",
      "Iteration 1546, loss = 0.02021802\n",
      "Iteration 1547, loss = 0.02020673\n",
      "Iteration 1548, loss = 0.02019092\n",
      "Iteration 1549, loss = 0.02017684\n",
      "Iteration 1550, loss = 0.02016265\n",
      "Iteration 1551, loss = 0.02014945\n",
      "Iteration 1552, loss = 0.02013493\n",
      "Iteration 1553, loss = 0.02012226\n",
      "Iteration 1554, loss = 0.02010593\n",
      "Iteration 1555, loss = 0.02009321\n",
      "Iteration 1556, loss = 0.02008038\n",
      "Iteration 1557, loss = 0.02006461\n",
      "Iteration 1558, loss = 0.02004877\n",
      "Iteration 1559, loss = 0.02003374\n",
      "Iteration 1560, loss = 0.02001931\n",
      "Iteration 1561, loss = 0.02000550\n",
      "Iteration 1562, loss = 0.01998934\n",
      "Iteration 1563, loss = 0.01997536\n",
      "Iteration 1564, loss = 0.01996023\n",
      "Iteration 1565, loss = 0.01994603\n",
      "Iteration 1566, loss = 0.01993113\n",
      "Iteration 1567, loss = 0.01991716\n",
      "Iteration 1568, loss = 0.01990345\n",
      "Iteration 1569, loss = 0.01988976\n",
      "Iteration 1570, loss = 0.01987617\n",
      "Iteration 1571, loss = 0.01986260\n",
      "Iteration 1572, loss = 0.01984866\n",
      "Iteration 1573, loss = 0.01983542\n",
      "Iteration 1574, loss = 0.01982058\n",
      "Iteration 1575, loss = 0.01980717\n",
      "Iteration 1576, loss = 0.01979475\n",
      "Iteration 1577, loss = 0.01977963\n",
      "Iteration 1578, loss = 0.01976444\n",
      "Iteration 1579, loss = 0.01974949\n",
      "Iteration 1580, loss = 0.01973544\n",
      "Iteration 1581, loss = 0.01972203\n",
      "Iteration 1582, loss = 0.01970880\n",
      "Iteration 1583, loss = 0.01969453\n",
      "Iteration 1584, loss = 0.01968037\n",
      "Iteration 1585, loss = 0.01966871\n",
      "Iteration 1586, loss = 0.01965464\n",
      "Iteration 1587, loss = 0.01964243\n",
      "Iteration 1588, loss = 0.01962773\n",
      "Iteration 1589, loss = 0.01961427\n",
      "Iteration 1590, loss = 0.01960192\n",
      "Iteration 1591, loss = 0.01958757\n",
      "Iteration 1592, loss = 0.01957244\n",
      "Iteration 1593, loss = 0.01955943\n",
      "Iteration 1594, loss = 0.01954566\n",
      "Iteration 1595, loss = 0.01953183\n",
      "Iteration 1596, loss = 0.01951864\n",
      "Iteration 1597, loss = 0.01950402\n",
      "Iteration 1598, loss = 0.01948980\n",
      "Iteration 1599, loss = 0.01947588\n",
      "Iteration 1600, loss = 0.01946326\n",
      "Iteration 1601, loss = 0.01944801\n",
      "Iteration 1602, loss = 0.01943359\n",
      "Iteration 1603, loss = 0.01942023\n",
      "Iteration 1604, loss = 0.01940537\n",
      "Iteration 1605, loss = 0.01939168\n",
      "Iteration 1606, loss = 0.01937803\n",
      "Iteration 1607, loss = 0.01936377\n",
      "Iteration 1608, loss = 0.01935008\n",
      "Iteration 1609, loss = 0.01933636\n",
      "Iteration 1610, loss = 0.01932272\n",
      "Iteration 1611, loss = 0.01930964\n",
      "Iteration 1612, loss = 0.01929458\n",
      "Iteration 1613, loss = 0.01928133\n",
      "Iteration 1614, loss = 0.01927009\n",
      "Iteration 1615, loss = 0.01925641\n",
      "Iteration 1616, loss = 0.01924354\n",
      "Iteration 1617, loss = 0.01923086\n",
      "Iteration 1618, loss = 0.01921864\n",
      "Iteration 1619, loss = 0.01920381\n",
      "Iteration 1620, loss = 0.01919023\n",
      "Iteration 1621, loss = 0.01917748\n",
      "Iteration 1622, loss = 0.01916448\n",
      "Iteration 1623, loss = 0.01915154\n",
      "Iteration 1624, loss = 0.01913641\n",
      "Iteration 1625, loss = 0.01912347\n",
      "Iteration 1626, loss = 0.01911194\n",
      "Iteration 1627, loss = 0.01909669\n",
      "Iteration 1628, loss = 0.01908469\n",
      "Iteration 1629, loss = 0.01907035\n",
      "Iteration 1630, loss = 0.01905702\n",
      "Iteration 1631, loss = 0.01904646\n",
      "Iteration 1632, loss = 0.01903120\n",
      "Iteration 1633, loss = 0.01901682\n",
      "Iteration 1634, loss = 0.01900513\n",
      "Iteration 1635, loss = 0.01899149\n",
      "Iteration 1636, loss = 0.01897804\n",
      "Iteration 1637, loss = 0.01896547\n",
      "Iteration 1638, loss = 0.01895126\n",
      "Iteration 1639, loss = 0.01893849\n",
      "Iteration 1640, loss = 0.01892603\n",
      "Iteration 1641, loss = 0.01891281\n",
      "Iteration 1642, loss = 0.01890080\n",
      "Iteration 1643, loss = 0.01888750\n",
      "Iteration 1644, loss = 0.01887516\n",
      "Iteration 1645, loss = 0.01886227\n",
      "Iteration 1646, loss = 0.01885011\n",
      "Iteration 1647, loss = 0.01883733\n",
      "Iteration 1648, loss = 0.01882612\n",
      "Iteration 1649, loss = 0.01881339\n",
      "Iteration 1650, loss = 0.01880185\n",
      "Iteration 1651, loss = 0.01878962\n",
      "Iteration 1652, loss = 0.01877827\n",
      "Iteration 1653, loss = 0.01876639\n",
      "Iteration 1654, loss = 0.01875457\n",
      "Iteration 1655, loss = 0.01874720\n",
      "Iteration 1656, loss = 0.01873331\n",
      "Iteration 1657, loss = 0.01871949\n",
      "Iteration 1658, loss = 0.01870759\n",
      "Iteration 1659, loss = 0.01869546\n",
      "Iteration 1660, loss = 0.01868311\n",
      "Iteration 1661, loss = 0.01867277\n",
      "Iteration 1662, loss = 0.01865894\n",
      "Iteration 1663, loss = 0.01864633\n",
      "Iteration 1664, loss = 0.01863441\n",
      "Iteration 1665, loss = 0.01862261\n",
      "Iteration 1666, loss = 0.01861086\n",
      "Iteration 1667, loss = 0.01860034\n",
      "Iteration 1668, loss = 0.01858892\n",
      "Iteration 1669, loss = 0.01857869\n",
      "Iteration 1670, loss = 0.01856586\n",
      "Iteration 1671, loss = 0.01855447\n",
      "Iteration 1672, loss = 0.01854301\n",
      "Iteration 1673, loss = 0.01853164\n",
      "Iteration 1674, loss = 0.01851964\n",
      "Iteration 1675, loss = 0.01850824\n",
      "Iteration 1676, loss = 0.01850020\n",
      "Iteration 1677, loss = 0.01848624\n",
      "Iteration 1678, loss = 0.01847361\n",
      "Iteration 1679, loss = 0.01846426\n",
      "Iteration 1680, loss = 0.01845022\n",
      "Iteration 1681, loss = 0.01843802\n",
      "Iteration 1682, loss = 0.01842479\n",
      "Iteration 1683, loss = 0.01841249\n",
      "Iteration 1684, loss = 0.01840060\n",
      "Iteration 1685, loss = 0.01838745\n",
      "Iteration 1686, loss = 0.01837538\n",
      "Iteration 1687, loss = 0.01836330\n",
      "Iteration 1688, loss = 0.01835188\n",
      "Iteration 1689, loss = 0.01833985\n",
      "Iteration 1690, loss = 0.01832803\n",
      "Iteration 1691, loss = 0.01831665\n",
      "Iteration 1692, loss = 0.01830531\n",
      "Iteration 1693, loss = 0.01829320\n",
      "Iteration 1694, loss = 0.01828223\n",
      "Iteration 1695, loss = 0.01827117\n",
      "Iteration 1696, loss = 0.01826115\n",
      "Iteration 1697, loss = 0.01824869\n",
      "Iteration 1698, loss = 0.01823801\n",
      "Iteration 1699, loss = 0.01822464\n",
      "Iteration 1700, loss = 0.01821103\n",
      "Iteration 1701, loss = 0.01820141\n",
      "Iteration 1702, loss = 0.01818788\n",
      "Iteration 1703, loss = 0.01817395\n",
      "Iteration 1704, loss = 0.01816380\n",
      "Iteration 1705, loss = 0.01815091\n",
      "Iteration 1706, loss = 0.01814015\n",
      "Iteration 1707, loss = 0.01812803\n",
      "Iteration 1708, loss = 0.01811563\n",
      "Iteration 1709, loss = 0.01810329\n",
      "Iteration 1710, loss = 0.01809212\n",
      "Iteration 1711, loss = 0.01807987\n",
      "Iteration 1712, loss = 0.01806932\n",
      "Iteration 1713, loss = 0.01805600\n",
      "Iteration 1714, loss = 0.01804510\n",
      "Iteration 1715, loss = 0.01803438\n",
      "Iteration 1716, loss = 0.01802186\n",
      "Iteration 1717, loss = 0.01801062\n",
      "Iteration 1718, loss = 0.01799970\n",
      "Iteration 1719, loss = 0.01798705\n",
      "Iteration 1720, loss = 0.01797637\n",
      "Iteration 1721, loss = 0.01796365\n",
      "Iteration 1722, loss = 0.01795379\n",
      "Iteration 1723, loss = 0.01794310\n",
      "Iteration 1724, loss = 0.01793097\n",
      "Iteration 1725, loss = 0.01791824\n",
      "Iteration 1726, loss = 0.01790652\n",
      "Iteration 1727, loss = 0.01789581\n",
      "Iteration 1728, loss = 0.01788587\n",
      "Iteration 1729, loss = 0.01787386\n",
      "Iteration 1730, loss = 0.01786219\n",
      "Iteration 1731, loss = 0.01785081\n",
      "Iteration 1732, loss = 0.01783985\n",
      "Iteration 1733, loss = 0.01782928\n",
      "Iteration 1734, loss = 0.01782051\n",
      "Iteration 1735, loss = 0.01780613\n",
      "Iteration 1736, loss = 0.01779412\n",
      "Iteration 1737, loss = 0.01778266\n",
      "Iteration 1738, loss = 0.01777067\n",
      "Iteration 1739, loss = 0.01775978\n",
      "Iteration 1740, loss = 0.01774699\n",
      "Iteration 1741, loss = 0.01773640\n",
      "Iteration 1742, loss = 0.01772110\n",
      "Iteration 1743, loss = 0.01770899\n",
      "Iteration 1744, loss = 0.01769891\n",
      "Iteration 1745, loss = 0.01768763\n",
      "Iteration 1746, loss = 0.01767561\n",
      "Iteration 1747, loss = 0.01766786\n",
      "Iteration 1748, loss = 0.01765478\n",
      "Iteration 1749, loss = 0.01764438\n",
      "Iteration 1750, loss = 0.01763401\n",
      "Iteration 1751, loss = 0.01762296\n",
      "Iteration 1752, loss = 0.01761309\n",
      "Iteration 1753, loss = 0.01760022\n",
      "Iteration 1754, loss = 0.01758833\n",
      "Iteration 1755, loss = 0.01757860\n",
      "Iteration 1756, loss = 0.01756659\n",
      "Iteration 1757, loss = 0.01755515\n",
      "Iteration 1758, loss = 0.01754170\n",
      "Iteration 1759, loss = 0.01753051\n",
      "Iteration 1760, loss = 0.01751700\n",
      "Iteration 1761, loss = 0.01750660\n",
      "Iteration 1762, loss = 0.01749517\n",
      "Iteration 1763, loss = 0.01748262\n",
      "Iteration 1764, loss = 0.01747229\n",
      "Iteration 1765, loss = 0.01746091\n",
      "Iteration 1766, loss = 0.01745176\n",
      "Iteration 1767, loss = 0.01743677\n",
      "Iteration 1768, loss = 0.01742540\n",
      "Iteration 1769, loss = 0.01741505\n",
      "Iteration 1770, loss = 0.01740295\n",
      "Iteration 1771, loss = 0.01739162\n",
      "Iteration 1772, loss = 0.01738129\n",
      "Iteration 1773, loss = 0.01736989\n",
      "Iteration 1774, loss = 0.01736001\n",
      "Iteration 1775, loss = 0.01734786\n",
      "Iteration 1776, loss = 0.01733714\n",
      "Iteration 1777, loss = 0.01732609\n",
      "Iteration 1778, loss = 0.01731527\n",
      "Iteration 1779, loss = 0.01730411\n",
      "Iteration 1780, loss = 0.01729198\n",
      "Iteration 1781, loss = 0.01727999\n",
      "Iteration 1782, loss = 0.01726878\n",
      "Iteration 1783, loss = 0.01725665\n",
      "Iteration 1784, loss = 0.01724870\n",
      "Iteration 1785, loss = 0.01723581\n",
      "Iteration 1786, loss = 0.01722393\n",
      "Iteration 1787, loss = 0.01721287\n",
      "Iteration 1788, loss = 0.01720029\n",
      "Iteration 1789, loss = 0.01719149\n",
      "Iteration 1790, loss = 0.01717976\n",
      "Iteration 1791, loss = 0.01717371\n",
      "Iteration 1792, loss = 0.01715964\n",
      "Iteration 1793, loss = 0.01715296\n",
      "Iteration 1794, loss = 0.01714124\n",
      "Iteration 1795, loss = 0.01712896\n",
      "Iteration 1796, loss = 0.01712040\n",
      "Iteration 1797, loss = 0.01710919\n",
      "Iteration 1798, loss = 0.01709853\n",
      "Iteration 1799, loss = 0.01708761\n",
      "Iteration 1800, loss = 0.01707526\n",
      "Iteration 1801, loss = 0.01706416\n",
      "Iteration 1802, loss = 0.01705309\n",
      "Iteration 1803, loss = 0.01704321\n",
      "Iteration 1804, loss = 0.01703168\n",
      "Iteration 1805, loss = 0.01702182\n",
      "Iteration 1806, loss = 0.01701022\n",
      "Iteration 1807, loss = 0.01699955\n",
      "Iteration 1808, loss = 0.01698973\n",
      "Iteration 1809, loss = 0.01698032\n",
      "Iteration 1810, loss = 0.01696865\n",
      "Iteration 1811, loss = 0.01695942\n",
      "Iteration 1812, loss = 0.01694922\n",
      "Iteration 1813, loss = 0.01693680\n",
      "Iteration 1814, loss = 0.01692598\n",
      "Iteration 1815, loss = 0.01691636\n",
      "Iteration 1816, loss = 0.01690542\n",
      "Iteration 1817, loss = 0.01689455\n",
      "Iteration 1818, loss = 0.01688386\n",
      "Iteration 1819, loss = 0.01687500\n",
      "Iteration 1820, loss = 0.01686327\n",
      "Iteration 1821, loss = 0.01685295\n",
      "Iteration 1822, loss = 0.01684382\n",
      "Iteration 1823, loss = 0.01683310\n",
      "Iteration 1824, loss = 0.01682294\n",
      "Iteration 1825, loss = 0.01681276\n",
      "Iteration 1826, loss = 0.01680309\n",
      "Iteration 1827, loss = 0.01679157\n",
      "Iteration 1828, loss = 0.01678100\n",
      "Iteration 1829, loss = 0.01677070\n",
      "Iteration 1830, loss = 0.01676054\n",
      "Iteration 1831, loss = 0.01675028\n",
      "Iteration 1832, loss = 0.01674171\n",
      "Iteration 1833, loss = 0.01673171\n",
      "Iteration 1834, loss = 0.01672060\n",
      "Iteration 1835, loss = 0.01671068\n",
      "Iteration 1836, loss = 0.01670065\n",
      "Iteration 1837, loss = 0.01669112\n",
      "Iteration 1838, loss = 0.01668170\n",
      "Iteration 1839, loss = 0.01667250\n",
      "Iteration 1840, loss = 0.01666255\n",
      "Iteration 1841, loss = 0.01665229\n",
      "Iteration 1842, loss = 0.01664232\n",
      "Iteration 1843, loss = 0.01663345\n",
      "Iteration 1844, loss = 0.01662294\n",
      "Iteration 1845, loss = 0.01661315\n",
      "Iteration 1846, loss = 0.01660208\n",
      "Iteration 1847, loss = 0.01659240\n",
      "Iteration 1848, loss = 0.01658297\n",
      "Iteration 1849, loss = 0.01657178\n",
      "Iteration 1850, loss = 0.01656198\n",
      "Iteration 1851, loss = 0.01655260\n",
      "Iteration 1852, loss = 0.01654117\n",
      "Iteration 1853, loss = 0.01653101\n",
      "Iteration 1854, loss = 0.01652136\n",
      "Iteration 1855, loss = 0.01651275\n",
      "Iteration 1856, loss = 0.01650101\n",
      "Iteration 1857, loss = 0.01649126\n",
      "Iteration 1858, loss = 0.01648054\n",
      "Iteration 1859, loss = 0.01646981\n",
      "Iteration 1860, loss = 0.01645981\n",
      "Iteration 1861, loss = 0.01644951\n",
      "Iteration 1862, loss = 0.01643962\n",
      "Iteration 1863, loss = 0.01642980\n",
      "Iteration 1864, loss = 0.01641987\n",
      "Iteration 1865, loss = 0.01640960\n",
      "Iteration 1866, loss = 0.01640064\n",
      "Iteration 1867, loss = 0.01639022\n",
      "Iteration 1868, loss = 0.01637982\n",
      "Iteration 1869, loss = 0.01636905\n",
      "Iteration 1870, loss = 0.01635997\n",
      "Iteration 1871, loss = 0.01635053\n",
      "Iteration 1872, loss = 0.01634088\n",
      "Iteration 1873, loss = 0.01633078\n",
      "Iteration 1874, loss = 0.01632137\n",
      "Iteration 1875, loss = 0.01631216\n",
      "Iteration 1876, loss = 0.01630245\n",
      "Iteration 1877, loss = 0.01629343\n",
      "Iteration 1878, loss = 0.01628491\n",
      "Iteration 1879, loss = 0.01627496\n",
      "Iteration 1880, loss = 0.01626518\n",
      "Iteration 1881, loss = 0.01625583\n",
      "Iteration 1882, loss = 0.01624684\n",
      "Iteration 1883, loss = 0.01623724\n",
      "Iteration 1884, loss = 0.01622803\n",
      "Iteration 1885, loss = 0.01621950\n",
      "Iteration 1886, loss = 0.01620854\n",
      "Iteration 1887, loss = 0.01620018\n",
      "Iteration 1888, loss = 0.01618991\n",
      "Iteration 1889, loss = 0.01618111\n",
      "Iteration 1890, loss = 0.01617220\n",
      "Iteration 1891, loss = 0.01616388\n",
      "Iteration 1892, loss = 0.01615351\n",
      "Iteration 1893, loss = 0.01614339\n",
      "Iteration 1894, loss = 0.01613624\n",
      "Iteration 1895, loss = 0.01612796\n",
      "Iteration 1896, loss = 0.01611965\n",
      "Iteration 1897, loss = 0.01611150\n",
      "Iteration 1898, loss = 0.01610278\n",
      "Iteration 1899, loss = 0.01609450\n",
      "Iteration 1900, loss = 0.01608611\n",
      "Iteration 1901, loss = 0.01607736\n",
      "Iteration 1902, loss = 0.01606859\n",
      "Iteration 1903, loss = 0.01605951\n",
      "Iteration 1904, loss = 0.01604988\n",
      "Iteration 1905, loss = 0.01604136\n",
      "Iteration 1906, loss = 0.01603191\n",
      "Iteration 1907, loss = 0.01602321\n",
      "Iteration 1908, loss = 0.01601384\n",
      "Iteration 1909, loss = 0.01600503\n",
      "Iteration 1910, loss = 0.01599578\n",
      "Iteration 1911, loss = 0.01598831\n",
      "Iteration 1912, loss = 0.01597885\n",
      "Iteration 1913, loss = 0.01597050\n",
      "Iteration 1914, loss = 0.01596368\n",
      "Iteration 1915, loss = 0.01595402\n",
      "Iteration 1916, loss = 0.01594601\n",
      "Iteration 1917, loss = 0.01593711\n",
      "Iteration 1918, loss = 0.01593026\n",
      "Iteration 1919, loss = 0.01591923\n",
      "Iteration 1920, loss = 0.01590938\n",
      "Iteration 1921, loss = 0.01590027\n",
      "Iteration 1922, loss = 0.01588990\n",
      "Iteration 1923, loss = 0.01588159\n",
      "Iteration 1924, loss = 0.01586953\n",
      "Iteration 1925, loss = 0.01586030\n",
      "Iteration 1926, loss = 0.01585035\n",
      "Iteration 1927, loss = 0.01583939\n",
      "Iteration 1928, loss = 0.01582976\n",
      "Iteration 1929, loss = 0.01581951\n",
      "Iteration 1930, loss = 0.01580996\n",
      "Iteration 1931, loss = 0.01579996\n",
      "Iteration 1932, loss = 0.01579027\n",
      "Iteration 1933, loss = 0.01578124\n",
      "Iteration 1934, loss = 0.01577052\n",
      "Iteration 1935, loss = 0.01576226\n",
      "Iteration 1936, loss = 0.01575087\n",
      "Iteration 1937, loss = 0.01574157\n",
      "Iteration 1938, loss = 0.01573250\n",
      "Iteration 1939, loss = 0.01572164\n",
      "Iteration 1940, loss = 0.01571294\n",
      "Iteration 1941, loss = 0.01570379\n",
      "Iteration 1942, loss = 0.01569505\n",
      "Iteration 1943, loss = 0.01568361\n",
      "Iteration 1944, loss = 0.01567526\n",
      "Iteration 1945, loss = 0.01566374\n",
      "Iteration 1946, loss = 0.01565431\n",
      "Iteration 1947, loss = 0.01564406\n",
      "Iteration 1948, loss = 0.01563473\n",
      "Iteration 1949, loss = 0.01562507\n",
      "Iteration 1950, loss = 0.01561487\n",
      "Iteration 1951, loss = 0.01560672\n",
      "Iteration 1952, loss = 0.01559665\n",
      "Iteration 1953, loss = 0.01558693\n",
      "Iteration 1954, loss = 0.01557852\n",
      "Iteration 1955, loss = 0.01556898\n",
      "Iteration 1956, loss = 0.01556011\n",
      "Iteration 1957, loss = 0.01555102\n",
      "Iteration 1958, loss = 0.01554264\n",
      "Iteration 1959, loss = 0.01553339\n",
      "Iteration 1960, loss = 0.01552444\n",
      "Iteration 1961, loss = 0.01551527\n",
      "Iteration 1962, loss = 0.01550557\n",
      "Iteration 1963, loss = 0.01549535\n",
      "Iteration 1964, loss = 0.01548743\n",
      "Iteration 1965, loss = 0.01547765\n",
      "Iteration 1966, loss = 0.01546967\n",
      "Iteration 1967, loss = 0.01546024\n",
      "Iteration 1968, loss = 0.01545154\n",
      "Iteration 1969, loss = 0.01544233\n",
      "Iteration 1970, loss = 0.01543396\n",
      "Iteration 1971, loss = 0.01542667\n",
      "Iteration 1972, loss = 0.01541652\n",
      "Iteration 1973, loss = 0.01540799\n",
      "Iteration 1974, loss = 0.01540149\n",
      "Iteration 1975, loss = 0.01539078\n",
      "Iteration 1976, loss = 0.01538199\n",
      "Iteration 1977, loss = 0.01537293\n",
      "Iteration 1978, loss = 0.01536360\n",
      "Iteration 1979, loss = 0.01535403\n",
      "Iteration 1980, loss = 0.01534537\n",
      "Iteration 1981, loss = 0.01533588\n",
      "Iteration 1982, loss = 0.01532687\n",
      "Iteration 1983, loss = 0.01531978\n",
      "Iteration 1984, loss = 0.01531139\n",
      "Iteration 1985, loss = 0.01530073\n",
      "Iteration 1986, loss = 0.01529343\n",
      "Iteration 1987, loss = 0.01528276\n",
      "Iteration 1988, loss = 0.01527512\n",
      "Iteration 1989, loss = 0.01526728\n",
      "Iteration 1990, loss = 0.01525845\n",
      "Iteration 1991, loss = 0.01525019\n",
      "Iteration 1992, loss = 0.01524092\n",
      "Iteration 1993, loss = 0.01523101\n",
      "Iteration 1994, loss = 0.01522226\n",
      "Iteration 1995, loss = 0.01521347\n",
      "Iteration 1996, loss = 0.01520412\n",
      "Iteration 1997, loss = 0.01519528\n",
      "Iteration 1998, loss = 0.01518613\n",
      "Iteration 1999, loss = 0.01517735\n",
      "Iteration 2000, loss = 0.01516809\n",
      "Iteration 2001, loss = 0.01516010\n",
      "Iteration 2002, loss = 0.01515100\n",
      "Iteration 2003, loss = 0.01514199\n",
      "Iteration 2004, loss = 0.01513352\n",
      "Iteration 2005, loss = 0.01512447\n",
      "Iteration 2006, loss = 0.01511603\n",
      "Iteration 2007, loss = 0.01510773\n",
      "Iteration 2008, loss = 0.01510013\n",
      "Iteration 2009, loss = 0.01509246\n",
      "Iteration 2010, loss = 0.01508341\n",
      "Iteration 2011, loss = 0.01507610\n",
      "Iteration 2012, loss = 0.01506726\n",
      "Iteration 2013, loss = 0.01506190\n",
      "Iteration 2014, loss = 0.01505089\n",
      "Iteration 2015, loss = 0.01504227\n",
      "Iteration 2016, loss = 0.01503387\n",
      "Iteration 2017, loss = 0.01502603\n",
      "Iteration 2018, loss = 0.01501769\n",
      "Iteration 2019, loss = 0.01500930\n",
      "Iteration 2020, loss = 0.01500127\n",
      "Iteration 2021, loss = 0.01499363\n",
      "Iteration 2022, loss = 0.01498474\n",
      "Iteration 2023, loss = 0.01497607\n",
      "Iteration 2024, loss = 0.01496852\n",
      "Iteration 2025, loss = 0.01495996\n",
      "Iteration 2026, loss = 0.01495252\n",
      "Iteration 2027, loss = 0.01494403\n",
      "Iteration 2028, loss = 0.01493715\n",
      "Iteration 2029, loss = 0.01492971\n",
      "Iteration 2030, loss = 0.01492026\n",
      "Iteration 2031, loss = 0.01491219\n",
      "Iteration 2032, loss = 0.01490396\n",
      "Iteration 2033, loss = 0.01489572\n",
      "Iteration 2034, loss = 0.01488798\n",
      "Iteration 2035, loss = 0.01488023\n",
      "Iteration 2036, loss = 0.01487223\n",
      "Iteration 2037, loss = 0.01486370\n",
      "Iteration 2038, loss = 0.01485765\n",
      "Iteration 2039, loss = 0.01485028\n",
      "Iteration 2040, loss = 0.01484085\n",
      "Iteration 2041, loss = 0.01483373\n",
      "Iteration 2042, loss = 0.01482574\n",
      "Iteration 2043, loss = 0.01481793\n",
      "Iteration 2044, loss = 0.01480995\n",
      "Iteration 2045, loss = 0.01480330\n",
      "Iteration 2046, loss = 0.01479496\n",
      "Iteration 2047, loss = 0.01478769\n",
      "Iteration 2048, loss = 0.01478147\n",
      "Iteration 2049, loss = 0.01477124\n",
      "Iteration 2050, loss = 0.01476269\n",
      "Iteration 2051, loss = 0.01475662\n",
      "Iteration 2052, loss = 0.01474888\n",
      "Iteration 2053, loss = 0.01474082\n",
      "Iteration 2054, loss = 0.01473336\n",
      "Iteration 2055, loss = 0.01472567\n",
      "Iteration 2056, loss = 0.01471800\n",
      "Iteration 2057, loss = 0.01471024\n",
      "Iteration 2058, loss = 0.01470451\n",
      "Iteration 2059, loss = 0.01469409\n",
      "Iteration 2060, loss = 0.01468583\n",
      "Iteration 2061, loss = 0.01467792\n",
      "Iteration 2062, loss = 0.01466901\n",
      "Iteration 2063, loss = 0.01466041\n",
      "Iteration 2064, loss = 0.01465095\n",
      "Iteration 2065, loss = 0.01464284\n",
      "Iteration 2066, loss = 0.01463521\n",
      "Iteration 2067, loss = 0.01462653\n",
      "Iteration 2068, loss = 0.01462045\n",
      "Iteration 2069, loss = 0.01461085\n",
      "Iteration 2070, loss = 0.01460228\n",
      "Iteration 2071, loss = 0.01459448\n",
      "Iteration 2072, loss = 0.01458547\n",
      "Iteration 2073, loss = 0.01457965\n",
      "Iteration 2074, loss = 0.01456836\n",
      "Iteration 2075, loss = 0.01456030\n",
      "Iteration 2076, loss = 0.01455216\n",
      "Iteration 2077, loss = 0.01454421\n",
      "Iteration 2078, loss = 0.01453624\n",
      "Iteration 2079, loss = 0.01452900\n",
      "Iteration 2080, loss = 0.01451999\n",
      "Iteration 2081, loss = 0.01451229\n",
      "Iteration 2082, loss = 0.01450481\n",
      "Iteration 2083, loss = 0.01449673\n",
      "Iteration 2084, loss = 0.01448936\n",
      "Iteration 2085, loss = 0.01448193\n",
      "Iteration 2086, loss = 0.01447323\n",
      "Iteration 2087, loss = 0.01446515\n",
      "Iteration 2088, loss = 0.01445671\n",
      "Iteration 2089, loss = 0.01444956\n",
      "Iteration 2090, loss = 0.01444110\n",
      "Iteration 2091, loss = 0.01443481\n",
      "Iteration 2092, loss = 0.01442687\n",
      "Iteration 2093, loss = 0.01441940\n",
      "Iteration 2094, loss = 0.01441160\n",
      "Iteration 2095, loss = 0.01440433\n",
      "Iteration 2096, loss = 0.01439669\n",
      "Iteration 2097, loss = 0.01438912\n",
      "Iteration 2098, loss = 0.01438165\n",
      "Iteration 2099, loss = 0.01437382\n",
      "Iteration 2100, loss = 0.01436735\n",
      "Iteration 2101, loss = 0.01435965\n",
      "Iteration 2102, loss = 0.01435162\n",
      "Iteration 2103, loss = 0.01434460\n",
      "Iteration 2104, loss = 0.01433726\n",
      "Iteration 2105, loss = 0.01433090\n",
      "Iteration 2106, loss = 0.01432289\n",
      "Iteration 2107, loss = 0.01431600\n",
      "Iteration 2108, loss = 0.01430711\n",
      "Iteration 2109, loss = 0.01430137\n",
      "Iteration 2110, loss = 0.01429222\n",
      "Iteration 2111, loss = 0.01428320\n",
      "Iteration 2112, loss = 0.01427840\n",
      "Iteration 2113, loss = 0.01426945\n",
      "Iteration 2114, loss = 0.01426302\n",
      "Iteration 2115, loss = 0.01425453\n",
      "Iteration 2116, loss = 0.01424727\n",
      "Iteration 2117, loss = 0.01423953\n",
      "Iteration 2118, loss = 0.01423310\n",
      "Iteration 2119, loss = 0.01422629\n",
      "Iteration 2120, loss = 0.01421659\n",
      "Iteration 2121, loss = 0.01420961\n",
      "Iteration 2122, loss = 0.01420174\n",
      "Iteration 2123, loss = 0.01419550\n",
      "Iteration 2124, loss = 0.01418619\n",
      "Iteration 2125, loss = 0.01417895\n",
      "Iteration 2126, loss = 0.01417406\n",
      "Iteration 2127, loss = 0.01416614\n",
      "Iteration 2128, loss = 0.01415906\n",
      "Iteration 2129, loss = 0.01415278\n",
      "Iteration 2130, loss = 0.01414521\n",
      "Iteration 2131, loss = 0.01413853\n",
      "Iteration 2132, loss = 0.01413148\n",
      "Iteration 2133, loss = 0.01412439\n",
      "Iteration 2134, loss = 0.01411804\n",
      "Iteration 2135, loss = 0.01411063\n",
      "Iteration 2136, loss = 0.01410394\n",
      "Iteration 2137, loss = 0.01409678\n",
      "Iteration 2138, loss = 0.01409067\n",
      "Iteration 2139, loss = 0.01408299\n",
      "Iteration 2140, loss = 0.01407563\n",
      "Iteration 2141, loss = 0.01406741\n",
      "Iteration 2142, loss = 0.01406049\n",
      "Iteration 2143, loss = 0.01405316\n",
      "Iteration 2144, loss = 0.01404572\n",
      "Iteration 2145, loss = 0.01403837\n",
      "Iteration 2146, loss = 0.01403059\n",
      "Iteration 2147, loss = 0.01402346\n",
      "Iteration 2148, loss = 0.01401544\n",
      "Iteration 2149, loss = 0.01400855\n",
      "Iteration 2150, loss = 0.01400076\n",
      "Iteration 2151, loss = 0.01399279\n",
      "Iteration 2152, loss = 0.01398512\n",
      "Iteration 2153, loss = 0.01397717\n",
      "Iteration 2154, loss = 0.01397021\n",
      "Iteration 2155, loss = 0.01396163\n",
      "Iteration 2156, loss = 0.01395334\n",
      "Iteration 2157, loss = 0.01394646\n",
      "Iteration 2158, loss = 0.01393772\n",
      "Iteration 2159, loss = 0.01393024\n",
      "Iteration 2160, loss = 0.01392204\n",
      "Iteration 2161, loss = 0.01391525\n",
      "Iteration 2162, loss = 0.01390798\n",
      "Iteration 2163, loss = 0.01390039\n",
      "Iteration 2164, loss = 0.01389299\n",
      "Iteration 2165, loss = 0.01388712\n",
      "Iteration 2166, loss = 0.01387834\n",
      "Iteration 2167, loss = 0.01387123\n",
      "Iteration 2168, loss = 0.01386407\n",
      "Iteration 2169, loss = 0.01385604\n",
      "Iteration 2170, loss = 0.01384841\n",
      "Iteration 2171, loss = 0.01384096\n",
      "Iteration 2172, loss = 0.01383570\n",
      "Iteration 2173, loss = 0.01382604\n",
      "Iteration 2174, loss = 0.01381831\n",
      "Iteration 2175, loss = 0.01381257\n",
      "Iteration 2176, loss = 0.01380438\n",
      "Iteration 2177, loss = 0.01379754\n",
      "Iteration 2178, loss = 0.01379002\n",
      "Iteration 2179, loss = 0.01378276\n",
      "Iteration 2180, loss = 0.01377535\n",
      "Iteration 2181, loss = 0.01376833\n",
      "Iteration 2182, loss = 0.01376151\n",
      "Iteration 2183, loss = 0.01375404\n",
      "Iteration 2184, loss = 0.01374666\n",
      "Iteration 2185, loss = 0.01374107\n",
      "Iteration 2186, loss = 0.01373548\n",
      "Iteration 2187, loss = 0.01372718\n",
      "Iteration 2188, loss = 0.01372018\n",
      "Iteration 2189, loss = 0.01371344\n",
      "Iteration 2190, loss = 0.01370587\n",
      "Iteration 2191, loss = 0.01369820\n",
      "Iteration 2192, loss = 0.01369102\n",
      "Iteration 2193, loss = 0.01368423\n",
      "Iteration 2194, loss = 0.01367712\n",
      "Iteration 2195, loss = 0.01367026\n",
      "Iteration 2196, loss = 0.01366420\n",
      "Iteration 2197, loss = 0.01365741\n",
      "Iteration 2198, loss = 0.01365084\n",
      "Iteration 2199, loss = 0.01364509\n",
      "Iteration 2200, loss = 0.01364011\n",
      "Iteration 2201, loss = 0.01363428\n",
      "Iteration 2202, loss = 0.01363011\n",
      "Iteration 2203, loss = 0.01362292\n",
      "Iteration 2204, loss = 0.01361602\n",
      "Iteration 2205, loss = 0.01361015\n",
      "Iteration 2206, loss = 0.01360310\n",
      "Iteration 2207, loss = 0.01359655\n",
      "Iteration 2208, loss = 0.01359151\n",
      "Iteration 2209, loss = 0.01358434\n",
      "Iteration 2210, loss = 0.01357709\n",
      "Iteration 2211, loss = 0.01356977\n",
      "Iteration 2212, loss = 0.01356432\n",
      "Iteration 2213, loss = 0.01355498\n",
      "Iteration 2214, loss = 0.01354757\n",
      "Iteration 2215, loss = 0.01354064\n",
      "Iteration 2216, loss = 0.01353279\n",
      "Iteration 2217, loss = 0.01352419\n",
      "Iteration 2218, loss = 0.01351655\n",
      "Iteration 2219, loss = 0.01351221\n",
      "Iteration 2220, loss = 0.01350250\n",
      "Iteration 2221, loss = 0.01349621\n",
      "Iteration 2222, loss = 0.01348924\n",
      "Iteration 2223, loss = 0.01348142\n",
      "Iteration 2224, loss = 0.01347539\n",
      "Iteration 2225, loss = 0.01346857\n",
      "Iteration 2226, loss = 0.01346177\n",
      "Iteration 2227, loss = 0.01345593\n",
      "Iteration 2228, loss = 0.01344901\n",
      "Iteration 2229, loss = 0.01344270\n",
      "Iteration 2230, loss = 0.01343650\n",
      "Iteration 2231, loss = 0.01343063\n",
      "Iteration 2232, loss = 0.01342542\n",
      "Iteration 2233, loss = 0.01341874\n",
      "Iteration 2234, loss = 0.01340963\n",
      "Iteration 2235, loss = 0.01340267\n",
      "Iteration 2236, loss = 0.01339456\n",
      "Iteration 2237, loss = 0.01339043\n",
      "Iteration 2238, loss = 0.01338081\n",
      "Iteration 2239, loss = 0.01337376\n",
      "Iteration 2240, loss = 0.01336764\n",
      "Iteration 2241, loss = 0.01336070\n",
      "Iteration 2242, loss = 0.01335315\n",
      "Iteration 2243, loss = 0.01334507\n",
      "Iteration 2244, loss = 0.01333988\n",
      "Iteration 2245, loss = 0.01333039\n",
      "Iteration 2246, loss = 0.01332555\n",
      "Iteration 2247, loss = 0.01331915\n",
      "Iteration 2248, loss = 0.01331247\n",
      "Iteration 2249, loss = 0.01330559\n",
      "Iteration 2250, loss = 0.01329822\n",
      "Iteration 2251, loss = 0.01329140\n",
      "Iteration 2252, loss = 0.01328502\n",
      "Iteration 2253, loss = 0.01327890\n",
      "Iteration 2254, loss = 0.01327126\n",
      "Iteration 2255, loss = 0.01326409\n",
      "Iteration 2256, loss = 0.01325713\n",
      "Iteration 2257, loss = 0.01325032\n",
      "Iteration 2258, loss = 0.01324471\n",
      "Iteration 2259, loss = 0.01323648\n",
      "Iteration 2260, loss = 0.01323022\n",
      "Iteration 2261, loss = 0.01322365\n",
      "Iteration 2262, loss = 0.01321662\n",
      "Iteration 2263, loss = 0.01320958\n",
      "Iteration 2264, loss = 0.01320310\n",
      "Iteration 2265, loss = 0.01319603\n",
      "Iteration 2266, loss = 0.01318935\n",
      "Iteration 2267, loss = 0.01318273\n",
      "Iteration 2268, loss = 0.01317651\n",
      "Iteration 2269, loss = 0.01316991\n",
      "Iteration 2270, loss = 0.01316358\n",
      "Iteration 2271, loss = 0.01315739\n",
      "Iteration 2272, loss = 0.01315028\n",
      "Iteration 2273, loss = 0.01314383\n",
      "Iteration 2274, loss = 0.01313720\n",
      "Iteration 2275, loss = 0.01313275\n",
      "Iteration 2276, loss = 0.01312446\n",
      "Iteration 2277, loss = 0.01311759\n",
      "Iteration 2278, loss = 0.01311028\n",
      "Iteration 2279, loss = 0.01310384\n",
      "Iteration 2280, loss = 0.01309779\n",
      "Iteration 2281, loss = 0.01309020\n",
      "Iteration 2282, loss = 0.01308354\n",
      "Iteration 2283, loss = 0.01307700\n",
      "Iteration 2284, loss = 0.01307003\n",
      "Iteration 2285, loss = 0.01306368\n",
      "Iteration 2286, loss = 0.01305671\n",
      "Iteration 2287, loss = 0.01305043\n",
      "Iteration 2288, loss = 0.01304370\n",
      "Iteration 2289, loss = 0.01303714\n",
      "Iteration 2290, loss = 0.01303207\n",
      "Iteration 2291, loss = 0.01302471\n",
      "Iteration 2292, loss = 0.01301797\n",
      "Iteration 2293, loss = 0.01301194\n",
      "Iteration 2294, loss = 0.01300625\n",
      "Iteration 2295, loss = 0.01299852\n",
      "Iteration 2296, loss = 0.01299342\n",
      "Iteration 2297, loss = 0.01298610\n",
      "Iteration 2298, loss = 0.01297929\n",
      "Iteration 2299, loss = 0.01297303\n",
      "Iteration 2300, loss = 0.01296655\n",
      "Iteration 2301, loss = 0.01296161\n",
      "Iteration 2302, loss = 0.01295410\n",
      "Iteration 2303, loss = 0.01294758\n",
      "Iteration 2304, loss = 0.01294068\n",
      "Iteration 2305, loss = 0.01293346\n",
      "Iteration 2306, loss = 0.01292992\n",
      "Iteration 2307, loss = 0.01292168\n",
      "Iteration 2308, loss = 0.01291635\n",
      "Iteration 2309, loss = 0.01290924\n",
      "Iteration 2310, loss = 0.01290438\n",
      "Iteration 2311, loss = 0.01289758\n",
      "Iteration 2312, loss = 0.01289134\n",
      "Iteration 2313, loss = 0.01288659\n",
      "Iteration 2314, loss = 0.01287934\n",
      "Iteration 2315, loss = 0.01287339\n",
      "Iteration 2316, loss = 0.01286687\n",
      "Iteration 2317, loss = 0.01285994\n",
      "Iteration 2318, loss = 0.01285441\n",
      "Iteration 2319, loss = 0.01284725\n",
      "Iteration 2320, loss = 0.01284055\n",
      "Iteration 2321, loss = 0.01283655\n",
      "Iteration 2322, loss = 0.01282711\n",
      "Iteration 2323, loss = 0.01281958\n",
      "Iteration 2324, loss = 0.01281340\n",
      "Iteration 2325, loss = 0.01280661\n",
      "Iteration 2326, loss = 0.01279992\n",
      "Iteration 2327, loss = 0.01279466\n",
      "Iteration 2328, loss = 0.01278759\n",
      "Iteration 2329, loss = 0.01278132\n",
      "Iteration 2330, loss = 0.01277472\n",
      "Iteration 2331, loss = 0.01276940\n",
      "Iteration 2332, loss = 0.01276447\n",
      "Iteration 2333, loss = 0.01275686\n",
      "Iteration 2334, loss = 0.01275019\n",
      "Iteration 2335, loss = 0.01274323\n",
      "Iteration 2336, loss = 0.01273610\n",
      "Iteration 2337, loss = 0.01273142\n",
      "Iteration 2338, loss = 0.01272346\n",
      "Iteration 2339, loss = 0.01271818\n",
      "Iteration 2340, loss = 0.01271214\n",
      "Iteration 2341, loss = 0.01270409\n",
      "Iteration 2342, loss = 0.01269766\n",
      "Iteration 2343, loss = 0.01269141\n",
      "Iteration 2344, loss = 0.01268561\n",
      "Iteration 2345, loss = 0.01267984\n",
      "Iteration 2346, loss = 0.01267253\n",
      "Iteration 2347, loss = 0.01266486\n",
      "Iteration 2348, loss = 0.01265851\n",
      "Iteration 2349, loss = 0.01265184\n",
      "Iteration 2350, loss = 0.01264682\n",
      "Iteration 2351, loss = 0.01264017\n",
      "Iteration 2352, loss = 0.01263341\n",
      "Iteration 2353, loss = 0.01262721\n",
      "Iteration 2354, loss = 0.01261952\n",
      "Iteration 2355, loss = 0.01261310\n",
      "Iteration 2356, loss = 0.01260618\n",
      "Iteration 2357, loss = 0.01259941\n",
      "Iteration 2358, loss = 0.01259298\n",
      "Iteration 2359, loss = 0.01258619\n",
      "Iteration 2360, loss = 0.01257946\n",
      "Iteration 2361, loss = 0.01257309\n",
      "Iteration 2362, loss = 0.01256649\n",
      "Iteration 2363, loss = 0.01256033\n",
      "Iteration 2364, loss = 0.01255570\n",
      "Iteration 2365, loss = 0.01255062\n",
      "Iteration 2366, loss = 0.01254412\n",
      "Iteration 2367, loss = 0.01253788\n",
      "Iteration 2368, loss = 0.01253120\n",
      "Iteration 2369, loss = 0.01252571\n",
      "Iteration 2370, loss = 0.01251868\n",
      "Iteration 2371, loss = 0.01251235\n",
      "Iteration 2372, loss = 0.01250808\n",
      "Iteration 2373, loss = 0.01250142\n",
      "Iteration 2374, loss = 0.01249449\n",
      "Iteration 2375, loss = 0.01248807\n",
      "Iteration 2376, loss = 0.01248345\n",
      "Iteration 2377, loss = 0.01247612\n",
      "Iteration 2378, loss = 0.01247059\n",
      "Iteration 2379, loss = 0.01246436\n",
      "Iteration 2380, loss = 0.01245856\n",
      "Iteration 2381, loss = 0.01245260\n",
      "Iteration 2382, loss = 0.01244636\n",
      "Iteration 2383, loss = 0.01244036\n",
      "Iteration 2384, loss = 0.01243450\n",
      "Iteration 2385, loss = 0.01242910\n",
      "Iteration 2386, loss = 0.01242365\n",
      "Iteration 2387, loss = 0.01241716\n",
      "Iteration 2388, loss = 0.01241192\n",
      "Iteration 2389, loss = 0.01240858\n",
      "Iteration 2390, loss = 0.01240110\n",
      "Iteration 2391, loss = 0.01239494\n",
      "Iteration 2392, loss = 0.01238927\n",
      "Iteration 2393, loss = 0.01238364\n",
      "Iteration 2394, loss = 0.01237757\n",
      "Iteration 2395, loss = 0.01237188\n",
      "Iteration 2396, loss = 0.01236632\n",
      "Iteration 2397, loss = 0.01236080\n",
      "Iteration 2398, loss = 0.01235506\n",
      "Iteration 2399, loss = 0.01234992\n",
      "Iteration 2400, loss = 0.01234502\n",
      "Iteration 2401, loss = 0.01233813\n",
      "Iteration 2402, loss = 0.01233198\n",
      "Iteration 2403, loss = 0.01232622\n",
      "Iteration 2404, loss = 0.01231958\n",
      "Iteration 2405, loss = 0.01231483\n",
      "Iteration 2406, loss = 0.01230863\n",
      "Iteration 2407, loss = 0.01230332\n",
      "Iteration 2408, loss = 0.01229877\n",
      "Iteration 2409, loss = 0.01229256\n",
      "Iteration 2410, loss = 0.01228687\n",
      "Iteration 2411, loss = 0.01228103\n",
      "Iteration 2412, loss = 0.01227559\n",
      "Iteration 2413, loss = 0.01226968\n",
      "Iteration 2414, loss = 0.01226398\n",
      "Iteration 2415, loss = 0.01225846\n",
      "Iteration 2416, loss = 0.01225498\n",
      "Iteration 2417, loss = 0.01224783\n",
      "Iteration 2418, loss = 0.01224357\n",
      "Iteration 2419, loss = 0.01223764\n",
      "Iteration 2420, loss = 0.01223194\n",
      "Iteration 2421, loss = 0.01222804\n",
      "Iteration 2422, loss = 0.01222168\n",
      "Iteration 2423, loss = 0.01221725\n",
      "Iteration 2424, loss = 0.01221099\n",
      "Iteration 2425, loss = 0.01220541\n",
      "Iteration 2426, loss = 0.01220258\n",
      "Iteration 2427, loss = 0.01219547\n",
      "Iteration 2428, loss = 0.01218896\n",
      "Iteration 2429, loss = 0.01218413\n",
      "Iteration 2430, loss = 0.01217856\n",
      "Iteration 2431, loss = 0.01217234\n",
      "Iteration 2432, loss = 0.01216767\n",
      "Iteration 2433, loss = 0.01216244\n",
      "Iteration 2434, loss = 0.01215624\n",
      "Iteration 2435, loss = 0.01215102\n",
      "Iteration 2436, loss = 0.01214558\n",
      "Iteration 2437, loss = 0.01214021\n",
      "Iteration 2438, loss = 0.01213481\n",
      "Iteration 2439, loss = 0.01212948\n",
      "Iteration 2440, loss = 0.01212446\n",
      "Iteration 2441, loss = 0.01211962\n",
      "Iteration 2442, loss = 0.01211362\n",
      "Iteration 2443, loss = 0.01210814\n",
      "Iteration 2444, loss = 0.01210260\n",
      "Iteration 2445, loss = 0.01209705\n",
      "Iteration 2446, loss = 0.01209173\n",
      "Iteration 2447, loss = 0.01208582\n",
      "Iteration 2448, loss = 0.01207939\n",
      "Iteration 2449, loss = 0.01207342\n",
      "Iteration 2450, loss = 0.01206730\n",
      "Iteration 2451, loss = 0.01206209\n",
      "Iteration 2452, loss = 0.01205663\n",
      "Iteration 2453, loss = 0.01205132\n",
      "Iteration 2454, loss = 0.01204498\n",
      "Iteration 2455, loss = 0.01203889\n",
      "Iteration 2456, loss = 0.01203357\n",
      "Iteration 2457, loss = 0.01202725\n",
      "Iteration 2458, loss = 0.01202162\n",
      "Iteration 2459, loss = 0.01201596\n",
      "Iteration 2460, loss = 0.01201059\n",
      "Iteration 2461, loss = 0.01200662\n",
      "Iteration 2462, loss = 0.01200089\n",
      "Iteration 2463, loss = 0.01199483\n",
      "Iteration 2464, loss = 0.01198886\n",
      "Iteration 2465, loss = 0.01198326\n",
      "Iteration 2466, loss = 0.01197772\n",
      "Iteration 2467, loss = 0.01196998\n",
      "Iteration 2468, loss = 0.01196664\n",
      "Iteration 2469, loss = 0.01195906\n",
      "Iteration 2470, loss = 0.01195403\n",
      "Iteration 2471, loss = 0.01194845\n",
      "Iteration 2472, loss = 0.01194277\n",
      "Iteration 2473, loss = 0.01193774\n",
      "Iteration 2474, loss = 0.01193255\n",
      "Iteration 2475, loss = 0.01192790\n",
      "Iteration 2476, loss = 0.01192214\n",
      "Iteration 2477, loss = 0.01191720\n",
      "Iteration 2478, loss = 0.01191280\n",
      "Iteration 2479, loss = 0.01190748\n",
      "Iteration 2480, loss = 0.01190244\n",
      "Iteration 2481, loss = 0.01189652\n",
      "Iteration 2482, loss = 0.01189127\n",
      "Iteration 2483, loss = 0.01188556\n",
      "Iteration 2484, loss = 0.01188088\n",
      "Iteration 2485, loss = 0.01187535\n",
      "Iteration 2486, loss = 0.01186856\n",
      "Iteration 2487, loss = 0.01186376\n",
      "Iteration 2488, loss = 0.01185594\n",
      "Iteration 2489, loss = 0.01185006\n",
      "Iteration 2490, loss = 0.01184308\n",
      "Iteration 2491, loss = 0.01183981\n",
      "Iteration 2492, loss = 0.01183137\n",
      "Iteration 2493, loss = 0.01182649\n",
      "Iteration 2494, loss = 0.01181961\n",
      "Iteration 2495, loss = 0.01181361\n",
      "Iteration 2496, loss = 0.01180901\n",
      "Iteration 2497, loss = 0.01180254\n",
      "Iteration 2498, loss = 0.01179744\n",
      "Iteration 2499, loss = 0.01179012\n",
      "Iteration 2500, loss = 0.01178576\n",
      "Iteration 2501, loss = 0.01177989\n",
      "Iteration 2502, loss = 0.01177563\n",
      "Iteration 2503, loss = 0.01176940\n",
      "Iteration 2504, loss = 0.01176337\n",
      "Iteration 2505, loss = 0.01175870\n",
      "Iteration 2506, loss = 0.01175206\n",
      "Iteration 2507, loss = 0.01174678\n",
      "Iteration 2508, loss = 0.01174169\n",
      "Iteration 2509, loss = 0.01173618\n",
      "Iteration 2510, loss = 0.01173126\n",
      "Iteration 2511, loss = 0.01172559\n",
      "Iteration 2512, loss = 0.01172001\n",
      "Iteration 2513, loss = 0.01171591\n",
      "Iteration 2514, loss = 0.01170978\n",
      "Iteration 2515, loss = 0.01170410\n",
      "Iteration 2516, loss = 0.01169869\n",
      "Iteration 2517, loss = 0.01169421\n",
      "Iteration 2518, loss = 0.01168745\n",
      "Iteration 2519, loss = 0.01168242\n",
      "Iteration 2520, loss = 0.01167718\n",
      "Iteration 2521, loss = 0.01167210\n",
      "Iteration 2522, loss = 0.01166676\n",
      "Iteration 2523, loss = 0.01166175\n",
      "Iteration 2524, loss = 0.01165625\n",
      "Iteration 2525, loss = 0.01165066\n",
      "Iteration 2526, loss = 0.01164481\n",
      "Iteration 2527, loss = 0.01163973\n",
      "Iteration 2528, loss = 0.01163405\n",
      "Iteration 2529, loss = 0.01163016\n",
      "Iteration 2530, loss = 0.01162548\n",
      "Iteration 2531, loss = 0.01161865\n",
      "Iteration 2532, loss = 0.01161329\n",
      "Iteration 2533, loss = 0.01160817\n",
      "Iteration 2534, loss = 0.01160316\n",
      "Iteration 2535, loss = 0.01159776\n",
      "Iteration 2536, loss = 0.01159330\n",
      "Iteration 2537, loss = 0.01158784\n",
      "Iteration 2538, loss = 0.01158234\n",
      "Iteration 2539, loss = 0.01157699\n",
      "Iteration 2540, loss = 0.01157201\n",
      "Iteration 2541, loss = 0.01156685\n",
      "Iteration 2542, loss = 0.01156121\n",
      "Iteration 2543, loss = 0.01155596\n",
      "Iteration 2544, loss = 0.01155089\n",
      "Iteration 2545, loss = 0.01154673\n",
      "Iteration 2546, loss = 0.01154120\n",
      "Iteration 2547, loss = 0.01153629\n",
      "Iteration 2548, loss = 0.01153146\n",
      "Iteration 2549, loss = 0.01152556\n",
      "Iteration 2550, loss = 0.01152029\n",
      "Iteration 2551, loss = 0.01151567\n",
      "Iteration 2552, loss = 0.01150951\n",
      "Iteration 2553, loss = 0.01150412\n",
      "Iteration 2554, loss = 0.01149918\n",
      "Iteration 2555, loss = 0.01149396\n",
      "Iteration 2556, loss = 0.01148912\n",
      "Iteration 2557, loss = 0.01148332\n",
      "Iteration 2558, loss = 0.01147831\n",
      "Iteration 2559, loss = 0.01147300\n",
      "Iteration 2560, loss = 0.01146744\n",
      "Iteration 2561, loss = 0.01146304\n",
      "Iteration 2562, loss = 0.01145722\n",
      "Iteration 2563, loss = 0.01145215\n",
      "Iteration 2564, loss = 0.01144788\n",
      "Iteration 2565, loss = 0.01144233\n",
      "Iteration 2566, loss = 0.01143734\n",
      "Iteration 2567, loss = 0.01143478\n",
      "Iteration 2568, loss = 0.01142682\n",
      "Iteration 2569, loss = 0.01142206\n",
      "Iteration 2570, loss = 0.01141610\n",
      "Iteration 2571, loss = 0.01140967\n",
      "Iteration 2572, loss = 0.01140719\n",
      "Iteration 2573, loss = 0.01140045\n",
      "Iteration 2574, loss = 0.01139420\n",
      "Iteration 2575, loss = 0.01138904\n",
      "Iteration 2576, loss = 0.01138318\n",
      "Iteration 2577, loss = 0.01137798\n",
      "Iteration 2578, loss = 0.01137292\n",
      "Iteration 2579, loss = 0.01136708\n",
      "Iteration 2580, loss = 0.01136232\n",
      "Iteration 2581, loss = 0.01135705\n",
      "Iteration 2582, loss = 0.01135091\n",
      "Iteration 2583, loss = 0.01134725\n",
      "Iteration 2584, loss = 0.01134127\n",
      "Iteration 2585, loss = 0.01133814\n",
      "Iteration 2586, loss = 0.01133221\n",
      "Iteration 2587, loss = 0.01132750\n",
      "Iteration 2588, loss = 0.01132212\n",
      "Iteration 2589, loss = 0.01131802\n",
      "Iteration 2590, loss = 0.01131340\n",
      "Iteration 2591, loss = 0.01130836\n",
      "Iteration 2592, loss = 0.01130300\n",
      "Iteration 2593, loss = 0.01130060\n",
      "Iteration 2594, loss = 0.01129429\n",
      "Iteration 2595, loss = 0.01129041\n",
      "Iteration 2596, loss = 0.01128569\n",
      "Iteration 2597, loss = 0.01128016\n",
      "Iteration 2598, loss = 0.01127500\n",
      "Iteration 2599, loss = 0.01126969\n",
      "Iteration 2600, loss = 0.01126512\n",
      "Iteration 2601, loss = 0.01125928\n",
      "Iteration 2602, loss = 0.01125496\n",
      "Iteration 2603, loss = 0.01124976\n",
      "Iteration 2604, loss = 0.01124424\n",
      "Iteration 2605, loss = 0.01123892\n",
      "Iteration 2606, loss = 0.01123424\n",
      "Iteration 2607, loss = 0.01122864\n",
      "Iteration 2608, loss = 0.01122394\n",
      "Iteration 2609, loss = 0.01121862\n",
      "Iteration 2610, loss = 0.01121334\n",
      "Iteration 2611, loss = 0.01120836\n",
      "Iteration 2612, loss = 0.01120294\n",
      "Iteration 2613, loss = 0.01119829\n",
      "Iteration 2614, loss = 0.01119248\n",
      "Iteration 2615, loss = 0.01118885\n",
      "Iteration 2616, loss = 0.01118253\n",
      "Iteration 2617, loss = 0.01117762\n",
      "Iteration 2618, loss = 0.01117276\n",
      "Iteration 2619, loss = 0.01116786\n",
      "Iteration 2620, loss = 0.01116227\n",
      "Iteration 2621, loss = 0.01115709\n",
      "Iteration 2622, loss = 0.01115206\n",
      "Iteration 2623, loss = 0.01114767\n",
      "Iteration 2624, loss = 0.01114155\n",
      "Iteration 2625, loss = 0.01113720\n",
      "Iteration 2626, loss = 0.01113089\n",
      "Iteration 2627, loss = 0.01112592\n",
      "Iteration 2628, loss = 0.01112094\n",
      "Iteration 2629, loss = 0.01111505\n",
      "Iteration 2630, loss = 0.01111009\n",
      "Iteration 2631, loss = 0.01110380\n",
      "Iteration 2632, loss = 0.01110008\n",
      "Iteration 2633, loss = 0.01109307\n",
      "Iteration 2634, loss = 0.01108968\n",
      "Iteration 2635, loss = 0.01108289\n",
      "Iteration 2636, loss = 0.01107800\n",
      "Iteration 2637, loss = 0.01107192\n",
      "Iteration 2638, loss = 0.01106773\n",
      "Iteration 2639, loss = 0.01106168\n",
      "Iteration 2640, loss = 0.01105645\n",
      "Iteration 2641, loss = 0.01105125\n",
      "Iteration 2642, loss = 0.01104580\n",
      "Iteration 2643, loss = 0.01104076\n",
      "Iteration 2644, loss = 0.01103501\n",
      "Iteration 2645, loss = 0.01102947\n",
      "Iteration 2646, loss = 0.01102553\n",
      "Iteration 2647, loss = 0.01101944\n",
      "Iteration 2648, loss = 0.01101500\n",
      "Iteration 2649, loss = 0.01100945\n",
      "Iteration 2650, loss = 0.01100420\n",
      "Iteration 2651, loss = 0.01099946\n",
      "Iteration 2652, loss = 0.01099736\n",
      "Iteration 2653, loss = 0.01098990\n",
      "Iteration 2654, loss = 0.01098543\n",
      "Iteration 2655, loss = 0.01098008\n",
      "Iteration 2656, loss = 0.01097502\n",
      "Iteration 2657, loss = 0.01097212\n",
      "Iteration 2658, loss = 0.01096546\n",
      "Iteration 2659, loss = 0.01096052\n",
      "Iteration 2660, loss = 0.01095567\n",
      "Iteration 2661, loss = 0.01095005\n",
      "Iteration 2662, loss = 0.01094590\n",
      "Iteration 2663, loss = 0.01094065\n",
      "Iteration 2664, loss = 0.01093542\n",
      "Iteration 2665, loss = 0.01093091\n",
      "Iteration 2666, loss = 0.01092686\n",
      "Iteration 2667, loss = 0.01092109\n",
      "Iteration 2668, loss = 0.01091749\n",
      "Iteration 2669, loss = 0.01091205\n",
      "Iteration 2670, loss = 0.01090740\n",
      "Iteration 2671, loss = 0.01090260\n",
      "Iteration 2672, loss = 0.01089795\n",
      "Iteration 2673, loss = 0.01089428\n",
      "Iteration 2674, loss = 0.01089000\n",
      "Iteration 2675, loss = 0.01088522\n",
      "Iteration 2676, loss = 0.01088026\n",
      "Iteration 2677, loss = 0.01087650\n",
      "Iteration 2678, loss = 0.01087127\n",
      "Iteration 2679, loss = 0.01086671\n",
      "Iteration 2680, loss = 0.01086184\n",
      "Iteration 2681, loss = 0.01085752\n",
      "Iteration 2682, loss = 0.01085441\n",
      "Iteration 2683, loss = 0.01084855\n",
      "Iteration 2684, loss = 0.01084349\n",
      "Iteration 2685, loss = 0.01083889\n",
      "Iteration 2686, loss = 0.01083430\n",
      "Iteration 2687, loss = 0.01082970\n",
      "Iteration 2688, loss = 0.01082624\n",
      "Iteration 2689, loss = 0.01082091\n",
      "Iteration 2690, loss = 0.01081659\n",
      "Iteration 2691, loss = 0.01081132\n",
      "Iteration 2692, loss = 0.01080688\n",
      "Iteration 2693, loss = 0.01080228\n",
      "Iteration 2694, loss = 0.01079817\n",
      "Iteration 2695, loss = 0.01079292\n",
      "Iteration 2696, loss = 0.01078839\n",
      "Iteration 2697, loss = 0.01078364\n",
      "Iteration 2698, loss = 0.01077926\n",
      "Iteration 2699, loss = 0.01077398\n",
      "Iteration 2700, loss = 0.01076969\n",
      "Iteration 2701, loss = 0.01076453\n",
      "Iteration 2702, loss = 0.01075946\n",
      "Iteration 2703, loss = 0.01075534\n",
      "Iteration 2704, loss = 0.01075097\n",
      "Iteration 2705, loss = 0.01074577\n",
      "Iteration 2706, loss = 0.01074150\n",
      "Iteration 2707, loss = 0.01073716\n",
      "Iteration 2708, loss = 0.01073248\n",
      "Iteration 2709, loss = 0.01072899\n",
      "Iteration 2710, loss = 0.01072393\n",
      "Iteration 2711, loss = 0.01071960\n",
      "Iteration 2712, loss = 0.01071404\n",
      "Iteration 2713, loss = 0.01070961\n",
      "Iteration 2714, loss = 0.01070663\n",
      "Iteration 2715, loss = 0.01070167\n",
      "Iteration 2716, loss = 0.01069691\n",
      "Iteration 2717, loss = 0.01069193\n",
      "Iteration 2718, loss = 0.01068733\n",
      "Iteration 2719, loss = 0.01068296\n",
      "Iteration 2720, loss = 0.01067840\n",
      "Iteration 2721, loss = 0.01067352\n",
      "Iteration 2722, loss = 0.01066894\n",
      "Iteration 2723, loss = 0.01066382\n",
      "Iteration 2724, loss = 0.01065991\n",
      "Iteration 2725, loss = 0.01065545\n",
      "Iteration 2726, loss = 0.01065031\n",
      "Iteration 2727, loss = 0.01064519\n",
      "Iteration 2728, loss = 0.01063997\n",
      "Iteration 2729, loss = 0.01063647\n",
      "Iteration 2730, loss = 0.01063116\n",
      "Iteration 2731, loss = 0.01062709\n",
      "Iteration 2732, loss = 0.01062142\n",
      "Iteration 2733, loss = 0.01061674\n",
      "Iteration 2734, loss = 0.01061266\n",
      "Iteration 2735, loss = 0.01060731\n",
      "Iteration 2736, loss = 0.01060390\n",
      "Iteration 2737, loss = 0.01059806\n",
      "Iteration 2738, loss = 0.01059505\n",
      "Iteration 2739, loss = 0.01059016\n",
      "Iteration 2740, loss = 0.01058489\n",
      "Iteration 2741, loss = 0.01058075\n",
      "Iteration 2742, loss = 0.01057573\n",
      "Iteration 2743, loss = 0.01057136\n",
      "Iteration 2744, loss = 0.01056681\n",
      "Iteration 2745, loss = 0.01056184\n",
      "Iteration 2746, loss = 0.01055720\n",
      "Iteration 2747, loss = 0.01055560\n",
      "Iteration 2748, loss = 0.01054890\n",
      "Iteration 2749, loss = 0.01054434\n",
      "Iteration 2750, loss = 0.01054086\n",
      "Iteration 2751, loss = 0.01053556\n",
      "Iteration 2752, loss = 0.01053123\n",
      "Iteration 2753, loss = 0.01052655\n",
      "Iteration 2754, loss = 0.01052302\n",
      "Iteration 2755, loss = 0.01051745\n",
      "Iteration 2756, loss = 0.01051299\n",
      "Iteration 2757, loss = 0.01050860\n",
      "Iteration 2758, loss = 0.01050396\n",
      "Iteration 2759, loss = 0.01049988\n",
      "Iteration 2760, loss = 0.01049530\n",
      "Iteration 2761, loss = 0.01049082\n",
      "Iteration 2762, loss = 0.01048629\n",
      "Iteration 2763, loss = 0.01048156\n",
      "Iteration 2764, loss = 0.01047764\n",
      "Iteration 2765, loss = 0.01047337\n",
      "Iteration 2766, loss = 0.01046853\n",
      "Iteration 2767, loss = 0.01046466\n",
      "Iteration 2768, loss = 0.01046010\n",
      "Iteration 2769, loss = 0.01045594\n",
      "Iteration 2770, loss = 0.01045142\n",
      "Iteration 2771, loss = 0.01044729\n",
      "Iteration 2772, loss = 0.01044279\n",
      "Iteration 2773, loss = 0.01043870\n",
      "Iteration 2774, loss = 0.01043459\n",
      "Iteration 2775, loss = 0.01043059\n",
      "Iteration 2776, loss = 0.01042575\n",
      "Iteration 2777, loss = 0.01042151\n",
      "Iteration 2778, loss = 0.01041676\n",
      "Iteration 2779, loss = 0.01041516\n",
      "Iteration 2780, loss = 0.01040991\n",
      "Iteration 2781, loss = 0.01040768\n",
      "Iteration 2782, loss = 0.01040066\n",
      "Iteration 2783, loss = 0.01039572\n",
      "Iteration 2784, loss = 0.01039136\n",
      "Iteration 2785, loss = 0.01038697\n",
      "Iteration 2786, loss = 0.01038230\n",
      "Iteration 2787, loss = 0.01037767\n",
      "Iteration 2788, loss = 0.01037326\n",
      "Iteration 2789, loss = 0.01036856\n",
      "Iteration 2790, loss = 0.01036425\n",
      "Iteration 2791, loss = 0.01035950\n",
      "Iteration 2792, loss = 0.01035541\n",
      "Iteration 2793, loss = 0.01035123\n",
      "Iteration 2794, loss = 0.01034703\n",
      "Iteration 2795, loss = 0.01034292\n",
      "Iteration 2796, loss = 0.01033860\n",
      "Iteration 2797, loss = 0.01033439\n",
      "Iteration 2798, loss = 0.01033090\n",
      "Iteration 2799, loss = 0.01032786\n",
      "Iteration 2800, loss = 0.01032272\n",
      "Iteration 2801, loss = 0.01031880\n",
      "Iteration 2802, loss = 0.01031352\n",
      "Iteration 2803, loss = 0.01030908\n",
      "Iteration 2804, loss = 0.01030459\n",
      "Iteration 2805, loss = 0.01030104\n",
      "Iteration 2806, loss = 0.01029527\n",
      "Iteration 2807, loss = 0.01029008\n",
      "Iteration 2808, loss = 0.01028517\n",
      "Iteration 2809, loss = 0.01028132\n",
      "Iteration 2810, loss = 0.01027644\n",
      "Iteration 2811, loss = 0.01027277\n",
      "Iteration 2812, loss = 0.01026736\n",
      "Iteration 2813, loss = 0.01026323\n",
      "Iteration 2814, loss = 0.01025878\n",
      "Iteration 2815, loss = 0.01025477\n",
      "Iteration 2816, loss = 0.01025132\n",
      "Iteration 2817, loss = 0.01024641\n",
      "Iteration 2818, loss = 0.01024262\n",
      "Iteration 2819, loss = 0.01023797\n",
      "Iteration 2820, loss = 0.01023456\n",
      "Iteration 2821, loss = 0.01023038\n",
      "Iteration 2822, loss = 0.01022597\n",
      "Iteration 2823, loss = 0.01022201\n",
      "Iteration 2824, loss = 0.01021773\n",
      "Iteration 2825, loss = 0.01021524\n",
      "Iteration 2826, loss = 0.01021120\n",
      "Iteration 2827, loss = 0.01020652\n",
      "Iteration 2828, loss = 0.01020295\n",
      "Iteration 2829, loss = 0.01019873\n",
      "Iteration 2830, loss = 0.01019533\n",
      "Iteration 2831, loss = 0.01019130\n",
      "Iteration 2832, loss = 0.01018952\n",
      "Iteration 2833, loss = 0.01018364\n",
      "Iteration 2834, loss = 0.01018004\n",
      "Iteration 2835, loss = 0.01017579\n",
      "Iteration 2836, loss = 0.01017269\n",
      "Iteration 2837, loss = 0.01016840\n",
      "Iteration 2838, loss = 0.01016475\n",
      "Iteration 2839, loss = 0.01016027\n",
      "Iteration 2840, loss = 0.01015762\n",
      "Iteration 2841, loss = 0.01015264\n",
      "Iteration 2842, loss = 0.01014940\n",
      "Iteration 2843, loss = 0.01014478\n",
      "Iteration 2844, loss = 0.01014085\n",
      "Iteration 2845, loss = 0.01013651\n",
      "Iteration 2846, loss = 0.01013346\n",
      "Iteration 2847, loss = 0.01012846\n",
      "Iteration 2848, loss = 0.01012401\n",
      "Iteration 2849, loss = 0.01011981\n",
      "Iteration 2850, loss = 0.01011567\n",
      "Iteration 2851, loss = 0.01011048\n",
      "Iteration 2852, loss = 0.01010442\n",
      "Iteration 2853, loss = 0.01010065\n",
      "Iteration 2854, loss = 0.01009667\n",
      "Iteration 2855, loss = 0.01009147\n",
      "Iteration 2856, loss = 0.01008679\n",
      "Iteration 2857, loss = 0.01008203\n",
      "Iteration 2858, loss = 0.01007788\n",
      "Iteration 2859, loss = 0.01007352\n",
      "Iteration 2860, loss = 0.01006928\n",
      "Iteration 2861, loss = 0.01006536\n",
      "Iteration 2862, loss = 0.01006219\n",
      "Iteration 2863, loss = 0.01005734\n",
      "Iteration 2864, loss = 0.01005312\n",
      "Iteration 2865, loss = 0.01004950\n",
      "Iteration 2866, loss = 0.01004601\n",
      "Iteration 2867, loss = 0.01004216\n",
      "Iteration 2868, loss = 0.01003835\n",
      "Iteration 2869, loss = 0.01003475\n",
      "Iteration 2870, loss = 0.01003082\n",
      "Iteration 2871, loss = 0.01002667\n",
      "Iteration 2872, loss = 0.01002247\n",
      "Iteration 2873, loss = 0.01001862\n",
      "Iteration 2874, loss = 0.01001497\n",
      "Iteration 2875, loss = 0.01001196\n",
      "Iteration 2876, loss = 0.01000732\n",
      "Iteration 2877, loss = 0.01000394\n",
      "Iteration 2878, loss = 0.00999974\n",
      "Iteration 2879, loss = 0.00999599\n",
      "Iteration 2880, loss = 0.00999219\n",
      "Iteration 2881, loss = 0.00998870\n",
      "Iteration 2882, loss = 0.00998412\n",
      "Iteration 2883, loss = 0.00998002\n",
      "Iteration 2884, loss = 0.00997616\n",
      "Iteration 2885, loss = 0.00997222\n",
      "Iteration 2886, loss = 0.00996874\n",
      "Iteration 2887, loss = 0.00996528\n",
      "Iteration 2888, loss = 0.00996115\n",
      "Iteration 2889, loss = 0.00995839\n",
      "Iteration 2890, loss = 0.00995403\n",
      "Iteration 2891, loss = 0.00995100\n",
      "Iteration 2892, loss = 0.00994615\n",
      "Iteration 2893, loss = 0.00994276\n",
      "Iteration 2894, loss = 0.00993777\n",
      "Iteration 2895, loss = 0.00993407\n",
      "Iteration 2896, loss = 0.00992975\n",
      "Iteration 2897, loss = 0.00992531\n",
      "Iteration 2898, loss = 0.00992189\n",
      "Iteration 2899, loss = 0.00991725\n",
      "Iteration 2900, loss = 0.00991453\n",
      "Iteration 2901, loss = 0.00990946\n",
      "Iteration 2902, loss = 0.00990560\n",
      "Iteration 2903, loss = 0.00990190\n",
      "Iteration 2904, loss = 0.00989853\n",
      "Iteration 2905, loss = 0.00989415\n",
      "Iteration 2906, loss = 0.00989107\n",
      "Iteration 2907, loss = 0.00988646\n",
      "Iteration 2908, loss = 0.00988198\n",
      "Iteration 2909, loss = 0.00987764\n",
      "Iteration 2910, loss = 0.00987363\n",
      "Iteration 2911, loss = 0.00986935\n",
      "Iteration 2912, loss = 0.00986476\n",
      "Iteration 2913, loss = 0.00985993\n",
      "Iteration 2914, loss = 0.00985607\n",
      "Iteration 2915, loss = 0.00985167\n",
      "Iteration 2916, loss = 0.00984730\n",
      "Iteration 2917, loss = 0.00984442\n",
      "Iteration 2918, loss = 0.00983980\n",
      "Iteration 2919, loss = 0.00983558\n",
      "Iteration 2920, loss = 0.00983218\n",
      "Iteration 2921, loss = 0.00982780\n",
      "Iteration 2922, loss = 0.00982385\n",
      "Iteration 2923, loss = 0.00982174\n",
      "Iteration 2924, loss = 0.00981672\n",
      "Iteration 2925, loss = 0.00981486\n",
      "Iteration 2926, loss = 0.00980940\n",
      "Iteration 2927, loss = 0.00980478\n",
      "Iteration 2928, loss = 0.00980112\n",
      "Iteration 2929, loss = 0.00979674\n",
      "Iteration 2930, loss = 0.00979228\n",
      "Iteration 2931, loss = 0.00978780\n",
      "Iteration 2932, loss = 0.00978492\n",
      "Iteration 2933, loss = 0.00978072\n",
      "Iteration 2934, loss = 0.00977615\n",
      "Iteration 2935, loss = 0.00977242\n",
      "Iteration 2936, loss = 0.00976866\n",
      "Iteration 2937, loss = 0.00976455\n",
      "Iteration 2938, loss = 0.00976056\n",
      "Iteration 2939, loss = 0.00975825\n",
      "Iteration 2940, loss = 0.00975329\n",
      "Iteration 2941, loss = 0.00974976\n",
      "Iteration 2942, loss = 0.00974577\n",
      "Iteration 2943, loss = 0.00974204\n",
      "Iteration 2944, loss = 0.00973851\n",
      "Iteration 2945, loss = 0.00973516\n",
      "Iteration 2946, loss = 0.00973181\n",
      "Iteration 2947, loss = 0.00972821\n",
      "Iteration 2948, loss = 0.00972463\n",
      "Iteration 2949, loss = 0.00972205\n",
      "Iteration 2950, loss = 0.00971774\n",
      "Iteration 2951, loss = 0.00971336\n",
      "Iteration 2952, loss = 0.00971043\n",
      "Iteration 2953, loss = 0.00970575\n",
      "Iteration 2954, loss = 0.00970152\n",
      "Iteration 2955, loss = 0.00969815\n",
      "Iteration 2956, loss = 0.00969505\n",
      "Iteration 2957, loss = 0.00969071\n",
      "Iteration 2958, loss = 0.00968682\n",
      "Iteration 2959, loss = 0.00968354\n",
      "Iteration 2960, loss = 0.00967963\n",
      "Iteration 2961, loss = 0.00967630\n",
      "Iteration 2962, loss = 0.00967274\n",
      "Iteration 2963, loss = 0.00966925\n",
      "Iteration 2964, loss = 0.00966595\n",
      "Iteration 2965, loss = 0.00966292\n",
      "Iteration 2966, loss = 0.00965959\n",
      "Iteration 2967, loss = 0.00965880\n",
      "Iteration 2968, loss = 0.00965284\n",
      "Iteration 2969, loss = 0.00965031\n",
      "Iteration 2970, loss = 0.00964573\n",
      "Iteration 2971, loss = 0.00964224\n",
      "Iteration 2972, loss = 0.00963864\n",
      "Iteration 2973, loss = 0.00963537\n",
      "Iteration 2974, loss = 0.00963184\n",
      "Iteration 2975, loss = 0.00962906\n",
      "Iteration 2976, loss = 0.00962543\n",
      "Iteration 2977, loss = 0.00962140\n",
      "Iteration 2978, loss = 0.00961859\n",
      "Iteration 2979, loss = 0.00961580\n",
      "Iteration 2980, loss = 0.00961306\n",
      "Iteration 2981, loss = 0.00960918\n",
      "Iteration 2982, loss = 0.00960708\n",
      "Iteration 2983, loss = 0.00960282\n",
      "Iteration 2984, loss = 0.00959898\n",
      "Iteration 2985, loss = 0.00959578\n",
      "Iteration 2986, loss = 0.00959175\n",
      "Iteration 2987, loss = 0.00958801\n",
      "Iteration 2988, loss = 0.00958423\n",
      "Iteration 2989, loss = 0.00958054\n",
      "Iteration 2990, loss = 0.00957666\n",
      "Iteration 2991, loss = 0.00957258\n",
      "Iteration 2992, loss = 0.00957005\n",
      "Iteration 2993, loss = 0.00956551\n",
      "Iteration 2994, loss = 0.00956140\n",
      "Iteration 2995, loss = 0.00955734\n",
      "Iteration 2996, loss = 0.00955385\n",
      "Iteration 2997, loss = 0.00955015\n",
      "Iteration 2998, loss = 0.00954524\n",
      "Iteration 2999, loss = 0.00954187\n",
      "Iteration 3000, loss = 0.00953725\n",
      "Iteration 3001, loss = 0.00953381\n",
      "Iteration 3002, loss = 0.00952979\n",
      "Iteration 3003, loss = 0.00952508\n",
      "Iteration 3004, loss = 0.00952147\n",
      "Iteration 3005, loss = 0.00951767\n",
      "Iteration 3006, loss = 0.00951337\n",
      "Iteration 3007, loss = 0.00950980\n",
      "Iteration 3008, loss = 0.00950628\n",
      "Iteration 3009, loss = 0.00950282\n",
      "Iteration 3010, loss = 0.00949901\n",
      "Iteration 3011, loss = 0.00949541\n",
      "Iteration 3012, loss = 0.00949194\n",
      "Iteration 3013, loss = 0.00948814\n",
      "Iteration 3014, loss = 0.00948407\n",
      "Iteration 3015, loss = 0.00948126\n",
      "Iteration 3016, loss = 0.00947732\n",
      "Iteration 3017, loss = 0.00947326\n",
      "Iteration 3018, loss = 0.00946964\n",
      "Iteration 3019, loss = 0.00946625\n",
      "Iteration 3020, loss = 0.00946227\n",
      "Iteration 3021, loss = 0.00945855\n",
      "Iteration 3022, loss = 0.00945464\n",
      "Iteration 3023, loss = 0.00944997\n",
      "Iteration 3024, loss = 0.00944667\n",
      "Iteration 3025, loss = 0.00944156\n",
      "Iteration 3026, loss = 0.00943884\n",
      "Iteration 3027, loss = 0.00943515\n",
      "Iteration 3028, loss = 0.00942998\n",
      "Iteration 3029, loss = 0.00942613\n",
      "Iteration 3030, loss = 0.00942265\n",
      "Iteration 3031, loss = 0.00941875\n",
      "Iteration 3032, loss = 0.00941575\n",
      "Iteration 3033, loss = 0.00941069\n",
      "Iteration 3034, loss = 0.00940657\n",
      "Iteration 3035, loss = 0.00940301\n",
      "Iteration 3036, loss = 0.00939953\n",
      "Iteration 3037, loss = 0.00939570\n",
      "Iteration 3038, loss = 0.00939173\n",
      "Iteration 3039, loss = 0.00938750\n",
      "Iteration 3040, loss = 0.00938402\n",
      "Iteration 3041, loss = 0.00937981\n",
      "Iteration 3042, loss = 0.00937582\n",
      "Iteration 3043, loss = 0.00937204\n",
      "Iteration 3044, loss = 0.00936847\n",
      "Iteration 3045, loss = 0.00936432\n",
      "Iteration 3046, loss = 0.00936106\n",
      "Iteration 3047, loss = 0.00935700\n",
      "Iteration 3048, loss = 0.00935458\n",
      "Iteration 3049, loss = 0.00935009\n",
      "Iteration 3050, loss = 0.00934674\n",
      "Iteration 3051, loss = 0.00934305\n",
      "Iteration 3052, loss = 0.00933990\n",
      "Iteration 3053, loss = 0.00933586\n",
      "Iteration 3054, loss = 0.00933216\n",
      "Iteration 3055, loss = 0.00932894\n",
      "Iteration 3056, loss = 0.00932519\n",
      "Iteration 3057, loss = 0.00932156\n",
      "Iteration 3058, loss = 0.00931795\n",
      "Iteration 3059, loss = 0.00931454\n",
      "Iteration 3060, loss = 0.00931123\n",
      "Iteration 3061, loss = 0.00930967\n",
      "Iteration 3062, loss = 0.00930481\n",
      "Iteration 3063, loss = 0.00930178\n",
      "Iteration 3064, loss = 0.00929818\n",
      "Iteration 3065, loss = 0.00929377\n",
      "Iteration 3066, loss = 0.00929035\n",
      "Iteration 3067, loss = 0.00928678\n",
      "Iteration 3068, loss = 0.00928272\n",
      "Iteration 3069, loss = 0.00927963\n",
      "Iteration 3070, loss = 0.00927587\n",
      "Iteration 3071, loss = 0.00927162\n",
      "Iteration 3072, loss = 0.00926943\n",
      "Iteration 3073, loss = 0.00926496\n",
      "Iteration 3074, loss = 0.00926229\n",
      "Iteration 3075, loss = 0.00925767\n",
      "Iteration 3076, loss = 0.00925406\n",
      "Iteration 3077, loss = 0.00925112\n",
      "Iteration 3078, loss = 0.00924567\n",
      "Iteration 3079, loss = 0.00924284\n",
      "Iteration 3080, loss = 0.00923985\n",
      "Iteration 3081, loss = 0.00923632\n",
      "Iteration 3082, loss = 0.00923235\n",
      "Iteration 3083, loss = 0.00923006\n",
      "Iteration 3084, loss = 0.00922590\n",
      "Iteration 3085, loss = 0.00922285\n",
      "Iteration 3086, loss = 0.00921970\n",
      "Iteration 3087, loss = 0.00921605\n",
      "Iteration 3088, loss = 0.00921200\n",
      "Iteration 3089, loss = 0.00920857\n",
      "Iteration 3090, loss = 0.00920525\n",
      "Iteration 3091, loss = 0.00920178\n",
      "Iteration 3092, loss = 0.00919836\n",
      "Iteration 3093, loss = 0.00919485\n",
      "Iteration 3094, loss = 0.00919130\n",
      "Iteration 3095, loss = 0.00918788\n",
      "Iteration 3096, loss = 0.00918512\n",
      "Iteration 3097, loss = 0.00918110\n",
      "Iteration 3098, loss = 0.00917770\n",
      "Iteration 3099, loss = 0.00917408\n",
      "Iteration 3100, loss = 0.00917043\n",
      "Iteration 3101, loss = 0.00916749\n",
      "Iteration 3102, loss = 0.00916431\n",
      "Iteration 3103, loss = 0.00916011\n",
      "Iteration 3104, loss = 0.00915724\n",
      "Iteration 3105, loss = 0.00915316\n",
      "Iteration 3106, loss = 0.00915055\n",
      "Iteration 3107, loss = 0.00914648\n",
      "Iteration 3108, loss = 0.00914362\n",
      "Iteration 3109, loss = 0.00913965\n",
      "Iteration 3110, loss = 0.00913618\n",
      "Iteration 3111, loss = 0.00913283\n",
      "Iteration 3112, loss = 0.00912938\n",
      "Iteration 3113, loss = 0.00912602\n",
      "Iteration 3114, loss = 0.00912307\n",
      "Iteration 3115, loss = 0.00911848\n",
      "Iteration 3116, loss = 0.00911499\n",
      "Iteration 3117, loss = 0.00911155\n",
      "Iteration 3118, loss = 0.00910871\n",
      "Iteration 3119, loss = 0.00910506\n",
      "Iteration 3120, loss = 0.00910135\n",
      "Iteration 3121, loss = 0.00909762\n",
      "Iteration 3122, loss = 0.00909418\n",
      "Iteration 3123, loss = 0.00909100\n",
      "Iteration 3124, loss = 0.00908732\n",
      "Iteration 3125, loss = 0.00908414\n",
      "Iteration 3126, loss = 0.00908096\n",
      "Iteration 3127, loss = 0.00907721\n",
      "Iteration 3128, loss = 0.00907359\n",
      "Iteration 3129, loss = 0.00907092\n",
      "Iteration 3130, loss = 0.00906714\n",
      "Iteration 3131, loss = 0.00906375\n",
      "Iteration 3132, loss = 0.00906084\n",
      "Iteration 3133, loss = 0.00905717\n",
      "Iteration 3134, loss = 0.00905413\n",
      "Iteration 3135, loss = 0.00905100\n",
      "Iteration 3136, loss = 0.00904742\n",
      "Iteration 3137, loss = 0.00904407\n",
      "Iteration 3138, loss = 0.00904268\n",
      "Iteration 3139, loss = 0.00903786\n",
      "Iteration 3140, loss = 0.00903415\n",
      "Iteration 3141, loss = 0.00903067\n",
      "Iteration 3142, loss = 0.00902824\n",
      "Iteration 3143, loss = 0.00902419\n",
      "Iteration 3144, loss = 0.00902114\n",
      "Iteration 3145, loss = 0.00901780\n",
      "Iteration 3146, loss = 0.00901357\n",
      "Iteration 3147, loss = 0.00900995\n",
      "Iteration 3148, loss = 0.00900660\n",
      "Iteration 3149, loss = 0.00900354\n",
      "Iteration 3150, loss = 0.00900007\n",
      "Iteration 3151, loss = 0.00899700\n",
      "Iteration 3152, loss = 0.00899384\n",
      "Iteration 3153, loss = 0.00899030\n",
      "Iteration 3154, loss = 0.00898695\n",
      "Iteration 3155, loss = 0.00898354\n",
      "Iteration 3156, loss = 0.00897977\n",
      "Iteration 3157, loss = 0.00897757\n",
      "Iteration 3158, loss = 0.00897312\n",
      "Iteration 3159, loss = 0.00896976\n",
      "Iteration 3160, loss = 0.00896617\n",
      "Iteration 3161, loss = 0.00896279\n",
      "Iteration 3162, loss = 0.00895953\n",
      "Iteration 3163, loss = 0.00895596\n",
      "Iteration 3164, loss = 0.00895289\n",
      "Iteration 3165, loss = 0.00894933\n",
      "Iteration 3166, loss = 0.00894640\n",
      "Iteration 3167, loss = 0.00894311\n",
      "Iteration 3168, loss = 0.00893982\n",
      "Iteration 3169, loss = 0.00893837\n",
      "Iteration 3170, loss = 0.00893429\n",
      "Iteration 3171, loss = 0.00893045\n",
      "Iteration 3172, loss = 0.00892752\n",
      "Iteration 3173, loss = 0.00892355\n",
      "Iteration 3174, loss = 0.00892008\n",
      "Iteration 3175, loss = 0.00891733\n",
      "Iteration 3176, loss = 0.00891336\n",
      "Iteration 3177, loss = 0.00891028\n",
      "Iteration 3178, loss = 0.00890732\n",
      "Iteration 3179, loss = 0.00890319\n",
      "Iteration 3180, loss = 0.00890024\n",
      "Iteration 3181, loss = 0.00889644\n",
      "Iteration 3182, loss = 0.00889365\n",
      "Iteration 3183, loss = 0.00888990\n",
      "Iteration 3184, loss = 0.00888598\n",
      "Iteration 3185, loss = 0.00888290\n",
      "Iteration 3186, loss = 0.00887894\n",
      "Iteration 3187, loss = 0.00887574\n",
      "Iteration 3188, loss = 0.00887240\n",
      "Iteration 3189, loss = 0.00886911\n",
      "Iteration 3190, loss = 0.00886614\n",
      "Iteration 3191, loss = 0.00886322\n",
      "Iteration 3192, loss = 0.00885981\n",
      "Iteration 3193, loss = 0.00885665\n",
      "Iteration 3194, loss = 0.00885373\n",
      "Iteration 3195, loss = 0.00885023\n",
      "Iteration 3196, loss = 0.00884674\n",
      "Iteration 3197, loss = 0.00884442\n",
      "Iteration 3198, loss = 0.00884054\n",
      "Iteration 3199, loss = 0.00883743\n",
      "Iteration 3200, loss = 0.00883498\n",
      "Iteration 3201, loss = 0.00883157\n",
      "Iteration 3202, loss = 0.00882837\n",
      "Iteration 3203, loss = 0.00882628\n",
      "Iteration 3204, loss = 0.00882269\n",
      "Iteration 3205, loss = 0.00881953\n",
      "Iteration 3206, loss = 0.00881609\n",
      "Iteration 3207, loss = 0.00881307\n",
      "Iteration 3208, loss = 0.00880969\n",
      "Iteration 3209, loss = 0.00880662\n",
      "Iteration 3210, loss = 0.00880335\n",
      "Iteration 3211, loss = 0.00880015\n",
      "Iteration 3212, loss = 0.00879709\n",
      "Iteration 3213, loss = 0.00879398\n",
      "Iteration 3214, loss = 0.00879049\n",
      "Iteration 3215, loss = 0.00878715\n",
      "Iteration 3216, loss = 0.00878423\n",
      "Iteration 3217, loss = 0.00878082\n",
      "Iteration 3218, loss = 0.00877684\n",
      "Iteration 3219, loss = 0.00877338\n",
      "Iteration 3220, loss = 0.00877040\n",
      "Iteration 3221, loss = 0.00876881\n",
      "Iteration 3222, loss = 0.00876411\n",
      "Iteration 3223, loss = 0.00876085\n",
      "Iteration 3224, loss = 0.00875774\n",
      "Iteration 3225, loss = 0.00875480\n",
      "Iteration 3226, loss = 0.00875241\n",
      "Iteration 3227, loss = 0.00874886\n",
      "Iteration 3228, loss = 0.00874612\n",
      "Iteration 3229, loss = 0.00874281\n",
      "Iteration 3230, loss = 0.00874166\n",
      "Iteration 3231, loss = 0.00873746\n",
      "Iteration 3232, loss = 0.00873344\n",
      "Iteration 3233, loss = 0.00873023\n",
      "Iteration 3234, loss = 0.00872710\n",
      "Iteration 3235, loss = 0.00872494\n",
      "Iteration 3236, loss = 0.00872041\n",
      "Iteration 3237, loss = 0.00871661\n",
      "Iteration 3238, loss = 0.00871347\n",
      "Iteration 3239, loss = 0.00871012\n",
      "Iteration 3240, loss = 0.00870673\n",
      "Iteration 3241, loss = 0.00870351\n",
      "Iteration 3242, loss = 0.00870036\n",
      "Iteration 3243, loss = 0.00869690\n",
      "Iteration 3244, loss = 0.00869367\n",
      "Iteration 3245, loss = 0.00869134\n",
      "Iteration 3246, loss = 0.00868779\n",
      "Iteration 3247, loss = 0.00868458\n",
      "Iteration 3248, loss = 0.00868126\n",
      "Iteration 3249, loss = 0.00867796\n",
      "Iteration 3250, loss = 0.00867449\n",
      "Iteration 3251, loss = 0.00867115\n",
      "Iteration 3252, loss = 0.00866760\n",
      "Iteration 3253, loss = 0.00866537\n",
      "Iteration 3254, loss = 0.00866167\n",
      "Iteration 3255, loss = 0.00865867\n",
      "Iteration 3256, loss = 0.00865464\n",
      "Iteration 3257, loss = 0.00865202\n",
      "Iteration 3258, loss = 0.00864855\n",
      "Iteration 3259, loss = 0.00864547\n",
      "Iteration 3260, loss = 0.00864281\n",
      "Iteration 3261, loss = 0.00863911\n",
      "Iteration 3262, loss = 0.00863631\n",
      "Iteration 3263, loss = 0.00863295\n",
      "Iteration 3264, loss = 0.00863066\n",
      "Iteration 3265, loss = 0.00862712\n",
      "Iteration 3266, loss = 0.00862493\n",
      "Iteration 3267, loss = 0.00862130\n",
      "Iteration 3268, loss = 0.00861778\n",
      "Iteration 3269, loss = 0.00861459\n",
      "Iteration 3270, loss = 0.00861205\n",
      "Iteration 3271, loss = 0.00860948\n",
      "Iteration 3272, loss = 0.00860535\n",
      "Iteration 3273, loss = 0.00860177\n",
      "Iteration 3274, loss = 0.00859860\n",
      "Iteration 3275, loss = 0.00859508\n",
      "Iteration 3276, loss = 0.00859159\n",
      "Iteration 3277, loss = 0.00859021\n",
      "Iteration 3278, loss = 0.00858660\n",
      "Iteration 3279, loss = 0.00858280\n",
      "Iteration 3280, loss = 0.00857966\n",
      "Iteration 3281, loss = 0.00857658\n",
      "Iteration 3282, loss = 0.00857257\n",
      "Iteration 3283, loss = 0.00857013\n",
      "Iteration 3284, loss = 0.00856665\n",
      "Iteration 3285, loss = 0.00856301\n",
      "Iteration 3286, loss = 0.00855966\n",
      "Iteration 3287, loss = 0.00855673\n",
      "Iteration 3288, loss = 0.00855288\n",
      "Iteration 3289, loss = 0.00855293\n",
      "Iteration 3290, loss = 0.00854756\n",
      "Iteration 3291, loss = 0.00854374\n",
      "Iteration 3292, loss = 0.00854096\n",
      "Iteration 3293, loss = 0.00853834\n",
      "Iteration 3294, loss = 0.00853498\n",
      "Iteration 3295, loss = 0.00853287\n",
      "Iteration 3296, loss = 0.00852894\n",
      "Iteration 3297, loss = 0.00852572\n",
      "Iteration 3298, loss = 0.00852231\n",
      "Iteration 3299, loss = 0.00851931\n",
      "Iteration 3300, loss = 0.00851624\n",
      "Iteration 3301, loss = 0.00851309\n",
      "Iteration 3302, loss = 0.00850986\n",
      "Iteration 3303, loss = 0.00850636\n",
      "Iteration 3304, loss = 0.00850467\n",
      "Iteration 3305, loss = 0.00850060\n",
      "Iteration 3306, loss = 0.00849911\n",
      "Iteration 3307, loss = 0.00849475\n",
      "Iteration 3308, loss = 0.00849192\n",
      "Iteration 3309, loss = 0.00848830\n",
      "Iteration 3310, loss = 0.00848565\n",
      "Iteration 3311, loss = 0.00848214\n",
      "Iteration 3312, loss = 0.00847900\n",
      "Iteration 3313, loss = 0.00847497\n",
      "Iteration 3314, loss = 0.00847267\n",
      "Iteration 3315, loss = 0.00846900\n",
      "Iteration 3316, loss = 0.00846581\n",
      "Iteration 3317, loss = 0.00846233\n",
      "Iteration 3318, loss = 0.00845949\n",
      "Iteration 3319, loss = 0.00845651\n",
      "Iteration 3320, loss = 0.00845347\n",
      "Iteration 3321, loss = 0.00845018\n",
      "Iteration 3322, loss = 0.00844813\n",
      "Iteration 3323, loss = 0.00844416\n",
      "Iteration 3324, loss = 0.00844141\n",
      "Iteration 3325, loss = 0.00843834\n",
      "Iteration 3326, loss = 0.00843553\n",
      "Iteration 3327, loss = 0.00843242\n",
      "Iteration 3328, loss = 0.00842955\n",
      "Iteration 3329, loss = 0.00842694\n",
      "Iteration 3330, loss = 0.00842438\n",
      "Iteration 3331, loss = 0.00842242\n",
      "Iteration 3332, loss = 0.00841884\n",
      "Iteration 3333, loss = 0.00841597\n",
      "Iteration 3334, loss = 0.00841304\n",
      "Iteration 3335, loss = 0.00841019\n",
      "Iteration 3336, loss = 0.00840761\n",
      "Iteration 3337, loss = 0.00840487\n",
      "Iteration 3338, loss = 0.00840215\n",
      "Iteration 3339, loss = 0.00839983\n",
      "Iteration 3340, loss = 0.00839797\n",
      "Iteration 3341, loss = 0.00839407\n",
      "Iteration 3342, loss = 0.00839111\n",
      "Iteration 3343, loss = 0.00838807\n",
      "Iteration 3344, loss = 0.00838518\n",
      "Iteration 3345, loss = 0.00838270\n",
      "Iteration 3346, loss = 0.00838044\n",
      "Iteration 3347, loss = 0.00837647\n",
      "Iteration 3348, loss = 0.00837391\n",
      "Iteration 3349, loss = 0.00837061\n",
      "Iteration 3350, loss = 0.00836758\n",
      "Iteration 3351, loss = 0.00836439\n",
      "Iteration 3352, loss = 0.00836174\n",
      "Iteration 3353, loss = 0.00835852\n",
      "Iteration 3354, loss = 0.00835558\n",
      "Iteration 3355, loss = 0.00835224\n",
      "Iteration 3356, loss = 0.00834941\n",
      "Iteration 3357, loss = 0.00834672\n",
      "Iteration 3358, loss = 0.00834321\n",
      "Iteration 3359, loss = 0.00834054\n",
      "Iteration 3360, loss = 0.00833849\n",
      "Iteration 3361, loss = 0.00833507\n",
      "Iteration 3362, loss = 0.00833213\n",
      "Iteration 3363, loss = 0.00832955\n",
      "Iteration 3364, loss = 0.00832679\n",
      "Iteration 3365, loss = 0.00832373\n",
      "Iteration 3366, loss = 0.00832078\n",
      "Iteration 3367, loss = 0.00832118\n",
      "Iteration 3368, loss = 0.00831565\n",
      "Iteration 3369, loss = 0.00831223\n",
      "Iteration 3370, loss = 0.00830875\n",
      "Iteration 3371, loss = 0.00830620\n",
      "Iteration 3372, loss = 0.00830227\n",
      "Iteration 3373, loss = 0.00830049\n",
      "Iteration 3374, loss = 0.00829654\n",
      "Iteration 3375, loss = 0.00829329\n",
      "Iteration 3376, loss = 0.00829065\n",
      "Iteration 3377, loss = 0.00828747\n",
      "Iteration 3378, loss = 0.00828414\n",
      "Iteration 3379, loss = 0.00828100\n",
      "Iteration 3380, loss = 0.00827843\n",
      "Iteration 3381, loss = 0.00827459\n",
      "Iteration 3382, loss = 0.00827262\n",
      "Iteration 3383, loss = 0.00826989\n",
      "Iteration 3384, loss = 0.00826698\n",
      "Iteration 3385, loss = 0.00826331\n",
      "Iteration 3386, loss = 0.00826010\n",
      "Iteration 3387, loss = 0.00825728\n",
      "Iteration 3388, loss = 0.00825466\n",
      "Iteration 3389, loss = 0.00825149\n",
      "Iteration 3390, loss = 0.00824927\n",
      "Iteration 3391, loss = 0.00824627\n",
      "Iteration 3392, loss = 0.00824305\n",
      "Iteration 3393, loss = 0.00824045\n",
      "Iteration 3394, loss = 0.00823767\n",
      "Iteration 3395, loss = 0.00823481\n",
      "Iteration 3396, loss = 0.00823182\n",
      "Iteration 3397, loss = 0.00823010\n",
      "Iteration 3398, loss = 0.00822843\n",
      "Iteration 3399, loss = 0.00822476\n",
      "Iteration 3400, loss = 0.00822209\n",
      "Iteration 3401, loss = 0.00821932\n",
      "Iteration 3402, loss = 0.00821672\n",
      "Iteration 3403, loss = 0.00821415\n",
      "Iteration 3404, loss = 0.00821244\n",
      "Iteration 3405, loss = 0.00820915\n",
      "Iteration 3406, loss = 0.00820661\n",
      "Iteration 3407, loss = 0.00820381\n",
      "Iteration 3408, loss = 0.00820136\n",
      "Iteration 3409, loss = 0.00819884\n",
      "Iteration 3410, loss = 0.00819618\n",
      "Iteration 3411, loss = 0.00819389\n",
      "Iteration 3412, loss = 0.00819155\n",
      "Iteration 3413, loss = 0.00818922\n",
      "Iteration 3414, loss = 0.00818654\n",
      "Iteration 3415, loss = 0.00818431\n",
      "Iteration 3416, loss = 0.00818142\n",
      "Iteration 3417, loss = 0.00817902\n",
      "Iteration 3418, loss = 0.00817755\n",
      "Iteration 3419, loss = 0.00817430\n",
      "Iteration 3420, loss = 0.00817183\n",
      "Iteration 3421, loss = 0.00816898\n",
      "Iteration 3422, loss = 0.00816657\n",
      "Iteration 3423, loss = 0.00816423\n",
      "Iteration 3424, loss = 0.00816190\n",
      "Iteration 3425, loss = 0.00815949\n",
      "Iteration 3426, loss = 0.00815846\n",
      "Iteration 3427, loss = 0.00815511\n",
      "Iteration 3428, loss = 0.00815229\n",
      "Iteration 3429, loss = 0.00814942\n",
      "Iteration 3430, loss = 0.00814719\n",
      "Iteration 3431, loss = 0.00814457\n",
      "Iteration 3432, loss = 0.00814130\n",
      "Iteration 3433, loss = 0.00813786\n",
      "Iteration 3434, loss = 0.00813474\n",
      "Iteration 3435, loss = 0.00813065\n",
      "Iteration 3436, loss = 0.00812702\n",
      "Iteration 3437, loss = 0.00812338\n",
      "Iteration 3438, loss = 0.00812062\n",
      "Iteration 3439, loss = 0.00811722\n",
      "Iteration 3440, loss = 0.00811392\n",
      "Iteration 3441, loss = 0.00811052\n",
      "Iteration 3442, loss = 0.00810778\n",
      "Iteration 3443, loss = 0.00810472\n",
      "Iteration 3444, loss = 0.00810174\n",
      "Iteration 3445, loss = 0.00809854\n",
      "Iteration 3446, loss = 0.00809605\n",
      "Iteration 3447, loss = 0.00809268\n",
      "Iteration 3448, loss = 0.00809005\n",
      "Iteration 3449, loss = 0.00808752\n",
      "Iteration 3450, loss = 0.00808447\n",
      "Iteration 3451, loss = 0.00808189\n",
      "Iteration 3452, loss = 0.00807943\n",
      "Iteration 3453, loss = 0.00807664\n",
      "Iteration 3454, loss = 0.00807393\n",
      "Iteration 3455, loss = 0.00807138\n",
      "Iteration 3456, loss = 0.00806886\n",
      "Iteration 3457, loss = 0.00806699\n",
      "Iteration 3458, loss = 0.00806324\n",
      "Iteration 3459, loss = 0.00806077\n",
      "Iteration 3460, loss = 0.00805772\n",
      "Iteration 3461, loss = 0.00805453\n",
      "Iteration 3462, loss = 0.00805187\n",
      "Iteration 3463, loss = 0.00804927\n",
      "Iteration 3464, loss = 0.00804701\n",
      "Iteration 3465, loss = 0.00804406\n",
      "Iteration 3466, loss = 0.00804242\n",
      "Iteration 3467, loss = 0.00803915\n",
      "Iteration 3468, loss = 0.00803599\n",
      "Iteration 3469, loss = 0.00803258\n",
      "Iteration 3470, loss = 0.00803051\n",
      "Iteration 3471, loss = 0.00802648\n",
      "Iteration 3472, loss = 0.00802264\n",
      "Iteration 3473, loss = 0.00802117\n",
      "Iteration 3474, loss = 0.00801611\n",
      "Iteration 3475, loss = 0.00801375\n",
      "Iteration 3476, loss = 0.00801094\n",
      "Iteration 3477, loss = 0.00800736\n",
      "Iteration 3478, loss = 0.00800555\n",
      "Iteration 3479, loss = 0.00800236\n",
      "Iteration 3480, loss = 0.00799904\n",
      "Iteration 3481, loss = 0.00799690\n",
      "Iteration 3482, loss = 0.00799391\n",
      "Iteration 3483, loss = 0.00799123\n",
      "Iteration 3484, loss = 0.00798830\n",
      "Iteration 3485, loss = 0.00798721\n",
      "Iteration 3486, loss = 0.00798327\n",
      "Iteration 3487, loss = 0.00798018\n",
      "Iteration 3488, loss = 0.00797754\n",
      "Iteration 3489, loss = 0.00797460\n",
      "Iteration 3490, loss = 0.00797323\n",
      "Iteration 3491, loss = 0.00796987\n",
      "Iteration 3492, loss = 0.00796704\n",
      "Iteration 3493, loss = 0.00796371\n",
      "Iteration 3494, loss = 0.00796092\n",
      "Iteration 3495, loss = 0.00795820\n",
      "Iteration 3496, loss = 0.00795546\n",
      "Iteration 3497, loss = 0.00795255\n",
      "Iteration 3498, loss = 0.00795010\n",
      "Iteration 3499, loss = 0.00794677\n",
      "Iteration 3500, loss = 0.00794354\n",
      "Iteration 3501, loss = 0.00794045\n",
      "Iteration 3502, loss = 0.00793699\n",
      "Iteration 3503, loss = 0.00793516\n",
      "Iteration 3504, loss = 0.00793124\n",
      "Iteration 3505, loss = 0.00792871\n",
      "Iteration 3506, loss = 0.00792580\n",
      "Iteration 3507, loss = 0.00792290\n",
      "Iteration 3508, loss = 0.00792020\n",
      "Iteration 3509, loss = 0.00791755\n",
      "Iteration 3510, loss = 0.00791510\n",
      "Iteration 3511, loss = 0.00791192\n",
      "Iteration 3512, loss = 0.00790943\n",
      "Iteration 3513, loss = 0.00790650\n",
      "Iteration 3514, loss = 0.00790532\n",
      "Iteration 3515, loss = 0.00790127\n",
      "Iteration 3516, loss = 0.00789908\n",
      "Iteration 3517, loss = 0.00789603\n",
      "Iteration 3518, loss = 0.00789351\n",
      "Iteration 3519, loss = 0.00789116\n",
      "Iteration 3520, loss = 0.00788865\n",
      "Iteration 3521, loss = 0.00788768\n",
      "Iteration 3522, loss = 0.00788364\n",
      "Iteration 3523, loss = 0.00788085\n",
      "Iteration 3524, loss = 0.00787847\n",
      "Iteration 3525, loss = 0.00787502\n",
      "Iteration 3526, loss = 0.00787274\n",
      "Iteration 3527, loss = 0.00787011\n",
      "Iteration 3528, loss = 0.00786616\n",
      "Iteration 3529, loss = 0.00786352\n",
      "Iteration 3530, loss = 0.00786131\n",
      "Iteration 3531, loss = 0.00785807\n",
      "Iteration 3532, loss = 0.00785581\n",
      "Iteration 3533, loss = 0.00785286\n",
      "Iteration 3534, loss = 0.00785015\n",
      "Iteration 3535, loss = 0.00784767\n",
      "Iteration 3536, loss = 0.00784582\n",
      "Iteration 3537, loss = 0.00784387\n",
      "Iteration 3538, loss = 0.00784044\n",
      "Iteration 3539, loss = 0.00783653\n",
      "Iteration 3540, loss = 0.00783467\n",
      "Iteration 3541, loss = 0.00783135\n",
      "Iteration 3542, loss = 0.00782848\n",
      "Iteration 3543, loss = 0.00782598\n",
      "Iteration 3544, loss = 0.00782263\n",
      "Iteration 3545, loss = 0.00781953\n",
      "Iteration 3546, loss = 0.00781739\n",
      "Iteration 3547, loss = 0.00781387\n",
      "Iteration 3548, loss = 0.00781163\n",
      "Iteration 3549, loss = 0.00780814\n",
      "Iteration 3550, loss = 0.00780602\n",
      "Iteration 3551, loss = 0.00780206\n",
      "Iteration 3552, loss = 0.00780109\n",
      "Iteration 3553, loss = 0.00779606\n",
      "Iteration 3554, loss = 0.00779330\n",
      "Iteration 3555, loss = 0.00779052\n",
      "Iteration 3556, loss = 0.00778791\n",
      "Iteration 3557, loss = 0.00778491\n",
      "Iteration 3558, loss = 0.00778237\n",
      "Iteration 3559, loss = 0.00777969\n",
      "Iteration 3560, loss = 0.00777725\n",
      "Iteration 3561, loss = 0.00777474\n",
      "Iteration 3562, loss = 0.00777190\n",
      "Iteration 3563, loss = 0.00776929\n",
      "Iteration 3564, loss = 0.00776678\n",
      "Iteration 3565, loss = 0.00776503\n",
      "Iteration 3566, loss = 0.00776182\n",
      "Iteration 3567, loss = 0.00775911\n",
      "Iteration 3568, loss = 0.00775705\n",
      "Iteration 3569, loss = 0.00775459\n",
      "Iteration 3570, loss = 0.00775252\n",
      "Iteration 3571, loss = 0.00774988\n",
      "Iteration 3572, loss = 0.00774719\n",
      "Iteration 3573, loss = 0.00774509\n",
      "Iteration 3574, loss = 0.00774232\n",
      "Iteration 3575, loss = 0.00773995\n",
      "Iteration 3576, loss = 0.00773731\n",
      "Iteration 3577, loss = 0.00773502\n",
      "Iteration 3578, loss = 0.00773244\n",
      "Iteration 3579, loss = 0.00772964\n",
      "Iteration 3580, loss = 0.00772702\n",
      "Iteration 3581, loss = 0.00772496\n",
      "Iteration 3582, loss = 0.00772204\n",
      "Iteration 3583, loss = 0.00771947\n",
      "Iteration 3584, loss = 0.00771742\n",
      "Iteration 3585, loss = 0.00771494\n",
      "Iteration 3586, loss = 0.00771345\n",
      "Iteration 3587, loss = 0.00771058\n",
      "Iteration 3588, loss = 0.00770849\n",
      "Iteration 3589, loss = 0.00770709\n",
      "Iteration 3590, loss = 0.00770428\n",
      "Iteration 3591, loss = 0.00770185\n",
      "Iteration 3592, loss = 0.00769905\n",
      "Iteration 3593, loss = 0.00769630\n",
      "Iteration 3594, loss = 0.00769379\n",
      "Iteration 3595, loss = 0.00769121\n",
      "Iteration 3596, loss = 0.00768926\n",
      "Iteration 3597, loss = 0.00768677\n",
      "Iteration 3598, loss = 0.00768510\n",
      "Iteration 3599, loss = 0.00768329\n",
      "Iteration 3600, loss = 0.00768094\n",
      "Iteration 3601, loss = 0.00767885\n",
      "Iteration 3602, loss = 0.00767642\n",
      "Iteration 3603, loss = 0.00767437\n",
      "Iteration 3604, loss = 0.00767167\n",
      "Iteration 3605, loss = 0.00766882\n",
      "Iteration 3606, loss = 0.00766568\n",
      "Iteration 3607, loss = 0.00766336\n",
      "Iteration 3608, loss = 0.00766056\n",
      "Iteration 3609, loss = 0.00765795\n",
      "Iteration 3610, loss = 0.00765527\n",
      "Iteration 3611, loss = 0.00765289\n",
      "Iteration 3612, loss = 0.00765064\n",
      "Iteration 3613, loss = 0.00764854\n",
      "Iteration 3614, loss = 0.00764624\n",
      "Iteration 3615, loss = 0.00764382\n",
      "Iteration 3616, loss = 0.00764092\n",
      "Iteration 3617, loss = 0.00763832\n",
      "Iteration 3618, loss = 0.00763584\n",
      "Iteration 3619, loss = 0.00763271\n",
      "Iteration 3620, loss = 0.00762989\n",
      "Iteration 3621, loss = 0.00762727\n",
      "Iteration 3622, loss = 0.00762489\n",
      "Iteration 3623, loss = 0.00762202\n",
      "Iteration 3624, loss = 0.00761994\n",
      "Iteration 3625, loss = 0.00761687\n",
      "Iteration 3626, loss = 0.00761392\n",
      "Iteration 3627, loss = 0.00761170\n",
      "Iteration 3628, loss = 0.00760965\n",
      "Iteration 3629, loss = 0.00760628\n",
      "Iteration 3630, loss = 0.00760426\n",
      "Iteration 3631, loss = 0.00760095\n",
      "Iteration 3632, loss = 0.00759900\n",
      "Iteration 3633, loss = 0.00759630\n",
      "Iteration 3634, loss = 0.00759318\n",
      "Iteration 3635, loss = 0.00759077\n",
      "Iteration 3636, loss = 0.00758838\n",
      "Iteration 3637, loss = 0.00758560\n",
      "Iteration 3638, loss = 0.00758325\n",
      "Iteration 3639, loss = 0.00758057\n",
      "Iteration 3640, loss = 0.00757798\n",
      "Iteration 3641, loss = 0.00757551\n",
      "Iteration 3642, loss = 0.00757311\n",
      "Iteration 3643, loss = 0.00757096\n",
      "Iteration 3644, loss = 0.00756858\n",
      "Iteration 3645, loss = 0.00756629\n",
      "Iteration 3646, loss = 0.00756339\n",
      "Iteration 3647, loss = 0.00756033\n",
      "Iteration 3648, loss = 0.00755752\n",
      "Iteration 3649, loss = 0.00755523\n",
      "Iteration 3650, loss = 0.00755170\n",
      "Iteration 3651, loss = 0.00754856\n",
      "Iteration 3652, loss = 0.00754747\n",
      "Iteration 3653, loss = 0.00754308\n",
      "Iteration 3654, loss = 0.00754149\n",
      "Iteration 3655, loss = 0.00753735\n",
      "Iteration 3656, loss = 0.00753458\n",
      "Iteration 3657, loss = 0.00753380\n",
      "Iteration 3658, loss = 0.00752924\n",
      "Iteration 3659, loss = 0.00752733\n",
      "Iteration 3660, loss = 0.00752410\n",
      "Iteration 3661, loss = 0.00752100\n",
      "Iteration 3662, loss = 0.00751858\n",
      "Iteration 3663, loss = 0.00751592\n",
      "Iteration 3664, loss = 0.00751319\n",
      "Iteration 3665, loss = 0.00751058\n",
      "Iteration 3666, loss = 0.00750865\n",
      "Iteration 3667, loss = 0.00750598\n",
      "Iteration 3668, loss = 0.00750327\n",
      "Iteration 3669, loss = 0.00750087\n",
      "Iteration 3670, loss = 0.00749849\n",
      "Iteration 3671, loss = 0.00749603\n",
      "Iteration 3672, loss = 0.00749390\n",
      "Iteration 3673, loss = 0.00749152\n",
      "Iteration 3674, loss = 0.00748987\n",
      "Iteration 3675, loss = 0.00748746\n",
      "Iteration 3676, loss = 0.00748502\n",
      "Iteration 3677, loss = 0.00748239\n",
      "Iteration 3678, loss = 0.00747996\n",
      "Iteration 3679, loss = 0.00747746\n",
      "Iteration 3680, loss = 0.00747475\n",
      "Iteration 3681, loss = 0.00747342\n",
      "Iteration 3682, loss = 0.00746984\n",
      "Iteration 3683, loss = 0.00746737\n",
      "Iteration 3684, loss = 0.00746483\n",
      "Iteration 3685, loss = 0.00746221\n",
      "Iteration 3686, loss = 0.00745952\n",
      "Iteration 3687, loss = 0.00745708\n",
      "Iteration 3688, loss = 0.00745450\n",
      "Iteration 3689, loss = 0.00745204\n",
      "Iteration 3690, loss = 0.00744920\n",
      "Iteration 3691, loss = 0.00744754\n",
      "Iteration 3692, loss = 0.00744521\n",
      "Iteration 3693, loss = 0.00744246\n",
      "Iteration 3694, loss = 0.00744046\n",
      "Iteration 3695, loss = 0.00743812\n",
      "Iteration 3696, loss = 0.00743904\n",
      "Iteration 3697, loss = 0.00743404\n",
      "Iteration 3698, loss = 0.00743127\n",
      "Iteration 3699, loss = 0.00742881\n",
      "Iteration 3700, loss = 0.00742691\n",
      "Iteration 3701, loss = 0.00742380\n",
      "Iteration 3702, loss = 0.00742164\n",
      "Iteration 3703, loss = 0.00741971\n",
      "Iteration 3704, loss = 0.00741635\n",
      "Iteration 3705, loss = 0.00741342\n",
      "Iteration 3706, loss = 0.00741097\n",
      "Iteration 3707, loss = 0.00740856\n",
      "Iteration 3708, loss = 0.00740536\n",
      "Iteration 3709, loss = 0.00740271\n",
      "Iteration 3710, loss = 0.00740048\n",
      "Iteration 3711, loss = 0.00739817\n",
      "Iteration 3712, loss = 0.00739520\n",
      "Iteration 3713, loss = 0.00739298\n",
      "Iteration 3714, loss = 0.00739021\n",
      "Iteration 3715, loss = 0.00738743\n",
      "Iteration 3716, loss = 0.00738475\n",
      "Iteration 3717, loss = 0.00738248\n",
      "Iteration 3718, loss = 0.00737986\n",
      "Iteration 3719, loss = 0.00737739\n",
      "Iteration 3720, loss = 0.00737470\n",
      "Iteration 3721, loss = 0.00737202\n",
      "Iteration 3722, loss = 0.00737008\n",
      "Iteration 3723, loss = 0.00736714\n",
      "Iteration 3724, loss = 0.00736454\n",
      "Iteration 3725, loss = 0.00736220\n",
      "Iteration 3726, loss = 0.00735952\n",
      "Iteration 3727, loss = 0.00735680\n",
      "Iteration 3728, loss = 0.00735576\n",
      "Iteration 3729, loss = 0.00735201\n",
      "Iteration 3730, loss = 0.00734969\n",
      "Iteration 3731, loss = 0.00734703\n",
      "Iteration 3732, loss = 0.00734471\n",
      "Iteration 3733, loss = 0.00734207\n",
      "Iteration 3734, loss = 0.00734002\n",
      "Iteration 3735, loss = 0.00733751\n",
      "Iteration 3736, loss = 0.00733502\n",
      "Iteration 3737, loss = 0.00733245\n",
      "Iteration 3738, loss = 0.00733064\n",
      "Iteration 3739, loss = 0.00732756\n",
      "Iteration 3740, loss = 0.00732511\n",
      "Iteration 3741, loss = 0.00732279\n",
      "Iteration 3742, loss = 0.00732006\n",
      "Iteration 3743, loss = 0.00731798\n",
      "Iteration 3744, loss = 0.00731482\n",
      "Iteration 3745, loss = 0.00731224\n",
      "Iteration 3746, loss = 0.00730987\n",
      "Iteration 3747, loss = 0.00730719\n",
      "Iteration 3748, loss = 0.00730487\n",
      "Iteration 3749, loss = 0.00730236\n",
      "Iteration 3750, loss = 0.00729974\n",
      "Iteration 3751, loss = 0.00729705\n",
      "Iteration 3752, loss = 0.00729620\n",
      "Iteration 3753, loss = 0.00729285\n",
      "Iteration 3754, loss = 0.00729079\n",
      "Iteration 3755, loss = 0.00728809\n",
      "Iteration 3756, loss = 0.00728640\n",
      "Iteration 3757, loss = 0.00728328\n",
      "Iteration 3758, loss = 0.00728108\n",
      "Iteration 3759, loss = 0.00727884\n",
      "Iteration 3760, loss = 0.00727639\n",
      "Iteration 3761, loss = 0.00727392\n",
      "Iteration 3762, loss = 0.00727297\n",
      "Iteration 3763, loss = 0.00726975\n",
      "Iteration 3764, loss = 0.00726712\n",
      "Iteration 3765, loss = 0.00726490\n",
      "Iteration 3766, loss = 0.00726278\n",
      "Iteration 3767, loss = 0.00726042\n",
      "Iteration 3768, loss = 0.00725785\n",
      "Iteration 3769, loss = 0.00725526\n",
      "Iteration 3770, loss = 0.00725326\n",
      "Iteration 3771, loss = 0.00725067\n",
      "Iteration 3772, loss = 0.00724928\n",
      "Iteration 3773, loss = 0.00724589\n",
      "Iteration 3774, loss = 0.00724387\n",
      "Iteration 3775, loss = 0.00724111\n",
      "Iteration 3776, loss = 0.00723885\n",
      "Iteration 3777, loss = 0.00723527\n",
      "Iteration 3778, loss = 0.00723363\n",
      "Iteration 3779, loss = 0.00723197\n",
      "Iteration 3780, loss = 0.00722955\n",
      "Iteration 3781, loss = 0.00722683\n",
      "Iteration 3782, loss = 0.00722610\n",
      "Iteration 3783, loss = 0.00722312\n",
      "Iteration 3784, loss = 0.00721983\n",
      "Iteration 3785, loss = 0.00721747\n",
      "Iteration 3786, loss = 0.00721605\n",
      "Iteration 3787, loss = 0.00721253\n",
      "Iteration 3788, loss = 0.00720937\n",
      "Iteration 3789, loss = 0.00720720\n",
      "Iteration 3790, loss = 0.00720438\n",
      "Iteration 3791, loss = 0.00720186\n",
      "Iteration 3792, loss = 0.00719952\n",
      "Iteration 3793, loss = 0.00719750\n",
      "Iteration 3794, loss = 0.00719441\n",
      "Iteration 3795, loss = 0.00719181\n",
      "Iteration 3796, loss = 0.00718981\n",
      "Iteration 3797, loss = 0.00718726\n",
      "Iteration 3798, loss = 0.00718498\n",
      "Iteration 3799, loss = 0.00718256\n",
      "Iteration 3800, loss = 0.00718047\n",
      "Iteration 3801, loss = 0.00717794\n",
      "Iteration 3802, loss = 0.00717652\n",
      "Iteration 3803, loss = 0.00717377\n",
      "Iteration 3804, loss = 0.00717122\n",
      "Iteration 3805, loss = 0.00716886\n",
      "Iteration 3806, loss = 0.00716638\n",
      "Iteration 3807, loss = 0.00716387\n",
      "Iteration 3808, loss = 0.00716235\n",
      "Iteration 3809, loss = 0.00715949\n",
      "Iteration 3810, loss = 0.00715637\n",
      "Iteration 3811, loss = 0.00715429\n",
      "Iteration 3812, loss = 0.00715197\n",
      "Iteration 3813, loss = 0.00714928\n",
      "Iteration 3814, loss = 0.00714687\n",
      "Iteration 3815, loss = 0.00714449\n",
      "Iteration 3816, loss = 0.00714282\n",
      "Iteration 3817, loss = 0.00714005\n",
      "Iteration 3818, loss = 0.00713786\n",
      "Iteration 3819, loss = 0.00713568\n",
      "Iteration 3820, loss = 0.00713345\n",
      "Iteration 3821, loss = 0.00713086\n",
      "Iteration 3822, loss = 0.00712871\n",
      "Iteration 3823, loss = 0.00712644\n",
      "Iteration 3824, loss = 0.00712447\n",
      "Iteration 3825, loss = 0.00712205\n",
      "Iteration 3826, loss = 0.00712086\n",
      "Iteration 3827, loss = 0.00711830\n",
      "Iteration 3828, loss = 0.00711568\n",
      "Iteration 3829, loss = 0.00711366\n",
      "Iteration 3830, loss = 0.00711095\n",
      "Iteration 3831, loss = 0.00710890\n",
      "Iteration 3832, loss = 0.00710642\n",
      "Iteration 3833, loss = 0.00710405\n",
      "Iteration 3834, loss = 0.00710157\n",
      "Iteration 3835, loss = 0.00709927\n",
      "Iteration 3836, loss = 0.00709673\n",
      "Iteration 3837, loss = 0.00709528\n",
      "Iteration 3838, loss = 0.00709247\n",
      "Iteration 3839, loss = 0.00708942\n",
      "Iteration 3840, loss = 0.00708776\n",
      "Iteration 3841, loss = 0.00708564\n",
      "Iteration 3842, loss = 0.00708292\n",
      "Iteration 3843, loss = 0.00708043\n",
      "Iteration 3844, loss = 0.00707789\n",
      "Iteration 3845, loss = 0.00707590\n",
      "Iteration 3846, loss = 0.00707338\n",
      "Iteration 3847, loss = 0.00707100\n",
      "Iteration 3848, loss = 0.00706912\n",
      "Iteration 3849, loss = 0.00706707\n",
      "Iteration 3850, loss = 0.00706429\n",
      "Iteration 3851, loss = 0.00706285\n",
      "Iteration 3852, loss = 0.00706015\n",
      "Iteration 3853, loss = 0.00705892\n",
      "Iteration 3854, loss = 0.00705597\n",
      "Iteration 3855, loss = 0.00705357\n",
      "Iteration 3856, loss = 0.00705154\n",
      "Iteration 3857, loss = 0.00704899\n",
      "Iteration 3858, loss = 0.00704614\n",
      "Iteration 3859, loss = 0.00704376\n",
      "Iteration 3860, loss = 0.00704209\n",
      "Iteration 3861, loss = 0.00703950\n",
      "Iteration 3862, loss = 0.00703677\n",
      "Iteration 3863, loss = 0.00703461\n",
      "Iteration 3864, loss = 0.00703213\n",
      "Iteration 3865, loss = 0.00702968\n",
      "Iteration 3866, loss = 0.00702747\n",
      "Iteration 3867, loss = 0.00702526\n",
      "Iteration 3868, loss = 0.00702311\n",
      "Iteration 3869, loss = 0.00702100\n",
      "Iteration 3870, loss = 0.00701905\n",
      "Iteration 3871, loss = 0.00701662\n",
      "Iteration 3872, loss = 0.00701447\n",
      "Iteration 3873, loss = 0.00701231\n",
      "Iteration 3874, loss = 0.00700986\n",
      "Iteration 3875, loss = 0.00700753\n",
      "Iteration 3876, loss = 0.00700564\n",
      "Iteration 3877, loss = 0.00700336\n",
      "Iteration 3878, loss = 0.00700092\n",
      "Iteration 3879, loss = 0.00699912\n",
      "Iteration 3880, loss = 0.00699712\n",
      "Iteration 3881, loss = 0.00699486\n",
      "Iteration 3882, loss = 0.00699242\n",
      "Iteration 3883, loss = 0.00699018\n",
      "Iteration 3884, loss = 0.00698792\n",
      "Iteration 3885, loss = 0.00698619\n",
      "Iteration 3886, loss = 0.00698386\n",
      "Iteration 3887, loss = 0.00698183\n",
      "Iteration 3888, loss = 0.00697972\n",
      "Iteration 3889, loss = 0.00697761\n",
      "Iteration 3890, loss = 0.00697581\n",
      "Iteration 3891, loss = 0.00697347\n",
      "Iteration 3892, loss = 0.00697154\n",
      "Iteration 3893, loss = 0.00696965\n",
      "Iteration 3894, loss = 0.00696689\n",
      "Iteration 3895, loss = 0.00696453\n",
      "Iteration 3896, loss = 0.00696227\n",
      "Iteration 3897, loss = 0.00695987\n",
      "Iteration 3898, loss = 0.00695797\n",
      "Iteration 3899, loss = 0.00695535\n",
      "Iteration 3900, loss = 0.00695322\n",
      "Iteration 3901, loss = 0.00695125\n",
      "Iteration 3902, loss = 0.00694968\n",
      "Iteration 3903, loss = 0.00694662\n",
      "Iteration 3904, loss = 0.00694456\n",
      "Iteration 3905, loss = 0.00694279\n",
      "Iteration 3906, loss = 0.00694010\n",
      "Iteration 3907, loss = 0.00693811\n",
      "Iteration 3908, loss = 0.00693558\n",
      "Iteration 3909, loss = 0.00693346\n",
      "Iteration 3910, loss = 0.00693120\n",
      "Iteration 3911, loss = 0.00692873\n",
      "Iteration 3912, loss = 0.00692601\n",
      "Iteration 3913, loss = 0.00692478\n",
      "Iteration 3914, loss = 0.00692251\n",
      "Iteration 3915, loss = 0.00691980\n",
      "Iteration 3916, loss = 0.00691733\n",
      "Iteration 3917, loss = 0.00691490\n",
      "Iteration 3918, loss = 0.00691281\n",
      "Iteration 3919, loss = 0.00691072\n",
      "Iteration 3920, loss = 0.00690886\n",
      "Iteration 3921, loss = 0.00690631\n",
      "Iteration 3922, loss = 0.00690412\n",
      "Iteration 3923, loss = 0.00690354\n",
      "Iteration 3924, loss = 0.00689991\n",
      "Iteration 3925, loss = 0.00689740\n",
      "Iteration 3926, loss = 0.00689498\n",
      "Iteration 3927, loss = 0.00689324\n",
      "Iteration 3928, loss = 0.00689178\n",
      "Iteration 3929, loss = 0.00688846\n",
      "Iteration 3930, loss = 0.00688546\n",
      "Iteration 3931, loss = 0.00688379\n",
      "Iteration 3932, loss = 0.00688089\n",
      "Iteration 3933, loss = 0.00687837\n",
      "Iteration 3934, loss = 0.00687587\n",
      "Iteration 3935, loss = 0.00687347\n",
      "Iteration 3936, loss = 0.00687149\n",
      "Iteration 3937, loss = 0.00687077\n",
      "Iteration 3938, loss = 0.00686704\n",
      "Iteration 3939, loss = 0.00686493\n",
      "Iteration 3940, loss = 0.00686304\n",
      "Iteration 3941, loss = 0.00686111\n",
      "Iteration 3942, loss = 0.00685898\n",
      "Iteration 3943, loss = 0.00685664\n",
      "Iteration 3944, loss = 0.00685451\n",
      "Iteration 3945, loss = 0.00685277\n",
      "Iteration 3946, loss = 0.00685062\n",
      "Iteration 3947, loss = 0.00684890\n",
      "Iteration 3948, loss = 0.00684672\n",
      "Iteration 3949, loss = 0.00684475\n",
      "Iteration 3950, loss = 0.00684289\n",
      "Iteration 3951, loss = 0.00684086\n",
      "Iteration 3952, loss = 0.00683930\n",
      "Iteration 3953, loss = 0.00683716\n",
      "Iteration 3954, loss = 0.00683671\n",
      "Iteration 3955, loss = 0.00683349\n",
      "Iteration 3956, loss = 0.00683172\n",
      "Iteration 3957, loss = 0.00683001\n",
      "Iteration 3958, loss = 0.00682823\n",
      "Iteration 3959, loss = 0.00682630\n",
      "Iteration 3960, loss = 0.00682484\n",
      "Iteration 3961, loss = 0.00682281\n",
      "Iteration 3962, loss = 0.00682121\n",
      "Iteration 3963, loss = 0.00681903\n",
      "Iteration 3964, loss = 0.00681695\n",
      "Iteration 3965, loss = 0.00681457\n",
      "Iteration 3966, loss = 0.00681270\n",
      "Iteration 3967, loss = 0.00681101\n",
      "Iteration 3968, loss = 0.00680748\n",
      "Iteration 3969, loss = 0.00680614\n",
      "Iteration 3970, loss = 0.00680284\n",
      "Iteration 3971, loss = 0.00680156\n",
      "Iteration 3972, loss = 0.00679942\n",
      "Iteration 3973, loss = 0.00679673\n",
      "Iteration 3974, loss = 0.00679460\n",
      "Iteration 3975, loss = 0.00679193\n",
      "Iteration 3976, loss = 0.00678978\n",
      "Iteration 3977, loss = 0.00678818\n",
      "Iteration 3978, loss = 0.00678604\n",
      "Iteration 3979, loss = 0.00678375\n",
      "Iteration 3980, loss = 0.00678171\n",
      "Iteration 3981, loss = 0.00677970\n",
      "Iteration 3982, loss = 0.00677778\n",
      "Iteration 3983, loss = 0.00677561\n",
      "Iteration 3984, loss = 0.00677374\n",
      "Iteration 3985, loss = 0.00677136\n",
      "Iteration 3986, loss = 0.00676898\n",
      "Iteration 3987, loss = 0.00676714\n",
      "Iteration 3988, loss = 0.00676503\n",
      "Iteration 3989, loss = 0.00676268\n",
      "Iteration 3990, loss = 0.00676064\n",
      "Iteration 3991, loss = 0.00675843\n",
      "Iteration 3992, loss = 0.00675631\n",
      "Iteration 3993, loss = 0.00675405\n",
      "Iteration 3994, loss = 0.00675200\n",
      "Iteration 3995, loss = 0.00674927\n",
      "Iteration 3996, loss = 0.00674739\n",
      "Iteration 3997, loss = 0.00674483\n",
      "Iteration 3998, loss = 0.00674325\n",
      "Iteration 3999, loss = 0.00674067\n",
      "Iteration 4000, loss = 0.00673843\n",
      "Iteration 4001, loss = 0.00673683\n",
      "Iteration 4002, loss = 0.00673436\n",
      "Iteration 4003, loss = 0.00673244\n",
      "Iteration 4004, loss = 0.00673096\n",
      "Iteration 4005, loss = 0.00672861\n",
      "Iteration 4006, loss = 0.00672620\n",
      "Iteration 4007, loss = 0.00672381\n",
      "Iteration 4008, loss = 0.00672179\n",
      "Iteration 4009, loss = 0.00672030\n",
      "Iteration 4010, loss = 0.00671771\n",
      "Iteration 4011, loss = 0.00671537\n",
      "Iteration 4012, loss = 0.00671342\n",
      "Iteration 4013, loss = 0.00671127\n",
      "Iteration 4014, loss = 0.00670955\n",
      "Iteration 4015, loss = 0.00670737\n",
      "Iteration 4016, loss = 0.00670501\n",
      "Iteration 4017, loss = 0.00670329\n",
      "Iteration 4018, loss = 0.00670110\n",
      "Iteration 4019, loss = 0.00669867\n",
      "Iteration 4020, loss = 0.00669710\n",
      "Iteration 4021, loss = 0.00669508\n",
      "Iteration 4022, loss = 0.00669312\n",
      "Iteration 4023, loss = 0.00669084\n",
      "Iteration 4024, loss = 0.00668872\n",
      "Iteration 4025, loss = 0.00668674\n",
      "Iteration 4026, loss = 0.00668501\n",
      "Iteration 4027, loss = 0.00668276\n",
      "Iteration 4028, loss = 0.00668087\n",
      "Iteration 4029, loss = 0.00667989\n",
      "Iteration 4030, loss = 0.00667718\n",
      "Iteration 4031, loss = 0.00667527\n",
      "Iteration 4032, loss = 0.00667327\n",
      "Iteration 4033, loss = 0.00667133\n",
      "Iteration 4034, loss = 0.00666948\n",
      "Iteration 4035, loss = 0.00666729\n",
      "Iteration 4036, loss = 0.00666566\n",
      "Iteration 4037, loss = 0.00666300\n",
      "Iteration 4038, loss = 0.00666095\n",
      "Iteration 4039, loss = 0.00665885\n",
      "Iteration 4040, loss = 0.00665673\n",
      "Iteration 4041, loss = 0.00665483\n",
      "Iteration 4042, loss = 0.00665286\n",
      "Iteration 4043, loss = 0.00665114\n",
      "Iteration 4044, loss = 0.00664874\n",
      "Iteration 4045, loss = 0.00664654\n",
      "Iteration 4046, loss = 0.00664495\n",
      "Iteration 4047, loss = 0.00664245\n",
      "Iteration 4048, loss = 0.00664019\n",
      "Iteration 4049, loss = 0.00663887\n",
      "Iteration 4050, loss = 0.00663627\n",
      "Iteration 4051, loss = 0.00663438\n",
      "Iteration 4052, loss = 0.00663194\n",
      "Iteration 4053, loss = 0.00662983\n",
      "Iteration 4054, loss = 0.00662791\n",
      "Iteration 4055, loss = 0.00662611\n",
      "Iteration 4056, loss = 0.00662396\n",
      "Iteration 4057, loss = 0.00662226\n",
      "Iteration 4058, loss = 0.00661987\n",
      "Iteration 4059, loss = 0.00661803\n",
      "Iteration 4060, loss = 0.00661667\n",
      "Iteration 4061, loss = 0.00661435\n",
      "Iteration 4062, loss = 0.00661247\n",
      "Iteration 4063, loss = 0.00661061\n",
      "Iteration 4064, loss = 0.00660873\n",
      "Iteration 4065, loss = 0.00660679\n",
      "Iteration 4066, loss = 0.00660549\n",
      "Iteration 4067, loss = 0.00660327\n",
      "Iteration 4068, loss = 0.00660139\n",
      "Iteration 4069, loss = 0.00659952\n",
      "Iteration 4070, loss = 0.00659781\n",
      "Iteration 4071, loss = 0.00659571\n",
      "Iteration 4072, loss = 0.00659394\n",
      "Iteration 4073, loss = 0.00659243\n",
      "Iteration 4074, loss = 0.00659137\n",
      "Iteration 4075, loss = 0.00658889\n",
      "Iteration 4076, loss = 0.00658738\n",
      "Iteration 4077, loss = 0.00658554\n",
      "Iteration 4078, loss = 0.00658337\n",
      "Iteration 4079, loss = 0.00658143\n",
      "Iteration 4080, loss = 0.00657975\n",
      "Iteration 4081, loss = 0.00657829\n",
      "Iteration 4082, loss = 0.00657601\n",
      "Iteration 4083, loss = 0.00657344\n",
      "Iteration 4084, loss = 0.00657148\n",
      "Iteration 4085, loss = 0.00656920\n",
      "Iteration 4086, loss = 0.00656733\n",
      "Iteration 4087, loss = 0.00656581\n",
      "Iteration 4088, loss = 0.00656381\n",
      "Iteration 4089, loss = 0.00656171\n",
      "Iteration 4090, loss = 0.00655982\n",
      "Iteration 4091, loss = 0.00655751\n",
      "Iteration 4092, loss = 0.00655583\n",
      "Iteration 4093, loss = 0.00655395\n",
      "Iteration 4094, loss = 0.00655238\n",
      "Iteration 4095, loss = 0.00655037\n",
      "Iteration 4096, loss = 0.00654815\n",
      "Iteration 4097, loss = 0.00654642\n",
      "Iteration 4098, loss = 0.00654528\n",
      "Iteration 4099, loss = 0.00654295\n",
      "Iteration 4100, loss = 0.00654107\n",
      "Iteration 4101, loss = 0.00653975\n",
      "Iteration 4102, loss = 0.00653763\n",
      "Iteration 4103, loss = 0.00653574\n",
      "Iteration 4104, loss = 0.00653372\n",
      "Iteration 4105, loss = 0.00653190\n",
      "Iteration 4106, loss = 0.00653077\n",
      "Iteration 4107, loss = 0.00652804\n",
      "Iteration 4108, loss = 0.00652677\n",
      "Iteration 4109, loss = 0.00652310\n",
      "Iteration 4110, loss = 0.00652169\n",
      "Iteration 4111, loss = 0.00651868\n",
      "Iteration 4112, loss = 0.00651632\n",
      "Iteration 4113, loss = 0.00651478\n",
      "Iteration 4114, loss = 0.00651195\n",
      "Iteration 4115, loss = 0.00650984\n",
      "Iteration 4116, loss = 0.00650710\n",
      "Iteration 4117, loss = 0.00650594\n",
      "Iteration 4118, loss = 0.00650327\n",
      "Iteration 4119, loss = 0.00650069\n",
      "Iteration 4120, loss = 0.00649842\n",
      "Iteration 4121, loss = 0.00649627\n",
      "Iteration 4122, loss = 0.00649431\n",
      "Iteration 4123, loss = 0.00649332\n",
      "Iteration 4124, loss = 0.00649049\n",
      "Iteration 4125, loss = 0.00648853\n",
      "Iteration 4126, loss = 0.00648668\n",
      "Iteration 4127, loss = 0.00648452\n",
      "Iteration 4128, loss = 0.00648263\n",
      "Iteration 4129, loss = 0.00648081\n",
      "Iteration 4130, loss = 0.00647933\n",
      "Iteration 4131, loss = 0.00647763\n",
      "Iteration 4132, loss = 0.00647578\n",
      "Iteration 4133, loss = 0.00647402\n",
      "Iteration 4134, loss = 0.00647218\n",
      "Iteration 4135, loss = 0.00647044\n",
      "Iteration 4136, loss = 0.00646940\n",
      "Iteration 4137, loss = 0.00646701\n",
      "Iteration 4138, loss = 0.00646534\n",
      "Iteration 4139, loss = 0.00646297\n",
      "Iteration 4140, loss = 0.00646079\n",
      "Iteration 4141, loss = 0.00646019\n",
      "Iteration 4142, loss = 0.00645692\n",
      "Iteration 4143, loss = 0.00645437\n",
      "Iteration 4144, loss = 0.00645201\n",
      "Iteration 4145, loss = 0.00645049\n",
      "Iteration 4146, loss = 0.00644807\n",
      "Iteration 4147, loss = 0.00644602\n",
      "Iteration 4148, loss = 0.00644480\n",
      "Iteration 4149, loss = 0.00644201\n",
      "Iteration 4150, loss = 0.00644017\n",
      "Iteration 4151, loss = 0.00643850\n",
      "Iteration 4152, loss = 0.00643643\n",
      "Iteration 4153, loss = 0.00643449\n",
      "Iteration 4154, loss = 0.00643262\n",
      "Iteration 4155, loss = 0.00643111\n",
      "Iteration 4156, loss = 0.00642901\n",
      "Iteration 4157, loss = 0.00642724\n",
      "Iteration 4158, loss = 0.00642568\n",
      "Iteration 4159, loss = 0.00642396\n",
      "Iteration 4160, loss = 0.00642208\n",
      "Iteration 4161, loss = 0.00642057\n",
      "Iteration 4162, loss = 0.00641852\n",
      "Iteration 4163, loss = 0.00641661\n",
      "Iteration 4164, loss = 0.00641501\n",
      "Iteration 4165, loss = 0.00641264\n",
      "Iteration 4166, loss = 0.00641120\n",
      "Iteration 4167, loss = 0.00640901\n",
      "Iteration 4168, loss = 0.00640737\n",
      "Iteration 4169, loss = 0.00640550\n",
      "Iteration 4170, loss = 0.00640320\n",
      "Iteration 4171, loss = 0.00640156\n",
      "Iteration 4172, loss = 0.00639960\n",
      "Iteration 4173, loss = 0.00639764\n",
      "Iteration 4174, loss = 0.00639641\n",
      "Iteration 4175, loss = 0.00639419\n",
      "Iteration 4176, loss = 0.00639240\n",
      "Iteration 4177, loss = 0.00639076\n",
      "Iteration 4178, loss = 0.00638858\n",
      "Iteration 4179, loss = 0.00638676\n",
      "Iteration 4180, loss = 0.00638501\n",
      "Iteration 4181, loss = 0.00638342\n",
      "Iteration 4182, loss = 0.00638287\n",
      "Iteration 4183, loss = 0.00638053\n",
      "Iteration 4184, loss = 0.00637836\n",
      "Iteration 4185, loss = 0.00637727\n",
      "Iteration 4186, loss = 0.00637481\n",
      "Iteration 4187, loss = 0.00637298\n",
      "Iteration 4188, loss = 0.00637107\n",
      "Iteration 4189, loss = 0.00636952\n",
      "Iteration 4190, loss = 0.00636712\n",
      "Iteration 4191, loss = 0.00636530\n",
      "Iteration 4192, loss = 0.00636354\n",
      "Iteration 4193, loss = 0.00636152\n",
      "Iteration 4194, loss = 0.00635957\n",
      "Iteration 4195, loss = 0.00635772\n",
      "Iteration 4196, loss = 0.00635677\n",
      "Iteration 4197, loss = 0.00635349\n",
      "Iteration 4198, loss = 0.00635120\n",
      "Iteration 4199, loss = 0.00634875\n",
      "Iteration 4200, loss = 0.00634811\n",
      "Iteration 4201, loss = 0.00634411\n",
      "Iteration 4202, loss = 0.00634200\n",
      "Iteration 4203, loss = 0.00634067\n",
      "Iteration 4204, loss = 0.00633901\n",
      "Iteration 4205, loss = 0.00633615\n",
      "Iteration 4206, loss = 0.00633417\n",
      "Iteration 4207, loss = 0.00633235\n",
      "Iteration 4208, loss = 0.00633061\n",
      "Iteration 4209, loss = 0.00632870\n",
      "Iteration 4210, loss = 0.00632707\n",
      "Iteration 4211, loss = 0.00632620\n",
      "Iteration 4212, loss = 0.00632299\n",
      "Iteration 4213, loss = 0.00632270\n",
      "Iteration 4214, loss = 0.00632009\n",
      "Iteration 4215, loss = 0.00631781\n",
      "Iteration 4216, loss = 0.00631569\n",
      "Iteration 4217, loss = 0.00631447\n",
      "Iteration 4218, loss = 0.00631240\n",
      "Iteration 4219, loss = 0.00631022\n",
      "Iteration 4220, loss = 0.00630878\n",
      "Iteration 4221, loss = 0.00630697\n",
      "Iteration 4222, loss = 0.00630499\n",
      "Iteration 4223, loss = 0.00630323\n",
      "Iteration 4224, loss = 0.00630137\n",
      "Iteration 4225, loss = 0.00629975\n",
      "Iteration 4226, loss = 0.00629828\n",
      "Iteration 4227, loss = 0.00629641\n",
      "Iteration 4228, loss = 0.00629438\n",
      "Iteration 4229, loss = 0.00629279\n",
      "Iteration 4230, loss = 0.00629116\n",
      "Iteration 4231, loss = 0.00628953\n",
      "Iteration 4232, loss = 0.00628780\n",
      "Iteration 4233, loss = 0.00628662\n",
      "Iteration 4234, loss = 0.00628459\n",
      "Iteration 4235, loss = 0.00628284\n",
      "Iteration 4236, loss = 0.00628129\n",
      "Iteration 4237, loss = 0.00627921\n",
      "Iteration 4238, loss = 0.00627739\n",
      "Iteration 4239, loss = 0.00627619\n",
      "Iteration 4240, loss = 0.00627387\n",
      "Iteration 4241, loss = 0.00627194\n",
      "Iteration 4242, loss = 0.00627053\n",
      "Iteration 4243, loss = 0.00626831\n",
      "Iteration 4244, loss = 0.00626703\n",
      "Iteration 4245, loss = 0.00626486\n",
      "Iteration 4246, loss = 0.00626287\n",
      "Iteration 4247, loss = 0.00626103\n",
      "Iteration 4248, loss = 0.00625928\n",
      "Iteration 4249, loss = 0.00625776\n",
      "Iteration 4250, loss = 0.00625602\n",
      "Iteration 4251, loss = 0.00625414\n",
      "Iteration 4252, loss = 0.00625221\n",
      "Iteration 4253, loss = 0.00625049\n",
      "Iteration 4254, loss = 0.00624868\n",
      "Iteration 4255, loss = 0.00624681\n",
      "Iteration 4256, loss = 0.00624475\n",
      "Iteration 4257, loss = 0.00624287\n",
      "Iteration 4258, loss = 0.00624095\n",
      "Iteration 4259, loss = 0.00623908\n",
      "Iteration 4260, loss = 0.00623733\n",
      "Iteration 4261, loss = 0.00623564\n",
      "Iteration 4262, loss = 0.00623397\n",
      "Iteration 4263, loss = 0.00623205\n",
      "Iteration 4264, loss = 0.00623061\n",
      "Iteration 4265, loss = 0.00622878\n",
      "Iteration 4266, loss = 0.00622714\n",
      "Iteration 4267, loss = 0.00622544\n",
      "Iteration 4268, loss = 0.00622373\n",
      "Iteration 4269, loss = 0.00622241\n",
      "Iteration 4270, loss = 0.00622016\n",
      "Iteration 4271, loss = 0.00621841\n",
      "Iteration 4272, loss = 0.00621694\n",
      "Iteration 4273, loss = 0.00621504\n",
      "Iteration 4274, loss = 0.00621338\n",
      "Iteration 4275, loss = 0.00621268\n",
      "Iteration 4276, loss = 0.00620989\n",
      "Iteration 4277, loss = 0.00620783\n",
      "Iteration 4278, loss = 0.00620542\n",
      "Iteration 4279, loss = 0.00620355\n",
      "Iteration 4280, loss = 0.00620200\n",
      "Iteration 4281, loss = 0.00619993\n",
      "Iteration 4282, loss = 0.00619807\n",
      "Iteration 4283, loss = 0.00619628\n",
      "Iteration 4284, loss = 0.00619453\n",
      "Iteration 4285, loss = 0.00619290\n",
      "Iteration 4286, loss = 0.00619150\n",
      "Iteration 4287, loss = 0.00618969\n",
      "Iteration 4288, loss = 0.00618762\n",
      "Iteration 4289, loss = 0.00618608\n",
      "Iteration 4290, loss = 0.00618418\n",
      "Iteration 4291, loss = 0.00618275\n",
      "Iteration 4292, loss = 0.00618089\n",
      "Iteration 4293, loss = 0.00617936\n",
      "Iteration 4294, loss = 0.00618000\n",
      "Iteration 4295, loss = 0.00617616\n",
      "Iteration 4296, loss = 0.00617432\n",
      "Iteration 4297, loss = 0.00617250\n",
      "Iteration 4298, loss = 0.00617036\n",
      "Iteration 4299, loss = 0.00616921\n",
      "Iteration 4300, loss = 0.00616701\n",
      "Iteration 4301, loss = 0.00616499\n",
      "Iteration 4302, loss = 0.00616361\n",
      "Iteration 4303, loss = 0.00616192\n",
      "Iteration 4304, loss = 0.00616000\n",
      "Iteration 4305, loss = 0.00615861\n",
      "Iteration 4306, loss = 0.00615695\n",
      "Iteration 4307, loss = 0.00615569\n",
      "Iteration 4308, loss = 0.00615393\n",
      "Iteration 4309, loss = 0.00615235\n",
      "Iteration 4310, loss = 0.00615063\n",
      "Iteration 4311, loss = 0.00614866\n",
      "Iteration 4312, loss = 0.00614711\n",
      "Iteration 4313, loss = 0.00614564\n",
      "Iteration 4314, loss = 0.00614390\n",
      "Iteration 4315, loss = 0.00614242\n",
      "Iteration 4316, loss = 0.00614079\n",
      "Iteration 4317, loss = 0.00613923\n",
      "Iteration 4318, loss = 0.00613763\n",
      "Iteration 4319, loss = 0.00613612\n",
      "Iteration 4320, loss = 0.00613474\n",
      "Iteration 4321, loss = 0.00613305\n",
      "Iteration 4322, loss = 0.00613134\n",
      "Iteration 4323, loss = 0.00613035\n",
      "Iteration 4324, loss = 0.00612833\n",
      "Iteration 4325, loss = 0.00612746\n",
      "Iteration 4326, loss = 0.00612528\n",
      "Iteration 4327, loss = 0.00612328\n",
      "Iteration 4328, loss = 0.00612125\n",
      "Iteration 4329, loss = 0.00611931\n",
      "Iteration 4330, loss = 0.00611731\n",
      "Iteration 4331, loss = 0.00611528\n",
      "Iteration 4332, loss = 0.00611400\n",
      "Iteration 4333, loss = 0.00611129\n",
      "Iteration 4334, loss = 0.00610906\n",
      "Iteration 4335, loss = 0.00610794\n",
      "Iteration 4336, loss = 0.00610593\n",
      "Iteration 4337, loss = 0.00610400\n",
      "Iteration 4338, loss = 0.00610200\n",
      "Iteration 4339, loss = 0.00609998\n",
      "Iteration 4340, loss = 0.00609874\n",
      "Iteration 4341, loss = 0.00609633\n",
      "Iteration 4342, loss = 0.00609488\n",
      "Iteration 4343, loss = 0.00609272\n",
      "Iteration 4344, loss = 0.00609109\n",
      "Iteration 4345, loss = 0.00608976\n",
      "Iteration 4346, loss = 0.00608798\n",
      "Iteration 4347, loss = 0.00608621\n",
      "Iteration 4348, loss = 0.00608449\n",
      "Iteration 4349, loss = 0.00608267\n",
      "Iteration 4350, loss = 0.00608100\n",
      "Iteration 4351, loss = 0.00607937\n",
      "Iteration 4352, loss = 0.00607757\n",
      "Iteration 4353, loss = 0.00607573\n",
      "Iteration 4354, loss = 0.00607427\n",
      "Iteration 4355, loss = 0.00607233\n",
      "Iteration 4356, loss = 0.00607071\n",
      "Iteration 4357, loss = 0.00606899\n",
      "Iteration 4358, loss = 0.00606820\n",
      "Iteration 4359, loss = 0.00606590\n",
      "Iteration 4360, loss = 0.00606454\n",
      "Iteration 4361, loss = 0.00606258\n",
      "Iteration 4362, loss = 0.00606094\n",
      "Iteration 4363, loss = 0.00605950\n",
      "Iteration 4364, loss = 0.00605780\n",
      "Iteration 4365, loss = 0.00605584\n",
      "Iteration 4366, loss = 0.00605416\n",
      "Iteration 4367, loss = 0.00605244\n",
      "Iteration 4368, loss = 0.00605094\n",
      "Iteration 4369, loss = 0.00604924\n",
      "Iteration 4370, loss = 0.00604770\n",
      "Iteration 4371, loss = 0.00604589\n",
      "Iteration 4372, loss = 0.00604455\n",
      "Iteration 4373, loss = 0.00604279\n",
      "Iteration 4374, loss = 0.00604090\n",
      "Iteration 4375, loss = 0.00603935\n",
      "Iteration 4376, loss = 0.00603750\n",
      "Iteration 4377, loss = 0.00603573\n",
      "Iteration 4378, loss = 0.00603411\n",
      "Iteration 4379, loss = 0.00603225\n",
      "Iteration 4380, loss = 0.00603058\n",
      "Iteration 4381, loss = 0.00602893\n",
      "Iteration 4382, loss = 0.00602780\n",
      "Iteration 4383, loss = 0.00602598\n",
      "Iteration 4384, loss = 0.00602462\n",
      "Iteration 4385, loss = 0.00602326\n",
      "Iteration 4386, loss = 0.00602123\n",
      "Iteration 4387, loss = 0.00601966\n",
      "Iteration 4388, loss = 0.00601808\n",
      "Iteration 4389, loss = 0.00601642\n",
      "Iteration 4390, loss = 0.00601434\n",
      "Iteration 4391, loss = 0.00601271\n",
      "Iteration 4392, loss = 0.00601088\n",
      "Iteration 4393, loss = 0.00600874\n",
      "Iteration 4394, loss = 0.00600775\n",
      "Iteration 4395, loss = 0.00600514\n",
      "Iteration 4396, loss = 0.00600346\n",
      "Iteration 4397, loss = 0.00600171\n",
      "Iteration 4398, loss = 0.00600083\n",
      "Iteration 4399, loss = 0.00599860\n",
      "Iteration 4400, loss = 0.00599652\n",
      "Iteration 4401, loss = 0.00599480\n",
      "Iteration 4402, loss = 0.00599338\n",
      "Iteration 4403, loss = 0.00599173\n",
      "Iteration 4404, loss = 0.00598990\n",
      "Iteration 4405, loss = 0.00598909\n",
      "Iteration 4406, loss = 0.00598651\n",
      "Iteration 4407, loss = 0.00598434\n",
      "Iteration 4408, loss = 0.00598292\n",
      "Iteration 4409, loss = 0.00598119\n",
      "Iteration 4410, loss = 0.00597923\n",
      "Iteration 4411, loss = 0.00597779\n",
      "Iteration 4412, loss = 0.00597597\n",
      "Iteration 4413, loss = 0.00597448\n",
      "Iteration 4414, loss = 0.00597291\n",
      "Iteration 4415, loss = 0.00597158\n",
      "Iteration 4416, loss = 0.00596999\n",
      "Iteration 4417, loss = 0.00596839\n",
      "Iteration 4418, loss = 0.00596677\n",
      "Iteration 4419, loss = 0.00596599\n",
      "Iteration 4420, loss = 0.00596381\n",
      "Iteration 4421, loss = 0.00596257\n",
      "Iteration 4422, loss = 0.00596038\n",
      "Iteration 4423, loss = 0.00595801\n",
      "Iteration 4424, loss = 0.00595641\n",
      "Iteration 4425, loss = 0.00595505\n",
      "Iteration 4426, loss = 0.00595300\n",
      "Iteration 4427, loss = 0.00595102\n",
      "Iteration 4428, loss = 0.00594904\n",
      "Iteration 4429, loss = 0.00594743\n",
      "Iteration 4430, loss = 0.00594622\n",
      "Iteration 4431, loss = 0.00594436\n",
      "Iteration 4432, loss = 0.00594239\n",
      "Iteration 4433, loss = 0.00594164\n",
      "Iteration 4434, loss = 0.00593940\n",
      "Iteration 4435, loss = 0.00593784\n",
      "Iteration 4436, loss = 0.00593640\n",
      "Iteration 4437, loss = 0.00593486\n",
      "Iteration 4438, loss = 0.00593344\n",
      "Iteration 4439, loss = 0.00593169\n",
      "Iteration 4440, loss = 0.00593035\n",
      "Iteration 4441, loss = 0.00592869\n",
      "Iteration 4442, loss = 0.00592701\n",
      "Iteration 4443, loss = 0.00592527\n",
      "Iteration 4444, loss = 0.00592372\n",
      "Iteration 4445, loss = 0.00592213\n",
      "Iteration 4446, loss = 0.00592051\n",
      "Iteration 4447, loss = 0.00591876\n",
      "Iteration 4448, loss = 0.00591855\n",
      "Iteration 4449, loss = 0.00591586\n",
      "Iteration 4450, loss = 0.00591423\n",
      "Iteration 4451, loss = 0.00591255\n",
      "Iteration 4452, loss = 0.00591224\n",
      "Iteration 4453, loss = 0.00590955\n",
      "Iteration 4454, loss = 0.00590763\n",
      "Iteration 4455, loss = 0.00590597\n",
      "Iteration 4456, loss = 0.00590422\n",
      "Iteration 4457, loss = 0.00590243\n",
      "Iteration 4458, loss = 0.00590064\n",
      "Iteration 4459, loss = 0.00589959\n",
      "Iteration 4460, loss = 0.00589632\n",
      "Iteration 4461, loss = 0.00589551\n",
      "Iteration 4462, loss = 0.00589252\n",
      "Iteration 4463, loss = 0.00589293\n",
      "Iteration 4464, loss = 0.00588961\n",
      "Iteration 4465, loss = 0.00588773\n",
      "Iteration 4466, loss = 0.00588582\n",
      "Iteration 4467, loss = 0.00588445\n",
      "Iteration 4468, loss = 0.00588269\n",
      "Iteration 4469, loss = 0.00588116\n",
      "Iteration 4470, loss = 0.00587967\n",
      "Iteration 4471, loss = 0.00587791\n",
      "Iteration 4472, loss = 0.00587620\n",
      "Iteration 4473, loss = 0.00587458\n",
      "Iteration 4474, loss = 0.00587309\n",
      "Iteration 4475, loss = 0.00587162\n",
      "Iteration 4476, loss = 0.00587018\n",
      "Iteration 4477, loss = 0.00586860\n",
      "Iteration 4478, loss = 0.00586719\n",
      "Iteration 4479, loss = 0.00586593\n",
      "Iteration 4480, loss = 0.00586439\n",
      "Iteration 4481, loss = 0.00586333\n",
      "Iteration 4482, loss = 0.00586235\n",
      "Iteration 4483, loss = 0.00586066\n",
      "Iteration 4484, loss = 0.00585881\n",
      "Iteration 4485, loss = 0.00585732\n",
      "Iteration 4486, loss = 0.00585526\n",
      "Iteration 4487, loss = 0.00585407\n",
      "Iteration 4488, loss = 0.00585263\n",
      "Iteration 4489, loss = 0.00585081\n",
      "Iteration 4490, loss = 0.00584904\n",
      "Iteration 4491, loss = 0.00584791\n",
      "Iteration 4492, loss = 0.00584664\n",
      "Iteration 4493, loss = 0.00584447\n",
      "Iteration 4494, loss = 0.00584293\n",
      "Iteration 4495, loss = 0.00584141\n",
      "Iteration 4496, loss = 0.00583972\n",
      "Iteration 4497, loss = 0.00583809\n",
      "Iteration 4498, loss = 0.00583681\n",
      "Iteration 4499, loss = 0.00583521\n",
      "Iteration 4500, loss = 0.00583406\n",
      "Iteration 4501, loss = 0.00583178\n",
      "Iteration 4502, loss = 0.00583023\n",
      "Iteration 4503, loss = 0.00582879\n",
      "Iteration 4504, loss = 0.00582683\n",
      "Iteration 4505, loss = 0.00582497\n",
      "Iteration 4506, loss = 0.00582327\n",
      "Iteration 4507, loss = 0.00582188\n",
      "Iteration 4508, loss = 0.00582014\n",
      "Iteration 4509, loss = 0.00581851\n",
      "Iteration 4510, loss = 0.00581662\n",
      "Iteration 4511, loss = 0.00581549\n",
      "Iteration 4512, loss = 0.00581320\n",
      "Iteration 4513, loss = 0.00581126\n",
      "Iteration 4514, loss = 0.00581151\n",
      "Iteration 4515, loss = 0.00580877\n",
      "Iteration 4516, loss = 0.00580715\n",
      "Iteration 4517, loss = 0.00580526\n",
      "Iteration 4518, loss = 0.00580354\n",
      "Iteration 4519, loss = 0.00580212\n",
      "Iteration 4520, loss = 0.00580007\n",
      "Iteration 4521, loss = 0.00579860\n",
      "Iteration 4522, loss = 0.00579710\n",
      "Iteration 4523, loss = 0.00579571\n",
      "Iteration 4524, loss = 0.00579433\n",
      "Iteration 4525, loss = 0.00579259\n",
      "Iteration 4526, loss = 0.00579111\n",
      "Iteration 4527, loss = 0.00578956\n",
      "Iteration 4528, loss = 0.00578828\n",
      "Iteration 4529, loss = 0.00578650\n",
      "Iteration 4530, loss = 0.00578489\n",
      "Iteration 4531, loss = 0.00578355\n",
      "Iteration 4532, loss = 0.00578185\n",
      "Iteration 4533, loss = 0.00578049\n",
      "Iteration 4534, loss = 0.00577900\n",
      "Iteration 4535, loss = 0.00577755\n",
      "Iteration 4536, loss = 0.00577697\n",
      "Iteration 4537, loss = 0.00577518\n",
      "Iteration 4538, loss = 0.00577377\n",
      "Iteration 4539, loss = 0.00577195\n",
      "Iteration 4540, loss = 0.00577042\n",
      "Iteration 4541, loss = 0.00576894\n",
      "Iteration 4542, loss = 0.00576749\n",
      "Iteration 4543, loss = 0.00576601\n",
      "Iteration 4544, loss = 0.00576508\n",
      "Iteration 4545, loss = 0.00576328\n",
      "Iteration 4546, loss = 0.00576201\n",
      "Iteration 4547, loss = 0.00576076\n",
      "Iteration 4548, loss = 0.00575944\n",
      "Iteration 4549, loss = 0.00575782\n",
      "Iteration 4550, loss = 0.00575645\n",
      "Iteration 4551, loss = 0.00575492\n",
      "Iteration 4552, loss = 0.00575352\n",
      "Iteration 4553, loss = 0.00575213\n",
      "Iteration 4554, loss = 0.00575047\n",
      "Iteration 4555, loss = 0.00574887\n",
      "Iteration 4556, loss = 0.00574757\n",
      "Iteration 4557, loss = 0.00574595\n",
      "Iteration 4558, loss = 0.00574456\n",
      "Iteration 4559, loss = 0.00574314\n",
      "Iteration 4560, loss = 0.00574162\n",
      "Iteration 4561, loss = 0.00574036\n",
      "Iteration 4562, loss = 0.00573902\n",
      "Iteration 4563, loss = 0.00573728\n",
      "Iteration 4564, loss = 0.00573627\n",
      "Iteration 4565, loss = 0.00573433\n",
      "Iteration 4566, loss = 0.00573298\n",
      "Iteration 4567, loss = 0.00573148\n",
      "Iteration 4568, loss = 0.00573003\n",
      "Iteration 4569, loss = 0.00572842\n",
      "Iteration 4570, loss = 0.00572770\n",
      "Iteration 4571, loss = 0.00572605\n",
      "Iteration 4572, loss = 0.00572418\n",
      "Iteration 4573, loss = 0.00572255\n",
      "Iteration 4574, loss = 0.00572123\n",
      "Iteration 4575, loss = 0.00571922\n",
      "Iteration 4576, loss = 0.00571686\n",
      "Iteration 4577, loss = 0.00571473\n",
      "Iteration 4578, loss = 0.00571391\n",
      "Iteration 4579, loss = 0.00571184\n",
      "Iteration 4580, loss = 0.00571005\n",
      "Iteration 4581, loss = 0.00570838\n",
      "Iteration 4582, loss = 0.00570687\n",
      "Iteration 4583, loss = 0.00570528\n",
      "Iteration 4584, loss = 0.00570393\n",
      "Iteration 4585, loss = 0.00570265\n",
      "Iteration 4586, loss = 0.00570132\n",
      "Iteration 4587, loss = 0.00570002\n",
      "Iteration 4588, loss = 0.00569862\n",
      "Iteration 4589, loss = 0.00569698\n",
      "Iteration 4590, loss = 0.00569514\n",
      "Iteration 4591, loss = 0.00569367\n",
      "Iteration 4592, loss = 0.00569208\n",
      "Iteration 4593, loss = 0.00569035\n",
      "Iteration 4594, loss = 0.00568885\n",
      "Iteration 4595, loss = 0.00568823\n",
      "Iteration 4596, loss = 0.00568628\n",
      "Iteration 4597, loss = 0.00568394\n",
      "Iteration 4598, loss = 0.00568256\n",
      "Iteration 4599, loss = 0.00568085\n",
      "Iteration 4600, loss = 0.00567916\n",
      "Iteration 4601, loss = 0.00567751\n",
      "Iteration 4602, loss = 0.00567583\n",
      "Iteration 4603, loss = 0.00567447\n",
      "Iteration 4604, loss = 0.00567316\n",
      "Iteration 4605, loss = 0.00567163\n",
      "Iteration 4606, loss = 0.00567019\n",
      "Iteration 4607, loss = 0.00566855\n",
      "Iteration 4608, loss = 0.00566700\n",
      "Iteration 4609, loss = 0.00566556\n",
      "Iteration 4610, loss = 0.00566416\n",
      "Iteration 4611, loss = 0.00566289\n",
      "Iteration 4612, loss = 0.00566128\n",
      "Iteration 4613, loss = 0.00566003\n",
      "Iteration 4614, loss = 0.00565844\n",
      "Iteration 4615, loss = 0.00565690\n",
      "Iteration 4616, loss = 0.00565577\n",
      "Iteration 4617, loss = 0.00565383\n",
      "Iteration 4618, loss = 0.00565251\n",
      "Iteration 4619, loss = 0.00565002\n",
      "Iteration 4620, loss = 0.00564864\n",
      "Iteration 4621, loss = 0.00564630\n",
      "Iteration 4622, loss = 0.00564505\n",
      "Iteration 4623, loss = 0.00564309\n",
      "Iteration 4624, loss = 0.00564099\n",
      "Iteration 4625, loss = 0.00563988\n",
      "Iteration 4626, loss = 0.00563755\n",
      "Iteration 4627, loss = 0.00563571\n",
      "Iteration 4628, loss = 0.00563487\n",
      "Iteration 4629, loss = 0.00563338\n",
      "Iteration 4630, loss = 0.00563242\n",
      "Iteration 4631, loss = 0.00563021\n",
      "Iteration 4632, loss = 0.00562878\n",
      "Iteration 4633, loss = 0.00562731\n",
      "Iteration 4634, loss = 0.00562579\n",
      "Iteration 4635, loss = 0.00562432\n",
      "Iteration 4636, loss = 0.00562376\n",
      "Iteration 4637, loss = 0.00562170\n",
      "Iteration 4638, loss = 0.00562025\n",
      "Iteration 4639, loss = 0.00561873\n",
      "Iteration 4640, loss = 0.00561704\n",
      "Iteration 4641, loss = 0.00561532\n",
      "Iteration 4642, loss = 0.00561396\n",
      "Iteration 4643, loss = 0.00561257\n",
      "Iteration 4644, loss = 0.00561110\n",
      "Iteration 4645, loss = 0.00560921\n",
      "Iteration 4646, loss = 0.00560748\n",
      "Iteration 4647, loss = 0.00560569\n",
      "Iteration 4648, loss = 0.00560449\n",
      "Iteration 4649, loss = 0.00560328\n",
      "Iteration 4650, loss = 0.00560160\n",
      "Iteration 4651, loss = 0.00560010\n",
      "Iteration 4652, loss = 0.00559881\n",
      "Iteration 4653, loss = 0.00559730\n",
      "Iteration 4654, loss = 0.00559631\n",
      "Iteration 4655, loss = 0.00559461\n",
      "Iteration 4656, loss = 0.00559341\n",
      "Iteration 4657, loss = 0.00559167\n",
      "Iteration 4658, loss = 0.00559002\n",
      "Iteration 4659, loss = 0.00558866\n",
      "Iteration 4660, loss = 0.00558700\n",
      "Iteration 4661, loss = 0.00558542\n",
      "Iteration 4662, loss = 0.00558382\n",
      "Iteration 4663, loss = 0.00558246\n",
      "Iteration 4664, loss = 0.00558107\n",
      "Iteration 4665, loss = 0.00557939\n",
      "Iteration 4666, loss = 0.00557881\n",
      "Iteration 4667, loss = 0.00557677\n",
      "Iteration 4668, loss = 0.00557534\n",
      "Iteration 4669, loss = 0.00557374\n",
      "Iteration 4670, loss = 0.00557248\n",
      "Iteration 4671, loss = 0.00557076\n",
      "Iteration 4672, loss = 0.00556900\n",
      "Iteration 4673, loss = 0.00556756\n",
      "Iteration 4674, loss = 0.00556675\n",
      "Iteration 4675, loss = 0.00556470\n",
      "Iteration 4676, loss = 0.00556318\n",
      "Iteration 4677, loss = 0.00556189\n",
      "Iteration 4678, loss = 0.00556006\n",
      "Iteration 4679, loss = 0.00555854\n",
      "Iteration 4680, loss = 0.00555681\n",
      "Iteration 4681, loss = 0.00555571\n",
      "Iteration 4682, loss = 0.00555360\n",
      "Iteration 4683, loss = 0.00555230\n",
      "Iteration 4684, loss = 0.00555055\n",
      "Iteration 4685, loss = 0.00554882\n",
      "Iteration 4686, loss = 0.00554766\n",
      "Iteration 4687, loss = 0.00554608\n",
      "Iteration 4688, loss = 0.00554471\n",
      "Iteration 4689, loss = 0.00554321\n",
      "Iteration 4690, loss = 0.00554162\n",
      "Iteration 4691, loss = 0.00554023\n",
      "Iteration 4692, loss = 0.00553875\n",
      "Iteration 4693, loss = 0.00553741\n",
      "Iteration 4694, loss = 0.00553508\n",
      "Iteration 4695, loss = 0.00553346\n",
      "Iteration 4696, loss = 0.00553163\n",
      "Iteration 4697, loss = 0.00553076\n",
      "Iteration 4698, loss = 0.00552878\n",
      "Iteration 4699, loss = 0.00552737\n",
      "Iteration 4700, loss = 0.00552533\n",
      "Iteration 4701, loss = 0.00552384\n",
      "Iteration 4702, loss = 0.00552218\n",
      "Iteration 4703, loss = 0.00552067\n",
      "Iteration 4704, loss = 0.00551907\n",
      "Iteration 4705, loss = 0.00551809\n",
      "Iteration 4706, loss = 0.00551609\n",
      "Iteration 4707, loss = 0.00551453\n",
      "Iteration 4708, loss = 0.00551312\n",
      "Iteration 4709, loss = 0.00551162\n",
      "Iteration 4710, loss = 0.00550987\n",
      "Iteration 4711, loss = 0.00550875\n",
      "Iteration 4712, loss = 0.00550694\n",
      "Iteration 4713, loss = 0.00550549\n",
      "Iteration 4714, loss = 0.00550422\n",
      "Iteration 4715, loss = 0.00550261\n",
      "Iteration 4716, loss = 0.00550115\n",
      "Iteration 4717, loss = 0.00549978\n",
      "Iteration 4718, loss = 0.00549845\n",
      "Iteration 4719, loss = 0.00549710\n",
      "Iteration 4720, loss = 0.00549579\n",
      "Iteration 4721, loss = 0.00549452\n",
      "Iteration 4722, loss = 0.00549327\n",
      "Iteration 4723, loss = 0.00549245\n",
      "Iteration 4724, loss = 0.00549124\n",
      "Iteration 4725, loss = 0.00548935\n",
      "Iteration 4726, loss = 0.00548792\n",
      "Iteration 4727, loss = 0.00548643\n",
      "Iteration 4728, loss = 0.00548501\n",
      "Iteration 4729, loss = 0.00548464\n",
      "Iteration 4730, loss = 0.00548245\n",
      "Iteration 4731, loss = 0.00548123\n",
      "Iteration 4732, loss = 0.00547952\n",
      "Iteration 4733, loss = 0.00547821\n",
      "Iteration 4734, loss = 0.00547658\n",
      "Iteration 4735, loss = 0.00547536\n",
      "Iteration 4736, loss = 0.00547398\n",
      "Iteration 4737, loss = 0.00547268\n",
      "Iteration 4738, loss = 0.00547135\n",
      "Iteration 4739, loss = 0.00546977\n",
      "Iteration 4740, loss = 0.00546871\n",
      "Iteration 4741, loss = 0.00546725\n",
      "Iteration 4742, loss = 0.00546579\n",
      "Iteration 4743, loss = 0.00546369\n",
      "Iteration 4744, loss = 0.00546224\n",
      "Iteration 4745, loss = 0.00546033\n",
      "Iteration 4746, loss = 0.00545954\n",
      "Iteration 4747, loss = 0.00545749\n",
      "Iteration 4748, loss = 0.00545635\n",
      "Iteration 4749, loss = 0.00545436\n",
      "Iteration 4750, loss = 0.00545289\n",
      "Iteration 4751, loss = 0.00545139\n",
      "Iteration 4752, loss = 0.00545011\n",
      "Iteration 4753, loss = 0.00544846\n",
      "Iteration 4754, loss = 0.00544696\n",
      "Iteration 4755, loss = 0.00544544\n",
      "Iteration 4756, loss = 0.00544422\n",
      "Iteration 4757, loss = 0.00544474\n",
      "Iteration 4758, loss = 0.00544172\n",
      "Iteration 4759, loss = 0.00544022\n",
      "Iteration 4760, loss = 0.00543913\n",
      "Iteration 4761, loss = 0.00543727\n",
      "Iteration 4762, loss = 0.00543592\n",
      "Iteration 4763, loss = 0.00543459\n",
      "Iteration 4764, loss = 0.00543280\n",
      "Iteration 4765, loss = 0.00543165\n",
      "Iteration 4766, loss = 0.00543008\n",
      "Iteration 4767, loss = 0.00542855\n",
      "Iteration 4768, loss = 0.00542716\n",
      "Iteration 4769, loss = 0.00542597\n",
      "Iteration 4770, loss = 0.00542482\n",
      "Iteration 4771, loss = 0.00542325\n",
      "Iteration 4772, loss = 0.00542205\n",
      "Iteration 4773, loss = 0.00542043\n",
      "Iteration 4774, loss = 0.00541891\n",
      "Iteration 4775, loss = 0.00541768\n",
      "Iteration 4776, loss = 0.00541591\n",
      "Iteration 4777, loss = 0.00541425\n",
      "Iteration 4778, loss = 0.00541281\n",
      "Iteration 4779, loss = 0.00541143\n",
      "Iteration 4780, loss = 0.00540960\n",
      "Iteration 4781, loss = 0.00540832\n",
      "Iteration 4782, loss = 0.00540657\n",
      "Iteration 4783, loss = 0.00540474\n",
      "Iteration 4784, loss = 0.00540367\n",
      "Iteration 4785, loss = 0.00540164\n",
      "Iteration 4786, loss = 0.00540052\n",
      "Iteration 4787, loss = 0.00539878\n",
      "Iteration 4788, loss = 0.00539761\n",
      "Iteration 4789, loss = 0.00539550\n",
      "Iteration 4790, loss = 0.00539459\n",
      "Iteration 4791, loss = 0.00539289\n",
      "Iteration 4792, loss = 0.00539161\n",
      "Iteration 4793, loss = 0.00538970\n",
      "Iteration 4794, loss = 0.00538853\n",
      "Iteration 4795, loss = 0.00538675\n",
      "Iteration 4796, loss = 0.00538524\n",
      "Iteration 4797, loss = 0.00538360\n",
      "Iteration 4798, loss = 0.00538200\n",
      "Iteration 4799, loss = 0.00538103\n",
      "Iteration 4800, loss = 0.00537916\n",
      "Iteration 4801, loss = 0.00537750\n",
      "Iteration 4802, loss = 0.00537605\n",
      "Iteration 4803, loss = 0.00537500\n",
      "Iteration 4804, loss = 0.00537304\n",
      "Iteration 4805, loss = 0.00537167\n",
      "Iteration 4806, loss = 0.00536996\n",
      "Iteration 4807, loss = 0.00536891\n",
      "Iteration 4808, loss = 0.00536732\n",
      "Iteration 4809, loss = 0.00536570\n",
      "Iteration 4810, loss = 0.00536450\n",
      "Iteration 4811, loss = 0.00536295\n",
      "Iteration 4812, loss = 0.00536193\n",
      "Iteration 4813, loss = 0.00536031\n",
      "Iteration 4814, loss = 0.00535866\n",
      "Iteration 4815, loss = 0.00535712\n",
      "Iteration 4816, loss = 0.00535602\n",
      "Iteration 4817, loss = 0.00535471\n",
      "Iteration 4818, loss = 0.00535343\n",
      "Iteration 4819, loss = 0.00535163\n",
      "Iteration 4820, loss = 0.00534999\n",
      "Iteration 4821, loss = 0.00534848\n",
      "Iteration 4822, loss = 0.00534665\n",
      "Iteration 4823, loss = 0.00534511\n",
      "Iteration 4824, loss = 0.00534388\n",
      "Iteration 4825, loss = 0.00534238\n",
      "Iteration 4826, loss = 0.00534086\n",
      "Iteration 4827, loss = 0.00533942\n",
      "Iteration 4828, loss = 0.00533797\n",
      "Iteration 4829, loss = 0.00533668\n",
      "Iteration 4830, loss = 0.00533511\n",
      "Iteration 4831, loss = 0.00533364\n",
      "Iteration 4832, loss = 0.00533210\n",
      "Iteration 4833, loss = 0.00533053\n",
      "Iteration 4834, loss = 0.00532937\n",
      "Iteration 4835, loss = 0.00532816\n",
      "Iteration 4836, loss = 0.00532652\n",
      "Iteration 4837, loss = 0.00532524\n",
      "Iteration 4838, loss = 0.00532380\n",
      "Iteration 4839, loss = 0.00532258\n",
      "Iteration 4840, loss = 0.00532114\n",
      "Iteration 4841, loss = 0.00531950\n",
      "Iteration 4842, loss = 0.00531848\n",
      "Iteration 4843, loss = 0.00531695\n",
      "Iteration 4844, loss = 0.00531552\n",
      "Iteration 4845, loss = 0.00531418\n",
      "Iteration 4846, loss = 0.00531265\n",
      "Iteration 4847, loss = 0.00531125\n",
      "Iteration 4848, loss = 0.00530989\n",
      "Iteration 4849, loss = 0.00530903\n",
      "Iteration 4850, loss = 0.00530748\n",
      "Iteration 4851, loss = 0.00530610\n",
      "Iteration 4852, loss = 0.00530480\n",
      "Iteration 4853, loss = 0.00530347\n",
      "Iteration 4854, loss = 0.00530217\n",
      "Iteration 4855, loss = 0.00530107\n",
      "Iteration 4856, loss = 0.00529969\n",
      "Iteration 4857, loss = 0.00529833\n",
      "Iteration 4858, loss = 0.00529695\n",
      "Iteration 4859, loss = 0.00529572\n",
      "Iteration 4860, loss = 0.00529463\n",
      "Iteration 4861, loss = 0.00529281\n",
      "Iteration 4862, loss = 0.00529126\n",
      "Iteration 4863, loss = 0.00528977\n",
      "Iteration 4864, loss = 0.00528886\n",
      "Iteration 4865, loss = 0.00528698\n",
      "Iteration 4866, loss = 0.00528568\n",
      "Iteration 4867, loss = 0.00528427\n",
      "Iteration 4868, loss = 0.00528271\n",
      "Iteration 4869, loss = 0.00528137\n",
      "Iteration 4870, loss = 0.00527947\n",
      "Iteration 4871, loss = 0.00527802\n",
      "Iteration 4872, loss = 0.00527657\n",
      "Iteration 4873, loss = 0.00527517\n",
      "Iteration 4874, loss = 0.00527396\n",
      "Iteration 4875, loss = 0.00527254\n",
      "Iteration 4876, loss = 0.00527106\n",
      "Iteration 4877, loss = 0.00527038\n",
      "Iteration 4878, loss = 0.00526843\n",
      "Iteration 4879, loss = 0.00526708\n",
      "Iteration 4880, loss = 0.00526582\n",
      "Iteration 4881, loss = 0.00526445\n",
      "Iteration 4882, loss = 0.00526388\n",
      "Iteration 4883, loss = 0.00526181\n",
      "Iteration 4884, loss = 0.00526020\n",
      "Iteration 4885, loss = 0.00525946\n",
      "Iteration 4886, loss = 0.00525749\n",
      "Iteration 4887, loss = 0.00525615\n",
      "Iteration 4888, loss = 0.00525498\n",
      "Iteration 4889, loss = 0.00525344\n",
      "Iteration 4890, loss = 0.00525198\n",
      "Iteration 4891, loss = 0.00525072\n",
      "Iteration 4892, loss = 0.00524929\n",
      "Iteration 4893, loss = 0.00524933\n",
      "Iteration 4894, loss = 0.00524742\n",
      "Iteration 4895, loss = 0.00524588\n",
      "Iteration 4896, loss = 0.00524448\n",
      "Iteration 4897, loss = 0.00524362\n",
      "Iteration 4898, loss = 0.00524198\n",
      "Iteration 4899, loss = 0.00524063\n",
      "Iteration 4900, loss = 0.00523916\n",
      "Iteration 4901, loss = 0.00523776\n",
      "Iteration 4902, loss = 0.00523661\n",
      "Iteration 4903, loss = 0.00523498\n",
      "Iteration 4904, loss = 0.00523352\n",
      "Iteration 4905, loss = 0.00523192\n",
      "Iteration 4906, loss = 0.00523075\n",
      "Iteration 4907, loss = 0.00522932\n",
      "Iteration 4908, loss = 0.00522805\n",
      "Iteration 4909, loss = 0.00522662\n",
      "Iteration 4910, loss = 0.00522533\n",
      "Iteration 4911, loss = 0.00522394\n",
      "Iteration 4912, loss = 0.00522266\n",
      "Iteration 4913, loss = 0.00522179\n",
      "Iteration 4914, loss = 0.00522028\n",
      "Iteration 4915, loss = 0.00521894\n",
      "Iteration 4916, loss = 0.00521776\n",
      "Iteration 4917, loss = 0.00521671\n",
      "Iteration 4918, loss = 0.00521540\n",
      "Iteration 4919, loss = 0.00521397\n",
      "Iteration 4920, loss = 0.00521275\n",
      "Iteration 4921, loss = 0.00521153\n",
      "Iteration 4922, loss = 0.00521014\n",
      "Iteration 4923, loss = 0.00520887\n",
      "Iteration 4924, loss = 0.00520766\n",
      "Iteration 4925, loss = 0.00520677\n",
      "Iteration 4926, loss = 0.00520568\n",
      "Iteration 4927, loss = 0.00520423\n",
      "Iteration 4928, loss = 0.00520254\n",
      "Iteration 4929, loss = 0.00520133\n",
      "Iteration 4930, loss = 0.00520024\n",
      "Iteration 4931, loss = 0.00519917\n",
      "Iteration 4932, loss = 0.00519858\n",
      "Iteration 4933, loss = 0.00519681\n",
      "Iteration 4934, loss = 0.00519560\n",
      "Iteration 4935, loss = 0.00519451\n",
      "Iteration 4936, loss = 0.00519333\n",
      "Iteration 4937, loss = 0.00519224\n",
      "Iteration 4938, loss = 0.00519121\n",
      "Iteration 4939, loss = 0.00519022\n",
      "Iteration 4940, loss = 0.00518934\n",
      "Iteration 4941, loss = 0.00518851\n",
      "Iteration 4942, loss = 0.00518717\n",
      "Iteration 4943, loss = 0.00518541\n",
      "Iteration 4944, loss = 0.00518472\n",
      "Iteration 4945, loss = 0.00518270\n",
      "Iteration 4946, loss = 0.00518108\n",
      "Iteration 4947, loss = 0.00517966\n",
      "Iteration 4948, loss = 0.00517813\n",
      "Iteration 4949, loss = 0.00517667\n",
      "Iteration 4950, loss = 0.00517577\n",
      "Iteration 4951, loss = 0.00517390\n",
      "Iteration 4952, loss = 0.00517268\n",
      "Iteration 4953, loss = 0.00517145\n",
      "Iteration 4954, loss = 0.00517020\n",
      "Iteration 4955, loss = 0.00516950\n",
      "Iteration 4956, loss = 0.00516786\n",
      "Iteration 4957, loss = 0.00516668\n",
      "Iteration 4958, loss = 0.00516567\n",
      "Iteration 4959, loss = 0.00516399\n",
      "Iteration 4960, loss = 0.00516295\n",
      "Iteration 4961, loss = 0.00516140\n",
      "Iteration 4962, loss = 0.00516020\n",
      "Iteration 4963, loss = 0.00515909\n",
      "Iteration 4964, loss = 0.00515806\n",
      "Iteration 4965, loss = 0.00515661\n",
      "Iteration 4966, loss = 0.00515545\n",
      "Iteration 4967, loss = 0.00515451\n",
      "Iteration 4968, loss = 0.00515360\n",
      "Iteration 4969, loss = 0.00515212\n",
      "Iteration 4970, loss = 0.00515145\n",
      "Iteration 4971, loss = 0.00514980\n",
      "Iteration 4972, loss = 0.00514814\n",
      "Iteration 4973, loss = 0.00514687\n",
      "Iteration 4974, loss = 0.00514577\n",
      "Iteration 4975, loss = 0.00514401\n",
      "Iteration 4976, loss = 0.00514271\n",
      "Iteration 4977, loss = 0.00514147\n",
      "Iteration 4978, loss = 0.00514085\n",
      "Iteration 4979, loss = 0.00513848\n",
      "Iteration 4980, loss = 0.00513769\n",
      "Iteration 4981, loss = 0.00513561\n",
      "Iteration 4982, loss = 0.00513467\n",
      "Iteration 4983, loss = 0.00513253\n",
      "Iteration 4984, loss = 0.00513244\n",
      "Iteration 4985, loss = 0.00513009\n",
      "Iteration 4986, loss = 0.00512873\n",
      "Iteration 4987, loss = 0.00512712\n",
      "Iteration 4988, loss = 0.00512557\n",
      "Iteration 4989, loss = 0.00512404\n",
      "Iteration 4990, loss = 0.00512299\n",
      "Iteration 4991, loss = 0.00512137\n",
      "Iteration 4992, loss = 0.00511985\n",
      "Iteration 4993, loss = 0.00511864\n",
      "Iteration 4994, loss = 0.00511722\n",
      "Iteration 4995, loss = 0.00511582\n",
      "Iteration 4996, loss = 0.00511464\n",
      "Iteration 4997, loss = 0.00511358\n",
      "Iteration 4998, loss = 0.00511165\n",
      "Iteration 4999, loss = 0.00511042\n",
      "Iteration 5000, loss = 0.00510954\n",
      "Iteration 5001, loss = 0.00510815\n",
      "Iteration 5002, loss = 0.00510735\n",
      "Iteration 5003, loss = 0.00510575\n",
      "Iteration 5004, loss = 0.00510441\n",
      "Iteration 5005, loss = 0.00510329\n",
      "Iteration 5006, loss = 0.00510188\n",
      "Iteration 5007, loss = 0.00510058\n",
      "Iteration 5008, loss = 0.00509965\n",
      "Iteration 5009, loss = 0.00509815\n",
      "Iteration 5010, loss = 0.00509679\n",
      "Iteration 5011, loss = 0.00509540\n",
      "Iteration 5012, loss = 0.00509398\n",
      "Iteration 5013, loss = 0.00509266\n",
      "Iteration 5014, loss = 0.00509165\n",
      "Iteration 5015, loss = 0.00508988\n",
      "Iteration 5016, loss = 0.00508850\n",
      "Iteration 5017, loss = 0.00508717\n",
      "Iteration 5018, loss = 0.00508564\n",
      "Iteration 5019, loss = 0.00508479\n",
      "Iteration 5020, loss = 0.00508315\n",
      "Iteration 5021, loss = 0.00508210\n",
      "Iteration 5022, loss = 0.00508064\n",
      "Iteration 5023, loss = 0.00507908\n",
      "Iteration 5024, loss = 0.00507790\n",
      "Iteration 5025, loss = 0.00507636\n",
      "Iteration 5026, loss = 0.00507489\n",
      "Iteration 5027, loss = 0.00507368\n",
      "Iteration 5028, loss = 0.00507218\n",
      "Iteration 5029, loss = 0.00507119\n",
      "Iteration 5030, loss = 0.00506958\n",
      "Iteration 5031, loss = 0.00506855\n",
      "Iteration 5032, loss = 0.00506701\n",
      "Iteration 5033, loss = 0.00506610\n",
      "Iteration 5034, loss = 0.00506444\n",
      "Iteration 5035, loss = 0.00506348\n",
      "Iteration 5036, loss = 0.00506198\n",
      "Iteration 5037, loss = 0.00506073\n",
      "Iteration 5038, loss = 0.00505956\n",
      "Iteration 5039, loss = 0.00505841\n",
      "Iteration 5040, loss = 0.00505748\n",
      "Iteration 5041, loss = 0.00505606\n",
      "Iteration 5042, loss = 0.00505478\n",
      "Iteration 5043, loss = 0.00505375\n",
      "Iteration 5044, loss = 0.00505239\n",
      "Iteration 5045, loss = 0.00505097\n",
      "Iteration 5046, loss = 0.00504968\n",
      "Iteration 5047, loss = 0.00504896\n",
      "Iteration 5048, loss = 0.00504719\n",
      "Iteration 5049, loss = 0.00504583\n",
      "Iteration 5050, loss = 0.00504487\n",
      "Iteration 5051, loss = 0.00504342\n",
      "Iteration 5052, loss = 0.00504247\n",
      "Iteration 5053, loss = 0.00504105\n",
      "Iteration 5054, loss = 0.00503993\n",
      "Iteration 5055, loss = 0.00503885\n",
      "Iteration 5056, loss = 0.00503818\n",
      "Iteration 5057, loss = 0.00503666\n",
      "Iteration 5058, loss = 0.00503530\n",
      "Iteration 5059, loss = 0.00503426\n",
      "Iteration 5060, loss = 0.00503276\n",
      "Iteration 5061, loss = 0.00503151\n",
      "Iteration 5062, loss = 0.00503042\n",
      "Iteration 5063, loss = 0.00502903\n",
      "Iteration 5064, loss = 0.00502764\n",
      "Iteration 5065, loss = 0.00502592\n",
      "Iteration 5066, loss = 0.00502423\n",
      "Iteration 5067, loss = 0.00502321\n",
      "Iteration 5068, loss = 0.00502130\n",
      "Iteration 5069, loss = 0.00502018\n",
      "Iteration 5070, loss = 0.00501842\n",
      "Iteration 5071, loss = 0.00501738\n",
      "Iteration 5072, loss = 0.00501609\n",
      "Iteration 5073, loss = 0.00501508\n",
      "Iteration 5074, loss = 0.00501343\n",
      "Iteration 5075, loss = 0.00501205\n",
      "Iteration 5076, loss = 0.00501090\n",
      "Iteration 5077, loss = 0.00500959\n",
      "Iteration 5078, loss = 0.00500849\n",
      "Iteration 5079, loss = 0.00500709\n",
      "Iteration 5080, loss = 0.00500593\n",
      "Iteration 5081, loss = 0.00500483\n",
      "Iteration 5082, loss = 0.00500368\n",
      "Iteration 5083, loss = 0.00500261\n",
      "Iteration 5084, loss = 0.00500136\n",
      "Iteration 5085, loss = 0.00500117\n",
      "Iteration 5086, loss = 0.00499827\n",
      "Iteration 5087, loss = 0.00499725\n",
      "Iteration 5088, loss = 0.00499608\n",
      "Iteration 5089, loss = 0.00499456\n",
      "Iteration 5090, loss = 0.00499324\n",
      "Iteration 5091, loss = 0.00499215\n",
      "Iteration 5092, loss = 0.00499095\n",
      "Iteration 5093, loss = 0.00498977\n",
      "Iteration 5094, loss = 0.00498866\n",
      "Iteration 5095, loss = 0.00498749\n",
      "Iteration 5096, loss = 0.00498632\n",
      "Iteration 5097, loss = 0.00498476\n",
      "Iteration 5098, loss = 0.00498364\n",
      "Iteration 5099, loss = 0.00498228\n",
      "Iteration 5100, loss = 0.00498104\n",
      "Iteration 5101, loss = 0.00498097\n",
      "Iteration 5102, loss = 0.00497881\n",
      "Iteration 5103, loss = 0.00497734\n",
      "Iteration 5104, loss = 0.00497634\n",
      "Iteration 5105, loss = 0.00497504\n",
      "Iteration 5106, loss = 0.00497387\n",
      "Iteration 5107, loss = 0.00497298\n",
      "Iteration 5108, loss = 0.00497146\n",
      "Iteration 5109, loss = 0.00497048\n",
      "Iteration 5110, loss = 0.00496912\n",
      "Iteration 5111, loss = 0.00496762\n",
      "Iteration 5112, loss = 0.00496610\n",
      "Iteration 5113, loss = 0.00496492\n",
      "Iteration 5114, loss = 0.00496358\n",
      "Iteration 5115, loss = 0.00496208\n",
      "Iteration 5116, loss = 0.00496045\n",
      "Iteration 5117, loss = 0.00495975\n",
      "Iteration 5118, loss = 0.00495829\n",
      "Iteration 5119, loss = 0.00495675\n",
      "Iteration 5120, loss = 0.00495542\n",
      "Iteration 5121, loss = 0.00495400\n",
      "Iteration 5122, loss = 0.00495320\n",
      "Iteration 5123, loss = 0.00495175\n",
      "Iteration 5124, loss = 0.00495079\n",
      "Iteration 5125, loss = 0.00494939\n",
      "Iteration 5126, loss = 0.00494768\n",
      "Iteration 5127, loss = 0.00494690\n",
      "Iteration 5128, loss = 0.00494565\n",
      "Iteration 5129, loss = 0.00494449\n",
      "Iteration 5130, loss = 0.00494321\n",
      "Iteration 5131, loss = 0.00494203\n",
      "Iteration 5132, loss = 0.00494137\n",
      "Iteration 5133, loss = 0.00493995\n",
      "Iteration 5134, loss = 0.00493851\n",
      "Iteration 5135, loss = 0.00493711\n",
      "Iteration 5136, loss = 0.00493574\n",
      "Iteration 5137, loss = 0.00493471\n",
      "Iteration 5138, loss = 0.00493332\n",
      "Iteration 5139, loss = 0.00493198\n",
      "Iteration 5140, loss = 0.00493056\n",
      "Iteration 5141, loss = 0.00492942\n",
      "Iteration 5142, loss = 0.00492818\n",
      "Iteration 5143, loss = 0.00492691\n",
      "Iteration 5144, loss = 0.00492558\n",
      "Iteration 5145, loss = 0.00492432\n",
      "Iteration 5146, loss = 0.00492291\n",
      "Iteration 5147, loss = 0.00492196\n",
      "Iteration 5148, loss = 0.00492059\n",
      "Iteration 5149, loss = 0.00491962\n",
      "Iteration 5150, loss = 0.00491838\n",
      "Iteration 5151, loss = 0.00491730\n",
      "Iteration 5152, loss = 0.00491719\n",
      "Iteration 5153, loss = 0.00491517\n",
      "Iteration 5154, loss = 0.00491397\n",
      "Iteration 5155, loss = 0.00491265\n",
      "Iteration 5156, loss = 0.00491144\n",
      "Iteration 5157, loss = 0.00491038\n",
      "Iteration 5158, loss = 0.00490916\n",
      "Iteration 5159, loss = 0.00490946\n",
      "Iteration 5160, loss = 0.00490699\n",
      "Iteration 5161, loss = 0.00490547\n",
      "Iteration 5162, loss = 0.00490433\n",
      "Iteration 5163, loss = 0.00490313\n",
      "Iteration 5164, loss = 0.00490173\n",
      "Iteration 5165, loss = 0.00490048\n",
      "Iteration 5166, loss = 0.00489934\n",
      "Iteration 5167, loss = 0.00489816\n",
      "Iteration 5168, loss = 0.00489718\n",
      "Iteration 5169, loss = 0.00489588\n",
      "Iteration 5170, loss = 0.00489491\n",
      "Iteration 5171, loss = 0.00489350\n",
      "Iteration 5172, loss = 0.00489252\n",
      "Iteration 5173, loss = 0.00489160\n",
      "Iteration 5174, loss = 0.00489042\n",
      "Iteration 5175, loss = 0.00488910\n",
      "Iteration 5176, loss = 0.00488789\n",
      "Iteration 5177, loss = 0.00488738\n",
      "Iteration 5178, loss = 0.00488570\n",
      "Iteration 5179, loss = 0.00488460\n",
      "Iteration 5180, loss = 0.00488291\n",
      "Iteration 5181, loss = 0.00488159\n",
      "Iteration 5182, loss = 0.00488025\n",
      "Iteration 5183, loss = 0.00487912\n",
      "Iteration 5184, loss = 0.00487799\n",
      "Iteration 5185, loss = 0.00487660\n",
      "Iteration 5186, loss = 0.00487556\n",
      "Iteration 5187, loss = 0.00487415\n",
      "Iteration 5188, loss = 0.00487299\n",
      "Iteration 5189, loss = 0.00487221\n",
      "Iteration 5190, loss = 0.00487079\n",
      "Iteration 5191, loss = 0.00486936\n",
      "Iteration 5192, loss = 0.00486848\n",
      "Iteration 5193, loss = 0.00486703\n",
      "Iteration 5194, loss = 0.00486565\n",
      "Iteration 5195, loss = 0.00486449\n",
      "Iteration 5196, loss = 0.00486341\n",
      "Iteration 5197, loss = 0.00486245\n",
      "Iteration 5198, loss = 0.00486084\n",
      "Iteration 5199, loss = 0.00486003\n",
      "Iteration 5200, loss = 0.00485818\n",
      "Iteration 5201, loss = 0.00485689\n",
      "Iteration 5202, loss = 0.00485635\n",
      "Iteration 5203, loss = 0.00485462\n",
      "Iteration 5204, loss = 0.00485405\n",
      "Iteration 5205, loss = 0.00485232\n",
      "Iteration 5206, loss = 0.00485145\n",
      "Iteration 5207, loss = 0.00484991\n",
      "Iteration 5208, loss = 0.00484867\n",
      "Iteration 5209, loss = 0.00484741\n",
      "Iteration 5210, loss = 0.00484619\n",
      "Iteration 5211, loss = 0.00484513\n",
      "Iteration 5212, loss = 0.00484400\n",
      "Iteration 5213, loss = 0.00484286\n",
      "Iteration 5214, loss = 0.00484189\n",
      "Iteration 5215, loss = 0.00484098\n",
      "Iteration 5216, loss = 0.00484013\n",
      "Iteration 5217, loss = 0.00483867\n",
      "Iteration 5218, loss = 0.00483759\n",
      "Iteration 5219, loss = 0.00483660\n",
      "Iteration 5220, loss = 0.00483549\n",
      "Iteration 5221, loss = 0.00483447\n",
      "Iteration 5222, loss = 0.00483375\n",
      "Iteration 5223, loss = 0.00483222\n",
      "Iteration 5224, loss = 0.00483124\n",
      "Iteration 5225, loss = 0.00482992\n",
      "Iteration 5226, loss = 0.00482889\n",
      "Iteration 5227, loss = 0.00482809\n",
      "Iteration 5228, loss = 0.00482641\n",
      "Iteration 5229, loss = 0.00482546\n",
      "Iteration 5230, loss = 0.00482412\n",
      "Iteration 5231, loss = 0.00482324\n",
      "Iteration 5232, loss = 0.00482196\n",
      "Iteration 5233, loss = 0.00482077\n",
      "Iteration 5234, loss = 0.00481954\n",
      "Iteration 5235, loss = 0.00481830\n",
      "Iteration 5236, loss = 0.00481686\n",
      "Iteration 5237, loss = 0.00481528\n",
      "Iteration 5238, loss = 0.00481386\n",
      "Iteration 5239, loss = 0.00481244\n",
      "Iteration 5240, loss = 0.00481081\n",
      "Iteration 5241, loss = 0.00481015\n",
      "Iteration 5242, loss = 0.00480897\n",
      "Iteration 5243, loss = 0.00480764\n",
      "Iteration 5244, loss = 0.00480608\n",
      "Iteration 5245, loss = 0.00480509\n",
      "Iteration 5246, loss = 0.00480366\n",
      "Iteration 5247, loss = 0.00480281\n",
      "Iteration 5248, loss = 0.00480203\n",
      "Iteration 5249, loss = 0.00480031\n",
      "Iteration 5250, loss = 0.00479940\n",
      "Iteration 5251, loss = 0.00479797\n",
      "Iteration 5252, loss = 0.00479715\n",
      "Iteration 5253, loss = 0.00479578\n",
      "Iteration 5254, loss = 0.00479461\n",
      "Iteration 5255, loss = 0.00479329\n",
      "Iteration 5256, loss = 0.00479202\n",
      "Iteration 5257, loss = 0.00479091\n",
      "Iteration 5258, loss = 0.00478970\n",
      "Iteration 5259, loss = 0.00478826\n",
      "Iteration 5260, loss = 0.00478722\n",
      "Iteration 5261, loss = 0.00478605\n",
      "Iteration 5262, loss = 0.00478486\n",
      "Iteration 5263, loss = 0.00478340\n",
      "Iteration 5264, loss = 0.00478223\n",
      "Iteration 5265, loss = 0.00478106\n",
      "Iteration 5266, loss = 0.00477983\n",
      "Iteration 5267, loss = 0.00477885\n",
      "Iteration 5268, loss = 0.00477740\n",
      "Iteration 5269, loss = 0.00477601\n",
      "Iteration 5270, loss = 0.00477491\n",
      "Iteration 5271, loss = 0.00477459\n",
      "Iteration 5272, loss = 0.00477272\n",
      "Iteration 5273, loss = 0.00477152\n",
      "Iteration 5274, loss = 0.00477029\n",
      "Iteration 5275, loss = 0.00476939\n",
      "Iteration 5276, loss = 0.00476826\n",
      "Iteration 5277, loss = 0.00476764\n",
      "Iteration 5278, loss = 0.00476664\n",
      "Iteration 5279, loss = 0.00476457\n",
      "Iteration 5280, loss = 0.00476359\n",
      "Iteration 5281, loss = 0.00476243\n",
      "Iteration 5282, loss = 0.00476116\n",
      "Iteration 5283, loss = 0.00475999\n",
      "Iteration 5284, loss = 0.00475897\n",
      "Iteration 5285, loss = 0.00475773\n",
      "Iteration 5286, loss = 0.00475641\n",
      "Iteration 5287, loss = 0.00475554\n",
      "Iteration 5288, loss = 0.00475439\n",
      "Iteration 5289, loss = 0.00475323\n",
      "Iteration 5290, loss = 0.00475221\n",
      "Iteration 5291, loss = 0.00475080\n",
      "Iteration 5292, loss = 0.00474983\n",
      "Iteration 5293, loss = 0.00474868\n",
      "Iteration 5294, loss = 0.00474733\n",
      "Iteration 5295, loss = 0.00474687\n",
      "Iteration 5296, loss = 0.00474523\n",
      "Iteration 5297, loss = 0.00474381\n",
      "Iteration 5298, loss = 0.00474294\n",
      "Iteration 5299, loss = 0.00474141\n",
      "Iteration 5300, loss = 0.00474033\n",
      "Iteration 5301, loss = 0.00473879\n",
      "Iteration 5302, loss = 0.00473735\n",
      "Iteration 5303, loss = 0.00473669\n",
      "Iteration 5304, loss = 0.00473493\n",
      "Iteration 5305, loss = 0.00473380\n",
      "Iteration 5306, loss = 0.00473265\n",
      "Iteration 5307, loss = 0.00473151\n",
      "Iteration 5308, loss = 0.00473019\n",
      "Iteration 5309, loss = 0.00472885\n",
      "Iteration 5310, loss = 0.00472781\n",
      "Iteration 5311, loss = 0.00472676\n",
      "Iteration 5312, loss = 0.00472522\n",
      "Iteration 5313, loss = 0.00472402\n",
      "Iteration 5314, loss = 0.00472297\n",
      "Iteration 5315, loss = 0.00472193\n",
      "Iteration 5316, loss = 0.00472055\n",
      "Iteration 5317, loss = 0.00471942\n",
      "Iteration 5318, loss = 0.00471865\n",
      "Iteration 5319, loss = 0.00471712\n",
      "Iteration 5320, loss = 0.00471601\n",
      "Iteration 5321, loss = 0.00471488\n",
      "Iteration 5322, loss = 0.00471354\n",
      "Iteration 5323, loss = 0.00471259\n",
      "Iteration 5324, loss = 0.00471136\n",
      "Iteration 5325, loss = 0.00471009\n",
      "Iteration 5326, loss = 0.00470944\n",
      "Iteration 5327, loss = 0.00470799\n",
      "Iteration 5328, loss = 0.00470701\n",
      "Iteration 5329, loss = 0.00470532\n",
      "Iteration 5330, loss = 0.00470442\n",
      "Iteration 5331, loss = 0.00470315\n",
      "Iteration 5332, loss = 0.00470194\n",
      "Iteration 5333, loss = 0.00470087\n",
      "Iteration 5334, loss = 0.00469968\n",
      "Iteration 5335, loss = 0.00469891\n",
      "Iteration 5336, loss = 0.00469760\n",
      "Iteration 5337, loss = 0.00469642\n",
      "Iteration 5338, loss = 0.00469509\n",
      "Iteration 5339, loss = 0.00469449\n",
      "Iteration 5340, loss = 0.00469285\n",
      "Iteration 5341, loss = 0.00469172\n",
      "Iteration 5342, loss = 0.00469053\n",
      "Iteration 5343, loss = 0.00468938\n",
      "Iteration 5344, loss = 0.00468935\n",
      "Iteration 5345, loss = 0.00468716\n",
      "Iteration 5346, loss = 0.00468597\n",
      "Iteration 5347, loss = 0.00468497\n",
      "Iteration 5348, loss = 0.00468336\n",
      "Iteration 5349, loss = 0.00468289\n",
      "Iteration 5350, loss = 0.00468158\n",
      "Iteration 5351, loss = 0.00468011\n",
      "Iteration 5352, loss = 0.00467934\n",
      "Iteration 5353, loss = 0.00467776\n",
      "Iteration 5354, loss = 0.00467685\n",
      "Iteration 5355, loss = 0.00467572\n",
      "Iteration 5356, loss = 0.00467447\n",
      "Iteration 5357, loss = 0.00467349\n",
      "Iteration 5358, loss = 0.00467237\n",
      "Iteration 5359, loss = 0.00467109\n",
      "Iteration 5360, loss = 0.00466984\n",
      "Iteration 5361, loss = 0.00466868\n",
      "Iteration 5362, loss = 0.00466760\n",
      "Iteration 5363, loss = 0.00466649\n",
      "Iteration 5364, loss = 0.00466542\n",
      "Iteration 5365, loss = 0.00466416\n",
      "Iteration 5366, loss = 0.00466328\n",
      "Iteration 5367, loss = 0.00466210\n",
      "Iteration 5368, loss = 0.00466103\n",
      "Iteration 5369, loss = 0.00466008\n",
      "Iteration 5370, loss = 0.00465893\n",
      "Iteration 5371, loss = 0.00465794\n",
      "Iteration 5372, loss = 0.00465685\n",
      "Iteration 5373, loss = 0.00465586\n",
      "Iteration 5374, loss = 0.00465490\n",
      "Iteration 5375, loss = 0.00465360\n",
      "Iteration 5376, loss = 0.00465293\n",
      "Iteration 5377, loss = 0.00465154\n",
      "Iteration 5378, loss = 0.00465078\n",
      "Iteration 5379, loss = 0.00464951\n",
      "Iteration 5380, loss = 0.00464858\n",
      "Iteration 5381, loss = 0.00464752\n",
      "Iteration 5382, loss = 0.00464636\n",
      "Iteration 5383, loss = 0.00464525\n",
      "Iteration 5384, loss = 0.00464425\n",
      "Iteration 5385, loss = 0.00464311\n",
      "Iteration 5386, loss = 0.00464207\n",
      "Iteration 5387, loss = 0.00464101\n",
      "Iteration 5388, loss = 0.00464007\n",
      "Iteration 5389, loss = 0.00463895\n",
      "Iteration 5390, loss = 0.00463787\n",
      "Iteration 5391, loss = 0.00463658\n",
      "Iteration 5392, loss = 0.00463528\n",
      "Iteration 5393, loss = 0.00463484\n",
      "Iteration 5394, loss = 0.00463309\n",
      "Iteration 5395, loss = 0.00463206\n",
      "Iteration 5396, loss = 0.00463151\n",
      "Iteration 5397, loss = 0.00463009\n",
      "Iteration 5398, loss = 0.00462892\n",
      "Iteration 5399, loss = 0.00462779\n",
      "Iteration 5400, loss = 0.00462672\n",
      "Iteration 5401, loss = 0.00462601\n",
      "Iteration 5402, loss = 0.00462473\n",
      "Iteration 5403, loss = 0.00462353\n",
      "Iteration 5404, loss = 0.00462225\n",
      "Iteration 5405, loss = 0.00462130\n",
      "Iteration 5406, loss = 0.00461988\n",
      "Iteration 5407, loss = 0.00461902\n",
      "Iteration 5408, loss = 0.00461805\n",
      "Iteration 5409, loss = 0.00461696\n",
      "Iteration 5410, loss = 0.00461653\n",
      "Iteration 5411, loss = 0.00461514\n",
      "Iteration 5412, loss = 0.00461403\n",
      "Iteration 5413, loss = 0.00461318\n",
      "Iteration 5414, loss = 0.00461135\n",
      "Iteration 5415, loss = 0.00461009\n",
      "Iteration 5416, loss = 0.00460855\n",
      "Iteration 5417, loss = 0.00460929\n",
      "Iteration 5418, loss = 0.00460730\n",
      "Iteration 5419, loss = 0.00460661\n",
      "Iteration 5420, loss = 0.00460480\n",
      "Iteration 5421, loss = 0.00460358\n",
      "Iteration 5422, loss = 0.00460254\n",
      "Iteration 5423, loss = 0.00460143\n",
      "Iteration 5424, loss = 0.00460033\n",
      "Iteration 5425, loss = 0.00459905\n",
      "Iteration 5426, loss = 0.00459760\n",
      "Iteration 5427, loss = 0.00459662\n",
      "Iteration 5428, loss = 0.00459552\n",
      "Iteration 5429, loss = 0.00459428\n",
      "Iteration 5430, loss = 0.00459340\n",
      "Iteration 5431, loss = 0.00459205\n",
      "Iteration 5432, loss = 0.00459126\n",
      "Iteration 5433, loss = 0.00458994\n",
      "Iteration 5434, loss = 0.00458876\n",
      "Iteration 5435, loss = 0.00458773\n",
      "Iteration 5436, loss = 0.00458673\n",
      "Iteration 5437, loss = 0.00458558\n",
      "Iteration 5438, loss = 0.00458465\n",
      "Iteration 5439, loss = 0.00458365\n",
      "Iteration 5440, loss = 0.00458256\n",
      "Iteration 5441, loss = 0.00458207\n",
      "Iteration 5442, loss = 0.00458075\n",
      "Iteration 5443, loss = 0.00457973\n",
      "Iteration 5444, loss = 0.00457871\n",
      "Iteration 5445, loss = 0.00457771\n",
      "Iteration 5446, loss = 0.00457671\n",
      "Iteration 5447, loss = 0.00457577\n",
      "Iteration 5448, loss = 0.00457462\n",
      "Iteration 5449, loss = 0.00457372\n",
      "Iteration 5450, loss = 0.00457260\n",
      "Iteration 5451, loss = 0.00457154\n",
      "Iteration 5452, loss = 0.00457063\n",
      "Iteration 5453, loss = 0.00456934\n",
      "Iteration 5454, loss = 0.00457023\n",
      "Iteration 5455, loss = 0.00456762\n",
      "Iteration 5456, loss = 0.00456656\n",
      "Iteration 5457, loss = 0.00456563\n",
      "Iteration 5458, loss = 0.00456446\n",
      "Iteration 5459, loss = 0.00456334\n",
      "Iteration 5460, loss = 0.00456234\n",
      "Iteration 5461, loss = 0.00456125\n",
      "Iteration 5462, loss = 0.00456030\n",
      "Iteration 5463, loss = 0.00455951\n",
      "Iteration 5464, loss = 0.00455847\n",
      "Iteration 5465, loss = 0.00455744\n",
      "Iteration 5466, loss = 0.00455649\n",
      "Iteration 5467, loss = 0.00455571\n",
      "Iteration 5468, loss = 0.00455486\n",
      "Iteration 5469, loss = 0.00455412\n",
      "Iteration 5470, loss = 0.00455295\n",
      "Iteration 5471, loss = 0.00455191\n",
      "Iteration 5472, loss = 0.00455092\n",
      "Iteration 5473, loss = 0.00454991\n",
      "Iteration 5474, loss = 0.00454885\n",
      "Iteration 5475, loss = 0.00454843\n",
      "Iteration 5476, loss = 0.00454752\n",
      "Iteration 5477, loss = 0.00454741\n",
      "Iteration 5478, loss = 0.00454584\n",
      "Iteration 5479, loss = 0.00454504\n",
      "Iteration 5480, loss = 0.00454391\n",
      "Iteration 5481, loss = 0.00454298\n",
      "Iteration 5482, loss = 0.00454191\n",
      "Iteration 5483, loss = 0.00454100\n",
      "Iteration 5484, loss = 0.00454007\n",
      "Iteration 5485, loss = 0.00453871\n",
      "Iteration 5486, loss = 0.00453766\n",
      "Iteration 5487, loss = 0.00453668\n",
      "Iteration 5488, loss = 0.00453668\n",
      "Iteration 5489, loss = 0.00453482\n",
      "Iteration 5490, loss = 0.00453358\n",
      "Iteration 5491, loss = 0.00453250\n",
      "Iteration 5492, loss = 0.00453150\n",
      "Iteration 5493, loss = 0.00453026\n",
      "Iteration 5494, loss = 0.00452921\n",
      "Iteration 5495, loss = 0.00452810\n",
      "Iteration 5496, loss = 0.00452700\n",
      "Iteration 5497, loss = 0.00452633\n",
      "Iteration 5498, loss = 0.00452514\n",
      "Iteration 5499, loss = 0.00452383\n",
      "Iteration 5500, loss = 0.00452319\n",
      "Iteration 5501, loss = 0.00452156\n",
      "Iteration 5502, loss = 0.00452021\n",
      "Iteration 5503, loss = 0.00451892\n",
      "Iteration 5504, loss = 0.00451778\n",
      "Iteration 5505, loss = 0.00451699\n",
      "Iteration 5506, loss = 0.00451570\n",
      "Iteration 5507, loss = 0.00451463\n",
      "Iteration 5508, loss = 0.00451378\n",
      "Iteration 5509, loss = 0.00451213\n",
      "Iteration 5510, loss = 0.00451131\n",
      "Iteration 5511, loss = 0.00451005\n",
      "Iteration 5512, loss = 0.00450882\n",
      "Iteration 5513, loss = 0.00450775\n",
      "Iteration 5514, loss = 0.00450647\n",
      "Iteration 5515, loss = 0.00450569\n",
      "Iteration 5516, loss = 0.00450466\n",
      "Iteration 5517, loss = 0.00450334\n",
      "Iteration 5518, loss = 0.00450253\n",
      "Iteration 5519, loss = 0.00450145\n",
      "Iteration 5520, loss = 0.00450051\n",
      "Iteration 5521, loss = 0.00449918\n",
      "Iteration 5522, loss = 0.00449825\n",
      "Iteration 5523, loss = 0.00449701\n",
      "Iteration 5524, loss = 0.00449631\n",
      "Iteration 5525, loss = 0.00449494\n",
      "Iteration 5526, loss = 0.00449385\n",
      "Iteration 5527, loss = 0.00449286\n",
      "Iteration 5528, loss = 0.00449176\n",
      "Iteration 5529, loss = 0.00449079\n",
      "Iteration 5530, loss = 0.00448990\n",
      "Iteration 5531, loss = 0.00448874\n",
      "Iteration 5532, loss = 0.00448766\n",
      "Iteration 5533, loss = 0.00448666\n",
      "Iteration 5534, loss = 0.00448550\n",
      "Iteration 5535, loss = 0.00448463\n",
      "Iteration 5536, loss = 0.00448352\n",
      "Iteration 5537, loss = 0.00448234\n",
      "Iteration 5538, loss = 0.00448118\n",
      "Iteration 5539, loss = 0.00448023\n",
      "Iteration 5540, loss = 0.00447922\n",
      "Iteration 5541, loss = 0.00447801\n",
      "Iteration 5542, loss = 0.00447732\n",
      "Iteration 5543, loss = 0.00447612\n",
      "Iteration 5544, loss = 0.00447520\n",
      "Iteration 5545, loss = 0.00447406\n",
      "Iteration 5546, loss = 0.00447314\n",
      "Iteration 5547, loss = 0.00447187\n",
      "Iteration 5548, loss = 0.00447108\n",
      "Iteration 5549, loss = 0.00447004\n",
      "Iteration 5550, loss = 0.00446875\n",
      "Iteration 5551, loss = 0.00446755\n",
      "Iteration 5552, loss = 0.00446634\n",
      "Iteration 5553, loss = 0.00446533\n",
      "Iteration 5554, loss = 0.00446406\n",
      "Iteration 5555, loss = 0.00446291\n",
      "Iteration 5556, loss = 0.00446172\n",
      "Iteration 5557, loss = 0.00446059\n",
      "Iteration 5558, loss = 0.00445955\n",
      "Iteration 5559, loss = 0.00445863\n",
      "Iteration 5560, loss = 0.00445747\n",
      "Iteration 5561, loss = 0.00445638\n",
      "Iteration 5562, loss = 0.00445547\n",
      "Iteration 5563, loss = 0.00445446\n",
      "Iteration 5564, loss = 0.00445327\n",
      "Iteration 5565, loss = 0.00445247\n",
      "Iteration 5566, loss = 0.00445108\n",
      "Iteration 5567, loss = 0.00445006\n",
      "Iteration 5568, loss = 0.00444891\n",
      "Iteration 5569, loss = 0.00444790\n",
      "Iteration 5570, loss = 0.00444717\n",
      "Iteration 5571, loss = 0.00444604\n",
      "Iteration 5572, loss = 0.00444496\n",
      "Iteration 5573, loss = 0.00444419\n",
      "Iteration 5574, loss = 0.00444283\n",
      "Iteration 5575, loss = 0.00444180\n",
      "Iteration 5576, loss = 0.00444101\n",
      "Iteration 5577, loss = 0.00443972\n",
      "Iteration 5578, loss = 0.00443883\n",
      "Iteration 5579, loss = 0.00443786\n",
      "Iteration 5580, loss = 0.00443687\n",
      "Iteration 5581, loss = 0.00443591\n",
      "Iteration 5582, loss = 0.00443523\n",
      "Iteration 5583, loss = 0.00443419\n",
      "Iteration 5584, loss = 0.00443341\n",
      "Iteration 5585, loss = 0.00443200\n",
      "Iteration 5586, loss = 0.00443114\n",
      "Iteration 5587, loss = 0.00443019\n",
      "Iteration 5588, loss = 0.00442937\n",
      "Iteration 5589, loss = 0.00442856\n",
      "Iteration 5590, loss = 0.00442714\n",
      "Iteration 5591, loss = 0.00442636\n",
      "Iteration 5592, loss = 0.00442535\n",
      "Iteration 5593, loss = 0.00442392\n",
      "Iteration 5594, loss = 0.00442287\n",
      "Iteration 5595, loss = 0.00442174\n",
      "Iteration 5596, loss = 0.00442084\n",
      "Iteration 5597, loss = 0.00441986\n",
      "Iteration 5598, loss = 0.00441884\n",
      "Iteration 5599, loss = 0.00441781\n",
      "Iteration 5600, loss = 0.00441694\n",
      "Iteration 5601, loss = 0.00441595\n",
      "Iteration 5602, loss = 0.00441484\n",
      "Iteration 5603, loss = 0.00441450\n",
      "Iteration 5604, loss = 0.00441378\n",
      "Iteration 5605, loss = 0.00441226\n",
      "Iteration 5606, loss = 0.00441078\n",
      "Iteration 5607, loss = 0.00440989\n",
      "Iteration 5608, loss = 0.00440877\n",
      "Iteration 5609, loss = 0.00440771\n",
      "Iteration 5610, loss = 0.00440668\n",
      "Iteration 5611, loss = 0.00440551\n",
      "Iteration 5612, loss = 0.00440456\n",
      "Iteration 5613, loss = 0.00440329\n",
      "Iteration 5614, loss = 0.00440226\n",
      "Iteration 5615, loss = 0.00440119\n",
      "Iteration 5616, loss = 0.00440018\n",
      "Iteration 5617, loss = 0.00440016\n",
      "Iteration 5618, loss = 0.00439785\n",
      "Iteration 5619, loss = 0.00439692\n",
      "Iteration 5620, loss = 0.00439602\n",
      "Iteration 5621, loss = 0.00439458\n",
      "Iteration 5622, loss = 0.00439364\n",
      "Iteration 5623, loss = 0.00439255\n",
      "Iteration 5624, loss = 0.00439140\n",
      "Iteration 5625, loss = 0.00438998\n",
      "Iteration 5626, loss = 0.00438915\n",
      "Iteration 5627, loss = 0.00438810\n",
      "Iteration 5628, loss = 0.00438674\n",
      "Iteration 5629, loss = 0.00438565\n",
      "Iteration 5630, loss = 0.00438481\n",
      "Iteration 5631, loss = 0.00438332\n",
      "Iteration 5632, loss = 0.00438215\n",
      "Iteration 5633, loss = 0.00438114\n",
      "Iteration 5634, loss = 0.00438023\n",
      "Iteration 5635, loss = 0.00437891\n",
      "Iteration 5636, loss = 0.00437770\n",
      "Iteration 5637, loss = 0.00437690\n",
      "Iteration 5638, loss = 0.00437555\n",
      "Iteration 5639, loss = 0.00437443\n",
      "Iteration 5640, loss = 0.00437335\n",
      "Iteration 5641, loss = 0.00437279\n",
      "Iteration 5642, loss = 0.00437141\n",
      "Iteration 5643, loss = 0.00437087\n",
      "Iteration 5644, loss = 0.00436936\n",
      "Iteration 5645, loss = 0.00436828\n",
      "Iteration 5646, loss = 0.00436714\n",
      "Iteration 5647, loss = 0.00436638\n",
      "Iteration 5648, loss = 0.00436517\n",
      "Iteration 5649, loss = 0.00436415\n",
      "Iteration 5650, loss = 0.00436330\n",
      "Iteration 5651, loss = 0.00436218\n",
      "Iteration 5652, loss = 0.00436137\n",
      "Iteration 5653, loss = 0.00436050\n",
      "Iteration 5654, loss = 0.00435968\n",
      "Iteration 5655, loss = 0.00435886\n",
      "Iteration 5656, loss = 0.00435792\n",
      "Iteration 5657, loss = 0.00435699\n",
      "Iteration 5658, loss = 0.00435632\n",
      "Iteration 5659, loss = 0.00435550\n",
      "Iteration 5660, loss = 0.00435486\n",
      "Iteration 5661, loss = 0.00435375\n",
      "Iteration 5662, loss = 0.00435308\n",
      "Iteration 5663, loss = 0.00435246\n",
      "Iteration 5664, loss = 0.00435148\n",
      "Iteration 5665, loss = 0.00435084\n",
      "Iteration 5666, loss = 0.00435020\n",
      "Iteration 5667, loss = 0.00434938\n",
      "Iteration 5668, loss = 0.00434914\n",
      "Iteration 5669, loss = 0.00434802\n",
      "Iteration 5670, loss = 0.00434725\n",
      "Iteration 5671, loss = 0.00434639\n",
      "Iteration 5672, loss = 0.00434586\n",
      "Iteration 5673, loss = 0.00434432\n",
      "Iteration 5674, loss = 0.00434324\n",
      "Iteration 5675, loss = 0.00434228\n",
      "Iteration 5676, loss = 0.00434087\n",
      "Iteration 5677, loss = 0.00433964\n",
      "Iteration 5678, loss = 0.00433929\n",
      "Iteration 5679, loss = 0.00433752\n",
      "Iteration 5680, loss = 0.00433702\n",
      "Iteration 5681, loss = 0.00433513\n",
      "Iteration 5682, loss = 0.00433387\n",
      "Iteration 5683, loss = 0.00433252\n",
      "Iteration 5684, loss = 0.00433141\n",
      "Iteration 5685, loss = 0.00433051\n",
      "Iteration 5686, loss = 0.00432932\n",
      "Iteration 5687, loss = 0.00432832\n",
      "Iteration 5688, loss = 0.00432738\n",
      "Iteration 5689, loss = 0.00432616\n",
      "Iteration 5690, loss = 0.00432513\n",
      "Iteration 5691, loss = 0.00432400\n",
      "Iteration 5692, loss = 0.00432292\n",
      "Iteration 5693, loss = 0.00432165\n",
      "Iteration 5694, loss = 0.00432082\n",
      "Iteration 5695, loss = 0.00431981\n",
      "Iteration 5696, loss = 0.00431859\n",
      "Iteration 5697, loss = 0.00431746\n",
      "Iteration 5698, loss = 0.00431661\n",
      "Iteration 5699, loss = 0.00431548\n",
      "Iteration 5700, loss = 0.00431437\n",
      "Iteration 5701, loss = 0.00431332\n",
      "Iteration 5702, loss = 0.00431242\n",
      "Iteration 5703, loss = 0.00431165\n",
      "Iteration 5704, loss = 0.00430974\n",
      "Iteration 5705, loss = 0.00430840\n",
      "Iteration 5706, loss = 0.00430791\n",
      "Iteration 5707, loss = 0.00430672\n",
      "Iteration 5708, loss = 0.00430598\n",
      "Iteration 5709, loss = 0.00430536\n",
      "Iteration 5710, loss = 0.00430411\n",
      "Iteration 5711, loss = 0.00430281\n",
      "Iteration 5712, loss = 0.00430174\n",
      "Iteration 5713, loss = 0.00430085\n",
      "Iteration 5714, loss = 0.00430000\n",
      "Iteration 5715, loss = 0.00429879\n",
      "Iteration 5716, loss = 0.00429778\n",
      "Iteration 5717, loss = 0.00429668\n",
      "Iteration 5718, loss = 0.00429575\n",
      "Iteration 5719, loss = 0.00429482\n",
      "Iteration 5720, loss = 0.00429373\n",
      "Iteration 5721, loss = 0.00429310\n",
      "Iteration 5722, loss = 0.00429228\n",
      "Iteration 5723, loss = 0.00429185\n",
      "Iteration 5724, loss = 0.00429121\n",
      "Iteration 5725, loss = 0.00428923\n",
      "Iteration 5726, loss = 0.00428804\n",
      "Iteration 5727, loss = 0.00428676\n",
      "Iteration 5728, loss = 0.00428677\n",
      "Iteration 5729, loss = 0.00428493\n",
      "Iteration 5730, loss = 0.00428364\n",
      "Iteration 5731, loss = 0.00428238\n",
      "Iteration 5732, loss = 0.00428161\n",
      "Iteration 5733, loss = 0.00428075\n",
      "Iteration 5734, loss = 0.00427944\n",
      "Iteration 5735, loss = 0.00427855\n",
      "Iteration 5736, loss = 0.00427747\n",
      "Iteration 5737, loss = 0.00427682\n",
      "Iteration 5738, loss = 0.00427557\n",
      "Iteration 5739, loss = 0.00427443\n",
      "Iteration 5740, loss = 0.00427362\n",
      "Iteration 5741, loss = 0.00427266\n",
      "Iteration 5742, loss = 0.00427150\n",
      "Iteration 5743, loss = 0.00427058\n",
      "Iteration 5744, loss = 0.00427003\n",
      "Iteration 5745, loss = 0.00426849\n",
      "Iteration 5746, loss = 0.00426759\n",
      "Iteration 5747, loss = 0.00426657\n",
      "Iteration 5748, loss = 0.00426560\n",
      "Iteration 5749, loss = 0.00426467\n",
      "Iteration 5750, loss = 0.00426374\n",
      "Iteration 5751, loss = 0.00426274\n",
      "Iteration 5752, loss = 0.00426191\n",
      "Iteration 5753, loss = 0.00426111\n",
      "Iteration 5754, loss = 0.00425993\n",
      "Iteration 5755, loss = 0.00425906\n",
      "Iteration 5756, loss = 0.00425791\n",
      "Iteration 5757, loss = 0.00425711\n",
      "Iteration 5758, loss = 0.00425589\n",
      "Iteration 5759, loss = 0.00425531\n",
      "Iteration 5760, loss = 0.00425400\n",
      "Iteration 5761, loss = 0.00425342\n",
      "Iteration 5762, loss = 0.00425223\n",
      "Iteration 5763, loss = 0.00425177\n",
      "Iteration 5764, loss = 0.00425051\n",
      "Iteration 5765, loss = 0.00424926\n",
      "Iteration 5766, loss = 0.00424858\n",
      "Iteration 5767, loss = 0.00424753\n",
      "Iteration 5768, loss = 0.00424642\n",
      "Iteration 5769, loss = 0.00424551\n",
      "Iteration 5770, loss = 0.00424463\n",
      "Iteration 5771, loss = 0.00424368\n",
      "Iteration 5772, loss = 0.00424280\n",
      "Iteration 5773, loss = 0.00424247\n",
      "Iteration 5774, loss = 0.00424139\n",
      "Iteration 5775, loss = 0.00424020\n",
      "Iteration 5776, loss = 0.00423910\n",
      "Iteration 5777, loss = 0.00423812\n",
      "Iteration 5778, loss = 0.00423777\n",
      "Iteration 5779, loss = 0.00423625\n",
      "Iteration 5780, loss = 0.00423527\n",
      "Iteration 5781, loss = 0.00423439\n",
      "Iteration 5782, loss = 0.00423351\n",
      "Iteration 5783, loss = 0.00423252\n",
      "Iteration 5784, loss = 0.00423155\n",
      "Iteration 5785, loss = 0.00423068\n",
      "Iteration 5786, loss = 0.00422968\n",
      "Iteration 5787, loss = 0.00422869\n",
      "Iteration 5788, loss = 0.00422777\n",
      "Iteration 5789, loss = 0.00422733\n",
      "Iteration 5790, loss = 0.00422578\n",
      "Iteration 5791, loss = 0.00422475\n",
      "Iteration 5792, loss = 0.00422418\n",
      "Iteration 5793, loss = 0.00422304\n",
      "Iteration 5794, loss = 0.00422177\n",
      "Iteration 5795, loss = 0.00422054\n",
      "Iteration 5796, loss = 0.00421934\n",
      "Iteration 5797, loss = 0.00421955\n",
      "Iteration 5798, loss = 0.00421797\n",
      "Iteration 5799, loss = 0.00421679\n",
      "Iteration 5800, loss = 0.00421627\n",
      "Iteration 5801, loss = 0.00421495\n",
      "Iteration 5802, loss = 0.00421388\n",
      "Iteration 5803, loss = 0.00421289\n",
      "Iteration 5804, loss = 0.00421184\n",
      "Iteration 5805, loss = 0.00421097\n",
      "Iteration 5806, loss = 0.00420978\n",
      "Iteration 5807, loss = 0.00420906\n",
      "Iteration 5808, loss = 0.00420838\n",
      "Iteration 5809, loss = 0.00420711\n",
      "Iteration 5810, loss = 0.00420612\n",
      "Iteration 5811, loss = 0.00420520\n",
      "Iteration 5812, loss = 0.00420465\n",
      "Iteration 5813, loss = 0.00420348\n",
      "Iteration 5814, loss = 0.00420249\n",
      "Iteration 5815, loss = 0.00420158\n",
      "Iteration 5816, loss = 0.00420077\n",
      "Iteration 5817, loss = 0.00419982\n",
      "Iteration 5818, loss = 0.00419889\n",
      "Iteration 5819, loss = 0.00419790\n",
      "Iteration 5820, loss = 0.00419711\n",
      "Iteration 5821, loss = 0.00419644\n",
      "Iteration 5822, loss = 0.00419553\n",
      "Iteration 5823, loss = 0.00419435\n",
      "Iteration 5824, loss = 0.00419345\n",
      "Iteration 5825, loss = 0.00419260\n",
      "Iteration 5826, loss = 0.00419162\n",
      "Iteration 5827, loss = 0.00419063\n",
      "Iteration 5828, loss = 0.00418999\n",
      "Iteration 5829, loss = 0.00418900\n",
      "Iteration 5830, loss = 0.00418787\n",
      "Iteration 5831, loss = 0.00418690\n",
      "Iteration 5832, loss = 0.00418572\n",
      "Iteration 5833, loss = 0.00418477\n",
      "Iteration 5834, loss = 0.00418372\n",
      "Iteration 5835, loss = 0.00418273\n",
      "Iteration 5836, loss = 0.00418178\n",
      "Iteration 5837, loss = 0.00418087\n",
      "Iteration 5838, loss = 0.00417991\n",
      "Iteration 5839, loss = 0.00417896\n",
      "Iteration 5840, loss = 0.00417823\n",
      "Iteration 5841, loss = 0.00417720\n",
      "Iteration 5842, loss = 0.00417622\n",
      "Iteration 5843, loss = 0.00417547\n",
      "Iteration 5844, loss = 0.00417438\n",
      "Iteration 5845, loss = 0.00417353\n",
      "Iteration 5846, loss = 0.00417251\n",
      "Iteration 5847, loss = 0.00417168\n",
      "Iteration 5848, loss = 0.00417079\n",
      "Iteration 5849, loss = 0.00416989\n",
      "Iteration 5850, loss = 0.00416898\n",
      "Iteration 5851, loss = 0.00416794\n",
      "Iteration 5852, loss = 0.00416734\n",
      "Iteration 5853, loss = 0.00416648\n",
      "Iteration 5854, loss = 0.00416561\n",
      "Iteration 5855, loss = 0.00416465\n",
      "Iteration 5856, loss = 0.00416396\n",
      "Iteration 5857, loss = 0.00416301\n",
      "Iteration 5858, loss = 0.00416219\n",
      "Iteration 5859, loss = 0.00416142\n",
      "Iteration 5860, loss = 0.00416036\n",
      "Iteration 5861, loss = 0.00415952\n",
      "Iteration 5862, loss = 0.00415852\n",
      "Iteration 5863, loss = 0.00415762\n",
      "Iteration 5864, loss = 0.00415706\n",
      "Iteration 5865, loss = 0.00415579\n",
      "Iteration 5866, loss = 0.00415518\n",
      "Iteration 5867, loss = 0.00415414\n",
      "Iteration 5868, loss = 0.00415329\n",
      "Iteration 5869, loss = 0.00415223\n",
      "Iteration 5870, loss = 0.00415163\n",
      "Iteration 5871, loss = 0.00415043\n",
      "Iteration 5872, loss = 0.00414958\n",
      "Iteration 5873, loss = 0.00414865\n",
      "Iteration 5874, loss = 0.00414770\n",
      "Iteration 5875, loss = 0.00414777\n",
      "Iteration 5876, loss = 0.00414588\n",
      "Iteration 5877, loss = 0.00414480\n",
      "Iteration 5878, loss = 0.00414390\n",
      "Iteration 5879, loss = 0.00414298\n",
      "Iteration 5880, loss = 0.00414195\n",
      "Iteration 5881, loss = 0.00414114\n",
      "Iteration 5882, loss = 0.00414021\n",
      "Iteration 5883, loss = 0.00414027\n",
      "Iteration 5884, loss = 0.00413854\n",
      "Iteration 5885, loss = 0.00413763\n",
      "Iteration 5886, loss = 0.00413667\n",
      "Iteration 5887, loss = 0.00413586\n",
      "Iteration 5888, loss = 0.00413493\n",
      "Iteration 5889, loss = 0.00413442\n",
      "Iteration 5890, loss = 0.00413336\n",
      "Iteration 5891, loss = 0.00413246\n",
      "Iteration 5892, loss = 0.00413156\n",
      "Iteration 5893, loss = 0.00413073\n",
      "Iteration 5894, loss = 0.00412978\n",
      "Iteration 5895, loss = 0.00412901\n",
      "Iteration 5896, loss = 0.00412816\n",
      "Iteration 5897, loss = 0.00412680\n",
      "Iteration 5898, loss = 0.00412613\n",
      "Iteration 5899, loss = 0.00412520\n",
      "Iteration 5900, loss = 0.00412433\n",
      "Iteration 5901, loss = 0.00412385\n",
      "Iteration 5902, loss = 0.00412267\n",
      "Iteration 5903, loss = 0.00412180\n",
      "Iteration 5904, loss = 0.00412091\n",
      "Iteration 5905, loss = 0.00411998\n",
      "Iteration 5906, loss = 0.00411915\n",
      "Iteration 5907, loss = 0.00411845\n",
      "Iteration 5908, loss = 0.00411746\n",
      "Iteration 5909, loss = 0.00411665\n",
      "Iteration 5910, loss = 0.00411594\n",
      "Iteration 5911, loss = 0.00411505\n",
      "Iteration 5912, loss = 0.00411399\n",
      "Iteration 5913, loss = 0.00411332\n",
      "Iteration 5914, loss = 0.00411234\n",
      "Iteration 5915, loss = 0.00411149\n",
      "Iteration 5916, loss = 0.00411058\n",
      "Iteration 5917, loss = 0.00410968\n",
      "Iteration 5918, loss = 0.00410876\n",
      "Iteration 5919, loss = 0.00410872\n",
      "Iteration 5920, loss = 0.00410723\n",
      "Iteration 5921, loss = 0.00410637\n",
      "Iteration 5922, loss = 0.00410553\n",
      "Iteration 5923, loss = 0.00410511\n",
      "Iteration 5924, loss = 0.00410398\n",
      "Iteration 5925, loss = 0.00410306\n",
      "Iteration 5926, loss = 0.00410212\n",
      "Iteration 5927, loss = 0.00410126\n",
      "Iteration 5928, loss = 0.00410042\n",
      "Iteration 5929, loss = 0.00409940\n",
      "Iteration 5930, loss = 0.00409851\n",
      "Iteration 5931, loss = 0.00409793\n",
      "Iteration 5932, loss = 0.00409717\n",
      "Iteration 5933, loss = 0.00409556\n",
      "Iteration 5934, loss = 0.00409461\n",
      "Iteration 5935, loss = 0.00409408\n",
      "Iteration 5936, loss = 0.00409259\n",
      "Iteration 5937, loss = 0.00409152\n",
      "Iteration 5938, loss = 0.00409083\n",
      "Iteration 5939, loss = 0.00408991\n",
      "Iteration 5940, loss = 0.00408893\n",
      "Iteration 5941, loss = 0.00408808\n",
      "Iteration 5942, loss = 0.00408686\n",
      "Iteration 5943, loss = 0.00408591\n",
      "Iteration 5944, loss = 0.00408529\n",
      "Iteration 5945, loss = 0.00408418\n",
      "Iteration 5946, loss = 0.00408374\n",
      "Iteration 5947, loss = 0.00408246\n",
      "Iteration 5948, loss = 0.00408165\n",
      "Iteration 5949, loss = 0.00408068\n",
      "Iteration 5950, loss = 0.00407988\n",
      "Iteration 5951, loss = 0.00407894\n",
      "Iteration 5952, loss = 0.00407837\n",
      "Iteration 5953, loss = 0.00407723\n",
      "Iteration 5954, loss = 0.00407639\n",
      "Iteration 5955, loss = 0.00407557\n",
      "Iteration 5956, loss = 0.00407467\n",
      "Iteration 5957, loss = 0.00407391\n",
      "Iteration 5958, loss = 0.00407299\n",
      "Iteration 5959, loss = 0.00407219\n",
      "Iteration 5960, loss = 0.00407113\n",
      "Iteration 5961, loss = 0.00407020\n",
      "Iteration 5962, loss = 0.00406935\n",
      "Iteration 5963, loss = 0.00406862\n",
      "Iteration 5964, loss = 0.00406779\n",
      "Iteration 5965, loss = 0.00406669\n",
      "Iteration 5966, loss = 0.00406556\n",
      "Iteration 5967, loss = 0.00406512\n",
      "Iteration 5968, loss = 0.00406389\n",
      "Iteration 5969, loss = 0.00406300\n",
      "Iteration 5970, loss = 0.00406230\n",
      "Iteration 5971, loss = 0.00406149\n",
      "Iteration 5972, loss = 0.00406038\n",
      "Iteration 5973, loss = 0.00405962\n",
      "Iteration 5974, loss = 0.00405873\n",
      "Iteration 5975, loss = 0.00405790\n",
      "Iteration 5976, loss = 0.00405732\n",
      "Iteration 5977, loss = 0.00405631\n",
      "Iteration 5978, loss = 0.00405547\n",
      "Iteration 5979, loss = 0.00405466\n",
      "Iteration 5980, loss = 0.00405389\n",
      "Iteration 5981, loss = 0.00405300\n",
      "Iteration 5982, loss = 0.00405226\n",
      "Iteration 5983, loss = 0.00405199\n",
      "Iteration 5984, loss = 0.00405087\n",
      "Iteration 5985, loss = 0.00405011\n",
      "Iteration 5986, loss = 0.00404918\n",
      "Iteration 5987, loss = 0.00404831\n",
      "Iteration 5988, loss = 0.00404692\n",
      "Iteration 5989, loss = 0.00404598\n",
      "Iteration 5990, loss = 0.00404530\n",
      "Iteration 5991, loss = 0.00404423\n",
      "Iteration 5992, loss = 0.00404330\n",
      "Iteration 5993, loss = 0.00404256\n",
      "Iteration 5994, loss = 0.00404167\n",
      "Iteration 5995, loss = 0.00404080\n",
      "Iteration 5996, loss = 0.00404014\n",
      "Iteration 5997, loss = 0.00403932\n",
      "Iteration 5998, loss = 0.00403851\n",
      "Iteration 5999, loss = 0.00403853\n",
      "Iteration 6000, loss = 0.00403672\n",
      "Iteration 6001, loss = 0.00403553\n",
      "Iteration 6002, loss = 0.00403442\n",
      "Iteration 6003, loss = 0.00403379\n",
      "Iteration 6004, loss = 0.00403236\n",
      "Iteration 6005, loss = 0.00403191\n",
      "Iteration 6006, loss = 0.00403086\n",
      "Iteration 6007, loss = 0.00403017\n",
      "Iteration 6008, loss = 0.00402893\n",
      "Iteration 6009, loss = 0.00402808\n",
      "Iteration 6010, loss = 0.00402721\n",
      "Iteration 6011, loss = 0.00402643\n",
      "Iteration 6012, loss = 0.00402559\n",
      "Iteration 6013, loss = 0.00402528\n",
      "Iteration 6014, loss = 0.00402410\n",
      "Iteration 6015, loss = 0.00402315\n",
      "Iteration 6016, loss = 0.00402219\n",
      "Iteration 6017, loss = 0.00402131\n",
      "Iteration 6018, loss = 0.00402063\n",
      "Iteration 6019, loss = 0.00401974\n",
      "Iteration 6020, loss = 0.00401934\n",
      "Iteration 6021, loss = 0.00401824\n",
      "Iteration 6022, loss = 0.00401739\n",
      "Iteration 6023, loss = 0.00401654\n",
      "Iteration 6024, loss = 0.00401589\n",
      "Iteration 6025, loss = 0.00401537\n",
      "Iteration 6026, loss = 0.00401437\n",
      "Iteration 6027, loss = 0.00401357\n",
      "Iteration 6028, loss = 0.00401276\n",
      "Iteration 6029, loss = 0.00401200\n",
      "Iteration 6030, loss = 0.00401116\n",
      "Iteration 6031, loss = 0.00401026\n",
      "Iteration 6032, loss = 0.00400945\n",
      "Iteration 6033, loss = 0.00400880\n",
      "Iteration 6034, loss = 0.00400773\n",
      "Iteration 6035, loss = 0.00400734\n",
      "Iteration 6036, loss = 0.00400606\n",
      "Iteration 6037, loss = 0.00400496\n",
      "Iteration 6038, loss = 0.00400426\n",
      "Iteration 6039, loss = 0.00400306\n",
      "Iteration 6040, loss = 0.00400204\n",
      "Iteration 6041, loss = 0.00400101\n",
      "Iteration 6042, loss = 0.00400047\n",
      "Iteration 6043, loss = 0.00399936\n",
      "Iteration 6044, loss = 0.00399876\n",
      "Iteration 6045, loss = 0.00399743\n",
      "Iteration 6046, loss = 0.00399657\n",
      "Iteration 6047, loss = 0.00399560\n",
      "Iteration 6048, loss = 0.00399466\n",
      "Iteration 6049, loss = 0.00399376\n",
      "Iteration 6050, loss = 0.00399269\n",
      "Iteration 6051, loss = 0.00399236\n",
      "Iteration 6052, loss = 0.00399104\n",
      "Iteration 6053, loss = 0.00399052\n",
      "Iteration 6054, loss = 0.00398938\n",
      "Iteration 6055, loss = 0.00398833\n",
      "Iteration 6056, loss = 0.00398763\n",
      "Iteration 6057, loss = 0.00398668\n",
      "Iteration 6058, loss = 0.00398583\n",
      "Iteration 6059, loss = 0.00398551\n",
      "Iteration 6060, loss = 0.00398421\n",
      "Iteration 6061, loss = 0.00398326\n",
      "Iteration 6062, loss = 0.00398255\n",
      "Iteration 6063, loss = 0.00398176\n",
      "Iteration 6064, loss = 0.00398069\n",
      "Iteration 6065, loss = 0.00397969\n",
      "Iteration 6066, loss = 0.00397886\n",
      "Iteration 6067, loss = 0.00397800\n",
      "Iteration 6068, loss = 0.00397719\n",
      "Iteration 6069, loss = 0.00397632\n",
      "Iteration 6070, loss = 0.00397563\n",
      "Iteration 6071, loss = 0.00397461\n",
      "Iteration 6072, loss = 0.00397391\n",
      "Iteration 6073, loss = 0.00397303\n",
      "Iteration 6074, loss = 0.00397224\n",
      "Iteration 6075, loss = 0.00397133\n",
      "Iteration 6076, loss = 0.00397060\n",
      "Iteration 6077, loss = 0.00396991\n",
      "Iteration 6078, loss = 0.00396878\n",
      "Iteration 6079, loss = 0.00396793\n",
      "Iteration 6080, loss = 0.00396738\n",
      "Iteration 6081, loss = 0.00396599\n",
      "Iteration 6082, loss = 0.00396515\n",
      "Iteration 6083, loss = 0.00396416\n",
      "Iteration 6084, loss = 0.00396318\n",
      "Iteration 6085, loss = 0.00396221\n",
      "Iteration 6086, loss = 0.00396146\n",
      "Iteration 6087, loss = 0.00396061\n",
      "Iteration 6088, loss = 0.00395979\n",
      "Iteration 6089, loss = 0.00395883\n",
      "Iteration 6090, loss = 0.00395792\n",
      "Iteration 6091, loss = 0.00395701\n",
      "Iteration 6092, loss = 0.00395620\n",
      "Iteration 6093, loss = 0.00395540\n",
      "Iteration 6094, loss = 0.00395441\n",
      "Iteration 6095, loss = 0.00395351\n",
      "Iteration 6096, loss = 0.00395273\n",
      "Iteration 6097, loss = 0.00395153\n",
      "Iteration 6098, loss = 0.00395062\n",
      "Iteration 6099, loss = 0.00394990\n",
      "Iteration 6100, loss = 0.00394880\n",
      "Iteration 6101, loss = 0.00394794\n",
      "Iteration 6102, loss = 0.00394690\n",
      "Iteration 6103, loss = 0.00394643\n",
      "Iteration 6104, loss = 0.00394537\n",
      "Iteration 6105, loss = 0.00394456\n",
      "Iteration 6106, loss = 0.00394361\n",
      "Iteration 6107, loss = 0.00394294\n",
      "Iteration 6108, loss = 0.00394207\n",
      "Iteration 6109, loss = 0.00394105\n",
      "Iteration 6110, loss = 0.00394018\n",
      "Iteration 6111, loss = 0.00393931\n",
      "Iteration 6112, loss = 0.00393840\n",
      "Iteration 6113, loss = 0.00393766\n",
      "Iteration 6114, loss = 0.00393685\n",
      "Iteration 6115, loss = 0.00393635\n",
      "Iteration 6116, loss = 0.00393544\n",
      "Iteration 6117, loss = 0.00393455\n",
      "Iteration 6118, loss = 0.00393372\n",
      "Iteration 6119, loss = 0.00393292\n",
      "Iteration 6120, loss = 0.00393202\n",
      "Iteration 6121, loss = 0.00393118\n",
      "Iteration 6122, loss = 0.00393037\n",
      "Iteration 6123, loss = 0.00392964\n",
      "Iteration 6124, loss = 0.00392884\n",
      "Iteration 6125, loss = 0.00392836\n",
      "Iteration 6126, loss = 0.00392729\n",
      "Iteration 6127, loss = 0.00392649\n",
      "Iteration 6128, loss = 0.00392554\n",
      "Iteration 6129, loss = 0.00392475\n",
      "Iteration 6130, loss = 0.00392412\n",
      "Iteration 6131, loss = 0.00392466\n",
      "Iteration 6132, loss = 0.00392251\n",
      "Iteration 6133, loss = 0.00392195\n",
      "Iteration 6134, loss = 0.00392069\n",
      "Iteration 6135, loss = 0.00391939\n",
      "Iteration 6136, loss = 0.00391909\n",
      "Iteration 6137, loss = 0.00391764\n",
      "Iteration 6138, loss = 0.00391713\n",
      "Iteration 6139, loss = 0.00391599\n",
      "Iteration 6140, loss = 0.00391515\n",
      "Iteration 6141, loss = 0.00391453\n",
      "Iteration 6142, loss = 0.00391391\n",
      "Iteration 6143, loss = 0.00391263\n",
      "Iteration 6144, loss = 0.00391193\n",
      "Iteration 6145, loss = 0.00391084\n",
      "Iteration 6146, loss = 0.00391022\n",
      "Iteration 6147, loss = 0.00390935\n",
      "Iteration 6148, loss = 0.00390832\n",
      "Iteration 6149, loss = 0.00390751\n",
      "Iteration 6150, loss = 0.00390684\n",
      "Iteration 6151, loss = 0.00390584\n",
      "Iteration 6152, loss = 0.00390512\n",
      "Iteration 6153, loss = 0.00390419\n",
      "Iteration 6154, loss = 0.00390344\n",
      "Iteration 6155, loss = 0.00390282\n",
      "Iteration 6156, loss = 0.00390183\n",
      "Iteration 6157, loss = 0.00390097\n",
      "Iteration 6158, loss = 0.00389987\n",
      "Iteration 6159, loss = 0.00389929\n",
      "Iteration 6160, loss = 0.00389851\n",
      "Iteration 6161, loss = 0.00389741\n",
      "Iteration 6162, loss = 0.00389651\n",
      "Iteration 6163, loss = 0.00389580\n",
      "Iteration 6164, loss = 0.00389516\n",
      "Iteration 6165, loss = 0.00389408\n",
      "Iteration 6166, loss = 0.00389307\n",
      "Iteration 6167, loss = 0.00389207\n",
      "Iteration 6168, loss = 0.00389208\n",
      "Iteration 6169, loss = 0.00389140\n",
      "Iteration 6170, loss = 0.00388992\n",
      "Iteration 6171, loss = 0.00388898\n",
      "Iteration 6172, loss = 0.00388809\n",
      "Iteration 6173, loss = 0.00388746\n",
      "Iteration 6174, loss = 0.00388617\n",
      "Iteration 6175, loss = 0.00388525\n",
      "Iteration 6176, loss = 0.00388455\n",
      "Iteration 6177, loss = 0.00388379\n",
      "Iteration 6178, loss = 0.00388279\n",
      "Iteration 6179, loss = 0.00388173\n",
      "Iteration 6180, loss = 0.00388104\n",
      "Iteration 6181, loss = 0.00387997\n",
      "Iteration 6182, loss = 0.00387948\n",
      "Iteration 6183, loss = 0.00387839\n",
      "Iteration 6184, loss = 0.00387766\n",
      "Iteration 6185, loss = 0.00387672\n",
      "Iteration 6186, loss = 0.00387578\n",
      "Iteration 6187, loss = 0.00387488\n",
      "Iteration 6188, loss = 0.00387421\n",
      "Iteration 6189, loss = 0.00387316\n",
      "Iteration 6190, loss = 0.00387227\n",
      "Iteration 6191, loss = 0.00387167\n",
      "Iteration 6192, loss = 0.00387090\n",
      "Iteration 6193, loss = 0.00387013\n",
      "Iteration 6194, loss = 0.00386913\n",
      "Iteration 6195, loss = 0.00386824\n",
      "Iteration 6196, loss = 0.00386765\n",
      "Iteration 6197, loss = 0.00386666\n",
      "Iteration 6198, loss = 0.00386583\n",
      "Iteration 6199, loss = 0.00386521\n",
      "Iteration 6200, loss = 0.00386448\n",
      "Iteration 6201, loss = 0.00386355\n",
      "Iteration 6202, loss = 0.00386283\n",
      "Iteration 6203, loss = 0.00386203\n",
      "Iteration 6204, loss = 0.00386105\n",
      "Iteration 6205, loss = 0.00386033\n",
      "Iteration 6206, loss = 0.00385943\n",
      "Iteration 6207, loss = 0.00385880\n",
      "Iteration 6208, loss = 0.00385786\n",
      "Iteration 6209, loss = 0.00385759\n",
      "Iteration 6210, loss = 0.00385645\n",
      "Iteration 6211, loss = 0.00385583\n",
      "Iteration 6212, loss = 0.00385499\n",
      "Iteration 6213, loss = 0.00385414\n",
      "Iteration 6214, loss = 0.00385328\n",
      "Iteration 6215, loss = 0.00385270\n",
      "Iteration 6216, loss = 0.00385180\n",
      "Iteration 6217, loss = 0.00385103\n",
      "Iteration 6218, loss = 0.00385033\n",
      "Iteration 6219, loss = 0.00384943\n",
      "Iteration 6220, loss = 0.00384875\n",
      "Iteration 6221, loss = 0.00384852\n",
      "Iteration 6222, loss = 0.00384724\n",
      "Iteration 6223, loss = 0.00384640\n",
      "Iteration 6224, loss = 0.00384559\n",
      "Iteration 6225, loss = 0.00384463\n",
      "Iteration 6226, loss = 0.00384423\n",
      "Iteration 6227, loss = 0.00384306\n",
      "Iteration 6228, loss = 0.00384210\n",
      "Iteration 6229, loss = 0.00384135\n",
      "Iteration 6230, loss = 0.00384040\n",
      "Iteration 6231, loss = 0.00383959\n",
      "Iteration 6232, loss = 0.00383884\n",
      "Iteration 6233, loss = 0.00383804\n",
      "Iteration 6234, loss = 0.00383785\n",
      "Iteration 6235, loss = 0.00383654\n",
      "Iteration 6236, loss = 0.00383552\n",
      "Iteration 6237, loss = 0.00383487\n",
      "Iteration 6238, loss = 0.00383396\n",
      "Iteration 6239, loss = 0.00383322\n",
      "Iteration 6240, loss = 0.00383231\n",
      "Iteration 6241, loss = 0.00383148\n",
      "Iteration 6242, loss = 0.00383067\n",
      "Iteration 6243, loss = 0.00382970\n",
      "Iteration 6244, loss = 0.00382906\n",
      "Iteration 6245, loss = 0.00382813\n",
      "Iteration 6246, loss = 0.00382752\n",
      "Iteration 6247, loss = 0.00382668\n",
      "Iteration 6248, loss = 0.00382602\n",
      "Iteration 6249, loss = 0.00382501\n",
      "Iteration 6250, loss = 0.00382417\n",
      "Iteration 6251, loss = 0.00382364\n",
      "Iteration 6252, loss = 0.00382271\n",
      "Iteration 6253, loss = 0.00382184\n",
      "Iteration 6254, loss = 0.00382097\n",
      "Iteration 6255, loss = 0.00382019\n",
      "Iteration 6256, loss = 0.00381930\n",
      "Iteration 6257, loss = 0.00381872\n",
      "Iteration 6258, loss = 0.00381767\n",
      "Iteration 6259, loss = 0.00381688\n",
      "Iteration 6260, loss = 0.00381622\n",
      "Iteration 6261, loss = 0.00381520\n",
      "Iteration 6262, loss = 0.00381424\n",
      "Iteration 6263, loss = 0.00381324\n",
      "Iteration 6264, loss = 0.00381264\n",
      "Iteration 6265, loss = 0.00381176\n",
      "Iteration 6266, loss = 0.00381135\n",
      "Iteration 6267, loss = 0.00381052\n",
      "Iteration 6268, loss = 0.00380957\n",
      "Iteration 6269, loss = 0.00380879\n",
      "Iteration 6270, loss = 0.00380783\n",
      "Iteration 6271, loss = 0.00380711\n",
      "Iteration 6272, loss = 0.00380625\n",
      "Iteration 6273, loss = 0.00380549\n",
      "Iteration 6274, loss = 0.00380477\n",
      "Iteration 6275, loss = 0.00380400\n",
      "Iteration 6276, loss = 0.00380299\n",
      "Iteration 6277, loss = 0.00380209\n",
      "Iteration 6278, loss = 0.00380151\n",
      "Iteration 6279, loss = 0.00380076\n",
      "Iteration 6280, loss = 0.00380045\n",
      "Iteration 6281, loss = 0.00379930\n",
      "Iteration 6282, loss = 0.00379852\n",
      "Iteration 6283, loss = 0.00379823\n",
      "Iteration 6284, loss = 0.00379731\n",
      "Iteration 6285, loss = 0.00379625\n",
      "Iteration 6286, loss = 0.00379565\n",
      "Iteration 6287, loss = 0.00379586\n",
      "Iteration 6288, loss = 0.00379423\n",
      "Iteration 6289, loss = 0.00379341\n",
      "Iteration 6290, loss = 0.00379272\n",
      "Iteration 6291, loss = 0.00379187\n",
      "Iteration 6292, loss = 0.00379109\n",
      "Iteration 6293, loss = 0.00379042\n",
      "Iteration 6294, loss = 0.00378980\n",
      "Iteration 6295, loss = 0.00378868\n",
      "Iteration 6296, loss = 0.00378789\n",
      "Iteration 6297, loss = 0.00378710\n",
      "Iteration 6298, loss = 0.00378635\n",
      "Iteration 6299, loss = 0.00378577\n",
      "Iteration 6300, loss = 0.00378489\n",
      "Iteration 6301, loss = 0.00378418\n",
      "Iteration 6302, loss = 0.00378335\n",
      "Iteration 6303, loss = 0.00378256\n",
      "Iteration 6304, loss = 0.00378177\n",
      "Iteration 6305, loss = 0.00378099\n",
      "Iteration 6306, loss = 0.00378009\n",
      "Iteration 6307, loss = 0.00377946\n",
      "Iteration 6308, loss = 0.00377859\n",
      "Iteration 6309, loss = 0.00377763\n",
      "Iteration 6310, loss = 0.00377680\n",
      "Iteration 6311, loss = 0.00377613\n",
      "Iteration 6312, loss = 0.00377518\n",
      "Iteration 6313, loss = 0.00377482\n",
      "Iteration 6314, loss = 0.00377374\n",
      "Iteration 6315, loss = 0.00377307\n",
      "Iteration 6316, loss = 0.00377189\n",
      "Iteration 6317, loss = 0.00377113\n",
      "Iteration 6318, loss = 0.00377031\n",
      "Iteration 6319, loss = 0.00376965\n",
      "Iteration 6320, loss = 0.00376875\n",
      "Iteration 6321, loss = 0.00376793\n",
      "Iteration 6322, loss = 0.00376746\n",
      "Iteration 6323, loss = 0.00376622\n",
      "Iteration 6324, loss = 0.00376535\n",
      "Iteration 6325, loss = 0.00376500\n",
      "Iteration 6326, loss = 0.00376402\n",
      "Iteration 6327, loss = 0.00376346\n",
      "Iteration 6328, loss = 0.00376257\n",
      "Iteration 6329, loss = 0.00376164\n",
      "Iteration 6330, loss = 0.00376067\n",
      "Iteration 6331, loss = 0.00375980\n",
      "Iteration 6332, loss = 0.00375908\n",
      "Iteration 6333, loss = 0.00375820\n",
      "Iteration 6334, loss = 0.00375747\n",
      "Iteration 6335, loss = 0.00375648\n",
      "Iteration 6336, loss = 0.00375579\n",
      "Iteration 6337, loss = 0.00375495\n",
      "Iteration 6338, loss = 0.00375431\n",
      "Iteration 6339, loss = 0.00375347\n",
      "Iteration 6340, loss = 0.00375274\n",
      "Iteration 6341, loss = 0.00375205\n",
      "Iteration 6342, loss = 0.00375139\n",
      "Iteration 6343, loss = 0.00375069\n",
      "Iteration 6344, loss = 0.00375003\n",
      "Iteration 6345, loss = 0.00374934\n",
      "Iteration 6346, loss = 0.00374921\n",
      "Iteration 6347, loss = 0.00374813\n",
      "Iteration 6348, loss = 0.00374750\n",
      "Iteration 6349, loss = 0.00374665\n",
      "Iteration 6350, loss = 0.00374640\n",
      "Iteration 6351, loss = 0.00374534\n",
      "Iteration 6352, loss = 0.00374466\n",
      "Iteration 6353, loss = 0.00374391\n",
      "Iteration 6354, loss = 0.00374329\n",
      "Iteration 6355, loss = 0.00374239\n",
      "Iteration 6356, loss = 0.00374181\n",
      "Iteration 6357, loss = 0.00374093\n",
      "Iteration 6358, loss = 0.00374015\n",
      "Iteration 6359, loss = 0.00373940\n",
      "Iteration 6360, loss = 0.00373866\n",
      "Iteration 6361, loss = 0.00373797\n",
      "Iteration 6362, loss = 0.00373737\n",
      "Iteration 6363, loss = 0.00373666\n",
      "Iteration 6364, loss = 0.00373599\n",
      "Iteration 6365, loss = 0.00373528\n",
      "Iteration 6366, loss = 0.00373509\n",
      "Iteration 6367, loss = 0.00373408\n",
      "Iteration 6368, loss = 0.00373350\n",
      "Iteration 6369, loss = 0.00373276\n",
      "Iteration 6370, loss = 0.00373211\n",
      "Iteration 6371, loss = 0.00373144\n",
      "Iteration 6372, loss = 0.00373084\n",
      "Iteration 6373, loss = 0.00373013\n",
      "Iteration 6374, loss = 0.00372950\n",
      "Iteration 6375, loss = 0.00372904\n",
      "Iteration 6376, loss = 0.00372837\n",
      "Iteration 6377, loss = 0.00372812\n",
      "Iteration 6378, loss = 0.00372727\n",
      "Iteration 6379, loss = 0.00372646\n",
      "Iteration 6380, loss = 0.00372581\n",
      "Iteration 6381, loss = 0.00372521\n",
      "Iteration 6382, loss = 0.00372514\n",
      "Iteration 6383, loss = 0.00372398\n",
      "Iteration 6384, loss = 0.00372328\n",
      "Iteration 6385, loss = 0.00372256\n",
      "Iteration 6386, loss = 0.00372218\n",
      "Iteration 6387, loss = 0.00372143\n",
      "Iteration 6388, loss = 0.00372048\n",
      "Iteration 6389, loss = 0.00371975\n",
      "Iteration 6390, loss = 0.00371927\n",
      "Iteration 6391, loss = 0.00371903\n",
      "Iteration 6392, loss = 0.00371841\n",
      "Iteration 6393, loss = 0.00371674\n",
      "Iteration 6394, loss = 0.00371563\n",
      "Iteration 6395, loss = 0.00371499\n",
      "Iteration 6396, loss = 0.00371405\n",
      "Iteration 6397, loss = 0.00371283\n",
      "Iteration 6398, loss = 0.00371251\n",
      "Iteration 6399, loss = 0.00371144\n",
      "Iteration 6400, loss = 0.00371075\n",
      "Iteration 6401, loss = 0.00370989\n",
      "Iteration 6402, loss = 0.00370930\n",
      "Iteration 6403, loss = 0.00370854\n",
      "Iteration 6404, loss = 0.00370806\n",
      "Iteration 6405, loss = 0.00370729\n",
      "Iteration 6406, loss = 0.00370667\n",
      "Iteration 6407, loss = 0.00370593\n",
      "Iteration 6408, loss = 0.00370559\n",
      "Iteration 6409, loss = 0.00370468\n",
      "Iteration 6410, loss = 0.00370403\n",
      "Iteration 6411, loss = 0.00370331\n",
      "Iteration 6412, loss = 0.00370270\n",
      "Iteration 6413, loss = 0.00370219\n",
      "Iteration 6414, loss = 0.00370168\n",
      "Iteration 6415, loss = 0.00370099\n",
      "Iteration 6416, loss = 0.00370026\n",
      "Iteration 6417, loss = 0.00369951\n",
      "Iteration 6418, loss = 0.00369877\n",
      "Iteration 6419, loss = 0.00369811\n",
      "Iteration 6420, loss = 0.00369724\n",
      "Iteration 6421, loss = 0.00369629\n",
      "Iteration 6422, loss = 0.00369569\n",
      "Iteration 6423, loss = 0.00369486\n",
      "Iteration 6424, loss = 0.00369389\n",
      "Iteration 6425, loss = 0.00369316\n",
      "Iteration 6426, loss = 0.00369222\n",
      "Iteration 6427, loss = 0.00369150\n",
      "Iteration 6428, loss = 0.00369065\n",
      "Iteration 6429, loss = 0.00369006\n",
      "Iteration 6430, loss = 0.00368929\n",
      "Iteration 6431, loss = 0.00368869\n",
      "Iteration 6432, loss = 0.00368775\n",
      "Iteration 6433, loss = 0.00368674\n",
      "Iteration 6434, loss = 0.00368581\n",
      "Iteration 6435, loss = 0.00368465\n",
      "Iteration 6436, loss = 0.00368344\n",
      "Iteration 6437, loss = 0.00368249\n",
      "Iteration 6438, loss = 0.00368226\n",
      "Iteration 6439, loss = 0.00368040\n",
      "Iteration 6440, loss = 0.00368013\n",
      "Iteration 6441, loss = 0.00367887\n",
      "Iteration 6442, loss = 0.00367808\n",
      "Iteration 6443, loss = 0.00367715\n",
      "Iteration 6444, loss = 0.00367675\n",
      "Iteration 6445, loss = 0.00367550\n",
      "Iteration 6446, loss = 0.00367469\n",
      "Iteration 6447, loss = 0.00367390\n",
      "Iteration 6448, loss = 0.00367299\n",
      "Iteration 6449, loss = 0.00367243\n",
      "Iteration 6450, loss = 0.00367156\n",
      "Iteration 6451, loss = 0.00367072\n",
      "Iteration 6452, loss = 0.00367005\n",
      "Iteration 6453, loss = 0.00366927\n",
      "Iteration 6454, loss = 0.00366880\n",
      "Iteration 6455, loss = 0.00366783\n",
      "Iteration 6456, loss = 0.00366717\n",
      "Iteration 6457, loss = 0.00366632\n",
      "Iteration 6458, loss = 0.00366575\n",
      "Iteration 6459, loss = 0.00366500\n",
      "Iteration 6460, loss = 0.00366418\n",
      "Iteration 6461, loss = 0.00366360\n",
      "Iteration 6462, loss = 0.00366280\n",
      "Iteration 6463, loss = 0.00366216\n",
      "Iteration 6464, loss = 0.00366143\n",
      "Iteration 6465, loss = 0.00366073\n",
      "Iteration 6466, loss = 0.00366054\n",
      "Iteration 6467, loss = 0.00365941\n",
      "Iteration 6468, loss = 0.00365871\n",
      "Iteration 6469, loss = 0.00365828\n",
      "Iteration 6470, loss = 0.00365727\n",
      "Iteration 6471, loss = 0.00365657\n",
      "Iteration 6472, loss = 0.00365587\n",
      "Iteration 6473, loss = 0.00365520\n",
      "Iteration 6474, loss = 0.00365456\n",
      "Iteration 6475, loss = 0.00365368\n",
      "Iteration 6476, loss = 0.00365306\n",
      "Iteration 6477, loss = 0.00365238\n",
      "Iteration 6478, loss = 0.00365211\n",
      "Iteration 6479, loss = 0.00365120\n",
      "Iteration 6480, loss = 0.00365034\n",
      "Iteration 6481, loss = 0.00364978\n",
      "Iteration 6482, loss = 0.00364914\n",
      "Iteration 6483, loss = 0.00364887\n",
      "Iteration 6484, loss = 0.00364798\n",
      "Iteration 6485, loss = 0.00364731\n",
      "Iteration 6486, loss = 0.00364645\n",
      "Iteration 6487, loss = 0.00364573\n",
      "Iteration 6488, loss = 0.00364504\n",
      "Iteration 6489, loss = 0.00364465\n",
      "Iteration 6490, loss = 0.00364407\n",
      "Iteration 6491, loss = 0.00364281\n",
      "Iteration 6492, loss = 0.00364190\n",
      "Iteration 6493, loss = 0.00364127\n",
      "Iteration 6494, loss = 0.00364045\n",
      "Iteration 6495, loss = 0.00363964\n",
      "Iteration 6496, loss = 0.00363879\n",
      "Iteration 6497, loss = 0.00363805\n",
      "Iteration 6498, loss = 0.00363759\n",
      "Iteration 6499, loss = 0.00363634\n",
      "Iteration 6500, loss = 0.00363527\n",
      "Iteration 6501, loss = 0.00363535\n",
      "Iteration 6502, loss = 0.00363408\n",
      "Iteration 6503, loss = 0.00363341\n",
      "Iteration 6504, loss = 0.00363242\n",
      "Iteration 6505, loss = 0.00363168\n",
      "Iteration 6506, loss = 0.00363101\n",
      "Iteration 6507, loss = 0.00363025\n",
      "Iteration 6508, loss = 0.00362940\n",
      "Iteration 6509, loss = 0.00362886\n",
      "Iteration 6510, loss = 0.00362793\n",
      "Iteration 6511, loss = 0.00362732\n",
      "Iteration 6512, loss = 0.00362693\n",
      "Iteration 6513, loss = 0.00362604\n",
      "Iteration 6514, loss = 0.00362527\n",
      "Iteration 6515, loss = 0.00362453\n",
      "Iteration 6516, loss = 0.00362393\n",
      "Iteration 6517, loss = 0.00362317\n",
      "Iteration 6518, loss = 0.00362254\n",
      "Iteration 6519, loss = 0.00362180\n",
      "Iteration 6520, loss = 0.00362115\n",
      "Iteration 6521, loss = 0.00362072\n",
      "Iteration 6522, loss = 0.00361990\n",
      "Iteration 6523, loss = 0.00361952\n",
      "Iteration 6524, loss = 0.00361823\n",
      "Iteration 6525, loss = 0.00361745\n",
      "Iteration 6526, loss = 0.00361678\n",
      "Iteration 6527, loss = 0.00361626\n",
      "Iteration 6528, loss = 0.00361526\n",
      "Iteration 6529, loss = 0.00361478\n",
      "Iteration 6530, loss = 0.00361385\n",
      "Iteration 6531, loss = 0.00361312\n",
      "Iteration 6532, loss = 0.00361228\n",
      "Iteration 6533, loss = 0.00361156\n",
      "Iteration 6534, loss = 0.00361092\n",
      "Iteration 6535, loss = 0.00361025\n",
      "Iteration 6536, loss = 0.00360960\n",
      "Iteration 6537, loss = 0.00360890\n",
      "Iteration 6538, loss = 0.00360825\n",
      "Iteration 6539, loss = 0.00360759\n",
      "Iteration 6540, loss = 0.00360705\n",
      "Iteration 6541, loss = 0.00360647\n",
      "Iteration 6542, loss = 0.00360622\n",
      "Iteration 6543, loss = 0.00360530\n",
      "Iteration 6544, loss = 0.00360463\n",
      "Iteration 6545, loss = 0.00360394\n",
      "Iteration 6546, loss = 0.00360339\n",
      "Iteration 6547, loss = 0.00360247\n",
      "Iteration 6548, loss = 0.00360180\n",
      "Iteration 6549, loss = 0.00360107\n",
      "Iteration 6550, loss = 0.00360042\n",
      "Iteration 6551, loss = 0.00359968\n",
      "Iteration 6552, loss = 0.00359894\n",
      "Iteration 6553, loss = 0.00359844\n",
      "Iteration 6554, loss = 0.00359761\n",
      "Iteration 6555, loss = 0.00359688\n",
      "Iteration 6556, loss = 0.00359616\n",
      "Iteration 6557, loss = 0.00359585\n",
      "Iteration 6558, loss = 0.00359492\n",
      "Iteration 6559, loss = 0.00359402\n",
      "Iteration 6560, loss = 0.00359325\n",
      "Iteration 6561, loss = 0.00359239\n",
      "Iteration 6562, loss = 0.00359196\n",
      "Iteration 6563, loss = 0.00359101\n",
      "Iteration 6564, loss = 0.00359035\n",
      "Iteration 6565, loss = 0.00358941\n",
      "Iteration 6566, loss = 0.00358839\n",
      "Iteration 6567, loss = 0.00358827\n",
      "Iteration 6568, loss = 0.00358709\n",
      "Iteration 6569, loss = 0.00358621\n",
      "Iteration 6570, loss = 0.00358556\n",
      "Iteration 6571, loss = 0.00358492\n",
      "Iteration 6572, loss = 0.00358414\n",
      "Iteration 6573, loss = 0.00358346\n",
      "Iteration 6574, loss = 0.00358257\n",
      "Iteration 6575, loss = 0.00358185\n",
      "Iteration 6576, loss = 0.00358113\n",
      "Iteration 6577, loss = 0.00358054\n",
      "Iteration 6578, loss = 0.00357962\n",
      "Iteration 6579, loss = 0.00357891\n",
      "Iteration 6580, loss = 0.00357825\n",
      "Iteration 6581, loss = 0.00357756\n",
      "Iteration 6582, loss = 0.00357686\n",
      "Iteration 6583, loss = 0.00357639\n",
      "Iteration 6584, loss = 0.00357551\n",
      "Iteration 6585, loss = 0.00357478\n",
      "Iteration 6586, loss = 0.00357401\n",
      "Iteration 6587, loss = 0.00357371\n",
      "Iteration 6588, loss = 0.00357285\n",
      "Iteration 6589, loss = 0.00357207\n",
      "Iteration 6590, loss = 0.00357142\n",
      "Iteration 6591, loss = 0.00357075\n",
      "Iteration 6592, loss = 0.00356999\n",
      "Iteration 6593, loss = 0.00356941\n",
      "Iteration 6594, loss = 0.00356867\n",
      "Iteration 6595, loss = 0.00356835\n",
      "Iteration 6596, loss = 0.00356768\n",
      "Iteration 6597, loss = 0.00356726\n",
      "Iteration 6598, loss = 0.00356695\n",
      "Iteration 6599, loss = 0.00356596\n",
      "Iteration 6600, loss = 0.00356521\n",
      "Iteration 6601, loss = 0.00356453\n",
      "Iteration 6602, loss = 0.00356375\n",
      "Iteration 6603, loss = 0.00356319\n",
      "Iteration 6604, loss = 0.00356236\n",
      "Iteration 6605, loss = 0.00356172\n",
      "Iteration 6606, loss = 0.00356109\n",
      "Iteration 6607, loss = 0.00356032\n",
      "Iteration 6608, loss = 0.00355969\n",
      "Iteration 6609, loss = 0.00355902\n",
      "Iteration 6610, loss = 0.00355841\n",
      "Iteration 6611, loss = 0.00355812\n",
      "Iteration 6612, loss = 0.00355739\n",
      "Iteration 6613, loss = 0.00355662\n",
      "Iteration 6614, loss = 0.00355582\n",
      "Iteration 6615, loss = 0.00355521\n",
      "Iteration 6616, loss = 0.00355434\n",
      "Iteration 6617, loss = 0.00355376\n",
      "Iteration 6618, loss = 0.00355301\n",
      "Iteration 6619, loss = 0.00355235\n",
      "Iteration 6620, loss = 0.00355147\n",
      "Iteration 6621, loss = 0.00355065\n",
      "Iteration 6622, loss = 0.00355003\n",
      "Iteration 6623, loss = 0.00354926\n",
      "Iteration 6624, loss = 0.00354861\n",
      "Iteration 6625, loss = 0.00354783\n",
      "Iteration 6626, loss = 0.00354704\n",
      "Iteration 6627, loss = 0.00354632\n",
      "Iteration 6628, loss = 0.00354564\n",
      "Iteration 6629, loss = 0.00354499\n",
      "Iteration 6630, loss = 0.00354437\n",
      "Iteration 6631, loss = 0.00354371\n",
      "Iteration 6632, loss = 0.00354359\n",
      "Iteration 6633, loss = 0.00354274\n",
      "Iteration 6634, loss = 0.00354185\n",
      "Iteration 6635, loss = 0.00354113\n",
      "Iteration 6636, loss = 0.00354047\n",
      "Iteration 6637, loss = 0.00354001\n",
      "Iteration 6638, loss = 0.00353933\n",
      "Iteration 6639, loss = 0.00353877\n",
      "Iteration 6640, loss = 0.00353784\n",
      "Iteration 6641, loss = 0.00353712\n",
      "Iteration 6642, loss = 0.00353643\n",
      "Iteration 6643, loss = 0.00353574\n",
      "Iteration 6644, loss = 0.00353525\n",
      "Iteration 6645, loss = 0.00353429\n",
      "Iteration 6646, loss = 0.00353363\n",
      "Iteration 6647, loss = 0.00353303\n",
      "Iteration 6648, loss = 0.00353239\n",
      "Iteration 6649, loss = 0.00353157\n",
      "Iteration 6650, loss = 0.00353094\n",
      "Iteration 6651, loss = 0.00353027\n",
      "Iteration 6652, loss = 0.00352945\n",
      "Iteration 6653, loss = 0.00352894\n",
      "Iteration 6654, loss = 0.00352822\n",
      "Iteration 6655, loss = 0.00352742\n",
      "Iteration 6656, loss = 0.00352678\n",
      "Iteration 6657, loss = 0.00352611\n",
      "Iteration 6658, loss = 0.00352557\n",
      "Iteration 6659, loss = 0.00352485\n",
      "Iteration 6660, loss = 0.00352421\n",
      "Iteration 6661, loss = 0.00352374\n",
      "Iteration 6662, loss = 0.00352299\n",
      "Iteration 6663, loss = 0.00352222\n",
      "Iteration 6664, loss = 0.00352152\n",
      "Iteration 6665, loss = 0.00352091\n",
      "Iteration 6666, loss = 0.00352024\n",
      "Iteration 6667, loss = 0.00351943\n",
      "Iteration 6668, loss = 0.00351886\n",
      "Iteration 6669, loss = 0.00351832\n",
      "Iteration 6670, loss = 0.00351727\n",
      "Iteration 6671, loss = 0.00351668\n",
      "Iteration 6672, loss = 0.00351589\n",
      "Iteration 6673, loss = 0.00351518\n",
      "Iteration 6674, loss = 0.00351455\n",
      "Iteration 6675, loss = 0.00351380\n",
      "Iteration 6676, loss = 0.00351309\n",
      "Iteration 6677, loss = 0.00351238\n",
      "Iteration 6678, loss = 0.00351173\n",
      "Iteration 6679, loss = 0.00351114\n",
      "Iteration 6680, loss = 0.00351049\n",
      "Iteration 6681, loss = 0.00350980\n",
      "Iteration 6682, loss = 0.00350923\n",
      "Iteration 6683, loss = 0.00350850\n",
      "Iteration 6684, loss = 0.00350781\n",
      "Iteration 6685, loss = 0.00350720\n",
      "Iteration 6686, loss = 0.00350659\n",
      "Iteration 6687, loss = 0.00350617\n",
      "Iteration 6688, loss = 0.00350539\n",
      "Iteration 6689, loss = 0.00350468\n",
      "Iteration 6690, loss = 0.00350407\n",
      "Iteration 6691, loss = 0.00350344\n",
      "Iteration 6692, loss = 0.00350289\n",
      "Iteration 6693, loss = 0.00350228\n",
      "Iteration 6694, loss = 0.00350190\n",
      "Iteration 6695, loss = 0.00350109\n",
      "Iteration 6696, loss = 0.00350054\n",
      "Iteration 6697, loss = 0.00349987\n",
      "Iteration 6698, loss = 0.00349966\n",
      "Iteration 6699, loss = 0.00349870\n",
      "Iteration 6700, loss = 0.00349773\n",
      "Iteration 6701, loss = 0.00349702\n",
      "Iteration 6702, loss = 0.00349638\n",
      "Iteration 6703, loss = 0.00349568\n",
      "Iteration 6704, loss = 0.00349499\n",
      "Iteration 6705, loss = 0.00349463\n",
      "Iteration 6706, loss = 0.00349376\n",
      "Iteration 6707, loss = 0.00349292\n",
      "Iteration 6708, loss = 0.00349240\n",
      "Iteration 6709, loss = 0.00349156\n",
      "Iteration 6710, loss = 0.00349088\n",
      "Iteration 6711, loss = 0.00349022\n",
      "Iteration 6712, loss = 0.00348956\n",
      "Iteration 6713, loss = 0.00348902\n",
      "Iteration 6714, loss = 0.00348859\n",
      "Iteration 6715, loss = 0.00348792\n",
      "Iteration 6716, loss = 0.00348743\n",
      "Iteration 6717, loss = 0.00348705\n",
      "Iteration 6718, loss = 0.00348625\n",
      "Iteration 6719, loss = 0.00348562\n",
      "Iteration 6720, loss = 0.00348524\n",
      "Iteration 6721, loss = 0.00348453\n",
      "Iteration 6722, loss = 0.00348374\n",
      "Iteration 6723, loss = 0.00348308\n",
      "Iteration 6724, loss = 0.00348248\n",
      "Iteration 6725, loss = 0.00348202\n",
      "Iteration 6726, loss = 0.00348107\n",
      "Iteration 6727, loss = 0.00348043\n",
      "Iteration 6728, loss = 0.00347968\n",
      "Iteration 6729, loss = 0.00347896\n",
      "Iteration 6730, loss = 0.00347830\n",
      "Iteration 6731, loss = 0.00347772\n",
      "Iteration 6732, loss = 0.00347690\n",
      "Iteration 6733, loss = 0.00347625\n",
      "Iteration 6734, loss = 0.00347553\n",
      "Iteration 6735, loss = 0.00347486\n",
      "Iteration 6736, loss = 0.00347422\n",
      "Iteration 6737, loss = 0.00347371\n",
      "Iteration 6738, loss = 0.00347338\n",
      "Iteration 6739, loss = 0.00347243\n",
      "Iteration 6740, loss = 0.00347195\n",
      "Iteration 6741, loss = 0.00347114\n",
      "Iteration 6742, loss = 0.00347057\n",
      "Iteration 6743, loss = 0.00346988\n",
      "Iteration 6744, loss = 0.00346924\n",
      "Iteration 6745, loss = 0.00346869\n",
      "Iteration 6746, loss = 0.00346829\n",
      "Iteration 6747, loss = 0.00346770\n",
      "Iteration 6748, loss = 0.00346684\n",
      "Iteration 6749, loss = 0.00346592\n",
      "Iteration 6750, loss = 0.00346522\n",
      "Iteration 6751, loss = 0.00346453\n",
      "Iteration 6752, loss = 0.00346377\n",
      "Iteration 6753, loss = 0.00346321\n",
      "Iteration 6754, loss = 0.00346228\n",
      "Iteration 6755, loss = 0.00346165\n",
      "Iteration 6756, loss = 0.00346092\n",
      "Iteration 6757, loss = 0.00346029\n",
      "Iteration 6758, loss = 0.00345978\n",
      "Iteration 6759, loss = 0.00345917\n",
      "Iteration 6760, loss = 0.00345871\n",
      "Iteration 6761, loss = 0.00345824\n",
      "Iteration 6762, loss = 0.00345761\n",
      "Iteration 6763, loss = 0.00345699\n",
      "Iteration 6764, loss = 0.00345646\n",
      "Iteration 6765, loss = 0.00345583\n",
      "Iteration 6766, loss = 0.00345520\n",
      "Iteration 6767, loss = 0.00345459\n",
      "Iteration 6768, loss = 0.00345412\n",
      "Iteration 6769, loss = 0.00345363\n",
      "Iteration 6770, loss = 0.00345270\n",
      "Iteration 6771, loss = 0.00345181\n",
      "Iteration 6772, loss = 0.00345131\n",
      "Iteration 6773, loss = 0.00345055\n",
      "Iteration 6774, loss = 0.00344993\n",
      "Iteration 6775, loss = 0.00344914\n",
      "Iteration 6776, loss = 0.00344841\n",
      "Iteration 6777, loss = 0.00344779\n",
      "Iteration 6778, loss = 0.00344717\n",
      "Iteration 6779, loss = 0.00344673\n",
      "Iteration 6780, loss = 0.00344612\n",
      "Iteration 6781, loss = 0.00344526\n",
      "Iteration 6782, loss = 0.00344454\n",
      "Iteration 6783, loss = 0.00344392\n",
      "Iteration 6784, loss = 0.00344327\n",
      "Iteration 6785, loss = 0.00344270\n",
      "Iteration 6786, loss = 0.00344222\n",
      "Iteration 6787, loss = 0.00344152\n",
      "Iteration 6788, loss = 0.00344093\n",
      "Iteration 6789, loss = 0.00344035\n",
      "Iteration 6790, loss = 0.00343952\n",
      "Iteration 6791, loss = 0.00343892\n",
      "Iteration 6792, loss = 0.00343823\n",
      "Iteration 6793, loss = 0.00343759\n",
      "Iteration 6794, loss = 0.00343685\n",
      "Iteration 6795, loss = 0.00343624\n",
      "Iteration 6796, loss = 0.00343569\n",
      "Iteration 6797, loss = 0.00343513\n",
      "Iteration 6798, loss = 0.00343472\n",
      "Iteration 6799, loss = 0.00343397\n",
      "Iteration 6800, loss = 0.00343329\n",
      "Iteration 6801, loss = 0.00343267\n",
      "Iteration 6802, loss = 0.00343214\n",
      "Iteration 6803, loss = 0.00343150\n",
      "Iteration 6804, loss = 0.00343099\n",
      "Iteration 6805, loss = 0.00343070\n",
      "Iteration 6806, loss = 0.00342995\n",
      "Iteration 6807, loss = 0.00342922\n",
      "Iteration 6808, loss = 0.00342913\n",
      "Iteration 6809, loss = 0.00342811\n",
      "Iteration 6810, loss = 0.00342718\n",
      "Iteration 6811, loss = 0.00342663\n",
      "Iteration 6812, loss = 0.00342582\n",
      "Iteration 6813, loss = 0.00342517\n",
      "Iteration 6814, loss = 0.00342454\n",
      "Iteration 6815, loss = 0.00342397\n",
      "Iteration 6816, loss = 0.00342371\n",
      "Iteration 6817, loss = 0.00342280\n",
      "Iteration 6818, loss = 0.00342210\n",
      "Iteration 6819, loss = 0.00342119\n",
      "Iteration 6820, loss = 0.00342082\n",
      "Iteration 6821, loss = 0.00341994\n",
      "Iteration 6822, loss = 0.00341928\n",
      "Iteration 6823, loss = 0.00341858\n",
      "Iteration 6824, loss = 0.00341785\n",
      "Iteration 6825, loss = 0.00341719\n",
      "Iteration 6826, loss = 0.00341651\n",
      "Iteration 6827, loss = 0.00341592\n",
      "Iteration 6828, loss = 0.00341515\n",
      "Iteration 6829, loss = 0.00341464\n",
      "Iteration 6830, loss = 0.00341326\n",
      "Iteration 6831, loss = 0.00341283\n",
      "Iteration 6832, loss = 0.00341166\n",
      "Iteration 6833, loss = 0.00341078\n",
      "Iteration 6834, loss = 0.00341029\n",
      "Iteration 6835, loss = 0.00340915\n",
      "Iteration 6836, loss = 0.00340839\n",
      "Iteration 6837, loss = 0.00340769\n",
      "Iteration 6838, loss = 0.00340724\n",
      "Iteration 6839, loss = 0.00340627\n",
      "Iteration 6840, loss = 0.00340556\n",
      "Iteration 6841, loss = 0.00340507\n",
      "Iteration 6842, loss = 0.00340445\n",
      "Iteration 6843, loss = 0.00340371\n",
      "Iteration 6844, loss = 0.00340305\n",
      "Iteration 6845, loss = 0.00340254\n",
      "Iteration 6846, loss = 0.00340191\n",
      "Iteration 6847, loss = 0.00340125\n",
      "Iteration 6848, loss = 0.00340058\n",
      "Iteration 6849, loss = 0.00340023\n",
      "Iteration 6850, loss = 0.00339959\n",
      "Iteration 6851, loss = 0.00339900\n",
      "Iteration 6852, loss = 0.00339849\n",
      "Iteration 6853, loss = 0.00339783\n",
      "Iteration 6854, loss = 0.00339792\n",
      "Iteration 6855, loss = 0.00339679\n",
      "Iteration 6856, loss = 0.00339619\n",
      "Iteration 6857, loss = 0.00339547\n",
      "Iteration 6858, loss = 0.00339494\n",
      "Iteration 6859, loss = 0.00339414\n",
      "Iteration 6860, loss = 0.00339341\n",
      "Iteration 6861, loss = 0.00339250\n",
      "Iteration 6862, loss = 0.00339209\n",
      "Iteration 6863, loss = 0.00339125\n",
      "Iteration 6864, loss = 0.00339044\n",
      "Iteration 6865, loss = 0.00338985\n",
      "Iteration 6866, loss = 0.00338924\n",
      "Iteration 6867, loss = 0.00338859\n",
      "Iteration 6868, loss = 0.00338799\n",
      "Iteration 6869, loss = 0.00338727\n",
      "Iteration 6870, loss = 0.00338675\n",
      "Iteration 6871, loss = 0.00338617\n",
      "Iteration 6872, loss = 0.00338559\n",
      "Iteration 6873, loss = 0.00338478\n",
      "Iteration 6874, loss = 0.00338412\n",
      "Iteration 6875, loss = 0.00338347\n",
      "Iteration 6876, loss = 0.00338287\n",
      "Iteration 6877, loss = 0.00338233\n",
      "Iteration 6878, loss = 0.00338182\n",
      "Iteration 6879, loss = 0.00338128\n",
      "Iteration 6880, loss = 0.00338077\n",
      "Iteration 6881, loss = 0.00338033\n",
      "Iteration 6882, loss = 0.00337971\n",
      "Iteration 6883, loss = 0.00337918\n",
      "Iteration 6884, loss = 0.00337854\n",
      "Iteration 6885, loss = 0.00337814\n",
      "Iteration 6886, loss = 0.00337756\n",
      "Iteration 6887, loss = 0.00337715\n",
      "Iteration 6888, loss = 0.00337661\n",
      "Iteration 6889, loss = 0.00337621\n",
      "Iteration 6890, loss = 0.00337595\n",
      "Iteration 6891, loss = 0.00337514\n",
      "Iteration 6892, loss = 0.00337458\n",
      "Iteration 6893, loss = 0.00337388\n",
      "Iteration 6894, loss = 0.00337331\n",
      "Iteration 6895, loss = 0.00337233\n",
      "Iteration 6896, loss = 0.00337182\n",
      "Iteration 6897, loss = 0.00337117\n",
      "Iteration 6898, loss = 0.00337044\n",
      "Iteration 6899, loss = 0.00336901\n",
      "Iteration 6900, loss = 0.00336770\n",
      "Iteration 6901, loss = 0.00336668\n",
      "Iteration 6902, loss = 0.00336657\n",
      "Iteration 6903, loss = 0.00336574\n",
      "Iteration 6904, loss = 0.00336490\n",
      "Iteration 6905, loss = 0.00336409\n",
      "Iteration 6906, loss = 0.00336315\n",
      "Iteration 6907, loss = 0.00336256\n",
      "Iteration 6908, loss = 0.00336191\n",
      "Iteration 6909, loss = 0.00336127\n",
      "Iteration 6910, loss = 0.00336076\n",
      "Iteration 6911, loss = 0.00335995\n",
      "Iteration 6912, loss = 0.00335909\n",
      "Iteration 6913, loss = 0.00335839\n",
      "Iteration 6914, loss = 0.00335758\n",
      "Iteration 6915, loss = 0.00335706\n",
      "Iteration 6916, loss = 0.00335632\n",
      "Iteration 6917, loss = 0.00335570\n",
      "Iteration 6918, loss = 0.00335510\n",
      "Iteration 6919, loss = 0.00335471\n",
      "Iteration 6920, loss = 0.00335401\n",
      "Iteration 6921, loss = 0.00335340\n",
      "Iteration 6922, loss = 0.00335282\n",
      "Iteration 6923, loss = 0.00335220\n",
      "Iteration 6924, loss = 0.00335172\n",
      "Iteration 6925, loss = 0.00335101\n",
      "Iteration 6926, loss = 0.00335044\n",
      "Iteration 6927, loss = 0.00334988\n",
      "Iteration 6928, loss = 0.00334995\n",
      "Iteration 6929, loss = 0.00334884\n",
      "Iteration 6930, loss = 0.00334824\n",
      "Iteration 6931, loss = 0.00334767\n",
      "Iteration 6932, loss = 0.00334698\n",
      "Iteration 6933, loss = 0.00334633\n",
      "Iteration 6934, loss = 0.00334570\n",
      "Iteration 6935, loss = 0.00334501\n",
      "Iteration 6936, loss = 0.00334453\n",
      "Iteration 6937, loss = 0.00334394\n",
      "Iteration 6938, loss = 0.00334311\n",
      "Iteration 6939, loss = 0.00334256\n",
      "Iteration 6940, loss = 0.00334191\n",
      "Iteration 6941, loss = 0.00334134\n",
      "Iteration 6942, loss = 0.00334078\n",
      "Iteration 6943, loss = 0.00334027\n",
      "Iteration 6944, loss = 0.00333993\n",
      "Iteration 6945, loss = 0.00333909\n",
      "Iteration 6946, loss = 0.00333880\n",
      "Iteration 6947, loss = 0.00333795\n",
      "Iteration 6948, loss = 0.00333710\n",
      "Iteration 6949, loss = 0.00333632\n",
      "Iteration 6950, loss = 0.00333556\n",
      "Iteration 6951, loss = 0.00333494\n",
      "Iteration 6952, loss = 0.00333442\n",
      "Iteration 6953, loss = 0.00333378\n",
      "Iteration 6954, loss = 0.00333311\n",
      "Iteration 6955, loss = 0.00333257\n",
      "Iteration 6956, loss = 0.00333187\n",
      "Iteration 6957, loss = 0.00333124\n",
      "Iteration 6958, loss = 0.00333076\n",
      "Iteration 6959, loss = 0.00333016\n",
      "Iteration 6960, loss = 0.00332937\n",
      "Iteration 6961, loss = 0.00332859\n",
      "Iteration 6962, loss = 0.00332788\n",
      "Iteration 6963, loss = 0.00332713\n",
      "Iteration 6964, loss = 0.00332658\n",
      "Iteration 6965, loss = 0.00332603\n",
      "Iteration 6966, loss = 0.00332526\n",
      "Iteration 6967, loss = 0.00332467\n",
      "Iteration 6968, loss = 0.00332405\n",
      "Iteration 6969, loss = 0.00332353\n",
      "Iteration 6970, loss = 0.00332305\n",
      "Iteration 6971, loss = 0.00332254\n",
      "Iteration 6972, loss = 0.00332202\n",
      "Iteration 6973, loss = 0.00332154\n",
      "Iteration 6974, loss = 0.00332108\n",
      "Iteration 6975, loss = 0.00332081\n",
      "Iteration 6976, loss = 0.00332002\n",
      "Iteration 6977, loss = 0.00331931\n",
      "Iteration 6978, loss = 0.00331854\n",
      "Iteration 6979, loss = 0.00331771\n",
      "Iteration 6980, loss = 0.00331735\n",
      "Iteration 6981, loss = 0.00331644\n",
      "Iteration 6982, loss = 0.00331546\n",
      "Iteration 6983, loss = 0.00331465\n",
      "Iteration 6984, loss = 0.00331419\n",
      "Iteration 6985, loss = 0.00331336\n",
      "Iteration 6986, loss = 0.00331256\n",
      "Iteration 6987, loss = 0.00331208\n",
      "Iteration 6988, loss = 0.00331106\n",
      "Iteration 6989, loss = 0.00331034\n",
      "Iteration 6990, loss = 0.00330983\n",
      "Iteration 6991, loss = 0.00330906\n",
      "Iteration 6992, loss = 0.00330838\n",
      "Iteration 6993, loss = 0.00330771\n",
      "Iteration 6994, loss = 0.00330728\n",
      "Iteration 6995, loss = 0.00330654\n",
      "Iteration 6996, loss = 0.00330598\n",
      "Iteration 6997, loss = 0.00330528\n",
      "Iteration 6998, loss = 0.00330459\n",
      "Iteration 6999, loss = 0.00330416\n",
      "Iteration 7000, loss = 0.00330332\n",
      "Iteration 7001, loss = 0.00330272\n",
      "Iteration 7002, loss = 0.00330205\n",
      "Iteration 7003, loss = 0.00330171\n",
      "Iteration 7004, loss = 0.00330115\n",
      "Iteration 7005, loss = 0.00330076\n",
      "Iteration 7006, loss = 0.00329975\n",
      "Iteration 7007, loss = 0.00329915\n",
      "Iteration 7008, loss = 0.00329840\n",
      "Iteration 7009, loss = 0.00329793\n",
      "Iteration 7010, loss = 0.00329722\n",
      "Iteration 7011, loss = 0.00329656\n",
      "Iteration 7012, loss = 0.00329597\n",
      "Iteration 7013, loss = 0.00329535\n",
      "Iteration 7014, loss = 0.00329468\n",
      "Iteration 7015, loss = 0.00329405\n",
      "Iteration 7016, loss = 0.00329360\n",
      "Iteration 7017, loss = 0.00329303\n",
      "Iteration 7018, loss = 0.00329241\n",
      "Iteration 7019, loss = 0.00329195\n",
      "Iteration 7020, loss = 0.00329121\n",
      "Iteration 7021, loss = 0.00329063\n",
      "Iteration 7022, loss = 0.00329004\n",
      "Iteration 7023, loss = 0.00328950\n",
      "Iteration 7024, loss = 0.00328902\n",
      "Iteration 7025, loss = 0.00328833\n",
      "Iteration 7026, loss = 0.00328777\n",
      "Iteration 7027, loss = 0.00328715\n",
      "Iteration 7028, loss = 0.00328683\n",
      "Iteration 7029, loss = 0.00328612\n",
      "Iteration 7030, loss = 0.00328558\n",
      "Iteration 7031, loss = 0.00328446\n",
      "Iteration 7032, loss = 0.00328396\n",
      "Iteration 7033, loss = 0.00328350\n",
      "Iteration 7034, loss = 0.00328261\n",
      "Iteration 7035, loss = 0.00328196\n",
      "Iteration 7036, loss = 0.00328139\n",
      "Iteration 7037, loss = 0.00328076\n",
      "Iteration 7038, loss = 0.00328025\n",
      "Iteration 7039, loss = 0.00327967\n",
      "Iteration 7040, loss = 0.00327902\n",
      "Iteration 7041, loss = 0.00327828\n",
      "Iteration 7042, loss = 0.00327784\n",
      "Iteration 7043, loss = 0.00327721\n",
      "Iteration 7044, loss = 0.00327661\n",
      "Iteration 7045, loss = 0.00327594\n",
      "Iteration 7046, loss = 0.00327535\n",
      "Iteration 7047, loss = 0.00327485\n",
      "Iteration 7048, loss = 0.00327425\n",
      "Iteration 7049, loss = 0.00327426\n",
      "Iteration 7050, loss = 0.00327318\n",
      "Iteration 7051, loss = 0.00327269\n",
      "Iteration 7052, loss = 0.00327163\n",
      "Iteration 7053, loss = 0.00327093\n",
      "Iteration 7054, loss = 0.00327029\n",
      "Iteration 7055, loss = 0.00326996\n",
      "Iteration 7056, loss = 0.00326893\n",
      "Iteration 7057, loss = 0.00326812\n",
      "Iteration 7058, loss = 0.00326783\n",
      "Iteration 7059, loss = 0.00326680\n",
      "Iteration 7060, loss = 0.00326605\n",
      "Iteration 7061, loss = 0.00326571\n",
      "Iteration 7062, loss = 0.00326500\n",
      "Iteration 7063, loss = 0.00326419\n",
      "Iteration 7064, loss = 0.00326334\n",
      "Iteration 7065, loss = 0.00326254\n",
      "Iteration 7066, loss = 0.00326204\n",
      "Iteration 7067, loss = 0.00326156\n",
      "Iteration 7068, loss = 0.00326078\n",
      "Iteration 7069, loss = 0.00326015\n",
      "Iteration 7070, loss = 0.00325945\n",
      "Iteration 7071, loss = 0.00325874\n",
      "Iteration 7072, loss = 0.00325828\n",
      "Iteration 7073, loss = 0.00325765\n",
      "Iteration 7074, loss = 0.00325687\n",
      "Iteration 7075, loss = 0.00325613\n",
      "Iteration 7076, loss = 0.00325572\n",
      "Iteration 7077, loss = 0.00325504\n",
      "Iteration 7078, loss = 0.00325439\n",
      "Iteration 7079, loss = 0.00325376\n",
      "Iteration 7080, loss = 0.00325311\n",
      "Iteration 7081, loss = 0.00325246\n",
      "Iteration 7082, loss = 0.00325178\n",
      "Iteration 7083, loss = 0.00325123\n",
      "Iteration 7084, loss = 0.00325080\n",
      "Iteration 7085, loss = 0.00325032\n",
      "Iteration 7086, loss = 0.00324924\n",
      "Iteration 7087, loss = 0.00324863\n",
      "Iteration 7088, loss = 0.00324782\n",
      "Iteration 7089, loss = 0.00324702\n",
      "Iteration 7090, loss = 0.00324680\n",
      "Iteration 7091, loss = 0.00324599\n",
      "Iteration 7092, loss = 0.00324562\n",
      "Iteration 7093, loss = 0.00324464\n",
      "Iteration 7094, loss = 0.00324389\n",
      "Iteration 7095, loss = 0.00324322\n",
      "Iteration 7096, loss = 0.00324259\n",
      "Iteration 7097, loss = 0.00324183\n",
      "Iteration 7098, loss = 0.00324164\n",
      "Iteration 7099, loss = 0.00324085\n",
      "Iteration 7100, loss = 0.00324009\n",
      "Iteration 7101, loss = 0.00323960\n",
      "Iteration 7102, loss = 0.00323885\n",
      "Iteration 7103, loss = 0.00323818\n",
      "Iteration 7104, loss = 0.00323779\n",
      "Iteration 7105, loss = 0.00323738\n",
      "Iteration 7106, loss = 0.00323663\n",
      "Iteration 7107, loss = 0.00323617\n",
      "Iteration 7108, loss = 0.00323541\n",
      "Iteration 7109, loss = 0.00323501\n",
      "Iteration 7110, loss = 0.00323431\n",
      "Iteration 7111, loss = 0.00323377\n",
      "Iteration 7112, loss = 0.00323306\n",
      "Iteration 7113, loss = 0.00323249\n",
      "Iteration 7114, loss = 0.00323180\n",
      "Iteration 7115, loss = 0.00323109\n",
      "Iteration 7116, loss = 0.00323084\n",
      "Iteration 7117, loss = 0.00322989\n",
      "Iteration 7118, loss = 0.00322971\n",
      "Iteration 7119, loss = 0.00322894\n",
      "Iteration 7120, loss = 0.00322794\n",
      "Iteration 7121, loss = 0.00322736\n",
      "Iteration 7122, loss = 0.00322663\n",
      "Iteration 7123, loss = 0.00322603\n",
      "Iteration 7124, loss = 0.00322565\n",
      "Iteration 7125, loss = 0.00322470\n",
      "Iteration 7126, loss = 0.00322408\n",
      "Iteration 7127, loss = 0.00322350\n",
      "Iteration 7128, loss = 0.00322270\n",
      "Iteration 7129, loss = 0.00322202\n",
      "Iteration 7130, loss = 0.00322137\n",
      "Iteration 7131, loss = 0.00322078\n",
      "Iteration 7132, loss = 0.00322020\n",
      "Iteration 7133, loss = 0.00321959\n",
      "Iteration 7134, loss = 0.00321903\n",
      "Iteration 7135, loss = 0.00321838\n",
      "Iteration 7136, loss = 0.00321787\n",
      "Iteration 7137, loss = 0.00321703\n",
      "Iteration 7138, loss = 0.00321649\n",
      "Iteration 7139, loss = 0.00321573\n",
      "Iteration 7140, loss = 0.00321512\n",
      "Iteration 7141, loss = 0.00321503\n",
      "Iteration 7142, loss = 0.00321396\n",
      "Iteration 7143, loss = 0.00321333\n",
      "Iteration 7144, loss = 0.00321273\n",
      "Iteration 7145, loss = 0.00321218\n",
      "Iteration 7146, loss = 0.00321127\n",
      "Iteration 7147, loss = 0.00321072\n",
      "Iteration 7148, loss = 0.00321020\n",
      "Iteration 7149, loss = 0.00320960\n",
      "Iteration 7150, loss = 0.00320901\n",
      "Iteration 7151, loss = 0.00320860\n",
      "Iteration 7152, loss = 0.00320807\n",
      "Iteration 7153, loss = 0.00320755\n",
      "Iteration 7154, loss = 0.00320682\n",
      "Iteration 7155, loss = 0.00320628\n",
      "Iteration 7156, loss = 0.00320557\n",
      "Iteration 7157, loss = 0.00320534\n",
      "Iteration 7158, loss = 0.00320449\n",
      "Iteration 7159, loss = 0.00320392\n",
      "Iteration 7160, loss = 0.00320352\n",
      "Iteration 7161, loss = 0.00320264\n",
      "Iteration 7162, loss = 0.00320199\n",
      "Iteration 7163, loss = 0.00320152\n",
      "Iteration 7164, loss = 0.00320073\n",
      "Iteration 7165, loss = 0.00320004\n",
      "Iteration 7166, loss = 0.00319934\n",
      "Iteration 7167, loss = 0.00319906\n",
      "Iteration 7168, loss = 0.00319828\n",
      "Iteration 7169, loss = 0.00319749\n",
      "Iteration 7170, loss = 0.00319693\n",
      "Iteration 7171, loss = 0.00319621\n",
      "Iteration 7172, loss = 0.00319579\n",
      "Iteration 7173, loss = 0.00319498\n",
      "Iteration 7174, loss = 0.00319445\n",
      "Iteration 7175, loss = 0.00319380\n",
      "Iteration 7176, loss = 0.00319323\n",
      "Iteration 7177, loss = 0.00319274\n",
      "Iteration 7178, loss = 0.00319209\n",
      "Iteration 7179, loss = 0.00319147\n",
      "Iteration 7180, loss = 0.00319078\n",
      "Iteration 7181, loss = 0.00319020\n",
      "Iteration 7182, loss = 0.00318956\n",
      "Iteration 7183, loss = 0.00318904\n",
      "Iteration 7184, loss = 0.00318837\n",
      "Iteration 7185, loss = 0.00318795\n",
      "Iteration 7186, loss = 0.00318728\n",
      "Iteration 7187, loss = 0.00318662\n",
      "Iteration 7188, loss = 0.00318607\n",
      "Iteration 7189, loss = 0.00318540\n",
      "Iteration 7190, loss = 0.00318477\n",
      "Iteration 7191, loss = 0.00318417\n",
      "Iteration 7192, loss = 0.00318360\n",
      "Iteration 7193, loss = 0.00318302\n",
      "Iteration 7194, loss = 0.00318246\n",
      "Iteration 7195, loss = 0.00318206\n",
      "Iteration 7196, loss = 0.00318177\n",
      "Iteration 7197, loss = 0.00318072\n",
      "Iteration 7198, loss = 0.00318042\n",
      "Iteration 7199, loss = 0.00317958\n",
      "Iteration 7200, loss = 0.00317894\n",
      "Iteration 7201, loss = 0.00317830\n",
      "Iteration 7202, loss = 0.00317804\n",
      "Iteration 7203, loss = 0.00317699\n",
      "Iteration 7204, loss = 0.00317636\n",
      "Iteration 7205, loss = 0.00317579\n",
      "Iteration 7206, loss = 0.00317514\n",
      "Iteration 7207, loss = 0.00317438\n",
      "Iteration 7208, loss = 0.00317415\n",
      "Iteration 7209, loss = 0.00317353\n",
      "Iteration 7210, loss = 0.00317283\n",
      "Iteration 7211, loss = 0.00317213\n",
      "Iteration 7212, loss = 0.00317148\n",
      "Iteration 7213, loss = 0.00317094\n",
      "Iteration 7214, loss = 0.00317032\n",
      "Iteration 7215, loss = 0.00316965\n",
      "Iteration 7216, loss = 0.00316913\n",
      "Iteration 7217, loss = 0.00316837\n",
      "Iteration 7218, loss = 0.00316769\n",
      "Iteration 7219, loss = 0.00316712\n",
      "Iteration 7220, loss = 0.00316651\n",
      "Iteration 7221, loss = 0.00316595\n",
      "Iteration 7222, loss = 0.00316542\n",
      "Iteration 7223, loss = 0.00316495\n",
      "Iteration 7224, loss = 0.00316434\n",
      "Iteration 7225, loss = 0.00316372\n",
      "Iteration 7226, loss = 0.00316318\n",
      "Iteration 7227, loss = 0.00316247\n",
      "Iteration 7228, loss = 0.00316200\n",
      "Iteration 7229, loss = 0.00316142\n",
      "Iteration 7230, loss = 0.00316101\n",
      "Iteration 7231, loss = 0.00316027\n",
      "Iteration 7232, loss = 0.00315977\n",
      "Iteration 7233, loss = 0.00315913\n",
      "Iteration 7234, loss = 0.00315836\n",
      "Iteration 7235, loss = 0.00315774\n",
      "Iteration 7236, loss = 0.00315709\n",
      "Iteration 7237, loss = 0.00315653\n",
      "Iteration 7238, loss = 0.00315600\n",
      "Iteration 7239, loss = 0.00315536\n",
      "Iteration 7240, loss = 0.00315487\n",
      "Iteration 7241, loss = 0.00315423\n",
      "Iteration 7242, loss = 0.00315369\n",
      "Iteration 7243, loss = 0.00315310\n",
      "Iteration 7244, loss = 0.00315258\n",
      "Iteration 7245, loss = 0.00315209\n",
      "Iteration 7246, loss = 0.00315151\n",
      "Iteration 7247, loss = 0.00315111\n",
      "Iteration 7248, loss = 0.00315043\n",
      "Iteration 7249, loss = 0.00314996\n",
      "Iteration 7250, loss = 0.00314954\n",
      "Iteration 7251, loss = 0.00314889\n",
      "Iteration 7252, loss = 0.00314837\n",
      "Iteration 7253, loss = 0.00314785\n",
      "Iteration 7254, loss = 0.00314787\n",
      "Iteration 7255, loss = 0.00314660\n",
      "Iteration 7256, loss = 0.00314597\n",
      "Iteration 7257, loss = 0.00314575\n",
      "Iteration 7258, loss = 0.00314520\n",
      "Iteration 7259, loss = 0.00314438\n",
      "Iteration 7260, loss = 0.00314387\n",
      "Iteration 7261, loss = 0.00314325\n",
      "Iteration 7262, loss = 0.00314276\n",
      "Iteration 7263, loss = 0.00314199\n",
      "Iteration 7264, loss = 0.00314143\n",
      "Iteration 7265, loss = 0.00314081\n",
      "Iteration 7266, loss = 0.00314035\n",
      "Iteration 7267, loss = 0.00313971\n",
      "Iteration 7268, loss = 0.00313914\n",
      "Iteration 7269, loss = 0.00313854\n",
      "Iteration 7270, loss = 0.00313796\n",
      "Iteration 7271, loss = 0.00313738\n",
      "Iteration 7272, loss = 0.00313694\n",
      "Iteration 7273, loss = 0.00313651\n",
      "Iteration 7274, loss = 0.00313590\n",
      "Iteration 7275, loss = 0.00313525\n",
      "Iteration 7276, loss = 0.00313477\n",
      "Iteration 7277, loss = 0.00313428\n",
      "Iteration 7278, loss = 0.00313382\n",
      "Iteration 7279, loss = 0.00313338\n",
      "Iteration 7280, loss = 0.00313239\n",
      "Iteration 7281, loss = 0.00313211\n",
      "Iteration 7282, loss = 0.00313115\n",
      "Iteration 7283, loss = 0.00313095\n",
      "Iteration 7284, loss = 0.00313004\n",
      "Iteration 7285, loss = 0.00312920\n",
      "Iteration 7286, loss = 0.00312857\n",
      "Iteration 7287, loss = 0.00312767\n",
      "Iteration 7288, loss = 0.00312677\n",
      "Iteration 7289, loss = 0.00312675\n",
      "Iteration 7290, loss = 0.00312688\n",
      "Iteration 7291, loss = 0.00312596\n",
      "Iteration 7292, loss = 0.00312596\n",
      "Iteration 7293, loss = 0.00312491\n",
      "Iteration 7294, loss = 0.00312430\n",
      "Iteration 7295, loss = 0.00312387\n",
      "Iteration 7296, loss = 0.00312321\n",
      "Iteration 7297, loss = 0.00312315\n",
      "Iteration 7298, loss = 0.00312222\n",
      "Iteration 7299, loss = 0.00312168\n",
      "Iteration 7300, loss = 0.00312103\n",
      "Iteration 7301, loss = 0.00312072\n",
      "Iteration 7302, loss = 0.00312005\n",
      "Iteration 7303, loss = 0.00311962\n",
      "Iteration 7304, loss = 0.00311915\n",
      "Iteration 7305, loss = 0.00311832\n",
      "Iteration 7306, loss = 0.00311765\n",
      "Iteration 7307, loss = 0.00311700\n",
      "Iteration 7308, loss = 0.00311629\n",
      "Iteration 7309, loss = 0.00311612\n",
      "Iteration 7310, loss = 0.00311510\n",
      "Iteration 7311, loss = 0.00311473\n",
      "Iteration 7312, loss = 0.00311397\n",
      "Iteration 7313, loss = 0.00311334\n",
      "Iteration 7314, loss = 0.00311288\n",
      "Iteration 7315, loss = 0.00311226\n",
      "Iteration 7316, loss = 0.00311158\n",
      "Iteration 7317, loss = 0.00311119\n",
      "Iteration 7318, loss = 0.00311046\n",
      "Iteration 7319, loss = 0.00310983\n",
      "Iteration 7320, loss = 0.00310939\n",
      "Iteration 7321, loss = 0.00310869\n",
      "Iteration 7322, loss = 0.00310857\n",
      "Iteration 7323, loss = 0.00310768\n",
      "Iteration 7324, loss = 0.00310713\n",
      "Iteration 7325, loss = 0.00310667\n",
      "Iteration 7326, loss = 0.00310649\n",
      "Iteration 7327, loss = 0.00310569\n",
      "Iteration 7328, loss = 0.00310486\n",
      "Iteration 7329, loss = 0.00310467\n",
      "Iteration 7330, loss = 0.00310354\n",
      "Iteration 7331, loss = 0.00310318\n",
      "Iteration 7332, loss = 0.00310247\n",
      "Iteration 7333, loss = 0.00310240\n",
      "Iteration 7334, loss = 0.00310144\n",
      "Iteration 7335, loss = 0.00310078\n",
      "Iteration 7336, loss = 0.00310037\n",
      "Iteration 7337, loss = 0.00309956\n",
      "Iteration 7338, loss = 0.00309893\n",
      "Iteration 7339, loss = 0.00309849\n",
      "Iteration 7340, loss = 0.00309816\n",
      "Iteration 7341, loss = 0.00309731\n",
      "Iteration 7342, loss = 0.00309668\n",
      "Iteration 7343, loss = 0.00309612\n",
      "Iteration 7344, loss = 0.00309601\n",
      "Iteration 7345, loss = 0.00309537\n",
      "Iteration 7346, loss = 0.00309459\n",
      "Iteration 7347, loss = 0.00309406\n",
      "Iteration 7348, loss = 0.00309353\n",
      "Iteration 7349, loss = 0.00309298\n",
      "Iteration 7350, loss = 0.00309255\n",
      "Iteration 7351, loss = 0.00309187\n",
      "Iteration 7352, loss = 0.00309142\n",
      "Iteration 7353, loss = 0.00309073\n",
      "Iteration 7354, loss = 0.00309015\n",
      "Iteration 7355, loss = 0.00308948\n",
      "Iteration 7356, loss = 0.00308907\n",
      "Iteration 7357, loss = 0.00308836\n",
      "Iteration 7358, loss = 0.00308779\n",
      "Iteration 7359, loss = 0.00308714\n",
      "Iteration 7360, loss = 0.00308658\n",
      "Iteration 7361, loss = 0.00308600\n",
      "Iteration 7362, loss = 0.00308534\n",
      "Iteration 7363, loss = 0.00308481\n",
      "Iteration 7364, loss = 0.00308405\n",
      "Iteration 7365, loss = 0.00308383\n",
      "Iteration 7366, loss = 0.00308294\n",
      "Iteration 7367, loss = 0.00308232\n",
      "Iteration 7368, loss = 0.00308179\n",
      "Iteration 7369, loss = 0.00308119\n",
      "Iteration 7370, loss = 0.00308081\n",
      "Iteration 7371, loss = 0.00308013\n",
      "Iteration 7372, loss = 0.00307962\n",
      "Iteration 7373, loss = 0.00307904\n",
      "Iteration 7374, loss = 0.00307849\n",
      "Iteration 7375, loss = 0.00307806\n",
      "Iteration 7376, loss = 0.00307737\n",
      "Iteration 7377, loss = 0.00307684\n",
      "Iteration 7378, loss = 0.00307633\n",
      "Iteration 7379, loss = 0.00307565\n",
      "Iteration 7380, loss = 0.00307509\n",
      "Iteration 7381, loss = 0.00307443\n",
      "Iteration 7382, loss = 0.00307400\n",
      "Iteration 7383, loss = 0.00307328\n",
      "Iteration 7384, loss = 0.00307282\n",
      "Iteration 7385, loss = 0.00307220\n",
      "Iteration 7386, loss = 0.00307167\n",
      "Iteration 7387, loss = 0.00307107\n",
      "Iteration 7388, loss = 0.00307050\n",
      "Iteration 7389, loss = 0.00307005\n",
      "Iteration 7390, loss = 0.00306935\n",
      "Iteration 7391, loss = 0.00306876\n",
      "Iteration 7392, loss = 0.00306825\n",
      "Iteration 7393, loss = 0.00306753\n",
      "Iteration 7394, loss = 0.00306724\n",
      "Iteration 7395, loss = 0.00306637\n",
      "Iteration 7396, loss = 0.00306581\n",
      "Iteration 7397, loss = 0.00306526\n",
      "Iteration 7398, loss = 0.00306455\n",
      "Iteration 7399, loss = 0.00306398\n",
      "Iteration 7400, loss = 0.00306348\n",
      "Iteration 7401, loss = 0.00306294\n",
      "Iteration 7402, loss = 0.00306248\n",
      "Iteration 7403, loss = 0.00306180\n",
      "Iteration 7404, loss = 0.00306118\n",
      "Iteration 7405, loss = 0.00306058\n",
      "Iteration 7406, loss = 0.00305989\n",
      "Iteration 7407, loss = 0.00305976\n",
      "Iteration 7408, loss = 0.00305876\n",
      "Iteration 7409, loss = 0.00305815\n",
      "Iteration 7410, loss = 0.00305752\n",
      "Iteration 7411, loss = 0.00305730\n",
      "Iteration 7412, loss = 0.00305642\n",
      "Iteration 7413, loss = 0.00305586\n",
      "Iteration 7414, loss = 0.00305550\n",
      "Iteration 7415, loss = 0.00305468\n",
      "Iteration 7416, loss = 0.00305413\n",
      "Iteration 7417, loss = 0.00305347\n",
      "Iteration 7418, loss = 0.00305295\n",
      "Iteration 7419, loss = 0.00305217\n",
      "Iteration 7420, loss = 0.00305150\n",
      "Iteration 7421, loss = 0.00305105\n",
      "Iteration 7422, loss = 0.00305054\n",
      "Iteration 7423, loss = 0.00304976\n",
      "Iteration 7424, loss = 0.00304928\n",
      "Iteration 7425, loss = 0.00304869\n",
      "Iteration 7426, loss = 0.00304816\n",
      "Iteration 7427, loss = 0.00304756\n",
      "Iteration 7428, loss = 0.00304704\n",
      "Iteration 7429, loss = 0.00304656\n",
      "Iteration 7430, loss = 0.00304605\n",
      "Iteration 7431, loss = 0.00304539\n",
      "Iteration 7432, loss = 0.00304481\n",
      "Iteration 7433, loss = 0.00304453\n",
      "Iteration 7434, loss = 0.00304388\n",
      "Iteration 7435, loss = 0.00304358\n",
      "Iteration 7436, loss = 0.00304304\n",
      "Iteration 7437, loss = 0.00304254\n",
      "Iteration 7438, loss = 0.00304197\n",
      "Iteration 7439, loss = 0.00304175\n",
      "Iteration 7440, loss = 0.00304121\n",
      "Iteration 7441, loss = 0.00304050\n",
      "Iteration 7442, loss = 0.00304002\n",
      "Iteration 7443, loss = 0.00303943\n",
      "Iteration 7444, loss = 0.00303894\n",
      "Iteration 7445, loss = 0.00303828\n",
      "Iteration 7446, loss = 0.00303754\n",
      "Iteration 7447, loss = 0.00303696\n",
      "Iteration 7448, loss = 0.00303656\n",
      "Iteration 7449, loss = 0.00303586\n",
      "Iteration 7450, loss = 0.00303539\n",
      "Iteration 7451, loss = 0.00303489\n",
      "Iteration 7452, loss = 0.00303448\n",
      "Iteration 7453, loss = 0.00303387\n",
      "Iteration 7454, loss = 0.00303336\n",
      "Iteration 7455, loss = 0.00303332\n",
      "Iteration 7456, loss = 0.00303239\n",
      "Iteration 7457, loss = 0.00303200\n",
      "Iteration 7458, loss = 0.00303131\n",
      "Iteration 7459, loss = 0.00303069\n",
      "Iteration 7460, loss = 0.00303017\n",
      "Iteration 7461, loss = 0.00303025\n",
      "Iteration 7462, loss = 0.00302922\n",
      "Iteration 7463, loss = 0.00302880\n",
      "Iteration 7464, loss = 0.00302810\n",
      "Iteration 7465, loss = 0.00302763\n",
      "Iteration 7466, loss = 0.00302690\n",
      "Iteration 7467, loss = 0.00302645\n",
      "Iteration 7468, loss = 0.00302591\n",
      "Iteration 7469, loss = 0.00302558\n",
      "Iteration 7470, loss = 0.00302485\n",
      "Iteration 7471, loss = 0.00302429\n",
      "Iteration 7472, loss = 0.00302377\n",
      "Iteration 7473, loss = 0.00302333\n",
      "Iteration 7474, loss = 0.00302269\n",
      "Iteration 7475, loss = 0.00302226\n",
      "Iteration 7476, loss = 0.00302164\n",
      "Iteration 7477, loss = 0.00302123\n",
      "Iteration 7478, loss = 0.00302065\n",
      "Iteration 7479, loss = 0.00302017\n",
      "Iteration 7480, loss = 0.00301953\n",
      "Iteration 7481, loss = 0.00301891\n",
      "Iteration 7482, loss = 0.00301837\n",
      "Iteration 7483, loss = 0.00301782\n",
      "Iteration 7484, loss = 0.00301715\n",
      "Iteration 7485, loss = 0.00301660\n",
      "Iteration 7486, loss = 0.00301602\n",
      "Iteration 7487, loss = 0.00301519\n",
      "Iteration 7488, loss = 0.00301473\n",
      "Iteration 7489, loss = 0.00301397\n",
      "Iteration 7490, loss = 0.00301346\n",
      "Iteration 7491, loss = 0.00301291\n",
      "Iteration 7492, loss = 0.00301242\n",
      "Iteration 7493, loss = 0.00301177\n",
      "Iteration 7494, loss = 0.00301124\n",
      "Iteration 7495, loss = 0.00301075\n",
      "Iteration 7496, loss = 0.00301024\n",
      "Iteration 7497, loss = 0.00300974\n",
      "Iteration 7498, loss = 0.00300969\n",
      "Iteration 7499, loss = 0.00300872\n",
      "Iteration 7500, loss = 0.00300829\n",
      "Iteration 7501, loss = 0.00300784\n",
      "Iteration 7502, loss = 0.00300739\n",
      "Iteration 7503, loss = 0.00300689\n",
      "Iteration 7504, loss = 0.00300627\n",
      "Iteration 7505, loss = 0.00300583\n",
      "Iteration 7506, loss = 0.00300523\n",
      "Iteration 7507, loss = 0.00300461\n",
      "Iteration 7508, loss = 0.00300403\n",
      "Iteration 7509, loss = 0.00300365\n",
      "Iteration 7510, loss = 0.00300316\n",
      "Iteration 7511, loss = 0.00300246\n",
      "Iteration 7512, loss = 0.00300180\n",
      "Iteration 7513, loss = 0.00300126\n",
      "Iteration 7514, loss = 0.00300074\n",
      "Iteration 7515, loss = 0.00300037\n",
      "Iteration 7516, loss = 0.00299972\n",
      "Iteration 7517, loss = 0.00299922\n",
      "Iteration 7518, loss = 0.00299869\n",
      "Iteration 7519, loss = 0.00299806\n",
      "Iteration 7520, loss = 0.00299753\n",
      "Iteration 7521, loss = 0.00299706\n",
      "Iteration 7522, loss = 0.00299665\n",
      "Iteration 7523, loss = 0.00299601\n",
      "Iteration 7524, loss = 0.00299545\n",
      "Iteration 7525, loss = 0.00299488\n",
      "Iteration 7526, loss = 0.00299446\n",
      "Iteration 7527, loss = 0.00299383\n",
      "Iteration 7528, loss = 0.00299327\n",
      "Iteration 7529, loss = 0.00299281\n",
      "Iteration 7530, loss = 0.00299231\n",
      "Iteration 7531, loss = 0.00299192\n",
      "Iteration 7532, loss = 0.00299131\n",
      "Iteration 7533, loss = 0.00299082\n",
      "Iteration 7534, loss = 0.00299030\n",
      "Iteration 7535, loss = 0.00298990\n",
      "Iteration 7536, loss = 0.00298944\n",
      "Iteration 7537, loss = 0.00298867\n",
      "Iteration 7538, loss = 0.00298818\n",
      "Iteration 7539, loss = 0.00298769\n",
      "Iteration 7540, loss = 0.00298710\n",
      "Iteration 7541, loss = 0.00298635\n",
      "Iteration 7542, loss = 0.00298591\n",
      "Iteration 7543, loss = 0.00298532\n",
      "Iteration 7544, loss = 0.00298479\n",
      "Iteration 7545, loss = 0.00298419\n",
      "Iteration 7546, loss = 0.00298391\n",
      "Iteration 7547, loss = 0.00298344\n",
      "Iteration 7548, loss = 0.00298276\n",
      "Iteration 7549, loss = 0.00298227\n",
      "Iteration 7550, loss = 0.00298164\n",
      "Iteration 7551, loss = 0.00298105\n",
      "Iteration 7552, loss = 0.00298056\n",
      "Iteration 7553, loss = 0.00298001\n",
      "Iteration 7554, loss = 0.00297939\n",
      "Iteration 7555, loss = 0.00297880\n",
      "Iteration 7556, loss = 0.00297833\n",
      "Iteration 7557, loss = 0.00297787\n",
      "Iteration 7558, loss = 0.00297715\n",
      "Iteration 7559, loss = 0.00297650\n",
      "Iteration 7560, loss = 0.00297611\n",
      "Iteration 7561, loss = 0.00297545\n",
      "Iteration 7562, loss = 0.00297520\n",
      "Iteration 7563, loss = 0.00297437\n",
      "Iteration 7564, loss = 0.00297389\n",
      "Iteration 7565, loss = 0.00297349\n",
      "Iteration 7566, loss = 0.00297290\n",
      "Iteration 7567, loss = 0.00297257\n",
      "Iteration 7568, loss = 0.00297214\n",
      "Iteration 7569, loss = 0.00297146\n",
      "Iteration 7570, loss = 0.00297093\n",
      "Iteration 7571, loss = 0.00297042\n",
      "Iteration 7572, loss = 0.00296998\n",
      "Iteration 7573, loss = 0.00296948\n",
      "Iteration 7574, loss = 0.00296899\n",
      "Iteration 7575, loss = 0.00296849\n",
      "Iteration 7576, loss = 0.00296781\n",
      "Iteration 7577, loss = 0.00296722\n",
      "Iteration 7578, loss = 0.00296664\n",
      "Iteration 7579, loss = 0.00296609\n",
      "Iteration 7580, loss = 0.00296566\n",
      "Iteration 7581, loss = 0.00296500\n",
      "Iteration 7582, loss = 0.00296452\n",
      "Iteration 7583, loss = 0.00296392\n",
      "Iteration 7584, loss = 0.00296346\n",
      "Iteration 7585, loss = 0.00296281\n",
      "Iteration 7586, loss = 0.00296250\n",
      "Iteration 7587, loss = 0.00296176\n",
      "Iteration 7588, loss = 0.00296163\n",
      "Iteration 7589, loss = 0.00296072\n",
      "Iteration 7590, loss = 0.00296042\n",
      "Iteration 7591, loss = 0.00295994\n",
      "Iteration 7592, loss = 0.00295918\n",
      "Iteration 7593, loss = 0.00295866\n",
      "Iteration 7594, loss = 0.00295810\n",
      "Iteration 7595, loss = 0.00295768\n",
      "Iteration 7596, loss = 0.00295710\n",
      "Iteration 7597, loss = 0.00295659\n",
      "Iteration 7598, loss = 0.00295594\n",
      "Iteration 7599, loss = 0.00295552\n",
      "Iteration 7600, loss = 0.00295483\n",
      "Iteration 7601, loss = 0.00295440\n",
      "Iteration 7602, loss = 0.00295389\n",
      "Iteration 7603, loss = 0.00295352\n",
      "Iteration 7604, loss = 0.00295287\n",
      "Iteration 7605, loss = 0.00295245\n",
      "Iteration 7606, loss = 0.00295186\n",
      "Iteration 7607, loss = 0.00295138\n",
      "Iteration 7608, loss = 0.00295088\n",
      "Iteration 7609, loss = 0.00295038\n",
      "Iteration 7610, loss = 0.00295000\n",
      "Iteration 7611, loss = 0.00294939\n",
      "Iteration 7612, loss = 0.00294874\n",
      "Iteration 7613, loss = 0.00294850\n",
      "Iteration 7614, loss = 0.00294778\n",
      "Iteration 7615, loss = 0.00294732\n",
      "Iteration 7616, loss = 0.00294663\n",
      "Iteration 7617, loss = 0.00294596\n",
      "Iteration 7618, loss = 0.00294581\n",
      "Iteration 7619, loss = 0.00294507\n",
      "Iteration 7620, loss = 0.00294447\n",
      "Iteration 7621, loss = 0.00294445\n",
      "Iteration 7622, loss = 0.00294354\n",
      "Iteration 7623, loss = 0.00294298\n",
      "Iteration 7624, loss = 0.00294245\n",
      "Iteration 7625, loss = 0.00294212\n",
      "Iteration 7626, loss = 0.00294141\n",
      "Iteration 7627, loss = 0.00294089\n",
      "Iteration 7628, loss = 0.00294034\n",
      "Iteration 7629, loss = 0.00293984\n",
      "Iteration 7630, loss = 0.00293941\n",
      "Iteration 7631, loss = 0.00293921\n",
      "Iteration 7632, loss = 0.00293813\n",
      "Iteration 7633, loss = 0.00293750\n",
      "Iteration 7634, loss = 0.00293710\n",
      "Iteration 7635, loss = 0.00293648\n",
      "Iteration 7636, loss = 0.00293593\n",
      "Iteration 7637, loss = 0.00293534\n",
      "Iteration 7638, loss = 0.00293481\n",
      "Iteration 7639, loss = 0.00293447\n",
      "Iteration 7640, loss = 0.00293384\n",
      "Iteration 7641, loss = 0.00293347\n",
      "Iteration 7642, loss = 0.00293289\n",
      "Iteration 7643, loss = 0.00293231\n",
      "Iteration 7644, loss = 0.00293205\n",
      "Iteration 7645, loss = 0.00293132\n",
      "Iteration 7646, loss = 0.00293087\n",
      "Iteration 7647, loss = 0.00293027\n",
      "Iteration 7648, loss = 0.00292980\n",
      "Iteration 7649, loss = 0.00292932\n",
      "Iteration 7650, loss = 0.00292871\n",
      "Iteration 7651, loss = 0.00292832\n",
      "Iteration 7652, loss = 0.00292774\n",
      "Iteration 7653, loss = 0.00292716\n",
      "Iteration 7654, loss = 0.00292658\n",
      "Iteration 7655, loss = 0.00292605\n",
      "Iteration 7656, loss = 0.00292583\n",
      "Iteration 7657, loss = 0.00292504\n",
      "Iteration 7658, loss = 0.00292442\n",
      "Iteration 7659, loss = 0.00292387\n",
      "Iteration 7660, loss = 0.00292332\n",
      "Iteration 7661, loss = 0.00292301\n",
      "Iteration 7662, loss = 0.00292232\n",
      "Iteration 7663, loss = 0.00292175\n",
      "Iteration 7664, loss = 0.00292137\n",
      "Iteration 7665, loss = 0.00292119\n",
      "Iteration 7666, loss = 0.00292032\n",
      "Iteration 7667, loss = 0.00291974\n",
      "Iteration 7668, loss = 0.00291904\n",
      "Iteration 7669, loss = 0.00291869\n",
      "Iteration 7670, loss = 0.00291799\n",
      "Iteration 7671, loss = 0.00291758\n",
      "Iteration 7672, loss = 0.00291719\n",
      "Iteration 7673, loss = 0.00291639\n",
      "Iteration 7674, loss = 0.00291600\n",
      "Iteration 7675, loss = 0.00291542\n",
      "Iteration 7676, loss = 0.00291489\n",
      "Iteration 7677, loss = 0.00291447\n",
      "Iteration 7678, loss = 0.00291377\n",
      "Iteration 7679, loss = 0.00291334\n",
      "Iteration 7680, loss = 0.00291272\n",
      "Iteration 7681, loss = 0.00291220\n",
      "Iteration 7682, loss = 0.00291176\n",
      "Iteration 7683, loss = 0.00291116\n",
      "Iteration 7684, loss = 0.00291072\n",
      "Iteration 7685, loss = 0.00291020\n",
      "Iteration 7686, loss = 0.00290966\n",
      "Iteration 7687, loss = 0.00290937\n",
      "Iteration 7688, loss = 0.00290879\n",
      "Iteration 7689, loss = 0.00290822\n",
      "Iteration 7690, loss = 0.00290777\n",
      "Iteration 7691, loss = 0.00290726\n",
      "Iteration 7692, loss = 0.00290680\n",
      "Iteration 7693, loss = 0.00290626\n",
      "Iteration 7694, loss = 0.00290587\n",
      "Iteration 7695, loss = 0.00290542\n",
      "Iteration 7696, loss = 0.00290495\n",
      "Iteration 7697, loss = 0.00290446\n",
      "Iteration 7698, loss = 0.00290401\n",
      "Iteration 7699, loss = 0.00290375\n",
      "Iteration 7700, loss = 0.00290318\n",
      "Iteration 7701, loss = 0.00290268\n",
      "Iteration 7702, loss = 0.00290214\n",
      "Iteration 7703, loss = 0.00290165\n",
      "Iteration 7704, loss = 0.00290113\n",
      "Iteration 7705, loss = 0.00290063\n",
      "Iteration 7706, loss = 0.00290012\n",
      "Iteration 7707, loss = 0.00289967\n",
      "Iteration 7708, loss = 0.00289983\n",
      "Iteration 7709, loss = 0.00289865\n",
      "Iteration 7710, loss = 0.00289839\n",
      "Iteration 7711, loss = 0.00289769\n",
      "Iteration 7712, loss = 0.00289716\n",
      "Iteration 7713, loss = 0.00289660\n",
      "Iteration 7714, loss = 0.00289602\n",
      "Iteration 7715, loss = 0.00289548\n",
      "Iteration 7716, loss = 0.00289503\n",
      "Iteration 7717, loss = 0.00289450\n",
      "Iteration 7718, loss = 0.00289402\n",
      "Iteration 7719, loss = 0.00289350\n",
      "Iteration 7720, loss = 0.00289310\n",
      "Iteration 7721, loss = 0.00289291\n",
      "Iteration 7722, loss = 0.00289216\n",
      "Iteration 7723, loss = 0.00289167\n",
      "Iteration 7724, loss = 0.00289116\n",
      "Iteration 7725, loss = 0.00289065\n",
      "Iteration 7726, loss = 0.00289007\n",
      "Iteration 7727, loss = 0.00288958\n",
      "Iteration 7728, loss = 0.00288916\n",
      "Iteration 7729, loss = 0.00288870\n",
      "Iteration 7730, loss = 0.00288799\n",
      "Iteration 7731, loss = 0.00288745\n",
      "Iteration 7732, loss = 0.00288695\n",
      "Iteration 7733, loss = 0.00288650\n",
      "Iteration 7734, loss = 0.00288597\n",
      "Iteration 7735, loss = 0.00288556\n",
      "Iteration 7736, loss = 0.00288505\n",
      "Iteration 7737, loss = 0.00288468\n",
      "Iteration 7738, loss = 0.00288424\n",
      "Iteration 7739, loss = 0.00288375\n",
      "Iteration 7740, loss = 0.00288331\n",
      "Iteration 7741, loss = 0.00288282\n",
      "Iteration 7742, loss = 0.00288320\n",
      "Iteration 7743, loss = 0.00288202\n",
      "Iteration 7744, loss = 0.00288150\n",
      "Iteration 7745, loss = 0.00288095\n",
      "Iteration 7746, loss = 0.00288061\n",
      "Iteration 7747, loss = 0.00288001\n",
      "Iteration 7748, loss = 0.00287955\n",
      "Iteration 7749, loss = 0.00287893\n",
      "Iteration 7750, loss = 0.00287838\n",
      "Iteration 7751, loss = 0.00287783\n",
      "Iteration 7752, loss = 0.00287745\n",
      "Iteration 7753, loss = 0.00287681\n",
      "Iteration 7754, loss = 0.00287634\n",
      "Iteration 7755, loss = 0.00287594\n",
      "Iteration 7756, loss = 0.00287557\n",
      "Iteration 7757, loss = 0.00287487\n",
      "Iteration 7758, loss = 0.00287433\n",
      "Iteration 7759, loss = 0.00287398\n",
      "Iteration 7760, loss = 0.00287336\n",
      "Iteration 7761, loss = 0.00287287\n",
      "Iteration 7762, loss = 0.00287221\n",
      "Iteration 7763, loss = 0.00287156\n",
      "Iteration 7764, loss = 0.00287127\n",
      "Iteration 7765, loss = 0.00287050\n",
      "Iteration 7766, loss = 0.00286987\n",
      "Iteration 7767, loss = 0.00286958\n",
      "Iteration 7768, loss = 0.00286907\n",
      "Iteration 7769, loss = 0.00286854\n",
      "Iteration 7770, loss = 0.00286788\n",
      "Iteration 7771, loss = 0.00286727\n",
      "Iteration 7772, loss = 0.00286690\n",
      "Iteration 7773, loss = 0.00286620\n",
      "Iteration 7774, loss = 0.00286561\n",
      "Iteration 7775, loss = 0.00286513\n",
      "Iteration 7776, loss = 0.00286458\n",
      "Iteration 7777, loss = 0.00286437\n",
      "Iteration 7778, loss = 0.00286371\n",
      "Iteration 7779, loss = 0.00286314\n",
      "Iteration 7780, loss = 0.00286272\n",
      "Iteration 7781, loss = 0.00286232\n",
      "Iteration 7782, loss = 0.00286178\n",
      "Iteration 7783, loss = 0.00286120\n",
      "Iteration 7784, loss = 0.00286086\n",
      "Iteration 7785, loss = 0.00286034\n",
      "Iteration 7786, loss = 0.00285974\n",
      "Iteration 7787, loss = 0.00285918\n",
      "Iteration 7788, loss = 0.00285870\n",
      "Iteration 7789, loss = 0.00285833\n",
      "Iteration 7790, loss = 0.00285754\n",
      "Iteration 7791, loss = 0.00285686\n",
      "Iteration 7792, loss = 0.00285667\n",
      "Iteration 7793, loss = 0.00285588\n",
      "Iteration 7794, loss = 0.00285552\n",
      "Iteration 7795, loss = 0.00285494\n",
      "Iteration 7796, loss = 0.00285482\n",
      "Iteration 7797, loss = 0.00285405\n",
      "Iteration 7798, loss = 0.00285352\n",
      "Iteration 7799, loss = 0.00285310\n",
      "Iteration 7800, loss = 0.00285261\n",
      "Iteration 7801, loss = 0.00285211\n",
      "Iteration 7802, loss = 0.00285162\n",
      "Iteration 7803, loss = 0.00285119\n",
      "Iteration 7804, loss = 0.00285080\n",
      "Iteration 7805, loss = 0.00285018\n",
      "Iteration 7806, loss = 0.00284960\n",
      "Iteration 7807, loss = 0.00284928\n",
      "Iteration 7808, loss = 0.00284866\n",
      "Iteration 7809, loss = 0.00284822\n",
      "Iteration 7810, loss = 0.00284771\n",
      "Iteration 7811, loss = 0.00284719\n",
      "Iteration 7812, loss = 0.00284667\n",
      "Iteration 7813, loss = 0.00284658\n",
      "Iteration 7814, loss = 0.00284597\n",
      "Iteration 7815, loss = 0.00284538\n",
      "Iteration 7816, loss = 0.00284486\n",
      "Iteration 7817, loss = 0.00284450\n",
      "Iteration 7818, loss = 0.00284397\n",
      "Iteration 7819, loss = 0.00284330\n",
      "Iteration 7820, loss = 0.00284280\n",
      "Iteration 7821, loss = 0.00284223\n",
      "Iteration 7822, loss = 0.00284192\n",
      "Iteration 7823, loss = 0.00284119\n",
      "Iteration 7824, loss = 0.00284062\n",
      "Iteration 7825, loss = 0.00284018\n",
      "Iteration 7826, loss = 0.00283981\n",
      "Iteration 7827, loss = 0.00283911\n",
      "Iteration 7828, loss = 0.00283856\n",
      "Iteration 7829, loss = 0.00283811\n",
      "Iteration 7830, loss = 0.00283760\n",
      "Iteration 7831, loss = 0.00283715\n",
      "Iteration 7832, loss = 0.00283665\n",
      "Iteration 7833, loss = 0.00283640\n",
      "Iteration 7834, loss = 0.00283572\n",
      "Iteration 7835, loss = 0.00283542\n",
      "Iteration 7836, loss = 0.00283478\n",
      "Iteration 7837, loss = 0.00283425\n",
      "Iteration 7838, loss = 0.00283382\n",
      "Iteration 7839, loss = 0.00283406\n",
      "Iteration 7840, loss = 0.00283281\n",
      "Iteration 7841, loss = 0.00283244\n",
      "Iteration 7842, loss = 0.00283175\n",
      "Iteration 7843, loss = 0.00283127\n",
      "Iteration 7844, loss = 0.00283091\n",
      "Iteration 7845, loss = 0.00283025\n",
      "Iteration 7846, loss = 0.00282972\n",
      "Iteration 7847, loss = 0.00282935\n",
      "Iteration 7848, loss = 0.00282897\n",
      "Iteration 7849, loss = 0.00282860\n",
      "Iteration 7850, loss = 0.00282789\n",
      "Iteration 7851, loss = 0.00282746\n",
      "Iteration 7852, loss = 0.00282668\n",
      "Iteration 7853, loss = 0.00282609\n",
      "Iteration 7854, loss = 0.00282572\n",
      "Iteration 7855, loss = 0.00282525\n",
      "Iteration 7856, loss = 0.00282468\n",
      "Iteration 7857, loss = 0.00282438\n",
      "Iteration 7858, loss = 0.00282381\n",
      "Iteration 7859, loss = 0.00282346\n",
      "Iteration 7860, loss = 0.00282288\n",
      "Iteration 7861, loss = 0.00282237\n",
      "Iteration 7862, loss = 0.00282192\n",
      "Iteration 7863, loss = 0.00282144\n",
      "Iteration 7864, loss = 0.00282101\n",
      "Iteration 7865, loss = 0.00282062\n",
      "Iteration 7866, loss = 0.00282007\n",
      "Iteration 7867, loss = 0.00281961\n",
      "Iteration 7868, loss = 0.00281934\n",
      "Iteration 7869, loss = 0.00281858\n",
      "Iteration 7870, loss = 0.00281815\n",
      "Iteration 7871, loss = 0.00281769\n",
      "Iteration 7872, loss = 0.00281743\n",
      "Iteration 7873, loss = 0.00281678\n",
      "Iteration 7874, loss = 0.00281635\n",
      "Iteration 7875, loss = 0.00281590\n",
      "Iteration 7876, loss = 0.00281541\n",
      "Iteration 7877, loss = 0.00281510\n",
      "Iteration 7878, loss = 0.00281449\n",
      "Iteration 7879, loss = 0.00281408\n",
      "Iteration 7880, loss = 0.00281352\n",
      "Iteration 7881, loss = 0.00281305\n",
      "Iteration 7882, loss = 0.00281283\n",
      "Iteration 7883, loss = 0.00281206\n",
      "Iteration 7884, loss = 0.00281155\n",
      "Iteration 7885, loss = 0.00281101\n",
      "Iteration 7886, loss = 0.00281050\n",
      "Iteration 7887, loss = 0.00281029\n",
      "Iteration 7888, loss = 0.00280983\n",
      "Iteration 7889, loss = 0.00280928\n",
      "Iteration 7890, loss = 0.00280883\n",
      "Iteration 7891, loss = 0.00280814\n",
      "Iteration 7892, loss = 0.00280791\n",
      "Iteration 7893, loss = 0.00280716\n",
      "Iteration 7894, loss = 0.00280657\n",
      "Iteration 7895, loss = 0.00280606\n",
      "Iteration 7896, loss = 0.00280549\n",
      "Iteration 7897, loss = 0.00280494\n",
      "Iteration 7898, loss = 0.00280447\n",
      "Iteration 7899, loss = 0.00280392\n",
      "Iteration 7900, loss = 0.00280333\n",
      "Iteration 7901, loss = 0.00280276\n",
      "Iteration 7902, loss = 0.00280241\n",
      "Iteration 7903, loss = 0.00280224\n",
      "Iteration 7904, loss = 0.00280159\n",
      "Iteration 7905, loss = 0.00280101\n",
      "Iteration 7906, loss = 0.00280053\n",
      "Iteration 7907, loss = 0.00280029\n",
      "Iteration 7908, loss = 0.00279965\n",
      "Iteration 7909, loss = 0.00279922\n",
      "Iteration 7910, loss = 0.00279907\n",
      "Iteration 7911, loss = 0.00279838\n",
      "Iteration 7912, loss = 0.00279797\n",
      "Iteration 7913, loss = 0.00279747\n",
      "Iteration 7914, loss = 0.00279748\n",
      "Iteration 7915, loss = 0.00279675\n",
      "Iteration 7916, loss = 0.00279610\n",
      "Iteration 7917, loss = 0.00279570\n",
      "Iteration 7918, loss = 0.00279516\n",
      "Iteration 7919, loss = 0.00279464\n",
      "Iteration 7920, loss = 0.00279419\n",
      "Iteration 7921, loss = 0.00279374\n",
      "Iteration 7922, loss = 0.00279316\n",
      "Iteration 7923, loss = 0.00279289\n",
      "Iteration 7924, loss = 0.00279224\n",
      "Iteration 7925, loss = 0.00279182\n",
      "Iteration 7926, loss = 0.00279150\n",
      "Iteration 7927, loss = 0.00279092\n",
      "Iteration 7928, loss = 0.00279090\n",
      "Iteration 7929, loss = 0.00278982\n",
      "Iteration 7930, loss = 0.00278928\n",
      "Iteration 7931, loss = 0.00278883\n",
      "Iteration 7932, loss = 0.00278859\n",
      "Iteration 7933, loss = 0.00278778\n",
      "Iteration 7934, loss = 0.00278729\n",
      "Iteration 7935, loss = 0.00278685\n",
      "Iteration 7936, loss = 0.00278654\n",
      "Iteration 7937, loss = 0.00278597\n",
      "Iteration 7938, loss = 0.00278567\n",
      "Iteration 7939, loss = 0.00278511\n",
      "Iteration 7940, loss = 0.00278470\n",
      "Iteration 7941, loss = 0.00278420\n",
      "Iteration 7942, loss = 0.00278374\n",
      "Iteration 7943, loss = 0.00278323\n",
      "Iteration 7944, loss = 0.00278290\n",
      "Iteration 7945, loss = 0.00278237\n",
      "Iteration 7946, loss = 0.00278179\n",
      "Iteration 7947, loss = 0.00278167\n",
      "Iteration 7948, loss = 0.00278100\n",
      "Iteration 7949, loss = 0.00278055\n",
      "Iteration 7950, loss = 0.00278011\n",
      "Iteration 7951, loss = 0.00277972\n",
      "Iteration 7952, loss = 0.00277945\n",
      "Iteration 7953, loss = 0.00277873\n",
      "Iteration 7954, loss = 0.00277842\n",
      "Iteration 7955, loss = 0.00277781\n",
      "Iteration 7956, loss = 0.00277733\n",
      "Iteration 7957, loss = 0.00277693\n",
      "Iteration 7958, loss = 0.00277655\n",
      "Iteration 7959, loss = 0.00277584\n",
      "Iteration 7960, loss = 0.00277536\n",
      "Iteration 7961, loss = 0.00277499\n",
      "Iteration 7962, loss = 0.00277451\n",
      "Iteration 7963, loss = 0.00277434\n",
      "Iteration 7964, loss = 0.00277364\n",
      "Iteration 7965, loss = 0.00277324\n",
      "Iteration 7966, loss = 0.00277277\n",
      "Iteration 7967, loss = 0.00277228\n",
      "Iteration 7968, loss = 0.00277203\n",
      "Iteration 7969, loss = 0.00277144\n",
      "Iteration 7970, loss = 0.00277098\n",
      "Iteration 7971, loss = 0.00277054\n",
      "Iteration 7972, loss = 0.00277003\n",
      "Iteration 7973, loss = 0.00276981\n",
      "Iteration 7974, loss = 0.00276911\n",
      "Iteration 7975, loss = 0.00276875\n",
      "Iteration 7976, loss = 0.00276826\n",
      "Iteration 7977, loss = 0.00276778\n",
      "Iteration 7978, loss = 0.00276757\n",
      "Iteration 7979, loss = 0.00276692\n",
      "Iteration 7980, loss = 0.00276628\n",
      "Iteration 7981, loss = 0.00276565\n",
      "Iteration 7982, loss = 0.00276502\n",
      "Iteration 7983, loss = 0.00276452\n",
      "Iteration 7984, loss = 0.00276447\n",
      "Iteration 7985, loss = 0.00276412\n",
      "Iteration 7986, loss = 0.00276337\n",
      "Iteration 7987, loss = 0.00276305\n",
      "Iteration 7988, loss = 0.00276256\n",
      "Iteration 7989, loss = 0.00276217\n",
      "Iteration 7990, loss = 0.00276163\n",
      "Iteration 7991, loss = 0.00276122\n",
      "Iteration 7992, loss = 0.00276074\n",
      "Iteration 7993, loss = 0.00276029\n",
      "Iteration 7994, loss = 0.00275980\n",
      "Iteration 7995, loss = 0.00275937\n",
      "Iteration 7996, loss = 0.00275880\n",
      "Iteration 7997, loss = 0.00275830\n",
      "Iteration 7998, loss = 0.00275782\n",
      "Iteration 7999, loss = 0.00275735\n",
      "Iteration 8000, loss = 0.00275696\n",
      "Iteration 1, loss = 1.04047078\n",
      "Iteration 2, loss = 1.03728679\n",
      "Iteration 3, loss = 1.03232620\n",
      "Iteration 4, loss = 1.02600245\n",
      "Iteration 5, loss = 1.01852447\n",
      "Iteration 6, loss = 1.01055779\n",
      "Iteration 7, loss = 1.00180529\n",
      "Iteration 8, loss = 0.99283551\n",
      "Iteration 9, loss = 0.98354265\n",
      "Iteration 10, loss = 0.97395813\n",
      "Iteration 11, loss = 0.96441745\n",
      "Iteration 12, loss = 0.95476744\n",
      "Iteration 13, loss = 0.94523850\n",
      "Iteration 14, loss = 0.93563654\n",
      "Iteration 15, loss = 0.92629477\n",
      "Iteration 16, loss = 0.91708907\n",
      "Iteration 17, loss = 0.90807142\n",
      "Iteration 18, loss = 0.89938067\n",
      "Iteration 19, loss = 0.89071319\n",
      "Iteration 20, loss = 0.88247554\n",
      "Iteration 21, loss = 0.87432911\n",
      "Iteration 22, loss = 0.86669951\n",
      "Iteration 23, loss = 0.85903522\n",
      "Iteration 24, loss = 0.85142297\n",
      "Iteration 25, loss = 0.84429749\n",
      "Iteration 26, loss = 0.83702206\n",
      "Iteration 27, loss = 0.83023044\n",
      "Iteration 28, loss = 0.82325169\n",
      "Iteration 29, loss = 0.81691741\n",
      "Iteration 30, loss = 0.81053906\n",
      "Iteration 31, loss = 0.80420770\n",
      "Iteration 32, loss = 0.79839282\n",
      "Iteration 33, loss = 0.79269307\n",
      "Iteration 34, loss = 0.78684468\n",
      "Iteration 35, loss = 0.78136108\n",
      "Iteration 36, loss = 0.77621296\n",
      "Iteration 37, loss = 0.77099333\n",
      "Iteration 38, loss = 0.76614871\n",
      "Iteration 39, loss = 0.76120391\n",
      "Iteration 40, loss = 0.75662803\n",
      "Iteration 41, loss = 0.75199027\n",
      "Iteration 42, loss = 0.74771561\n",
      "Iteration 43, loss = 0.74327914\n",
      "Iteration 44, loss = 0.73901285\n",
      "Iteration 45, loss = 0.73499651\n",
      "Iteration 46, loss = 0.73079863\n",
      "Iteration 47, loss = 0.72692105\n",
      "Iteration 48, loss = 0.72307757\n",
      "Iteration 49, loss = 0.71931259\n",
      "Iteration 50, loss = 0.71563567\n",
      "Iteration 51, loss = 0.71209157\n",
      "Iteration 52, loss = 0.70858732\n",
      "Iteration 53, loss = 0.70521430\n",
      "Iteration 54, loss = 0.70191045\n",
      "Iteration 55, loss = 0.69848397\n",
      "Iteration 56, loss = 0.69522855\n",
      "Iteration 57, loss = 0.69213439\n",
      "Iteration 58, loss = 0.68878665\n",
      "Iteration 59, loss = 0.68586031\n",
      "Iteration 60, loss = 0.68277973\n",
      "Iteration 61, loss = 0.67978986\n",
      "Iteration 62, loss = 0.67697395\n",
      "Iteration 63, loss = 0.67407915\n",
      "Iteration 64, loss = 0.67124574\n",
      "Iteration 65, loss = 0.66851478\n",
      "Iteration 66, loss = 0.66571767\n",
      "Iteration 67, loss = 0.66297573\n",
      "Iteration 68, loss = 0.66025816\n",
      "Iteration 69, loss = 0.65749350\n",
      "Iteration 70, loss = 0.65486893\n",
      "Iteration 71, loss = 0.65213716\n",
      "Iteration 72, loss = 0.64949697\n",
      "Iteration 73, loss = 0.64684973\n",
      "Iteration 74, loss = 0.64421298\n",
      "Iteration 75, loss = 0.64156328\n",
      "Iteration 76, loss = 0.63891467\n",
      "Iteration 77, loss = 0.63633225\n",
      "Iteration 78, loss = 0.63366020\n",
      "Iteration 79, loss = 0.63107581\n",
      "Iteration 80, loss = 0.62853235\n",
      "Iteration 81, loss = 0.62596497\n",
      "Iteration 82, loss = 0.62346354\n",
      "Iteration 83, loss = 0.62098278\n",
      "Iteration 84, loss = 0.61849254\n",
      "Iteration 85, loss = 0.61599476\n",
      "Iteration 86, loss = 0.61363970\n",
      "Iteration 87, loss = 0.61112196\n",
      "Iteration 88, loss = 0.60872845\n",
      "Iteration 89, loss = 0.60629416\n",
      "Iteration 90, loss = 0.60383212\n",
      "Iteration 91, loss = 0.60144344\n",
      "Iteration 92, loss = 0.59899017\n",
      "Iteration 93, loss = 0.59655208\n",
      "Iteration 94, loss = 0.59413258\n",
      "Iteration 95, loss = 0.59171696\n",
      "Iteration 96, loss = 0.58931448\n",
      "Iteration 97, loss = 0.58689823\n",
      "Iteration 98, loss = 0.58448296\n",
      "Iteration 99, loss = 0.58210344\n",
      "Iteration 100, loss = 0.57974260\n",
      "Iteration 101, loss = 0.57730699\n",
      "Iteration 102, loss = 0.57489534\n",
      "Iteration 103, loss = 0.57250855\n",
      "Iteration 104, loss = 0.57015141\n",
      "Iteration 105, loss = 0.56776630\n",
      "Iteration 106, loss = 0.56547566\n",
      "Iteration 107, loss = 0.56308866\n",
      "Iteration 108, loss = 0.56085612\n",
      "Iteration 109, loss = 0.55851534\n",
      "Iteration 110, loss = 0.55623138\n",
      "Iteration 111, loss = 0.55396119\n",
      "Iteration 112, loss = 0.55168108\n",
      "Iteration 113, loss = 0.54946329\n",
      "Iteration 114, loss = 0.54718359\n",
      "Iteration 115, loss = 0.54496325\n",
      "Iteration 116, loss = 0.54274821\n",
      "Iteration 117, loss = 0.54048916\n",
      "Iteration 118, loss = 0.53826792\n",
      "Iteration 119, loss = 0.53600840\n",
      "Iteration 120, loss = 0.53375838\n",
      "Iteration 121, loss = 0.53151527\n",
      "Iteration 122, loss = 0.52932004\n",
      "Iteration 123, loss = 0.52704579\n",
      "Iteration 124, loss = 0.52484474\n",
      "Iteration 125, loss = 0.52267358\n",
      "Iteration 126, loss = 0.52045959\n",
      "Iteration 127, loss = 0.51827652\n",
      "Iteration 128, loss = 0.51611510\n",
      "Iteration 129, loss = 0.51395300\n",
      "Iteration 130, loss = 0.51179785\n",
      "Iteration 131, loss = 0.50965132\n",
      "Iteration 132, loss = 0.50750956\n",
      "Iteration 133, loss = 0.50535463\n",
      "Iteration 134, loss = 0.50324379\n",
      "Iteration 135, loss = 0.50113486\n",
      "Iteration 136, loss = 0.49903122\n",
      "Iteration 137, loss = 0.49695368\n",
      "Iteration 138, loss = 0.49486252\n",
      "Iteration 139, loss = 0.49277835\n",
      "Iteration 140, loss = 0.49068983\n",
      "Iteration 141, loss = 0.48860566\n",
      "Iteration 142, loss = 0.48651100\n",
      "Iteration 143, loss = 0.48441876\n",
      "Iteration 144, loss = 0.48235289\n",
      "Iteration 145, loss = 0.48021539\n",
      "Iteration 146, loss = 0.47817860\n",
      "Iteration 147, loss = 0.47605488\n",
      "Iteration 148, loss = 0.47402321\n",
      "Iteration 149, loss = 0.47189941\n",
      "Iteration 150, loss = 0.46983344\n",
      "Iteration 151, loss = 0.46778601\n",
      "Iteration 152, loss = 0.46568009\n",
      "Iteration 153, loss = 0.46361674\n",
      "Iteration 154, loss = 0.46153431\n",
      "Iteration 155, loss = 0.45945926\n",
      "Iteration 156, loss = 0.45743207\n",
      "Iteration 157, loss = 0.45532515\n",
      "Iteration 158, loss = 0.45329985\n",
      "Iteration 159, loss = 0.45124096\n",
      "Iteration 160, loss = 0.44918448\n",
      "Iteration 161, loss = 0.44713918\n",
      "Iteration 162, loss = 0.44507175\n",
      "Iteration 163, loss = 0.44298979\n",
      "Iteration 164, loss = 0.44092001\n",
      "Iteration 165, loss = 0.43880839\n",
      "Iteration 166, loss = 0.43671538\n",
      "Iteration 167, loss = 0.43460778\n",
      "Iteration 168, loss = 0.43249250\n",
      "Iteration 169, loss = 0.43035851\n",
      "Iteration 170, loss = 0.42825063\n",
      "Iteration 171, loss = 0.42614216\n",
      "Iteration 172, loss = 0.42402058\n",
      "Iteration 173, loss = 0.42189786\n",
      "Iteration 174, loss = 0.41982690\n",
      "Iteration 175, loss = 0.41771754\n",
      "Iteration 176, loss = 0.41561446\n",
      "Iteration 177, loss = 0.41354226\n",
      "Iteration 178, loss = 0.41143982\n",
      "Iteration 179, loss = 0.40936271\n",
      "Iteration 180, loss = 0.40729456\n",
      "Iteration 181, loss = 0.40522817\n",
      "Iteration 182, loss = 0.40315051\n",
      "Iteration 183, loss = 0.40109434\n",
      "Iteration 184, loss = 0.39901023\n",
      "Iteration 185, loss = 0.39697874\n",
      "Iteration 186, loss = 0.39491095\n",
      "Iteration 187, loss = 0.39283506\n",
      "Iteration 188, loss = 0.39079829\n",
      "Iteration 189, loss = 0.38877131\n",
      "Iteration 190, loss = 0.38671759\n",
      "Iteration 191, loss = 0.38469055\n",
      "Iteration 192, loss = 0.38267855\n",
      "Iteration 193, loss = 0.38065367\n",
      "Iteration 194, loss = 0.37861333\n",
      "Iteration 195, loss = 0.37659299\n",
      "Iteration 196, loss = 0.37456959\n",
      "Iteration 197, loss = 0.37255045\n",
      "Iteration 198, loss = 0.37052610\n",
      "Iteration 199, loss = 0.36850250\n",
      "Iteration 200, loss = 0.36647680\n",
      "Iteration 201, loss = 0.36446842\n",
      "Iteration 202, loss = 0.36244191\n",
      "Iteration 203, loss = 0.36043072\n",
      "Iteration 204, loss = 0.35840751\n",
      "Iteration 205, loss = 0.35638140\n",
      "Iteration 206, loss = 0.35439315\n",
      "Iteration 207, loss = 0.35238034\n",
      "Iteration 208, loss = 0.35037678\n",
      "Iteration 209, loss = 0.34838758\n",
      "Iteration 210, loss = 0.34640822\n",
      "Iteration 211, loss = 0.34439811\n",
      "Iteration 212, loss = 0.34243211\n",
      "Iteration 213, loss = 0.34048581\n",
      "Iteration 214, loss = 0.33850290\n",
      "Iteration 215, loss = 0.33656277\n",
      "Iteration 216, loss = 0.33461165\n",
      "Iteration 217, loss = 0.33267792\n",
      "Iteration 218, loss = 0.33075185\n",
      "Iteration 219, loss = 0.32883780\n",
      "Iteration 220, loss = 0.32692374\n",
      "Iteration 221, loss = 0.32502615\n",
      "Iteration 222, loss = 0.32314090\n",
      "Iteration 223, loss = 0.32125812\n",
      "Iteration 224, loss = 0.31937931\n",
      "Iteration 225, loss = 0.31751600\n",
      "Iteration 226, loss = 0.31567733\n",
      "Iteration 227, loss = 0.31380043\n",
      "Iteration 228, loss = 0.31195669\n",
      "Iteration 229, loss = 0.31010245\n",
      "Iteration 230, loss = 0.30826069\n",
      "Iteration 231, loss = 0.30640053\n",
      "Iteration 232, loss = 0.30456679\n",
      "Iteration 233, loss = 0.30272001\n",
      "Iteration 234, loss = 0.30092032\n",
      "Iteration 235, loss = 0.29908987\n",
      "Iteration 236, loss = 0.29729893\n",
      "Iteration 237, loss = 0.29550734\n",
      "Iteration 238, loss = 0.29373140\n",
      "Iteration 239, loss = 0.29196239\n",
      "Iteration 240, loss = 0.29019730\n",
      "Iteration 241, loss = 0.28845264\n",
      "Iteration 242, loss = 0.28671942\n",
      "Iteration 243, loss = 0.28499888\n",
      "Iteration 244, loss = 0.28328015\n",
      "Iteration 245, loss = 0.28159623\n",
      "Iteration 246, loss = 0.27989048\n",
      "Iteration 247, loss = 0.27820027\n",
      "Iteration 248, loss = 0.27652149\n",
      "Iteration 249, loss = 0.27482980\n",
      "Iteration 250, loss = 0.27317487\n",
      "Iteration 251, loss = 0.27149154\n",
      "Iteration 252, loss = 0.26984836\n",
      "Iteration 253, loss = 0.26820613\n",
      "Iteration 254, loss = 0.26656939\n",
      "Iteration 255, loss = 0.26494947\n",
      "Iteration 256, loss = 0.26332809\n",
      "Iteration 257, loss = 0.26175267\n",
      "Iteration 258, loss = 0.26013678\n",
      "Iteration 259, loss = 0.25853765\n",
      "Iteration 260, loss = 0.25694233\n",
      "Iteration 261, loss = 0.25536951\n",
      "Iteration 262, loss = 0.25379966\n",
      "Iteration 263, loss = 0.25222916\n",
      "Iteration 264, loss = 0.25068750\n",
      "Iteration 265, loss = 0.24915793\n",
      "Iteration 266, loss = 0.24763531\n",
      "Iteration 267, loss = 0.24613576\n",
      "Iteration 268, loss = 0.24463044\n",
      "Iteration 269, loss = 0.24315279\n",
      "Iteration 270, loss = 0.24166057\n",
      "Iteration 271, loss = 0.24021789\n",
      "Iteration 272, loss = 0.23876936\n",
      "Iteration 273, loss = 0.23732145\n",
      "Iteration 274, loss = 0.23591290\n",
      "Iteration 275, loss = 0.23448690\n",
      "Iteration 276, loss = 0.23309077\n",
      "Iteration 277, loss = 0.23170056\n",
      "Iteration 278, loss = 0.23035326\n",
      "Iteration 279, loss = 0.22896564\n",
      "Iteration 280, loss = 0.22762484\n",
      "Iteration 281, loss = 0.22629283\n",
      "Iteration 282, loss = 0.22497046\n",
      "Iteration 283, loss = 0.22365468\n",
      "Iteration 284, loss = 0.22234104\n",
      "Iteration 285, loss = 0.22103414\n",
      "Iteration 286, loss = 0.21974504\n",
      "Iteration 287, loss = 0.21845091\n",
      "Iteration 288, loss = 0.21716536\n",
      "Iteration 289, loss = 0.21589799\n",
      "Iteration 290, loss = 0.21463560\n",
      "Iteration 291, loss = 0.21337998\n",
      "Iteration 292, loss = 0.21214724\n",
      "Iteration 293, loss = 0.21090330\n",
      "Iteration 294, loss = 0.20967270\n",
      "Iteration 295, loss = 0.20845711\n",
      "Iteration 296, loss = 0.20724438\n",
      "Iteration 297, loss = 0.20603996\n",
      "Iteration 298, loss = 0.20484006\n",
      "Iteration 299, loss = 0.20367093\n",
      "Iteration 300, loss = 0.20251097\n",
      "Iteration 301, loss = 0.20134877\n",
      "Iteration 302, loss = 0.20020769\n",
      "Iteration 303, loss = 0.19908116\n",
      "Iteration 304, loss = 0.19796229\n",
      "Iteration 305, loss = 0.19684966\n",
      "Iteration 306, loss = 0.19573728\n",
      "Iteration 307, loss = 0.19463835\n",
      "Iteration 308, loss = 0.19353817\n",
      "Iteration 309, loss = 0.19244521\n",
      "Iteration 310, loss = 0.19137525\n",
      "Iteration 311, loss = 0.19030371\n",
      "Iteration 312, loss = 0.18923271\n",
      "Iteration 313, loss = 0.18818257\n",
      "Iteration 314, loss = 0.18713884\n",
      "Iteration 315, loss = 0.18609631\n",
      "Iteration 316, loss = 0.18506709\n",
      "Iteration 317, loss = 0.18403826\n",
      "Iteration 318, loss = 0.18302144\n",
      "Iteration 319, loss = 0.18201249\n",
      "Iteration 320, loss = 0.18100338\n",
      "Iteration 321, loss = 0.18000407\n",
      "Iteration 322, loss = 0.17901295\n",
      "Iteration 323, loss = 0.17803174\n",
      "Iteration 324, loss = 0.17705985\n",
      "Iteration 325, loss = 0.17608755\n",
      "Iteration 326, loss = 0.17513747\n",
      "Iteration 327, loss = 0.17419102\n",
      "Iteration 328, loss = 0.17324546\n",
      "Iteration 329, loss = 0.17231854\n",
      "Iteration 330, loss = 0.17140080\n",
      "Iteration 331, loss = 0.17047156\n",
      "Iteration 332, loss = 0.16957249\n",
      "Iteration 333, loss = 0.16867498\n",
      "Iteration 334, loss = 0.16778750\n",
      "Iteration 335, loss = 0.16689990\n",
      "Iteration 336, loss = 0.16602551\n",
      "Iteration 337, loss = 0.16516911\n",
      "Iteration 338, loss = 0.16430775\n",
      "Iteration 339, loss = 0.16346830\n",
      "Iteration 340, loss = 0.16262156\n",
      "Iteration 341, loss = 0.16178981\n",
      "Iteration 342, loss = 0.16095609\n",
      "Iteration 343, loss = 0.16014105\n",
      "Iteration 344, loss = 0.15931715\n",
      "Iteration 345, loss = 0.15850309\n",
      "Iteration 346, loss = 0.15769867\n",
      "Iteration 347, loss = 0.15690908\n",
      "Iteration 348, loss = 0.15611471\n",
      "Iteration 349, loss = 0.15533161\n",
      "Iteration 350, loss = 0.15455900\n",
      "Iteration 351, loss = 0.15378497\n",
      "Iteration 352, loss = 0.15301098\n",
      "Iteration 353, loss = 0.15224702\n",
      "Iteration 354, loss = 0.15148529\n",
      "Iteration 355, loss = 0.15072640\n",
      "Iteration 356, loss = 0.14997647\n",
      "Iteration 357, loss = 0.14922817\n",
      "Iteration 358, loss = 0.14848769\n",
      "Iteration 359, loss = 0.14776109\n",
      "Iteration 360, loss = 0.14703953\n",
      "Iteration 361, loss = 0.14632733\n",
      "Iteration 362, loss = 0.14562194\n",
      "Iteration 363, loss = 0.14491888\n",
      "Iteration 364, loss = 0.14423177\n",
      "Iteration 365, loss = 0.14355117\n",
      "Iteration 366, loss = 0.14285441\n",
      "Iteration 367, loss = 0.14218231\n",
      "Iteration 368, loss = 0.14150872\n",
      "Iteration 369, loss = 0.14084231\n",
      "Iteration 370, loss = 0.14018309\n",
      "Iteration 371, loss = 0.13953165\n",
      "Iteration 372, loss = 0.13888779\n",
      "Iteration 373, loss = 0.13825186\n",
      "Iteration 374, loss = 0.13761752\n",
      "Iteration 375, loss = 0.13698617\n",
      "Iteration 376, loss = 0.13636375\n",
      "Iteration 377, loss = 0.13574579\n",
      "Iteration 378, loss = 0.13513033\n",
      "Iteration 379, loss = 0.13451292\n",
      "Iteration 380, loss = 0.13390581\n",
      "Iteration 381, loss = 0.13329299\n",
      "Iteration 382, loss = 0.13268266\n",
      "Iteration 383, loss = 0.13208550\n",
      "Iteration 384, loss = 0.13149393\n",
      "Iteration 385, loss = 0.13091662\n",
      "Iteration 386, loss = 0.13033601\n",
      "Iteration 387, loss = 0.12977040\n",
      "Iteration 388, loss = 0.12919444\n",
      "Iteration 389, loss = 0.12863764\n",
      "Iteration 390, loss = 0.12808420\n",
      "Iteration 391, loss = 0.12753660\n",
      "Iteration 392, loss = 0.12700370\n",
      "Iteration 393, loss = 0.12646918\n",
      "Iteration 394, loss = 0.12594144\n",
      "Iteration 395, loss = 0.12542178\n",
      "Iteration 396, loss = 0.12490238\n",
      "Iteration 397, loss = 0.12438556\n",
      "Iteration 398, loss = 0.12386957\n",
      "Iteration 399, loss = 0.12335622\n",
      "Iteration 400, loss = 0.12284898\n",
      "Iteration 401, loss = 0.12235337\n",
      "Iteration 402, loss = 0.12184255\n",
      "Iteration 403, loss = 0.12135631\n",
      "Iteration 404, loss = 0.12086307\n",
      "Iteration 405, loss = 0.12037231\n",
      "Iteration 406, loss = 0.11988661\n",
      "Iteration 407, loss = 0.11941035\n",
      "Iteration 408, loss = 0.11893587\n",
      "Iteration 409, loss = 0.11846535\n",
      "Iteration 410, loss = 0.11799875\n",
      "Iteration 411, loss = 0.11754067\n",
      "Iteration 412, loss = 0.11707962\n",
      "Iteration 413, loss = 0.11662573\n",
      "Iteration 414, loss = 0.11616897\n",
      "Iteration 415, loss = 0.11571935\n",
      "Iteration 416, loss = 0.11527275\n",
      "Iteration 417, loss = 0.11483238\n",
      "Iteration 418, loss = 0.11439229\n",
      "Iteration 419, loss = 0.11395630\n",
      "Iteration 420, loss = 0.11352346\n",
      "Iteration 421, loss = 0.11309197\n",
      "Iteration 422, loss = 0.11266594\n",
      "Iteration 423, loss = 0.11223117\n",
      "Iteration 424, loss = 0.11180995\n",
      "Iteration 425, loss = 0.11138616\n",
      "Iteration 426, loss = 0.11096969\n",
      "Iteration 427, loss = 0.11055313\n",
      "Iteration 428, loss = 0.11013529\n",
      "Iteration 429, loss = 0.10972713\n",
      "Iteration 430, loss = 0.10931216\n",
      "Iteration 431, loss = 0.10890752\n",
      "Iteration 432, loss = 0.10850264\n",
      "Iteration 433, loss = 0.10810473\n",
      "Iteration 434, loss = 0.10770620\n",
      "Iteration 435, loss = 0.10731223\n",
      "Iteration 436, loss = 0.10692591\n",
      "Iteration 437, loss = 0.10654625\n",
      "Iteration 438, loss = 0.10615835\n",
      "Iteration 439, loss = 0.10578255\n",
      "Iteration 440, loss = 0.10540831\n",
      "Iteration 441, loss = 0.10503759\n",
      "Iteration 442, loss = 0.10467266\n",
      "Iteration 443, loss = 0.10430991\n",
      "Iteration 444, loss = 0.10393916\n",
      "Iteration 445, loss = 0.10358116\n",
      "Iteration 446, loss = 0.10321759\n",
      "Iteration 447, loss = 0.10286191\n",
      "Iteration 448, loss = 0.10250694\n",
      "Iteration 449, loss = 0.10215659\n",
      "Iteration 450, loss = 0.10180872\n",
      "Iteration 451, loss = 0.10146209\n",
      "Iteration 452, loss = 0.10111584\n",
      "Iteration 453, loss = 0.10077502\n",
      "Iteration 454, loss = 0.10043185\n",
      "Iteration 455, loss = 0.10009765\n",
      "Iteration 456, loss = 0.09975808\n",
      "Iteration 457, loss = 0.09942137\n",
      "Iteration 458, loss = 0.09908950\n",
      "Iteration 459, loss = 0.09875924\n",
      "Iteration 460, loss = 0.09842725\n",
      "Iteration 461, loss = 0.09810395\n",
      "Iteration 462, loss = 0.09777910\n",
      "Iteration 463, loss = 0.09745118\n",
      "Iteration 464, loss = 0.09711959\n",
      "Iteration 465, loss = 0.09679769\n",
      "Iteration 466, loss = 0.09648415\n",
      "Iteration 467, loss = 0.09616104\n",
      "Iteration 468, loss = 0.09584531\n",
      "Iteration 469, loss = 0.09553469\n",
      "Iteration 470, loss = 0.09522311\n",
      "Iteration 471, loss = 0.09492336\n",
      "Iteration 472, loss = 0.09462148\n",
      "Iteration 473, loss = 0.09432520\n",
      "Iteration 474, loss = 0.09402968\n",
      "Iteration 475, loss = 0.09373980\n",
      "Iteration 476, loss = 0.09344701\n",
      "Iteration 477, loss = 0.09315684\n",
      "Iteration 478, loss = 0.09287961\n",
      "Iteration 479, loss = 0.09260432\n",
      "Iteration 480, loss = 0.09232081\n",
      "Iteration 481, loss = 0.09203037\n",
      "Iteration 482, loss = 0.09174810\n",
      "Iteration 483, loss = 0.09146164\n",
      "Iteration 484, loss = 0.09117675\n",
      "Iteration 485, loss = 0.09089443\n",
      "Iteration 486, loss = 0.09061669\n",
      "Iteration 487, loss = 0.09034252\n",
      "Iteration 488, loss = 0.09007102\n",
      "Iteration 489, loss = 0.08979852\n",
      "Iteration 490, loss = 0.08952706\n",
      "Iteration 491, loss = 0.08925091\n",
      "Iteration 492, loss = 0.08898623\n",
      "Iteration 493, loss = 0.08871727\n",
      "Iteration 494, loss = 0.08844864\n",
      "Iteration 495, loss = 0.08818963\n",
      "Iteration 496, loss = 0.08792860\n",
      "Iteration 497, loss = 0.08767616\n",
      "Iteration 498, loss = 0.08742022\n",
      "Iteration 499, loss = 0.08717098\n",
      "Iteration 500, loss = 0.08692124\n",
      "Iteration 501, loss = 0.08667582\n",
      "Iteration 502, loss = 0.08642444\n",
      "Iteration 503, loss = 0.08619000\n",
      "Iteration 504, loss = 0.08594463\n",
      "Iteration 505, loss = 0.08570814\n",
      "Iteration 506, loss = 0.08547175\n",
      "Iteration 507, loss = 0.08523636\n",
      "Iteration 508, loss = 0.08500361\n",
      "Iteration 509, loss = 0.08477222\n",
      "Iteration 510, loss = 0.08454210\n",
      "Iteration 511, loss = 0.08431323\n",
      "Iteration 512, loss = 0.08408920\n",
      "Iteration 513, loss = 0.08386192\n",
      "Iteration 514, loss = 0.08363495\n",
      "Iteration 515, loss = 0.08340527\n",
      "Iteration 516, loss = 0.08318077\n",
      "Iteration 517, loss = 0.08294973\n",
      "Iteration 518, loss = 0.08273039\n",
      "Iteration 519, loss = 0.08249777\n",
      "Iteration 520, loss = 0.08227531\n",
      "Iteration 521, loss = 0.08206091\n",
      "Iteration 522, loss = 0.08183642\n",
      "Iteration 523, loss = 0.08161954\n",
      "Iteration 524, loss = 0.08140209\n",
      "Iteration 525, loss = 0.08119694\n",
      "Iteration 526, loss = 0.08097604\n",
      "Iteration 527, loss = 0.08076667\n",
      "Iteration 528, loss = 0.08056154\n",
      "Iteration 529, loss = 0.08034386\n",
      "Iteration 530, loss = 0.08014194\n",
      "Iteration 531, loss = 0.07993298\n",
      "Iteration 532, loss = 0.07972684\n",
      "Iteration 533, loss = 0.07952639\n",
      "Iteration 534, loss = 0.07932567\n",
      "Iteration 535, loss = 0.07912283\n",
      "Iteration 536, loss = 0.07892202\n",
      "Iteration 537, loss = 0.07872008\n",
      "Iteration 538, loss = 0.07852462\n",
      "Iteration 539, loss = 0.07831826\n",
      "Iteration 540, loss = 0.07811803\n",
      "Iteration 541, loss = 0.07791968\n",
      "Iteration 542, loss = 0.07772688\n",
      "Iteration 543, loss = 0.07752878\n",
      "Iteration 544, loss = 0.07733300\n",
      "Iteration 545, loss = 0.07714929\n",
      "Iteration 546, loss = 0.07695321\n",
      "Iteration 547, loss = 0.07676809\n",
      "Iteration 548, loss = 0.07657722\n",
      "Iteration 549, loss = 0.07639439\n",
      "Iteration 550, loss = 0.07621043\n",
      "Iteration 551, loss = 0.07602705\n",
      "Iteration 552, loss = 0.07584498\n",
      "Iteration 553, loss = 0.07566058\n",
      "Iteration 554, loss = 0.07548710\n",
      "Iteration 555, loss = 0.07530485\n",
      "Iteration 556, loss = 0.07512435\n",
      "Iteration 557, loss = 0.07494174\n",
      "Iteration 558, loss = 0.07476870\n",
      "Iteration 559, loss = 0.07459379\n",
      "Iteration 560, loss = 0.07441850\n",
      "Iteration 561, loss = 0.07424550\n",
      "Iteration 562, loss = 0.07407053\n",
      "Iteration 563, loss = 0.07390726\n",
      "Iteration 564, loss = 0.07373051\n",
      "Iteration 565, loss = 0.07356397\n",
      "Iteration 566, loss = 0.07339662\n",
      "Iteration 567, loss = 0.07323136\n",
      "Iteration 568, loss = 0.07306921\n",
      "Iteration 569, loss = 0.07290609\n",
      "Iteration 570, loss = 0.07274624\n",
      "Iteration 571, loss = 0.07259040\n",
      "Iteration 572, loss = 0.07242301\n",
      "Iteration 573, loss = 0.07226928\n",
      "Iteration 574, loss = 0.07210197\n",
      "Iteration 575, loss = 0.07193173\n",
      "Iteration 576, loss = 0.07177451\n",
      "Iteration 577, loss = 0.07161285\n",
      "Iteration 578, loss = 0.07145244\n",
      "Iteration 579, loss = 0.07129105\n",
      "Iteration 580, loss = 0.07113299\n",
      "Iteration 581, loss = 0.07097505\n",
      "Iteration 582, loss = 0.07081402\n",
      "Iteration 583, loss = 0.07065547\n",
      "Iteration 584, loss = 0.07049955\n",
      "Iteration 585, loss = 0.07034196\n",
      "Iteration 586, loss = 0.07019135\n",
      "Iteration 587, loss = 0.07003937\n",
      "Iteration 588, loss = 0.06987947\n",
      "Iteration 589, loss = 0.06972423\n",
      "Iteration 590, loss = 0.06957172\n",
      "Iteration 591, loss = 0.06941555\n",
      "Iteration 592, loss = 0.06925884\n",
      "Iteration 593, loss = 0.06910409\n",
      "Iteration 594, loss = 0.06895979\n",
      "Iteration 595, loss = 0.06880352\n",
      "Iteration 596, loss = 0.06865050\n",
      "Iteration 597, loss = 0.06850327\n",
      "Iteration 598, loss = 0.06835579\n",
      "Iteration 599, loss = 0.06821479\n",
      "Iteration 600, loss = 0.06806616\n",
      "Iteration 601, loss = 0.06792055\n",
      "Iteration 602, loss = 0.06778269\n",
      "Iteration 603, loss = 0.06763795\n",
      "Iteration 604, loss = 0.06749705\n",
      "Iteration 605, loss = 0.06735806\n",
      "Iteration 606, loss = 0.06722393\n",
      "Iteration 607, loss = 0.06708978\n",
      "Iteration 608, loss = 0.06695387\n",
      "Iteration 609, loss = 0.06682015\n",
      "Iteration 610, loss = 0.06668601\n",
      "Iteration 611, loss = 0.06655570\n",
      "Iteration 612, loss = 0.06642118\n",
      "Iteration 613, loss = 0.06628992\n",
      "Iteration 614, loss = 0.06615833\n",
      "Iteration 615, loss = 0.06602236\n",
      "Iteration 616, loss = 0.06589394\n",
      "Iteration 617, loss = 0.06576243\n",
      "Iteration 618, loss = 0.06563890\n",
      "Iteration 619, loss = 0.06550823\n",
      "Iteration 620, loss = 0.06538122\n",
      "Iteration 621, loss = 0.06525175\n",
      "Iteration 622, loss = 0.06512646\n",
      "Iteration 623, loss = 0.06500130\n",
      "Iteration 624, loss = 0.06487458\n",
      "Iteration 625, loss = 0.06474835\n",
      "Iteration 626, loss = 0.06462567\n",
      "Iteration 627, loss = 0.06449952\n",
      "Iteration 628, loss = 0.06437302\n",
      "Iteration 629, loss = 0.06424973\n",
      "Iteration 630, loss = 0.06412145\n",
      "Iteration 631, loss = 0.06399593\n",
      "Iteration 632, loss = 0.06388030\n",
      "Iteration 633, loss = 0.06374917\n",
      "Iteration 634, loss = 0.06363118\n",
      "Iteration 635, loss = 0.06351822\n",
      "Iteration 636, loss = 0.06339658\n",
      "Iteration 637, loss = 0.06327800\n",
      "Iteration 638, loss = 0.06316553\n",
      "Iteration 639, loss = 0.06304142\n",
      "Iteration 640, loss = 0.06292220\n",
      "Iteration 641, loss = 0.06280202\n",
      "Iteration 642, loss = 0.06268611\n",
      "Iteration 643, loss = 0.06257263\n",
      "Iteration 644, loss = 0.06245595\n",
      "Iteration 645, loss = 0.06234017\n",
      "Iteration 646, loss = 0.06222545\n",
      "Iteration 647, loss = 0.06210922\n",
      "Iteration 648, loss = 0.06199379\n",
      "Iteration 649, loss = 0.06188321\n",
      "Iteration 650, loss = 0.06176834\n",
      "Iteration 651, loss = 0.06165824\n",
      "Iteration 652, loss = 0.06154978\n",
      "Iteration 653, loss = 0.06143518\n",
      "Iteration 654, loss = 0.06132448\n",
      "Iteration 655, loss = 0.06121626\n",
      "Iteration 656, loss = 0.06110147\n",
      "Iteration 657, loss = 0.06099317\n",
      "Iteration 658, loss = 0.06088135\n",
      "Iteration 659, loss = 0.06077321\n",
      "Iteration 660, loss = 0.06066502\n",
      "Iteration 661, loss = 0.06056286\n",
      "Iteration 662, loss = 0.06044903\n",
      "Iteration 663, loss = 0.06034094\n",
      "Iteration 664, loss = 0.06023193\n",
      "Iteration 665, loss = 0.06012331\n",
      "Iteration 666, loss = 0.06001618\n",
      "Iteration 667, loss = 0.05990648\n",
      "Iteration 668, loss = 0.05980059\n",
      "Iteration 669, loss = 0.05969685\n",
      "Iteration 670, loss = 0.05958911\n",
      "Iteration 671, loss = 0.05948952\n",
      "Iteration 672, loss = 0.05938110\n",
      "Iteration 673, loss = 0.05927653\n",
      "Iteration 674, loss = 0.05917364\n",
      "Iteration 675, loss = 0.05906852\n",
      "Iteration 676, loss = 0.05896767\n",
      "Iteration 677, loss = 0.05886654\n",
      "Iteration 678, loss = 0.05876329\n",
      "Iteration 679, loss = 0.05866260\n",
      "Iteration 680, loss = 0.05856347\n",
      "Iteration 681, loss = 0.05846073\n",
      "Iteration 682, loss = 0.05836131\n",
      "Iteration 683, loss = 0.05825956\n",
      "Iteration 684, loss = 0.05815949\n",
      "Iteration 685, loss = 0.05805988\n",
      "Iteration 686, loss = 0.05797013\n",
      "Iteration 687, loss = 0.05786794\n",
      "Iteration 688, loss = 0.05777403\n",
      "Iteration 689, loss = 0.05767612\n",
      "Iteration 690, loss = 0.05757365\n",
      "Iteration 691, loss = 0.05747643\n",
      "Iteration 692, loss = 0.05737799\n",
      "Iteration 693, loss = 0.05728250\n",
      "Iteration 694, loss = 0.05719295\n",
      "Iteration 695, loss = 0.05709207\n",
      "Iteration 696, loss = 0.05699649\n",
      "Iteration 697, loss = 0.05690517\n",
      "Iteration 698, loss = 0.05680563\n",
      "Iteration 699, loss = 0.05670912\n",
      "Iteration 700, loss = 0.05660855\n",
      "Iteration 701, loss = 0.05651916\n",
      "Iteration 702, loss = 0.05641624\n",
      "Iteration 703, loss = 0.05631677\n",
      "Iteration 704, loss = 0.05621764\n",
      "Iteration 705, loss = 0.05612607\n",
      "Iteration 706, loss = 0.05602286\n",
      "Iteration 707, loss = 0.05592983\n",
      "Iteration 708, loss = 0.05583013\n",
      "Iteration 709, loss = 0.05574009\n",
      "Iteration 710, loss = 0.05564733\n",
      "Iteration 711, loss = 0.05554916\n",
      "Iteration 712, loss = 0.05545607\n",
      "Iteration 713, loss = 0.05536266\n",
      "Iteration 714, loss = 0.05527121\n",
      "Iteration 715, loss = 0.05517961\n",
      "Iteration 716, loss = 0.05509171\n",
      "Iteration 717, loss = 0.05499614\n",
      "Iteration 718, loss = 0.05490912\n",
      "Iteration 719, loss = 0.05481961\n",
      "Iteration 720, loss = 0.05473296\n",
      "Iteration 721, loss = 0.05464482\n",
      "Iteration 722, loss = 0.05456173\n",
      "Iteration 723, loss = 0.05447218\n",
      "Iteration 724, loss = 0.05438368\n",
      "Iteration 725, loss = 0.05429993\n",
      "Iteration 726, loss = 0.05421111\n",
      "Iteration 727, loss = 0.05412683\n",
      "Iteration 728, loss = 0.05404192\n",
      "Iteration 729, loss = 0.05395757\n",
      "Iteration 730, loss = 0.05387610\n",
      "Iteration 731, loss = 0.05379081\n",
      "Iteration 732, loss = 0.05370715\n",
      "Iteration 733, loss = 0.05362314\n",
      "Iteration 734, loss = 0.05353890\n",
      "Iteration 735, loss = 0.05345505\n",
      "Iteration 736, loss = 0.05337354\n",
      "Iteration 737, loss = 0.05328874\n",
      "Iteration 738, loss = 0.05320853\n",
      "Iteration 739, loss = 0.05312302\n",
      "Iteration 740, loss = 0.05304237\n",
      "Iteration 741, loss = 0.05295937\n",
      "Iteration 742, loss = 0.05287937\n",
      "Iteration 743, loss = 0.05279628\n",
      "Iteration 744, loss = 0.05271431\n",
      "Iteration 745, loss = 0.05263532\n",
      "Iteration 746, loss = 0.05255323\n",
      "Iteration 747, loss = 0.05246829\n",
      "Iteration 748, loss = 0.05238115\n",
      "Iteration 749, loss = 0.05229657\n",
      "Iteration 750, loss = 0.05221657\n",
      "Iteration 751, loss = 0.05212925\n",
      "Iteration 752, loss = 0.05204717\n",
      "Iteration 753, loss = 0.05197030\n",
      "Iteration 754, loss = 0.05188666\n",
      "Iteration 755, loss = 0.05180612\n",
      "Iteration 756, loss = 0.05173939\n",
      "Iteration 757, loss = 0.05165065\n",
      "Iteration 758, loss = 0.05158067\n",
      "Iteration 759, loss = 0.05150069\n",
      "Iteration 760, loss = 0.05142083\n",
      "Iteration 761, loss = 0.05134846\n",
      "Iteration 762, loss = 0.05126734\n",
      "Iteration 763, loss = 0.05119274\n",
      "Iteration 764, loss = 0.05111545\n",
      "Iteration 765, loss = 0.05103561\n",
      "Iteration 766, loss = 0.05096280\n",
      "Iteration 767, loss = 0.05088992\n",
      "Iteration 768, loss = 0.05081028\n",
      "Iteration 769, loss = 0.05073660\n",
      "Iteration 770, loss = 0.05066221\n",
      "Iteration 771, loss = 0.05058587\n",
      "Iteration 772, loss = 0.05051659\n",
      "Iteration 773, loss = 0.05043958\n",
      "Iteration 774, loss = 0.05036635\n",
      "Iteration 775, loss = 0.05029313\n",
      "Iteration 776, loss = 0.05022199\n",
      "Iteration 777, loss = 0.05014762\n",
      "Iteration 778, loss = 0.05007681\n",
      "Iteration 779, loss = 0.05000489\n",
      "Iteration 780, loss = 0.04993755\n",
      "Iteration 781, loss = 0.04985948\n",
      "Iteration 782, loss = 0.04979060\n",
      "Iteration 783, loss = 0.04971768\n",
      "Iteration 784, loss = 0.04963723\n",
      "Iteration 785, loss = 0.04956616\n",
      "Iteration 786, loss = 0.04949819\n",
      "Iteration 787, loss = 0.04942083\n",
      "Iteration 788, loss = 0.04934459\n",
      "Iteration 789, loss = 0.04927405\n",
      "Iteration 790, loss = 0.04919770\n",
      "Iteration 791, loss = 0.04912851\n",
      "Iteration 792, loss = 0.04905448\n",
      "Iteration 793, loss = 0.04898563\n",
      "Iteration 794, loss = 0.04891032\n",
      "Iteration 795, loss = 0.04884160\n",
      "Iteration 796, loss = 0.04877006\n",
      "Iteration 797, loss = 0.04870585\n",
      "Iteration 798, loss = 0.04863273\n",
      "Iteration 799, loss = 0.04856761\n",
      "Iteration 800, loss = 0.04849883\n",
      "Iteration 801, loss = 0.04843257\n",
      "Iteration 802, loss = 0.04836641\n",
      "Iteration 803, loss = 0.04830080\n",
      "Iteration 804, loss = 0.04823792\n",
      "Iteration 805, loss = 0.04817367\n",
      "Iteration 806, loss = 0.04810894\n",
      "Iteration 807, loss = 0.04804246\n",
      "Iteration 808, loss = 0.04797835\n",
      "Iteration 809, loss = 0.04791086\n",
      "Iteration 810, loss = 0.04784631\n",
      "Iteration 811, loss = 0.04778140\n",
      "Iteration 812, loss = 0.04771926\n",
      "Iteration 813, loss = 0.04765474\n",
      "Iteration 814, loss = 0.04759098\n",
      "Iteration 815, loss = 0.04752841\n",
      "Iteration 816, loss = 0.04746524\n",
      "Iteration 817, loss = 0.04740273\n",
      "Iteration 818, loss = 0.04734085\n",
      "Iteration 819, loss = 0.04727947\n",
      "Iteration 820, loss = 0.04721702\n",
      "Iteration 821, loss = 0.04715444\n",
      "Iteration 822, loss = 0.04709148\n",
      "Iteration 823, loss = 0.04702355\n",
      "Iteration 824, loss = 0.04695888\n",
      "Iteration 825, loss = 0.04689519\n",
      "Iteration 826, loss = 0.04682902\n",
      "Iteration 827, loss = 0.04676927\n",
      "Iteration 828, loss = 0.04670540\n",
      "Iteration 829, loss = 0.04664445\n",
      "Iteration 830, loss = 0.04658199\n",
      "Iteration 831, loss = 0.04652284\n",
      "Iteration 832, loss = 0.04646089\n",
      "Iteration 833, loss = 0.04640426\n",
      "Iteration 834, loss = 0.04634178\n",
      "Iteration 835, loss = 0.04627920\n",
      "Iteration 836, loss = 0.04621948\n",
      "Iteration 837, loss = 0.04615365\n",
      "Iteration 838, loss = 0.04609469\n",
      "Iteration 839, loss = 0.04603363\n",
      "Iteration 840, loss = 0.04597340\n",
      "Iteration 841, loss = 0.04591566\n",
      "Iteration 842, loss = 0.04585746\n",
      "Iteration 843, loss = 0.04579948\n",
      "Iteration 844, loss = 0.04574224\n",
      "Iteration 845, loss = 0.04568713\n",
      "Iteration 846, loss = 0.04563014\n",
      "Iteration 847, loss = 0.04556689\n",
      "Iteration 848, loss = 0.04550637\n",
      "Iteration 849, loss = 0.04544804\n",
      "Iteration 850, loss = 0.04538954\n",
      "Iteration 851, loss = 0.04533098\n",
      "Iteration 852, loss = 0.04527164\n",
      "Iteration 853, loss = 0.04521536\n",
      "Iteration 854, loss = 0.04515468\n",
      "Iteration 855, loss = 0.04509294\n",
      "Iteration 856, loss = 0.04503725\n",
      "Iteration 857, loss = 0.04497692\n",
      "Iteration 858, loss = 0.04491736\n",
      "Iteration 859, loss = 0.04485794\n",
      "Iteration 860, loss = 0.04480375\n",
      "Iteration 861, loss = 0.04474814\n",
      "Iteration 862, loss = 0.04468714\n",
      "Iteration 863, loss = 0.04463098\n",
      "Iteration 864, loss = 0.04457239\n",
      "Iteration 865, loss = 0.04451964\n",
      "Iteration 866, loss = 0.04446435\n",
      "Iteration 867, loss = 0.04440565\n",
      "Iteration 868, loss = 0.04435418\n",
      "Iteration 869, loss = 0.04429265\n",
      "Iteration 870, loss = 0.04424211\n",
      "Iteration 871, loss = 0.04418309\n",
      "Iteration 872, loss = 0.04412619\n",
      "Iteration 873, loss = 0.04407351\n",
      "Iteration 874, loss = 0.04401424\n",
      "Iteration 875, loss = 0.04396210\n",
      "Iteration 876, loss = 0.04390785\n",
      "Iteration 877, loss = 0.04385082\n",
      "Iteration 878, loss = 0.04379925\n",
      "Iteration 879, loss = 0.04374308\n",
      "Iteration 880, loss = 0.04369062\n",
      "Iteration 881, loss = 0.04364041\n",
      "Iteration 882, loss = 0.04358882\n",
      "Iteration 883, loss = 0.04353911\n",
      "Iteration 884, loss = 0.04348627\n",
      "Iteration 885, loss = 0.04343930\n",
      "Iteration 886, loss = 0.04338646\n",
      "Iteration 887, loss = 0.04333167\n",
      "Iteration 888, loss = 0.04328078\n",
      "Iteration 889, loss = 0.04322562\n",
      "Iteration 890, loss = 0.04317501\n",
      "Iteration 891, loss = 0.04312584\n",
      "Iteration 892, loss = 0.04307579\n",
      "Iteration 893, loss = 0.04302973\n",
      "Iteration 894, loss = 0.04297489\n",
      "Iteration 895, loss = 0.04292355\n",
      "Iteration 896, loss = 0.04287616\n",
      "Iteration 897, loss = 0.04282655\n",
      "Iteration 898, loss = 0.04277292\n",
      "Iteration 899, loss = 0.04272134\n",
      "Iteration 900, loss = 0.04267170\n",
      "Iteration 901, loss = 0.04262094\n",
      "Iteration 902, loss = 0.04257178\n",
      "Iteration 903, loss = 0.04252127\n",
      "Iteration 904, loss = 0.04247176\n",
      "Iteration 905, loss = 0.04241948\n",
      "Iteration 906, loss = 0.04236770\n",
      "Iteration 907, loss = 0.04231926\n",
      "Iteration 908, loss = 0.04227138\n",
      "Iteration 909, loss = 0.04221985\n",
      "Iteration 910, loss = 0.04217212\n",
      "Iteration 911, loss = 0.04212073\n",
      "Iteration 912, loss = 0.04207035\n",
      "Iteration 913, loss = 0.04202494\n",
      "Iteration 914, loss = 0.04197292\n",
      "Iteration 915, loss = 0.04192212\n",
      "Iteration 916, loss = 0.04187636\n",
      "Iteration 917, loss = 0.04182765\n",
      "Iteration 918, loss = 0.04177927\n",
      "Iteration 919, loss = 0.04173264\n",
      "Iteration 920, loss = 0.04168246\n",
      "Iteration 921, loss = 0.04163709\n",
      "Iteration 922, loss = 0.04158738\n",
      "Iteration 923, loss = 0.04154083\n",
      "Iteration 924, loss = 0.04149410\n",
      "Iteration 925, loss = 0.04144806\n",
      "Iteration 926, loss = 0.04140526\n",
      "Iteration 927, loss = 0.04135579\n",
      "Iteration 928, loss = 0.04130785\n",
      "Iteration 929, loss = 0.04126264\n",
      "Iteration 930, loss = 0.04121720\n",
      "Iteration 931, loss = 0.04116922\n",
      "Iteration 932, loss = 0.04112009\n",
      "Iteration 933, loss = 0.04107277\n",
      "Iteration 934, loss = 0.04102841\n",
      "Iteration 935, loss = 0.04098161\n",
      "Iteration 936, loss = 0.04093485\n",
      "Iteration 937, loss = 0.04089006\n",
      "Iteration 938, loss = 0.04084760\n",
      "Iteration 939, loss = 0.04079740\n",
      "Iteration 940, loss = 0.04075004\n",
      "Iteration 941, loss = 0.04070472\n",
      "Iteration 942, loss = 0.04065674\n",
      "Iteration 943, loss = 0.04061040\n",
      "Iteration 944, loss = 0.04056072\n",
      "Iteration 945, loss = 0.04051361\n",
      "Iteration 946, loss = 0.04046706\n",
      "Iteration 947, loss = 0.04041824\n",
      "Iteration 948, loss = 0.04037220\n",
      "Iteration 949, loss = 0.04032702\n",
      "Iteration 950, loss = 0.04027806\n",
      "Iteration 951, loss = 0.04023025\n",
      "Iteration 952, loss = 0.04018230\n",
      "Iteration 953, loss = 0.04014512\n",
      "Iteration 954, loss = 0.04009397\n",
      "Iteration 955, loss = 0.04004977\n",
      "Iteration 956, loss = 0.04000305\n",
      "Iteration 957, loss = 0.03995746\n",
      "Iteration 958, loss = 0.03991365\n",
      "Iteration 959, loss = 0.03986882\n",
      "Iteration 960, loss = 0.03982486\n",
      "Iteration 961, loss = 0.03978179\n",
      "Iteration 962, loss = 0.03973665\n",
      "Iteration 963, loss = 0.03969414\n",
      "Iteration 964, loss = 0.03965124\n",
      "Iteration 965, loss = 0.03960809\n",
      "Iteration 966, loss = 0.03956309\n",
      "Iteration 967, loss = 0.03951956\n",
      "Iteration 968, loss = 0.03947557\n",
      "Iteration 969, loss = 0.03943451\n",
      "Iteration 970, loss = 0.03938981\n",
      "Iteration 971, loss = 0.03934567\n",
      "Iteration 972, loss = 0.03930349\n",
      "Iteration 973, loss = 0.03925978\n",
      "Iteration 974, loss = 0.03921793\n",
      "Iteration 975, loss = 0.03917591\n",
      "Iteration 976, loss = 0.03913403\n",
      "Iteration 977, loss = 0.03909392\n",
      "Iteration 978, loss = 0.03905307\n",
      "Iteration 979, loss = 0.03901261\n",
      "Iteration 980, loss = 0.03897168\n",
      "Iteration 981, loss = 0.03893119\n",
      "Iteration 982, loss = 0.03889353\n",
      "Iteration 983, loss = 0.03885221\n",
      "Iteration 984, loss = 0.03881167\n",
      "Iteration 985, loss = 0.03877650\n",
      "Iteration 986, loss = 0.03873366\n",
      "Iteration 987, loss = 0.03869250\n",
      "Iteration 988, loss = 0.03865247\n",
      "Iteration 989, loss = 0.03861417\n",
      "Iteration 990, loss = 0.03857249\n",
      "Iteration 991, loss = 0.03853346\n",
      "Iteration 992, loss = 0.03849548\n",
      "Iteration 993, loss = 0.03845429\n",
      "Iteration 994, loss = 0.03841193\n",
      "Iteration 995, loss = 0.03837181\n",
      "Iteration 996, loss = 0.03833265\n",
      "Iteration 997, loss = 0.03828982\n",
      "Iteration 998, loss = 0.03824844\n",
      "Iteration 999, loss = 0.03821421\n",
      "Iteration 1000, loss = 0.03817205\n",
      "Iteration 1001, loss = 0.03813578\n",
      "Iteration 1002, loss = 0.03809508\n",
      "Iteration 1003, loss = 0.03805454\n",
      "Iteration 1004, loss = 0.03801896\n",
      "Iteration 1005, loss = 0.03797577\n",
      "Iteration 1006, loss = 0.03793954\n",
      "Iteration 1007, loss = 0.03789742\n",
      "Iteration 1008, loss = 0.03785616\n",
      "Iteration 1009, loss = 0.03781569\n",
      "Iteration 1010, loss = 0.03777636\n",
      "Iteration 1011, loss = 0.03773481\n",
      "Iteration 1012, loss = 0.03769365\n",
      "Iteration 1013, loss = 0.03765436\n",
      "Iteration 1014, loss = 0.03761412\n",
      "Iteration 1015, loss = 0.03757445\n",
      "Iteration 1016, loss = 0.03753453\n",
      "Iteration 1017, loss = 0.03749692\n",
      "Iteration 1018, loss = 0.03745899\n",
      "Iteration 1019, loss = 0.03742050\n",
      "Iteration 1020, loss = 0.03738204\n",
      "Iteration 1021, loss = 0.03734153\n",
      "Iteration 1022, loss = 0.03729938\n",
      "Iteration 1023, loss = 0.03725936\n",
      "Iteration 1024, loss = 0.03721884\n",
      "Iteration 1025, loss = 0.03717502\n",
      "Iteration 1026, loss = 0.03713715\n",
      "Iteration 1027, loss = 0.03709800\n",
      "Iteration 1028, loss = 0.03706227\n",
      "Iteration 1029, loss = 0.03702630\n",
      "Iteration 1030, loss = 0.03697896\n",
      "Iteration 1031, loss = 0.03694074\n",
      "Iteration 1032, loss = 0.03690239\n",
      "Iteration 1033, loss = 0.03686115\n",
      "Iteration 1034, loss = 0.03682191\n",
      "Iteration 1035, loss = 0.03678800\n",
      "Iteration 1036, loss = 0.03674693\n",
      "Iteration 1037, loss = 0.03671012\n",
      "Iteration 1038, loss = 0.03667156\n",
      "Iteration 1039, loss = 0.03663813\n",
      "Iteration 1040, loss = 0.03659879\n",
      "Iteration 1041, loss = 0.03656200\n",
      "Iteration 1042, loss = 0.03652671\n",
      "Iteration 1043, loss = 0.03648726\n",
      "Iteration 1044, loss = 0.03644949\n",
      "Iteration 1045, loss = 0.03641331\n",
      "Iteration 1046, loss = 0.03637536\n",
      "Iteration 1047, loss = 0.03634078\n",
      "Iteration 1048, loss = 0.03630155\n",
      "Iteration 1049, loss = 0.03626757\n",
      "Iteration 1050, loss = 0.03622986\n",
      "Iteration 1051, loss = 0.03619330\n",
      "Iteration 1052, loss = 0.03615777\n",
      "Iteration 1053, loss = 0.03611572\n",
      "Iteration 1054, loss = 0.03608359\n",
      "Iteration 1055, loss = 0.03604470\n",
      "Iteration 1056, loss = 0.03600784\n",
      "Iteration 1057, loss = 0.03597088\n",
      "Iteration 1058, loss = 0.03593234\n",
      "Iteration 1059, loss = 0.03589621\n",
      "Iteration 1060, loss = 0.03585998\n",
      "Iteration 1061, loss = 0.03582012\n",
      "Iteration 1062, loss = 0.03578185\n",
      "Iteration 1063, loss = 0.03574761\n",
      "Iteration 1064, loss = 0.03570748\n",
      "Iteration 1065, loss = 0.03567049\n",
      "Iteration 1066, loss = 0.03563079\n",
      "Iteration 1067, loss = 0.03559721\n",
      "Iteration 1068, loss = 0.03555966\n",
      "Iteration 1069, loss = 0.03552176\n",
      "Iteration 1070, loss = 0.03548404\n",
      "Iteration 1071, loss = 0.03544437\n",
      "Iteration 1072, loss = 0.03540753\n",
      "Iteration 1073, loss = 0.03537152\n",
      "Iteration 1074, loss = 0.03533677\n",
      "Iteration 1075, loss = 0.03530025\n",
      "Iteration 1076, loss = 0.03527316\n",
      "Iteration 1077, loss = 0.03523429\n",
      "Iteration 1078, loss = 0.03520232\n",
      "Iteration 1079, loss = 0.03516796\n",
      "Iteration 1080, loss = 0.03513084\n",
      "Iteration 1081, loss = 0.03509653\n",
      "Iteration 1082, loss = 0.03506121\n",
      "Iteration 1083, loss = 0.03502414\n",
      "Iteration 1084, loss = 0.03498834\n",
      "Iteration 1085, loss = 0.03495156\n",
      "Iteration 1086, loss = 0.03491473\n",
      "Iteration 1087, loss = 0.03487718\n",
      "Iteration 1088, loss = 0.03484696\n",
      "Iteration 1089, loss = 0.03480657\n",
      "Iteration 1090, loss = 0.03476915\n",
      "Iteration 1091, loss = 0.03473450\n",
      "Iteration 1092, loss = 0.03470021\n",
      "Iteration 1093, loss = 0.03466448\n",
      "Iteration 1094, loss = 0.03462600\n",
      "Iteration 1095, loss = 0.03459700\n",
      "Iteration 1096, loss = 0.03455441\n",
      "Iteration 1097, loss = 0.03451694\n",
      "Iteration 1098, loss = 0.03448565\n",
      "Iteration 1099, loss = 0.03444716\n",
      "Iteration 1100, loss = 0.03441221\n",
      "Iteration 1101, loss = 0.03437702\n",
      "Iteration 1102, loss = 0.03434161\n",
      "Iteration 1103, loss = 0.03431124\n",
      "Iteration 1104, loss = 0.03427705\n",
      "Iteration 1105, loss = 0.03424301\n",
      "Iteration 1106, loss = 0.03420699\n",
      "Iteration 1107, loss = 0.03417177\n",
      "Iteration 1108, loss = 0.03413899\n",
      "Iteration 1109, loss = 0.03410518\n",
      "Iteration 1110, loss = 0.03407213\n",
      "Iteration 1111, loss = 0.03404213\n",
      "Iteration 1112, loss = 0.03400795\n",
      "Iteration 1113, loss = 0.03397420\n",
      "Iteration 1114, loss = 0.03393831\n",
      "Iteration 1115, loss = 0.03390579\n",
      "Iteration 1116, loss = 0.03387414\n",
      "Iteration 1117, loss = 0.03383990\n",
      "Iteration 1118, loss = 0.03380839\n",
      "Iteration 1119, loss = 0.03377680\n",
      "Iteration 1120, loss = 0.03374441\n",
      "Iteration 1121, loss = 0.03371141\n",
      "Iteration 1122, loss = 0.03367838\n",
      "Iteration 1123, loss = 0.03364551\n",
      "Iteration 1124, loss = 0.03361433\n",
      "Iteration 1125, loss = 0.03358593\n",
      "Iteration 1126, loss = 0.03354925\n",
      "Iteration 1127, loss = 0.03351883\n",
      "Iteration 1128, loss = 0.03348643\n",
      "Iteration 1129, loss = 0.03345660\n",
      "Iteration 1130, loss = 0.03342177\n",
      "Iteration 1131, loss = 0.03338983\n",
      "Iteration 1132, loss = 0.03335449\n",
      "Iteration 1133, loss = 0.03331982\n",
      "Iteration 1134, loss = 0.03329304\n",
      "Iteration 1135, loss = 0.03325961\n",
      "Iteration 1136, loss = 0.03322542\n",
      "Iteration 1137, loss = 0.03319328\n",
      "Iteration 1138, loss = 0.03315911\n",
      "Iteration 1139, loss = 0.03312574\n",
      "Iteration 1140, loss = 0.03309664\n",
      "Iteration 1141, loss = 0.03306003\n",
      "Iteration 1142, loss = 0.03302750\n",
      "Iteration 1143, loss = 0.03299581\n",
      "Iteration 1144, loss = 0.03296769\n",
      "Iteration 1145, loss = 0.03293134\n",
      "Iteration 1146, loss = 0.03289999\n",
      "Iteration 1147, loss = 0.03286602\n",
      "Iteration 1148, loss = 0.03283348\n",
      "Iteration 1149, loss = 0.03280133\n",
      "Iteration 1150, loss = 0.03276914\n",
      "Iteration 1151, loss = 0.03273524\n",
      "Iteration 1152, loss = 0.03270940\n",
      "Iteration 1153, loss = 0.03267874\n",
      "Iteration 1154, loss = 0.03264638\n",
      "Iteration 1155, loss = 0.03261677\n",
      "Iteration 1156, loss = 0.03258567\n",
      "Iteration 1157, loss = 0.03255875\n",
      "Iteration 1158, loss = 0.03252626\n",
      "Iteration 1159, loss = 0.03249822\n",
      "Iteration 1160, loss = 0.03246896\n",
      "Iteration 1161, loss = 0.03243766\n",
      "Iteration 1162, loss = 0.03240746\n",
      "Iteration 1163, loss = 0.03237749\n",
      "Iteration 1164, loss = 0.03234905\n",
      "Iteration 1165, loss = 0.03232007\n",
      "Iteration 1166, loss = 0.03229370\n",
      "Iteration 1167, loss = 0.03226331\n",
      "Iteration 1168, loss = 0.03223299\n",
      "Iteration 1169, loss = 0.03220854\n",
      "Iteration 1170, loss = 0.03217276\n",
      "Iteration 1171, loss = 0.03214377\n",
      "Iteration 1172, loss = 0.03211414\n",
      "Iteration 1173, loss = 0.03208082\n",
      "Iteration 1174, loss = 0.03205217\n",
      "Iteration 1175, loss = 0.03202067\n",
      "Iteration 1176, loss = 0.03199141\n",
      "Iteration 1177, loss = 0.03196328\n",
      "Iteration 1178, loss = 0.03193491\n",
      "Iteration 1179, loss = 0.03190851\n",
      "Iteration 1180, loss = 0.03188023\n",
      "Iteration 1181, loss = 0.03184880\n",
      "Iteration 1182, loss = 0.03182175\n",
      "Iteration 1183, loss = 0.03178988\n",
      "Iteration 1184, loss = 0.03176018\n",
      "Iteration 1185, loss = 0.03173138\n",
      "Iteration 1186, loss = 0.03169941\n",
      "Iteration 1187, loss = 0.03167335\n",
      "Iteration 1188, loss = 0.03164141\n",
      "Iteration 1189, loss = 0.03161263\n",
      "Iteration 1190, loss = 0.03158429\n",
      "Iteration 1191, loss = 0.03155701\n",
      "Iteration 1192, loss = 0.03152773\n",
      "Iteration 1193, loss = 0.03149973\n",
      "Iteration 1194, loss = 0.03147283\n",
      "Iteration 1195, loss = 0.03144619\n",
      "Iteration 1196, loss = 0.03141712\n",
      "Iteration 1197, loss = 0.03138867\n",
      "Iteration 1198, loss = 0.03135878\n",
      "Iteration 1199, loss = 0.03133434\n",
      "Iteration 1200, loss = 0.03130397\n",
      "Iteration 1201, loss = 0.03127589\n",
      "Iteration 1202, loss = 0.03125210\n",
      "Iteration 1203, loss = 0.03122066\n",
      "Iteration 1204, loss = 0.03119119\n",
      "Iteration 1205, loss = 0.03116473\n",
      "Iteration 1206, loss = 0.03113794\n",
      "Iteration 1207, loss = 0.03110770\n",
      "Iteration 1208, loss = 0.03108369\n",
      "Iteration 1209, loss = 0.03105430\n",
      "Iteration 1210, loss = 0.03102875\n",
      "Iteration 1211, loss = 0.03100301\n",
      "Iteration 1212, loss = 0.03097658\n",
      "Iteration 1213, loss = 0.03094883\n",
      "Iteration 1214, loss = 0.03092205\n",
      "Iteration 1215, loss = 0.03089509\n",
      "Iteration 1216, loss = 0.03086928\n",
      "Iteration 1217, loss = 0.03084224\n",
      "Iteration 1218, loss = 0.03081625\n",
      "Iteration 1219, loss = 0.03078929\n",
      "Iteration 1220, loss = 0.03076415\n",
      "Iteration 1221, loss = 0.03073886\n",
      "Iteration 1222, loss = 0.03071292\n",
      "Iteration 1223, loss = 0.03068908\n",
      "Iteration 1224, loss = 0.03065648\n",
      "Iteration 1225, loss = 0.03063685\n",
      "Iteration 1226, loss = 0.03060852\n",
      "Iteration 1227, loss = 0.03058110\n",
      "Iteration 1228, loss = 0.03054903\n",
      "Iteration 1229, loss = 0.03052271\n",
      "Iteration 1230, loss = 0.03049562\n",
      "Iteration 1231, loss = 0.03046819\n",
      "Iteration 1232, loss = 0.03043956\n",
      "Iteration 1233, loss = 0.03041571\n",
      "Iteration 1234, loss = 0.03038614\n",
      "Iteration 1235, loss = 0.03035772\n",
      "Iteration 1236, loss = 0.03033207\n",
      "Iteration 1237, loss = 0.03030703\n",
      "Iteration 1238, loss = 0.03028004\n",
      "Iteration 1239, loss = 0.03025239\n",
      "Iteration 1240, loss = 0.03022749\n",
      "Iteration 1241, loss = 0.03020061\n",
      "Iteration 1242, loss = 0.03017508\n",
      "Iteration 1243, loss = 0.03015229\n",
      "Iteration 1244, loss = 0.03012581\n",
      "Iteration 1245, loss = 0.03009711\n",
      "Iteration 1246, loss = 0.03006893\n",
      "Iteration 1247, loss = 0.03004178\n",
      "Iteration 1248, loss = 0.03001497\n",
      "Iteration 1249, loss = 0.02998627\n",
      "Iteration 1250, loss = 0.02995851\n",
      "Iteration 1251, loss = 0.02992921\n",
      "Iteration 1252, loss = 0.02990433\n",
      "Iteration 1253, loss = 0.02987641\n",
      "Iteration 1254, loss = 0.02984775\n",
      "Iteration 1255, loss = 0.02982064\n",
      "Iteration 1256, loss = 0.02979388\n",
      "Iteration 1257, loss = 0.02977197\n",
      "Iteration 1258, loss = 0.02974099\n",
      "Iteration 1259, loss = 0.02971453\n",
      "Iteration 1260, loss = 0.02968816\n",
      "Iteration 1261, loss = 0.02966120\n",
      "Iteration 1262, loss = 0.02963490\n",
      "Iteration 1263, loss = 0.02961061\n",
      "Iteration 1264, loss = 0.02958368\n",
      "Iteration 1265, loss = 0.02955843\n",
      "Iteration 1266, loss = 0.02953217\n",
      "Iteration 1267, loss = 0.02950840\n",
      "Iteration 1268, loss = 0.02948206\n",
      "Iteration 1269, loss = 0.02945738\n",
      "Iteration 1270, loss = 0.02943088\n",
      "Iteration 1271, loss = 0.02940728\n",
      "Iteration 1272, loss = 0.02937900\n",
      "Iteration 1273, loss = 0.02935557\n",
      "Iteration 1274, loss = 0.02932886\n",
      "Iteration 1275, loss = 0.02930117\n",
      "Iteration 1276, loss = 0.02927991\n",
      "Iteration 1277, loss = 0.02925045\n",
      "Iteration 1278, loss = 0.02922366\n",
      "Iteration 1279, loss = 0.02920025\n",
      "Iteration 1280, loss = 0.02917146\n",
      "Iteration 1281, loss = 0.02914631\n",
      "Iteration 1282, loss = 0.02912145\n",
      "Iteration 1283, loss = 0.02910366\n",
      "Iteration 1284, loss = 0.02907536\n",
      "Iteration 1285, loss = 0.02905072\n",
      "Iteration 1286, loss = 0.02902713\n",
      "Iteration 1287, loss = 0.02900321\n",
      "Iteration 1288, loss = 0.02897806\n",
      "Iteration 1289, loss = 0.02895178\n",
      "Iteration 1290, loss = 0.02892852\n",
      "Iteration 1291, loss = 0.02890254\n",
      "Iteration 1292, loss = 0.02887698\n",
      "Iteration 1293, loss = 0.02885413\n",
      "Iteration 1294, loss = 0.02882843\n",
      "Iteration 1295, loss = 0.02880326\n",
      "Iteration 1296, loss = 0.02878001\n",
      "Iteration 1297, loss = 0.02875627\n",
      "Iteration 1298, loss = 0.02873249\n",
      "Iteration 1299, loss = 0.02870647\n",
      "Iteration 1300, loss = 0.02868179\n",
      "Iteration 1301, loss = 0.02865733\n",
      "Iteration 1302, loss = 0.02863375\n",
      "Iteration 1303, loss = 0.02860712\n",
      "Iteration 1304, loss = 0.02858310\n",
      "Iteration 1305, loss = 0.02855878\n",
      "Iteration 1306, loss = 0.02853301\n",
      "Iteration 1307, loss = 0.02851068\n",
      "Iteration 1308, loss = 0.02848501\n",
      "Iteration 1309, loss = 0.02845850\n",
      "Iteration 1310, loss = 0.02843630\n",
      "Iteration 1311, loss = 0.02841178\n",
      "Iteration 1312, loss = 0.02838509\n",
      "Iteration 1313, loss = 0.02836090\n",
      "Iteration 1314, loss = 0.02833725\n",
      "Iteration 1315, loss = 0.02831450\n",
      "Iteration 1316, loss = 0.02828954\n",
      "Iteration 1317, loss = 0.02826512\n",
      "Iteration 1318, loss = 0.02824084\n",
      "Iteration 1319, loss = 0.02821760\n",
      "Iteration 1320, loss = 0.02819426\n",
      "Iteration 1321, loss = 0.02817040\n",
      "Iteration 1322, loss = 0.02814662\n",
      "Iteration 1323, loss = 0.02812523\n",
      "Iteration 1324, loss = 0.02810219\n",
      "Iteration 1325, loss = 0.02807617\n",
      "Iteration 1326, loss = 0.02805365\n",
      "Iteration 1327, loss = 0.02803033\n",
      "Iteration 1328, loss = 0.02800893\n",
      "Iteration 1329, loss = 0.02798691\n",
      "Iteration 1330, loss = 0.02796357\n",
      "Iteration 1331, loss = 0.02794127\n",
      "Iteration 1332, loss = 0.02791739\n",
      "Iteration 1333, loss = 0.02789335\n",
      "Iteration 1334, loss = 0.02787403\n",
      "Iteration 1335, loss = 0.02784892\n",
      "Iteration 1336, loss = 0.02782712\n",
      "Iteration 1337, loss = 0.02780419\n",
      "Iteration 1338, loss = 0.02778185\n",
      "Iteration 1339, loss = 0.02776453\n",
      "Iteration 1340, loss = 0.02773991\n",
      "Iteration 1341, loss = 0.02772262\n",
      "Iteration 1342, loss = 0.02769701\n",
      "Iteration 1343, loss = 0.02767496\n",
      "Iteration 1344, loss = 0.02765511\n",
      "Iteration 1345, loss = 0.02763314\n",
      "Iteration 1346, loss = 0.02761114\n",
      "Iteration 1347, loss = 0.02759119\n",
      "Iteration 1348, loss = 0.02756845\n",
      "Iteration 1349, loss = 0.02754573\n",
      "Iteration 1350, loss = 0.02752314\n",
      "Iteration 1351, loss = 0.02750043\n",
      "Iteration 1352, loss = 0.02747685\n",
      "Iteration 1353, loss = 0.02745486\n",
      "Iteration 1354, loss = 0.02743168\n",
      "Iteration 1355, loss = 0.02740986\n",
      "Iteration 1356, loss = 0.02738587\n",
      "Iteration 1357, loss = 0.02736557\n",
      "Iteration 1358, loss = 0.02734167\n",
      "Iteration 1359, loss = 0.02731956\n",
      "Iteration 1360, loss = 0.02729636\n",
      "Iteration 1361, loss = 0.02727564\n",
      "Iteration 1362, loss = 0.02725259\n",
      "Iteration 1363, loss = 0.02723138\n",
      "Iteration 1364, loss = 0.02720950\n",
      "Iteration 1365, loss = 0.02718631\n",
      "Iteration 1366, loss = 0.02716448\n",
      "Iteration 1367, loss = 0.02714215\n",
      "Iteration 1368, loss = 0.02712172\n",
      "Iteration 1369, loss = 0.02709871\n",
      "Iteration 1370, loss = 0.02707417\n",
      "Iteration 1371, loss = 0.02705809\n",
      "Iteration 1372, loss = 0.02703373\n",
      "Iteration 1373, loss = 0.02701142\n",
      "Iteration 1374, loss = 0.02699078\n",
      "Iteration 1375, loss = 0.02696941\n",
      "Iteration 1376, loss = 0.02694681\n",
      "Iteration 1377, loss = 0.02692504\n",
      "Iteration 1378, loss = 0.02690297\n",
      "Iteration 1379, loss = 0.02687896\n",
      "Iteration 1380, loss = 0.02685482\n",
      "Iteration 1381, loss = 0.02683535\n",
      "Iteration 1382, loss = 0.02680962\n",
      "Iteration 1383, loss = 0.02678736\n",
      "Iteration 1384, loss = 0.02676711\n",
      "Iteration 1385, loss = 0.02674139\n",
      "Iteration 1386, loss = 0.02672094\n",
      "Iteration 1387, loss = 0.02669906\n",
      "Iteration 1388, loss = 0.02667903\n",
      "Iteration 1389, loss = 0.02665636\n",
      "Iteration 1390, loss = 0.02663611\n",
      "Iteration 1391, loss = 0.02661257\n",
      "Iteration 1392, loss = 0.02659227\n",
      "Iteration 1393, loss = 0.02657159\n",
      "Iteration 1394, loss = 0.02654944\n",
      "Iteration 1395, loss = 0.02652964\n",
      "Iteration 1396, loss = 0.02650748\n",
      "Iteration 1397, loss = 0.02648494\n",
      "Iteration 1398, loss = 0.02646558\n",
      "Iteration 1399, loss = 0.02644287\n",
      "Iteration 1400, loss = 0.02642433\n",
      "Iteration 1401, loss = 0.02640238\n",
      "Iteration 1402, loss = 0.02638473\n",
      "Iteration 1403, loss = 0.02636083\n",
      "Iteration 1404, loss = 0.02633925\n",
      "Iteration 1405, loss = 0.02631905\n",
      "Iteration 1406, loss = 0.02629807\n",
      "Iteration 1407, loss = 0.02628031\n",
      "Iteration 1408, loss = 0.02626104\n",
      "Iteration 1409, loss = 0.02624180\n",
      "Iteration 1410, loss = 0.02621875\n",
      "Iteration 1411, loss = 0.02620160\n",
      "Iteration 1412, loss = 0.02618023\n",
      "Iteration 1413, loss = 0.02616200\n",
      "Iteration 1414, loss = 0.02614020\n",
      "Iteration 1415, loss = 0.02612061\n",
      "Iteration 1416, loss = 0.02610184\n",
      "Iteration 1417, loss = 0.02608040\n",
      "Iteration 1418, loss = 0.02606190\n",
      "Iteration 1419, loss = 0.02604467\n",
      "Iteration 1420, loss = 0.02602243\n",
      "Iteration 1421, loss = 0.02600307\n",
      "Iteration 1422, loss = 0.02598178\n",
      "Iteration 1423, loss = 0.02596053\n",
      "Iteration 1424, loss = 0.02593890\n",
      "Iteration 1425, loss = 0.02591966\n",
      "Iteration 1426, loss = 0.02589883\n",
      "Iteration 1427, loss = 0.02587963\n",
      "Iteration 1428, loss = 0.02585884\n",
      "Iteration 1429, loss = 0.02583884\n",
      "Iteration 1430, loss = 0.02581705\n",
      "Iteration 1431, loss = 0.02579567\n",
      "Iteration 1432, loss = 0.02577776\n",
      "Iteration 1433, loss = 0.02575513\n",
      "Iteration 1434, loss = 0.02573549\n",
      "Iteration 1435, loss = 0.02571571\n",
      "Iteration 1436, loss = 0.02569256\n",
      "Iteration 1437, loss = 0.02567360\n",
      "Iteration 1438, loss = 0.02565049\n",
      "Iteration 1439, loss = 0.02562833\n",
      "Iteration 1440, loss = 0.02561176\n",
      "Iteration 1441, loss = 0.02558769\n",
      "Iteration 1442, loss = 0.02556962\n",
      "Iteration 1443, loss = 0.02554800\n",
      "Iteration 1444, loss = 0.02552663\n",
      "Iteration 1445, loss = 0.02551022\n",
      "Iteration 1446, loss = 0.02548528\n",
      "Iteration 1447, loss = 0.02546385\n",
      "Iteration 1448, loss = 0.02544570\n",
      "Iteration 1449, loss = 0.02542967\n",
      "Iteration 1450, loss = 0.02540672\n",
      "Iteration 1451, loss = 0.02538886\n",
      "Iteration 1452, loss = 0.02536834\n",
      "Iteration 1453, loss = 0.02535225\n",
      "Iteration 1454, loss = 0.02533167\n",
      "Iteration 1455, loss = 0.02531083\n",
      "Iteration 1456, loss = 0.02529283\n",
      "Iteration 1457, loss = 0.02527235\n",
      "Iteration 1458, loss = 0.02525264\n",
      "Iteration 1459, loss = 0.02523384\n",
      "Iteration 1460, loss = 0.02521281\n",
      "Iteration 1461, loss = 0.02519214\n",
      "Iteration 1462, loss = 0.02517349\n",
      "Iteration 1463, loss = 0.02515267\n",
      "Iteration 1464, loss = 0.02513260\n",
      "Iteration 1465, loss = 0.02511236\n",
      "Iteration 1466, loss = 0.02509095\n",
      "Iteration 1467, loss = 0.02507773\n",
      "Iteration 1468, loss = 0.02505316\n",
      "Iteration 1469, loss = 0.02503391\n",
      "Iteration 1470, loss = 0.02501391\n",
      "Iteration 1471, loss = 0.02499565\n",
      "Iteration 1472, loss = 0.02497842\n",
      "Iteration 1473, loss = 0.02495804\n",
      "Iteration 1474, loss = 0.02493945\n",
      "Iteration 1475, loss = 0.02492289\n",
      "Iteration 1476, loss = 0.02490469\n",
      "Iteration 1477, loss = 0.02488566\n",
      "Iteration 1478, loss = 0.02486392\n",
      "Iteration 1479, loss = 0.02484593\n",
      "Iteration 1480, loss = 0.02482430\n",
      "Iteration 1481, loss = 0.02480648\n",
      "Iteration 1482, loss = 0.02478535\n",
      "Iteration 1483, loss = 0.02476582\n",
      "Iteration 1484, loss = 0.02474669\n",
      "Iteration 1485, loss = 0.02472762\n",
      "Iteration 1486, loss = 0.02471020\n",
      "Iteration 1487, loss = 0.02469006\n",
      "Iteration 1488, loss = 0.02467375\n",
      "Iteration 1489, loss = 0.02465364\n",
      "Iteration 1490, loss = 0.02463439\n",
      "Iteration 1491, loss = 0.02461634\n",
      "Iteration 1492, loss = 0.02459860\n",
      "Iteration 1493, loss = 0.02457790\n",
      "Iteration 1494, loss = 0.02455779\n",
      "Iteration 1495, loss = 0.02453891\n",
      "Iteration 1496, loss = 0.02452002\n",
      "Iteration 1497, loss = 0.02449938\n",
      "Iteration 1498, loss = 0.02447995\n",
      "Iteration 1499, loss = 0.02446110\n",
      "Iteration 1500, loss = 0.02444332\n",
      "Iteration 1501, loss = 0.02442301\n",
      "Iteration 1502, loss = 0.02440421\n",
      "Iteration 1503, loss = 0.02438623\n",
      "Iteration 1504, loss = 0.02436820\n",
      "Iteration 1505, loss = 0.02434948\n",
      "Iteration 1506, loss = 0.02433120\n",
      "Iteration 1507, loss = 0.02431363\n",
      "Iteration 1508, loss = 0.02429840\n",
      "Iteration 1509, loss = 0.02427876\n",
      "Iteration 1510, loss = 0.02426373\n",
      "Iteration 1511, loss = 0.02424642\n",
      "Iteration 1512, loss = 0.02423027\n",
      "Iteration 1513, loss = 0.02421047\n",
      "Iteration 1514, loss = 0.02419245\n",
      "Iteration 1515, loss = 0.02417381\n",
      "Iteration 1516, loss = 0.02415380\n",
      "Iteration 1517, loss = 0.02413554\n",
      "Iteration 1518, loss = 0.02411716\n",
      "Iteration 1519, loss = 0.02409556\n",
      "Iteration 1520, loss = 0.02407788\n",
      "Iteration 1521, loss = 0.02405793\n",
      "Iteration 1522, loss = 0.02403934\n",
      "Iteration 1523, loss = 0.02402061\n",
      "Iteration 1524, loss = 0.02400083\n",
      "Iteration 1525, loss = 0.02398413\n",
      "Iteration 1526, loss = 0.02396734\n",
      "Iteration 1527, loss = 0.02394626\n",
      "Iteration 1528, loss = 0.02392683\n",
      "Iteration 1529, loss = 0.02390914\n",
      "Iteration 1530, loss = 0.02389133\n",
      "Iteration 1531, loss = 0.02387362\n",
      "Iteration 1532, loss = 0.02385398\n",
      "Iteration 1533, loss = 0.02383455\n",
      "Iteration 1534, loss = 0.02381728\n",
      "Iteration 1535, loss = 0.02379906\n",
      "Iteration 1536, loss = 0.02378217\n",
      "Iteration 1537, loss = 0.02376497\n",
      "Iteration 1538, loss = 0.02374737\n",
      "Iteration 1539, loss = 0.02373079\n",
      "Iteration 1540, loss = 0.02371232\n",
      "Iteration 1541, loss = 0.02369635\n",
      "Iteration 1542, loss = 0.02367919\n",
      "Iteration 1543, loss = 0.02366190\n",
      "Iteration 1544, loss = 0.02364499\n",
      "Iteration 1545, loss = 0.02362765\n",
      "Iteration 1546, loss = 0.02361143\n",
      "Iteration 1547, loss = 0.02359301\n",
      "Iteration 1548, loss = 0.02357902\n",
      "Iteration 1549, loss = 0.02355636\n",
      "Iteration 1550, loss = 0.02353979\n",
      "Iteration 1551, loss = 0.02351989\n",
      "Iteration 1552, loss = 0.02350362\n",
      "Iteration 1553, loss = 0.02348630\n",
      "Iteration 1554, loss = 0.02346925\n",
      "Iteration 1555, loss = 0.02345129\n",
      "Iteration 1556, loss = 0.02343508\n",
      "Iteration 1557, loss = 0.02341707\n",
      "Iteration 1558, loss = 0.02339955\n",
      "Iteration 1559, loss = 0.02338265\n",
      "Iteration 1560, loss = 0.02336507\n",
      "Iteration 1561, loss = 0.02334824\n",
      "Iteration 1562, loss = 0.02333016\n",
      "Iteration 1563, loss = 0.02331417\n",
      "Iteration 1564, loss = 0.02329616\n",
      "Iteration 1565, loss = 0.02328034\n",
      "Iteration 1566, loss = 0.02326141\n",
      "Iteration 1567, loss = 0.02324497\n",
      "Iteration 1568, loss = 0.02322760\n",
      "Iteration 1569, loss = 0.02321114\n",
      "Iteration 1570, loss = 0.02319366\n",
      "Iteration 1571, loss = 0.02317624\n",
      "Iteration 1572, loss = 0.02316170\n",
      "Iteration 1573, loss = 0.02314174\n",
      "Iteration 1574, loss = 0.02312685\n",
      "Iteration 1575, loss = 0.02310660\n",
      "Iteration 1576, loss = 0.02309084\n",
      "Iteration 1577, loss = 0.02307466\n",
      "Iteration 1578, loss = 0.02305561\n",
      "Iteration 1579, loss = 0.02303802\n",
      "Iteration 1580, loss = 0.02302178\n",
      "Iteration 1581, loss = 0.02300412\n",
      "Iteration 1582, loss = 0.02298739\n",
      "Iteration 1583, loss = 0.02297507\n",
      "Iteration 1584, loss = 0.02296305\n",
      "Iteration 1585, loss = 0.02294418\n",
      "Iteration 1586, loss = 0.02292719\n",
      "Iteration 1587, loss = 0.02291015\n",
      "Iteration 1588, loss = 0.02289312\n",
      "Iteration 1589, loss = 0.02287646\n",
      "Iteration 1590, loss = 0.02286002\n",
      "Iteration 1591, loss = 0.02284281\n",
      "Iteration 1592, loss = 0.02282705\n",
      "Iteration 1593, loss = 0.02281350\n",
      "Iteration 1594, loss = 0.02279314\n",
      "Iteration 1595, loss = 0.02277755\n",
      "Iteration 1596, loss = 0.02276071\n",
      "Iteration 1597, loss = 0.02274399\n",
      "Iteration 1598, loss = 0.02272722\n",
      "Iteration 1599, loss = 0.02271092\n",
      "Iteration 1600, loss = 0.02269434\n",
      "Iteration 1601, loss = 0.02267734\n",
      "Iteration 1602, loss = 0.02266429\n",
      "Iteration 1603, loss = 0.02264516\n",
      "Iteration 1604, loss = 0.02262873\n",
      "Iteration 1605, loss = 0.02261263\n",
      "Iteration 1606, loss = 0.02259912\n",
      "Iteration 1607, loss = 0.02258208\n",
      "Iteration 1608, loss = 0.02256463\n",
      "Iteration 1609, loss = 0.02254954\n",
      "Iteration 1610, loss = 0.02253239\n",
      "Iteration 1611, loss = 0.02251750\n",
      "Iteration 1612, loss = 0.02250338\n",
      "Iteration 1613, loss = 0.02248610\n",
      "Iteration 1614, loss = 0.02247065\n",
      "Iteration 1615, loss = 0.02245448\n",
      "Iteration 1616, loss = 0.02243790\n",
      "Iteration 1617, loss = 0.02242223\n",
      "Iteration 1618, loss = 0.02240666\n",
      "Iteration 1619, loss = 0.02239108\n",
      "Iteration 1620, loss = 0.02237568\n",
      "Iteration 1621, loss = 0.02236124\n",
      "Iteration 1622, loss = 0.02234667\n",
      "Iteration 1623, loss = 0.02233089\n",
      "Iteration 1624, loss = 0.02231979\n",
      "Iteration 1625, loss = 0.02230115\n",
      "Iteration 1626, loss = 0.02228591\n",
      "Iteration 1627, loss = 0.02227023\n",
      "Iteration 1628, loss = 0.02225705\n",
      "Iteration 1629, loss = 0.02223900\n",
      "Iteration 1630, loss = 0.02222739\n",
      "Iteration 1631, loss = 0.02220595\n",
      "Iteration 1632, loss = 0.02219084\n",
      "Iteration 1633, loss = 0.02218019\n",
      "Iteration 1634, loss = 0.02215832\n",
      "Iteration 1635, loss = 0.02214340\n",
      "Iteration 1636, loss = 0.02212667\n",
      "Iteration 1637, loss = 0.02211080\n",
      "Iteration 1638, loss = 0.02209381\n",
      "Iteration 1639, loss = 0.02207716\n",
      "Iteration 1640, loss = 0.02206389\n",
      "Iteration 1641, loss = 0.02204508\n",
      "Iteration 1642, loss = 0.02203347\n",
      "Iteration 1643, loss = 0.02202016\n",
      "Iteration 1644, loss = 0.02200065\n",
      "Iteration 1645, loss = 0.02198629\n",
      "Iteration 1646, loss = 0.02197063\n",
      "Iteration 1647, loss = 0.02195488\n",
      "Iteration 1648, loss = 0.02194052\n",
      "Iteration 1649, loss = 0.02192537\n",
      "Iteration 1650, loss = 0.02191080\n",
      "Iteration 1651, loss = 0.02189497\n",
      "Iteration 1652, loss = 0.02188070\n",
      "Iteration 1653, loss = 0.02186599\n",
      "Iteration 1654, loss = 0.02185019\n",
      "Iteration 1655, loss = 0.02183657\n",
      "Iteration 1656, loss = 0.02182354\n",
      "Iteration 1657, loss = 0.02180893\n",
      "Iteration 1658, loss = 0.02179335\n",
      "Iteration 1659, loss = 0.02177796\n",
      "Iteration 1660, loss = 0.02176164\n",
      "Iteration 1661, loss = 0.02174688\n",
      "Iteration 1662, loss = 0.02173334\n",
      "Iteration 1663, loss = 0.02171641\n",
      "Iteration 1664, loss = 0.02170085\n",
      "Iteration 1665, loss = 0.02168492\n",
      "Iteration 1666, loss = 0.02166928\n",
      "Iteration 1667, loss = 0.02165595\n",
      "Iteration 1668, loss = 0.02164096\n",
      "Iteration 1669, loss = 0.02162453\n",
      "Iteration 1670, loss = 0.02160936\n",
      "Iteration 1671, loss = 0.02159473\n",
      "Iteration 1672, loss = 0.02157869\n",
      "Iteration 1673, loss = 0.02156320\n",
      "Iteration 1674, loss = 0.02154758\n",
      "Iteration 1675, loss = 0.02153383\n",
      "Iteration 1676, loss = 0.02151910\n",
      "Iteration 1677, loss = 0.02150137\n",
      "Iteration 1678, loss = 0.02148626\n",
      "Iteration 1679, loss = 0.02147621\n",
      "Iteration 1680, loss = 0.02145994\n",
      "Iteration 1681, loss = 0.02144601\n",
      "Iteration 1682, loss = 0.02143324\n",
      "Iteration 1683, loss = 0.02141846\n",
      "Iteration 1684, loss = 0.02140338\n",
      "Iteration 1685, loss = 0.02138994\n",
      "Iteration 1686, loss = 0.02137467\n",
      "Iteration 1687, loss = 0.02136026\n",
      "Iteration 1688, loss = 0.02134483\n",
      "Iteration 1689, loss = 0.02132950\n",
      "Iteration 1690, loss = 0.02131425\n",
      "Iteration 1691, loss = 0.02129919\n",
      "Iteration 1692, loss = 0.02128456\n",
      "Iteration 1693, loss = 0.02126928\n",
      "Iteration 1694, loss = 0.02125460\n",
      "Iteration 1695, loss = 0.02124013\n",
      "Iteration 1696, loss = 0.02122474\n",
      "Iteration 1697, loss = 0.02120989\n",
      "Iteration 1698, loss = 0.02119632\n",
      "Iteration 1699, loss = 0.02118382\n",
      "Iteration 1700, loss = 0.02116702\n",
      "Iteration 1701, loss = 0.02115320\n",
      "Iteration 1702, loss = 0.02113855\n",
      "Iteration 1703, loss = 0.02112431\n",
      "Iteration 1704, loss = 0.02111379\n",
      "Iteration 1705, loss = 0.02109575\n",
      "Iteration 1706, loss = 0.02108168\n",
      "Iteration 1707, loss = 0.02106642\n",
      "Iteration 1708, loss = 0.02105196\n",
      "Iteration 1709, loss = 0.02103802\n",
      "Iteration 1710, loss = 0.02102271\n",
      "Iteration 1711, loss = 0.02100913\n",
      "Iteration 1712, loss = 0.02099243\n",
      "Iteration 1713, loss = 0.02097712\n",
      "Iteration 1714, loss = 0.02096338\n",
      "Iteration 1715, loss = 0.02095255\n",
      "Iteration 1716, loss = 0.02093793\n",
      "Iteration 1717, loss = 0.02092916\n",
      "Iteration 1718, loss = 0.02091151\n",
      "Iteration 1719, loss = 0.02089739\n",
      "Iteration 1720, loss = 0.02088191\n",
      "Iteration 1721, loss = 0.02086732\n",
      "Iteration 1722, loss = 0.02085492\n",
      "Iteration 1723, loss = 0.02084044\n",
      "Iteration 1724, loss = 0.02082588\n",
      "Iteration 1725, loss = 0.02081209\n",
      "Iteration 1726, loss = 0.02079747\n",
      "Iteration 1727, loss = 0.02078522\n",
      "Iteration 1728, loss = 0.02076925\n",
      "Iteration 1729, loss = 0.02075528\n",
      "Iteration 1730, loss = 0.02074107\n",
      "Iteration 1731, loss = 0.02072513\n",
      "Iteration 1732, loss = 0.02071967\n",
      "Iteration 1733, loss = 0.02069793\n",
      "Iteration 1734, loss = 0.02068355\n",
      "Iteration 1735, loss = 0.02066998\n",
      "Iteration 1736, loss = 0.02065816\n",
      "Iteration 1737, loss = 0.02064483\n",
      "Iteration 1738, loss = 0.02063011\n",
      "Iteration 1739, loss = 0.02061660\n",
      "Iteration 1740, loss = 0.02060281\n",
      "Iteration 1741, loss = 0.02058898\n",
      "Iteration 1742, loss = 0.02057583\n",
      "Iteration 1743, loss = 0.02056250\n",
      "Iteration 1744, loss = 0.02054850\n",
      "Iteration 1745, loss = 0.02053518\n",
      "Iteration 1746, loss = 0.02052150\n",
      "Iteration 1747, loss = 0.02050954\n",
      "Iteration 1748, loss = 0.02049472\n",
      "Iteration 1749, loss = 0.02048196\n",
      "Iteration 1750, loss = 0.02046892\n",
      "Iteration 1751, loss = 0.02045467\n",
      "Iteration 1752, loss = 0.02044102\n",
      "Iteration 1753, loss = 0.02043039\n",
      "Iteration 1754, loss = 0.02041509\n",
      "Iteration 1755, loss = 0.02040139\n",
      "Iteration 1756, loss = 0.02038722\n",
      "Iteration 1757, loss = 0.02037745\n",
      "Iteration 1758, loss = 0.02036123\n",
      "Iteration 1759, loss = 0.02034777\n",
      "Iteration 1760, loss = 0.02033471\n",
      "Iteration 1761, loss = 0.02032053\n",
      "Iteration 1762, loss = 0.02030672\n",
      "Iteration 1763, loss = 0.02029665\n",
      "Iteration 1764, loss = 0.02028182\n",
      "Iteration 1765, loss = 0.02026735\n",
      "Iteration 1766, loss = 0.02025508\n",
      "Iteration 1767, loss = 0.02024174\n",
      "Iteration 1768, loss = 0.02023028\n",
      "Iteration 1769, loss = 0.02021840\n",
      "Iteration 1770, loss = 0.02020789\n",
      "Iteration 1771, loss = 0.02019308\n",
      "Iteration 1772, loss = 0.02017953\n",
      "Iteration 1773, loss = 0.02016638\n",
      "Iteration 1774, loss = 0.02015330\n",
      "Iteration 1775, loss = 0.02013927\n",
      "Iteration 1776, loss = 0.02012623\n",
      "Iteration 1777, loss = 0.02011249\n",
      "Iteration 1778, loss = 0.02009949\n",
      "Iteration 1779, loss = 0.02008590\n",
      "Iteration 1780, loss = 0.02007254\n",
      "Iteration 1781, loss = 0.02005989\n",
      "Iteration 1782, loss = 0.02005351\n",
      "Iteration 1783, loss = 0.02003402\n",
      "Iteration 1784, loss = 0.02002159\n",
      "Iteration 1785, loss = 0.02000665\n",
      "Iteration 1786, loss = 0.01999335\n",
      "Iteration 1787, loss = 0.01998065\n",
      "Iteration 1788, loss = 0.01996706\n",
      "Iteration 1789, loss = 0.01995300\n",
      "Iteration 1790, loss = 0.01993956\n",
      "Iteration 1791, loss = 0.01992496\n",
      "Iteration 1792, loss = 0.01991070\n",
      "Iteration 1793, loss = 0.01989769\n",
      "Iteration 1794, loss = 0.01988241\n",
      "Iteration 1795, loss = 0.01986958\n",
      "Iteration 1796, loss = 0.01985775\n",
      "Iteration 1797, loss = 0.01984454\n",
      "Iteration 1798, loss = 0.01983186\n",
      "Iteration 1799, loss = 0.01982344\n",
      "Iteration 1800, loss = 0.01980600\n",
      "Iteration 1801, loss = 0.01979190\n",
      "Iteration 1802, loss = 0.01977872\n",
      "Iteration 1803, loss = 0.01976565\n",
      "Iteration 1804, loss = 0.01975365\n",
      "Iteration 1805, loss = 0.01973912\n",
      "Iteration 1806, loss = 0.01972612\n",
      "Iteration 1807, loss = 0.01971749\n",
      "Iteration 1808, loss = 0.01969949\n",
      "Iteration 1809, loss = 0.01968639\n",
      "Iteration 1810, loss = 0.01967312\n",
      "Iteration 1811, loss = 0.01965926\n",
      "Iteration 1812, loss = 0.01964422\n",
      "Iteration 1813, loss = 0.01963478\n",
      "Iteration 1814, loss = 0.01961900\n",
      "Iteration 1815, loss = 0.01960499\n",
      "Iteration 1816, loss = 0.01959122\n",
      "Iteration 1817, loss = 0.01957662\n",
      "Iteration 1818, loss = 0.01956551\n",
      "Iteration 1819, loss = 0.01955531\n",
      "Iteration 1820, loss = 0.01953838\n",
      "Iteration 1821, loss = 0.01952612\n",
      "Iteration 1822, loss = 0.01951448\n",
      "Iteration 1823, loss = 0.01950018\n",
      "Iteration 1824, loss = 0.01948841\n",
      "Iteration 1825, loss = 0.01947528\n",
      "Iteration 1826, loss = 0.01946259\n",
      "Iteration 1827, loss = 0.01944952\n",
      "Iteration 1828, loss = 0.01943652\n",
      "Iteration 1829, loss = 0.01942457\n",
      "Iteration 1830, loss = 0.01941257\n",
      "Iteration 1831, loss = 0.01939936\n",
      "Iteration 1832, loss = 0.01938698\n",
      "Iteration 1833, loss = 0.01937506\n",
      "Iteration 1834, loss = 0.01936279\n",
      "Iteration 1835, loss = 0.01935111\n",
      "Iteration 1836, loss = 0.01933742\n",
      "Iteration 1837, loss = 0.01932561\n",
      "Iteration 1838, loss = 0.01931625\n",
      "Iteration 1839, loss = 0.01930071\n",
      "Iteration 1840, loss = 0.01928976\n",
      "Iteration 1841, loss = 0.01927954\n",
      "Iteration 1842, loss = 0.01926540\n",
      "Iteration 1843, loss = 0.01925251\n",
      "Iteration 1844, loss = 0.01924388\n",
      "Iteration 1845, loss = 0.01922977\n",
      "Iteration 1846, loss = 0.01921882\n",
      "Iteration 1847, loss = 0.01920816\n",
      "Iteration 1848, loss = 0.01919646\n",
      "Iteration 1849, loss = 0.01918676\n",
      "Iteration 1850, loss = 0.01917488\n",
      "Iteration 1851, loss = 0.01916232\n",
      "Iteration 1852, loss = 0.01915047\n",
      "Iteration 1853, loss = 0.01913844\n",
      "Iteration 1854, loss = 0.01912708\n",
      "Iteration 1855, loss = 0.01911689\n",
      "Iteration 1856, loss = 0.01910721\n",
      "Iteration 1857, loss = 0.01909680\n",
      "Iteration 1858, loss = 0.01908496\n",
      "Iteration 1859, loss = 0.01907383\n",
      "Iteration 1860, loss = 0.01906207\n",
      "Iteration 1861, loss = 0.01905061\n",
      "Iteration 1862, loss = 0.01903866\n",
      "Iteration 1863, loss = 0.01902663\n",
      "Iteration 1864, loss = 0.01901462\n",
      "Iteration 1865, loss = 0.01900183\n",
      "Iteration 1866, loss = 0.01899065\n",
      "Iteration 1867, loss = 0.01897790\n",
      "Iteration 1868, loss = 0.01896520\n",
      "Iteration 1869, loss = 0.01895519\n",
      "Iteration 1870, loss = 0.01894303\n",
      "Iteration 1871, loss = 0.01893064\n",
      "Iteration 1872, loss = 0.01891887\n",
      "Iteration 1873, loss = 0.01890548\n",
      "Iteration 1874, loss = 0.01889415\n",
      "Iteration 1875, loss = 0.01888201\n",
      "Iteration 1876, loss = 0.01886877\n",
      "Iteration 1877, loss = 0.01885592\n",
      "Iteration 1878, loss = 0.01884355\n",
      "Iteration 1879, loss = 0.01883357\n",
      "Iteration 1880, loss = 0.01882350\n",
      "Iteration 1881, loss = 0.01880905\n",
      "Iteration 1882, loss = 0.01879606\n",
      "Iteration 1883, loss = 0.01878471\n",
      "Iteration 1884, loss = 0.01877028\n",
      "Iteration 1885, loss = 0.01875697\n",
      "Iteration 1886, loss = 0.01874592\n",
      "Iteration 1887, loss = 0.01873202\n",
      "Iteration 1888, loss = 0.01871910\n",
      "Iteration 1889, loss = 0.01870602\n",
      "Iteration 1890, loss = 0.01869374\n",
      "Iteration 1891, loss = 0.01867972\n",
      "Iteration 1892, loss = 0.01866832\n",
      "Iteration 1893, loss = 0.01865708\n",
      "Iteration 1894, loss = 0.01864560\n",
      "Iteration 1895, loss = 0.01863086\n",
      "Iteration 1896, loss = 0.01861830\n",
      "Iteration 1897, loss = 0.01860693\n",
      "Iteration 1898, loss = 0.01859431\n",
      "Iteration 1899, loss = 0.01858249\n",
      "Iteration 1900, loss = 0.01856903\n",
      "Iteration 1901, loss = 0.01855559\n",
      "Iteration 1902, loss = 0.01854414\n",
      "Iteration 1903, loss = 0.01853040\n",
      "Iteration 1904, loss = 0.01851944\n",
      "Iteration 1905, loss = 0.01850801\n",
      "Iteration 1906, loss = 0.01849761\n",
      "Iteration 1907, loss = 0.01848480\n",
      "Iteration 1908, loss = 0.01847430\n",
      "Iteration 1909, loss = 0.01846062\n",
      "Iteration 1910, loss = 0.01845008\n",
      "Iteration 1911, loss = 0.01843760\n",
      "Iteration 1912, loss = 0.01842801\n",
      "Iteration 1913, loss = 0.01841529\n",
      "Iteration 1914, loss = 0.01840548\n",
      "Iteration 1915, loss = 0.01839237\n",
      "Iteration 1916, loss = 0.01838047\n",
      "Iteration 1917, loss = 0.01837045\n",
      "Iteration 1918, loss = 0.01835841\n",
      "Iteration 1919, loss = 0.01834562\n",
      "Iteration 1920, loss = 0.01833534\n",
      "Iteration 1921, loss = 0.01832368\n",
      "Iteration 1922, loss = 0.01831227\n",
      "Iteration 1923, loss = 0.01830171\n",
      "Iteration 1924, loss = 0.01829117\n",
      "Iteration 1925, loss = 0.01828237\n",
      "Iteration 1926, loss = 0.01826857\n",
      "Iteration 1927, loss = 0.01825686\n",
      "Iteration 1928, loss = 0.01824570\n",
      "Iteration 1929, loss = 0.01823315\n",
      "Iteration 1930, loss = 0.01822497\n",
      "Iteration 1931, loss = 0.01821200\n",
      "Iteration 1932, loss = 0.01820342\n",
      "Iteration 1933, loss = 0.01819169\n",
      "Iteration 1934, loss = 0.01818167\n",
      "Iteration 1935, loss = 0.01817333\n",
      "Iteration 1936, loss = 0.01816326\n",
      "Iteration 1937, loss = 0.01815124\n",
      "Iteration 1938, loss = 0.01813939\n",
      "Iteration 1939, loss = 0.01812984\n",
      "Iteration 1940, loss = 0.01811846\n",
      "Iteration 1941, loss = 0.01810745\n",
      "Iteration 1942, loss = 0.01809594\n",
      "Iteration 1943, loss = 0.01808665\n",
      "Iteration 1944, loss = 0.01807406\n",
      "Iteration 1945, loss = 0.01806251\n",
      "Iteration 1946, loss = 0.01805030\n",
      "Iteration 1947, loss = 0.01803924\n",
      "Iteration 1948, loss = 0.01802685\n",
      "Iteration 1949, loss = 0.01801509\n",
      "Iteration 1950, loss = 0.01800350\n",
      "Iteration 1951, loss = 0.01799308\n",
      "Iteration 1952, loss = 0.01798196\n",
      "Iteration 1953, loss = 0.01797117\n",
      "Iteration 1954, loss = 0.01796164\n",
      "Iteration 1955, loss = 0.01794973\n",
      "Iteration 1956, loss = 0.01793890\n",
      "Iteration 1957, loss = 0.01792897\n",
      "Iteration 1958, loss = 0.01791891\n",
      "Iteration 1959, loss = 0.01790706\n",
      "Iteration 1960, loss = 0.01789693\n",
      "Iteration 1961, loss = 0.01788812\n",
      "Iteration 1962, loss = 0.01787813\n",
      "Iteration 1963, loss = 0.01786819\n",
      "Iteration 1964, loss = 0.01785864\n",
      "Iteration 1965, loss = 0.01784740\n",
      "Iteration 1966, loss = 0.01783698\n",
      "Iteration 1967, loss = 0.01782860\n",
      "Iteration 1968, loss = 0.01781547\n",
      "Iteration 1969, loss = 0.01780467\n",
      "Iteration 1970, loss = 0.01779318\n",
      "Iteration 1971, loss = 0.01778324\n",
      "Iteration 1972, loss = 0.01777311\n",
      "Iteration 1973, loss = 0.01776611\n",
      "Iteration 1974, loss = 0.01775148\n",
      "Iteration 1975, loss = 0.01773994\n",
      "Iteration 1976, loss = 0.01772888\n",
      "Iteration 1977, loss = 0.01771750\n",
      "Iteration 1978, loss = 0.01770669\n",
      "Iteration 1979, loss = 0.01769492\n",
      "Iteration 1980, loss = 0.01768280\n",
      "Iteration 1981, loss = 0.01767231\n",
      "Iteration 1982, loss = 0.01765958\n",
      "Iteration 1983, loss = 0.01764815\n",
      "Iteration 1984, loss = 0.01763705\n",
      "Iteration 1985, loss = 0.01762583\n",
      "Iteration 1986, loss = 0.01761446\n",
      "Iteration 1987, loss = 0.01760421\n",
      "Iteration 1988, loss = 0.01759481\n",
      "Iteration 1989, loss = 0.01758336\n",
      "Iteration 1990, loss = 0.01757327\n",
      "Iteration 1991, loss = 0.01756282\n",
      "Iteration 1992, loss = 0.01755436\n",
      "Iteration 1993, loss = 0.01754272\n",
      "Iteration 1994, loss = 0.01753339\n",
      "Iteration 1995, loss = 0.01752305\n",
      "Iteration 1996, loss = 0.01751270\n",
      "Iteration 1997, loss = 0.01750314\n",
      "Iteration 1998, loss = 0.01749296\n",
      "Iteration 1999, loss = 0.01748235\n",
      "Iteration 2000, loss = 0.01747488\n",
      "Iteration 2001, loss = 0.01746278\n",
      "Iteration 2002, loss = 0.01745200\n",
      "Iteration 2003, loss = 0.01744308\n",
      "Iteration 2004, loss = 0.01743123\n",
      "Iteration 2005, loss = 0.01742264\n",
      "Iteration 2006, loss = 0.01741090\n",
      "Iteration 2007, loss = 0.01740121\n",
      "Iteration 2008, loss = 0.01739060\n",
      "Iteration 2009, loss = 0.01738048\n",
      "Iteration 2010, loss = 0.01737014\n",
      "Iteration 2011, loss = 0.01735982\n",
      "Iteration 2012, loss = 0.01734969\n",
      "Iteration 2013, loss = 0.01733954\n",
      "Iteration 2014, loss = 0.01732977\n",
      "Iteration 2015, loss = 0.01732112\n",
      "Iteration 2016, loss = 0.01730901\n",
      "Iteration 2017, loss = 0.01729766\n",
      "Iteration 2018, loss = 0.01728426\n",
      "Iteration 2019, loss = 0.01727412\n",
      "Iteration 2020, loss = 0.01726258\n",
      "Iteration 2021, loss = 0.01725000\n",
      "Iteration 2022, loss = 0.01723880\n",
      "Iteration 2023, loss = 0.01722838\n",
      "Iteration 2024, loss = 0.01721774\n",
      "Iteration 2025, loss = 0.01720598\n",
      "Iteration 2026, loss = 0.01719592\n",
      "Iteration 2027, loss = 0.01718604\n",
      "Iteration 2028, loss = 0.01717452\n",
      "Iteration 2029, loss = 0.01716574\n",
      "Iteration 2030, loss = 0.01715409\n",
      "Iteration 2031, loss = 0.01714275\n",
      "Iteration 2032, loss = 0.01713322\n",
      "Iteration 2033, loss = 0.01712215\n",
      "Iteration 2034, loss = 0.01711229\n",
      "Iteration 2035, loss = 0.01710047\n",
      "Iteration 2036, loss = 0.01709078\n",
      "Iteration 2037, loss = 0.01708244\n",
      "Iteration 2038, loss = 0.01707000\n",
      "Iteration 2039, loss = 0.01705897\n",
      "Iteration 2040, loss = 0.01704760\n",
      "Iteration 2041, loss = 0.01703875\n",
      "Iteration 2042, loss = 0.01702735\n",
      "Iteration 2043, loss = 0.01701682\n",
      "Iteration 2044, loss = 0.01700429\n",
      "Iteration 2045, loss = 0.01699470\n",
      "Iteration 2046, loss = 0.01698364\n",
      "Iteration 2047, loss = 0.01697258\n",
      "Iteration 2048, loss = 0.01696366\n",
      "Iteration 2049, loss = 0.01695170\n",
      "Iteration 2050, loss = 0.01694005\n",
      "Iteration 2051, loss = 0.01693077\n",
      "Iteration 2052, loss = 0.01692174\n",
      "Iteration 2053, loss = 0.01691042\n",
      "Iteration 2054, loss = 0.01690144\n",
      "Iteration 2055, loss = 0.01688886\n",
      "Iteration 2056, loss = 0.01687930\n",
      "Iteration 2057, loss = 0.01687178\n",
      "Iteration 2058, loss = 0.01685873\n",
      "Iteration 2059, loss = 0.01685005\n",
      "Iteration 2060, loss = 0.01683931\n",
      "Iteration 2061, loss = 0.01682856\n",
      "Iteration 2062, loss = 0.01681921\n",
      "Iteration 2063, loss = 0.01680817\n",
      "Iteration 2064, loss = 0.01679863\n",
      "Iteration 2065, loss = 0.01678809\n",
      "Iteration 2066, loss = 0.01677844\n",
      "Iteration 2067, loss = 0.01676825\n",
      "Iteration 2068, loss = 0.01675883\n",
      "Iteration 2069, loss = 0.01674890\n",
      "Iteration 2070, loss = 0.01673966\n",
      "Iteration 2071, loss = 0.01673092\n",
      "Iteration 2072, loss = 0.01672104\n",
      "Iteration 2073, loss = 0.01671478\n",
      "Iteration 2074, loss = 0.01670183\n",
      "Iteration 2075, loss = 0.01669121\n",
      "Iteration 2076, loss = 0.01668133\n",
      "Iteration 2077, loss = 0.01667166\n",
      "Iteration 2078, loss = 0.01666014\n",
      "Iteration 2079, loss = 0.01665184\n",
      "Iteration 2080, loss = 0.01664017\n",
      "Iteration 2081, loss = 0.01662981\n",
      "Iteration 2082, loss = 0.01661927\n",
      "Iteration 2083, loss = 0.01661019\n",
      "Iteration 2084, loss = 0.01659948\n",
      "Iteration 2085, loss = 0.01659115\n",
      "Iteration 2086, loss = 0.01658026\n",
      "Iteration 2087, loss = 0.01657178\n",
      "Iteration 2088, loss = 0.01656227\n",
      "Iteration 2089, loss = 0.01655515\n",
      "Iteration 2090, loss = 0.01654554\n",
      "Iteration 2091, loss = 0.01653809\n",
      "Iteration 2092, loss = 0.01652777\n",
      "Iteration 2093, loss = 0.01651920\n",
      "Iteration 2094, loss = 0.01651063\n",
      "Iteration 2095, loss = 0.01650144\n",
      "Iteration 2096, loss = 0.01649186\n",
      "Iteration 2097, loss = 0.01648155\n",
      "Iteration 2098, loss = 0.01647307\n",
      "Iteration 2099, loss = 0.01646305\n",
      "Iteration 2100, loss = 0.01645189\n",
      "Iteration 2101, loss = 0.01644224\n",
      "Iteration 2102, loss = 0.01643257\n",
      "Iteration 2103, loss = 0.01642212\n",
      "Iteration 2104, loss = 0.01641374\n",
      "Iteration 2105, loss = 0.01640307\n",
      "Iteration 2106, loss = 0.01639320\n",
      "Iteration 2107, loss = 0.01638173\n",
      "Iteration 2108, loss = 0.01637223\n",
      "Iteration 2109, loss = 0.01636237\n",
      "Iteration 2110, loss = 0.01635436\n",
      "Iteration 2111, loss = 0.01634279\n",
      "Iteration 2112, loss = 0.01633415\n",
      "Iteration 2113, loss = 0.01632390\n",
      "Iteration 2114, loss = 0.01631544\n",
      "Iteration 2115, loss = 0.01630573\n",
      "Iteration 2116, loss = 0.01629673\n",
      "Iteration 2117, loss = 0.01628720\n",
      "Iteration 2118, loss = 0.01627688\n",
      "Iteration 2119, loss = 0.01626782\n",
      "Iteration 2120, loss = 0.01625682\n",
      "Iteration 2121, loss = 0.01624764\n",
      "Iteration 2122, loss = 0.01623715\n",
      "Iteration 2123, loss = 0.01622773\n",
      "Iteration 2124, loss = 0.01621850\n",
      "Iteration 2125, loss = 0.01620840\n",
      "Iteration 2126, loss = 0.01619949\n",
      "Iteration 2127, loss = 0.01618962\n",
      "Iteration 2128, loss = 0.01617935\n",
      "Iteration 2129, loss = 0.01616921\n",
      "Iteration 2130, loss = 0.01616092\n",
      "Iteration 2131, loss = 0.01615171\n",
      "Iteration 2132, loss = 0.01614276\n",
      "Iteration 2133, loss = 0.01613394\n",
      "Iteration 2134, loss = 0.01612219\n",
      "Iteration 2135, loss = 0.01611386\n",
      "Iteration 2136, loss = 0.01610536\n",
      "Iteration 2137, loss = 0.01609484\n",
      "Iteration 2138, loss = 0.01608459\n",
      "Iteration 2139, loss = 0.01607449\n",
      "Iteration 2140, loss = 0.01606633\n",
      "Iteration 2141, loss = 0.01605693\n",
      "Iteration 2142, loss = 0.01604679\n",
      "Iteration 2143, loss = 0.01603808\n",
      "Iteration 2144, loss = 0.01602747\n",
      "Iteration 2145, loss = 0.01601846\n",
      "Iteration 2146, loss = 0.01601025\n",
      "Iteration 2147, loss = 0.01599981\n",
      "Iteration 2148, loss = 0.01599119\n",
      "Iteration 2149, loss = 0.01598188\n",
      "Iteration 2150, loss = 0.01597387\n",
      "Iteration 2151, loss = 0.01596432\n",
      "Iteration 2152, loss = 0.01595514\n",
      "Iteration 2153, loss = 0.01594700\n",
      "Iteration 2154, loss = 0.01593683\n",
      "Iteration 2155, loss = 0.01592744\n",
      "Iteration 2156, loss = 0.01591880\n",
      "Iteration 2157, loss = 0.01590889\n",
      "Iteration 2158, loss = 0.01589860\n",
      "Iteration 2159, loss = 0.01588995\n",
      "Iteration 2160, loss = 0.01587984\n",
      "Iteration 2161, loss = 0.01587243\n",
      "Iteration 2162, loss = 0.01586545\n",
      "Iteration 2163, loss = 0.01585294\n",
      "Iteration 2164, loss = 0.01584310\n",
      "Iteration 2165, loss = 0.01583446\n",
      "Iteration 2166, loss = 0.01582309\n",
      "Iteration 2167, loss = 0.01581437\n",
      "Iteration 2168, loss = 0.01580420\n",
      "Iteration 2169, loss = 0.01579325\n",
      "Iteration 2170, loss = 0.01578690\n",
      "Iteration 2171, loss = 0.01577802\n",
      "Iteration 2172, loss = 0.01576748\n",
      "Iteration 2173, loss = 0.01576018\n",
      "Iteration 2174, loss = 0.01575152\n",
      "Iteration 2175, loss = 0.01574421\n",
      "Iteration 2176, loss = 0.01573412\n",
      "Iteration 2177, loss = 0.01572465\n",
      "Iteration 2178, loss = 0.01571487\n",
      "Iteration 2179, loss = 0.01570665\n",
      "Iteration 2180, loss = 0.01569774\n",
      "Iteration 2181, loss = 0.01568883\n",
      "Iteration 2182, loss = 0.01567857\n",
      "Iteration 2183, loss = 0.01566855\n",
      "Iteration 2184, loss = 0.01566062\n",
      "Iteration 2185, loss = 0.01565062\n",
      "Iteration 2186, loss = 0.01564268\n",
      "Iteration 2187, loss = 0.01563290\n",
      "Iteration 2188, loss = 0.01562536\n",
      "Iteration 2189, loss = 0.01561579\n",
      "Iteration 2190, loss = 0.01560715\n",
      "Iteration 2191, loss = 0.01559804\n",
      "Iteration 2192, loss = 0.01559027\n",
      "Iteration 2193, loss = 0.01557989\n",
      "Iteration 2194, loss = 0.01557205\n",
      "Iteration 2195, loss = 0.01556141\n",
      "Iteration 2196, loss = 0.01555269\n",
      "Iteration 2197, loss = 0.01554411\n",
      "Iteration 2198, loss = 0.01553483\n",
      "Iteration 2199, loss = 0.01552589\n",
      "Iteration 2200, loss = 0.01551791\n",
      "Iteration 2201, loss = 0.01550922\n",
      "Iteration 2202, loss = 0.01550100\n",
      "Iteration 2203, loss = 0.01549375\n",
      "Iteration 2204, loss = 0.01548472\n",
      "Iteration 2205, loss = 0.01547611\n",
      "Iteration 2206, loss = 0.01546798\n",
      "Iteration 2207, loss = 0.01546157\n",
      "Iteration 2208, loss = 0.01545301\n",
      "Iteration 2209, loss = 0.01544408\n",
      "Iteration 2210, loss = 0.01543628\n",
      "Iteration 2211, loss = 0.01542765\n",
      "Iteration 2212, loss = 0.01541824\n",
      "Iteration 2213, loss = 0.01541038\n",
      "Iteration 2214, loss = 0.01540247\n",
      "Iteration 2215, loss = 0.01539520\n",
      "Iteration 2216, loss = 0.01538808\n",
      "Iteration 2217, loss = 0.01537696\n",
      "Iteration 2218, loss = 0.01536896\n",
      "Iteration 2219, loss = 0.01536020\n",
      "Iteration 2220, loss = 0.01535078\n",
      "Iteration 2221, loss = 0.01534134\n",
      "Iteration 2222, loss = 0.01533254\n",
      "Iteration 2223, loss = 0.01532297\n",
      "Iteration 2224, loss = 0.01531515\n",
      "Iteration 2225, loss = 0.01530573\n",
      "Iteration 2226, loss = 0.01529687\n",
      "Iteration 2227, loss = 0.01528882\n",
      "Iteration 2228, loss = 0.01528048\n",
      "Iteration 2229, loss = 0.01527396\n",
      "Iteration 2230, loss = 0.01526482\n",
      "Iteration 2231, loss = 0.01525628\n",
      "Iteration 2232, loss = 0.01524801\n",
      "Iteration 2233, loss = 0.01523968\n",
      "Iteration 2234, loss = 0.01523188\n",
      "Iteration 2235, loss = 0.01522369\n",
      "Iteration 2236, loss = 0.01521640\n",
      "Iteration 2237, loss = 0.01520817\n",
      "Iteration 2238, loss = 0.01519998\n",
      "Iteration 2239, loss = 0.01519154\n",
      "Iteration 2240, loss = 0.01518148\n",
      "Iteration 2241, loss = 0.01517385\n",
      "Iteration 2242, loss = 0.01516395\n",
      "Iteration 2243, loss = 0.01515403\n",
      "Iteration 2244, loss = 0.01514641\n",
      "Iteration 2245, loss = 0.01513871\n",
      "Iteration 2246, loss = 0.01512784\n",
      "Iteration 2247, loss = 0.01512026\n",
      "Iteration 2248, loss = 0.01511256\n",
      "Iteration 2249, loss = 0.01510354\n",
      "Iteration 2250, loss = 0.01509496\n",
      "Iteration 2251, loss = 0.01508966\n",
      "Iteration 2252, loss = 0.01508166\n",
      "Iteration 2253, loss = 0.01507298\n",
      "Iteration 2254, loss = 0.01506366\n",
      "Iteration 2255, loss = 0.01505672\n",
      "Iteration 2256, loss = 0.01504748\n",
      "Iteration 2257, loss = 0.01503971\n",
      "Iteration 2258, loss = 0.01503218\n",
      "Iteration 2259, loss = 0.01502349\n",
      "Iteration 2260, loss = 0.01501460\n",
      "Iteration 2261, loss = 0.01500957\n",
      "Iteration 2262, loss = 0.01499750\n",
      "Iteration 2263, loss = 0.01498907\n",
      "Iteration 2264, loss = 0.01497995\n",
      "Iteration 2265, loss = 0.01497095\n",
      "Iteration 2266, loss = 0.01496355\n",
      "Iteration 2267, loss = 0.01495652\n",
      "Iteration 2268, loss = 0.01494763\n",
      "Iteration 2269, loss = 0.01493985\n",
      "Iteration 2270, loss = 0.01493170\n",
      "Iteration 2271, loss = 0.01492393\n",
      "Iteration 2272, loss = 0.01491649\n",
      "Iteration 2273, loss = 0.01490933\n",
      "Iteration 2274, loss = 0.01489980\n",
      "Iteration 2275, loss = 0.01489380\n",
      "Iteration 2276, loss = 0.01488311\n",
      "Iteration 2277, loss = 0.01487390\n",
      "Iteration 2278, loss = 0.01486433\n",
      "Iteration 2279, loss = 0.01485656\n",
      "Iteration 2280, loss = 0.01484852\n",
      "Iteration 2281, loss = 0.01484072\n",
      "Iteration 2282, loss = 0.01483146\n",
      "Iteration 2283, loss = 0.01482409\n",
      "Iteration 2284, loss = 0.01481453\n",
      "Iteration 2285, loss = 0.01480657\n",
      "Iteration 2286, loss = 0.01479809\n",
      "Iteration 2287, loss = 0.01478976\n",
      "Iteration 2288, loss = 0.01478090\n",
      "Iteration 2289, loss = 0.01477422\n",
      "Iteration 2290, loss = 0.01476606\n",
      "Iteration 2291, loss = 0.01475761\n",
      "Iteration 2292, loss = 0.01474907\n",
      "Iteration 2293, loss = 0.01474034\n",
      "Iteration 2294, loss = 0.01473292\n",
      "Iteration 2295, loss = 0.01472441\n",
      "Iteration 2296, loss = 0.01471697\n",
      "Iteration 2297, loss = 0.01470811\n",
      "Iteration 2298, loss = 0.01470055\n",
      "Iteration 2299, loss = 0.01469249\n",
      "Iteration 2300, loss = 0.01468604\n",
      "Iteration 2301, loss = 0.01467629\n",
      "Iteration 2302, loss = 0.01466832\n",
      "Iteration 2303, loss = 0.01465943\n",
      "Iteration 2304, loss = 0.01465064\n",
      "Iteration 2305, loss = 0.01464209\n",
      "Iteration 2306, loss = 0.01463412\n",
      "Iteration 2307, loss = 0.01462770\n",
      "Iteration 2308, loss = 0.01461933\n",
      "Iteration 2309, loss = 0.01460982\n",
      "Iteration 2310, loss = 0.01460144\n",
      "Iteration 2311, loss = 0.01459583\n",
      "Iteration 2312, loss = 0.01458569\n",
      "Iteration 2313, loss = 0.01457719\n",
      "Iteration 2314, loss = 0.01457006\n",
      "Iteration 2315, loss = 0.01456221\n",
      "Iteration 2316, loss = 0.01455406\n",
      "Iteration 2317, loss = 0.01454554\n",
      "Iteration 2318, loss = 0.01453810\n",
      "Iteration 2319, loss = 0.01453000\n",
      "Iteration 2320, loss = 0.01452303\n",
      "Iteration 2321, loss = 0.01451549\n",
      "Iteration 2322, loss = 0.01450686\n",
      "Iteration 2323, loss = 0.01449837\n",
      "Iteration 2324, loss = 0.01449023\n",
      "Iteration 2325, loss = 0.01448354\n",
      "Iteration 2326, loss = 0.01447510\n",
      "Iteration 2327, loss = 0.01446695\n",
      "Iteration 2328, loss = 0.01445877\n",
      "Iteration 2329, loss = 0.01444979\n",
      "Iteration 2330, loss = 0.01444402\n",
      "Iteration 2331, loss = 0.01443447\n",
      "Iteration 2332, loss = 0.01442727\n",
      "Iteration 2333, loss = 0.01441963\n",
      "Iteration 2334, loss = 0.01441043\n",
      "Iteration 2335, loss = 0.01440335\n",
      "Iteration 2336, loss = 0.01439517\n",
      "Iteration 2337, loss = 0.01438679\n",
      "Iteration 2338, loss = 0.01438050\n",
      "Iteration 2339, loss = 0.01437174\n",
      "Iteration 2340, loss = 0.01436522\n",
      "Iteration 2341, loss = 0.01435662\n",
      "Iteration 2342, loss = 0.01434893\n",
      "Iteration 2343, loss = 0.01434167\n",
      "Iteration 2344, loss = 0.01433359\n",
      "Iteration 2345, loss = 0.01432617\n",
      "Iteration 2346, loss = 0.01432041\n",
      "Iteration 2347, loss = 0.01431091\n",
      "Iteration 2348, loss = 0.01430155\n",
      "Iteration 2349, loss = 0.01429377\n",
      "Iteration 2350, loss = 0.01428623\n",
      "Iteration 2351, loss = 0.01427836\n",
      "Iteration 2352, loss = 0.01426984\n",
      "Iteration 2353, loss = 0.01426332\n",
      "Iteration 2354, loss = 0.01425551\n",
      "Iteration 2355, loss = 0.01424607\n",
      "Iteration 2356, loss = 0.01424111\n",
      "Iteration 2357, loss = 0.01422915\n",
      "Iteration 2358, loss = 0.01422099\n",
      "Iteration 2359, loss = 0.01421375\n",
      "Iteration 2360, loss = 0.01420516\n",
      "Iteration 2361, loss = 0.01419710\n",
      "Iteration 2362, loss = 0.01418921\n",
      "Iteration 2363, loss = 0.01418143\n",
      "Iteration 2364, loss = 0.01417241\n",
      "Iteration 2365, loss = 0.01416364\n",
      "Iteration 2366, loss = 0.01415667\n",
      "Iteration 2367, loss = 0.01414756\n",
      "Iteration 2368, loss = 0.01414151\n",
      "Iteration 2369, loss = 0.01413198\n",
      "Iteration 2370, loss = 0.01412437\n",
      "Iteration 2371, loss = 0.01411748\n",
      "Iteration 2372, loss = 0.01411095\n",
      "Iteration 2373, loss = 0.01410180\n",
      "Iteration 2374, loss = 0.01409418\n",
      "Iteration 2375, loss = 0.01408651\n",
      "Iteration 2376, loss = 0.01407807\n",
      "Iteration 2377, loss = 0.01407033\n",
      "Iteration 2378, loss = 0.01406268\n",
      "Iteration 2379, loss = 0.01405588\n",
      "Iteration 2380, loss = 0.01404756\n",
      "Iteration 2381, loss = 0.01403980\n",
      "Iteration 2382, loss = 0.01403269\n",
      "Iteration 2383, loss = 0.01402686\n",
      "Iteration 2384, loss = 0.01401892\n",
      "Iteration 2385, loss = 0.01401178\n",
      "Iteration 2386, loss = 0.01400443\n",
      "Iteration 2387, loss = 0.01399757\n",
      "Iteration 2388, loss = 0.01399049\n",
      "Iteration 2389, loss = 0.01398239\n",
      "Iteration 2390, loss = 0.01397511\n",
      "Iteration 2391, loss = 0.01396717\n",
      "Iteration 2392, loss = 0.01395961\n",
      "Iteration 2393, loss = 0.01395238\n",
      "Iteration 2394, loss = 0.01394496\n",
      "Iteration 2395, loss = 0.01393922\n",
      "Iteration 2396, loss = 0.01392958\n",
      "Iteration 2397, loss = 0.01392217\n",
      "Iteration 2398, loss = 0.01391529\n",
      "Iteration 2399, loss = 0.01390610\n",
      "Iteration 2400, loss = 0.01389994\n",
      "Iteration 2401, loss = 0.01389242\n",
      "Iteration 2402, loss = 0.01388332\n",
      "Iteration 2403, loss = 0.01387547\n",
      "Iteration 2404, loss = 0.01386853\n",
      "Iteration 2405, loss = 0.01386188\n",
      "Iteration 2406, loss = 0.01385333\n",
      "Iteration 2407, loss = 0.01384573\n",
      "Iteration 2408, loss = 0.01383876\n",
      "Iteration 2409, loss = 0.01383153\n",
      "Iteration 2410, loss = 0.01382463\n",
      "Iteration 2411, loss = 0.01381674\n",
      "Iteration 2412, loss = 0.01381006\n",
      "Iteration 2413, loss = 0.01380271\n",
      "Iteration 2414, loss = 0.01379637\n",
      "Iteration 2415, loss = 0.01378632\n",
      "Iteration 2416, loss = 0.01377813\n",
      "Iteration 2417, loss = 0.01377017\n",
      "Iteration 2418, loss = 0.01376524\n",
      "Iteration 2419, loss = 0.01375533\n",
      "Iteration 2420, loss = 0.01374836\n",
      "Iteration 2421, loss = 0.01374121\n",
      "Iteration 2422, loss = 0.01373368\n",
      "Iteration 2423, loss = 0.01372657\n",
      "Iteration 2424, loss = 0.01371907\n",
      "Iteration 2425, loss = 0.01371139\n",
      "Iteration 2426, loss = 0.01370499\n",
      "Iteration 2427, loss = 0.01369756\n",
      "Iteration 2428, loss = 0.01369138\n",
      "Iteration 2429, loss = 0.01368395\n",
      "Iteration 2430, loss = 0.01367697\n",
      "Iteration 2431, loss = 0.01367014\n",
      "Iteration 2432, loss = 0.01366288\n",
      "Iteration 2433, loss = 0.01365674\n",
      "Iteration 2434, loss = 0.01364923\n",
      "Iteration 2435, loss = 0.01364334\n",
      "Iteration 2436, loss = 0.01363627\n",
      "Iteration 2437, loss = 0.01362907\n",
      "Iteration 2438, loss = 0.01362222\n",
      "Iteration 2439, loss = 0.01361611\n",
      "Iteration 2440, loss = 0.01360978\n",
      "Iteration 2441, loss = 0.01360319\n",
      "Iteration 2442, loss = 0.01359686\n",
      "Iteration 2443, loss = 0.01359000\n",
      "Iteration 2444, loss = 0.01358576\n",
      "Iteration 2445, loss = 0.01357995\n",
      "Iteration 2446, loss = 0.01357207\n",
      "Iteration 2447, loss = 0.01356655\n",
      "Iteration 2448, loss = 0.01355752\n",
      "Iteration 2449, loss = 0.01355091\n",
      "Iteration 2450, loss = 0.01354339\n",
      "Iteration 2451, loss = 0.01353684\n",
      "Iteration 2452, loss = 0.01352996\n",
      "Iteration 2453, loss = 0.01352380\n",
      "Iteration 2454, loss = 0.01351773\n",
      "Iteration 2455, loss = 0.01351118\n",
      "Iteration 2456, loss = 0.01350542\n",
      "Iteration 2457, loss = 0.01349811\n",
      "Iteration 2458, loss = 0.01349092\n",
      "Iteration 2459, loss = 0.01348487\n",
      "Iteration 2460, loss = 0.01347830\n",
      "Iteration 2461, loss = 0.01346960\n",
      "Iteration 2462, loss = 0.01346276\n",
      "Iteration 2463, loss = 0.01345571\n",
      "Iteration 2464, loss = 0.01344733\n",
      "Iteration 2465, loss = 0.01343972\n",
      "Iteration 2466, loss = 0.01343371\n",
      "Iteration 2467, loss = 0.01342460\n",
      "Iteration 2468, loss = 0.01341847\n",
      "Iteration 2469, loss = 0.01341016\n",
      "Iteration 2470, loss = 0.01340249\n",
      "Iteration 2471, loss = 0.01339547\n",
      "Iteration 2472, loss = 0.01338758\n",
      "Iteration 2473, loss = 0.01338186\n",
      "Iteration 2474, loss = 0.01337401\n",
      "Iteration 2475, loss = 0.01336627\n",
      "Iteration 2476, loss = 0.01335968\n",
      "Iteration 2477, loss = 0.01335175\n",
      "Iteration 2478, loss = 0.01334520\n",
      "Iteration 2479, loss = 0.01333872\n",
      "Iteration 2480, loss = 0.01333134\n",
      "Iteration 2481, loss = 0.01332529\n",
      "Iteration 2482, loss = 0.01331874\n",
      "Iteration 2483, loss = 0.01331279\n",
      "Iteration 2484, loss = 0.01330682\n",
      "Iteration 2485, loss = 0.01330096\n",
      "Iteration 2486, loss = 0.01329534\n",
      "Iteration 2487, loss = 0.01329109\n",
      "Iteration 2488, loss = 0.01328397\n",
      "Iteration 2489, loss = 0.01327818\n",
      "Iteration 2490, loss = 0.01327269\n",
      "Iteration 2491, loss = 0.01326567\n",
      "Iteration 2492, loss = 0.01325964\n",
      "Iteration 2493, loss = 0.01325406\n",
      "Iteration 2494, loss = 0.01324789\n",
      "Iteration 2495, loss = 0.01324090\n",
      "Iteration 2496, loss = 0.01323450\n",
      "Iteration 2497, loss = 0.01322778\n",
      "Iteration 2498, loss = 0.01322268\n",
      "Iteration 2499, loss = 0.01321594\n",
      "Iteration 2500, loss = 0.01321041\n",
      "Iteration 2501, loss = 0.01320275\n",
      "Iteration 2502, loss = 0.01319681\n",
      "Iteration 2503, loss = 0.01319006\n",
      "Iteration 2504, loss = 0.01318353\n",
      "Iteration 2505, loss = 0.01317712\n",
      "Iteration 2506, loss = 0.01317145\n",
      "Iteration 2507, loss = 0.01316462\n",
      "Iteration 2508, loss = 0.01315823\n",
      "Iteration 2509, loss = 0.01315168\n",
      "Iteration 2510, loss = 0.01314590\n",
      "Iteration 2511, loss = 0.01313944\n",
      "Iteration 2512, loss = 0.01313339\n",
      "Iteration 2513, loss = 0.01312741\n",
      "Iteration 2514, loss = 0.01312138\n",
      "Iteration 2515, loss = 0.01311528\n",
      "Iteration 2516, loss = 0.01310970\n",
      "Iteration 2517, loss = 0.01310429\n",
      "Iteration 2518, loss = 0.01310104\n",
      "Iteration 2519, loss = 0.01309404\n",
      "Iteration 2520, loss = 0.01308856\n",
      "Iteration 2521, loss = 0.01308357\n",
      "Iteration 2522, loss = 0.01307664\n",
      "Iteration 2523, loss = 0.01306975\n",
      "Iteration 2524, loss = 0.01306300\n",
      "Iteration 2525, loss = 0.01305692\n",
      "Iteration 2526, loss = 0.01305008\n",
      "Iteration 2527, loss = 0.01304383\n",
      "Iteration 2528, loss = 0.01303766\n",
      "Iteration 2529, loss = 0.01303221\n",
      "Iteration 2530, loss = 0.01302755\n",
      "Iteration 2531, loss = 0.01302157\n",
      "Iteration 2532, loss = 0.01301401\n",
      "Iteration 2533, loss = 0.01300748\n",
      "Iteration 2534, loss = 0.01300054\n",
      "Iteration 2535, loss = 0.01299395\n",
      "Iteration 2536, loss = 0.01298542\n",
      "Iteration 2537, loss = 0.01298103\n",
      "Iteration 2538, loss = 0.01297424\n",
      "Iteration 2539, loss = 0.01296472\n",
      "Iteration 2540, loss = 0.01295845\n",
      "Iteration 2541, loss = 0.01295008\n",
      "Iteration 2542, loss = 0.01294414\n",
      "Iteration 2543, loss = 0.01293625\n",
      "Iteration 2544, loss = 0.01293030\n",
      "Iteration 2545, loss = 0.01292322\n",
      "Iteration 2546, loss = 0.01291593\n",
      "Iteration 2547, loss = 0.01290730\n",
      "Iteration 2548, loss = 0.01290169\n",
      "Iteration 2549, loss = 0.01289208\n",
      "Iteration 2550, loss = 0.01288492\n",
      "Iteration 2551, loss = 0.01287872\n",
      "Iteration 2552, loss = 0.01287056\n",
      "Iteration 2553, loss = 0.01286437\n",
      "Iteration 2554, loss = 0.01285679\n",
      "Iteration 2555, loss = 0.01285102\n",
      "Iteration 2556, loss = 0.01284409\n",
      "Iteration 2557, loss = 0.01283765\n",
      "Iteration 2558, loss = 0.01283250\n",
      "Iteration 2559, loss = 0.01282466\n",
      "Iteration 2560, loss = 0.01281764\n",
      "Iteration 2561, loss = 0.01281145\n",
      "Iteration 2562, loss = 0.01280495\n",
      "Iteration 2563, loss = 0.01279761\n",
      "Iteration 2564, loss = 0.01279186\n",
      "Iteration 2565, loss = 0.01278423\n",
      "Iteration 2566, loss = 0.01277700\n",
      "Iteration 2567, loss = 0.01277072\n",
      "Iteration 2568, loss = 0.01276275\n",
      "Iteration 2569, loss = 0.01275547\n",
      "Iteration 2570, loss = 0.01274883\n",
      "Iteration 2571, loss = 0.01274282\n",
      "Iteration 2572, loss = 0.01273530\n",
      "Iteration 2573, loss = 0.01273046\n",
      "Iteration 2574, loss = 0.01272374\n",
      "Iteration 2575, loss = 0.01271686\n",
      "Iteration 2576, loss = 0.01271069\n",
      "Iteration 2577, loss = 0.01270467\n",
      "Iteration 2578, loss = 0.01269722\n",
      "Iteration 2579, loss = 0.01269124\n",
      "Iteration 2580, loss = 0.01268534\n",
      "Iteration 2581, loss = 0.01267921\n",
      "Iteration 2582, loss = 0.01267352\n",
      "Iteration 2583, loss = 0.01266792\n",
      "Iteration 2584, loss = 0.01266104\n",
      "Iteration 2585, loss = 0.01265494\n",
      "Iteration 2586, loss = 0.01264922\n",
      "Iteration 2587, loss = 0.01264340\n",
      "Iteration 2588, loss = 0.01263758\n",
      "Iteration 2589, loss = 0.01263418\n",
      "Iteration 2590, loss = 0.01262765\n",
      "Iteration 2591, loss = 0.01262152\n",
      "Iteration 2592, loss = 0.01261535\n",
      "Iteration 2593, loss = 0.01260947\n",
      "Iteration 2594, loss = 0.01260321\n",
      "Iteration 2595, loss = 0.01259787\n",
      "Iteration 2596, loss = 0.01259333\n",
      "Iteration 2597, loss = 0.01258437\n",
      "Iteration 2598, loss = 0.01257877\n",
      "Iteration 2599, loss = 0.01257155\n",
      "Iteration 2600, loss = 0.01256753\n",
      "Iteration 2601, loss = 0.01255898\n",
      "Iteration 2602, loss = 0.01255257\n",
      "Iteration 2603, loss = 0.01254664\n",
      "Iteration 2604, loss = 0.01254022\n",
      "Iteration 2605, loss = 0.01253439\n",
      "Iteration 2606, loss = 0.01252836\n",
      "Iteration 2607, loss = 0.01252276\n",
      "Iteration 2608, loss = 0.01251715\n",
      "Iteration 2609, loss = 0.01251093\n",
      "Iteration 2610, loss = 0.01250442\n",
      "Iteration 2611, loss = 0.01249795\n",
      "Iteration 2612, loss = 0.01249158\n",
      "Iteration 2613, loss = 0.01248609\n",
      "Iteration 2614, loss = 0.01247805\n",
      "Iteration 2615, loss = 0.01247209\n",
      "Iteration 2616, loss = 0.01246494\n",
      "Iteration 2617, loss = 0.01245883\n",
      "Iteration 2618, loss = 0.01245346\n",
      "Iteration 2619, loss = 0.01244736\n",
      "Iteration 2620, loss = 0.01244154\n",
      "Iteration 2621, loss = 0.01243649\n",
      "Iteration 2622, loss = 0.01243050\n",
      "Iteration 2623, loss = 0.01242681\n",
      "Iteration 2624, loss = 0.01241952\n",
      "Iteration 2625, loss = 0.01241358\n",
      "Iteration 2626, loss = 0.01240795\n",
      "Iteration 2627, loss = 0.01240239\n",
      "Iteration 2628, loss = 0.01239707\n",
      "Iteration 2629, loss = 0.01239287\n",
      "Iteration 2630, loss = 0.01238732\n",
      "Iteration 2631, loss = 0.01238458\n",
      "Iteration 2632, loss = 0.01237782\n",
      "Iteration 2633, loss = 0.01237230\n",
      "Iteration 2634, loss = 0.01236663\n",
      "Iteration 2635, loss = 0.01236130\n",
      "Iteration 2636, loss = 0.01235440\n",
      "Iteration 2637, loss = 0.01234817\n",
      "Iteration 2638, loss = 0.01234259\n",
      "Iteration 2639, loss = 0.01233563\n",
      "Iteration 2640, loss = 0.01232990\n",
      "Iteration 2641, loss = 0.01232437\n",
      "Iteration 2642, loss = 0.01231873\n",
      "Iteration 2643, loss = 0.01231328\n",
      "Iteration 2644, loss = 0.01230812\n",
      "Iteration 2645, loss = 0.01230288\n",
      "Iteration 2646, loss = 0.01229714\n",
      "Iteration 2647, loss = 0.01229167\n",
      "Iteration 2648, loss = 0.01228660\n",
      "Iteration 2649, loss = 0.01228238\n",
      "Iteration 2650, loss = 0.01227633\n",
      "Iteration 2651, loss = 0.01227061\n",
      "Iteration 2652, loss = 0.01226531\n",
      "Iteration 2653, loss = 0.01225958\n",
      "Iteration 2654, loss = 0.01225514\n",
      "Iteration 2655, loss = 0.01225121\n",
      "Iteration 2656, loss = 0.01224515\n",
      "Iteration 2657, loss = 0.01223989\n",
      "Iteration 2658, loss = 0.01223403\n",
      "Iteration 2659, loss = 0.01222843\n",
      "Iteration 2660, loss = 0.01222171\n",
      "Iteration 2661, loss = 0.01221533\n",
      "Iteration 2662, loss = 0.01220898\n",
      "Iteration 2663, loss = 0.01220239\n",
      "Iteration 2664, loss = 0.01219645\n",
      "Iteration 2665, loss = 0.01218990\n",
      "Iteration 2666, loss = 0.01218313\n",
      "Iteration 2667, loss = 0.01217723\n",
      "Iteration 2668, loss = 0.01217012\n",
      "Iteration 2669, loss = 0.01216471\n",
      "Iteration 2670, loss = 0.01215879\n",
      "Iteration 2671, loss = 0.01215314\n",
      "Iteration 2672, loss = 0.01214650\n",
      "Iteration 2673, loss = 0.01213976\n",
      "Iteration 2674, loss = 0.01213460\n",
      "Iteration 2675, loss = 0.01212754\n",
      "Iteration 2676, loss = 0.01212180\n",
      "Iteration 2677, loss = 0.01211551\n",
      "Iteration 2678, loss = 0.01210952\n",
      "Iteration 2679, loss = 0.01210338\n",
      "Iteration 2680, loss = 0.01209745\n",
      "Iteration 2681, loss = 0.01209248\n",
      "Iteration 2682, loss = 0.01208478\n",
      "Iteration 2683, loss = 0.01207763\n",
      "Iteration 2684, loss = 0.01207035\n",
      "Iteration 2685, loss = 0.01206241\n",
      "Iteration 2686, loss = 0.01205515\n",
      "Iteration 2687, loss = 0.01204891\n",
      "Iteration 2688, loss = 0.01204235\n",
      "Iteration 2689, loss = 0.01203532\n",
      "Iteration 2690, loss = 0.01202975\n",
      "Iteration 2691, loss = 0.01202243\n",
      "Iteration 2692, loss = 0.01201620\n",
      "Iteration 2693, loss = 0.01200976\n",
      "Iteration 2694, loss = 0.01200554\n",
      "Iteration 2695, loss = 0.01199796\n",
      "Iteration 2696, loss = 0.01199095\n",
      "Iteration 2697, loss = 0.01198550\n",
      "Iteration 2698, loss = 0.01197781\n",
      "Iteration 2699, loss = 0.01197110\n",
      "Iteration 2700, loss = 0.01196628\n",
      "Iteration 2701, loss = 0.01196375\n",
      "Iteration 2702, loss = 0.01195370\n",
      "Iteration 2703, loss = 0.01194828\n",
      "Iteration 2704, loss = 0.01194325\n",
      "Iteration 2705, loss = 0.01193605\n",
      "Iteration 2706, loss = 0.01193034\n",
      "Iteration 2707, loss = 0.01192459\n",
      "Iteration 2708, loss = 0.01191967\n",
      "Iteration 2709, loss = 0.01191409\n",
      "Iteration 2710, loss = 0.01190714\n",
      "Iteration 2711, loss = 0.01190147\n",
      "Iteration 2712, loss = 0.01189544\n",
      "Iteration 2713, loss = 0.01188964\n",
      "Iteration 2714, loss = 0.01188414\n",
      "Iteration 2715, loss = 0.01187915\n",
      "Iteration 2716, loss = 0.01187277\n",
      "Iteration 2717, loss = 0.01186664\n",
      "Iteration 2718, loss = 0.01186196\n",
      "Iteration 2719, loss = 0.01185547\n",
      "Iteration 2720, loss = 0.01185001\n",
      "Iteration 2721, loss = 0.01184468\n",
      "Iteration 2722, loss = 0.01184026\n",
      "Iteration 2723, loss = 0.01183366\n",
      "Iteration 2724, loss = 0.01182784\n",
      "Iteration 2725, loss = 0.01182239\n",
      "Iteration 2726, loss = 0.01181714\n",
      "Iteration 2727, loss = 0.01181189\n",
      "Iteration 2728, loss = 0.01180650\n",
      "Iteration 2729, loss = 0.01180045\n",
      "Iteration 2730, loss = 0.01179500\n",
      "Iteration 2731, loss = 0.01178954\n",
      "Iteration 2732, loss = 0.01178409\n",
      "Iteration 2733, loss = 0.01177985\n",
      "Iteration 2734, loss = 0.01177248\n",
      "Iteration 2735, loss = 0.01176678\n",
      "Iteration 2736, loss = 0.01176085\n",
      "Iteration 2737, loss = 0.01175511\n",
      "Iteration 2738, loss = 0.01174941\n",
      "Iteration 2739, loss = 0.01174411\n",
      "Iteration 2740, loss = 0.01173881\n",
      "Iteration 2741, loss = 0.01173237\n",
      "Iteration 2742, loss = 0.01172702\n",
      "Iteration 2743, loss = 0.01172278\n",
      "Iteration 2744, loss = 0.01171600\n",
      "Iteration 2745, loss = 0.01170972\n",
      "Iteration 2746, loss = 0.01170428\n",
      "Iteration 2747, loss = 0.01169829\n",
      "Iteration 2748, loss = 0.01169253\n",
      "Iteration 2749, loss = 0.01168713\n",
      "Iteration 2750, loss = 0.01168087\n",
      "Iteration 2751, loss = 0.01167465\n",
      "Iteration 2752, loss = 0.01166879\n",
      "Iteration 2753, loss = 0.01166220\n",
      "Iteration 2754, loss = 0.01165761\n",
      "Iteration 2755, loss = 0.01165032\n",
      "Iteration 2756, loss = 0.01164483\n",
      "Iteration 2757, loss = 0.01163892\n",
      "Iteration 2758, loss = 0.01163269\n",
      "Iteration 2759, loss = 0.01162746\n",
      "Iteration 2760, loss = 0.01162184\n",
      "Iteration 2761, loss = 0.01161570\n",
      "Iteration 2762, loss = 0.01161007\n",
      "Iteration 2763, loss = 0.01160532\n",
      "Iteration 2764, loss = 0.01159934\n",
      "Iteration 2765, loss = 0.01159316\n",
      "Iteration 2766, loss = 0.01158662\n",
      "Iteration 2767, loss = 0.01158228\n",
      "Iteration 2768, loss = 0.01157567\n",
      "Iteration 2769, loss = 0.01157008\n",
      "Iteration 2770, loss = 0.01156472\n",
      "Iteration 2771, loss = 0.01155935\n",
      "Iteration 2772, loss = 0.01155389\n",
      "Iteration 2773, loss = 0.01154851\n",
      "Iteration 2774, loss = 0.01154281\n",
      "Iteration 2775, loss = 0.01153838\n",
      "Iteration 2776, loss = 0.01153264\n",
      "Iteration 2777, loss = 0.01152721\n",
      "Iteration 2778, loss = 0.01152133\n",
      "Iteration 2779, loss = 0.01151750\n",
      "Iteration 2780, loss = 0.01151214\n",
      "Iteration 2781, loss = 0.01150682\n",
      "Iteration 2782, loss = 0.01149946\n",
      "Iteration 2783, loss = 0.01149389\n",
      "Iteration 2784, loss = 0.01148841\n",
      "Iteration 2785, loss = 0.01148289\n",
      "Iteration 2786, loss = 0.01147778\n",
      "Iteration 2787, loss = 0.01147271\n",
      "Iteration 2788, loss = 0.01146649\n",
      "Iteration 2789, loss = 0.01146053\n",
      "Iteration 2790, loss = 0.01145487\n",
      "Iteration 2791, loss = 0.01145001\n",
      "Iteration 2792, loss = 0.01144459\n",
      "Iteration 2793, loss = 0.01143907\n",
      "Iteration 2794, loss = 0.01143367\n",
      "Iteration 2795, loss = 0.01142841\n",
      "Iteration 2796, loss = 0.01142345\n",
      "Iteration 2797, loss = 0.01141753\n",
      "Iteration 2798, loss = 0.01141221\n",
      "Iteration 2799, loss = 0.01140693\n",
      "Iteration 2800, loss = 0.01140162\n",
      "Iteration 2801, loss = 0.01139583\n",
      "Iteration 2802, loss = 0.01139031\n",
      "Iteration 2803, loss = 0.01138514\n",
      "Iteration 2804, loss = 0.01138077\n",
      "Iteration 2805, loss = 0.01137553\n",
      "Iteration 2806, loss = 0.01136940\n",
      "Iteration 2807, loss = 0.01136411\n",
      "Iteration 2808, loss = 0.01135857\n",
      "Iteration 2809, loss = 0.01135322\n",
      "Iteration 2810, loss = 0.01134920\n",
      "Iteration 2811, loss = 0.01134350\n",
      "Iteration 2812, loss = 0.01133931\n",
      "Iteration 2813, loss = 0.01133377\n",
      "Iteration 2814, loss = 0.01132859\n",
      "Iteration 2815, loss = 0.01132331\n",
      "Iteration 2816, loss = 0.01131908\n",
      "Iteration 2817, loss = 0.01131192\n",
      "Iteration 2818, loss = 0.01130665\n",
      "Iteration 2819, loss = 0.01130175\n",
      "Iteration 2820, loss = 0.01129678\n",
      "Iteration 2821, loss = 0.01129143\n",
      "Iteration 2822, loss = 0.01128697\n",
      "Iteration 2823, loss = 0.01128051\n",
      "Iteration 2824, loss = 0.01127425\n",
      "Iteration 2825, loss = 0.01126999\n",
      "Iteration 2826, loss = 0.01126306\n",
      "Iteration 2827, loss = 0.01125911\n",
      "Iteration 2828, loss = 0.01125276\n",
      "Iteration 2829, loss = 0.01124744\n",
      "Iteration 2830, loss = 0.01124240\n",
      "Iteration 2831, loss = 0.01123724\n",
      "Iteration 2832, loss = 0.01123161\n",
      "Iteration 2833, loss = 0.01122617\n",
      "Iteration 2834, loss = 0.01122098\n",
      "Iteration 2835, loss = 0.01121558\n",
      "Iteration 2836, loss = 0.01121085\n",
      "Iteration 2837, loss = 0.01120478\n",
      "Iteration 2838, loss = 0.01120026\n",
      "Iteration 2839, loss = 0.01119431\n",
      "Iteration 2840, loss = 0.01118916\n",
      "Iteration 2841, loss = 0.01118358\n",
      "Iteration 2842, loss = 0.01117809\n",
      "Iteration 2843, loss = 0.01117380\n",
      "Iteration 2844, loss = 0.01116729\n",
      "Iteration 2845, loss = 0.01116114\n",
      "Iteration 2846, loss = 0.01115595\n",
      "Iteration 2847, loss = 0.01114918\n",
      "Iteration 2848, loss = 0.01114414\n",
      "Iteration 2849, loss = 0.01113813\n",
      "Iteration 2850, loss = 0.01113319\n",
      "Iteration 2851, loss = 0.01112680\n",
      "Iteration 2852, loss = 0.01112137\n",
      "Iteration 2853, loss = 0.01111591\n",
      "Iteration 2854, loss = 0.01111048\n",
      "Iteration 2855, loss = 0.01110634\n",
      "Iteration 2856, loss = 0.01110050\n",
      "Iteration 2857, loss = 0.01109510\n",
      "Iteration 2858, loss = 0.01109034\n",
      "Iteration 2859, loss = 0.01108453\n",
      "Iteration 2860, loss = 0.01107990\n",
      "Iteration 2861, loss = 0.01107384\n",
      "Iteration 2862, loss = 0.01106875\n",
      "Iteration 2863, loss = 0.01106310\n",
      "Iteration 2864, loss = 0.01105722\n",
      "Iteration 2865, loss = 0.01105201\n",
      "Iteration 2866, loss = 0.01104629\n",
      "Iteration 2867, loss = 0.01104034\n",
      "Iteration 2868, loss = 0.01103476\n",
      "Iteration 2869, loss = 0.01103005\n",
      "Iteration 2870, loss = 0.01102364\n",
      "Iteration 2871, loss = 0.01101844\n",
      "Iteration 2872, loss = 0.01101258\n",
      "Iteration 2873, loss = 0.01100825\n",
      "Iteration 2874, loss = 0.01100238\n",
      "Iteration 2875, loss = 0.01099709\n",
      "Iteration 2876, loss = 0.01099209\n",
      "Iteration 2877, loss = 0.01098740\n",
      "Iteration 2878, loss = 0.01098165\n",
      "Iteration 2879, loss = 0.01097674\n",
      "Iteration 2880, loss = 0.01097465\n",
      "Iteration 2881, loss = 0.01096680\n",
      "Iteration 2882, loss = 0.01096150\n",
      "Iteration 2883, loss = 0.01095640\n",
      "Iteration 2884, loss = 0.01095076\n",
      "Iteration 2885, loss = 0.01094725\n",
      "Iteration 2886, loss = 0.01094088\n",
      "Iteration 2887, loss = 0.01093546\n",
      "Iteration 2888, loss = 0.01093124\n",
      "Iteration 2889, loss = 0.01092572\n",
      "Iteration 2890, loss = 0.01092035\n",
      "Iteration 2891, loss = 0.01091473\n",
      "Iteration 2892, loss = 0.01091150\n",
      "Iteration 2893, loss = 0.01090464\n",
      "Iteration 2894, loss = 0.01089915\n",
      "Iteration 2895, loss = 0.01089397\n",
      "Iteration 2896, loss = 0.01088890\n",
      "Iteration 2897, loss = 0.01088363\n",
      "Iteration 2898, loss = 0.01087800\n",
      "Iteration 2899, loss = 0.01087418\n",
      "Iteration 2900, loss = 0.01086824\n",
      "Iteration 2901, loss = 0.01086277\n",
      "Iteration 2902, loss = 0.01085727\n",
      "Iteration 2903, loss = 0.01085219\n",
      "Iteration 2904, loss = 0.01084711\n",
      "Iteration 2905, loss = 0.01084170\n",
      "Iteration 2906, loss = 0.01083703\n",
      "Iteration 2907, loss = 0.01083313\n",
      "Iteration 2908, loss = 0.01082684\n",
      "Iteration 2909, loss = 0.01082175\n",
      "Iteration 2910, loss = 0.01081742\n",
      "Iteration 2911, loss = 0.01081196\n",
      "Iteration 2912, loss = 0.01080755\n",
      "Iteration 2913, loss = 0.01080185\n",
      "Iteration 2914, loss = 0.01079622\n",
      "Iteration 2915, loss = 0.01079093\n",
      "Iteration 2916, loss = 0.01078648\n",
      "Iteration 2917, loss = 0.01078241\n",
      "Iteration 2918, loss = 0.01077715\n",
      "Iteration 2919, loss = 0.01077172\n",
      "Iteration 2920, loss = 0.01076661\n",
      "Iteration 2921, loss = 0.01076290\n",
      "Iteration 2922, loss = 0.01075645\n",
      "Iteration 2923, loss = 0.01075138\n",
      "Iteration 2924, loss = 0.01074662\n",
      "Iteration 2925, loss = 0.01074097\n",
      "Iteration 2926, loss = 0.01073623\n",
      "Iteration 2927, loss = 0.01073083\n",
      "Iteration 2928, loss = 0.01072551\n",
      "Iteration 2929, loss = 0.01072085\n",
      "Iteration 2930, loss = 0.01071632\n",
      "Iteration 2931, loss = 0.01071144\n",
      "Iteration 2932, loss = 0.01070678\n",
      "Iteration 2933, loss = 0.01070139\n",
      "Iteration 2934, loss = 0.01069816\n",
      "Iteration 2935, loss = 0.01069170\n",
      "Iteration 2936, loss = 0.01068720\n",
      "Iteration 2937, loss = 0.01068204\n",
      "Iteration 2938, loss = 0.01067838\n",
      "Iteration 2939, loss = 0.01067236\n",
      "Iteration 2940, loss = 0.01066876\n",
      "Iteration 2941, loss = 0.01066256\n",
      "Iteration 2942, loss = 0.01065853\n",
      "Iteration 2943, loss = 0.01065296\n",
      "Iteration 2944, loss = 0.01064852\n",
      "Iteration 2945, loss = 0.01064239\n",
      "Iteration 2946, loss = 0.01063682\n",
      "Iteration 2947, loss = 0.01063233\n",
      "Iteration 2948, loss = 0.01062834\n",
      "Iteration 2949, loss = 0.01062089\n",
      "Iteration 2950, loss = 0.01061536\n",
      "Iteration 2951, loss = 0.01061008\n",
      "Iteration 2952, loss = 0.01060573\n",
      "Iteration 2953, loss = 0.01060003\n",
      "Iteration 2954, loss = 0.01059575\n",
      "Iteration 2955, loss = 0.01059054\n",
      "Iteration 2956, loss = 0.01058628\n",
      "Iteration 2957, loss = 0.01058090\n",
      "Iteration 2958, loss = 0.01057642\n",
      "Iteration 2959, loss = 0.01057134\n",
      "Iteration 2960, loss = 0.01056626\n",
      "Iteration 2961, loss = 0.01056120\n",
      "Iteration 2962, loss = 0.01055667\n",
      "Iteration 2963, loss = 0.01055181\n",
      "Iteration 2964, loss = 0.01054738\n",
      "Iteration 2965, loss = 0.01054341\n",
      "Iteration 2966, loss = 0.01053737\n",
      "Iteration 2967, loss = 0.01053230\n",
      "Iteration 2968, loss = 0.01052643\n",
      "Iteration 2969, loss = 0.01052313\n",
      "Iteration 2970, loss = 0.01051686\n",
      "Iteration 2971, loss = 0.01051257\n",
      "Iteration 2972, loss = 0.01050641\n",
      "Iteration 2973, loss = 0.01050300\n",
      "Iteration 2974, loss = 0.01049645\n",
      "Iteration 2975, loss = 0.01049158\n",
      "Iteration 2976, loss = 0.01048650\n",
      "Iteration 2977, loss = 0.01048154\n",
      "Iteration 2978, loss = 0.01047720\n",
      "Iteration 2979, loss = 0.01047254\n",
      "Iteration 2980, loss = 0.01046807\n",
      "Iteration 2981, loss = 0.01046302\n",
      "Iteration 2982, loss = 0.01045834\n",
      "Iteration 2983, loss = 0.01045352\n",
      "Iteration 2984, loss = 0.01044996\n",
      "Iteration 2985, loss = 0.01044518\n",
      "Iteration 2986, loss = 0.01044252\n",
      "Iteration 2987, loss = 0.01043675\n",
      "Iteration 2988, loss = 0.01043330\n",
      "Iteration 2989, loss = 0.01042924\n",
      "Iteration 2990, loss = 0.01042473\n",
      "Iteration 2991, loss = 0.01042106\n",
      "Iteration 2992, loss = 0.01041678\n",
      "Iteration 2993, loss = 0.01041352\n",
      "Iteration 2994, loss = 0.01040829\n",
      "Iteration 2995, loss = 0.01040438\n",
      "Iteration 2996, loss = 0.01040004\n",
      "Iteration 2997, loss = 0.01039538\n",
      "Iteration 2998, loss = 0.01039140\n",
      "Iteration 2999, loss = 0.01038716\n",
      "Iteration 3000, loss = 0.01038282\n",
      "Iteration 3001, loss = 0.01037814\n",
      "Iteration 3002, loss = 0.01037366\n",
      "Iteration 3003, loss = 0.01036890\n",
      "Iteration 3004, loss = 0.01036414\n",
      "Iteration 3005, loss = 0.01036052\n",
      "Iteration 3006, loss = 0.01035507\n",
      "Iteration 3007, loss = 0.01035138\n",
      "Iteration 3008, loss = 0.01034629\n",
      "Iteration 3009, loss = 0.01034167\n",
      "Iteration 3010, loss = 0.01033764\n",
      "Iteration 3011, loss = 0.01033251\n",
      "Iteration 3012, loss = 0.01032806\n",
      "Iteration 3013, loss = 0.01032330\n",
      "Iteration 3014, loss = 0.01031795\n",
      "Iteration 3015, loss = 0.01031371\n",
      "Iteration 3016, loss = 0.01030922\n",
      "Iteration 3017, loss = 0.01030374\n",
      "Iteration 3018, loss = 0.01029866\n",
      "Iteration 3019, loss = 0.01029310\n",
      "Iteration 3020, loss = 0.01028817\n",
      "Iteration 3021, loss = 0.01028511\n",
      "Iteration 3022, loss = 0.01027862\n",
      "Iteration 3023, loss = 0.01027350\n",
      "Iteration 3024, loss = 0.01026860\n",
      "Iteration 3025, loss = 0.01026398\n",
      "Iteration 3026, loss = 0.01026025\n",
      "Iteration 3027, loss = 0.01025593\n",
      "Iteration 3028, loss = 0.01025181\n",
      "Iteration 3029, loss = 0.01024738\n",
      "Iteration 3030, loss = 0.01024239\n",
      "Iteration 3031, loss = 0.01023799\n",
      "Iteration 3032, loss = 0.01023319\n",
      "Iteration 3033, loss = 0.01022839\n",
      "Iteration 3034, loss = 0.01022429\n",
      "Iteration 3035, loss = 0.01021957\n",
      "Iteration 3036, loss = 0.01021495\n",
      "Iteration 3037, loss = 0.01021076\n",
      "Iteration 3038, loss = 0.01020597\n",
      "Iteration 3039, loss = 0.01020096\n",
      "Iteration 3040, loss = 0.01019734\n",
      "Iteration 3041, loss = 0.01019265\n",
      "Iteration 3042, loss = 0.01018809\n",
      "Iteration 3043, loss = 0.01018366\n",
      "Iteration 3044, loss = 0.01017986\n",
      "Iteration 3045, loss = 0.01017589\n",
      "Iteration 3046, loss = 0.01017154\n",
      "Iteration 3047, loss = 0.01016593\n",
      "Iteration 3048, loss = 0.01016135\n",
      "Iteration 3049, loss = 0.01015733\n",
      "Iteration 3050, loss = 0.01015358\n",
      "Iteration 3051, loss = 0.01014730\n",
      "Iteration 3052, loss = 0.01014239\n",
      "Iteration 3053, loss = 0.01013716\n",
      "Iteration 3054, loss = 0.01013438\n",
      "Iteration 3055, loss = 0.01012909\n",
      "Iteration 3056, loss = 0.01012370\n",
      "Iteration 3057, loss = 0.01012017\n",
      "Iteration 3058, loss = 0.01011491\n",
      "Iteration 3059, loss = 0.01011071\n",
      "Iteration 3060, loss = 0.01010656\n",
      "Iteration 3061, loss = 0.01010276\n",
      "Iteration 3062, loss = 0.01009740\n",
      "Iteration 3063, loss = 0.01009326\n",
      "Iteration 3064, loss = 0.01008914\n",
      "Iteration 3065, loss = 0.01008582\n",
      "Iteration 3066, loss = 0.01008028\n",
      "Iteration 3067, loss = 0.01007529\n",
      "Iteration 3068, loss = 0.01007037\n",
      "Iteration 3069, loss = 0.01006790\n",
      "Iteration 3070, loss = 0.01006314\n",
      "Iteration 3071, loss = 0.01005750\n",
      "Iteration 3072, loss = 0.01005318\n",
      "Iteration 3073, loss = 0.01004847\n",
      "Iteration 3074, loss = 0.01004434\n",
      "Iteration 3075, loss = 0.01003994\n",
      "Iteration 3076, loss = 0.01003529\n",
      "Iteration 3077, loss = 0.01003041\n",
      "Iteration 3078, loss = 0.01002605\n",
      "Iteration 3079, loss = 0.01002182\n",
      "Iteration 3080, loss = 0.01001739\n",
      "Iteration 3081, loss = 0.01001299\n",
      "Iteration 3082, loss = 0.01000896\n",
      "Iteration 3083, loss = 0.01000469\n",
      "Iteration 3084, loss = 0.01000060\n",
      "Iteration 3085, loss = 0.00999664\n",
      "Iteration 3086, loss = 0.00999211\n",
      "Iteration 3087, loss = 0.00998813\n",
      "Iteration 3088, loss = 0.00998427\n",
      "Iteration 3089, loss = 0.00998045\n",
      "Iteration 3090, loss = 0.00997627\n",
      "Iteration 3091, loss = 0.00997337\n",
      "Iteration 3092, loss = 0.00996859\n",
      "Iteration 3093, loss = 0.00996478\n",
      "Iteration 3094, loss = 0.00996072\n",
      "Iteration 3095, loss = 0.00995850\n",
      "Iteration 3096, loss = 0.00995395\n",
      "Iteration 3097, loss = 0.00994861\n",
      "Iteration 3098, loss = 0.00994430\n",
      "Iteration 3099, loss = 0.00993949\n",
      "Iteration 3100, loss = 0.00993549\n",
      "Iteration 3101, loss = 0.00993170\n",
      "Iteration 3102, loss = 0.00992809\n",
      "Iteration 3103, loss = 0.00992408\n",
      "Iteration 3104, loss = 0.00992005\n",
      "Iteration 3105, loss = 0.00991547\n",
      "Iteration 3106, loss = 0.00991166\n",
      "Iteration 3107, loss = 0.00990724\n",
      "Iteration 3108, loss = 0.00990346\n",
      "Iteration 3109, loss = 0.00989900\n",
      "Iteration 3110, loss = 0.00989463\n",
      "Iteration 3111, loss = 0.00989076\n",
      "Iteration 3112, loss = 0.00988646\n",
      "Iteration 3113, loss = 0.00988224\n",
      "Iteration 3114, loss = 0.00987831\n",
      "Iteration 3115, loss = 0.00987440\n",
      "Iteration 3116, loss = 0.00987060\n",
      "Iteration 3117, loss = 0.00986659\n",
      "Iteration 3118, loss = 0.00986232\n",
      "Iteration 3119, loss = 0.00985815\n",
      "Iteration 3120, loss = 0.00985388\n",
      "Iteration 3121, loss = 0.00985039\n",
      "Iteration 3122, loss = 0.00984597\n",
      "Iteration 3123, loss = 0.00984181\n",
      "Iteration 3124, loss = 0.00983831\n",
      "Iteration 3125, loss = 0.00983319\n",
      "Iteration 3126, loss = 0.00982864\n",
      "Iteration 3127, loss = 0.00982428\n",
      "Iteration 3128, loss = 0.00982129\n",
      "Iteration 3129, loss = 0.00981587\n",
      "Iteration 3130, loss = 0.00981147\n",
      "Iteration 3131, loss = 0.00980687\n",
      "Iteration 3132, loss = 0.00980194\n",
      "Iteration 3133, loss = 0.00979914\n",
      "Iteration 3134, loss = 0.00979353\n",
      "Iteration 3135, loss = 0.00978994\n",
      "Iteration 3136, loss = 0.00978501\n",
      "Iteration 3137, loss = 0.00978094\n",
      "Iteration 3138, loss = 0.00977704\n",
      "Iteration 3139, loss = 0.00977285\n",
      "Iteration 3140, loss = 0.00976848\n",
      "Iteration 3141, loss = 0.00976594\n",
      "Iteration 3142, loss = 0.00976127\n",
      "Iteration 3143, loss = 0.00975651\n",
      "Iteration 3144, loss = 0.00975285\n",
      "Iteration 3145, loss = 0.00974893\n",
      "Iteration 3146, loss = 0.00974635\n",
      "Iteration 3147, loss = 0.00974356\n",
      "Iteration 3148, loss = 0.00973839\n",
      "Iteration 3149, loss = 0.00973383\n",
      "Iteration 3150, loss = 0.00973051\n",
      "Iteration 3151, loss = 0.00972607\n",
      "Iteration 3152, loss = 0.00972220\n",
      "Iteration 3153, loss = 0.00971845\n",
      "Iteration 3154, loss = 0.00971492\n",
      "Iteration 3155, loss = 0.00971080\n",
      "Iteration 3156, loss = 0.00970780\n",
      "Iteration 3157, loss = 0.00970317\n",
      "Iteration 3158, loss = 0.00969796\n",
      "Iteration 3159, loss = 0.00969406\n",
      "Iteration 3160, loss = 0.00968944\n",
      "Iteration 3161, loss = 0.00968513\n",
      "Iteration 3162, loss = 0.00968075\n",
      "Iteration 3163, loss = 0.00967701\n",
      "Iteration 3164, loss = 0.00967276\n",
      "Iteration 3165, loss = 0.00966957\n",
      "Iteration 3166, loss = 0.00966517\n",
      "Iteration 3167, loss = 0.00966179\n",
      "Iteration 3168, loss = 0.00965763\n",
      "Iteration 3169, loss = 0.00965132\n",
      "Iteration 3170, loss = 0.00964755\n",
      "Iteration 3171, loss = 0.00964335\n",
      "Iteration 3172, loss = 0.00963907\n",
      "Iteration 3173, loss = 0.00963477\n",
      "Iteration 3174, loss = 0.00963065\n",
      "Iteration 3175, loss = 0.00962666\n",
      "Iteration 3176, loss = 0.00962297\n",
      "Iteration 3177, loss = 0.00961904\n",
      "Iteration 3178, loss = 0.00961563\n",
      "Iteration 3179, loss = 0.00961238\n",
      "Iteration 3180, loss = 0.00960839\n",
      "Iteration 3181, loss = 0.00960473\n",
      "Iteration 3182, loss = 0.00960090\n",
      "Iteration 3183, loss = 0.00959709\n",
      "Iteration 3184, loss = 0.00959380\n",
      "Iteration 3185, loss = 0.00958953\n",
      "Iteration 3186, loss = 0.00958550\n",
      "Iteration 3187, loss = 0.00958168\n",
      "Iteration 3188, loss = 0.00957794\n",
      "Iteration 3189, loss = 0.00957538\n",
      "Iteration 3190, loss = 0.00957062\n",
      "Iteration 3191, loss = 0.00956654\n",
      "Iteration 3192, loss = 0.00956211\n",
      "Iteration 3193, loss = 0.00955842\n",
      "Iteration 3194, loss = 0.00955434\n",
      "Iteration 3195, loss = 0.00955071\n",
      "Iteration 3196, loss = 0.00954622\n",
      "Iteration 3197, loss = 0.00954222\n",
      "Iteration 3198, loss = 0.00953792\n",
      "Iteration 3199, loss = 0.00953416\n",
      "Iteration 3200, loss = 0.00952962\n",
      "Iteration 3201, loss = 0.00952594\n",
      "Iteration 3202, loss = 0.00952177\n",
      "Iteration 3203, loss = 0.00951854\n",
      "Iteration 3204, loss = 0.00951528\n",
      "Iteration 3205, loss = 0.00950981\n",
      "Iteration 3206, loss = 0.00950521\n",
      "Iteration 3207, loss = 0.00950178\n",
      "Iteration 3208, loss = 0.00949730\n",
      "Iteration 3209, loss = 0.00949313\n",
      "Iteration 3210, loss = 0.00948949\n",
      "Iteration 3211, loss = 0.00948552\n",
      "Iteration 3212, loss = 0.00948133\n",
      "Iteration 3213, loss = 0.00947804\n",
      "Iteration 3214, loss = 0.00947342\n",
      "Iteration 3215, loss = 0.00946990\n",
      "Iteration 3216, loss = 0.00946642\n",
      "Iteration 3217, loss = 0.00946134\n",
      "Iteration 3218, loss = 0.00945746\n",
      "Iteration 3219, loss = 0.00945363\n",
      "Iteration 3220, loss = 0.00944893\n",
      "Iteration 3221, loss = 0.00944543\n",
      "Iteration 3222, loss = 0.00944168\n",
      "Iteration 3223, loss = 0.00943752\n",
      "Iteration 3224, loss = 0.00943406\n",
      "Iteration 3225, loss = 0.00943005\n",
      "Iteration 3226, loss = 0.00942652\n",
      "Iteration 3227, loss = 0.00942289\n",
      "Iteration 3228, loss = 0.00941914\n",
      "Iteration 3229, loss = 0.00941634\n",
      "Iteration 3230, loss = 0.00941223\n",
      "Iteration 3231, loss = 0.00940877\n",
      "Iteration 3232, loss = 0.00940462\n",
      "Iteration 3233, loss = 0.00940090\n",
      "Iteration 3234, loss = 0.00939656\n",
      "Iteration 3235, loss = 0.00939319\n",
      "Iteration 3236, loss = 0.00938885\n",
      "Iteration 3237, loss = 0.00938562\n",
      "Iteration 3238, loss = 0.00938169\n",
      "Iteration 3239, loss = 0.00937787\n",
      "Iteration 3240, loss = 0.00937470\n",
      "Iteration 3241, loss = 0.00937110\n",
      "Iteration 3242, loss = 0.00936755\n",
      "Iteration 3243, loss = 0.00936509\n",
      "Iteration 3244, loss = 0.00936031\n",
      "Iteration 3245, loss = 0.00935632\n",
      "Iteration 3246, loss = 0.00935159\n",
      "Iteration 3247, loss = 0.00934723\n",
      "Iteration 3248, loss = 0.00934348\n",
      "Iteration 3249, loss = 0.00934023\n",
      "Iteration 3250, loss = 0.00933481\n",
      "Iteration 3251, loss = 0.00933162\n",
      "Iteration 3252, loss = 0.00932611\n",
      "Iteration 3253, loss = 0.00932169\n",
      "Iteration 3254, loss = 0.00931738\n",
      "Iteration 3255, loss = 0.00931551\n",
      "Iteration 3256, loss = 0.00930983\n",
      "Iteration 3257, loss = 0.00930558\n",
      "Iteration 3258, loss = 0.00930129\n",
      "Iteration 3259, loss = 0.00929787\n",
      "Iteration 3260, loss = 0.00929432\n",
      "Iteration 3261, loss = 0.00929043\n",
      "Iteration 3262, loss = 0.00928636\n",
      "Iteration 3263, loss = 0.00928229\n",
      "Iteration 3264, loss = 0.00927845\n",
      "Iteration 3265, loss = 0.00927465\n",
      "Iteration 3266, loss = 0.00927054\n",
      "Iteration 3267, loss = 0.00926668\n",
      "Iteration 3268, loss = 0.00926278\n",
      "Iteration 3269, loss = 0.00925878\n",
      "Iteration 3270, loss = 0.00925552\n",
      "Iteration 3271, loss = 0.00925211\n",
      "Iteration 3272, loss = 0.00924861\n",
      "Iteration 3273, loss = 0.00924463\n",
      "Iteration 3274, loss = 0.00924009\n",
      "Iteration 3275, loss = 0.00923607\n",
      "Iteration 3276, loss = 0.00923235\n",
      "Iteration 3277, loss = 0.00922851\n",
      "Iteration 3278, loss = 0.00922544\n",
      "Iteration 3279, loss = 0.00922132\n",
      "Iteration 3280, loss = 0.00921762\n",
      "Iteration 3281, loss = 0.00921396\n",
      "Iteration 3282, loss = 0.00920955\n",
      "Iteration 3283, loss = 0.00920560\n",
      "Iteration 3284, loss = 0.00920200\n",
      "Iteration 3285, loss = 0.00919770\n",
      "Iteration 3286, loss = 0.00919388\n",
      "Iteration 3287, loss = 0.00919028\n",
      "Iteration 3288, loss = 0.00918613\n",
      "Iteration 3289, loss = 0.00918238\n",
      "Iteration 3290, loss = 0.00917869\n",
      "Iteration 3291, loss = 0.00917554\n",
      "Iteration 3292, loss = 0.00917284\n",
      "Iteration 3293, loss = 0.00916837\n",
      "Iteration 3294, loss = 0.00916489\n",
      "Iteration 3295, loss = 0.00916188\n",
      "Iteration 3296, loss = 0.00915760\n",
      "Iteration 3297, loss = 0.00915401\n",
      "Iteration 3298, loss = 0.00915074\n",
      "Iteration 3299, loss = 0.00914734\n",
      "Iteration 3300, loss = 0.00914254\n",
      "Iteration 3301, loss = 0.00913886\n",
      "Iteration 3302, loss = 0.00913546\n",
      "Iteration 3303, loss = 0.00913085\n",
      "Iteration 3304, loss = 0.00912746\n",
      "Iteration 3305, loss = 0.00912554\n",
      "Iteration 3306, loss = 0.00911952\n",
      "Iteration 3307, loss = 0.00911545\n",
      "Iteration 3308, loss = 0.00911143\n",
      "Iteration 3309, loss = 0.00910837\n",
      "Iteration 3310, loss = 0.00910364\n",
      "Iteration 3311, loss = 0.00910018\n",
      "Iteration 3312, loss = 0.00909711\n",
      "Iteration 3313, loss = 0.00909281\n",
      "Iteration 3314, loss = 0.00908880\n",
      "Iteration 3315, loss = 0.00908502\n",
      "Iteration 3316, loss = 0.00908134\n",
      "Iteration 3317, loss = 0.00907740\n",
      "Iteration 3318, loss = 0.00907351\n",
      "Iteration 3319, loss = 0.00906987\n",
      "Iteration 3320, loss = 0.00906575\n",
      "Iteration 3321, loss = 0.00906239\n",
      "Iteration 3322, loss = 0.00905961\n",
      "Iteration 3323, loss = 0.00905535\n",
      "Iteration 3324, loss = 0.00905117\n",
      "Iteration 3325, loss = 0.00904764\n",
      "Iteration 3326, loss = 0.00904432\n",
      "Iteration 3327, loss = 0.00903991\n",
      "Iteration 3328, loss = 0.00903644\n",
      "Iteration 3329, loss = 0.00903233\n",
      "Iteration 3330, loss = 0.00902792\n",
      "Iteration 3331, loss = 0.00902480\n",
      "Iteration 3332, loss = 0.00902037\n",
      "Iteration 3333, loss = 0.00901650\n",
      "Iteration 3334, loss = 0.00901232\n",
      "Iteration 3335, loss = 0.00900890\n",
      "Iteration 3336, loss = 0.00900452\n",
      "Iteration 3337, loss = 0.00900139\n",
      "Iteration 3338, loss = 0.00899658\n",
      "Iteration 3339, loss = 0.00899340\n",
      "Iteration 3340, loss = 0.00898866\n",
      "Iteration 3341, loss = 0.00898447\n",
      "Iteration 3342, loss = 0.00898199\n",
      "Iteration 3343, loss = 0.00897720\n",
      "Iteration 3344, loss = 0.00897336\n",
      "Iteration 3345, loss = 0.00896936\n",
      "Iteration 3346, loss = 0.00896558\n",
      "Iteration 3347, loss = 0.00896164\n",
      "Iteration 3348, loss = 0.00895807\n",
      "Iteration 3349, loss = 0.00895395\n",
      "Iteration 3350, loss = 0.00895106\n",
      "Iteration 3351, loss = 0.00894689\n",
      "Iteration 3352, loss = 0.00894288\n",
      "Iteration 3353, loss = 0.00893947\n",
      "Iteration 3354, loss = 0.00893612\n",
      "Iteration 3355, loss = 0.00893185\n",
      "Iteration 3356, loss = 0.00892738\n",
      "Iteration 3357, loss = 0.00892476\n",
      "Iteration 3358, loss = 0.00892051\n",
      "Iteration 3359, loss = 0.00891653\n",
      "Iteration 3360, loss = 0.00891354\n",
      "Iteration 3361, loss = 0.00890962\n",
      "Iteration 3362, loss = 0.00890663\n",
      "Iteration 3363, loss = 0.00890197\n",
      "Iteration 3364, loss = 0.00889840\n",
      "Iteration 3365, loss = 0.00889405\n",
      "Iteration 3366, loss = 0.00889243\n",
      "Iteration 3367, loss = 0.00888898\n",
      "Iteration 3368, loss = 0.00888435\n",
      "Iteration 3369, loss = 0.00888139\n",
      "Iteration 3370, loss = 0.00887703\n",
      "Iteration 3371, loss = 0.00887351\n",
      "Iteration 3372, loss = 0.00887001\n",
      "Iteration 3373, loss = 0.00886623\n",
      "Iteration 3374, loss = 0.00886256\n",
      "Iteration 3375, loss = 0.00885900\n",
      "Iteration 3376, loss = 0.00885517\n",
      "Iteration 3377, loss = 0.00885057\n",
      "Iteration 3378, loss = 0.00884754\n",
      "Iteration 3379, loss = 0.00884330\n",
      "Iteration 3380, loss = 0.00883927\n",
      "Iteration 3381, loss = 0.00883565\n",
      "Iteration 3382, loss = 0.00883355\n",
      "Iteration 3383, loss = 0.00882840\n",
      "Iteration 3384, loss = 0.00882438\n",
      "Iteration 3385, loss = 0.00882002\n",
      "Iteration 3386, loss = 0.00881671\n",
      "Iteration 3387, loss = 0.00881293\n",
      "Iteration 3388, loss = 0.00880904\n",
      "Iteration 3389, loss = 0.00880532\n",
      "Iteration 3390, loss = 0.00880069\n",
      "Iteration 3391, loss = 0.00879694\n",
      "Iteration 3392, loss = 0.00879337\n",
      "Iteration 3393, loss = 0.00878985\n",
      "Iteration 3394, loss = 0.00878554\n",
      "Iteration 3395, loss = 0.00878354\n",
      "Iteration 3396, loss = 0.00878020\n",
      "Iteration 3397, loss = 0.00877636\n",
      "Iteration 3398, loss = 0.00877297\n",
      "Iteration 3399, loss = 0.00877024\n",
      "Iteration 3400, loss = 0.00876659\n",
      "Iteration 3401, loss = 0.00876302\n",
      "Iteration 3402, loss = 0.00875918\n",
      "Iteration 3403, loss = 0.00875580\n",
      "Iteration 3404, loss = 0.00875317\n",
      "Iteration 3405, loss = 0.00874900\n",
      "Iteration 3406, loss = 0.00874506\n",
      "Iteration 3407, loss = 0.00874148\n",
      "Iteration 3408, loss = 0.00873784\n",
      "Iteration 3409, loss = 0.00873374\n",
      "Iteration 3410, loss = 0.00873032\n",
      "Iteration 3411, loss = 0.00872647\n",
      "Iteration 3412, loss = 0.00872272\n",
      "Iteration 3413, loss = 0.00871917\n",
      "Iteration 3414, loss = 0.00871658\n",
      "Iteration 3415, loss = 0.00871272\n",
      "Iteration 3416, loss = 0.00870953\n",
      "Iteration 3417, loss = 0.00870635\n",
      "Iteration 3418, loss = 0.00870251\n",
      "Iteration 3419, loss = 0.00869900\n",
      "Iteration 3420, loss = 0.00869548\n",
      "Iteration 3421, loss = 0.00869249\n",
      "Iteration 3422, loss = 0.00868892\n",
      "Iteration 3423, loss = 0.00868533\n",
      "Iteration 3424, loss = 0.00868201\n",
      "Iteration 3425, loss = 0.00867859\n",
      "Iteration 3426, loss = 0.00867556\n",
      "Iteration 3427, loss = 0.00867213\n",
      "Iteration 3428, loss = 0.00866805\n",
      "Iteration 3429, loss = 0.00866611\n",
      "Iteration 3430, loss = 0.00866097\n",
      "Iteration 3431, loss = 0.00865696\n",
      "Iteration 3432, loss = 0.00865351\n",
      "Iteration 3433, loss = 0.00865007\n",
      "Iteration 3434, loss = 0.00864652\n",
      "Iteration 3435, loss = 0.00864283\n",
      "Iteration 3436, loss = 0.00863935\n",
      "Iteration 3437, loss = 0.00863608\n",
      "Iteration 3438, loss = 0.00863223\n",
      "Iteration 3439, loss = 0.00862872\n",
      "Iteration 3440, loss = 0.00862525\n",
      "Iteration 3441, loss = 0.00862207\n",
      "Iteration 3442, loss = 0.00861865\n",
      "Iteration 3443, loss = 0.00861537\n",
      "Iteration 3444, loss = 0.00861228\n",
      "Iteration 3445, loss = 0.00860907\n",
      "Iteration 3446, loss = 0.00860561\n",
      "Iteration 3447, loss = 0.00860225\n",
      "Iteration 3448, loss = 0.00859928\n",
      "Iteration 3449, loss = 0.00859596\n",
      "Iteration 3450, loss = 0.00859260\n",
      "Iteration 3451, loss = 0.00859059\n",
      "Iteration 3452, loss = 0.00858637\n",
      "Iteration 3453, loss = 0.00858273\n",
      "Iteration 3454, loss = 0.00858000\n",
      "Iteration 3455, loss = 0.00857634\n",
      "Iteration 3456, loss = 0.00857459\n",
      "Iteration 3457, loss = 0.00857014\n",
      "Iteration 3458, loss = 0.00856715\n",
      "Iteration 3459, loss = 0.00856349\n",
      "Iteration 3460, loss = 0.00856033\n",
      "Iteration 3461, loss = 0.00855713\n",
      "Iteration 3462, loss = 0.00855418\n",
      "Iteration 3463, loss = 0.00855059\n",
      "Iteration 3464, loss = 0.00854753\n",
      "Iteration 3465, loss = 0.00854424\n",
      "Iteration 3466, loss = 0.00854044\n",
      "Iteration 3467, loss = 0.00853674\n",
      "Iteration 3468, loss = 0.00853336\n",
      "Iteration 3469, loss = 0.00853011\n",
      "Iteration 3470, loss = 0.00852646\n",
      "Iteration 3471, loss = 0.00852329\n",
      "Iteration 3472, loss = 0.00851945\n",
      "Iteration 3473, loss = 0.00851646\n",
      "Iteration 3474, loss = 0.00851258\n",
      "Iteration 3475, loss = 0.00850930\n",
      "Iteration 3476, loss = 0.00850527\n",
      "Iteration 3477, loss = 0.00850185\n",
      "Iteration 3478, loss = 0.00849877\n",
      "Iteration 3479, loss = 0.00849484\n",
      "Iteration 3480, loss = 0.00849200\n",
      "Iteration 3481, loss = 0.00848800\n",
      "Iteration 3482, loss = 0.00848594\n",
      "Iteration 3483, loss = 0.00848180\n",
      "Iteration 3484, loss = 0.00847992\n",
      "Iteration 3485, loss = 0.00847659\n",
      "Iteration 3486, loss = 0.00847321\n",
      "Iteration 3487, loss = 0.00846965\n",
      "Iteration 3488, loss = 0.00846603\n",
      "Iteration 3489, loss = 0.00846347\n",
      "Iteration 3490, loss = 0.00845929\n",
      "Iteration 3491, loss = 0.00845572\n",
      "Iteration 3492, loss = 0.00845288\n",
      "Iteration 3493, loss = 0.00844926\n",
      "Iteration 3494, loss = 0.00844587\n",
      "Iteration 3495, loss = 0.00844290\n",
      "Iteration 3496, loss = 0.00843965\n",
      "Iteration 3497, loss = 0.00843615\n",
      "Iteration 3498, loss = 0.00843290\n",
      "Iteration 3499, loss = 0.00842946\n",
      "Iteration 3500, loss = 0.00842617\n",
      "Iteration 3501, loss = 0.00842264\n",
      "Iteration 3502, loss = 0.00841961\n",
      "Iteration 3503, loss = 0.00841580\n",
      "Iteration 3504, loss = 0.00841244\n",
      "Iteration 3505, loss = 0.00840888\n",
      "Iteration 3506, loss = 0.00840534\n",
      "Iteration 3507, loss = 0.00840387\n",
      "Iteration 3508, loss = 0.00839932\n",
      "Iteration 3509, loss = 0.00839617\n",
      "Iteration 3510, loss = 0.00839232\n",
      "Iteration 3511, loss = 0.00838889\n",
      "Iteration 3512, loss = 0.00838622\n",
      "Iteration 3513, loss = 0.00838218\n",
      "Iteration 3514, loss = 0.00837978\n",
      "Iteration 3515, loss = 0.00837577\n",
      "Iteration 3516, loss = 0.00837241\n",
      "Iteration 3517, loss = 0.00837007\n",
      "Iteration 3518, loss = 0.00836611\n",
      "Iteration 3519, loss = 0.00836281\n",
      "Iteration 3520, loss = 0.00835909\n",
      "Iteration 3521, loss = 0.00835569\n",
      "Iteration 3522, loss = 0.00835302\n",
      "Iteration 3523, loss = 0.00834899\n",
      "Iteration 3524, loss = 0.00834577\n",
      "Iteration 3525, loss = 0.00834224\n",
      "Iteration 3526, loss = 0.00834026\n",
      "Iteration 3527, loss = 0.00833538\n",
      "Iteration 3528, loss = 0.00833186\n",
      "Iteration 3529, loss = 0.00832836\n",
      "Iteration 3530, loss = 0.00832468\n",
      "Iteration 3531, loss = 0.00832155\n",
      "Iteration 3532, loss = 0.00831762\n",
      "Iteration 3533, loss = 0.00831426\n",
      "Iteration 3534, loss = 0.00831063\n",
      "Iteration 3535, loss = 0.00830718\n",
      "Iteration 3536, loss = 0.00830390\n",
      "Iteration 3537, loss = 0.00830079\n",
      "Iteration 3538, loss = 0.00829736\n",
      "Iteration 3539, loss = 0.00829427\n",
      "Iteration 3540, loss = 0.00829142\n",
      "Iteration 3541, loss = 0.00828815\n",
      "Iteration 3542, loss = 0.00828488\n",
      "Iteration 3543, loss = 0.00828182\n",
      "Iteration 3544, loss = 0.00827858\n",
      "Iteration 3545, loss = 0.00827603\n",
      "Iteration 3546, loss = 0.00827272\n",
      "Iteration 3547, loss = 0.00826989\n",
      "Iteration 3548, loss = 0.00826718\n",
      "Iteration 3549, loss = 0.00826291\n",
      "Iteration 3550, loss = 0.00826007\n",
      "Iteration 3551, loss = 0.00825633\n",
      "Iteration 3552, loss = 0.00825461\n",
      "Iteration 3553, loss = 0.00825028\n",
      "Iteration 3554, loss = 0.00824713\n",
      "Iteration 3555, loss = 0.00824399\n",
      "Iteration 3556, loss = 0.00824025\n",
      "Iteration 3557, loss = 0.00823680\n",
      "Iteration 3558, loss = 0.00823366\n",
      "Iteration 3559, loss = 0.00823029\n",
      "Iteration 3560, loss = 0.00822740\n",
      "Iteration 3561, loss = 0.00822472\n",
      "Iteration 3562, loss = 0.00822120\n",
      "Iteration 3563, loss = 0.00821834\n",
      "Iteration 3564, loss = 0.00821545\n",
      "Iteration 3565, loss = 0.00821254\n",
      "Iteration 3566, loss = 0.00821043\n",
      "Iteration 3567, loss = 0.00820747\n",
      "Iteration 3568, loss = 0.00820431\n",
      "Iteration 3569, loss = 0.00820087\n",
      "Iteration 3570, loss = 0.00819770\n",
      "Iteration 3571, loss = 0.00819492\n",
      "Iteration 3572, loss = 0.00819153\n",
      "Iteration 3573, loss = 0.00818972\n",
      "Iteration 3574, loss = 0.00818466\n",
      "Iteration 3575, loss = 0.00818177\n",
      "Iteration 3576, loss = 0.00817925\n",
      "Iteration 3577, loss = 0.00817411\n",
      "Iteration 3578, loss = 0.00817097\n",
      "Iteration 3579, loss = 0.00816744\n",
      "Iteration 3580, loss = 0.00816510\n",
      "Iteration 3581, loss = 0.00816183\n",
      "Iteration 3582, loss = 0.00815834\n",
      "Iteration 3583, loss = 0.00815595\n",
      "Iteration 3584, loss = 0.00815222\n",
      "Iteration 3585, loss = 0.00814913\n",
      "Iteration 3586, loss = 0.00814578\n",
      "Iteration 3587, loss = 0.00814279\n",
      "Iteration 3588, loss = 0.00813995\n",
      "Iteration 3589, loss = 0.00813672\n",
      "Iteration 3590, loss = 0.00813353\n",
      "Iteration 3591, loss = 0.00813043\n",
      "Iteration 3592, loss = 0.00812754\n",
      "Iteration 3593, loss = 0.00812496\n",
      "Iteration 3594, loss = 0.00812221\n",
      "Iteration 3595, loss = 0.00811926\n",
      "Iteration 3596, loss = 0.00811539\n",
      "Iteration 3597, loss = 0.00811194\n",
      "Iteration 3598, loss = 0.00810830\n",
      "Iteration 3599, loss = 0.00810528\n",
      "Iteration 3600, loss = 0.00810141\n",
      "Iteration 3601, loss = 0.00809823\n",
      "Iteration 3602, loss = 0.00809543\n",
      "Iteration 3603, loss = 0.00809167\n",
      "Iteration 3604, loss = 0.00808969\n",
      "Iteration 3605, loss = 0.00808592\n",
      "Iteration 3606, loss = 0.00808239\n",
      "Iteration 3607, loss = 0.00808043\n",
      "Iteration 3608, loss = 0.00807684\n",
      "Iteration 3609, loss = 0.00807358\n",
      "Iteration 3610, loss = 0.00807057\n",
      "Iteration 3611, loss = 0.00806746\n",
      "Iteration 3612, loss = 0.00806492\n",
      "Iteration 3613, loss = 0.00806190\n",
      "Iteration 3614, loss = 0.00805922\n",
      "Iteration 3615, loss = 0.00805656\n",
      "Iteration 3616, loss = 0.00805385\n",
      "Iteration 3617, loss = 0.00805088\n",
      "Iteration 3618, loss = 0.00804870\n",
      "Iteration 3619, loss = 0.00804496\n",
      "Iteration 3620, loss = 0.00804191\n",
      "Iteration 3621, loss = 0.00803858\n",
      "Iteration 3622, loss = 0.00803651\n",
      "Iteration 3623, loss = 0.00803270\n",
      "Iteration 3624, loss = 0.00802985\n",
      "Iteration 3625, loss = 0.00802645\n",
      "Iteration 3626, loss = 0.00802375\n",
      "Iteration 3627, loss = 0.00802117\n",
      "Iteration 3628, loss = 0.00801795\n",
      "Iteration 3629, loss = 0.00801492\n",
      "Iteration 3630, loss = 0.00801190\n",
      "Iteration 3631, loss = 0.00800939\n",
      "Iteration 3632, loss = 0.00800638\n",
      "Iteration 3633, loss = 0.00800387\n",
      "Iteration 3634, loss = 0.00800091\n",
      "Iteration 3635, loss = 0.00799847\n",
      "Iteration 3636, loss = 0.00799600\n",
      "Iteration 3637, loss = 0.00799337\n",
      "Iteration 3638, loss = 0.00799050\n",
      "Iteration 3639, loss = 0.00798796\n",
      "Iteration 3640, loss = 0.00798522\n",
      "Iteration 3641, loss = 0.00798245\n",
      "Iteration 3642, loss = 0.00798000\n",
      "Iteration 3643, loss = 0.00797742\n",
      "Iteration 3644, loss = 0.00797364\n",
      "Iteration 3645, loss = 0.00797082\n",
      "Iteration 3646, loss = 0.00796763\n",
      "Iteration 3647, loss = 0.00796460\n",
      "Iteration 3648, loss = 0.00796184\n",
      "Iteration 3649, loss = 0.00795888\n",
      "Iteration 3650, loss = 0.00795585\n",
      "Iteration 3651, loss = 0.00795336\n",
      "Iteration 3652, loss = 0.00795007\n",
      "Iteration 3653, loss = 0.00794672\n",
      "Iteration 3654, loss = 0.00794400\n",
      "Iteration 3655, loss = 0.00794074\n",
      "Iteration 3656, loss = 0.00793791\n",
      "Iteration 3657, loss = 0.00793499\n",
      "Iteration 3658, loss = 0.00793185\n",
      "Iteration 3659, loss = 0.00792945\n",
      "Iteration 3660, loss = 0.00792579\n",
      "Iteration 3661, loss = 0.00792291\n",
      "Iteration 3662, loss = 0.00791943\n",
      "Iteration 3663, loss = 0.00791684\n",
      "Iteration 3664, loss = 0.00791339\n",
      "Iteration 3665, loss = 0.00791053\n",
      "Iteration 3666, loss = 0.00790810\n",
      "Iteration 3667, loss = 0.00790469\n",
      "Iteration 3668, loss = 0.00790329\n",
      "Iteration 3669, loss = 0.00789959\n",
      "Iteration 3670, loss = 0.00789688\n",
      "Iteration 3671, loss = 0.00789402\n",
      "Iteration 3672, loss = 0.00789107\n",
      "Iteration 3673, loss = 0.00788851\n",
      "Iteration 3674, loss = 0.00788568\n",
      "Iteration 3675, loss = 0.00788301\n",
      "Iteration 3676, loss = 0.00787987\n",
      "Iteration 3677, loss = 0.00787696\n",
      "Iteration 3678, loss = 0.00787416\n",
      "Iteration 3679, loss = 0.00787164\n",
      "Iteration 3680, loss = 0.00786949\n",
      "Iteration 3681, loss = 0.00786618\n",
      "Iteration 3682, loss = 0.00786364\n",
      "Iteration 3683, loss = 0.00786059\n",
      "Iteration 3684, loss = 0.00785761\n",
      "Iteration 3685, loss = 0.00785475\n",
      "Iteration 3686, loss = 0.00785135\n",
      "Iteration 3687, loss = 0.00784861\n",
      "Iteration 3688, loss = 0.00784535\n",
      "Iteration 3689, loss = 0.00784286\n",
      "Iteration 3690, loss = 0.00783969\n",
      "Iteration 3691, loss = 0.00783674\n",
      "Iteration 3692, loss = 0.00783402\n",
      "Iteration 3693, loss = 0.00783175\n",
      "Iteration 3694, loss = 0.00782893\n",
      "Iteration 3695, loss = 0.00782704\n",
      "Iteration 3696, loss = 0.00782339\n",
      "Iteration 3697, loss = 0.00782050\n",
      "Iteration 3698, loss = 0.00781786\n",
      "Iteration 3699, loss = 0.00781477\n",
      "Iteration 3700, loss = 0.00781194\n",
      "Iteration 3701, loss = 0.00780891\n",
      "Iteration 3702, loss = 0.00780645\n",
      "Iteration 3703, loss = 0.00780329\n",
      "Iteration 3704, loss = 0.00780045\n",
      "Iteration 3705, loss = 0.00779673\n",
      "Iteration 3706, loss = 0.00779392\n",
      "Iteration 3707, loss = 0.00779051\n",
      "Iteration 3708, loss = 0.00778817\n",
      "Iteration 3709, loss = 0.00778465\n",
      "Iteration 3710, loss = 0.00778174\n",
      "Iteration 3711, loss = 0.00777887\n",
      "Iteration 3712, loss = 0.00777583\n",
      "Iteration 3713, loss = 0.00777302\n",
      "Iteration 3714, loss = 0.00777047\n",
      "Iteration 3715, loss = 0.00776760\n",
      "Iteration 3716, loss = 0.00776472\n",
      "Iteration 3717, loss = 0.00776216\n",
      "Iteration 3718, loss = 0.00775897\n",
      "Iteration 3719, loss = 0.00775639\n",
      "Iteration 3720, loss = 0.00775333\n",
      "Iteration 3721, loss = 0.00775060\n",
      "Iteration 3722, loss = 0.00774753\n",
      "Iteration 3723, loss = 0.00774493\n",
      "Iteration 3724, loss = 0.00774130\n",
      "Iteration 3725, loss = 0.00773846\n",
      "Iteration 3726, loss = 0.00773524\n",
      "Iteration 3727, loss = 0.00773261\n",
      "Iteration 3728, loss = 0.00772995\n",
      "Iteration 3729, loss = 0.00772708\n",
      "Iteration 3730, loss = 0.00772422\n",
      "Iteration 3731, loss = 0.00772092\n",
      "Iteration 3732, loss = 0.00771823\n",
      "Iteration 3733, loss = 0.00771488\n",
      "Iteration 3734, loss = 0.00771213\n",
      "Iteration 3735, loss = 0.00770930\n",
      "Iteration 3736, loss = 0.00770571\n",
      "Iteration 3737, loss = 0.00770264\n",
      "Iteration 3738, loss = 0.00769923\n",
      "Iteration 3739, loss = 0.00769588\n",
      "Iteration 3740, loss = 0.00769251\n",
      "Iteration 3741, loss = 0.00769008\n",
      "Iteration 3742, loss = 0.00768647\n",
      "Iteration 3743, loss = 0.00768391\n",
      "Iteration 3744, loss = 0.00768096\n",
      "Iteration 3745, loss = 0.00767743\n",
      "Iteration 3746, loss = 0.00767522\n",
      "Iteration 3747, loss = 0.00767186\n",
      "Iteration 3748, loss = 0.00766923\n",
      "Iteration 3749, loss = 0.00766669\n",
      "Iteration 3750, loss = 0.00766395\n",
      "Iteration 3751, loss = 0.00766124\n",
      "Iteration 3752, loss = 0.00765867\n",
      "Iteration 3753, loss = 0.00765737\n",
      "Iteration 3754, loss = 0.00765345\n",
      "Iteration 3755, loss = 0.00765020\n",
      "Iteration 3756, loss = 0.00764752\n",
      "Iteration 3757, loss = 0.00764432\n",
      "Iteration 3758, loss = 0.00764165\n",
      "Iteration 3759, loss = 0.00763877\n",
      "Iteration 3760, loss = 0.00763581\n",
      "Iteration 3761, loss = 0.00763271\n",
      "Iteration 3762, loss = 0.00763048\n",
      "Iteration 3763, loss = 0.00762718\n",
      "Iteration 3764, loss = 0.00762418\n",
      "Iteration 3765, loss = 0.00762166\n",
      "Iteration 3766, loss = 0.00761910\n",
      "Iteration 3767, loss = 0.00761629\n",
      "Iteration 3768, loss = 0.00761365\n",
      "Iteration 3769, loss = 0.00761121\n",
      "Iteration 3770, loss = 0.00760872\n",
      "Iteration 3771, loss = 0.00760612\n",
      "Iteration 3772, loss = 0.00760334\n",
      "Iteration 3773, loss = 0.00760098\n",
      "Iteration 3774, loss = 0.00759780\n",
      "Iteration 3775, loss = 0.00759522\n",
      "Iteration 3776, loss = 0.00759283\n",
      "Iteration 3777, loss = 0.00759027\n",
      "Iteration 3778, loss = 0.00758725\n",
      "Iteration 3779, loss = 0.00758444\n",
      "Iteration 3780, loss = 0.00758201\n",
      "Iteration 3781, loss = 0.00757909\n",
      "Iteration 3782, loss = 0.00757664\n",
      "Iteration 3783, loss = 0.00757403\n",
      "Iteration 3784, loss = 0.00757135\n",
      "Iteration 3785, loss = 0.00756914\n",
      "Iteration 3786, loss = 0.00756589\n",
      "Iteration 3787, loss = 0.00756343\n",
      "Iteration 3788, loss = 0.00756083\n",
      "Iteration 3789, loss = 0.00755791\n",
      "Iteration 3790, loss = 0.00755532\n",
      "Iteration 3791, loss = 0.00755263\n",
      "Iteration 3792, loss = 0.00755002\n",
      "Iteration 3793, loss = 0.00754752\n",
      "Iteration 3794, loss = 0.00754528\n",
      "Iteration 3795, loss = 0.00754247\n",
      "Iteration 3796, loss = 0.00754005\n",
      "Iteration 3797, loss = 0.00753756\n",
      "Iteration 3798, loss = 0.00753527\n",
      "Iteration 3799, loss = 0.00753285\n",
      "Iteration 3800, loss = 0.00753042\n",
      "Iteration 3801, loss = 0.00752773\n",
      "Iteration 3802, loss = 0.00752519\n",
      "Iteration 3803, loss = 0.00752261\n",
      "Iteration 3804, loss = 0.00752048\n",
      "Iteration 3805, loss = 0.00751747\n",
      "Iteration 3806, loss = 0.00751457\n",
      "Iteration 3807, loss = 0.00751258\n",
      "Iteration 3808, loss = 0.00751044\n",
      "Iteration 3809, loss = 0.00750697\n",
      "Iteration 3810, loss = 0.00750493\n",
      "Iteration 3811, loss = 0.00750164\n",
      "Iteration 3812, loss = 0.00749896\n",
      "Iteration 3813, loss = 0.00749745\n",
      "Iteration 3814, loss = 0.00749401\n",
      "Iteration 3815, loss = 0.00749141\n",
      "Iteration 3816, loss = 0.00748864\n",
      "Iteration 3817, loss = 0.00748621\n",
      "Iteration 3818, loss = 0.00748372\n",
      "Iteration 3819, loss = 0.00748104\n",
      "Iteration 3820, loss = 0.00747829\n",
      "Iteration 3821, loss = 0.00747559\n",
      "Iteration 3822, loss = 0.00747267\n",
      "Iteration 3823, loss = 0.00747037\n",
      "Iteration 3824, loss = 0.00746773\n",
      "Iteration 3825, loss = 0.00746504\n",
      "Iteration 3826, loss = 0.00746206\n",
      "Iteration 3827, loss = 0.00745979\n",
      "Iteration 3828, loss = 0.00745689\n",
      "Iteration 3829, loss = 0.00745413\n",
      "Iteration 3830, loss = 0.00745161\n",
      "Iteration 3831, loss = 0.00744920\n",
      "Iteration 3832, loss = 0.00744684\n",
      "Iteration 3833, loss = 0.00744403\n",
      "Iteration 3834, loss = 0.00744156\n",
      "Iteration 3835, loss = 0.00743881\n",
      "Iteration 3836, loss = 0.00743624\n",
      "Iteration 3837, loss = 0.00743366\n",
      "Iteration 3838, loss = 0.00743122\n",
      "Iteration 3839, loss = 0.00742836\n",
      "Iteration 3840, loss = 0.00742570\n",
      "Iteration 3841, loss = 0.00742318\n",
      "Iteration 3842, loss = 0.00742053\n",
      "Iteration 3843, loss = 0.00741766\n",
      "Iteration 3844, loss = 0.00741545\n",
      "Iteration 3845, loss = 0.00741215\n",
      "Iteration 3846, loss = 0.00740924\n",
      "Iteration 3847, loss = 0.00740662\n",
      "Iteration 3848, loss = 0.00740423\n",
      "Iteration 3849, loss = 0.00740113\n",
      "Iteration 3850, loss = 0.00739862\n",
      "Iteration 3851, loss = 0.00739619\n",
      "Iteration 3852, loss = 0.00739378\n",
      "Iteration 3853, loss = 0.00739162\n",
      "Iteration 3854, loss = 0.00738909\n",
      "Iteration 3855, loss = 0.00738655\n",
      "Iteration 3856, loss = 0.00738343\n",
      "Iteration 3857, loss = 0.00738131\n",
      "Iteration 3858, loss = 0.00737960\n",
      "Iteration 3859, loss = 0.00737577\n",
      "Iteration 3860, loss = 0.00737321\n",
      "Iteration 3861, loss = 0.00737078\n",
      "Iteration 3862, loss = 0.00736816\n",
      "Iteration 3863, loss = 0.00736529\n",
      "Iteration 3864, loss = 0.00736235\n",
      "Iteration 3865, loss = 0.00736132\n",
      "Iteration 3866, loss = 0.00735750\n",
      "Iteration 3867, loss = 0.00735466\n",
      "Iteration 3868, loss = 0.00735213\n",
      "Iteration 3869, loss = 0.00735020\n",
      "Iteration 3870, loss = 0.00734817\n",
      "Iteration 3871, loss = 0.00734529\n",
      "Iteration 3872, loss = 0.00734295\n",
      "Iteration 3873, loss = 0.00734029\n",
      "Iteration 3874, loss = 0.00733789\n",
      "Iteration 3875, loss = 0.00733537\n",
      "Iteration 3876, loss = 0.00733290\n",
      "Iteration 3877, loss = 0.00733051\n",
      "Iteration 3878, loss = 0.00732814\n",
      "Iteration 3879, loss = 0.00732636\n",
      "Iteration 3880, loss = 0.00732381\n",
      "Iteration 3881, loss = 0.00732110\n",
      "Iteration 3882, loss = 0.00731895\n",
      "Iteration 3883, loss = 0.00731618\n",
      "Iteration 3884, loss = 0.00731364\n",
      "Iteration 3885, loss = 0.00731127\n",
      "Iteration 3886, loss = 0.00730851\n",
      "Iteration 3887, loss = 0.00730602\n",
      "Iteration 3888, loss = 0.00730373\n",
      "Iteration 3889, loss = 0.00730142\n",
      "Iteration 3890, loss = 0.00729901\n",
      "Iteration 3891, loss = 0.00729637\n",
      "Iteration 3892, loss = 0.00729437\n",
      "Iteration 3893, loss = 0.00729189\n",
      "Iteration 3894, loss = 0.00728995\n",
      "Iteration 3895, loss = 0.00728763\n",
      "Iteration 3896, loss = 0.00728572\n",
      "Iteration 3897, loss = 0.00728269\n",
      "Iteration 3898, loss = 0.00728031\n",
      "Iteration 3899, loss = 0.00727781\n",
      "Iteration 3900, loss = 0.00727571\n",
      "Iteration 3901, loss = 0.00727301\n",
      "Iteration 3902, loss = 0.00727063\n",
      "Iteration 3903, loss = 0.00726880\n",
      "Iteration 3904, loss = 0.00726593\n",
      "Iteration 3905, loss = 0.00726395\n",
      "Iteration 3906, loss = 0.00726122\n",
      "Iteration 3907, loss = 0.00725899\n",
      "Iteration 3908, loss = 0.00725687\n",
      "Iteration 3909, loss = 0.00725422\n",
      "Iteration 3910, loss = 0.00725192\n",
      "Iteration 3911, loss = 0.00724944\n",
      "Iteration 3912, loss = 0.00724776\n",
      "Iteration 3913, loss = 0.00724414\n",
      "Iteration 3914, loss = 0.00724177\n",
      "Iteration 3915, loss = 0.00723835\n",
      "Iteration 3916, loss = 0.00723518\n",
      "Iteration 3917, loss = 0.00723227\n",
      "Iteration 3918, loss = 0.00722983\n",
      "Iteration 3919, loss = 0.00722665\n",
      "Iteration 3920, loss = 0.00722392\n",
      "Iteration 3921, loss = 0.00722197\n",
      "Iteration 3922, loss = 0.00721959\n",
      "Iteration 3923, loss = 0.00721639\n",
      "Iteration 3924, loss = 0.00721458\n",
      "Iteration 3925, loss = 0.00721143\n",
      "Iteration 3926, loss = 0.00720882\n",
      "Iteration 3927, loss = 0.00720596\n",
      "Iteration 3928, loss = 0.00720296\n",
      "Iteration 3929, loss = 0.00719984\n",
      "Iteration 3930, loss = 0.00719760\n",
      "Iteration 3931, loss = 0.00719412\n",
      "Iteration 3932, loss = 0.00719153\n",
      "Iteration 3933, loss = 0.00718955\n",
      "Iteration 3934, loss = 0.00718634\n",
      "Iteration 3935, loss = 0.00718413\n",
      "Iteration 3936, loss = 0.00718109\n",
      "Iteration 3937, loss = 0.00717872\n",
      "Iteration 3938, loss = 0.00717616\n",
      "Iteration 3939, loss = 0.00717351\n",
      "Iteration 3940, loss = 0.00717092\n",
      "Iteration 3941, loss = 0.00716810\n",
      "Iteration 3942, loss = 0.00716536\n",
      "Iteration 3943, loss = 0.00716247\n",
      "Iteration 3944, loss = 0.00715992\n",
      "Iteration 3945, loss = 0.00715755\n",
      "Iteration 3946, loss = 0.00715485\n",
      "Iteration 3947, loss = 0.00715239\n",
      "Iteration 3948, loss = 0.00715007\n",
      "Iteration 3949, loss = 0.00714778\n",
      "Iteration 3950, loss = 0.00714516\n",
      "Iteration 3951, loss = 0.00714301\n",
      "Iteration 3952, loss = 0.00714076\n",
      "Iteration 3953, loss = 0.00713952\n",
      "Iteration 3954, loss = 0.00713623\n",
      "Iteration 3955, loss = 0.00713371\n",
      "Iteration 3956, loss = 0.00713134\n",
      "Iteration 3957, loss = 0.00712915\n",
      "Iteration 3958, loss = 0.00712680\n",
      "Iteration 3959, loss = 0.00712493\n",
      "Iteration 3960, loss = 0.00712251\n",
      "Iteration 3961, loss = 0.00711958\n",
      "Iteration 3962, loss = 0.00711694\n",
      "Iteration 3963, loss = 0.00711489\n",
      "Iteration 3964, loss = 0.00711130\n",
      "Iteration 3965, loss = 0.00710825\n",
      "Iteration 3966, loss = 0.00710731\n",
      "Iteration 3967, loss = 0.00710446\n",
      "Iteration 3968, loss = 0.00710085\n",
      "Iteration 3969, loss = 0.00709846\n",
      "Iteration 3970, loss = 0.00709575\n",
      "Iteration 3971, loss = 0.00709336\n",
      "Iteration 3972, loss = 0.00709099\n",
      "Iteration 3973, loss = 0.00708789\n",
      "Iteration 3974, loss = 0.00708480\n",
      "Iteration 3975, loss = 0.00708268\n",
      "Iteration 3976, loss = 0.00708072\n",
      "Iteration 3977, loss = 0.00707727\n",
      "Iteration 3978, loss = 0.00707507\n",
      "Iteration 3979, loss = 0.00707263\n",
      "Iteration 3980, loss = 0.00706951\n",
      "Iteration 3981, loss = 0.00706723\n",
      "Iteration 3982, loss = 0.00706504\n",
      "Iteration 3983, loss = 0.00706352\n",
      "Iteration 3984, loss = 0.00706025\n",
      "Iteration 3985, loss = 0.00705812\n",
      "Iteration 3986, loss = 0.00705540\n",
      "Iteration 3987, loss = 0.00705306\n",
      "Iteration 3988, loss = 0.00705054\n",
      "Iteration 3989, loss = 0.00704798\n",
      "Iteration 3990, loss = 0.00704590\n",
      "Iteration 3991, loss = 0.00704290\n",
      "Iteration 3992, loss = 0.00704066\n",
      "Iteration 3993, loss = 0.00703852\n",
      "Iteration 3994, loss = 0.00703532\n",
      "Iteration 3995, loss = 0.00703286\n",
      "Iteration 3996, loss = 0.00703064\n",
      "Iteration 3997, loss = 0.00702806\n",
      "Iteration 3998, loss = 0.00702520\n",
      "Iteration 3999, loss = 0.00702314\n",
      "Iteration 4000, loss = 0.00702022\n",
      "Iteration 4001, loss = 0.00701786\n",
      "Iteration 4002, loss = 0.00701517\n",
      "Iteration 4003, loss = 0.00701266\n",
      "Iteration 4004, loss = 0.00701039\n",
      "Iteration 4005, loss = 0.00700765\n",
      "Iteration 4006, loss = 0.00700504\n",
      "Iteration 4007, loss = 0.00700297\n",
      "Iteration 4008, loss = 0.00700001\n",
      "Iteration 4009, loss = 0.00699726\n",
      "Iteration 4010, loss = 0.00699477\n",
      "Iteration 4011, loss = 0.00699221\n",
      "Iteration 4012, loss = 0.00698954\n",
      "Iteration 4013, loss = 0.00698708\n",
      "Iteration 4014, loss = 0.00698420\n",
      "Iteration 4015, loss = 0.00698200\n",
      "Iteration 4016, loss = 0.00697903\n",
      "Iteration 4017, loss = 0.00697664\n",
      "Iteration 4018, loss = 0.00697415\n",
      "Iteration 4019, loss = 0.00697190\n",
      "Iteration 4020, loss = 0.00696911\n",
      "Iteration 4021, loss = 0.00696683\n",
      "Iteration 4022, loss = 0.00696431\n",
      "Iteration 4023, loss = 0.00696243\n",
      "Iteration 4024, loss = 0.00695951\n",
      "Iteration 4025, loss = 0.00695726\n",
      "Iteration 4026, loss = 0.00695509\n",
      "Iteration 4027, loss = 0.00695254\n",
      "Iteration 4028, loss = 0.00695022\n",
      "Iteration 4029, loss = 0.00694808\n",
      "Iteration 4030, loss = 0.00694610\n",
      "Iteration 4031, loss = 0.00694354\n",
      "Iteration 4032, loss = 0.00694058\n",
      "Iteration 4033, loss = 0.00693834\n",
      "Iteration 4034, loss = 0.00693613\n",
      "Iteration 4035, loss = 0.00693356\n",
      "Iteration 4036, loss = 0.00693103\n",
      "Iteration 4037, loss = 0.00692873\n",
      "Iteration 4038, loss = 0.00692607\n",
      "Iteration 4039, loss = 0.00692354\n",
      "Iteration 4040, loss = 0.00692108\n",
      "Iteration 4041, loss = 0.00691820\n",
      "Iteration 4042, loss = 0.00691673\n",
      "Iteration 4043, loss = 0.00691342\n",
      "Iteration 4044, loss = 0.00691126\n",
      "Iteration 4045, loss = 0.00690822\n",
      "Iteration 4046, loss = 0.00690649\n",
      "Iteration 4047, loss = 0.00690344\n",
      "Iteration 4048, loss = 0.00690162\n",
      "Iteration 4049, loss = 0.00689897\n",
      "Iteration 4050, loss = 0.00689654\n",
      "Iteration 4051, loss = 0.00689395\n",
      "Iteration 4052, loss = 0.00689147\n",
      "Iteration 4053, loss = 0.00688905\n",
      "Iteration 4054, loss = 0.00688668\n",
      "Iteration 4055, loss = 0.00688516\n",
      "Iteration 4056, loss = 0.00688179\n",
      "Iteration 4057, loss = 0.00687928\n",
      "Iteration 4058, loss = 0.00687705\n",
      "Iteration 4059, loss = 0.00687399\n",
      "Iteration 4060, loss = 0.00687124\n",
      "Iteration 4061, loss = 0.00686859\n",
      "Iteration 4062, loss = 0.00686648\n",
      "Iteration 4063, loss = 0.00686394\n",
      "Iteration 4064, loss = 0.00686127\n",
      "Iteration 4065, loss = 0.00685876\n",
      "Iteration 4066, loss = 0.00685619\n",
      "Iteration 4067, loss = 0.00685525\n",
      "Iteration 4068, loss = 0.00685165\n",
      "Iteration 4069, loss = 0.00684935\n",
      "Iteration 4070, loss = 0.00684704\n",
      "Iteration 4071, loss = 0.00684452\n",
      "Iteration 4072, loss = 0.00684234\n",
      "Iteration 4073, loss = 0.00683999\n",
      "Iteration 4074, loss = 0.00683817\n",
      "Iteration 4075, loss = 0.00683492\n",
      "Iteration 4076, loss = 0.00683327\n",
      "Iteration 4077, loss = 0.00683177\n",
      "Iteration 4078, loss = 0.00682841\n",
      "Iteration 4079, loss = 0.00682659\n",
      "Iteration 4080, loss = 0.00682371\n",
      "Iteration 4081, loss = 0.00682152\n",
      "Iteration 4082, loss = 0.00681925\n",
      "Iteration 4083, loss = 0.00681697\n",
      "Iteration 4084, loss = 0.00681486\n",
      "Iteration 4085, loss = 0.00681265\n",
      "Iteration 4086, loss = 0.00681027\n",
      "Iteration 4087, loss = 0.00680801\n",
      "Iteration 4088, loss = 0.00680679\n",
      "Iteration 4089, loss = 0.00680347\n",
      "Iteration 4090, loss = 0.00680098\n",
      "Iteration 4091, loss = 0.00679896\n",
      "Iteration 4092, loss = 0.00679646\n",
      "Iteration 4093, loss = 0.00679427\n",
      "Iteration 4094, loss = 0.00679235\n",
      "Iteration 4095, loss = 0.00678994\n",
      "Iteration 4096, loss = 0.00678789\n",
      "Iteration 4097, loss = 0.00678632\n",
      "Iteration 4098, loss = 0.00678403\n",
      "Iteration 4099, loss = 0.00678170\n",
      "Iteration 4100, loss = 0.00678005\n",
      "Iteration 4101, loss = 0.00677792\n",
      "Iteration 4102, loss = 0.00677564\n",
      "Iteration 4103, loss = 0.00677350\n",
      "Iteration 4104, loss = 0.00677155\n",
      "Iteration 4105, loss = 0.00676924\n",
      "Iteration 4106, loss = 0.00676726\n",
      "Iteration 4107, loss = 0.00676571\n",
      "Iteration 4108, loss = 0.00676336\n",
      "Iteration 4109, loss = 0.00676102\n",
      "Iteration 4110, loss = 0.00675904\n",
      "Iteration 4111, loss = 0.00675678\n",
      "Iteration 4112, loss = 0.00675472\n",
      "Iteration 4113, loss = 0.00675262\n",
      "Iteration 4114, loss = 0.00675054\n",
      "Iteration 4115, loss = 0.00674915\n",
      "Iteration 4116, loss = 0.00674746\n",
      "Iteration 4117, loss = 0.00674481\n",
      "Iteration 4118, loss = 0.00674237\n",
      "Iteration 4119, loss = 0.00674006\n",
      "Iteration 4120, loss = 0.00673799\n",
      "Iteration 4121, loss = 0.00673586\n",
      "Iteration 4122, loss = 0.00673409\n",
      "Iteration 4123, loss = 0.00673190\n",
      "Iteration 4124, loss = 0.00672961\n",
      "Iteration 4125, loss = 0.00672780\n",
      "Iteration 4126, loss = 0.00672550\n",
      "Iteration 4127, loss = 0.00672332\n",
      "Iteration 4128, loss = 0.00672179\n",
      "Iteration 4129, loss = 0.00672075\n",
      "Iteration 4130, loss = 0.00671858\n",
      "Iteration 4131, loss = 0.00671668\n",
      "Iteration 4132, loss = 0.00671447\n",
      "Iteration 4133, loss = 0.00671387\n",
      "Iteration 4134, loss = 0.00671078\n",
      "Iteration 4135, loss = 0.00670862\n",
      "Iteration 4136, loss = 0.00670666\n",
      "Iteration 4137, loss = 0.00670427\n",
      "Iteration 4138, loss = 0.00670191\n",
      "Iteration 4139, loss = 0.00669964\n",
      "Iteration 4140, loss = 0.00669776\n",
      "Iteration 4141, loss = 0.00669630\n",
      "Iteration 4142, loss = 0.00669342\n",
      "Iteration 4143, loss = 0.00669193\n",
      "Iteration 4144, loss = 0.00669047\n",
      "Iteration 4145, loss = 0.00668869\n",
      "Iteration 4146, loss = 0.00668567\n",
      "Iteration 4147, loss = 0.00668395\n",
      "Iteration 4148, loss = 0.00668076\n",
      "Iteration 4149, loss = 0.00667807\n",
      "Iteration 4150, loss = 0.00667541\n",
      "Iteration 4151, loss = 0.00667250\n",
      "Iteration 4152, loss = 0.00667079\n",
      "Iteration 4153, loss = 0.00666723\n",
      "Iteration 4154, loss = 0.00666497\n",
      "Iteration 4155, loss = 0.00666258\n",
      "Iteration 4156, loss = 0.00666023\n",
      "Iteration 4157, loss = 0.00665798\n",
      "Iteration 4158, loss = 0.00665579\n",
      "Iteration 4159, loss = 0.00665334\n",
      "Iteration 4160, loss = 0.00665036\n",
      "Iteration 4161, loss = 0.00664819\n",
      "Iteration 4162, loss = 0.00664501\n",
      "Iteration 4163, loss = 0.00664245\n",
      "Iteration 4164, loss = 0.00664108\n",
      "Iteration 4165, loss = 0.00663778\n",
      "Iteration 4166, loss = 0.00663530\n",
      "Iteration 4167, loss = 0.00663322\n",
      "Iteration 4168, loss = 0.00663114\n",
      "Iteration 4169, loss = 0.00662847\n",
      "Iteration 4170, loss = 0.00662620\n",
      "Iteration 4171, loss = 0.00662386\n",
      "Iteration 4172, loss = 0.00662156\n",
      "Iteration 4173, loss = 0.00661913\n",
      "Iteration 4174, loss = 0.00661638\n",
      "Iteration 4175, loss = 0.00661361\n",
      "Iteration 4176, loss = 0.00661139\n",
      "Iteration 4177, loss = 0.00660889\n",
      "Iteration 4178, loss = 0.00660617\n",
      "Iteration 4179, loss = 0.00660376\n",
      "Iteration 4180, loss = 0.00660100\n",
      "Iteration 4181, loss = 0.00659889\n",
      "Iteration 4182, loss = 0.00659593\n",
      "Iteration 4183, loss = 0.00659393\n",
      "Iteration 4184, loss = 0.00659156\n",
      "Iteration 4185, loss = 0.00659029\n",
      "Iteration 4186, loss = 0.00658683\n",
      "Iteration 4187, loss = 0.00658507\n",
      "Iteration 4188, loss = 0.00658217\n",
      "Iteration 4189, loss = 0.00658003\n",
      "Iteration 4190, loss = 0.00657797\n",
      "Iteration 4191, loss = 0.00657585\n",
      "Iteration 4192, loss = 0.00657374\n",
      "Iteration 4193, loss = 0.00657147\n",
      "Iteration 4194, loss = 0.00656943\n",
      "Iteration 4195, loss = 0.00656704\n",
      "Iteration 4196, loss = 0.00656451\n",
      "Iteration 4197, loss = 0.00656226\n",
      "Iteration 4198, loss = 0.00656043\n",
      "Iteration 4199, loss = 0.00655792\n",
      "Iteration 4200, loss = 0.00655557\n",
      "Iteration 4201, loss = 0.00655360\n",
      "Iteration 4202, loss = 0.00655164\n",
      "Iteration 4203, loss = 0.00654961\n",
      "Iteration 4204, loss = 0.00654721\n",
      "Iteration 4205, loss = 0.00654501\n",
      "Iteration 4206, loss = 0.00654258\n",
      "Iteration 4207, loss = 0.00653996\n",
      "Iteration 4208, loss = 0.00653779\n",
      "Iteration 4209, loss = 0.00653573\n",
      "Iteration 4210, loss = 0.00653321\n",
      "Iteration 4211, loss = 0.00653127\n",
      "Iteration 4212, loss = 0.00652877\n",
      "Iteration 4213, loss = 0.00652711\n",
      "Iteration 4214, loss = 0.00652500\n",
      "Iteration 4215, loss = 0.00652317\n",
      "Iteration 4216, loss = 0.00652081\n",
      "Iteration 4217, loss = 0.00651864\n",
      "Iteration 4218, loss = 0.00651635\n",
      "Iteration 4219, loss = 0.00651463\n",
      "Iteration 4220, loss = 0.00651217\n",
      "Iteration 4221, loss = 0.00650993\n",
      "Iteration 4222, loss = 0.00650770\n",
      "Iteration 4223, loss = 0.00650637\n",
      "Iteration 4224, loss = 0.00650403\n",
      "Iteration 4225, loss = 0.00650164\n",
      "Iteration 4226, loss = 0.00649944\n",
      "Iteration 4227, loss = 0.00649777\n",
      "Iteration 4228, loss = 0.00649545\n",
      "Iteration 4229, loss = 0.00649300\n",
      "Iteration 4230, loss = 0.00649093\n",
      "Iteration 4231, loss = 0.00648860\n",
      "Iteration 4232, loss = 0.00648657\n",
      "Iteration 4233, loss = 0.00648429\n",
      "Iteration 4234, loss = 0.00648205\n",
      "Iteration 4235, loss = 0.00648017\n",
      "Iteration 4236, loss = 0.00647760\n",
      "Iteration 4237, loss = 0.00647524\n",
      "Iteration 4238, loss = 0.00647373\n",
      "Iteration 4239, loss = 0.00647155\n",
      "Iteration 4240, loss = 0.00646897\n",
      "Iteration 4241, loss = 0.00646664\n",
      "Iteration 4242, loss = 0.00646435\n",
      "Iteration 4243, loss = 0.00646250\n",
      "Iteration 4244, loss = 0.00646058\n",
      "Iteration 4245, loss = 0.00645854\n",
      "Iteration 4246, loss = 0.00645637\n",
      "Iteration 4247, loss = 0.00645456\n",
      "Iteration 4248, loss = 0.00645239\n",
      "Iteration 4249, loss = 0.00645049\n",
      "Iteration 4250, loss = 0.00644886\n",
      "Iteration 4251, loss = 0.00644670\n",
      "Iteration 4252, loss = 0.00644478\n",
      "Iteration 4253, loss = 0.00644290\n",
      "Iteration 4254, loss = 0.00644101\n",
      "Iteration 4255, loss = 0.00643922\n",
      "Iteration 4256, loss = 0.00643773\n",
      "Iteration 4257, loss = 0.00643554\n",
      "Iteration 4258, loss = 0.00643320\n",
      "Iteration 4259, loss = 0.00643143\n",
      "Iteration 4260, loss = 0.00642920\n",
      "Iteration 4261, loss = 0.00642727\n",
      "Iteration 4262, loss = 0.00642545\n",
      "Iteration 4263, loss = 0.00642354\n",
      "Iteration 4264, loss = 0.00642135\n",
      "Iteration 4265, loss = 0.00641962\n",
      "Iteration 4266, loss = 0.00641730\n",
      "Iteration 4267, loss = 0.00641544\n",
      "Iteration 4268, loss = 0.00641347\n",
      "Iteration 4269, loss = 0.00641125\n",
      "Iteration 4270, loss = 0.00640902\n",
      "Iteration 4271, loss = 0.00640691\n",
      "Iteration 4272, loss = 0.00640487\n",
      "Iteration 4273, loss = 0.00640279\n",
      "Iteration 4274, loss = 0.00640083\n",
      "Iteration 4275, loss = 0.00639883\n",
      "Iteration 4276, loss = 0.00639652\n",
      "Iteration 4277, loss = 0.00639414\n",
      "Iteration 4278, loss = 0.00639204\n",
      "Iteration 4279, loss = 0.00638970\n",
      "Iteration 4280, loss = 0.00638730\n",
      "Iteration 4281, loss = 0.00638538\n",
      "Iteration 4282, loss = 0.00638271\n",
      "Iteration 4283, loss = 0.00638094\n",
      "Iteration 4284, loss = 0.00637821\n",
      "Iteration 4285, loss = 0.00637603\n",
      "Iteration 4286, loss = 0.00637343\n",
      "Iteration 4287, loss = 0.00637178\n",
      "Iteration 4288, loss = 0.00636938\n",
      "Iteration 4289, loss = 0.00636694\n",
      "Iteration 4290, loss = 0.00636446\n",
      "Iteration 4291, loss = 0.00636383\n",
      "Iteration 4292, loss = 0.00636042\n",
      "Iteration 4293, loss = 0.00635883\n",
      "Iteration 4294, loss = 0.00635622\n",
      "Iteration 4295, loss = 0.00635409\n",
      "Iteration 4296, loss = 0.00635173\n",
      "Iteration 4297, loss = 0.00634952\n",
      "Iteration 4298, loss = 0.00634789\n",
      "Iteration 4299, loss = 0.00634622\n",
      "Iteration 4300, loss = 0.00634373\n",
      "Iteration 4301, loss = 0.00634152\n",
      "Iteration 4302, loss = 0.00633931\n",
      "Iteration 4303, loss = 0.00633739\n",
      "Iteration 4304, loss = 0.00633475\n",
      "Iteration 4305, loss = 0.00633263\n",
      "Iteration 4306, loss = 0.00633108\n",
      "Iteration 4307, loss = 0.00632822\n",
      "Iteration 4308, loss = 0.00632603\n",
      "Iteration 4309, loss = 0.00632423\n",
      "Iteration 4310, loss = 0.00632217\n",
      "Iteration 4311, loss = 0.00632025\n",
      "Iteration 4312, loss = 0.00631816\n",
      "Iteration 4313, loss = 0.00631591\n",
      "Iteration 4314, loss = 0.00631379\n",
      "Iteration 4315, loss = 0.00631157\n",
      "Iteration 4316, loss = 0.00630959\n",
      "Iteration 4317, loss = 0.00630740\n",
      "Iteration 4318, loss = 0.00630527\n",
      "Iteration 4319, loss = 0.00630285\n",
      "Iteration 4320, loss = 0.00630113\n",
      "Iteration 4321, loss = 0.00629880\n",
      "Iteration 4322, loss = 0.00629665\n",
      "Iteration 4323, loss = 0.00629482\n",
      "Iteration 4324, loss = 0.00629249\n",
      "Iteration 4325, loss = 0.00629078\n",
      "Iteration 4326, loss = 0.00628849\n",
      "Iteration 4327, loss = 0.00628581\n",
      "Iteration 4328, loss = 0.00628383\n",
      "Iteration 4329, loss = 0.00628191\n",
      "Iteration 4330, loss = 0.00627917\n",
      "Iteration 4331, loss = 0.00627742\n",
      "Iteration 4332, loss = 0.00627485\n",
      "Iteration 4333, loss = 0.00627273\n",
      "Iteration 4334, loss = 0.00627084\n",
      "Iteration 4335, loss = 0.00626854\n",
      "Iteration 4336, loss = 0.00626669\n",
      "Iteration 4337, loss = 0.00626401\n",
      "Iteration 4338, loss = 0.00626218\n",
      "Iteration 4339, loss = 0.00625948\n",
      "Iteration 4340, loss = 0.00625747\n",
      "Iteration 4341, loss = 0.00625500\n",
      "Iteration 4342, loss = 0.00625393\n",
      "Iteration 4343, loss = 0.00625087\n",
      "Iteration 4344, loss = 0.00624877\n",
      "Iteration 4345, loss = 0.00624651\n",
      "Iteration 4346, loss = 0.00624444\n",
      "Iteration 4347, loss = 0.00624276\n",
      "Iteration 4348, loss = 0.00624025\n",
      "Iteration 4349, loss = 0.00623831\n",
      "Iteration 4350, loss = 0.00623626\n",
      "Iteration 4351, loss = 0.00623398\n",
      "Iteration 4352, loss = 0.00623198\n",
      "Iteration 4353, loss = 0.00623029\n",
      "Iteration 4354, loss = 0.00622815\n",
      "Iteration 4355, loss = 0.00622629\n",
      "Iteration 4356, loss = 0.00622481\n",
      "Iteration 4357, loss = 0.00622236\n",
      "Iteration 4358, loss = 0.00622068\n",
      "Iteration 4359, loss = 0.00621852\n",
      "Iteration 4360, loss = 0.00621632\n",
      "Iteration 4361, loss = 0.00621452\n",
      "Iteration 4362, loss = 0.00621237\n",
      "Iteration 4363, loss = 0.00621070\n",
      "Iteration 4364, loss = 0.00620858\n",
      "Iteration 4365, loss = 0.00620668\n",
      "Iteration 4366, loss = 0.00620452\n",
      "Iteration 4367, loss = 0.00620287\n",
      "Iteration 4368, loss = 0.00620092\n",
      "Iteration 4369, loss = 0.00619888\n",
      "Iteration 4370, loss = 0.00619711\n",
      "Iteration 4371, loss = 0.00619555\n",
      "Iteration 4372, loss = 0.00619344\n",
      "Iteration 4373, loss = 0.00619154\n",
      "Iteration 4374, loss = 0.00619035\n",
      "Iteration 4375, loss = 0.00618800\n",
      "Iteration 4376, loss = 0.00618597\n",
      "Iteration 4377, loss = 0.00618433\n",
      "Iteration 4378, loss = 0.00618268\n",
      "Iteration 4379, loss = 0.00618071\n",
      "Iteration 4380, loss = 0.00617846\n",
      "Iteration 4381, loss = 0.00617659\n",
      "Iteration 4382, loss = 0.00617427\n",
      "Iteration 4383, loss = 0.00617239\n",
      "Iteration 4384, loss = 0.00617089\n",
      "Iteration 4385, loss = 0.00616827\n",
      "Iteration 4386, loss = 0.00616661\n",
      "Iteration 4387, loss = 0.00616445\n",
      "Iteration 4388, loss = 0.00616283\n",
      "Iteration 4389, loss = 0.00616086\n",
      "Iteration 4390, loss = 0.00615987\n",
      "Iteration 4391, loss = 0.00615694\n",
      "Iteration 4392, loss = 0.00615501\n",
      "Iteration 4393, loss = 0.00615305\n",
      "Iteration 4394, loss = 0.00615121\n",
      "Iteration 4395, loss = 0.00614973\n",
      "Iteration 4396, loss = 0.00614701\n",
      "Iteration 4397, loss = 0.00614531\n",
      "Iteration 4398, loss = 0.00614322\n",
      "Iteration 4399, loss = 0.00614084\n",
      "Iteration 4400, loss = 0.00613870\n",
      "Iteration 4401, loss = 0.00613727\n",
      "Iteration 4402, loss = 0.00613531\n",
      "Iteration 4403, loss = 0.00613302\n",
      "Iteration 4404, loss = 0.00613135\n",
      "Iteration 4405, loss = 0.00612955\n",
      "Iteration 4406, loss = 0.00612712\n",
      "Iteration 4407, loss = 0.00612522\n",
      "Iteration 4408, loss = 0.00612315\n",
      "Iteration 4409, loss = 0.00612147\n",
      "Iteration 4410, loss = 0.00611943\n",
      "Iteration 4411, loss = 0.00611748\n",
      "Iteration 4412, loss = 0.00611554\n",
      "Iteration 4413, loss = 0.00611350\n",
      "Iteration 4414, loss = 0.00611168\n",
      "Iteration 4415, loss = 0.00611010\n",
      "Iteration 4416, loss = 0.00610795\n",
      "Iteration 4417, loss = 0.00610659\n",
      "Iteration 4418, loss = 0.00610405\n",
      "Iteration 4419, loss = 0.00610226\n",
      "Iteration 4420, loss = 0.00610018\n",
      "Iteration 4421, loss = 0.00609830\n",
      "Iteration 4422, loss = 0.00609639\n",
      "Iteration 4423, loss = 0.00609461\n",
      "Iteration 4424, loss = 0.00609265\n",
      "Iteration 4425, loss = 0.00609061\n",
      "Iteration 4426, loss = 0.00608877\n",
      "Iteration 4427, loss = 0.00608676\n",
      "Iteration 4428, loss = 0.00608503\n",
      "Iteration 4429, loss = 0.00608331\n",
      "Iteration 4430, loss = 0.00608129\n",
      "Iteration 4431, loss = 0.00607969\n",
      "Iteration 4432, loss = 0.00607786\n",
      "Iteration 4433, loss = 0.00607616\n",
      "Iteration 4434, loss = 0.00607430\n",
      "Iteration 4435, loss = 0.00607253\n",
      "Iteration 4436, loss = 0.00607083\n",
      "Iteration 4437, loss = 0.00606873\n",
      "Iteration 4438, loss = 0.00606708\n",
      "Iteration 4439, loss = 0.00606496\n",
      "Iteration 4440, loss = 0.00606334\n",
      "Iteration 4441, loss = 0.00606243\n",
      "Iteration 4442, loss = 0.00605942\n",
      "Iteration 4443, loss = 0.00605758\n",
      "Iteration 4444, loss = 0.00605565\n",
      "Iteration 4445, loss = 0.00605477\n",
      "Iteration 4446, loss = 0.00605221\n",
      "Iteration 4447, loss = 0.00605024\n",
      "Iteration 4448, loss = 0.00604801\n",
      "Iteration 4449, loss = 0.00604598\n",
      "Iteration 4450, loss = 0.00604402\n",
      "Iteration 4451, loss = 0.00604224\n",
      "Iteration 4452, loss = 0.00604011\n",
      "Iteration 4453, loss = 0.00603804\n",
      "Iteration 4454, loss = 0.00603617\n",
      "Iteration 4455, loss = 0.00603447\n",
      "Iteration 4456, loss = 0.00603234\n",
      "Iteration 4457, loss = 0.00603052\n",
      "Iteration 4458, loss = 0.00602877\n",
      "Iteration 4459, loss = 0.00602717\n",
      "Iteration 4460, loss = 0.00602490\n",
      "Iteration 4461, loss = 0.00602317\n",
      "Iteration 4462, loss = 0.00602104\n",
      "Iteration 4463, loss = 0.00601914\n",
      "Iteration 4464, loss = 0.00601741\n",
      "Iteration 4465, loss = 0.00601565\n",
      "Iteration 4466, loss = 0.00601434\n",
      "Iteration 4467, loss = 0.00601225\n",
      "Iteration 4468, loss = 0.00601062\n",
      "Iteration 4469, loss = 0.00600896\n",
      "Iteration 4470, loss = 0.00600704\n",
      "Iteration 4471, loss = 0.00600534\n",
      "Iteration 4472, loss = 0.00600344\n",
      "Iteration 4473, loss = 0.00600151\n",
      "Iteration 4474, loss = 0.00599979\n",
      "Iteration 4475, loss = 0.00599764\n",
      "Iteration 4476, loss = 0.00599560\n",
      "Iteration 4477, loss = 0.00599405\n",
      "Iteration 4478, loss = 0.00599169\n",
      "Iteration 4479, loss = 0.00598988\n",
      "Iteration 4480, loss = 0.00598849\n",
      "Iteration 4481, loss = 0.00598600\n",
      "Iteration 4482, loss = 0.00598408\n",
      "Iteration 4483, loss = 0.00598211\n",
      "Iteration 4484, loss = 0.00597978\n",
      "Iteration 4485, loss = 0.00597774\n",
      "Iteration 4486, loss = 0.00597677\n",
      "Iteration 4487, loss = 0.00597422\n",
      "Iteration 4488, loss = 0.00597235\n",
      "Iteration 4489, loss = 0.00597032\n",
      "Iteration 4490, loss = 0.00596871\n",
      "Iteration 4491, loss = 0.00596657\n",
      "Iteration 4492, loss = 0.00596459\n",
      "Iteration 4493, loss = 0.00596259\n",
      "Iteration 4494, loss = 0.00596077\n",
      "Iteration 4495, loss = 0.00595867\n",
      "Iteration 4496, loss = 0.00595683\n",
      "Iteration 4497, loss = 0.00595478\n",
      "Iteration 4498, loss = 0.00595293\n",
      "Iteration 4499, loss = 0.00595102\n",
      "Iteration 4500, loss = 0.00594950\n",
      "Iteration 4501, loss = 0.00594740\n",
      "Iteration 4502, loss = 0.00594572\n",
      "Iteration 4503, loss = 0.00594392\n",
      "Iteration 4504, loss = 0.00594233\n",
      "Iteration 4505, loss = 0.00594034\n",
      "Iteration 4506, loss = 0.00593848\n",
      "Iteration 4507, loss = 0.00593673\n",
      "Iteration 4508, loss = 0.00593547\n",
      "Iteration 4509, loss = 0.00593330\n",
      "Iteration 4510, loss = 0.00593181\n",
      "Iteration 4511, loss = 0.00592976\n",
      "Iteration 4512, loss = 0.00592813\n",
      "Iteration 4513, loss = 0.00592590\n",
      "Iteration 4514, loss = 0.00592401\n",
      "Iteration 4515, loss = 0.00592221\n",
      "Iteration 4516, loss = 0.00591963\n",
      "Iteration 4517, loss = 0.00591740\n",
      "Iteration 4518, loss = 0.00591554\n",
      "Iteration 4519, loss = 0.00591339\n",
      "Iteration 4520, loss = 0.00591254\n",
      "Iteration 4521, loss = 0.00591026\n",
      "Iteration 4522, loss = 0.00590787\n",
      "Iteration 4523, loss = 0.00590590\n",
      "Iteration 4524, loss = 0.00590412\n",
      "Iteration 4525, loss = 0.00590216\n",
      "Iteration 4526, loss = 0.00590031\n",
      "Iteration 4527, loss = 0.00589872\n",
      "Iteration 4528, loss = 0.00589658\n",
      "Iteration 4529, loss = 0.00589500\n",
      "Iteration 4530, loss = 0.00589314\n",
      "Iteration 4531, loss = 0.00589100\n",
      "Iteration 4532, loss = 0.00588927\n",
      "Iteration 4533, loss = 0.00588746\n",
      "Iteration 4534, loss = 0.00588635\n",
      "Iteration 4535, loss = 0.00588425\n",
      "Iteration 4536, loss = 0.00588304\n",
      "Iteration 4537, loss = 0.00588045\n",
      "Iteration 4538, loss = 0.00587863\n",
      "Iteration 4539, loss = 0.00587655\n",
      "Iteration 4540, loss = 0.00587484\n",
      "Iteration 4541, loss = 0.00587379\n",
      "Iteration 4542, loss = 0.00587138\n",
      "Iteration 4543, loss = 0.00586981\n",
      "Iteration 4544, loss = 0.00586774\n",
      "Iteration 4545, loss = 0.00586596\n",
      "Iteration 4546, loss = 0.00586429\n",
      "Iteration 4547, loss = 0.00586255\n",
      "Iteration 4548, loss = 0.00586063\n",
      "Iteration 4549, loss = 0.00585887\n",
      "Iteration 4550, loss = 0.00585695\n",
      "Iteration 4551, loss = 0.00585496\n",
      "Iteration 4552, loss = 0.00585322\n",
      "Iteration 4553, loss = 0.00585142\n",
      "Iteration 4554, loss = 0.00584937\n",
      "Iteration 4555, loss = 0.00584740\n",
      "Iteration 4556, loss = 0.00584587\n",
      "Iteration 4557, loss = 0.00584366\n",
      "Iteration 4558, loss = 0.00584210\n",
      "Iteration 4559, loss = 0.00584043\n",
      "Iteration 4560, loss = 0.00583823\n",
      "Iteration 4561, loss = 0.00583625\n",
      "Iteration 4562, loss = 0.00583413\n",
      "Iteration 4563, loss = 0.00583237\n",
      "Iteration 4564, loss = 0.00583024\n",
      "Iteration 4565, loss = 0.00582836\n",
      "Iteration 4566, loss = 0.00582689\n",
      "Iteration 4567, loss = 0.00582474\n",
      "Iteration 4568, loss = 0.00582260\n",
      "Iteration 4569, loss = 0.00582128\n",
      "Iteration 4570, loss = 0.00581882\n",
      "Iteration 4571, loss = 0.00581730\n",
      "Iteration 4572, loss = 0.00581509\n",
      "Iteration 4573, loss = 0.00581320\n",
      "Iteration 4574, loss = 0.00581130\n",
      "Iteration 4575, loss = 0.00580931\n",
      "Iteration 4576, loss = 0.00580793\n",
      "Iteration 4577, loss = 0.00580557\n",
      "Iteration 4578, loss = 0.00580410\n",
      "Iteration 4579, loss = 0.00580222\n",
      "Iteration 4580, loss = 0.00579982\n",
      "Iteration 4581, loss = 0.00579831\n",
      "Iteration 4582, loss = 0.00579597\n",
      "Iteration 4583, loss = 0.00579486\n",
      "Iteration 4584, loss = 0.00579258\n",
      "Iteration 4585, loss = 0.00579070\n",
      "Iteration 4586, loss = 0.00578939\n",
      "Iteration 4587, loss = 0.00578696\n",
      "Iteration 4588, loss = 0.00578543\n",
      "Iteration 4589, loss = 0.00578334\n",
      "Iteration 4590, loss = 0.00578172\n",
      "Iteration 4591, loss = 0.00577974\n",
      "Iteration 4592, loss = 0.00577797\n",
      "Iteration 4593, loss = 0.00577630\n",
      "Iteration 4594, loss = 0.00577435\n",
      "Iteration 4595, loss = 0.00577284\n",
      "Iteration 4596, loss = 0.00577127\n",
      "Iteration 4597, loss = 0.00576902\n",
      "Iteration 4598, loss = 0.00576724\n",
      "Iteration 4599, loss = 0.00576566\n",
      "Iteration 4600, loss = 0.00576335\n",
      "Iteration 4601, loss = 0.00576162\n",
      "Iteration 4602, loss = 0.00575981\n",
      "Iteration 4603, loss = 0.00575800\n",
      "Iteration 4604, loss = 0.00575651\n",
      "Iteration 4605, loss = 0.00575503\n",
      "Iteration 4606, loss = 0.00575334\n",
      "Iteration 4607, loss = 0.00575157\n",
      "Iteration 4608, loss = 0.00574986\n",
      "Iteration 4609, loss = 0.00574845\n",
      "Iteration 4610, loss = 0.00574665\n",
      "Iteration 4611, loss = 0.00574479\n",
      "Iteration 4612, loss = 0.00574331\n",
      "Iteration 4613, loss = 0.00574140\n",
      "Iteration 4614, loss = 0.00573942\n",
      "Iteration 4615, loss = 0.00573799\n",
      "Iteration 4616, loss = 0.00573578\n",
      "Iteration 4617, loss = 0.00573421\n",
      "Iteration 4618, loss = 0.00573251\n",
      "Iteration 4619, loss = 0.00573037\n",
      "Iteration 4620, loss = 0.00572886\n",
      "Iteration 4621, loss = 0.00572690\n",
      "Iteration 4622, loss = 0.00572510\n",
      "Iteration 4623, loss = 0.00572321\n",
      "Iteration 4624, loss = 0.00572156\n",
      "Iteration 4625, loss = 0.00571958\n",
      "Iteration 4626, loss = 0.00571811\n",
      "Iteration 4627, loss = 0.00571631\n",
      "Iteration 4628, loss = 0.00571453\n",
      "Iteration 4629, loss = 0.00571292\n",
      "Iteration 4630, loss = 0.00571139\n",
      "Iteration 4631, loss = 0.00570937\n",
      "Iteration 4632, loss = 0.00570796\n",
      "Iteration 4633, loss = 0.00570591\n",
      "Iteration 4634, loss = 0.00570455\n",
      "Iteration 4635, loss = 0.00570227\n",
      "Iteration 4636, loss = 0.00570022\n",
      "Iteration 4637, loss = 0.00569850\n",
      "Iteration 4638, loss = 0.00569643\n",
      "Iteration 4639, loss = 0.00569496\n",
      "Iteration 4640, loss = 0.00569344\n",
      "Iteration 4641, loss = 0.00569162\n",
      "Iteration 4642, loss = 0.00568958\n",
      "Iteration 4643, loss = 0.00568770\n",
      "Iteration 4644, loss = 0.00568609\n",
      "Iteration 4645, loss = 0.00568433\n",
      "Iteration 4646, loss = 0.00568241\n",
      "Iteration 4647, loss = 0.00568102\n",
      "Iteration 4648, loss = 0.00567924\n",
      "Iteration 4649, loss = 0.00567757\n",
      "Iteration 4650, loss = 0.00567575\n",
      "Iteration 4651, loss = 0.00567411\n",
      "Iteration 4652, loss = 0.00567197\n",
      "Iteration 4653, loss = 0.00567101\n",
      "Iteration 4654, loss = 0.00566953\n",
      "Iteration 4655, loss = 0.00566717\n",
      "Iteration 4656, loss = 0.00566533\n",
      "Iteration 4657, loss = 0.00566358\n",
      "Iteration 4658, loss = 0.00566157\n",
      "Iteration 4659, loss = 0.00566006\n",
      "Iteration 4660, loss = 0.00565802\n",
      "Iteration 4661, loss = 0.00565636\n",
      "Iteration 4662, loss = 0.00565481\n",
      "Iteration 4663, loss = 0.00565278\n",
      "Iteration 4664, loss = 0.00565101\n",
      "Iteration 4665, loss = 0.00564935\n",
      "Iteration 4666, loss = 0.00564755\n",
      "Iteration 4667, loss = 0.00564583\n",
      "Iteration 4668, loss = 0.00564427\n",
      "Iteration 4669, loss = 0.00564266\n",
      "Iteration 4670, loss = 0.00564084\n",
      "Iteration 4671, loss = 0.00563896\n",
      "Iteration 4672, loss = 0.00563847\n",
      "Iteration 4673, loss = 0.00563555\n",
      "Iteration 4674, loss = 0.00563383\n",
      "Iteration 4675, loss = 0.00563190\n",
      "Iteration 4676, loss = 0.00563011\n",
      "Iteration 4677, loss = 0.00562851\n",
      "Iteration 4678, loss = 0.00562676\n",
      "Iteration 4679, loss = 0.00562499\n",
      "Iteration 4680, loss = 0.00562354\n",
      "Iteration 4681, loss = 0.00562163\n",
      "Iteration 4682, loss = 0.00561992\n",
      "Iteration 4683, loss = 0.00561834\n",
      "Iteration 4684, loss = 0.00561681\n",
      "Iteration 4685, loss = 0.00561495\n",
      "Iteration 4686, loss = 0.00561327\n",
      "Iteration 4687, loss = 0.00561147\n",
      "Iteration 4688, loss = 0.00560981\n",
      "Iteration 4689, loss = 0.00560840\n",
      "Iteration 4690, loss = 0.00560696\n",
      "Iteration 4691, loss = 0.00560506\n",
      "Iteration 4692, loss = 0.00560333\n",
      "Iteration 4693, loss = 0.00560175\n",
      "Iteration 4694, loss = 0.00560004\n",
      "Iteration 4695, loss = 0.00559834\n",
      "Iteration 4696, loss = 0.00559713\n",
      "Iteration 4697, loss = 0.00559522\n",
      "Iteration 4698, loss = 0.00559368\n",
      "Iteration 4699, loss = 0.00559243\n",
      "Iteration 4700, loss = 0.00559029\n",
      "Iteration 4701, loss = 0.00558881\n",
      "Iteration 4702, loss = 0.00558699\n",
      "Iteration 4703, loss = 0.00558533\n",
      "Iteration 4704, loss = 0.00558365\n",
      "Iteration 4705, loss = 0.00558179\n",
      "Iteration 4706, loss = 0.00558069\n",
      "Iteration 4707, loss = 0.00557866\n",
      "Iteration 4708, loss = 0.00557785\n",
      "Iteration 4709, loss = 0.00557569\n",
      "Iteration 4710, loss = 0.00557415\n",
      "Iteration 4711, loss = 0.00557281\n",
      "Iteration 4712, loss = 0.00557117\n",
      "Iteration 4713, loss = 0.00556968\n",
      "Iteration 4714, loss = 0.00556825\n",
      "Iteration 4715, loss = 0.00556684\n",
      "Iteration 4716, loss = 0.00556521\n",
      "Iteration 4717, loss = 0.00556366\n",
      "Iteration 4718, loss = 0.00556274\n",
      "Iteration 4719, loss = 0.00556038\n",
      "Iteration 4720, loss = 0.00555884\n",
      "Iteration 4721, loss = 0.00555727\n",
      "Iteration 4722, loss = 0.00555545\n",
      "Iteration 4723, loss = 0.00555389\n",
      "Iteration 4724, loss = 0.00555183\n",
      "Iteration 4725, loss = 0.00555015\n",
      "Iteration 4726, loss = 0.00554848\n",
      "Iteration 4727, loss = 0.00554700\n",
      "Iteration 4728, loss = 0.00554540\n",
      "Iteration 4729, loss = 0.00554361\n",
      "Iteration 4730, loss = 0.00554190\n",
      "Iteration 4731, loss = 0.00554069\n",
      "Iteration 4732, loss = 0.00553897\n",
      "Iteration 4733, loss = 0.00553740\n",
      "Iteration 4734, loss = 0.00553609\n",
      "Iteration 4735, loss = 0.00553489\n",
      "Iteration 4736, loss = 0.00553336\n",
      "Iteration 4737, loss = 0.00553181\n",
      "Iteration 4738, loss = 0.00553033\n",
      "Iteration 4739, loss = 0.00552884\n",
      "Iteration 4740, loss = 0.00552786\n",
      "Iteration 4741, loss = 0.00552612\n",
      "Iteration 4742, loss = 0.00552451\n",
      "Iteration 4743, loss = 0.00552318\n",
      "Iteration 4744, loss = 0.00552180\n",
      "Iteration 4745, loss = 0.00552049\n",
      "Iteration 4746, loss = 0.00551892\n",
      "Iteration 4747, loss = 0.00551746\n",
      "Iteration 4748, loss = 0.00551617\n",
      "Iteration 4749, loss = 0.00551467\n",
      "Iteration 4750, loss = 0.00551329\n",
      "Iteration 4751, loss = 0.00551093\n",
      "Iteration 4752, loss = 0.00550954\n",
      "Iteration 4753, loss = 0.00550723\n",
      "Iteration 4754, loss = 0.00550592\n",
      "Iteration 4755, loss = 0.00550398\n",
      "Iteration 4756, loss = 0.00550230\n",
      "Iteration 4757, loss = 0.00550050\n",
      "Iteration 4758, loss = 0.00549922\n",
      "Iteration 4759, loss = 0.00549717\n",
      "Iteration 4760, loss = 0.00549558\n",
      "Iteration 4761, loss = 0.00549408\n",
      "Iteration 4762, loss = 0.00549252\n",
      "Iteration 4763, loss = 0.00549085\n",
      "Iteration 4764, loss = 0.00548911\n",
      "Iteration 4765, loss = 0.00548760\n",
      "Iteration 4766, loss = 0.00548583\n",
      "Iteration 4767, loss = 0.00548390\n",
      "Iteration 4768, loss = 0.00548205\n",
      "Iteration 4769, loss = 0.00548014\n",
      "Iteration 4770, loss = 0.00547891\n",
      "Iteration 4771, loss = 0.00547668\n",
      "Iteration 4772, loss = 0.00547536\n",
      "Iteration 4773, loss = 0.00547349\n",
      "Iteration 4774, loss = 0.00547200\n",
      "Iteration 4775, loss = 0.00547023\n",
      "Iteration 4776, loss = 0.00546870\n",
      "Iteration 4777, loss = 0.00546691\n",
      "Iteration 4778, loss = 0.00546508\n",
      "Iteration 4779, loss = 0.00546340\n",
      "Iteration 4780, loss = 0.00546215\n",
      "Iteration 4781, loss = 0.00546043\n",
      "Iteration 4782, loss = 0.00545903\n",
      "Iteration 4783, loss = 0.00545708\n",
      "Iteration 4784, loss = 0.00545600\n",
      "Iteration 4785, loss = 0.00545407\n",
      "Iteration 4786, loss = 0.00545229\n",
      "Iteration 4787, loss = 0.00545081\n",
      "Iteration 4788, loss = 0.00544896\n",
      "Iteration 4789, loss = 0.00544740\n",
      "Iteration 4790, loss = 0.00544581\n",
      "Iteration 4791, loss = 0.00544374\n",
      "Iteration 4792, loss = 0.00544182\n",
      "Iteration 4793, loss = 0.00544024\n",
      "Iteration 4794, loss = 0.00543853\n",
      "Iteration 4795, loss = 0.00543662\n",
      "Iteration 4796, loss = 0.00543535\n",
      "Iteration 4797, loss = 0.00543347\n",
      "Iteration 4798, loss = 0.00543169\n",
      "Iteration 4799, loss = 0.00542993\n",
      "Iteration 4800, loss = 0.00542821\n",
      "Iteration 4801, loss = 0.00542677\n",
      "Iteration 4802, loss = 0.00542518\n",
      "Iteration 4803, loss = 0.00542349\n",
      "Iteration 4804, loss = 0.00542182\n",
      "Iteration 4805, loss = 0.00542032\n",
      "Iteration 4806, loss = 0.00541849\n",
      "Iteration 4807, loss = 0.00541707\n",
      "Iteration 4808, loss = 0.00541545\n",
      "Iteration 4809, loss = 0.00541379\n",
      "Iteration 4810, loss = 0.00541215\n",
      "Iteration 4811, loss = 0.00541066\n",
      "Iteration 4812, loss = 0.00540891\n",
      "Iteration 4813, loss = 0.00540742\n",
      "Iteration 4814, loss = 0.00540721\n",
      "Iteration 4815, loss = 0.00540438\n",
      "Iteration 4816, loss = 0.00540263\n",
      "Iteration 4817, loss = 0.00540080\n",
      "Iteration 4818, loss = 0.00539903\n",
      "Iteration 4819, loss = 0.00539715\n",
      "Iteration 4820, loss = 0.00539632\n",
      "Iteration 4821, loss = 0.00539419\n",
      "Iteration 4822, loss = 0.00539256\n",
      "Iteration 4823, loss = 0.00539070\n",
      "Iteration 4824, loss = 0.00538900\n",
      "Iteration 4825, loss = 0.00538759\n",
      "Iteration 4826, loss = 0.00538593\n",
      "Iteration 4827, loss = 0.00538448\n",
      "Iteration 4828, loss = 0.00538250\n",
      "Iteration 4829, loss = 0.00538101\n",
      "Iteration 4830, loss = 0.00537940\n",
      "Iteration 4831, loss = 0.00537767\n",
      "Iteration 4832, loss = 0.00537579\n",
      "Iteration 4833, loss = 0.00537419\n",
      "Iteration 4834, loss = 0.00537265\n",
      "Iteration 4835, loss = 0.00537088\n",
      "Iteration 4836, loss = 0.00536970\n",
      "Iteration 4837, loss = 0.00536786\n",
      "Iteration 4838, loss = 0.00536602\n",
      "Iteration 4839, loss = 0.00536430\n",
      "Iteration 4840, loss = 0.00536312\n",
      "Iteration 4841, loss = 0.00536129\n",
      "Iteration 4842, loss = 0.00535987\n",
      "Iteration 4843, loss = 0.00535825\n",
      "Iteration 4844, loss = 0.00535695\n",
      "Iteration 4845, loss = 0.00535545\n",
      "Iteration 4846, loss = 0.00535391\n",
      "Iteration 4847, loss = 0.00535210\n",
      "Iteration 4848, loss = 0.00535057\n",
      "Iteration 4849, loss = 0.00534897\n",
      "Iteration 4850, loss = 0.00534730\n",
      "Iteration 4851, loss = 0.00534573\n",
      "Iteration 4852, loss = 0.00534440\n",
      "Iteration 4853, loss = 0.00534277\n",
      "Iteration 4854, loss = 0.00534104\n",
      "Iteration 4855, loss = 0.00533970\n",
      "Iteration 4856, loss = 0.00533793\n",
      "Iteration 4857, loss = 0.00533673\n",
      "Iteration 4858, loss = 0.00533457\n",
      "Iteration 4859, loss = 0.00533273\n",
      "Iteration 4860, loss = 0.00533116\n",
      "Iteration 4861, loss = 0.00532967\n",
      "Iteration 4862, loss = 0.00532796\n",
      "Iteration 4863, loss = 0.00532646\n",
      "Iteration 4864, loss = 0.00532483\n",
      "Iteration 4865, loss = 0.00532329\n",
      "Iteration 4866, loss = 0.00532176\n",
      "Iteration 4867, loss = 0.00532034\n",
      "Iteration 4868, loss = 0.00531850\n",
      "Iteration 4869, loss = 0.00531748\n",
      "Iteration 4870, loss = 0.00531580\n",
      "Iteration 4871, loss = 0.00531493\n",
      "Iteration 4872, loss = 0.00531360\n",
      "Iteration 4873, loss = 0.00531259\n",
      "Iteration 4874, loss = 0.00531135\n",
      "Iteration 4875, loss = 0.00530961\n",
      "Iteration 4876, loss = 0.00530821\n",
      "Iteration 4877, loss = 0.00530652\n",
      "Iteration 4878, loss = 0.00530521\n",
      "Iteration 4879, loss = 0.00530358\n",
      "Iteration 4880, loss = 0.00530201\n",
      "Iteration 4881, loss = 0.00530126\n",
      "Iteration 4882, loss = 0.00529936\n",
      "Iteration 4883, loss = 0.00529813\n",
      "Iteration 4884, loss = 0.00529675\n",
      "Iteration 4885, loss = 0.00529535\n",
      "Iteration 4886, loss = 0.00529408\n",
      "Iteration 4887, loss = 0.00529248\n",
      "Iteration 4888, loss = 0.00529136\n",
      "Iteration 4889, loss = 0.00528953\n",
      "Iteration 4890, loss = 0.00528807\n",
      "Iteration 4891, loss = 0.00528638\n",
      "Iteration 4892, loss = 0.00528461\n",
      "Iteration 4893, loss = 0.00528264\n",
      "Iteration 4894, loss = 0.00528123\n",
      "Iteration 4895, loss = 0.00527941\n",
      "Iteration 4896, loss = 0.00527800\n",
      "Iteration 4897, loss = 0.00527637\n",
      "Iteration 4898, loss = 0.00527482\n",
      "Iteration 4899, loss = 0.00527330\n",
      "Iteration 4900, loss = 0.00527184\n",
      "Iteration 4901, loss = 0.00527014\n",
      "Iteration 4902, loss = 0.00526893\n",
      "Iteration 4903, loss = 0.00526725\n",
      "Iteration 4904, loss = 0.00526568\n",
      "Iteration 4905, loss = 0.00526427\n",
      "Iteration 4906, loss = 0.00526295\n",
      "Iteration 4907, loss = 0.00526102\n",
      "Iteration 4908, loss = 0.00525924\n",
      "Iteration 4909, loss = 0.00525761\n",
      "Iteration 4910, loss = 0.00525602\n",
      "Iteration 4911, loss = 0.00525437\n",
      "Iteration 4912, loss = 0.00525324\n",
      "Iteration 4913, loss = 0.00525135\n",
      "Iteration 4914, loss = 0.00524988\n",
      "Iteration 4915, loss = 0.00524856\n",
      "Iteration 4916, loss = 0.00524707\n",
      "Iteration 4917, loss = 0.00524497\n",
      "Iteration 4918, loss = 0.00524355\n",
      "Iteration 4919, loss = 0.00524215\n",
      "Iteration 4920, loss = 0.00524073\n",
      "Iteration 4921, loss = 0.00523992\n",
      "Iteration 4922, loss = 0.00523800\n",
      "Iteration 4923, loss = 0.00523626\n",
      "Iteration 4924, loss = 0.00523482\n",
      "Iteration 4925, loss = 0.00523390\n",
      "Iteration 4926, loss = 0.00523215\n",
      "Iteration 4927, loss = 0.00523056\n",
      "Iteration 4928, loss = 0.00522917\n",
      "Iteration 4929, loss = 0.00522768\n",
      "Iteration 4930, loss = 0.00522625\n",
      "Iteration 4931, loss = 0.00522476\n",
      "Iteration 4932, loss = 0.00522319\n",
      "Iteration 4933, loss = 0.00522190\n",
      "Iteration 4934, loss = 0.00522049\n",
      "Iteration 4935, loss = 0.00521894\n",
      "Iteration 4936, loss = 0.00521724\n",
      "Iteration 4937, loss = 0.00521699\n",
      "Iteration 4938, loss = 0.00521447\n",
      "Iteration 4939, loss = 0.00521295\n",
      "Iteration 4940, loss = 0.00521116\n",
      "Iteration 4941, loss = 0.00520946\n",
      "Iteration 4942, loss = 0.00520811\n",
      "Iteration 4943, loss = 0.00520627\n",
      "Iteration 4944, loss = 0.00520535\n",
      "Iteration 4945, loss = 0.00520318\n",
      "Iteration 4946, loss = 0.00520184\n",
      "Iteration 4947, loss = 0.00520056\n",
      "Iteration 4948, loss = 0.00519902\n",
      "Iteration 4949, loss = 0.00519797\n",
      "Iteration 4950, loss = 0.00519636\n",
      "Iteration 4951, loss = 0.00519487\n",
      "Iteration 4952, loss = 0.00519331\n",
      "Iteration 4953, loss = 0.00519168\n",
      "Iteration 4954, loss = 0.00519010\n",
      "Iteration 4955, loss = 0.00518875\n",
      "Iteration 4956, loss = 0.00518742\n",
      "Iteration 4957, loss = 0.00518552\n",
      "Iteration 4958, loss = 0.00518401\n",
      "Iteration 4959, loss = 0.00518232\n",
      "Iteration 4960, loss = 0.00518090\n",
      "Iteration 4961, loss = 0.00517929\n",
      "Iteration 4962, loss = 0.00517775\n",
      "Iteration 4963, loss = 0.00517617\n",
      "Iteration 4964, loss = 0.00517468\n",
      "Iteration 4965, loss = 0.00517334\n",
      "Iteration 4966, loss = 0.00517166\n",
      "Iteration 4967, loss = 0.00517003\n",
      "Iteration 4968, loss = 0.00516827\n",
      "Iteration 4969, loss = 0.00516673\n",
      "Iteration 4970, loss = 0.00516481\n",
      "Iteration 4971, loss = 0.00516403\n",
      "Iteration 4972, loss = 0.00516178\n",
      "Iteration 4973, loss = 0.00516080\n",
      "Iteration 4974, loss = 0.00515876\n",
      "Iteration 4975, loss = 0.00515717\n",
      "Iteration 4976, loss = 0.00515565\n",
      "Iteration 4977, loss = 0.00515440\n",
      "Iteration 4978, loss = 0.00515266\n",
      "Iteration 4979, loss = 0.00515122\n",
      "Iteration 4980, loss = 0.00514980\n",
      "Iteration 4981, loss = 0.00514836\n",
      "Iteration 4982, loss = 0.00514736\n",
      "Iteration 4983, loss = 0.00514586\n",
      "Iteration 4984, loss = 0.00514419\n",
      "Iteration 4985, loss = 0.00514258\n",
      "Iteration 4986, loss = 0.00514109\n",
      "Iteration 4987, loss = 0.00513972\n",
      "Iteration 4988, loss = 0.00513799\n",
      "Iteration 4989, loss = 0.00513655\n",
      "Iteration 4990, loss = 0.00513489\n",
      "Iteration 4991, loss = 0.00513360\n",
      "Iteration 4992, loss = 0.00513182\n",
      "Iteration 4993, loss = 0.00513037\n",
      "Iteration 4994, loss = 0.00512896\n",
      "Iteration 4995, loss = 0.00512714\n",
      "Iteration 4996, loss = 0.00512571\n",
      "Iteration 4997, loss = 0.00512425\n",
      "Iteration 4998, loss = 0.00512276\n",
      "Iteration 4999, loss = 0.00512148\n",
      "Iteration 5000, loss = 0.00511985\n",
      "Iteration 5001, loss = 0.00511829\n",
      "Iteration 5002, loss = 0.00511688\n",
      "Iteration 5003, loss = 0.00511558\n",
      "Iteration 5004, loss = 0.00511422\n",
      "Iteration 5005, loss = 0.00511277\n",
      "Iteration 5006, loss = 0.00511207\n",
      "Iteration 5007, loss = 0.00511010\n",
      "Iteration 5008, loss = 0.00510864\n",
      "Iteration 5009, loss = 0.00510720\n",
      "Iteration 5010, loss = 0.00510595\n",
      "Iteration 5011, loss = 0.00510446\n",
      "Iteration 5012, loss = 0.00510319\n",
      "Iteration 5013, loss = 0.00510179\n",
      "Iteration 5014, loss = 0.00510075\n",
      "Iteration 5015, loss = 0.00509879\n",
      "Iteration 5016, loss = 0.00509754\n",
      "Iteration 5017, loss = 0.00509603\n",
      "Iteration 5018, loss = 0.00509461\n",
      "Iteration 5019, loss = 0.00509324\n",
      "Iteration 5020, loss = 0.00509189\n",
      "Iteration 5021, loss = 0.00509073\n",
      "Iteration 5022, loss = 0.00508927\n",
      "Iteration 5023, loss = 0.00508801\n",
      "Iteration 5024, loss = 0.00508670\n",
      "Iteration 5025, loss = 0.00508545\n",
      "Iteration 5026, loss = 0.00508416\n",
      "Iteration 5027, loss = 0.00508282\n",
      "Iteration 5028, loss = 0.00508185\n",
      "Iteration 5029, loss = 0.00508049\n",
      "Iteration 5030, loss = 0.00507886\n",
      "Iteration 5031, loss = 0.00507772\n",
      "Iteration 5032, loss = 0.00507642\n",
      "Iteration 5033, loss = 0.00507493\n",
      "Iteration 5034, loss = 0.00507367\n",
      "Iteration 5035, loss = 0.00507240\n",
      "Iteration 5036, loss = 0.00507104\n",
      "Iteration 5037, loss = 0.00506982\n",
      "Iteration 5038, loss = 0.00506839\n",
      "Iteration 5039, loss = 0.00506723\n",
      "Iteration 5040, loss = 0.00506573\n",
      "Iteration 5041, loss = 0.00506449\n",
      "Iteration 5042, loss = 0.00506302\n",
      "Iteration 5043, loss = 0.00506187\n",
      "Iteration 5044, loss = 0.00506051\n",
      "Iteration 5045, loss = 0.00505913\n",
      "Iteration 5046, loss = 0.00505778\n",
      "Iteration 5047, loss = 0.00505652\n",
      "Iteration 5048, loss = 0.00505538\n",
      "Iteration 5049, loss = 0.00505364\n",
      "Iteration 5050, loss = 0.00505222\n",
      "Iteration 5051, loss = 0.00505116\n",
      "Iteration 5052, loss = 0.00504979\n",
      "Iteration 5053, loss = 0.00504822\n",
      "Iteration 5054, loss = 0.00504688\n",
      "Iteration 5055, loss = 0.00504571\n",
      "Iteration 5056, loss = 0.00504436\n",
      "Iteration 5057, loss = 0.00504300\n",
      "Iteration 5058, loss = 0.00504169\n",
      "Iteration 5059, loss = 0.00504056\n",
      "Iteration 5060, loss = 0.00503885\n",
      "Iteration 5061, loss = 0.00503754\n",
      "Iteration 5062, loss = 0.00503612\n",
      "Iteration 5063, loss = 0.00503467\n",
      "Iteration 5064, loss = 0.00503335\n",
      "Iteration 5065, loss = 0.00503191\n",
      "Iteration 5066, loss = 0.00503041\n",
      "Iteration 5067, loss = 0.00502932\n",
      "Iteration 5068, loss = 0.00502780\n",
      "Iteration 5069, loss = 0.00502616\n",
      "Iteration 5070, loss = 0.00502548\n",
      "Iteration 5071, loss = 0.00502353\n",
      "Iteration 5072, loss = 0.00502216\n",
      "Iteration 5073, loss = 0.00502092\n",
      "Iteration 5074, loss = 0.00501954\n",
      "Iteration 5075, loss = 0.00501842\n",
      "Iteration 5076, loss = 0.00501714\n",
      "Iteration 5077, loss = 0.00501564\n",
      "Iteration 5078, loss = 0.00501443\n",
      "Iteration 5079, loss = 0.00501277\n",
      "Iteration 5080, loss = 0.00501117\n",
      "Iteration 5081, loss = 0.00500955\n",
      "Iteration 5082, loss = 0.00500851\n",
      "Iteration 5083, loss = 0.00500685\n",
      "Iteration 5084, loss = 0.00500535\n",
      "Iteration 5085, loss = 0.00500414\n",
      "Iteration 5086, loss = 0.00500247\n",
      "Iteration 5087, loss = 0.00500107\n",
      "Iteration 5088, loss = 0.00499937\n",
      "Iteration 5089, loss = 0.00499793\n",
      "Iteration 5090, loss = 0.00499680\n",
      "Iteration 5091, loss = 0.00499542\n",
      "Iteration 5092, loss = 0.00499374\n",
      "Iteration 5093, loss = 0.00499218\n",
      "Iteration 5094, loss = 0.00499117\n",
      "Iteration 5095, loss = 0.00498953\n",
      "Iteration 5096, loss = 0.00498809\n",
      "Iteration 5097, loss = 0.00498679\n",
      "Iteration 5098, loss = 0.00498528\n",
      "Iteration 5099, loss = 0.00498389\n",
      "Iteration 5100, loss = 0.00498278\n",
      "Iteration 5101, loss = 0.00498144\n",
      "Iteration 5102, loss = 0.00498026\n",
      "Iteration 5103, loss = 0.00497901\n",
      "Iteration 5104, loss = 0.00497820\n",
      "Iteration 5105, loss = 0.00497640\n",
      "Iteration 5106, loss = 0.00497502\n",
      "Iteration 5107, loss = 0.00497374\n",
      "Iteration 5108, loss = 0.00497237\n",
      "Iteration 5109, loss = 0.00497104\n",
      "Iteration 5110, loss = 0.00496964\n",
      "Iteration 5111, loss = 0.00496844\n",
      "Iteration 5112, loss = 0.00496695\n",
      "Iteration 5113, loss = 0.00496559\n",
      "Iteration 5114, loss = 0.00496385\n",
      "Iteration 5115, loss = 0.00496251\n",
      "Iteration 5116, loss = 0.00496086\n",
      "Iteration 5117, loss = 0.00496003\n",
      "Iteration 5118, loss = 0.00495813\n",
      "Iteration 5119, loss = 0.00495714\n",
      "Iteration 5120, loss = 0.00495551\n",
      "Iteration 5121, loss = 0.00495433\n",
      "Iteration 5122, loss = 0.00495273\n",
      "Iteration 5123, loss = 0.00495227\n",
      "Iteration 5124, loss = 0.00495041\n",
      "Iteration 5125, loss = 0.00494890\n",
      "Iteration 5126, loss = 0.00494790\n",
      "Iteration 5127, loss = 0.00494617\n",
      "Iteration 5128, loss = 0.00494457\n",
      "Iteration 5129, loss = 0.00494360\n",
      "Iteration 5130, loss = 0.00494169\n",
      "Iteration 5131, loss = 0.00494062\n",
      "Iteration 5132, loss = 0.00493896\n",
      "Iteration 5133, loss = 0.00493729\n",
      "Iteration 5134, loss = 0.00493607\n",
      "Iteration 5135, loss = 0.00493443\n",
      "Iteration 5136, loss = 0.00493283\n",
      "Iteration 5137, loss = 0.00493123\n",
      "Iteration 5138, loss = 0.00492994\n",
      "Iteration 5139, loss = 0.00492841\n",
      "Iteration 5140, loss = 0.00492743\n",
      "Iteration 5141, loss = 0.00492568\n",
      "Iteration 5142, loss = 0.00492461\n",
      "Iteration 5143, loss = 0.00492305\n",
      "Iteration 5144, loss = 0.00492172\n",
      "Iteration 5145, loss = 0.00492047\n",
      "Iteration 5146, loss = 0.00491889\n",
      "Iteration 5147, loss = 0.00491747\n",
      "Iteration 5148, loss = 0.00491594\n",
      "Iteration 5149, loss = 0.00491466\n",
      "Iteration 5150, loss = 0.00491316\n",
      "Iteration 5151, loss = 0.00491216\n",
      "Iteration 5152, loss = 0.00491069\n",
      "Iteration 5153, loss = 0.00490906\n",
      "Iteration 5154, loss = 0.00490828\n",
      "Iteration 5155, loss = 0.00490633\n",
      "Iteration 5156, loss = 0.00490510\n",
      "Iteration 5157, loss = 0.00490367\n",
      "Iteration 5158, loss = 0.00490238\n",
      "Iteration 5159, loss = 0.00490157\n",
      "Iteration 5160, loss = 0.00489986\n",
      "Iteration 5161, loss = 0.00489841\n",
      "Iteration 5162, loss = 0.00489713\n",
      "Iteration 5163, loss = 0.00489602\n",
      "Iteration 5164, loss = 0.00489457\n",
      "Iteration 5165, loss = 0.00489325\n",
      "Iteration 5166, loss = 0.00489198\n",
      "Iteration 5167, loss = 0.00489067\n",
      "Iteration 5168, loss = 0.00488944\n",
      "Iteration 5169, loss = 0.00488826\n",
      "Iteration 5170, loss = 0.00488703\n",
      "Iteration 5171, loss = 0.00488587\n",
      "Iteration 5172, loss = 0.00488457\n",
      "Iteration 5173, loss = 0.00488335\n",
      "Iteration 5174, loss = 0.00488193\n",
      "Iteration 5175, loss = 0.00488003\n",
      "Iteration 5176, loss = 0.00487900\n",
      "Iteration 5177, loss = 0.00487779\n",
      "Iteration 5178, loss = 0.00487641\n",
      "Iteration 5179, loss = 0.00487587\n",
      "Iteration 5180, loss = 0.00487389\n",
      "Iteration 5181, loss = 0.00487281\n",
      "Iteration 5182, loss = 0.00487105\n",
      "Iteration 5183, loss = 0.00486994\n",
      "Iteration 5184, loss = 0.00486837\n",
      "Iteration 5185, loss = 0.00486682\n",
      "Iteration 5186, loss = 0.00486537\n",
      "Iteration 5187, loss = 0.00486420\n",
      "Iteration 5188, loss = 0.00486246\n",
      "Iteration 5189, loss = 0.00486153\n",
      "Iteration 5190, loss = 0.00485974\n",
      "Iteration 5191, loss = 0.00485845\n",
      "Iteration 5192, loss = 0.00485705\n",
      "Iteration 5193, loss = 0.00485576\n",
      "Iteration 5194, loss = 0.00485457\n",
      "Iteration 5195, loss = 0.00485344\n",
      "Iteration 5196, loss = 0.00485180\n",
      "Iteration 5197, loss = 0.00485056\n",
      "Iteration 5198, loss = 0.00484935\n",
      "Iteration 5199, loss = 0.00484809\n",
      "Iteration 5200, loss = 0.00484682\n",
      "Iteration 5201, loss = 0.00484571\n",
      "Iteration 5202, loss = 0.00484418\n",
      "Iteration 5203, loss = 0.00484296\n",
      "Iteration 5204, loss = 0.00484136\n",
      "Iteration 5205, loss = 0.00484020\n",
      "Iteration 5206, loss = 0.00483881\n",
      "Iteration 5207, loss = 0.00483757\n",
      "Iteration 5208, loss = 0.00483625\n",
      "Iteration 5209, loss = 0.00483532\n",
      "Iteration 5210, loss = 0.00483388\n",
      "Iteration 5211, loss = 0.00483255\n",
      "Iteration 5212, loss = 0.00483118\n",
      "Iteration 5213, loss = 0.00482990\n",
      "Iteration 5214, loss = 0.00482911\n",
      "Iteration 5215, loss = 0.00482748\n",
      "Iteration 5216, loss = 0.00482640\n",
      "Iteration 5217, loss = 0.00482505\n",
      "Iteration 5218, loss = 0.00482377\n",
      "Iteration 5219, loss = 0.00482277\n",
      "Iteration 5220, loss = 0.00482106\n",
      "Iteration 5221, loss = 0.00481990\n",
      "Iteration 5222, loss = 0.00481857\n",
      "Iteration 5223, loss = 0.00481722\n",
      "Iteration 5224, loss = 0.00481619\n",
      "Iteration 5225, loss = 0.00481465\n",
      "Iteration 5226, loss = 0.00481395\n",
      "Iteration 5227, loss = 0.00481226\n",
      "Iteration 5228, loss = 0.00481098\n",
      "Iteration 5229, loss = 0.00480973\n",
      "Iteration 5230, loss = 0.00480845\n",
      "Iteration 5231, loss = 0.00480711\n",
      "Iteration 5232, loss = 0.00480599\n",
      "Iteration 5233, loss = 0.00480474\n",
      "Iteration 5234, loss = 0.00480359\n",
      "Iteration 5235, loss = 0.00480223\n",
      "Iteration 5236, loss = 0.00480113\n",
      "Iteration 5237, loss = 0.00480000\n",
      "Iteration 5238, loss = 0.00479853\n",
      "Iteration 5239, loss = 0.00479726\n",
      "Iteration 5240, loss = 0.00479604\n",
      "Iteration 5241, loss = 0.00479458\n",
      "Iteration 5242, loss = 0.00479340\n",
      "Iteration 5243, loss = 0.00479197\n",
      "Iteration 5244, loss = 0.00479106\n",
      "Iteration 5245, loss = 0.00478943\n",
      "Iteration 5246, loss = 0.00478839\n",
      "Iteration 5247, loss = 0.00478713\n",
      "Iteration 5248, loss = 0.00478581\n",
      "Iteration 5249, loss = 0.00478490\n",
      "Iteration 5250, loss = 0.00478343\n",
      "Iteration 5251, loss = 0.00478201\n",
      "Iteration 5252, loss = 0.00478058\n",
      "Iteration 5253, loss = 0.00477932\n",
      "Iteration 5254, loss = 0.00477817\n",
      "Iteration 5255, loss = 0.00477655\n",
      "Iteration 5256, loss = 0.00477526\n",
      "Iteration 5257, loss = 0.00477398\n",
      "Iteration 5258, loss = 0.00477250\n",
      "Iteration 5259, loss = 0.00477135\n",
      "Iteration 5260, loss = 0.00476969\n",
      "Iteration 5261, loss = 0.00476822\n",
      "Iteration 5262, loss = 0.00476726\n",
      "Iteration 5263, loss = 0.00476553\n",
      "Iteration 5264, loss = 0.00476428\n",
      "Iteration 5265, loss = 0.00476305\n",
      "Iteration 5266, loss = 0.00476157\n",
      "Iteration 5267, loss = 0.00476015\n",
      "Iteration 5268, loss = 0.00475867\n",
      "Iteration 5269, loss = 0.00475790\n",
      "Iteration 5270, loss = 0.00475625\n",
      "Iteration 5271, loss = 0.00475473\n",
      "Iteration 5272, loss = 0.00475335\n",
      "Iteration 5273, loss = 0.00475257\n",
      "Iteration 5274, loss = 0.00475086\n",
      "Iteration 5275, loss = 0.00474978\n",
      "Iteration 5276, loss = 0.00474841\n",
      "Iteration 5277, loss = 0.00474716\n",
      "Iteration 5278, loss = 0.00474580\n",
      "Iteration 5279, loss = 0.00474456\n",
      "Iteration 5280, loss = 0.00474340\n",
      "Iteration 5281, loss = 0.00474223\n",
      "Iteration 5282, loss = 0.00474104\n",
      "Iteration 5283, loss = 0.00473992\n",
      "Iteration 5284, loss = 0.00473878\n",
      "Iteration 5285, loss = 0.00473748\n",
      "Iteration 5286, loss = 0.00473628\n",
      "Iteration 5287, loss = 0.00473499\n",
      "Iteration 5288, loss = 0.00473374\n",
      "Iteration 5289, loss = 0.00473239\n",
      "Iteration 5290, loss = 0.00473102\n",
      "Iteration 5291, loss = 0.00473003\n",
      "Iteration 5292, loss = 0.00472863\n",
      "Iteration 5293, loss = 0.00472744\n",
      "Iteration 5294, loss = 0.00472629\n",
      "Iteration 5295, loss = 0.00472502\n",
      "Iteration 5296, loss = 0.00472399\n",
      "Iteration 5297, loss = 0.00472243\n",
      "Iteration 5298, loss = 0.00472160\n",
      "Iteration 5299, loss = 0.00472014\n",
      "Iteration 5300, loss = 0.00471870\n",
      "Iteration 5301, loss = 0.00471742\n",
      "Iteration 5302, loss = 0.00471633\n",
      "Iteration 5303, loss = 0.00471477\n",
      "Iteration 5304, loss = 0.00471426\n",
      "Iteration 5305, loss = 0.00471212\n",
      "Iteration 5306, loss = 0.00471061\n",
      "Iteration 5307, loss = 0.00470944\n",
      "Iteration 5308, loss = 0.00470811\n",
      "Iteration 5309, loss = 0.00470687\n",
      "Iteration 5310, loss = 0.00470560\n",
      "Iteration 5311, loss = 0.00470399\n",
      "Iteration 5312, loss = 0.00470280\n",
      "Iteration 5313, loss = 0.00470141\n",
      "Iteration 5314, loss = 0.00470035\n",
      "Iteration 5315, loss = 0.00469908\n",
      "Iteration 5316, loss = 0.00469774\n",
      "Iteration 5317, loss = 0.00469680\n",
      "Iteration 5318, loss = 0.00469516\n",
      "Iteration 5319, loss = 0.00469376\n",
      "Iteration 5320, loss = 0.00469262\n",
      "Iteration 5321, loss = 0.00469114\n",
      "Iteration 5322, loss = 0.00468984\n",
      "Iteration 5323, loss = 0.00468862\n",
      "Iteration 5324, loss = 0.00468731\n",
      "Iteration 5325, loss = 0.00468603\n",
      "Iteration 5326, loss = 0.00468484\n",
      "Iteration 5327, loss = 0.00468355\n",
      "Iteration 5328, loss = 0.00468212\n",
      "Iteration 5329, loss = 0.00468093\n",
      "Iteration 5330, loss = 0.00467951\n",
      "Iteration 5331, loss = 0.00467847\n",
      "Iteration 5332, loss = 0.00467697\n",
      "Iteration 5333, loss = 0.00467590\n",
      "Iteration 5334, loss = 0.00467435\n",
      "Iteration 5335, loss = 0.00467298\n",
      "Iteration 5336, loss = 0.00467175\n",
      "Iteration 5337, loss = 0.00467053\n",
      "Iteration 5338, loss = 0.00466916\n",
      "Iteration 5339, loss = 0.00466793\n",
      "Iteration 5340, loss = 0.00466669\n",
      "Iteration 5341, loss = 0.00466544\n",
      "Iteration 5342, loss = 0.00466428\n",
      "Iteration 5343, loss = 0.00466293\n",
      "Iteration 5344, loss = 0.00466194\n",
      "Iteration 5345, loss = 0.00466098\n",
      "Iteration 5346, loss = 0.00465950\n",
      "Iteration 5347, loss = 0.00465843\n",
      "Iteration 5348, loss = 0.00465720\n",
      "Iteration 5349, loss = 0.00465607\n",
      "Iteration 5350, loss = 0.00465475\n",
      "Iteration 5351, loss = 0.00465399\n",
      "Iteration 5352, loss = 0.00465250\n",
      "Iteration 5353, loss = 0.00465132\n",
      "Iteration 5354, loss = 0.00465046\n",
      "Iteration 5355, loss = 0.00464928\n",
      "Iteration 5356, loss = 0.00464769\n",
      "Iteration 5357, loss = 0.00464637\n",
      "Iteration 5358, loss = 0.00464495\n",
      "Iteration 5359, loss = 0.00464371\n",
      "Iteration 5360, loss = 0.00464242\n",
      "Iteration 5361, loss = 0.00464110\n",
      "Iteration 5362, loss = 0.00463995\n",
      "Iteration 5363, loss = 0.00463860\n",
      "Iteration 5364, loss = 0.00463745\n",
      "Iteration 5365, loss = 0.00463618\n",
      "Iteration 5366, loss = 0.00463503\n",
      "Iteration 5367, loss = 0.00463388\n",
      "Iteration 5368, loss = 0.00463259\n",
      "Iteration 5369, loss = 0.00463117\n",
      "Iteration 5370, loss = 0.00463016\n",
      "Iteration 5371, loss = 0.00462888\n",
      "Iteration 5372, loss = 0.00462800\n",
      "Iteration 5373, loss = 0.00462643\n",
      "Iteration 5374, loss = 0.00462532\n",
      "Iteration 5375, loss = 0.00462407\n",
      "Iteration 5376, loss = 0.00462272\n",
      "Iteration 5377, loss = 0.00462163\n",
      "Iteration 5378, loss = 0.00462015\n",
      "Iteration 5379, loss = 0.00461900\n",
      "Iteration 5380, loss = 0.00461756\n",
      "Iteration 5381, loss = 0.00461639\n",
      "Iteration 5382, loss = 0.00461503\n",
      "Iteration 5383, loss = 0.00461361\n",
      "Iteration 5384, loss = 0.00461288\n",
      "Iteration 5385, loss = 0.00461214\n",
      "Iteration 5386, loss = 0.00461037\n",
      "Iteration 5387, loss = 0.00460917\n",
      "Iteration 5388, loss = 0.00460809\n",
      "Iteration 5389, loss = 0.00460720\n",
      "Iteration 5390, loss = 0.00460545\n",
      "Iteration 5391, loss = 0.00460418\n",
      "Iteration 5392, loss = 0.00460302\n",
      "Iteration 5393, loss = 0.00460175\n",
      "Iteration 5394, loss = 0.00460055\n",
      "Iteration 5395, loss = 0.00459936\n",
      "Iteration 5396, loss = 0.00459832\n",
      "Iteration 5397, loss = 0.00459703\n",
      "Iteration 5398, loss = 0.00459593\n",
      "Iteration 5399, loss = 0.00459477\n",
      "Iteration 5400, loss = 0.00459343\n",
      "Iteration 5401, loss = 0.00459216\n",
      "Iteration 5402, loss = 0.00459096\n",
      "Iteration 5403, loss = 0.00458964\n",
      "Iteration 5404, loss = 0.00458818\n",
      "Iteration 5405, loss = 0.00458754\n",
      "Iteration 5406, loss = 0.00458658\n",
      "Iteration 5407, loss = 0.00458466\n",
      "Iteration 5408, loss = 0.00458332\n",
      "Iteration 5409, loss = 0.00458208\n",
      "Iteration 5410, loss = 0.00458058\n",
      "Iteration 5411, loss = 0.00457954\n",
      "Iteration 5412, loss = 0.00457863\n",
      "Iteration 5413, loss = 0.00457823\n",
      "Iteration 5414, loss = 0.00457683\n",
      "Iteration 5415, loss = 0.00457509\n",
      "Iteration 5416, loss = 0.00457361\n",
      "Iteration 5417, loss = 0.00457254\n",
      "Iteration 5418, loss = 0.00457160\n",
      "Iteration 5419, loss = 0.00457042\n",
      "Iteration 5420, loss = 0.00456892\n",
      "Iteration 5421, loss = 0.00456768\n",
      "Iteration 5422, loss = 0.00456648\n",
      "Iteration 5423, loss = 0.00456514\n",
      "Iteration 5424, loss = 0.00456425\n",
      "Iteration 5425, loss = 0.00456276\n",
      "Iteration 5426, loss = 0.00456181\n",
      "Iteration 5427, loss = 0.00456065\n",
      "Iteration 5428, loss = 0.00455897\n",
      "Iteration 5429, loss = 0.00455785\n",
      "Iteration 5430, loss = 0.00455640\n",
      "Iteration 5431, loss = 0.00455569\n",
      "Iteration 5432, loss = 0.00455420\n",
      "Iteration 5433, loss = 0.00455326\n",
      "Iteration 5434, loss = 0.00455174\n",
      "Iteration 5435, loss = 0.00455057\n",
      "Iteration 5436, loss = 0.00454927\n",
      "Iteration 5437, loss = 0.00454834\n",
      "Iteration 5438, loss = 0.00454689\n",
      "Iteration 5439, loss = 0.00454577\n",
      "Iteration 5440, loss = 0.00454444\n",
      "Iteration 5441, loss = 0.00454324\n",
      "Iteration 5442, loss = 0.00454193\n",
      "Iteration 5443, loss = 0.00454064\n",
      "Iteration 5444, loss = 0.00453938\n",
      "Iteration 5445, loss = 0.00453802\n",
      "Iteration 5446, loss = 0.00453665\n",
      "Iteration 5447, loss = 0.00453546\n",
      "Iteration 5448, loss = 0.00453386\n",
      "Iteration 5449, loss = 0.00453280\n",
      "Iteration 5450, loss = 0.00453170\n",
      "Iteration 5451, loss = 0.00453027\n",
      "Iteration 5452, loss = 0.00452922\n",
      "Iteration 5453, loss = 0.00452798\n",
      "Iteration 5454, loss = 0.00452765\n",
      "Iteration 5455, loss = 0.00452567\n",
      "Iteration 5456, loss = 0.00452467\n",
      "Iteration 5457, loss = 0.00452337\n",
      "Iteration 5458, loss = 0.00452216\n",
      "Iteration 5459, loss = 0.00452107\n",
      "Iteration 5460, loss = 0.00452004\n",
      "Iteration 5461, loss = 0.00451900\n",
      "Iteration 5462, loss = 0.00451801\n",
      "Iteration 5463, loss = 0.00451682\n",
      "Iteration 5464, loss = 0.00451551\n",
      "Iteration 5465, loss = 0.00451462\n",
      "Iteration 5466, loss = 0.00451337\n",
      "Iteration 5467, loss = 0.00451214\n",
      "Iteration 5468, loss = 0.00451102\n",
      "Iteration 5469, loss = 0.00451023\n",
      "Iteration 5470, loss = 0.00450885\n",
      "Iteration 5471, loss = 0.00450759\n",
      "Iteration 5472, loss = 0.00450657\n",
      "Iteration 5473, loss = 0.00450610\n",
      "Iteration 5474, loss = 0.00450430\n",
      "Iteration 5475, loss = 0.00450347\n",
      "Iteration 5476, loss = 0.00450228\n",
      "Iteration 5477, loss = 0.00450105\n",
      "Iteration 5478, loss = 0.00449994\n",
      "Iteration 5479, loss = 0.00449903\n",
      "Iteration 5480, loss = 0.00449777\n",
      "Iteration 5481, loss = 0.00449667\n",
      "Iteration 5482, loss = 0.00449574\n",
      "Iteration 5483, loss = 0.00449489\n",
      "Iteration 5484, loss = 0.00449365\n",
      "Iteration 5485, loss = 0.00449264\n",
      "Iteration 5486, loss = 0.00449154\n",
      "Iteration 5487, loss = 0.00449048\n",
      "Iteration 5488, loss = 0.00448937\n",
      "Iteration 5489, loss = 0.00448825\n",
      "Iteration 5490, loss = 0.00448713\n",
      "Iteration 5491, loss = 0.00448623\n",
      "Iteration 5492, loss = 0.00448537\n",
      "Iteration 5493, loss = 0.00448418\n",
      "Iteration 5494, loss = 0.00448327\n",
      "Iteration 5495, loss = 0.00448198\n",
      "Iteration 5496, loss = 0.00448086\n",
      "Iteration 5497, loss = 0.00447981\n",
      "Iteration 5498, loss = 0.00447879\n",
      "Iteration 5499, loss = 0.00447756\n",
      "Iteration 5500, loss = 0.00447635\n",
      "Iteration 5501, loss = 0.00447518\n",
      "Iteration 5502, loss = 0.00447403\n",
      "Iteration 5503, loss = 0.00447295\n",
      "Iteration 5504, loss = 0.00447161\n",
      "Iteration 5505, loss = 0.00447049\n",
      "Iteration 5506, loss = 0.00446960\n",
      "Iteration 5507, loss = 0.00446822\n",
      "Iteration 5508, loss = 0.00446715\n",
      "Iteration 5509, loss = 0.00446630\n",
      "Iteration 5510, loss = 0.00446490\n",
      "Iteration 5511, loss = 0.00446395\n",
      "Iteration 5512, loss = 0.00446314\n",
      "Iteration 5513, loss = 0.00446162\n",
      "Iteration 5514, loss = 0.00446061\n",
      "Iteration 5515, loss = 0.00445946\n",
      "Iteration 5516, loss = 0.00445857\n",
      "Iteration 5517, loss = 0.00445743\n",
      "Iteration 5518, loss = 0.00445637\n",
      "Iteration 5519, loss = 0.00445523\n",
      "Iteration 5520, loss = 0.00445415\n",
      "Iteration 5521, loss = 0.00445309\n",
      "Iteration 5522, loss = 0.00445225\n",
      "Iteration 5523, loss = 0.00445109\n",
      "Iteration 5524, loss = 0.00445004\n",
      "Iteration 5525, loss = 0.00444904\n",
      "Iteration 5526, loss = 0.00444791\n",
      "Iteration 5527, loss = 0.00444674\n",
      "Iteration 5528, loss = 0.00444541\n",
      "Iteration 5529, loss = 0.00444446\n",
      "Iteration 5530, loss = 0.00444352\n",
      "Iteration 5531, loss = 0.00444202\n",
      "Iteration 5532, loss = 0.00444120\n",
      "Iteration 5533, loss = 0.00443965\n",
      "Iteration 5534, loss = 0.00443858\n",
      "Iteration 5535, loss = 0.00443731\n",
      "Iteration 5536, loss = 0.00443646\n",
      "Iteration 5537, loss = 0.00443510\n",
      "Iteration 5538, loss = 0.00443371\n",
      "Iteration 5539, loss = 0.00443313\n",
      "Iteration 5540, loss = 0.00443153\n",
      "Iteration 5541, loss = 0.00442995\n",
      "Iteration 5542, loss = 0.00442929\n",
      "Iteration 5543, loss = 0.00442803\n",
      "Iteration 5544, loss = 0.00442625\n",
      "Iteration 5545, loss = 0.00442515\n",
      "Iteration 5546, loss = 0.00442400\n",
      "Iteration 5547, loss = 0.00442263\n",
      "Iteration 5548, loss = 0.00442143\n",
      "Iteration 5549, loss = 0.00442000\n",
      "Iteration 5550, loss = 0.00441946\n",
      "Iteration 5551, loss = 0.00441774\n",
      "Iteration 5552, loss = 0.00441685\n",
      "Iteration 5553, loss = 0.00441526\n",
      "Iteration 5554, loss = 0.00441397\n",
      "Iteration 5555, loss = 0.00441282\n",
      "Iteration 5556, loss = 0.00441195\n",
      "Iteration 5557, loss = 0.00441052\n",
      "Iteration 5558, loss = 0.00440950\n",
      "Iteration 5559, loss = 0.00440829\n",
      "Iteration 5560, loss = 0.00440715\n",
      "Iteration 5561, loss = 0.00440616\n",
      "Iteration 5562, loss = 0.00440515\n",
      "Iteration 5563, loss = 0.00440377\n",
      "Iteration 5564, loss = 0.00440252\n",
      "Iteration 5565, loss = 0.00440162\n",
      "Iteration 5566, loss = 0.00440020\n",
      "Iteration 5567, loss = 0.00439917\n",
      "Iteration 5568, loss = 0.00439787\n",
      "Iteration 5569, loss = 0.00439675\n",
      "Iteration 5570, loss = 0.00439556\n",
      "Iteration 5571, loss = 0.00439464\n",
      "Iteration 5572, loss = 0.00439341\n",
      "Iteration 5573, loss = 0.00439256\n",
      "Iteration 5574, loss = 0.00439133\n",
      "Iteration 5575, loss = 0.00439013\n",
      "Iteration 5576, loss = 0.00438905\n",
      "Iteration 5577, loss = 0.00438759\n",
      "Iteration 5578, loss = 0.00438794\n",
      "Iteration 5579, loss = 0.00438548\n",
      "Iteration 5580, loss = 0.00438438\n",
      "Iteration 5581, loss = 0.00438307\n",
      "Iteration 5582, loss = 0.00438195\n",
      "Iteration 5583, loss = 0.00438076\n",
      "Iteration 5584, loss = 0.00437960\n",
      "Iteration 5585, loss = 0.00437861\n",
      "Iteration 5586, loss = 0.00437760\n",
      "Iteration 5587, loss = 0.00437660\n",
      "Iteration 5588, loss = 0.00437544\n",
      "Iteration 5589, loss = 0.00437453\n",
      "Iteration 5590, loss = 0.00437338\n",
      "Iteration 5591, loss = 0.00437237\n",
      "Iteration 5592, loss = 0.00437118\n",
      "Iteration 5593, loss = 0.00437029\n",
      "Iteration 5594, loss = 0.00436942\n",
      "Iteration 5595, loss = 0.00436812\n",
      "Iteration 5596, loss = 0.00436707\n",
      "Iteration 5597, loss = 0.00436610\n",
      "Iteration 5598, loss = 0.00436528\n",
      "Iteration 5599, loss = 0.00436373\n",
      "Iteration 5600, loss = 0.00436255\n",
      "Iteration 5601, loss = 0.00436133\n",
      "Iteration 5602, loss = 0.00436093\n",
      "Iteration 5603, loss = 0.00435942\n",
      "Iteration 5604, loss = 0.00435828\n",
      "Iteration 5605, loss = 0.00435720\n",
      "Iteration 5606, loss = 0.00435613\n",
      "Iteration 5607, loss = 0.00435512\n",
      "Iteration 5608, loss = 0.00435414\n",
      "Iteration 5609, loss = 0.00435297\n",
      "Iteration 5610, loss = 0.00435172\n",
      "Iteration 5611, loss = 0.00435046\n",
      "Iteration 5612, loss = 0.00434944\n",
      "Iteration 5613, loss = 0.00434811\n",
      "Iteration 5614, loss = 0.00434690\n",
      "Iteration 5615, loss = 0.00434594\n",
      "Iteration 5616, loss = 0.00434471\n",
      "Iteration 5617, loss = 0.00434337\n",
      "Iteration 5618, loss = 0.00434198\n",
      "Iteration 5619, loss = 0.00434090\n",
      "Iteration 5620, loss = 0.00433959\n",
      "Iteration 5621, loss = 0.00433845\n",
      "Iteration 5622, loss = 0.00433765\n",
      "Iteration 5623, loss = 0.00433639\n",
      "Iteration 5624, loss = 0.00433517\n",
      "Iteration 5625, loss = 0.00433381\n",
      "Iteration 5626, loss = 0.00433273\n",
      "Iteration 5627, loss = 0.00433152\n",
      "Iteration 5628, loss = 0.00433047\n",
      "Iteration 5629, loss = 0.00432948\n",
      "Iteration 5630, loss = 0.00432857\n",
      "Iteration 5631, loss = 0.00432752\n",
      "Iteration 5632, loss = 0.00432624\n",
      "Iteration 5633, loss = 0.00432510\n",
      "Iteration 5634, loss = 0.00432408\n",
      "Iteration 5635, loss = 0.00432301\n",
      "Iteration 5636, loss = 0.00432169\n",
      "Iteration 5637, loss = 0.00432060\n",
      "Iteration 5638, loss = 0.00431941\n",
      "Iteration 5639, loss = 0.00431822\n",
      "Iteration 5640, loss = 0.00431711\n",
      "Iteration 5641, loss = 0.00431614\n",
      "Iteration 5642, loss = 0.00431496\n",
      "Iteration 5643, loss = 0.00431407\n",
      "Iteration 5644, loss = 0.00431272\n",
      "Iteration 5645, loss = 0.00431151\n",
      "Iteration 5646, loss = 0.00431032\n",
      "Iteration 5647, loss = 0.00430923\n",
      "Iteration 5648, loss = 0.00430830\n",
      "Iteration 5649, loss = 0.00430688\n",
      "Iteration 5650, loss = 0.00430592\n",
      "Iteration 5651, loss = 0.00430476\n",
      "Iteration 5652, loss = 0.00430405\n",
      "Iteration 5653, loss = 0.00430277\n",
      "Iteration 5654, loss = 0.00430169\n",
      "Iteration 5655, loss = 0.00430067\n",
      "Iteration 5656, loss = 0.00429966\n",
      "Iteration 5657, loss = 0.00429853\n",
      "Iteration 5658, loss = 0.00429772\n",
      "Iteration 5659, loss = 0.00429651\n",
      "Iteration 5660, loss = 0.00429552\n",
      "Iteration 5661, loss = 0.00429445\n",
      "Iteration 5662, loss = 0.00429351\n",
      "Iteration 5663, loss = 0.00429250\n",
      "Iteration 5664, loss = 0.00429167\n",
      "Iteration 5665, loss = 0.00429073\n",
      "Iteration 5666, loss = 0.00428976\n",
      "Iteration 5667, loss = 0.00428872\n",
      "Iteration 5668, loss = 0.00428765\n",
      "Iteration 5669, loss = 0.00428678\n",
      "Iteration 5670, loss = 0.00428586\n",
      "Iteration 5671, loss = 0.00428511\n",
      "Iteration 5672, loss = 0.00428409\n",
      "Iteration 5673, loss = 0.00428313\n",
      "Iteration 5674, loss = 0.00428202\n",
      "Iteration 5675, loss = 0.00428110\n",
      "Iteration 5676, loss = 0.00428004\n",
      "Iteration 5677, loss = 0.00427891\n",
      "Iteration 5678, loss = 0.00427807\n",
      "Iteration 5679, loss = 0.00427678\n",
      "Iteration 5680, loss = 0.00427567\n",
      "Iteration 5681, loss = 0.00427458\n",
      "Iteration 5682, loss = 0.00427367\n",
      "Iteration 5683, loss = 0.00427258\n",
      "Iteration 5684, loss = 0.00427159\n",
      "Iteration 5685, loss = 0.00427040\n",
      "Iteration 5686, loss = 0.00426924\n",
      "Iteration 5687, loss = 0.00426821\n",
      "Iteration 5688, loss = 0.00426712\n",
      "Iteration 5689, loss = 0.00426606\n",
      "Iteration 5690, loss = 0.00426511\n",
      "Iteration 5691, loss = 0.00426409\n",
      "Iteration 5692, loss = 0.00426317\n",
      "Iteration 5693, loss = 0.00426222\n",
      "Iteration 5694, loss = 0.00426099\n",
      "Iteration 5695, loss = 0.00425994\n",
      "Iteration 5696, loss = 0.00425871\n",
      "Iteration 5697, loss = 0.00425747\n",
      "Iteration 5698, loss = 0.00425630\n",
      "Iteration 5699, loss = 0.00425570\n",
      "Iteration 5700, loss = 0.00425467\n",
      "Iteration 5701, loss = 0.00425342\n",
      "Iteration 5702, loss = 0.00425226\n",
      "Iteration 5703, loss = 0.00425119\n",
      "Iteration 5704, loss = 0.00425011\n",
      "Iteration 5705, loss = 0.00424929\n",
      "Iteration 5706, loss = 0.00424810\n",
      "Iteration 5707, loss = 0.00424708\n",
      "Iteration 5708, loss = 0.00424605\n",
      "Iteration 5709, loss = 0.00424497\n",
      "Iteration 5710, loss = 0.00424415\n",
      "Iteration 5711, loss = 0.00424293\n",
      "Iteration 5712, loss = 0.00424215\n",
      "Iteration 5713, loss = 0.00424103\n",
      "Iteration 5714, loss = 0.00423986\n",
      "Iteration 5715, loss = 0.00423863\n",
      "Iteration 5716, loss = 0.00423820\n",
      "Iteration 5717, loss = 0.00423661\n",
      "Iteration 5718, loss = 0.00423559\n",
      "Iteration 5719, loss = 0.00423472\n",
      "Iteration 5720, loss = 0.00423354\n",
      "Iteration 5721, loss = 0.00423240\n",
      "Iteration 5722, loss = 0.00423139\n",
      "Iteration 5723, loss = 0.00423037\n",
      "Iteration 5724, loss = 0.00422926\n",
      "Iteration 5725, loss = 0.00422810\n",
      "Iteration 5726, loss = 0.00422709\n",
      "Iteration 5727, loss = 0.00422625\n",
      "Iteration 5728, loss = 0.00422533\n",
      "Iteration 5729, loss = 0.00422402\n",
      "Iteration 5730, loss = 0.00422309\n",
      "Iteration 5731, loss = 0.00422211\n",
      "Iteration 5732, loss = 0.00422230\n",
      "Iteration 5733, loss = 0.00422054\n",
      "Iteration 5734, loss = 0.00421944\n",
      "Iteration 5735, loss = 0.00421834\n",
      "Iteration 5736, loss = 0.00421724\n",
      "Iteration 5737, loss = 0.00421630\n",
      "Iteration 5738, loss = 0.00421528\n",
      "Iteration 5739, loss = 0.00421429\n",
      "Iteration 5740, loss = 0.00421319\n",
      "Iteration 5741, loss = 0.00421237\n",
      "Iteration 5742, loss = 0.00421125\n",
      "Iteration 5743, loss = 0.00421020\n",
      "Iteration 5744, loss = 0.00420945\n",
      "Iteration 5745, loss = 0.00420829\n",
      "Iteration 5746, loss = 0.00420722\n",
      "Iteration 5747, loss = 0.00420632\n",
      "Iteration 5748, loss = 0.00420489\n",
      "Iteration 5749, loss = 0.00420374\n",
      "Iteration 5750, loss = 0.00420290\n",
      "Iteration 5751, loss = 0.00420218\n",
      "Iteration 5752, loss = 0.00420095\n",
      "Iteration 5753, loss = 0.00420007\n",
      "Iteration 5754, loss = 0.00419919\n",
      "Iteration 5755, loss = 0.00419834\n",
      "Iteration 5756, loss = 0.00419724\n",
      "Iteration 5757, loss = 0.00419628\n",
      "Iteration 5758, loss = 0.00419517\n",
      "Iteration 5759, loss = 0.00419426\n",
      "Iteration 5760, loss = 0.00419323\n",
      "Iteration 5761, loss = 0.00419188\n",
      "Iteration 5762, loss = 0.00419084\n",
      "Iteration 5763, loss = 0.00418958\n",
      "Iteration 5764, loss = 0.00418844\n",
      "Iteration 5765, loss = 0.00418753\n",
      "Iteration 5766, loss = 0.00418637\n",
      "Iteration 5767, loss = 0.00418524\n",
      "Iteration 5768, loss = 0.00418432\n",
      "Iteration 5769, loss = 0.00418309\n",
      "Iteration 5770, loss = 0.00418210\n",
      "Iteration 5771, loss = 0.00418113\n",
      "Iteration 5772, loss = 0.00418010\n",
      "Iteration 5773, loss = 0.00417899\n",
      "Iteration 5774, loss = 0.00417792\n",
      "Iteration 5775, loss = 0.00417709\n",
      "Iteration 5776, loss = 0.00417619\n",
      "Iteration 5777, loss = 0.00417482\n",
      "Iteration 5778, loss = 0.00417372\n",
      "Iteration 5779, loss = 0.00417256\n",
      "Iteration 5780, loss = 0.00417156\n",
      "Iteration 5781, loss = 0.00417044\n",
      "Iteration 5782, loss = 0.00416957\n",
      "Iteration 5783, loss = 0.00416899\n",
      "Iteration 5784, loss = 0.00416778\n",
      "Iteration 5785, loss = 0.00416665\n",
      "Iteration 5786, loss = 0.00416560\n",
      "Iteration 5787, loss = 0.00416487\n",
      "Iteration 5788, loss = 0.00416376\n",
      "Iteration 5789, loss = 0.00416296\n",
      "Iteration 5790, loss = 0.00416167\n",
      "Iteration 5791, loss = 0.00416057\n",
      "Iteration 5792, loss = 0.00415951\n",
      "Iteration 5793, loss = 0.00415861\n",
      "Iteration 5794, loss = 0.00415785\n",
      "Iteration 5795, loss = 0.00415649\n",
      "Iteration 5796, loss = 0.00415553\n",
      "Iteration 5797, loss = 0.00415443\n",
      "Iteration 5798, loss = 0.00415345\n",
      "Iteration 5799, loss = 0.00415259\n",
      "Iteration 5800, loss = 0.00415143\n",
      "Iteration 5801, loss = 0.00415020\n",
      "Iteration 5802, loss = 0.00414918\n",
      "Iteration 5803, loss = 0.00414807\n",
      "Iteration 5804, loss = 0.00414700\n",
      "Iteration 5805, loss = 0.00414597\n",
      "Iteration 5806, loss = 0.00414496\n",
      "Iteration 5807, loss = 0.00414386\n",
      "Iteration 5808, loss = 0.00414281\n",
      "Iteration 5809, loss = 0.00414176\n",
      "Iteration 5810, loss = 0.00414074\n",
      "Iteration 5811, loss = 0.00413985\n",
      "Iteration 5812, loss = 0.00413885\n",
      "Iteration 5813, loss = 0.00413780\n",
      "Iteration 5814, loss = 0.00413678\n",
      "Iteration 5815, loss = 0.00413600\n",
      "Iteration 5816, loss = 0.00413471\n",
      "Iteration 5817, loss = 0.00413396\n",
      "Iteration 5818, loss = 0.00413294\n",
      "Iteration 5819, loss = 0.00413188\n",
      "Iteration 5820, loss = 0.00413094\n",
      "Iteration 5821, loss = 0.00413001\n",
      "Iteration 5822, loss = 0.00412905\n",
      "Iteration 5823, loss = 0.00412813\n",
      "Iteration 5824, loss = 0.00412738\n",
      "Iteration 5825, loss = 0.00412614\n",
      "Iteration 5826, loss = 0.00412524\n",
      "Iteration 5827, loss = 0.00412418\n",
      "Iteration 5828, loss = 0.00412315\n",
      "Iteration 5829, loss = 0.00412208\n",
      "Iteration 5830, loss = 0.00412130\n",
      "Iteration 5831, loss = 0.00412021\n",
      "Iteration 5832, loss = 0.00411922\n",
      "Iteration 5833, loss = 0.00411824\n",
      "Iteration 5834, loss = 0.00411731\n",
      "Iteration 5835, loss = 0.00411629\n",
      "Iteration 5836, loss = 0.00411575\n",
      "Iteration 5837, loss = 0.00411433\n",
      "Iteration 5838, loss = 0.00411359\n",
      "Iteration 5839, loss = 0.00411222\n",
      "Iteration 5840, loss = 0.00411117\n",
      "Iteration 5841, loss = 0.00411021\n",
      "Iteration 5842, loss = 0.00410906\n",
      "Iteration 5843, loss = 0.00410806\n",
      "Iteration 5844, loss = 0.00410714\n",
      "Iteration 5845, loss = 0.00410595\n",
      "Iteration 5846, loss = 0.00410498\n",
      "Iteration 5847, loss = 0.00410412\n",
      "Iteration 5848, loss = 0.00410302\n",
      "Iteration 5849, loss = 0.00410221\n",
      "Iteration 5850, loss = 0.00410115\n",
      "Iteration 5851, loss = 0.00410039\n",
      "Iteration 5852, loss = 0.00409915\n",
      "Iteration 5853, loss = 0.00409807\n",
      "Iteration 5854, loss = 0.00409765\n",
      "Iteration 5855, loss = 0.00409589\n",
      "Iteration 5856, loss = 0.00409484\n",
      "Iteration 5857, loss = 0.00409349\n",
      "Iteration 5858, loss = 0.00409299\n",
      "Iteration 5859, loss = 0.00409124\n",
      "Iteration 5860, loss = 0.00409014\n",
      "Iteration 5861, loss = 0.00408889\n",
      "Iteration 5862, loss = 0.00408773\n",
      "Iteration 5863, loss = 0.00408692\n",
      "Iteration 5864, loss = 0.00408569\n",
      "Iteration 5865, loss = 0.00408463\n",
      "Iteration 5866, loss = 0.00408337\n",
      "Iteration 5867, loss = 0.00408249\n",
      "Iteration 5868, loss = 0.00408154\n",
      "Iteration 5869, loss = 0.00408046\n",
      "Iteration 5870, loss = 0.00407955\n",
      "Iteration 5871, loss = 0.00407847\n",
      "Iteration 5872, loss = 0.00407756\n",
      "Iteration 5873, loss = 0.00407651\n",
      "Iteration 5874, loss = 0.00407563\n",
      "Iteration 5875, loss = 0.00407462\n",
      "Iteration 5876, loss = 0.00407348\n",
      "Iteration 5877, loss = 0.00407263\n",
      "Iteration 5878, loss = 0.00407155\n",
      "Iteration 5879, loss = 0.00407047\n",
      "Iteration 5880, loss = 0.00406946\n",
      "Iteration 5881, loss = 0.00406844\n",
      "Iteration 5882, loss = 0.00406754\n",
      "Iteration 5883, loss = 0.00406662\n",
      "Iteration 5884, loss = 0.00406553\n",
      "Iteration 5885, loss = 0.00406453\n",
      "Iteration 5886, loss = 0.00406370\n",
      "Iteration 5887, loss = 0.00406278\n",
      "Iteration 5888, loss = 0.00406176\n",
      "Iteration 5889, loss = 0.00406084\n",
      "Iteration 5890, loss = 0.00406013\n",
      "Iteration 5891, loss = 0.00405876\n",
      "Iteration 5892, loss = 0.00405767\n",
      "Iteration 5893, loss = 0.00405669\n",
      "Iteration 5894, loss = 0.00405600\n",
      "Iteration 5895, loss = 0.00405482\n",
      "Iteration 5896, loss = 0.00405460\n",
      "Iteration 5897, loss = 0.00405303\n",
      "Iteration 5898, loss = 0.00405213\n",
      "Iteration 5899, loss = 0.00405108\n",
      "Iteration 5900, loss = 0.00404988\n",
      "Iteration 5901, loss = 0.00404949\n",
      "Iteration 5902, loss = 0.00404797\n",
      "Iteration 5903, loss = 0.00404692\n",
      "Iteration 5904, loss = 0.00404597\n",
      "Iteration 5905, loss = 0.00404493\n",
      "Iteration 5906, loss = 0.00404391\n",
      "Iteration 5907, loss = 0.00404297\n",
      "Iteration 5908, loss = 0.00404206\n",
      "Iteration 5909, loss = 0.00404088\n",
      "Iteration 5910, loss = 0.00404001\n",
      "Iteration 5911, loss = 0.00403930\n",
      "Iteration 5912, loss = 0.00403825\n",
      "Iteration 5913, loss = 0.00403722\n",
      "Iteration 5914, loss = 0.00403624\n",
      "Iteration 5915, loss = 0.00403514\n",
      "Iteration 5916, loss = 0.00403405\n",
      "Iteration 5917, loss = 0.00403287\n",
      "Iteration 5918, loss = 0.00403169\n",
      "Iteration 5919, loss = 0.00403055\n",
      "Iteration 5920, loss = 0.00402970\n",
      "Iteration 5921, loss = 0.00402925\n",
      "Iteration 5922, loss = 0.00402776\n",
      "Iteration 5923, loss = 0.00402689\n",
      "Iteration 5924, loss = 0.00402576\n",
      "Iteration 5925, loss = 0.00402465\n",
      "Iteration 5926, loss = 0.00402377\n",
      "Iteration 5927, loss = 0.00402259\n",
      "Iteration 5928, loss = 0.00402192\n",
      "Iteration 5929, loss = 0.00402073\n",
      "Iteration 5930, loss = 0.00401986\n",
      "Iteration 5931, loss = 0.00401893\n",
      "Iteration 5932, loss = 0.00401793\n",
      "Iteration 5933, loss = 0.00401709\n",
      "Iteration 5934, loss = 0.00401605\n",
      "Iteration 5935, loss = 0.00401525\n",
      "Iteration 5936, loss = 0.00401424\n",
      "Iteration 5937, loss = 0.00401378\n",
      "Iteration 5938, loss = 0.00401245\n",
      "Iteration 5939, loss = 0.00401164\n",
      "Iteration 5940, loss = 0.00401036\n",
      "Iteration 5941, loss = 0.00400937\n",
      "Iteration 5942, loss = 0.00400840\n",
      "Iteration 5943, loss = 0.00400740\n",
      "Iteration 5944, loss = 0.00400642\n",
      "Iteration 5945, loss = 0.00400547\n",
      "Iteration 5946, loss = 0.00400447\n",
      "Iteration 5947, loss = 0.00400359\n",
      "Iteration 5948, loss = 0.00400254\n",
      "Iteration 5949, loss = 0.00400157\n",
      "Iteration 5950, loss = 0.00400067\n",
      "Iteration 5951, loss = 0.00399958\n",
      "Iteration 5952, loss = 0.00399867\n",
      "Iteration 5953, loss = 0.00399757\n",
      "Iteration 5954, loss = 0.00399661\n",
      "Iteration 5955, loss = 0.00399546\n",
      "Iteration 5956, loss = 0.00399450\n",
      "Iteration 5957, loss = 0.00399377\n",
      "Iteration 5958, loss = 0.00399278\n",
      "Iteration 5959, loss = 0.00399151\n",
      "Iteration 5960, loss = 0.00399039\n",
      "Iteration 5961, loss = 0.00398990\n",
      "Iteration 5962, loss = 0.00398839\n",
      "Iteration 5963, loss = 0.00398774\n",
      "Iteration 5964, loss = 0.00398626\n",
      "Iteration 5965, loss = 0.00398521\n",
      "Iteration 5966, loss = 0.00398434\n",
      "Iteration 5967, loss = 0.00398324\n",
      "Iteration 5968, loss = 0.00398238\n",
      "Iteration 5969, loss = 0.00398138\n",
      "Iteration 5970, loss = 0.00398057\n",
      "Iteration 5971, loss = 0.00397969\n",
      "Iteration 5972, loss = 0.00397879\n",
      "Iteration 5973, loss = 0.00397785\n",
      "Iteration 5974, loss = 0.00397685\n",
      "Iteration 5975, loss = 0.00397614\n",
      "Iteration 5976, loss = 0.00397515\n",
      "Iteration 5977, loss = 0.00397451\n",
      "Iteration 5978, loss = 0.00397315\n",
      "Iteration 5979, loss = 0.00397225\n",
      "Iteration 5980, loss = 0.00397125\n",
      "Iteration 5981, loss = 0.00397044\n",
      "Iteration 5982, loss = 0.00396937\n",
      "Iteration 5983, loss = 0.00396852\n",
      "Iteration 5984, loss = 0.00396744\n",
      "Iteration 5985, loss = 0.00396660\n",
      "Iteration 5986, loss = 0.00396566\n",
      "Iteration 5987, loss = 0.00396465\n",
      "Iteration 5988, loss = 0.00396417\n",
      "Iteration 5989, loss = 0.00396300\n",
      "Iteration 5990, loss = 0.00396189\n",
      "Iteration 5991, loss = 0.00396124\n",
      "Iteration 5992, loss = 0.00396002\n",
      "Iteration 5993, loss = 0.00395894\n",
      "Iteration 5994, loss = 0.00395807\n",
      "Iteration 5995, loss = 0.00395744\n",
      "Iteration 5996, loss = 0.00395616\n",
      "Iteration 5997, loss = 0.00395551\n",
      "Iteration 5998, loss = 0.00395437\n",
      "Iteration 5999, loss = 0.00395342\n",
      "Iteration 6000, loss = 0.00395269\n",
      "Iteration 6001, loss = 0.00395162\n",
      "Iteration 6002, loss = 0.00395067\n",
      "Iteration 6003, loss = 0.00394967\n",
      "Iteration 6004, loss = 0.00394878\n",
      "Iteration 6005, loss = 0.00394804\n",
      "Iteration 6006, loss = 0.00394690\n",
      "Iteration 6007, loss = 0.00394594\n",
      "Iteration 6008, loss = 0.00394497\n",
      "Iteration 6009, loss = 0.00394399\n",
      "Iteration 6010, loss = 0.00394306\n",
      "Iteration 6011, loss = 0.00394230\n",
      "Iteration 6012, loss = 0.00394138\n",
      "Iteration 6013, loss = 0.00394030\n",
      "Iteration 6014, loss = 0.00393956\n",
      "Iteration 6015, loss = 0.00393848\n",
      "Iteration 6016, loss = 0.00393752\n",
      "Iteration 6017, loss = 0.00393661\n",
      "Iteration 6018, loss = 0.00393562\n",
      "Iteration 6019, loss = 0.00393476\n",
      "Iteration 6020, loss = 0.00393374\n",
      "Iteration 6021, loss = 0.00393273\n",
      "Iteration 6022, loss = 0.00393176\n",
      "Iteration 6023, loss = 0.00393167\n",
      "Iteration 6024, loss = 0.00393041\n",
      "Iteration 6025, loss = 0.00392932\n",
      "Iteration 6026, loss = 0.00392865\n",
      "Iteration 6027, loss = 0.00392773\n",
      "Iteration 6028, loss = 0.00392697\n",
      "Iteration 6029, loss = 0.00392598\n",
      "Iteration 6030, loss = 0.00392502\n",
      "Iteration 6031, loss = 0.00392433\n",
      "Iteration 6032, loss = 0.00392350\n",
      "Iteration 6033, loss = 0.00392251\n",
      "Iteration 6034, loss = 0.00392172\n",
      "Iteration 6035, loss = 0.00392088\n",
      "Iteration 6036, loss = 0.00392007\n",
      "Iteration 6037, loss = 0.00391908\n",
      "Iteration 6038, loss = 0.00391818\n",
      "Iteration 6039, loss = 0.00391738\n",
      "Iteration 6040, loss = 0.00391651\n",
      "Iteration 6041, loss = 0.00391566\n",
      "Iteration 6042, loss = 0.00391473\n",
      "Iteration 6043, loss = 0.00391374\n",
      "Iteration 6044, loss = 0.00391330\n",
      "Iteration 6045, loss = 0.00391205\n",
      "Iteration 6046, loss = 0.00391118\n",
      "Iteration 6047, loss = 0.00391016\n",
      "Iteration 6048, loss = 0.00390915\n",
      "Iteration 6049, loss = 0.00390840\n",
      "Iteration 6050, loss = 0.00390736\n",
      "Iteration 6051, loss = 0.00390640\n",
      "Iteration 6052, loss = 0.00390572\n",
      "Iteration 6053, loss = 0.00390478\n",
      "Iteration 6054, loss = 0.00390395\n",
      "Iteration 6055, loss = 0.00390358\n",
      "Iteration 6056, loss = 0.00390248\n",
      "Iteration 6057, loss = 0.00390137\n",
      "Iteration 6058, loss = 0.00390054\n",
      "Iteration 6059, loss = 0.00389961\n",
      "Iteration 6060, loss = 0.00389878\n",
      "Iteration 6061, loss = 0.00389799\n",
      "Iteration 6062, loss = 0.00389706\n",
      "Iteration 6063, loss = 0.00389641\n",
      "Iteration 6064, loss = 0.00389539\n",
      "Iteration 6065, loss = 0.00389454\n",
      "Iteration 6066, loss = 0.00389389\n",
      "Iteration 6067, loss = 0.00389292\n",
      "Iteration 6068, loss = 0.00389196\n",
      "Iteration 6069, loss = 0.00389110\n",
      "Iteration 6070, loss = 0.00389029\n",
      "Iteration 6071, loss = 0.00388941\n",
      "Iteration 6072, loss = 0.00388848\n",
      "Iteration 6073, loss = 0.00388843\n",
      "Iteration 6074, loss = 0.00388692\n",
      "Iteration 6075, loss = 0.00388619\n",
      "Iteration 6076, loss = 0.00388540\n",
      "Iteration 6077, loss = 0.00388436\n",
      "Iteration 6078, loss = 0.00388369\n",
      "Iteration 6079, loss = 0.00388277\n",
      "Iteration 6080, loss = 0.00388189\n",
      "Iteration 6081, loss = 0.00388096\n",
      "Iteration 6082, loss = 0.00388000\n",
      "Iteration 6083, loss = 0.00387922\n",
      "Iteration 6084, loss = 0.00387845\n",
      "Iteration 6085, loss = 0.00387766\n",
      "Iteration 6086, loss = 0.00387660\n",
      "Iteration 6087, loss = 0.00387656\n",
      "Iteration 6088, loss = 0.00387522\n",
      "Iteration 6089, loss = 0.00387431\n",
      "Iteration 6090, loss = 0.00387353\n",
      "Iteration 6091, loss = 0.00387288\n",
      "Iteration 6092, loss = 0.00387235\n",
      "Iteration 6093, loss = 0.00387115\n",
      "Iteration 6094, loss = 0.00387026\n",
      "Iteration 6095, loss = 0.00386937\n",
      "Iteration 6096, loss = 0.00386842\n",
      "Iteration 6097, loss = 0.00386782\n",
      "Iteration 6098, loss = 0.00386668\n",
      "Iteration 6099, loss = 0.00386576\n",
      "Iteration 6100, loss = 0.00386495\n",
      "Iteration 6101, loss = 0.00386393\n",
      "Iteration 6102, loss = 0.00386316\n",
      "Iteration 6103, loss = 0.00386228\n",
      "Iteration 6104, loss = 0.00386149\n",
      "Iteration 6105, loss = 0.00386076\n",
      "Iteration 6106, loss = 0.00386011\n",
      "Iteration 6107, loss = 0.00385917\n",
      "Iteration 6108, loss = 0.00385896\n",
      "Iteration 6109, loss = 0.00385755\n",
      "Iteration 6110, loss = 0.00385638\n",
      "Iteration 6111, loss = 0.00385538\n",
      "Iteration 6112, loss = 0.00385447\n",
      "Iteration 6113, loss = 0.00385356\n",
      "Iteration 6114, loss = 0.00385248\n",
      "Iteration 6115, loss = 0.00385165\n",
      "Iteration 6116, loss = 0.00385073\n",
      "Iteration 6117, loss = 0.00384968\n",
      "Iteration 6118, loss = 0.00384878\n",
      "Iteration 6119, loss = 0.00384785\n",
      "Iteration 6120, loss = 0.00384705\n",
      "Iteration 6121, loss = 0.00384618\n",
      "Iteration 6122, loss = 0.00384526\n",
      "Iteration 6123, loss = 0.00384425\n",
      "Iteration 6124, loss = 0.00384341\n",
      "Iteration 6125, loss = 0.00384255\n",
      "Iteration 6126, loss = 0.00384168\n",
      "Iteration 6127, loss = 0.00384059\n",
      "Iteration 6128, loss = 0.00383946\n",
      "Iteration 6129, loss = 0.00383917\n",
      "Iteration 6130, loss = 0.00383770\n",
      "Iteration 6131, loss = 0.00383668\n",
      "Iteration 6132, loss = 0.00383576\n",
      "Iteration 6133, loss = 0.00383474\n",
      "Iteration 6134, loss = 0.00383398\n",
      "Iteration 6135, loss = 0.00383284\n",
      "Iteration 6136, loss = 0.00383194\n",
      "Iteration 6137, loss = 0.00383125\n",
      "Iteration 6138, loss = 0.00383025\n",
      "Iteration 6139, loss = 0.00382968\n",
      "Iteration 6140, loss = 0.00382858\n",
      "Iteration 6141, loss = 0.00382780\n",
      "Iteration 6142, loss = 0.00382694\n",
      "Iteration 6143, loss = 0.00382615\n",
      "Iteration 6144, loss = 0.00382526\n",
      "Iteration 6145, loss = 0.00382446\n",
      "Iteration 6146, loss = 0.00382329\n",
      "Iteration 6147, loss = 0.00382266\n",
      "Iteration 6148, loss = 0.00382185\n",
      "Iteration 6149, loss = 0.00382056\n",
      "Iteration 6150, loss = 0.00381960\n",
      "Iteration 6151, loss = 0.00381873\n",
      "Iteration 6152, loss = 0.00381794\n",
      "Iteration 6153, loss = 0.00381694\n",
      "Iteration 6154, loss = 0.00381688\n",
      "Iteration 6155, loss = 0.00381513\n",
      "Iteration 6156, loss = 0.00381412\n",
      "Iteration 6157, loss = 0.00381326\n",
      "Iteration 6158, loss = 0.00381237\n",
      "Iteration 6159, loss = 0.00381142\n",
      "Iteration 6160, loss = 0.00381069\n",
      "Iteration 6161, loss = 0.00380980\n",
      "Iteration 6162, loss = 0.00380861\n",
      "Iteration 6163, loss = 0.00380810\n",
      "Iteration 6164, loss = 0.00380692\n",
      "Iteration 6165, loss = 0.00380579\n",
      "Iteration 6166, loss = 0.00380491\n",
      "Iteration 6167, loss = 0.00380399\n",
      "Iteration 6168, loss = 0.00380305\n",
      "Iteration 6169, loss = 0.00380214\n",
      "Iteration 6170, loss = 0.00380138\n",
      "Iteration 6171, loss = 0.00380036\n",
      "Iteration 6172, loss = 0.00379940\n",
      "Iteration 6173, loss = 0.00379843\n",
      "Iteration 6174, loss = 0.00379756\n",
      "Iteration 6175, loss = 0.00379668\n",
      "Iteration 6176, loss = 0.00379568\n",
      "Iteration 6177, loss = 0.00379505\n",
      "Iteration 6178, loss = 0.00379379\n",
      "Iteration 6179, loss = 0.00379301\n",
      "Iteration 6180, loss = 0.00379208\n",
      "Iteration 6181, loss = 0.00379123\n",
      "Iteration 6182, loss = 0.00379030\n",
      "Iteration 6183, loss = 0.00378936\n",
      "Iteration 6184, loss = 0.00378857\n",
      "Iteration 6185, loss = 0.00378773\n",
      "Iteration 6186, loss = 0.00378694\n",
      "Iteration 6187, loss = 0.00378600\n",
      "Iteration 6188, loss = 0.00378511\n",
      "Iteration 6189, loss = 0.00378424\n",
      "Iteration 6190, loss = 0.00378343\n",
      "Iteration 6191, loss = 0.00378278\n",
      "Iteration 6192, loss = 0.00378170\n",
      "Iteration 6193, loss = 0.00378085\n",
      "Iteration 6194, loss = 0.00377989\n",
      "Iteration 6195, loss = 0.00377898\n",
      "Iteration 6196, loss = 0.00377802\n",
      "Iteration 6197, loss = 0.00377716\n",
      "Iteration 6198, loss = 0.00377615\n",
      "Iteration 6199, loss = 0.00377528\n",
      "Iteration 6200, loss = 0.00377438\n",
      "Iteration 6201, loss = 0.00377343\n",
      "Iteration 6202, loss = 0.00377258\n",
      "Iteration 6203, loss = 0.00377177\n",
      "Iteration 6204, loss = 0.00377064\n",
      "Iteration 6205, loss = 0.00376965\n",
      "Iteration 6206, loss = 0.00376926\n",
      "Iteration 6207, loss = 0.00376788\n",
      "Iteration 6208, loss = 0.00376701\n",
      "Iteration 6209, loss = 0.00376660\n",
      "Iteration 6210, loss = 0.00376532\n",
      "Iteration 6211, loss = 0.00376441\n",
      "Iteration 6212, loss = 0.00376347\n",
      "Iteration 6213, loss = 0.00376255\n",
      "Iteration 6214, loss = 0.00376162\n",
      "Iteration 6215, loss = 0.00376085\n",
      "Iteration 6216, loss = 0.00375984\n",
      "Iteration 6217, loss = 0.00375897\n",
      "Iteration 6218, loss = 0.00375824\n",
      "Iteration 6219, loss = 0.00375733\n",
      "Iteration 6220, loss = 0.00375638\n",
      "Iteration 6221, loss = 0.00375568\n",
      "Iteration 6222, loss = 0.00375483\n",
      "Iteration 6223, loss = 0.00375440\n",
      "Iteration 6224, loss = 0.00375285\n",
      "Iteration 6225, loss = 0.00375192\n",
      "Iteration 6226, loss = 0.00375116\n",
      "Iteration 6227, loss = 0.00374996\n",
      "Iteration 6228, loss = 0.00374915\n",
      "Iteration 6229, loss = 0.00374834\n",
      "Iteration 6230, loss = 0.00374773\n",
      "Iteration 6231, loss = 0.00374676\n",
      "Iteration 6232, loss = 0.00374564\n",
      "Iteration 6233, loss = 0.00374499\n",
      "Iteration 6234, loss = 0.00374401\n",
      "Iteration 6235, loss = 0.00374291\n",
      "Iteration 6236, loss = 0.00374205\n",
      "Iteration 6237, loss = 0.00374110\n",
      "Iteration 6238, loss = 0.00374028\n",
      "Iteration 6239, loss = 0.00373959\n",
      "Iteration 6240, loss = 0.00373847\n",
      "Iteration 6241, loss = 0.00373762\n",
      "Iteration 6242, loss = 0.00373676\n",
      "Iteration 6243, loss = 0.00373593\n",
      "Iteration 6244, loss = 0.00373509\n",
      "Iteration 6245, loss = 0.00373425\n",
      "Iteration 6246, loss = 0.00373350\n",
      "Iteration 6247, loss = 0.00373252\n",
      "Iteration 6248, loss = 0.00373169\n",
      "Iteration 6249, loss = 0.00373094\n",
      "Iteration 6250, loss = 0.00373008\n",
      "Iteration 6251, loss = 0.00372939\n",
      "Iteration 6252, loss = 0.00372857\n",
      "Iteration 6253, loss = 0.00372778\n",
      "Iteration 6254, loss = 0.00372694\n",
      "Iteration 6255, loss = 0.00372637\n",
      "Iteration 6256, loss = 0.00372546\n",
      "Iteration 6257, loss = 0.00372486\n",
      "Iteration 6258, loss = 0.00372404\n",
      "Iteration 6259, loss = 0.00372308\n",
      "Iteration 6260, loss = 0.00372231\n",
      "Iteration 6261, loss = 0.00372162\n",
      "Iteration 6262, loss = 0.00372082\n",
      "Iteration 6263, loss = 0.00372017\n",
      "Iteration 6264, loss = 0.00371941\n",
      "Iteration 6265, loss = 0.00371935\n",
      "Iteration 6266, loss = 0.00371812\n",
      "Iteration 6267, loss = 0.00371737\n",
      "Iteration 6268, loss = 0.00371672\n",
      "Iteration 6269, loss = 0.00371591\n",
      "Iteration 6270, loss = 0.00371515\n",
      "Iteration 6271, loss = 0.00371439\n",
      "Iteration 6272, loss = 0.00371369\n",
      "Iteration 6273, loss = 0.00371341\n",
      "Iteration 6274, loss = 0.00371222\n",
      "Iteration 6275, loss = 0.00371127\n",
      "Iteration 6276, loss = 0.00371053\n",
      "Iteration 6277, loss = 0.00370950\n",
      "Iteration 6278, loss = 0.00370903\n",
      "Iteration 6279, loss = 0.00370778\n",
      "Iteration 6280, loss = 0.00370712\n",
      "Iteration 6281, loss = 0.00370599\n",
      "Iteration 6282, loss = 0.00370500\n",
      "Iteration 6283, loss = 0.00370430\n",
      "Iteration 6284, loss = 0.00370381\n",
      "Iteration 6285, loss = 0.00370265\n",
      "Iteration 6286, loss = 0.00370177\n",
      "Iteration 6287, loss = 0.00370101\n",
      "Iteration 6288, loss = 0.00370023\n",
      "Iteration 6289, loss = 0.00369943\n",
      "Iteration 6290, loss = 0.00369864\n",
      "Iteration 6291, loss = 0.00369788\n",
      "Iteration 6292, loss = 0.00369713\n",
      "Iteration 6293, loss = 0.00369637\n",
      "Iteration 6294, loss = 0.00369549\n",
      "Iteration 6295, loss = 0.00369464\n",
      "Iteration 6296, loss = 0.00369381\n",
      "Iteration 6297, loss = 0.00369305\n",
      "Iteration 6298, loss = 0.00369223\n",
      "Iteration 6299, loss = 0.00369156\n",
      "Iteration 6300, loss = 0.00369067\n",
      "Iteration 6301, loss = 0.00368986\n",
      "Iteration 6302, loss = 0.00368949\n",
      "Iteration 6303, loss = 0.00368851\n",
      "Iteration 6304, loss = 0.00368775\n",
      "Iteration 6305, loss = 0.00368699\n",
      "Iteration 6306, loss = 0.00368613\n",
      "Iteration 6307, loss = 0.00368544\n",
      "Iteration 6308, loss = 0.00368466\n",
      "Iteration 6309, loss = 0.00368395\n",
      "Iteration 6310, loss = 0.00368317\n",
      "Iteration 6311, loss = 0.00368250\n",
      "Iteration 6312, loss = 0.00368157\n",
      "Iteration 6313, loss = 0.00368085\n",
      "Iteration 6314, loss = 0.00368015\n",
      "Iteration 6315, loss = 0.00367941\n",
      "Iteration 6316, loss = 0.00367860\n",
      "Iteration 6317, loss = 0.00367772\n",
      "Iteration 6318, loss = 0.00367690\n",
      "Iteration 6319, loss = 0.00367616\n",
      "Iteration 6320, loss = 0.00367530\n",
      "Iteration 6321, loss = 0.00367442\n",
      "Iteration 6322, loss = 0.00367368\n",
      "Iteration 6323, loss = 0.00367292\n",
      "Iteration 6324, loss = 0.00367211\n",
      "Iteration 6325, loss = 0.00367120\n",
      "Iteration 6326, loss = 0.00367055\n",
      "Iteration 6327, loss = 0.00366978\n",
      "Iteration 6328, loss = 0.00366920\n",
      "Iteration 6329, loss = 0.00366834\n",
      "Iteration 6330, loss = 0.00366745\n",
      "Iteration 6331, loss = 0.00366747\n",
      "Iteration 6332, loss = 0.00366627\n",
      "Iteration 6333, loss = 0.00366543\n",
      "Iteration 6334, loss = 0.00366448\n",
      "Iteration 6335, loss = 0.00366438\n",
      "Iteration 6336, loss = 0.00366330\n",
      "Iteration 6337, loss = 0.00366283\n",
      "Iteration 6338, loss = 0.00366202\n",
      "Iteration 6339, loss = 0.00366101\n",
      "Iteration 6340, loss = 0.00366028\n",
      "Iteration 6341, loss = 0.00365939\n",
      "Iteration 6342, loss = 0.00365877\n",
      "Iteration 6343, loss = 0.00365790\n",
      "Iteration 6344, loss = 0.00365721\n",
      "Iteration 6345, loss = 0.00365632\n",
      "Iteration 6346, loss = 0.00365549\n",
      "Iteration 6347, loss = 0.00365469\n",
      "Iteration 6348, loss = 0.00365391\n",
      "Iteration 6349, loss = 0.00365294\n",
      "Iteration 6350, loss = 0.00365201\n",
      "Iteration 6351, loss = 0.00365103\n",
      "Iteration 6352, loss = 0.00364993\n",
      "Iteration 6353, loss = 0.00364893\n",
      "Iteration 6354, loss = 0.00364777\n",
      "Iteration 6355, loss = 0.00364694\n",
      "Iteration 6356, loss = 0.00364675\n",
      "Iteration 6357, loss = 0.00364506\n",
      "Iteration 6358, loss = 0.00364417\n",
      "Iteration 6359, loss = 0.00364326\n",
      "Iteration 6360, loss = 0.00364252\n",
      "Iteration 6361, loss = 0.00364159\n",
      "Iteration 6362, loss = 0.00364065\n",
      "Iteration 6363, loss = 0.00363976\n",
      "Iteration 6364, loss = 0.00363864\n",
      "Iteration 6365, loss = 0.00363767\n",
      "Iteration 6366, loss = 0.00363692\n",
      "Iteration 6367, loss = 0.00363582\n",
      "Iteration 6368, loss = 0.00363495\n",
      "Iteration 6369, loss = 0.00363398\n",
      "Iteration 6370, loss = 0.00363296\n",
      "Iteration 6371, loss = 0.00363210\n",
      "Iteration 6372, loss = 0.00363130\n",
      "Iteration 6373, loss = 0.00363050\n",
      "Iteration 6374, loss = 0.00362962\n",
      "Iteration 6375, loss = 0.00362887\n",
      "Iteration 6376, loss = 0.00362818\n",
      "Iteration 6377, loss = 0.00362724\n",
      "Iteration 6378, loss = 0.00362667\n",
      "Iteration 6379, loss = 0.00362566\n",
      "Iteration 6380, loss = 0.00362478\n",
      "Iteration 6381, loss = 0.00362389\n",
      "Iteration 6382, loss = 0.00362304\n",
      "Iteration 6383, loss = 0.00362215\n",
      "Iteration 6384, loss = 0.00362150\n",
      "Iteration 6385, loss = 0.00362038\n",
      "Iteration 6386, loss = 0.00361943\n",
      "Iteration 6387, loss = 0.00361868\n",
      "Iteration 6388, loss = 0.00361776\n",
      "Iteration 6389, loss = 0.00361767\n",
      "Iteration 6390, loss = 0.00361617\n",
      "Iteration 6391, loss = 0.00361539\n",
      "Iteration 6392, loss = 0.00361458\n",
      "Iteration 6393, loss = 0.00361369\n",
      "Iteration 6394, loss = 0.00361319\n",
      "Iteration 6395, loss = 0.00361222\n",
      "Iteration 6396, loss = 0.00361135\n",
      "Iteration 6397, loss = 0.00361038\n",
      "Iteration 6398, loss = 0.00360956\n",
      "Iteration 6399, loss = 0.00360886\n",
      "Iteration 6400, loss = 0.00360784\n",
      "Iteration 6401, loss = 0.00360701\n",
      "Iteration 6402, loss = 0.00360672\n",
      "Iteration 6403, loss = 0.00360525\n",
      "Iteration 6404, loss = 0.00360442\n",
      "Iteration 6405, loss = 0.00360351\n",
      "Iteration 6406, loss = 0.00360266\n",
      "Iteration 6407, loss = 0.00360182\n",
      "Iteration 6408, loss = 0.00360100\n",
      "Iteration 6409, loss = 0.00360017\n",
      "Iteration 6410, loss = 0.00359940\n",
      "Iteration 6411, loss = 0.00359893\n",
      "Iteration 6412, loss = 0.00359791\n",
      "Iteration 6413, loss = 0.00359717\n",
      "Iteration 6414, loss = 0.00359638\n",
      "Iteration 6415, loss = 0.00359552\n",
      "Iteration 6416, loss = 0.00359504\n",
      "Iteration 6417, loss = 0.00359419\n",
      "Iteration 6418, loss = 0.00359306\n",
      "Iteration 6419, loss = 0.00359224\n",
      "Iteration 6420, loss = 0.00359136\n",
      "Iteration 6421, loss = 0.00359071\n",
      "Iteration 6422, loss = 0.00358978\n",
      "Iteration 6423, loss = 0.00358882\n",
      "Iteration 6424, loss = 0.00358800\n",
      "Iteration 6425, loss = 0.00358729\n",
      "Iteration 6426, loss = 0.00358665\n",
      "Iteration 6427, loss = 0.00358573\n",
      "Iteration 6428, loss = 0.00358488\n",
      "Iteration 6429, loss = 0.00358407\n",
      "Iteration 6430, loss = 0.00358325\n",
      "Iteration 6431, loss = 0.00358277\n",
      "Iteration 6432, loss = 0.00358178\n",
      "Iteration 6433, loss = 0.00358108\n",
      "Iteration 6434, loss = 0.00358018\n",
      "Iteration 6435, loss = 0.00357926\n",
      "Iteration 6436, loss = 0.00357867\n",
      "Iteration 6437, loss = 0.00357764\n",
      "Iteration 6438, loss = 0.00357680\n",
      "Iteration 6439, loss = 0.00357599\n",
      "Iteration 6440, loss = 0.00357518\n",
      "Iteration 6441, loss = 0.00357442\n",
      "Iteration 6442, loss = 0.00357367\n",
      "Iteration 6443, loss = 0.00357295\n",
      "Iteration 6444, loss = 0.00357242\n",
      "Iteration 6445, loss = 0.00357159\n",
      "Iteration 6446, loss = 0.00357094\n",
      "Iteration 6447, loss = 0.00357019\n",
      "Iteration 6448, loss = 0.00356957\n",
      "Iteration 6449, loss = 0.00356874\n",
      "Iteration 6450, loss = 0.00356796\n",
      "Iteration 6451, loss = 0.00356707\n",
      "Iteration 6452, loss = 0.00356651\n",
      "Iteration 6453, loss = 0.00356555\n",
      "Iteration 6454, loss = 0.00356473\n",
      "Iteration 6455, loss = 0.00356380\n",
      "Iteration 6456, loss = 0.00356304\n",
      "Iteration 6457, loss = 0.00356215\n",
      "Iteration 6458, loss = 0.00356149\n",
      "Iteration 6459, loss = 0.00356066\n",
      "Iteration 6460, loss = 0.00355986\n",
      "Iteration 6461, loss = 0.00355933\n",
      "Iteration 6462, loss = 0.00355838\n",
      "Iteration 6463, loss = 0.00355764\n",
      "Iteration 6464, loss = 0.00355692\n",
      "Iteration 6465, loss = 0.00355626\n",
      "Iteration 6466, loss = 0.00355536\n",
      "Iteration 6467, loss = 0.00355457\n",
      "Iteration 6468, loss = 0.00355387\n",
      "Iteration 6469, loss = 0.00355310\n",
      "Iteration 6470, loss = 0.00355229\n",
      "Iteration 6471, loss = 0.00355159\n",
      "Iteration 6472, loss = 0.00355067\n",
      "Iteration 6473, loss = 0.00354982\n",
      "Iteration 6474, loss = 0.00354908\n",
      "Iteration 6475, loss = 0.00354825\n",
      "Iteration 6476, loss = 0.00354742\n",
      "Iteration 6477, loss = 0.00354656\n",
      "Iteration 6478, loss = 0.00354578\n",
      "Iteration 6479, loss = 0.00354504\n",
      "Iteration 6480, loss = 0.00354423\n",
      "Iteration 6481, loss = 0.00354325\n",
      "Iteration 6482, loss = 0.00354267\n",
      "Iteration 6483, loss = 0.00354169\n",
      "Iteration 6484, loss = 0.00354097\n",
      "Iteration 6485, loss = 0.00354015\n",
      "Iteration 6486, loss = 0.00353944\n",
      "Iteration 6487, loss = 0.00353869\n",
      "Iteration 6488, loss = 0.00353798\n",
      "Iteration 6489, loss = 0.00353729\n",
      "Iteration 6490, loss = 0.00353653\n",
      "Iteration 6491, loss = 0.00353568\n",
      "Iteration 6492, loss = 0.00353487\n",
      "Iteration 6493, loss = 0.00353410\n",
      "Iteration 6494, loss = 0.00353321\n",
      "Iteration 6495, loss = 0.00353234\n",
      "Iteration 6496, loss = 0.00353161\n",
      "Iteration 6497, loss = 0.00353091\n",
      "Iteration 6498, loss = 0.00353004\n",
      "Iteration 6499, loss = 0.00352930\n",
      "Iteration 6500, loss = 0.00352849\n",
      "Iteration 6501, loss = 0.00352773\n",
      "Iteration 6502, loss = 0.00352701\n",
      "Iteration 6503, loss = 0.00352693\n",
      "Iteration 6504, loss = 0.00352582\n",
      "Iteration 6505, loss = 0.00352493\n",
      "Iteration 6506, loss = 0.00352428\n",
      "Iteration 6507, loss = 0.00352332\n",
      "Iteration 6508, loss = 0.00352269\n",
      "Iteration 6509, loss = 0.00352192\n",
      "Iteration 6510, loss = 0.00352105\n",
      "Iteration 6511, loss = 0.00352034\n",
      "Iteration 6512, loss = 0.00351967\n",
      "Iteration 6513, loss = 0.00351886\n",
      "Iteration 6514, loss = 0.00351829\n",
      "Iteration 6515, loss = 0.00351781\n",
      "Iteration 6516, loss = 0.00351667\n",
      "Iteration 6517, loss = 0.00351595\n",
      "Iteration 6518, loss = 0.00351512\n",
      "Iteration 6519, loss = 0.00351428\n",
      "Iteration 6520, loss = 0.00351344\n",
      "Iteration 6521, loss = 0.00351249\n",
      "Iteration 6522, loss = 0.00351196\n",
      "Iteration 6523, loss = 0.00351119\n",
      "Iteration 6524, loss = 0.00351042\n",
      "Iteration 6525, loss = 0.00350953\n",
      "Iteration 6526, loss = 0.00350855\n",
      "Iteration 6527, loss = 0.00350793\n",
      "Iteration 6528, loss = 0.00350687\n",
      "Iteration 6529, loss = 0.00350623\n",
      "Iteration 6530, loss = 0.00350533\n",
      "Iteration 6531, loss = 0.00350446\n",
      "Iteration 6532, loss = 0.00350365\n",
      "Iteration 6533, loss = 0.00350306\n",
      "Iteration 6534, loss = 0.00350223\n",
      "Iteration 6535, loss = 0.00350140\n",
      "Iteration 6536, loss = 0.00350065\n",
      "Iteration 6537, loss = 0.00349982\n",
      "Iteration 6538, loss = 0.00349920\n",
      "Iteration 6539, loss = 0.00349836\n",
      "Iteration 6540, loss = 0.00349790\n",
      "Iteration 6541, loss = 0.00349702\n",
      "Iteration 6542, loss = 0.00349647\n",
      "Iteration 6543, loss = 0.00349562\n",
      "Iteration 6544, loss = 0.00349492\n",
      "Iteration 6545, loss = 0.00349414\n",
      "Iteration 6546, loss = 0.00349348\n",
      "Iteration 6547, loss = 0.00349286\n",
      "Iteration 6548, loss = 0.00349269\n",
      "Iteration 6549, loss = 0.00349139\n",
      "Iteration 6550, loss = 0.00349071\n",
      "Iteration 6551, loss = 0.00348995\n",
      "Iteration 6552, loss = 0.00348918\n",
      "Iteration 6553, loss = 0.00348824\n",
      "Iteration 6554, loss = 0.00348761\n",
      "Iteration 6555, loss = 0.00348693\n",
      "Iteration 6556, loss = 0.00348603\n",
      "Iteration 6557, loss = 0.00348518\n",
      "Iteration 6558, loss = 0.00348442\n",
      "Iteration 6559, loss = 0.00348384\n",
      "Iteration 6560, loss = 0.00348308\n",
      "Iteration 6561, loss = 0.00348216\n",
      "Iteration 6562, loss = 0.00348131\n",
      "Iteration 6563, loss = 0.00348058\n",
      "Iteration 6564, loss = 0.00347973\n",
      "Iteration 6565, loss = 0.00347895\n",
      "Iteration 6566, loss = 0.00347808\n",
      "Iteration 6567, loss = 0.00347741\n",
      "Iteration 6568, loss = 0.00347665\n",
      "Iteration 6569, loss = 0.00347574\n",
      "Iteration 6570, loss = 0.00347527\n",
      "Iteration 6571, loss = 0.00347441\n",
      "Iteration 6572, loss = 0.00347369\n",
      "Iteration 6573, loss = 0.00347285\n",
      "Iteration 6574, loss = 0.00347215\n",
      "Iteration 6575, loss = 0.00347149\n",
      "Iteration 6576, loss = 0.00347071\n",
      "Iteration 6577, loss = 0.00347005\n",
      "Iteration 6578, loss = 0.00346923\n",
      "Iteration 6579, loss = 0.00346852\n",
      "Iteration 6580, loss = 0.00346771\n",
      "Iteration 6581, loss = 0.00346704\n",
      "Iteration 6582, loss = 0.00346630\n",
      "Iteration 6583, loss = 0.00346548\n",
      "Iteration 6584, loss = 0.00346464\n",
      "Iteration 6585, loss = 0.00346386\n",
      "Iteration 6586, loss = 0.00346309\n",
      "Iteration 6587, loss = 0.00346238\n",
      "Iteration 6588, loss = 0.00346151\n",
      "Iteration 6589, loss = 0.00346078\n",
      "Iteration 6590, loss = 0.00346006\n",
      "Iteration 6591, loss = 0.00345912\n",
      "Iteration 6592, loss = 0.00345867\n",
      "Iteration 6593, loss = 0.00345762\n",
      "Iteration 6594, loss = 0.00345693\n",
      "Iteration 6595, loss = 0.00345611\n",
      "Iteration 6596, loss = 0.00345562\n",
      "Iteration 6597, loss = 0.00345477\n",
      "Iteration 6598, loss = 0.00345378\n",
      "Iteration 6599, loss = 0.00345297\n",
      "Iteration 6600, loss = 0.00345217\n",
      "Iteration 6601, loss = 0.00345137\n",
      "Iteration 6602, loss = 0.00345078\n",
      "Iteration 6603, loss = 0.00344997\n",
      "Iteration 6604, loss = 0.00344954\n",
      "Iteration 6605, loss = 0.00344849\n",
      "Iteration 6606, loss = 0.00344805\n",
      "Iteration 6607, loss = 0.00344700\n",
      "Iteration 6608, loss = 0.00344624\n",
      "Iteration 6609, loss = 0.00344549\n",
      "Iteration 6610, loss = 0.00344483\n",
      "Iteration 6611, loss = 0.00344418\n",
      "Iteration 6612, loss = 0.00344366\n",
      "Iteration 6613, loss = 0.00344288\n",
      "Iteration 6614, loss = 0.00344227\n",
      "Iteration 6615, loss = 0.00344154\n",
      "Iteration 6616, loss = 0.00344088\n",
      "Iteration 6617, loss = 0.00344022\n",
      "Iteration 6618, loss = 0.00343955\n",
      "Iteration 6619, loss = 0.00343889\n",
      "Iteration 6620, loss = 0.00343846\n",
      "Iteration 6621, loss = 0.00343755\n",
      "Iteration 6622, loss = 0.00343682\n",
      "Iteration 6623, loss = 0.00343615\n",
      "Iteration 6624, loss = 0.00343574\n",
      "Iteration 6625, loss = 0.00343485\n",
      "Iteration 6626, loss = 0.00343404\n",
      "Iteration 6627, loss = 0.00343327\n",
      "Iteration 6628, loss = 0.00343250\n",
      "Iteration 6629, loss = 0.00343218\n",
      "Iteration 6630, loss = 0.00343127\n",
      "Iteration 6631, loss = 0.00343069\n",
      "Iteration 6632, loss = 0.00342976\n",
      "Iteration 6633, loss = 0.00342885\n",
      "Iteration 6634, loss = 0.00342823\n",
      "Iteration 6635, loss = 0.00342756\n",
      "Iteration 6636, loss = 0.00342664\n",
      "Iteration 6637, loss = 0.00342604\n",
      "Iteration 6638, loss = 0.00342548\n",
      "Iteration 6639, loss = 0.00342457\n",
      "Iteration 6640, loss = 0.00342382\n",
      "Iteration 6641, loss = 0.00342329\n",
      "Iteration 6642, loss = 0.00342235\n",
      "Iteration 6643, loss = 0.00342166\n",
      "Iteration 6644, loss = 0.00342094\n",
      "Iteration 6645, loss = 0.00342028\n",
      "Iteration 6646, loss = 0.00341946\n",
      "Iteration 6647, loss = 0.00341855\n",
      "Iteration 6648, loss = 0.00341812\n",
      "Iteration 6649, loss = 0.00341704\n",
      "Iteration 6650, loss = 0.00341629\n",
      "Iteration 6651, loss = 0.00341555\n",
      "Iteration 6652, loss = 0.00341491\n",
      "Iteration 6653, loss = 0.00341402\n",
      "Iteration 6654, loss = 0.00341319\n",
      "Iteration 6655, loss = 0.00341237\n",
      "Iteration 6656, loss = 0.00341182\n",
      "Iteration 6657, loss = 0.00341099\n",
      "Iteration 6658, loss = 0.00341031\n",
      "Iteration 6659, loss = 0.00340994\n",
      "Iteration 6660, loss = 0.00340897\n",
      "Iteration 6661, loss = 0.00340824\n",
      "Iteration 6662, loss = 0.00340752\n",
      "Iteration 6663, loss = 0.00340682\n",
      "Iteration 6664, loss = 0.00340609\n",
      "Iteration 6665, loss = 0.00340535\n",
      "Iteration 6666, loss = 0.00340506\n",
      "Iteration 6667, loss = 0.00340403\n",
      "Iteration 6668, loss = 0.00340340\n",
      "Iteration 6669, loss = 0.00340265\n",
      "Iteration 6670, loss = 0.00340200\n",
      "Iteration 6671, loss = 0.00340138\n",
      "Iteration 6672, loss = 0.00340073\n",
      "Iteration 6673, loss = 0.00340007\n",
      "Iteration 6674, loss = 0.00339958\n",
      "Iteration 6675, loss = 0.00339861\n",
      "Iteration 6676, loss = 0.00339783\n",
      "Iteration 6677, loss = 0.00339702\n",
      "Iteration 6678, loss = 0.00339642\n",
      "Iteration 6679, loss = 0.00339555\n",
      "Iteration 6680, loss = 0.00339477\n",
      "Iteration 6681, loss = 0.00339433\n",
      "Iteration 6682, loss = 0.00339337\n",
      "Iteration 6683, loss = 0.00339296\n",
      "Iteration 6684, loss = 0.00339202\n",
      "Iteration 6685, loss = 0.00339138\n",
      "Iteration 6686, loss = 0.00339071\n",
      "Iteration 6687, loss = 0.00338995\n",
      "Iteration 6688, loss = 0.00338932\n",
      "Iteration 6689, loss = 0.00338872\n",
      "Iteration 6690, loss = 0.00338800\n",
      "Iteration 6691, loss = 0.00338727\n",
      "Iteration 6692, loss = 0.00338652\n",
      "Iteration 6693, loss = 0.00338589\n",
      "Iteration 6694, loss = 0.00338525\n",
      "Iteration 6695, loss = 0.00338455\n",
      "Iteration 6696, loss = 0.00338388\n",
      "Iteration 6697, loss = 0.00338339\n",
      "Iteration 6698, loss = 0.00338253\n",
      "Iteration 6699, loss = 0.00338186\n",
      "Iteration 6700, loss = 0.00338109\n",
      "Iteration 6701, loss = 0.00338087\n",
      "Iteration 6702, loss = 0.00337952\n",
      "Iteration 6703, loss = 0.00337897\n",
      "Iteration 6704, loss = 0.00337815\n",
      "Iteration 6705, loss = 0.00337747\n",
      "Iteration 6706, loss = 0.00337660\n",
      "Iteration 6707, loss = 0.00337580\n",
      "Iteration 6708, loss = 0.00337512\n",
      "Iteration 6709, loss = 0.00337425\n",
      "Iteration 6710, loss = 0.00337350\n",
      "Iteration 6711, loss = 0.00337281\n",
      "Iteration 6712, loss = 0.00337200\n",
      "Iteration 6713, loss = 0.00337137\n",
      "Iteration 6714, loss = 0.00337071\n",
      "Iteration 6715, loss = 0.00336983\n",
      "Iteration 6716, loss = 0.00336967\n",
      "Iteration 6717, loss = 0.00336840\n",
      "Iteration 6718, loss = 0.00336775\n",
      "Iteration 6719, loss = 0.00336707\n",
      "Iteration 6720, loss = 0.00336621\n",
      "Iteration 6721, loss = 0.00336546\n",
      "Iteration 6722, loss = 0.00336483\n",
      "Iteration 6723, loss = 0.00336402\n",
      "Iteration 6724, loss = 0.00336324\n",
      "Iteration 6725, loss = 0.00336254\n",
      "Iteration 6726, loss = 0.00336183\n",
      "Iteration 6727, loss = 0.00336108\n",
      "Iteration 6728, loss = 0.00336028\n",
      "Iteration 6729, loss = 0.00335956\n",
      "Iteration 6730, loss = 0.00335883\n",
      "Iteration 6731, loss = 0.00335805\n",
      "Iteration 6732, loss = 0.00335739\n",
      "Iteration 6733, loss = 0.00335656\n",
      "Iteration 6734, loss = 0.00335570\n",
      "Iteration 6735, loss = 0.00335494\n",
      "Iteration 6736, loss = 0.00335430\n",
      "Iteration 6737, loss = 0.00335354\n",
      "Iteration 6738, loss = 0.00335280\n",
      "Iteration 6739, loss = 0.00335212\n",
      "Iteration 6740, loss = 0.00335154\n",
      "Iteration 6741, loss = 0.00335093\n",
      "Iteration 6742, loss = 0.00335026\n",
      "Iteration 6743, loss = 0.00334963\n",
      "Iteration 6744, loss = 0.00334905\n",
      "Iteration 6745, loss = 0.00334842\n",
      "Iteration 6746, loss = 0.00334779\n",
      "Iteration 6747, loss = 0.00334722\n",
      "Iteration 6748, loss = 0.00334662\n",
      "Iteration 6749, loss = 0.00334595\n",
      "Iteration 6750, loss = 0.00334533\n",
      "Iteration 6751, loss = 0.00334470\n",
      "Iteration 6752, loss = 0.00334400\n",
      "Iteration 6753, loss = 0.00334323\n",
      "Iteration 6754, loss = 0.00334256\n",
      "Iteration 6755, loss = 0.00334179\n",
      "Iteration 6756, loss = 0.00334124\n",
      "Iteration 6757, loss = 0.00334048\n",
      "Iteration 6758, loss = 0.00334000\n",
      "Iteration 6759, loss = 0.00333920\n",
      "Iteration 6760, loss = 0.00333843\n",
      "Iteration 6761, loss = 0.00333794\n",
      "Iteration 6762, loss = 0.00333703\n",
      "Iteration 6763, loss = 0.00333635\n",
      "Iteration 6764, loss = 0.00333561\n",
      "Iteration 6765, loss = 0.00333485\n",
      "Iteration 6766, loss = 0.00333422\n",
      "Iteration 6767, loss = 0.00333372\n",
      "Iteration 6768, loss = 0.00333290\n",
      "Iteration 6769, loss = 0.00333220\n",
      "Iteration 6770, loss = 0.00333154\n",
      "Iteration 6771, loss = 0.00333086\n",
      "Iteration 6772, loss = 0.00333013\n",
      "Iteration 6773, loss = 0.00332964\n",
      "Iteration 6774, loss = 0.00332880\n",
      "Iteration 6775, loss = 0.00332798\n",
      "Iteration 6776, loss = 0.00332739\n",
      "Iteration 6777, loss = 0.00332656\n",
      "Iteration 6778, loss = 0.00332583\n",
      "Iteration 6779, loss = 0.00332500\n",
      "Iteration 6780, loss = 0.00332424\n",
      "Iteration 6781, loss = 0.00332351\n",
      "Iteration 6782, loss = 0.00332298\n",
      "Iteration 6783, loss = 0.00332202\n",
      "Iteration 6784, loss = 0.00332134\n",
      "Iteration 6785, loss = 0.00332068\n",
      "Iteration 6786, loss = 0.00331988\n",
      "Iteration 6787, loss = 0.00331916\n",
      "Iteration 6788, loss = 0.00331847\n",
      "Iteration 6789, loss = 0.00331781\n",
      "Iteration 6790, loss = 0.00331694\n",
      "Iteration 6791, loss = 0.00331633\n",
      "Iteration 6792, loss = 0.00331561\n",
      "Iteration 6793, loss = 0.00331508\n",
      "Iteration 6794, loss = 0.00331420\n",
      "Iteration 6795, loss = 0.00331364\n",
      "Iteration 6796, loss = 0.00331293\n",
      "Iteration 6797, loss = 0.00331209\n",
      "Iteration 6798, loss = 0.00331142\n",
      "Iteration 6799, loss = 0.00331075\n",
      "Iteration 6800, loss = 0.00331012\n",
      "Iteration 6801, loss = 0.00330958\n",
      "Iteration 6802, loss = 0.00330888\n",
      "Iteration 6803, loss = 0.00330825\n",
      "Iteration 6804, loss = 0.00330756\n",
      "Iteration 6805, loss = 0.00330702\n",
      "Iteration 6806, loss = 0.00330640\n",
      "Iteration 6807, loss = 0.00330599\n",
      "Iteration 6808, loss = 0.00330522\n",
      "Iteration 6809, loss = 0.00330450\n",
      "Iteration 6810, loss = 0.00330382\n",
      "Iteration 6811, loss = 0.00330338\n",
      "Iteration 6812, loss = 0.00330282\n",
      "Iteration 6813, loss = 0.00330216\n",
      "Iteration 6814, loss = 0.00330152\n",
      "Iteration 6815, loss = 0.00330091\n",
      "Iteration 6816, loss = 0.00330057\n",
      "Iteration 6817, loss = 0.00329965\n",
      "Iteration 6818, loss = 0.00329902\n",
      "Iteration 6819, loss = 0.00329841\n",
      "Iteration 6820, loss = 0.00329769\n",
      "Iteration 6821, loss = 0.00329709\n",
      "Iteration 6822, loss = 0.00329646\n",
      "Iteration 6823, loss = 0.00329579\n",
      "Iteration 6824, loss = 0.00329507\n",
      "Iteration 6825, loss = 0.00329436\n",
      "Iteration 6826, loss = 0.00329356\n",
      "Iteration 6827, loss = 0.00329298\n",
      "Iteration 6828, loss = 0.00329220\n",
      "Iteration 6829, loss = 0.00329149\n",
      "Iteration 6830, loss = 0.00329071\n",
      "Iteration 6831, loss = 0.00329012\n",
      "Iteration 6832, loss = 0.00328941\n",
      "Iteration 6833, loss = 0.00328887\n",
      "Iteration 6834, loss = 0.00328795\n",
      "Iteration 6835, loss = 0.00328723\n",
      "Iteration 6836, loss = 0.00328652\n",
      "Iteration 6837, loss = 0.00328579\n",
      "Iteration 6838, loss = 0.00328511\n",
      "Iteration 6839, loss = 0.00328418\n",
      "Iteration 6840, loss = 0.00328392\n",
      "Iteration 6841, loss = 0.00328340\n",
      "Iteration 6842, loss = 0.00328228\n",
      "Iteration 6843, loss = 0.00328150\n",
      "Iteration 6844, loss = 0.00328073\n",
      "Iteration 6845, loss = 0.00328015\n",
      "Iteration 6846, loss = 0.00327947\n",
      "Iteration 6847, loss = 0.00327863\n",
      "Iteration 6848, loss = 0.00327790\n",
      "Iteration 6849, loss = 0.00327716\n",
      "Iteration 6850, loss = 0.00327655\n",
      "Iteration 6851, loss = 0.00327580\n",
      "Iteration 6852, loss = 0.00327511\n",
      "Iteration 6853, loss = 0.00327447\n",
      "Iteration 6854, loss = 0.00327383\n",
      "Iteration 6855, loss = 0.00327311\n",
      "Iteration 6856, loss = 0.00327256\n",
      "Iteration 6857, loss = 0.00327201\n",
      "Iteration 6858, loss = 0.00327111\n",
      "Iteration 6859, loss = 0.00327061\n",
      "Iteration 6860, loss = 0.00326975\n",
      "Iteration 6861, loss = 0.00326937\n",
      "Iteration 6862, loss = 0.00326840\n",
      "Iteration 6863, loss = 0.00326770\n",
      "Iteration 6864, loss = 0.00326701\n",
      "Iteration 6865, loss = 0.00326646\n",
      "Iteration 6866, loss = 0.00326571\n",
      "Iteration 6867, loss = 0.00326492\n",
      "Iteration 6868, loss = 0.00326451\n",
      "Iteration 6869, loss = 0.00326372\n",
      "Iteration 6870, loss = 0.00326315\n",
      "Iteration 6871, loss = 0.00326249\n",
      "Iteration 6872, loss = 0.00326229\n",
      "Iteration 6873, loss = 0.00326122\n",
      "Iteration 6874, loss = 0.00326055\n",
      "Iteration 6875, loss = 0.00325995\n",
      "Iteration 6876, loss = 0.00325920\n",
      "Iteration 6877, loss = 0.00325860\n",
      "Iteration 6878, loss = 0.00325833\n",
      "Iteration 6879, loss = 0.00325731\n",
      "Iteration 6880, loss = 0.00325658\n",
      "Iteration 6881, loss = 0.00325595\n",
      "Iteration 6882, loss = 0.00325536\n",
      "Iteration 6883, loss = 0.00325459\n",
      "Iteration 6884, loss = 0.00325402\n",
      "Iteration 6885, loss = 0.00325335\n",
      "Iteration 6886, loss = 0.00325274\n",
      "Iteration 6887, loss = 0.00325199\n",
      "Iteration 6888, loss = 0.00325137\n",
      "Iteration 6889, loss = 0.00325074\n",
      "Iteration 6890, loss = 0.00325004\n",
      "Iteration 6891, loss = 0.00324950\n",
      "Iteration 6892, loss = 0.00324899\n",
      "Iteration 6893, loss = 0.00324826\n",
      "Iteration 6894, loss = 0.00324762\n",
      "Iteration 6895, loss = 0.00324697\n",
      "Iteration 6896, loss = 0.00324648\n",
      "Iteration 6897, loss = 0.00324592\n",
      "Iteration 6898, loss = 0.00324512\n",
      "Iteration 6899, loss = 0.00324457\n",
      "Iteration 6900, loss = 0.00324379\n",
      "Iteration 6901, loss = 0.00324318\n",
      "Iteration 6902, loss = 0.00324269\n",
      "Iteration 6903, loss = 0.00324187\n",
      "Iteration 6904, loss = 0.00324110\n",
      "Iteration 6905, loss = 0.00324081\n",
      "Iteration 6906, loss = 0.00323999\n",
      "Iteration 6907, loss = 0.00323982\n",
      "Iteration 6908, loss = 0.00323868\n",
      "Iteration 6909, loss = 0.00323799\n",
      "Iteration 6910, loss = 0.00323723\n",
      "Iteration 6911, loss = 0.00323654\n",
      "Iteration 6912, loss = 0.00323573\n",
      "Iteration 6913, loss = 0.00323515\n",
      "Iteration 6914, loss = 0.00323443\n",
      "Iteration 6915, loss = 0.00323358\n",
      "Iteration 6916, loss = 0.00323297\n",
      "Iteration 6917, loss = 0.00323222\n",
      "Iteration 6918, loss = 0.00323172\n",
      "Iteration 6919, loss = 0.00323122\n",
      "Iteration 6920, loss = 0.00323042\n",
      "Iteration 6921, loss = 0.00322981\n",
      "Iteration 6922, loss = 0.00322932\n",
      "Iteration 6923, loss = 0.00322876\n",
      "Iteration 6924, loss = 0.00322808\n",
      "Iteration 6925, loss = 0.00322733\n",
      "Iteration 6926, loss = 0.00322667\n",
      "Iteration 6927, loss = 0.00322594\n",
      "Iteration 6928, loss = 0.00322536\n",
      "Iteration 6929, loss = 0.00322463\n",
      "Iteration 6930, loss = 0.00322407\n",
      "Iteration 6931, loss = 0.00322332\n",
      "Iteration 6932, loss = 0.00322286\n",
      "Iteration 6933, loss = 0.00322204\n",
      "Iteration 6934, loss = 0.00322143\n",
      "Iteration 6935, loss = 0.00322070\n",
      "Iteration 6936, loss = 0.00321994\n",
      "Iteration 6937, loss = 0.00321928\n",
      "Iteration 6938, loss = 0.00321868\n",
      "Iteration 6939, loss = 0.00321791\n",
      "Iteration 6940, loss = 0.00321734\n",
      "Iteration 6941, loss = 0.00321655\n",
      "Iteration 6942, loss = 0.00321586\n",
      "Iteration 6943, loss = 0.00321519\n",
      "Iteration 6944, loss = 0.00321465\n",
      "Iteration 6945, loss = 0.00321398\n",
      "Iteration 6946, loss = 0.00321316\n",
      "Iteration 6947, loss = 0.00321239\n",
      "Iteration 6948, loss = 0.00321161\n",
      "Iteration 6949, loss = 0.00321082\n",
      "Iteration 6950, loss = 0.00321004\n",
      "Iteration 6951, loss = 0.00320941\n",
      "Iteration 6952, loss = 0.00320874\n",
      "Iteration 6953, loss = 0.00320832\n",
      "Iteration 6954, loss = 0.00320728\n",
      "Iteration 6955, loss = 0.00320662\n",
      "Iteration 6956, loss = 0.00320584\n",
      "Iteration 6957, loss = 0.00320515\n",
      "Iteration 6958, loss = 0.00320449\n",
      "Iteration 6959, loss = 0.00320376\n",
      "Iteration 6960, loss = 0.00320309\n",
      "Iteration 6961, loss = 0.00320240\n",
      "Iteration 6962, loss = 0.00320174\n",
      "Iteration 6963, loss = 0.00320103\n",
      "Iteration 6964, loss = 0.00320033\n",
      "Iteration 6965, loss = 0.00319965\n",
      "Iteration 6966, loss = 0.00319906\n",
      "Iteration 6967, loss = 0.00319842\n",
      "Iteration 6968, loss = 0.00319782\n",
      "Iteration 6969, loss = 0.00319720\n",
      "Iteration 6970, loss = 0.00319656\n",
      "Iteration 6971, loss = 0.00319610\n",
      "Iteration 6972, loss = 0.00319540\n",
      "Iteration 6973, loss = 0.00319456\n",
      "Iteration 6974, loss = 0.00319395\n",
      "Iteration 6975, loss = 0.00319319\n",
      "Iteration 6976, loss = 0.00319258\n",
      "Iteration 6977, loss = 0.00319200\n",
      "Iteration 6978, loss = 0.00319137\n",
      "Iteration 6979, loss = 0.00319042\n",
      "Iteration 6980, loss = 0.00318974\n",
      "Iteration 6981, loss = 0.00318894\n",
      "Iteration 6982, loss = 0.00318857\n",
      "Iteration 6983, loss = 0.00318760\n",
      "Iteration 6984, loss = 0.00318690\n",
      "Iteration 6985, loss = 0.00318628\n",
      "Iteration 6986, loss = 0.00318570\n",
      "Iteration 6987, loss = 0.00318492\n",
      "Iteration 6988, loss = 0.00318424\n",
      "Iteration 6989, loss = 0.00318361\n",
      "Iteration 6990, loss = 0.00318307\n",
      "Iteration 6991, loss = 0.00318239\n",
      "Iteration 6992, loss = 0.00318178\n",
      "Iteration 6993, loss = 0.00318122\n",
      "Iteration 6994, loss = 0.00318075\n",
      "Iteration 6995, loss = 0.00318007\n",
      "Iteration 6996, loss = 0.00317954\n",
      "Iteration 6997, loss = 0.00317919\n",
      "Iteration 6998, loss = 0.00317820\n",
      "Iteration 6999, loss = 0.00317771\n",
      "Iteration 7000, loss = 0.00317713\n",
      "Iteration 7001, loss = 0.00317648\n",
      "Iteration 7002, loss = 0.00317609\n",
      "Iteration 7003, loss = 0.00317536\n",
      "Iteration 7004, loss = 0.00317479\n",
      "Iteration 7005, loss = 0.00317417\n",
      "Iteration 7006, loss = 0.00317359\n",
      "Iteration 7007, loss = 0.00317300\n",
      "Iteration 7008, loss = 0.00317264\n",
      "Iteration 7009, loss = 0.00317171\n",
      "Iteration 7010, loss = 0.00317118\n",
      "Iteration 7011, loss = 0.00317046\n",
      "Iteration 7012, loss = 0.00316972\n",
      "Iteration 7013, loss = 0.00316896\n",
      "Iteration 7014, loss = 0.00316865\n",
      "Iteration 7015, loss = 0.00316736\n",
      "Iteration 7016, loss = 0.00316680\n",
      "Iteration 7017, loss = 0.00316637\n",
      "Iteration 7018, loss = 0.00316518\n",
      "Iteration 7019, loss = 0.00316476\n",
      "Iteration 7020, loss = 0.00316378\n",
      "Iteration 7021, loss = 0.00316322\n",
      "Iteration 7022, loss = 0.00316253\n",
      "Iteration 7023, loss = 0.00316182\n",
      "Iteration 7024, loss = 0.00316120\n",
      "Iteration 7025, loss = 0.00316055\n",
      "Iteration 7026, loss = 0.00316001\n",
      "Iteration 7027, loss = 0.00315951\n",
      "Iteration 7028, loss = 0.00315884\n",
      "Iteration 7029, loss = 0.00315816\n",
      "Iteration 7030, loss = 0.00315764\n",
      "Iteration 7031, loss = 0.00315695\n",
      "Iteration 7032, loss = 0.00315602\n",
      "Iteration 7033, loss = 0.00315558\n",
      "Iteration 7034, loss = 0.00315500\n",
      "Iteration 7035, loss = 0.00315448\n",
      "Iteration 7036, loss = 0.00315384\n",
      "Iteration 7037, loss = 0.00315349\n",
      "Iteration 7038, loss = 0.00315302\n",
      "Iteration 7039, loss = 0.00315239\n",
      "Iteration 7040, loss = 0.00315172\n",
      "Iteration 7041, loss = 0.00315127\n",
      "Iteration 7042, loss = 0.00315056\n",
      "Iteration 7043, loss = 0.00314991\n",
      "Iteration 7044, loss = 0.00314926\n",
      "Iteration 7045, loss = 0.00314870\n",
      "Iteration 7046, loss = 0.00314810\n",
      "Iteration 7047, loss = 0.00314742\n",
      "Iteration 7048, loss = 0.00314667\n",
      "Iteration 7049, loss = 0.00314621\n",
      "Iteration 7050, loss = 0.00314549\n",
      "Iteration 7051, loss = 0.00314484\n",
      "Iteration 7052, loss = 0.00314421\n",
      "Iteration 7053, loss = 0.00314379\n",
      "Iteration 7054, loss = 0.00314304\n",
      "Iteration 7055, loss = 0.00314237\n",
      "Iteration 7056, loss = 0.00314171\n",
      "Iteration 7057, loss = 0.00314114\n",
      "Iteration 7058, loss = 0.00314057\n",
      "Iteration 7059, loss = 0.00314000\n",
      "Iteration 7060, loss = 0.00313955\n",
      "Iteration 7061, loss = 0.00313928\n",
      "Iteration 7062, loss = 0.00313837\n",
      "Iteration 7063, loss = 0.00313777\n",
      "Iteration 7064, loss = 0.00313714\n",
      "Iteration 7065, loss = 0.00313644\n",
      "Iteration 7066, loss = 0.00313574\n",
      "Iteration 7067, loss = 0.00313529\n",
      "Iteration 7068, loss = 0.00313447\n",
      "Iteration 7069, loss = 0.00313380\n",
      "Iteration 7070, loss = 0.00313315\n",
      "Iteration 7071, loss = 0.00313251\n",
      "Iteration 7072, loss = 0.00313179\n",
      "Iteration 7073, loss = 0.00313108\n",
      "Iteration 7074, loss = 0.00313065\n",
      "Iteration 7075, loss = 0.00312995\n",
      "Iteration 7076, loss = 0.00312921\n",
      "Iteration 7077, loss = 0.00312851\n",
      "Iteration 7078, loss = 0.00312790\n",
      "Iteration 7079, loss = 0.00312723\n",
      "Iteration 7080, loss = 0.00312656\n",
      "Iteration 7081, loss = 0.00312603\n",
      "Iteration 7082, loss = 0.00312535\n",
      "Iteration 7083, loss = 0.00312459\n",
      "Iteration 7084, loss = 0.00312419\n",
      "Iteration 7085, loss = 0.00312332\n",
      "Iteration 7086, loss = 0.00312267\n",
      "Iteration 7087, loss = 0.00312233\n",
      "Iteration 7088, loss = 0.00312144\n",
      "Iteration 7089, loss = 0.00312087\n",
      "Iteration 7090, loss = 0.00312020\n",
      "Iteration 7091, loss = 0.00311970\n",
      "Iteration 7092, loss = 0.00311902\n",
      "Iteration 7093, loss = 0.00311840\n",
      "Iteration 7094, loss = 0.00311774\n",
      "Iteration 7095, loss = 0.00311723\n",
      "Iteration 7096, loss = 0.00311655\n",
      "Iteration 7097, loss = 0.00311602\n",
      "Iteration 7098, loss = 0.00311539\n",
      "Iteration 7099, loss = 0.00311481\n",
      "Iteration 7100, loss = 0.00311403\n",
      "Iteration 7101, loss = 0.00311328\n",
      "Iteration 7102, loss = 0.00311266\n",
      "Iteration 7103, loss = 0.00311194\n",
      "Iteration 7104, loss = 0.00311160\n",
      "Iteration 7105, loss = 0.00311082\n",
      "Iteration 7106, loss = 0.00311031\n",
      "Iteration 7107, loss = 0.00310963\n",
      "Iteration 7108, loss = 0.00310906\n",
      "Iteration 7109, loss = 0.00310857\n",
      "Iteration 7110, loss = 0.00310790\n",
      "Iteration 7111, loss = 0.00310730\n",
      "Iteration 7112, loss = 0.00310677\n",
      "Iteration 7113, loss = 0.00310618\n",
      "Iteration 7114, loss = 0.00310564\n",
      "Iteration 7115, loss = 0.00310532\n",
      "Iteration 7116, loss = 0.00310446\n",
      "Iteration 7117, loss = 0.00310383\n",
      "Iteration 7118, loss = 0.00310326\n",
      "Iteration 7119, loss = 0.00310263\n",
      "Iteration 7120, loss = 0.00310192\n",
      "Iteration 7121, loss = 0.00310133\n",
      "Iteration 7122, loss = 0.00310062\n",
      "Iteration 7123, loss = 0.00310017\n",
      "Iteration 7124, loss = 0.00309953\n",
      "Iteration 7125, loss = 0.00309892\n",
      "Iteration 7126, loss = 0.00309830\n",
      "Iteration 7127, loss = 0.00309771\n",
      "Iteration 7128, loss = 0.00309728\n",
      "Iteration 7129, loss = 0.00309661\n",
      "Iteration 7130, loss = 0.00309614\n",
      "Iteration 7131, loss = 0.00309551\n",
      "Iteration 7132, loss = 0.00309503\n",
      "Iteration 7133, loss = 0.00309432\n",
      "Iteration 7134, loss = 0.00309366\n",
      "Iteration 7135, loss = 0.00309311\n",
      "Iteration 7136, loss = 0.00309239\n",
      "Iteration 7137, loss = 0.00309181\n",
      "Iteration 7138, loss = 0.00309123\n",
      "Iteration 7139, loss = 0.00309064\n",
      "Iteration 7140, loss = 0.00309008\n",
      "Iteration 7141, loss = 0.00308952\n",
      "Iteration 7142, loss = 0.00308888\n",
      "Iteration 7143, loss = 0.00308831\n",
      "Iteration 7144, loss = 0.00308788\n",
      "Iteration 7145, loss = 0.00308728\n",
      "Iteration 7146, loss = 0.00308662\n",
      "Iteration 7147, loss = 0.00308618\n",
      "Iteration 7148, loss = 0.00308551\n",
      "Iteration 7149, loss = 0.00308501\n",
      "Iteration 7150, loss = 0.00308438\n",
      "Iteration 7151, loss = 0.00308369\n",
      "Iteration 7152, loss = 0.00308314\n",
      "Iteration 7153, loss = 0.00308252\n",
      "Iteration 7154, loss = 0.00308194\n",
      "Iteration 7155, loss = 0.00308134\n",
      "Iteration 7156, loss = 0.00308077\n",
      "Iteration 7157, loss = 0.00308022\n",
      "Iteration 7158, loss = 0.00307969\n",
      "Iteration 7159, loss = 0.00307931\n",
      "Iteration 7160, loss = 0.00307872\n",
      "Iteration 7161, loss = 0.00307805\n",
      "Iteration 7162, loss = 0.00307742\n",
      "Iteration 7163, loss = 0.00307686\n",
      "Iteration 7164, loss = 0.00307623\n",
      "Iteration 7165, loss = 0.00307527\n",
      "Iteration 7166, loss = 0.00307461\n",
      "Iteration 7167, loss = 0.00307406\n",
      "Iteration 7168, loss = 0.00307347\n",
      "Iteration 7169, loss = 0.00307266\n",
      "Iteration 7170, loss = 0.00307206\n",
      "Iteration 7171, loss = 0.00307143\n",
      "Iteration 7172, loss = 0.00307081\n",
      "Iteration 7173, loss = 0.00307028\n",
      "Iteration 7174, loss = 0.00306961\n",
      "Iteration 7175, loss = 0.00306912\n",
      "Iteration 7176, loss = 0.00306856\n",
      "Iteration 7177, loss = 0.00306802\n",
      "Iteration 7178, loss = 0.00306744\n",
      "Iteration 7179, loss = 0.00306688\n",
      "Iteration 7180, loss = 0.00306630\n",
      "Iteration 7181, loss = 0.00306571\n",
      "Iteration 7182, loss = 0.00306498\n",
      "Iteration 7183, loss = 0.00306436\n",
      "Iteration 7184, loss = 0.00306382\n",
      "Iteration 7185, loss = 0.00306319\n",
      "Iteration 7186, loss = 0.00306261\n",
      "Iteration 7187, loss = 0.00306190\n",
      "Iteration 7188, loss = 0.00306134\n",
      "Iteration 7189, loss = 0.00306079\n",
      "Iteration 7190, loss = 0.00306020\n",
      "Iteration 7191, loss = 0.00305949\n",
      "Iteration 7192, loss = 0.00305892\n",
      "Iteration 7193, loss = 0.00305824\n",
      "Iteration 7194, loss = 0.00305772\n",
      "Iteration 7195, loss = 0.00305711\n",
      "Iteration 7196, loss = 0.00305667\n",
      "Iteration 7197, loss = 0.00305611\n",
      "Iteration 7198, loss = 0.00305574\n",
      "Iteration 7199, loss = 0.00305481\n",
      "Iteration 7200, loss = 0.00305431\n",
      "Iteration 7201, loss = 0.00305367\n",
      "Iteration 7202, loss = 0.00305305\n",
      "Iteration 7203, loss = 0.00305252\n",
      "Iteration 7204, loss = 0.00305185\n",
      "Iteration 7205, loss = 0.00305132\n",
      "Iteration 7206, loss = 0.00305078\n",
      "Iteration 7207, loss = 0.00305026\n",
      "Iteration 7208, loss = 0.00304968\n",
      "Iteration 7209, loss = 0.00304916\n",
      "Iteration 7210, loss = 0.00304861\n",
      "Iteration 7211, loss = 0.00304811\n",
      "Iteration 7212, loss = 0.00304747\n",
      "Iteration 7213, loss = 0.00304683\n",
      "Iteration 7214, loss = 0.00304623\n",
      "Iteration 7215, loss = 0.00304566\n",
      "Iteration 7216, loss = 0.00304500\n",
      "Iteration 7217, loss = 0.00304425\n",
      "Iteration 7218, loss = 0.00304365\n",
      "Iteration 7219, loss = 0.00304312\n",
      "Iteration 7220, loss = 0.00304263\n",
      "Iteration 7221, loss = 0.00304186\n",
      "Iteration 7222, loss = 0.00304140\n",
      "Iteration 7223, loss = 0.00304070\n",
      "Iteration 7224, loss = 0.00304004\n",
      "Iteration 7225, loss = 0.00303959\n",
      "Iteration 7226, loss = 0.00303899\n",
      "Iteration 7227, loss = 0.00303854\n",
      "Iteration 7228, loss = 0.00303798\n",
      "Iteration 7229, loss = 0.00303725\n",
      "Iteration 7230, loss = 0.00303659\n",
      "Iteration 7231, loss = 0.00303603\n",
      "Iteration 7232, loss = 0.00303562\n",
      "Iteration 7233, loss = 0.00303492\n",
      "Iteration 7234, loss = 0.00303425\n",
      "Iteration 7235, loss = 0.00303373\n",
      "Iteration 7236, loss = 0.00303308\n",
      "Iteration 7237, loss = 0.00303247\n",
      "Iteration 7238, loss = 0.00303194\n",
      "Iteration 7239, loss = 0.00303141\n",
      "Iteration 7240, loss = 0.00303083\n",
      "Iteration 7241, loss = 0.00303006\n",
      "Iteration 7242, loss = 0.00302950\n",
      "Iteration 7243, loss = 0.00302888\n",
      "Iteration 7244, loss = 0.00302823\n",
      "Iteration 7245, loss = 0.00302753\n",
      "Iteration 7246, loss = 0.00302693\n",
      "Iteration 7247, loss = 0.00302629\n",
      "Iteration 7248, loss = 0.00302546\n",
      "Iteration 7249, loss = 0.00302485\n",
      "Iteration 7250, loss = 0.00302414\n",
      "Iteration 7251, loss = 0.00302370\n",
      "Iteration 7252, loss = 0.00302295\n",
      "Iteration 7253, loss = 0.00302239\n",
      "Iteration 7254, loss = 0.00302192\n",
      "Iteration 7255, loss = 0.00302124\n",
      "Iteration 7256, loss = 0.00302118\n",
      "Iteration 7257, loss = 0.00302019\n",
      "Iteration 7258, loss = 0.00301959\n",
      "Iteration 7259, loss = 0.00301907\n",
      "Iteration 7260, loss = 0.00301851\n",
      "Iteration 7261, loss = 0.00301807\n",
      "Iteration 7262, loss = 0.00301733\n",
      "Iteration 7263, loss = 0.00301715\n",
      "Iteration 7264, loss = 0.00301622\n",
      "Iteration 7265, loss = 0.00301564\n",
      "Iteration 7266, loss = 0.00301509\n",
      "Iteration 7267, loss = 0.00301455\n",
      "Iteration 7268, loss = 0.00301391\n",
      "Iteration 7269, loss = 0.00301338\n",
      "Iteration 7270, loss = 0.00301301\n",
      "Iteration 7271, loss = 0.00301229\n",
      "Iteration 7272, loss = 0.00301180\n",
      "Iteration 7273, loss = 0.00301125\n",
      "Iteration 7274, loss = 0.00301069\n",
      "Iteration 7275, loss = 0.00301010\n",
      "Iteration 7276, loss = 0.00300951\n",
      "Iteration 7277, loss = 0.00300893\n",
      "Iteration 7278, loss = 0.00300840\n",
      "Iteration 7279, loss = 0.00300783\n",
      "Iteration 7280, loss = 0.00300726\n",
      "Iteration 7281, loss = 0.00300664\n",
      "Iteration 7282, loss = 0.00300597\n",
      "Iteration 7283, loss = 0.00300536\n",
      "Iteration 7284, loss = 0.00300484\n",
      "Iteration 7285, loss = 0.00300422\n",
      "Iteration 7286, loss = 0.00300357\n",
      "Iteration 7287, loss = 0.00300304\n",
      "Iteration 7288, loss = 0.00300235\n",
      "Iteration 7289, loss = 0.00300177\n",
      "Iteration 7290, loss = 0.00300129\n",
      "Iteration 7291, loss = 0.00300068\n",
      "Iteration 7292, loss = 0.00300005\n",
      "Iteration 7293, loss = 0.00299944\n",
      "Iteration 7294, loss = 0.00299881\n",
      "Iteration 7295, loss = 0.00299833\n",
      "Iteration 7296, loss = 0.00299787\n",
      "Iteration 7297, loss = 0.00299714\n",
      "Iteration 7298, loss = 0.00299654\n",
      "Iteration 7299, loss = 0.00299597\n",
      "Iteration 7300, loss = 0.00299549\n",
      "Iteration 7301, loss = 0.00299486\n",
      "Iteration 7302, loss = 0.00299439\n",
      "Iteration 7303, loss = 0.00299383\n",
      "Iteration 7304, loss = 0.00299332\n",
      "Iteration 7305, loss = 0.00299272\n",
      "Iteration 7306, loss = 0.00299217\n",
      "Iteration 7307, loss = 0.00299152\n",
      "Iteration 7308, loss = 0.00299106\n",
      "Iteration 7309, loss = 0.00299033\n",
      "Iteration 7310, loss = 0.00298965\n",
      "Iteration 7311, loss = 0.00298898\n",
      "Iteration 7312, loss = 0.00298869\n",
      "Iteration 7313, loss = 0.00298847\n",
      "Iteration 7314, loss = 0.00298740\n",
      "Iteration 7315, loss = 0.00298668\n",
      "Iteration 7316, loss = 0.00298603\n",
      "Iteration 7317, loss = 0.00298579\n",
      "Iteration 7318, loss = 0.00298493\n",
      "Iteration 7319, loss = 0.00298433\n",
      "Iteration 7320, loss = 0.00298371\n",
      "Iteration 7321, loss = 0.00298319\n",
      "Iteration 7322, loss = 0.00298252\n",
      "Iteration 7323, loss = 0.00298186\n",
      "Iteration 7324, loss = 0.00298133\n",
      "Iteration 7325, loss = 0.00298083\n",
      "Iteration 7326, loss = 0.00298019\n",
      "Iteration 7327, loss = 0.00297952\n",
      "Iteration 7328, loss = 0.00297913\n",
      "Iteration 7329, loss = 0.00297856\n",
      "Iteration 7330, loss = 0.00297804\n",
      "Iteration 7331, loss = 0.00297754\n",
      "Iteration 7332, loss = 0.00297651\n",
      "Iteration 7333, loss = 0.00297568\n",
      "Iteration 7334, loss = 0.00297557\n",
      "Iteration 7335, loss = 0.00297473\n",
      "Iteration 7336, loss = 0.00297480\n",
      "Iteration 7337, loss = 0.00297370\n",
      "Iteration 7338, loss = 0.00297307\n",
      "Iteration 7339, loss = 0.00297244\n",
      "Iteration 7340, loss = 0.00297185\n",
      "Iteration 7341, loss = 0.00297134\n",
      "Iteration 7342, loss = 0.00297077\n",
      "Iteration 7343, loss = 0.00297032\n",
      "Iteration 7344, loss = 0.00296975\n",
      "Iteration 7345, loss = 0.00296920\n",
      "Iteration 7346, loss = 0.00296865\n",
      "Iteration 7347, loss = 0.00296808\n",
      "Iteration 7348, loss = 0.00296765\n",
      "Iteration 7349, loss = 0.00296708\n",
      "Iteration 7350, loss = 0.00296627\n",
      "Iteration 7351, loss = 0.00296585\n",
      "Iteration 7352, loss = 0.00296521\n",
      "Iteration 7353, loss = 0.00296461\n",
      "Iteration 7354, loss = 0.00296411\n",
      "Iteration 7355, loss = 0.00296361\n",
      "Iteration 7356, loss = 0.00296311\n",
      "Iteration 7357, loss = 0.00296243\n",
      "Iteration 7358, loss = 0.00296191\n",
      "Iteration 7359, loss = 0.00296130\n",
      "Iteration 7360, loss = 0.00296116\n",
      "Iteration 7361, loss = 0.00296039\n",
      "Iteration 7362, loss = 0.00295970\n",
      "Iteration 7363, loss = 0.00295904\n",
      "Iteration 7364, loss = 0.00295862\n",
      "Iteration 7365, loss = 0.00295787\n",
      "Iteration 7366, loss = 0.00295726\n",
      "Iteration 7367, loss = 0.00295651\n",
      "Iteration 7368, loss = 0.00295598\n",
      "Iteration 7369, loss = 0.00295551\n",
      "Iteration 7370, loss = 0.00295477\n",
      "Iteration 7371, loss = 0.00295419\n",
      "Iteration 7372, loss = 0.00295358\n",
      "Iteration 7373, loss = 0.00295307\n",
      "Iteration 7374, loss = 0.00295242\n",
      "Iteration 7375, loss = 0.00295183\n",
      "Iteration 7376, loss = 0.00295127\n",
      "Iteration 7377, loss = 0.00295065\n",
      "Iteration 7378, loss = 0.00295005\n",
      "Iteration 7379, loss = 0.00294937\n",
      "Iteration 7380, loss = 0.00294885\n",
      "Iteration 7381, loss = 0.00294859\n",
      "Iteration 7382, loss = 0.00294767\n",
      "Iteration 7383, loss = 0.00294720\n",
      "Iteration 7384, loss = 0.00294650\n",
      "Iteration 7385, loss = 0.00294585\n",
      "Iteration 7386, loss = 0.00294534\n",
      "Iteration 7387, loss = 0.00294479\n",
      "Iteration 7388, loss = 0.00294412\n",
      "Iteration 7389, loss = 0.00294355\n",
      "Iteration 7390, loss = 0.00294298\n",
      "Iteration 7391, loss = 0.00294242\n",
      "Iteration 7392, loss = 0.00294186\n",
      "Iteration 7393, loss = 0.00294120\n",
      "Iteration 7394, loss = 0.00294070\n",
      "Iteration 7395, loss = 0.00294003\n",
      "Iteration 7396, loss = 0.00293965\n",
      "Iteration 7397, loss = 0.00293901\n",
      "Iteration 7398, loss = 0.00293861\n",
      "Iteration 7399, loss = 0.00293783\n",
      "Iteration 7400, loss = 0.00293725\n",
      "Iteration 7401, loss = 0.00293646\n",
      "Iteration 7402, loss = 0.00293615\n",
      "Iteration 7403, loss = 0.00293567\n",
      "Iteration 7404, loss = 0.00293490\n",
      "Iteration 7405, loss = 0.00293464\n",
      "Iteration 7406, loss = 0.00293388\n",
      "Iteration 7407, loss = 0.00293336\n",
      "Iteration 7408, loss = 0.00293285\n",
      "Iteration 7409, loss = 0.00293232\n",
      "Iteration 7410, loss = 0.00293176\n",
      "Iteration 7411, loss = 0.00293120\n",
      "Iteration 7412, loss = 0.00293067\n",
      "Iteration 7413, loss = 0.00293009\n",
      "Iteration 7414, loss = 0.00292963\n",
      "Iteration 7415, loss = 0.00292921\n",
      "Iteration 7416, loss = 0.00292855\n",
      "Iteration 7417, loss = 0.00292809\n",
      "Iteration 7418, loss = 0.00292754\n",
      "Iteration 7419, loss = 0.00292707\n",
      "Iteration 7420, loss = 0.00292654\n",
      "Iteration 7421, loss = 0.00292604\n",
      "Iteration 7422, loss = 0.00292556\n",
      "Iteration 7423, loss = 0.00292512\n",
      "Iteration 7424, loss = 0.00292441\n",
      "Iteration 7425, loss = 0.00292413\n",
      "Iteration 7426, loss = 0.00292336\n",
      "Iteration 7427, loss = 0.00292283\n",
      "Iteration 7428, loss = 0.00292230\n",
      "Iteration 7429, loss = 0.00292176\n",
      "Iteration 7430, loss = 0.00292119\n",
      "Iteration 7431, loss = 0.00292076\n",
      "Iteration 7432, loss = 0.00292023\n",
      "Iteration 7433, loss = 0.00291950\n",
      "Iteration 7434, loss = 0.00291897\n",
      "Iteration 7435, loss = 0.00291834\n",
      "Iteration 7436, loss = 0.00291773\n",
      "Iteration 7437, loss = 0.00291715\n",
      "Iteration 7438, loss = 0.00291683\n",
      "Iteration 7439, loss = 0.00291605\n",
      "Iteration 7440, loss = 0.00291544\n",
      "Iteration 7441, loss = 0.00291492\n",
      "Iteration 7442, loss = 0.00291442\n",
      "Iteration 7443, loss = 0.00291372\n",
      "Iteration 7444, loss = 0.00291319\n",
      "Iteration 7445, loss = 0.00291261\n",
      "Iteration 7446, loss = 0.00291203\n",
      "Iteration 7447, loss = 0.00291150\n",
      "Iteration 7448, loss = 0.00291126\n",
      "Iteration 7449, loss = 0.00291056\n",
      "Iteration 7450, loss = 0.00290992\n",
      "Iteration 7451, loss = 0.00290943\n",
      "Iteration 7452, loss = 0.00290894\n",
      "Iteration 7453, loss = 0.00290885\n",
      "Iteration 7454, loss = 0.00290796\n",
      "Iteration 7455, loss = 0.00290744\n",
      "Iteration 7456, loss = 0.00290689\n",
      "Iteration 7457, loss = 0.00290634\n",
      "Iteration 7458, loss = 0.00290583\n",
      "Iteration 7459, loss = 0.00290523\n",
      "Iteration 7460, loss = 0.00290461\n",
      "Iteration 7461, loss = 0.00290407\n",
      "Iteration 7462, loss = 0.00290367\n",
      "Iteration 7463, loss = 0.00290306\n",
      "Iteration 7464, loss = 0.00290237\n",
      "Iteration 7465, loss = 0.00290191\n",
      "Iteration 7466, loss = 0.00290127\n",
      "Iteration 7467, loss = 0.00290079\n",
      "Iteration 7468, loss = 0.00290027\n",
      "Iteration 7469, loss = 0.00289969\n",
      "Iteration 7470, loss = 0.00289933\n",
      "Iteration 7471, loss = 0.00289871\n",
      "Iteration 7472, loss = 0.00289801\n",
      "Iteration 7473, loss = 0.00289761\n",
      "Iteration 7474, loss = 0.00289689\n",
      "Iteration 7475, loss = 0.00289628\n",
      "Iteration 7476, loss = 0.00289570\n",
      "Iteration 7477, loss = 0.00289528\n",
      "Iteration 7478, loss = 0.00289457\n",
      "Iteration 7479, loss = 0.00289405\n",
      "Iteration 7480, loss = 0.00289355\n",
      "Iteration 7481, loss = 0.00289314\n",
      "Iteration 7482, loss = 0.00289245\n",
      "Iteration 7483, loss = 0.00289179\n",
      "Iteration 7484, loss = 0.00289123\n",
      "Iteration 7485, loss = 0.00289069\n",
      "Iteration 7486, loss = 0.00289013\n",
      "Iteration 7487, loss = 0.00288958\n",
      "Iteration 7488, loss = 0.00288895\n",
      "Iteration 7489, loss = 0.00288865\n",
      "Iteration 7490, loss = 0.00288813\n",
      "Iteration 7491, loss = 0.00288743\n",
      "Iteration 7492, loss = 0.00288686\n",
      "Iteration 7493, loss = 0.00288633\n",
      "Iteration 7494, loss = 0.00288582\n",
      "Iteration 7495, loss = 0.00288529\n",
      "Iteration 7496, loss = 0.00288472\n",
      "Iteration 7497, loss = 0.00288428\n",
      "Iteration 7498, loss = 0.00288388\n",
      "Iteration 7499, loss = 0.00288302\n",
      "Iteration 7500, loss = 0.00288252\n",
      "Iteration 7501, loss = 0.00288192\n",
      "Iteration 7502, loss = 0.00288141\n",
      "Iteration 7503, loss = 0.00288083\n",
      "Iteration 7504, loss = 0.00288035\n",
      "Iteration 7505, loss = 0.00287974\n",
      "Iteration 7506, loss = 0.00287924\n",
      "Iteration 7507, loss = 0.00287875\n",
      "Iteration 7508, loss = 0.00287819\n",
      "Iteration 7509, loss = 0.00287790\n",
      "Iteration 7510, loss = 0.00287716\n",
      "Iteration 7511, loss = 0.00287666\n",
      "Iteration 7512, loss = 0.00287610\n",
      "Iteration 7513, loss = 0.00287567\n",
      "Iteration 7514, loss = 0.00287509\n",
      "Iteration 7515, loss = 0.00287453\n",
      "Iteration 7516, loss = 0.00287395\n",
      "Iteration 7517, loss = 0.00287347\n",
      "Iteration 7518, loss = 0.00287290\n",
      "Iteration 7519, loss = 0.00287235\n",
      "Iteration 7520, loss = 0.00287216\n",
      "Iteration 7521, loss = 0.00287150\n",
      "Iteration 7522, loss = 0.00287086\n",
      "Iteration 7523, loss = 0.00287045\n",
      "Iteration 7524, loss = 0.00286985\n",
      "Iteration 7525, loss = 0.00286942\n",
      "Iteration 7526, loss = 0.00286879\n",
      "Iteration 7527, loss = 0.00286827\n",
      "Iteration 7528, loss = 0.00286776\n",
      "Iteration 7529, loss = 0.00286724\n",
      "Iteration 7530, loss = 0.00286672\n",
      "Iteration 7531, loss = 0.00286617\n",
      "Iteration 7532, loss = 0.00286568\n",
      "Iteration 7533, loss = 0.00286538\n",
      "Iteration 7534, loss = 0.00286471\n",
      "Iteration 7535, loss = 0.00286427\n",
      "Iteration 7536, loss = 0.00286379\n",
      "Iteration 7537, loss = 0.00286321\n",
      "Iteration 7538, loss = 0.00286290\n",
      "Iteration 7539, loss = 0.00286210\n",
      "Iteration 7540, loss = 0.00286165\n",
      "Iteration 7541, loss = 0.00286116\n",
      "Iteration 7542, loss = 0.00286056\n",
      "Iteration 7543, loss = 0.00286010\n",
      "Iteration 7544, loss = 0.00285972\n",
      "Iteration 7545, loss = 0.00285898\n",
      "Iteration 7546, loss = 0.00285846\n",
      "Iteration 7547, loss = 0.00285805\n",
      "Iteration 7548, loss = 0.00285747\n",
      "Iteration 7549, loss = 0.00285697\n",
      "Iteration 7550, loss = 0.00285643\n",
      "Iteration 7551, loss = 0.00285596\n",
      "Iteration 7552, loss = 0.00285550\n",
      "Iteration 7553, loss = 0.00285514\n",
      "Iteration 7554, loss = 0.00285456\n",
      "Iteration 7555, loss = 0.00285426\n",
      "Iteration 7556, loss = 0.00285363\n",
      "Iteration 7557, loss = 0.00285338\n",
      "Iteration 7558, loss = 0.00285255\n",
      "Iteration 7559, loss = 0.00285205\n",
      "Iteration 7560, loss = 0.00285160\n",
      "Iteration 7561, loss = 0.00285098\n",
      "Iteration 7562, loss = 0.00285046\n",
      "Iteration 7563, loss = 0.00284991\n",
      "Iteration 7564, loss = 0.00284940\n",
      "Iteration 7565, loss = 0.00284889\n",
      "Iteration 7566, loss = 0.00284844\n",
      "Iteration 7567, loss = 0.00284791\n",
      "Iteration 7568, loss = 0.00284735\n",
      "Iteration 7569, loss = 0.00284684\n",
      "Iteration 7570, loss = 0.00284632\n",
      "Iteration 7571, loss = 0.00284589\n",
      "Iteration 7572, loss = 0.00284542\n",
      "Iteration 7573, loss = 0.00284492\n",
      "Iteration 7574, loss = 0.00284439\n",
      "Iteration 7575, loss = 0.00284387\n",
      "Iteration 7576, loss = 0.00284353\n",
      "Iteration 7577, loss = 0.00284313\n",
      "Iteration 7578, loss = 0.00284254\n",
      "Iteration 7579, loss = 0.00284202\n",
      "Iteration 7580, loss = 0.00284153\n",
      "Iteration 7581, loss = 0.00284100\n",
      "Iteration 7582, loss = 0.00284048\n",
      "Iteration 7583, loss = 0.00283990\n",
      "Iteration 7584, loss = 0.00283933\n",
      "Iteration 7585, loss = 0.00283895\n",
      "Iteration 7586, loss = 0.00283829\n",
      "Iteration 7587, loss = 0.00283774\n",
      "Iteration 7588, loss = 0.00283726\n",
      "Iteration 7589, loss = 0.00283670\n",
      "Iteration 7590, loss = 0.00283612\n",
      "Iteration 7591, loss = 0.00283556\n",
      "Iteration 7592, loss = 0.00283512\n",
      "Iteration 7593, loss = 0.00283455\n",
      "Iteration 7594, loss = 0.00283417\n",
      "Iteration 7595, loss = 0.00283348\n",
      "Iteration 7596, loss = 0.00283293\n",
      "Iteration 7597, loss = 0.00283237\n",
      "Iteration 7598, loss = 0.00283199\n",
      "Iteration 7599, loss = 0.00283131\n",
      "Iteration 7600, loss = 0.00283073\n",
      "Iteration 7601, loss = 0.00283018\n",
      "Iteration 7602, loss = 0.00282977\n",
      "Iteration 7603, loss = 0.00282931\n",
      "Iteration 7604, loss = 0.00282886\n",
      "Iteration 7605, loss = 0.00282812\n",
      "Iteration 7606, loss = 0.00282759\n",
      "Iteration 7607, loss = 0.00282697\n",
      "Iteration 7608, loss = 0.00282661\n",
      "Iteration 7609, loss = 0.00282596\n",
      "Iteration 7610, loss = 0.00282547\n",
      "Iteration 7611, loss = 0.00282527\n",
      "Iteration 7612, loss = 0.00282451\n",
      "Iteration 7613, loss = 0.00282398\n",
      "Iteration 7614, loss = 0.00282343\n",
      "Iteration 7615, loss = 0.00282293\n",
      "Iteration 7616, loss = 0.00282250\n",
      "Iteration 7617, loss = 0.00282187\n",
      "Iteration 7618, loss = 0.00282130\n",
      "Iteration 7619, loss = 0.00282082\n",
      "Iteration 7620, loss = 0.00282050\n",
      "Iteration 7621, loss = 0.00281995\n",
      "Iteration 7622, loss = 0.00281934\n",
      "Iteration 7623, loss = 0.00281878\n",
      "Iteration 7624, loss = 0.00281820\n",
      "Iteration 7625, loss = 0.00281777\n",
      "Iteration 7626, loss = 0.00281739\n",
      "Iteration 7627, loss = 0.00281674\n",
      "Iteration 7628, loss = 0.00281618\n",
      "Iteration 7629, loss = 0.00281565\n",
      "Iteration 7630, loss = 0.00281519\n",
      "Iteration 7631, loss = 0.00281472\n",
      "Iteration 7632, loss = 0.00281415\n",
      "Iteration 7633, loss = 0.00281360\n",
      "Iteration 7634, loss = 0.00281301\n",
      "Iteration 7635, loss = 0.00281279\n",
      "Iteration 7636, loss = 0.00281204\n",
      "Iteration 7637, loss = 0.00281148\n",
      "Iteration 7638, loss = 0.00281098\n",
      "Iteration 7639, loss = 0.00281052\n",
      "Iteration 7640, loss = 0.00281031\n",
      "Iteration 7641, loss = 0.00280954\n",
      "Iteration 7642, loss = 0.00280904\n",
      "Iteration 7643, loss = 0.00280855\n",
      "Iteration 7644, loss = 0.00280807\n",
      "Iteration 7645, loss = 0.00280761\n",
      "Iteration 7646, loss = 0.00280713\n",
      "Iteration 7647, loss = 0.00280689\n",
      "Iteration 7648, loss = 0.00280615\n",
      "Iteration 7649, loss = 0.00280575\n",
      "Iteration 7650, loss = 0.00280502\n",
      "Iteration 7651, loss = 0.00280455\n",
      "Iteration 7652, loss = 0.00280393\n",
      "Iteration 7653, loss = 0.00280354\n",
      "Iteration 7654, loss = 0.00280309\n",
      "Iteration 7655, loss = 0.00280244\n",
      "Iteration 7656, loss = 0.00280195\n",
      "Iteration 7657, loss = 0.00280147\n",
      "Iteration 7658, loss = 0.00280093\n",
      "Iteration 7659, loss = 0.00280043\n",
      "Iteration 7660, loss = 0.00280001\n",
      "Iteration 7661, loss = 0.00279948\n",
      "Iteration 7662, loss = 0.00279901\n",
      "Iteration 7663, loss = 0.00279849\n",
      "Iteration 7664, loss = 0.00279809\n",
      "Iteration 7665, loss = 0.00279756\n",
      "Iteration 7666, loss = 0.00279710\n",
      "Iteration 7667, loss = 0.00279662\n",
      "Iteration 7668, loss = 0.00279619\n",
      "Iteration 7669, loss = 0.00279575\n",
      "Iteration 7670, loss = 0.00279538\n",
      "Iteration 7671, loss = 0.00279488\n",
      "Iteration 7672, loss = 0.00279434\n",
      "Iteration 7673, loss = 0.00279387\n",
      "Iteration 7674, loss = 0.00279334\n",
      "Iteration 7675, loss = 0.00279283\n",
      "Iteration 7676, loss = 0.00279240\n",
      "Iteration 7677, loss = 0.00279176\n",
      "Iteration 7678, loss = 0.00279124\n",
      "Iteration 7679, loss = 0.00279074\n",
      "Iteration 7680, loss = 0.00279022\n",
      "Iteration 7681, loss = 0.00278970\n",
      "Iteration 7682, loss = 0.00278928\n",
      "Iteration 7683, loss = 0.00278872\n",
      "Iteration 7684, loss = 0.00278831\n",
      "Iteration 7685, loss = 0.00278772\n",
      "Iteration 7686, loss = 0.00278726\n",
      "Iteration 7687, loss = 0.00278663\n",
      "Iteration 7688, loss = 0.00278616\n",
      "Iteration 7689, loss = 0.00278549\n",
      "Iteration 7690, loss = 0.00278501\n",
      "Iteration 7691, loss = 0.00278445\n",
      "Iteration 7692, loss = 0.00278396\n",
      "Iteration 7693, loss = 0.00278342\n",
      "Iteration 7694, loss = 0.00278292\n",
      "Iteration 7695, loss = 0.00278254\n",
      "Iteration 7696, loss = 0.00278201\n",
      "Iteration 7697, loss = 0.00278139\n",
      "Iteration 7698, loss = 0.00278124\n",
      "Iteration 7699, loss = 0.00278063\n",
      "Iteration 7700, loss = 0.00278010\n",
      "Iteration 7701, loss = 0.00277953\n",
      "Iteration 7702, loss = 0.00277907\n",
      "Iteration 7703, loss = 0.00277858\n",
      "Iteration 7704, loss = 0.00277805\n",
      "Iteration 7705, loss = 0.00277760\n",
      "Iteration 7706, loss = 0.00277717\n",
      "Iteration 7707, loss = 0.00277696\n",
      "Iteration 7708, loss = 0.00277620\n",
      "Iteration 7709, loss = 0.00277576\n",
      "Iteration 7710, loss = 0.00277523\n",
      "Iteration 7711, loss = 0.00277483\n",
      "Iteration 7712, loss = 0.00277432\n",
      "Iteration 7713, loss = 0.00277369\n",
      "Iteration 7714, loss = 0.00277302\n",
      "Iteration 7715, loss = 0.00277269\n",
      "Iteration 7716, loss = 0.00277220\n",
      "Iteration 7717, loss = 0.00277151\n",
      "Iteration 7718, loss = 0.00277091\n",
      "Iteration 7719, loss = 0.00277048\n",
      "Iteration 7720, loss = 0.00276973\n",
      "Iteration 7721, loss = 0.00276924\n",
      "Iteration 7722, loss = 0.00276893\n",
      "Iteration 7723, loss = 0.00276820\n",
      "Iteration 7724, loss = 0.00276801\n",
      "Iteration 7725, loss = 0.00276722\n",
      "Iteration 7726, loss = 0.00276668\n",
      "Iteration 7727, loss = 0.00276608\n",
      "Iteration 7728, loss = 0.00276559\n",
      "Iteration 7729, loss = 0.00276500\n",
      "Iteration 7730, loss = 0.00276442\n",
      "Iteration 7731, loss = 0.00276386\n",
      "Iteration 7732, loss = 0.00276328\n",
      "Iteration 7733, loss = 0.00276272\n",
      "Iteration 7734, loss = 0.00276227\n",
      "Iteration 7735, loss = 0.00276174\n",
      "Iteration 7736, loss = 0.00276114\n",
      "Iteration 7737, loss = 0.00276068\n",
      "Iteration 7738, loss = 0.00276007\n",
      "Iteration 7739, loss = 0.00275955\n",
      "Iteration 7740, loss = 0.00275935\n",
      "Iteration 7741, loss = 0.00275846\n",
      "Iteration 7742, loss = 0.00275795\n",
      "Iteration 7743, loss = 0.00275748\n",
      "Iteration 7744, loss = 0.00275691\n",
      "Iteration 7745, loss = 0.00275660\n",
      "Iteration 7746, loss = 0.00275587\n",
      "Iteration 7747, loss = 0.00275554\n",
      "Iteration 7748, loss = 0.00275490\n",
      "Iteration 7749, loss = 0.00275429\n",
      "Iteration 7750, loss = 0.00275377\n",
      "Iteration 7751, loss = 0.00275331\n",
      "Iteration 7752, loss = 0.00275269\n",
      "Iteration 7753, loss = 0.00275213\n",
      "Iteration 7754, loss = 0.00275177\n",
      "Iteration 7755, loss = 0.00275120\n",
      "Iteration 7756, loss = 0.00275078\n",
      "Iteration 7757, loss = 0.00275033\n",
      "Iteration 7758, loss = 0.00274972\n",
      "Iteration 7759, loss = 0.00274938\n",
      "Iteration 7760, loss = 0.00274879\n",
      "Iteration 7761, loss = 0.00274818\n",
      "Iteration 7762, loss = 0.00274772\n",
      "Iteration 7763, loss = 0.00274710\n",
      "Iteration 7764, loss = 0.00274669\n",
      "Iteration 7765, loss = 0.00274602\n",
      "Iteration 7766, loss = 0.00274558\n",
      "Iteration 7767, loss = 0.00274499\n",
      "Iteration 7768, loss = 0.00274450\n",
      "Iteration 7769, loss = 0.00274396\n",
      "Iteration 7770, loss = 0.00274339\n",
      "Iteration 7771, loss = 0.00274291\n",
      "Iteration 7772, loss = 0.00274245\n",
      "Iteration 7773, loss = 0.00274188\n",
      "Iteration 7774, loss = 0.00274134\n",
      "Iteration 7775, loss = 0.00274089\n",
      "Iteration 7776, loss = 0.00274051\n",
      "Iteration 7777, loss = 0.00273990\n",
      "Iteration 7778, loss = 0.00273945\n",
      "Iteration 7779, loss = 0.00273885\n",
      "Iteration 7780, loss = 0.00273831\n",
      "Iteration 7781, loss = 0.00273788\n",
      "Iteration 7782, loss = 0.00273725\n",
      "Iteration 7783, loss = 0.00273670\n",
      "Iteration 7784, loss = 0.00273608\n",
      "Iteration 7785, loss = 0.00273617\n",
      "Iteration 7786, loss = 0.00273523\n",
      "Iteration 7787, loss = 0.00273486\n",
      "Iteration 7788, loss = 0.00273441\n",
      "Iteration 7789, loss = 0.00273418\n",
      "Iteration 7790, loss = 0.00273347\n",
      "Iteration 7791, loss = 0.00273296\n",
      "Iteration 7792, loss = 0.00273262\n",
      "Iteration 7793, loss = 0.00273210\n",
      "Iteration 7794, loss = 0.00273182\n",
      "Iteration 7795, loss = 0.00273118\n",
      "Iteration 7796, loss = 0.00273070\n",
      "Iteration 7797, loss = 0.00273023\n",
      "Iteration 7798, loss = 0.00272980\n",
      "Iteration 7799, loss = 0.00272921\n",
      "Iteration 7800, loss = 0.00272882\n",
      "Iteration 7801, loss = 0.00272828\n",
      "Iteration 7802, loss = 0.00272787\n",
      "Iteration 7803, loss = 0.00272732\n",
      "Iteration 7804, loss = 0.00272684\n",
      "Iteration 7805, loss = 0.00272645\n",
      "Iteration 7806, loss = 0.00272595\n",
      "Iteration 7807, loss = 0.00272544\n",
      "Iteration 7808, loss = 0.00272503\n",
      "Iteration 7809, loss = 0.00272448\n",
      "Iteration 7810, loss = 0.00272400\n",
      "Iteration 7811, loss = 0.00272355\n",
      "Iteration 7812, loss = 0.00272331\n",
      "Iteration 7813, loss = 0.00272256\n",
      "Iteration 7814, loss = 0.00272210\n",
      "Iteration 7815, loss = 0.00272157\n",
      "Iteration 7816, loss = 0.00272106\n",
      "Iteration 7817, loss = 0.00272069\n",
      "Iteration 7818, loss = 0.00272008\n",
      "Iteration 7819, loss = 0.00271960\n",
      "Iteration 7820, loss = 0.00271915\n",
      "Iteration 7821, loss = 0.00271869\n",
      "Iteration 7822, loss = 0.00271811\n",
      "Iteration 7823, loss = 0.00271761\n",
      "Iteration 7824, loss = 0.00271735\n",
      "Iteration 7825, loss = 0.00271671\n",
      "Iteration 7826, loss = 0.00271621\n",
      "Iteration 7827, loss = 0.00271569\n",
      "Iteration 7828, loss = 0.00271522\n",
      "Iteration 7829, loss = 0.00271473\n",
      "Iteration 7830, loss = 0.00271467\n",
      "Iteration 7831, loss = 0.00271391\n",
      "Iteration 7832, loss = 0.00271338\n",
      "Iteration 7833, loss = 0.00271290\n",
      "Iteration 7834, loss = 0.00271242\n",
      "Iteration 7835, loss = 0.00271195\n",
      "Iteration 7836, loss = 0.00271156\n",
      "Iteration 7837, loss = 0.00271107\n",
      "Iteration 7838, loss = 0.00271063\n",
      "Iteration 7839, loss = 0.00271030\n",
      "Iteration 7840, loss = 0.00270964\n",
      "Iteration 7841, loss = 0.00270903\n",
      "Iteration 7842, loss = 0.00270848\n",
      "Iteration 7843, loss = 0.00270793\n",
      "Iteration 7844, loss = 0.00270774\n",
      "Iteration 7845, loss = 0.00270703\n",
      "Iteration 7846, loss = 0.00270653\n",
      "Iteration 7847, loss = 0.00270600\n",
      "Iteration 7848, loss = 0.00270556\n",
      "Iteration 7849, loss = 0.00270516\n",
      "Iteration 7850, loss = 0.00270470\n",
      "Iteration 7851, loss = 0.00270419\n",
      "Iteration 7852, loss = 0.00270367\n",
      "Iteration 7853, loss = 0.00270314\n",
      "Iteration 7854, loss = 0.00270264\n",
      "Iteration 7855, loss = 0.00270219\n",
      "Iteration 7856, loss = 0.00270172\n",
      "Iteration 7857, loss = 0.00270127\n",
      "Iteration 7858, loss = 0.00270078\n",
      "Iteration 7859, loss = 0.00270031\n",
      "Iteration 7860, loss = 0.00269982\n",
      "Iteration 7861, loss = 0.00269947\n",
      "Iteration 7862, loss = 0.00269896\n",
      "Iteration 7863, loss = 0.00269852\n",
      "Iteration 7864, loss = 0.00269818\n",
      "Iteration 7865, loss = 0.00269757\n",
      "Iteration 7866, loss = 0.00269718\n",
      "Iteration 7867, loss = 0.00269677\n",
      "Iteration 7868, loss = 0.00269629\n",
      "Iteration 7869, loss = 0.00269587\n",
      "Iteration 7870, loss = 0.00269539\n",
      "Iteration 7871, loss = 0.00269499\n",
      "Iteration 7872, loss = 0.00269446\n",
      "Iteration 7873, loss = 0.00269405\n",
      "Iteration 7874, loss = 0.00269351\n",
      "Iteration 7875, loss = 0.00269301\n",
      "Iteration 7876, loss = 0.00269263\n",
      "Iteration 7877, loss = 0.00269208\n",
      "Iteration 7878, loss = 0.00269175\n",
      "Iteration 7879, loss = 0.00269121\n",
      "Iteration 7880, loss = 0.00269068\n",
      "Iteration 7881, loss = 0.00269041\n",
      "Iteration 7882, loss = 0.00268989\n",
      "Iteration 7883, loss = 0.00268933\n",
      "Iteration 7884, loss = 0.00268888\n",
      "Iteration 7885, loss = 0.00268831\n",
      "Iteration 7886, loss = 0.00268779\n",
      "Iteration 7887, loss = 0.00268733\n",
      "Iteration 7888, loss = 0.00268710\n",
      "Iteration 7889, loss = 0.00268663\n",
      "Iteration 7890, loss = 0.00268594\n",
      "Iteration 7891, loss = 0.00268551\n",
      "Iteration 7892, loss = 0.00268499\n",
      "Iteration 7893, loss = 0.00268459\n",
      "Iteration 7894, loss = 0.00268404\n",
      "Iteration 7895, loss = 0.00268361\n",
      "Iteration 7896, loss = 0.00268325\n",
      "Iteration 7897, loss = 0.00268274\n",
      "Iteration 7898, loss = 0.00268231\n",
      "Iteration 7899, loss = 0.00268185\n",
      "Iteration 7900, loss = 0.00268139\n",
      "Iteration 7901, loss = 0.00268085\n",
      "Iteration 7902, loss = 0.00268048\n",
      "Iteration 7903, loss = 0.00268002\n",
      "Iteration 7904, loss = 0.00267952\n",
      "Iteration 7905, loss = 0.00267900\n",
      "Iteration 7906, loss = 0.00267852\n",
      "Iteration 7907, loss = 0.00267795\n",
      "Iteration 7908, loss = 0.00267749\n",
      "Iteration 7909, loss = 0.00267693\n",
      "Iteration 7910, loss = 0.00267663\n",
      "Iteration 7911, loss = 0.00267606\n",
      "Iteration 7912, loss = 0.00267552\n",
      "Iteration 7913, loss = 0.00267499\n",
      "Iteration 7914, loss = 0.00267478\n",
      "Iteration 7915, loss = 0.00267407\n",
      "Iteration 7916, loss = 0.00267362\n",
      "Iteration 7917, loss = 0.00267308\n",
      "Iteration 7918, loss = 0.00267254\n",
      "Iteration 7919, loss = 0.00267207\n",
      "Iteration 7920, loss = 0.00267157\n",
      "Iteration 7921, loss = 0.00267128\n",
      "Iteration 7922, loss = 0.00267071\n",
      "Iteration 7923, loss = 0.00267024\n",
      "Iteration 7924, loss = 0.00266979\n",
      "Iteration 7925, loss = 0.00266932\n",
      "Iteration 7926, loss = 0.00266885\n",
      "Iteration 7927, loss = 0.00266839\n",
      "Iteration 7928, loss = 0.00266795\n",
      "Iteration 7929, loss = 0.00266744\n",
      "Iteration 7930, loss = 0.00266699\n",
      "Iteration 7931, loss = 0.00266652\n",
      "Iteration 7932, loss = 0.00266615\n",
      "Iteration 7933, loss = 0.00266562\n",
      "Iteration 7934, loss = 0.00266521\n",
      "Iteration 7935, loss = 0.00266479\n",
      "Iteration 7936, loss = 0.00266431\n",
      "Iteration 7937, loss = 0.00266390\n",
      "Iteration 7938, loss = 0.00266350\n",
      "Iteration 7939, loss = 0.00266311\n",
      "Iteration 7940, loss = 0.00266274\n",
      "Iteration 7941, loss = 0.00266214\n",
      "Iteration 7942, loss = 0.00266165\n",
      "Iteration 7943, loss = 0.00266113\n",
      "Iteration 7944, loss = 0.00266055\n",
      "Iteration 7945, loss = 0.00266000\n",
      "Iteration 7946, loss = 0.00265969\n",
      "Iteration 7947, loss = 0.00265916\n",
      "Iteration 7948, loss = 0.00265863\n",
      "Iteration 7949, loss = 0.00265805\n",
      "Iteration 7950, loss = 0.00265800\n",
      "Iteration 7951, loss = 0.00265723\n",
      "Iteration 7952, loss = 0.00265677\n",
      "Iteration 7953, loss = 0.00265638\n",
      "Iteration 7954, loss = 0.00265594\n",
      "Iteration 7955, loss = 0.00265543\n",
      "Iteration 7956, loss = 0.00265514\n",
      "Iteration 7957, loss = 0.00265452\n",
      "Iteration 7958, loss = 0.00265430\n",
      "Iteration 7959, loss = 0.00265369\n",
      "Iteration 7960, loss = 0.00265324\n",
      "Iteration 7961, loss = 0.00265308\n",
      "Iteration 7962, loss = 0.00265247\n",
      "Iteration 7963, loss = 0.00265191\n",
      "Iteration 7964, loss = 0.00265139\n",
      "Iteration 7965, loss = 0.00265106\n",
      "Iteration 7966, loss = 0.00265041\n",
      "Iteration 7967, loss = 0.00264999\n",
      "Iteration 7968, loss = 0.00264949\n",
      "Iteration 7969, loss = 0.00264903\n",
      "Iteration 7970, loss = 0.00264856\n",
      "Iteration 7971, loss = 0.00264800\n",
      "Iteration 7972, loss = 0.00264755\n",
      "Iteration 7973, loss = 0.00264724\n",
      "Iteration 7974, loss = 0.00264660\n",
      "Iteration 7975, loss = 0.00264618\n",
      "Iteration 7976, loss = 0.00264563\n",
      "Iteration 7977, loss = 0.00264500\n",
      "Iteration 7978, loss = 0.00264454\n",
      "Iteration 7979, loss = 0.00264399\n",
      "Iteration 7980, loss = 0.00264350\n",
      "Iteration 7981, loss = 0.00264303\n",
      "Iteration 7982, loss = 0.00264258\n",
      "Iteration 7983, loss = 0.00264206\n",
      "Iteration 7984, loss = 0.00264167\n",
      "Iteration 7985, loss = 0.00264117\n",
      "Iteration 7986, loss = 0.00264070\n",
      "Iteration 7987, loss = 0.00264029\n",
      "Iteration 7988, loss = 0.00263984\n",
      "Iteration 7989, loss = 0.00263933\n",
      "Iteration 7990, loss = 0.00263894\n",
      "Iteration 7991, loss = 0.00263838\n",
      "Iteration 7992, loss = 0.00263795\n",
      "Iteration 7993, loss = 0.00263750\n",
      "Iteration 7994, loss = 0.00263698\n",
      "Iteration 7995, loss = 0.00263655\n",
      "Iteration 7996, loss = 0.00263605\n",
      "Iteration 7997, loss = 0.00263565\n",
      "Iteration 7998, loss = 0.00263517\n",
      "Iteration 7999, loss = 0.00263471\n",
      "Iteration 8000, loss = 0.00263424\n",
      "Iteration 1, loss = 1.04347472\n",
      "Iteration 2, loss = 1.04016060\n",
      "Iteration 3, loss = 1.03499856\n",
      "Iteration 4, loss = 1.02845023\n",
      "Iteration 5, loss = 1.02078738\n",
      "Iteration 6, loss = 1.01263375\n",
      "Iteration 7, loss = 1.00370114\n",
      "Iteration 8, loss = 0.99455040\n",
      "Iteration 9, loss = 0.98507900\n",
      "Iteration 10, loss = 0.97535638\n",
      "Iteration 11, loss = 0.96553258\n",
      "Iteration 12, loss = 0.95567027\n",
      "Iteration 13, loss = 0.94590532\n",
      "Iteration 14, loss = 0.93608087\n",
      "Iteration 15, loss = 0.92649648\n",
      "Iteration 16, loss = 0.91697405\n",
      "Iteration 17, loss = 0.90776450\n",
      "Iteration 18, loss = 0.89881684\n",
      "Iteration 19, loss = 0.88997691\n",
      "Iteration 20, loss = 0.88147843\n",
      "Iteration 21, loss = 0.87308688\n",
      "Iteration 22, loss = 0.86518574\n",
      "Iteration 23, loss = 0.85729323\n",
      "Iteration 24, loss = 0.84944322\n",
      "Iteration 25, loss = 0.84204373\n",
      "Iteration 26, loss = 0.83454918\n",
      "Iteration 27, loss = 0.82752849\n",
      "Iteration 28, loss = 0.82037277\n",
      "Iteration 29, loss = 0.81390885\n",
      "Iteration 30, loss = 0.80742935\n",
      "Iteration 31, loss = 0.80092786\n",
      "Iteration 32, loss = 0.79504138\n",
      "Iteration 33, loss = 0.78917655\n",
      "Iteration 34, loss = 0.78331039\n",
      "Iteration 35, loss = 0.77778233\n",
      "Iteration 36, loss = 0.77258953\n",
      "Iteration 37, loss = 0.76737201\n",
      "Iteration 38, loss = 0.76240031\n",
      "Iteration 39, loss = 0.75751813\n",
      "Iteration 40, loss = 0.75286658\n",
      "Iteration 41, loss = 0.74815620\n",
      "Iteration 42, loss = 0.74385279\n",
      "Iteration 43, loss = 0.73936413\n",
      "Iteration 44, loss = 0.73508889\n",
      "Iteration 45, loss = 0.73099930\n",
      "Iteration 46, loss = 0.72677159\n",
      "Iteration 47, loss = 0.72285854\n",
      "Iteration 48, loss = 0.71897500\n",
      "Iteration 49, loss = 0.71521973\n",
      "Iteration 50, loss = 0.71155063\n",
      "Iteration 51, loss = 0.70795366\n",
      "Iteration 52, loss = 0.70441910\n",
      "Iteration 53, loss = 0.70096851\n",
      "Iteration 54, loss = 0.69763813\n",
      "Iteration 55, loss = 0.69417030\n",
      "Iteration 56, loss = 0.69081627\n",
      "Iteration 57, loss = 0.68768181\n",
      "Iteration 58, loss = 0.68424318\n",
      "Iteration 59, loss = 0.68120082\n",
      "Iteration 60, loss = 0.67800159\n",
      "Iteration 61, loss = 0.67494585\n",
      "Iteration 62, loss = 0.67194843\n",
      "Iteration 63, loss = 0.66894430\n",
      "Iteration 64, loss = 0.66598969\n",
      "Iteration 65, loss = 0.66312754\n",
      "Iteration 66, loss = 0.66024547\n",
      "Iteration 67, loss = 0.65739354\n",
      "Iteration 68, loss = 0.65455036\n",
      "Iteration 69, loss = 0.65173114\n",
      "Iteration 70, loss = 0.64901483\n",
      "Iteration 71, loss = 0.64618066\n",
      "Iteration 72, loss = 0.64347139\n",
      "Iteration 73, loss = 0.64073436\n",
      "Iteration 74, loss = 0.63803303\n",
      "Iteration 75, loss = 0.63528506\n",
      "Iteration 76, loss = 0.63259664\n",
      "Iteration 77, loss = 0.62996477\n",
      "Iteration 78, loss = 0.62724224\n",
      "Iteration 79, loss = 0.62460802\n",
      "Iteration 80, loss = 0.62199962\n",
      "Iteration 81, loss = 0.61940298\n",
      "Iteration 82, loss = 0.61682238\n",
      "Iteration 83, loss = 0.61426437\n",
      "Iteration 84, loss = 0.61169487\n",
      "Iteration 85, loss = 0.60909895\n",
      "Iteration 86, loss = 0.60663559\n",
      "Iteration 87, loss = 0.60400911\n",
      "Iteration 88, loss = 0.60150310\n",
      "Iteration 89, loss = 0.59896532\n",
      "Iteration 90, loss = 0.59640800\n",
      "Iteration 91, loss = 0.59393023\n",
      "Iteration 92, loss = 0.59141436\n",
      "Iteration 93, loss = 0.58888744\n",
      "Iteration 94, loss = 0.58640989\n",
      "Iteration 95, loss = 0.58394004\n",
      "Iteration 96, loss = 0.58146791\n",
      "Iteration 97, loss = 0.57901167\n",
      "Iteration 98, loss = 0.57653509\n",
      "Iteration 99, loss = 0.57414555\n",
      "Iteration 100, loss = 0.57174918\n",
      "Iteration 101, loss = 0.56928914\n",
      "Iteration 102, loss = 0.56689807\n",
      "Iteration 103, loss = 0.56448483\n",
      "Iteration 104, loss = 0.56213688\n",
      "Iteration 105, loss = 0.55972199\n",
      "Iteration 106, loss = 0.55739935\n",
      "Iteration 107, loss = 0.55497950\n",
      "Iteration 108, loss = 0.55269718\n",
      "Iteration 109, loss = 0.55033534\n",
      "Iteration 110, loss = 0.54799795\n",
      "Iteration 111, loss = 0.54567491\n",
      "Iteration 112, loss = 0.54333616\n",
      "Iteration 113, loss = 0.54106473\n",
      "Iteration 114, loss = 0.53872565\n",
      "Iteration 115, loss = 0.53642096\n",
      "Iteration 116, loss = 0.53414952\n",
      "Iteration 117, loss = 0.53183717\n",
      "Iteration 118, loss = 0.52955000\n",
      "Iteration 119, loss = 0.52723745\n",
      "Iteration 120, loss = 0.52494310\n",
      "Iteration 121, loss = 0.52264913\n",
      "Iteration 122, loss = 0.52040102\n",
      "Iteration 123, loss = 0.51807715\n",
      "Iteration 124, loss = 0.51586153\n",
      "Iteration 125, loss = 0.51367979\n",
      "Iteration 126, loss = 0.51147418\n",
      "Iteration 127, loss = 0.50928397\n",
      "Iteration 128, loss = 0.50711793\n",
      "Iteration 129, loss = 0.50494474\n",
      "Iteration 130, loss = 0.50276866\n",
      "Iteration 131, loss = 0.50061619\n",
      "Iteration 132, loss = 0.49846113\n",
      "Iteration 133, loss = 0.49632541\n",
      "Iteration 134, loss = 0.49421802\n",
      "Iteration 135, loss = 0.49209699\n",
      "Iteration 136, loss = 0.48996418\n",
      "Iteration 137, loss = 0.48787740\n",
      "Iteration 138, loss = 0.48575340\n",
      "Iteration 139, loss = 0.48363918\n",
      "Iteration 140, loss = 0.48154034\n",
      "Iteration 141, loss = 0.47941627\n",
      "Iteration 142, loss = 0.47731046\n",
      "Iteration 143, loss = 0.47519226\n",
      "Iteration 144, loss = 0.47310300\n",
      "Iteration 145, loss = 0.47095118\n",
      "Iteration 146, loss = 0.46886160\n",
      "Iteration 147, loss = 0.46672980\n",
      "Iteration 148, loss = 0.46466104\n",
      "Iteration 149, loss = 0.46250435\n",
      "Iteration 150, loss = 0.46040565\n",
      "Iteration 151, loss = 0.45831546\n",
      "Iteration 152, loss = 0.45617053\n",
      "Iteration 153, loss = 0.45405863\n",
      "Iteration 154, loss = 0.45193867\n",
      "Iteration 155, loss = 0.44981527\n",
      "Iteration 156, loss = 0.44773926\n",
      "Iteration 157, loss = 0.44559365\n",
      "Iteration 158, loss = 0.44352523\n",
      "Iteration 159, loss = 0.44142915\n",
      "Iteration 160, loss = 0.43935821\n",
      "Iteration 161, loss = 0.43727065\n",
      "Iteration 162, loss = 0.43518676\n",
      "Iteration 163, loss = 0.43307995\n",
      "Iteration 164, loss = 0.43099589\n",
      "Iteration 165, loss = 0.42886785\n",
      "Iteration 166, loss = 0.42674981\n",
      "Iteration 167, loss = 0.42462054\n",
      "Iteration 168, loss = 0.42249378\n",
      "Iteration 169, loss = 0.42034882\n",
      "Iteration 170, loss = 0.41820396\n",
      "Iteration 171, loss = 0.41608639\n",
      "Iteration 172, loss = 0.41395200\n",
      "Iteration 173, loss = 0.41180213\n",
      "Iteration 174, loss = 0.40971870\n",
      "Iteration 175, loss = 0.40759941\n",
      "Iteration 176, loss = 0.40548491\n",
      "Iteration 177, loss = 0.40340437\n",
      "Iteration 178, loss = 0.40128372\n",
      "Iteration 179, loss = 0.39920309\n",
      "Iteration 180, loss = 0.39711057\n",
      "Iteration 181, loss = 0.39505085\n",
      "Iteration 182, loss = 0.39295047\n",
      "Iteration 183, loss = 0.39088462\n",
      "Iteration 184, loss = 0.38879515\n",
      "Iteration 185, loss = 0.38676834\n",
      "Iteration 186, loss = 0.38471432\n",
      "Iteration 187, loss = 0.38263876\n",
      "Iteration 188, loss = 0.38061044\n",
      "Iteration 189, loss = 0.37858743\n",
      "Iteration 190, loss = 0.37653975\n",
      "Iteration 191, loss = 0.37450787\n",
      "Iteration 192, loss = 0.37249621\n",
      "Iteration 193, loss = 0.37046541\n",
      "Iteration 194, loss = 0.36841806\n",
      "Iteration 195, loss = 0.36640308\n",
      "Iteration 196, loss = 0.36435019\n",
      "Iteration 197, loss = 0.36233086\n",
      "Iteration 198, loss = 0.36029481\n",
      "Iteration 199, loss = 0.35826679\n",
      "Iteration 200, loss = 0.35622811\n",
      "Iteration 201, loss = 0.35422799\n",
      "Iteration 202, loss = 0.35219126\n",
      "Iteration 203, loss = 0.35016456\n",
      "Iteration 204, loss = 0.34814838\n",
      "Iteration 205, loss = 0.34612278\n",
      "Iteration 206, loss = 0.34412585\n",
      "Iteration 207, loss = 0.34212076\n",
      "Iteration 208, loss = 0.34010801\n",
      "Iteration 209, loss = 0.33811678\n",
      "Iteration 210, loss = 0.33613378\n",
      "Iteration 211, loss = 0.33413335\n",
      "Iteration 212, loss = 0.33216612\n",
      "Iteration 213, loss = 0.33022412\n",
      "Iteration 214, loss = 0.32823897\n",
      "Iteration 215, loss = 0.32630082\n",
      "Iteration 216, loss = 0.32435095\n",
      "Iteration 217, loss = 0.32241317\n",
      "Iteration 218, loss = 0.32049133\n",
      "Iteration 219, loss = 0.31857660\n",
      "Iteration 220, loss = 0.31665587\n",
      "Iteration 221, loss = 0.31476155\n",
      "Iteration 222, loss = 0.31287491\n",
      "Iteration 223, loss = 0.31099148\n",
      "Iteration 224, loss = 0.30911401\n",
      "Iteration 225, loss = 0.30724243\n",
      "Iteration 226, loss = 0.30540329\n",
      "Iteration 227, loss = 0.30352975\n",
      "Iteration 228, loss = 0.30168912\n",
      "Iteration 229, loss = 0.29983089\n",
      "Iteration 230, loss = 0.29800351\n",
      "Iteration 231, loss = 0.29614368\n",
      "Iteration 232, loss = 0.29431638\n",
      "Iteration 233, loss = 0.29248388\n",
      "Iteration 234, loss = 0.29068163\n",
      "Iteration 235, loss = 0.28885551\n",
      "Iteration 236, loss = 0.28706800\n",
      "Iteration 237, loss = 0.28528861\n",
      "Iteration 238, loss = 0.28350128\n",
      "Iteration 239, loss = 0.28173736\n",
      "Iteration 240, loss = 0.27998382\n",
      "Iteration 241, loss = 0.27823717\n",
      "Iteration 242, loss = 0.27650643\n",
      "Iteration 243, loss = 0.27479266\n",
      "Iteration 244, loss = 0.27306894\n",
      "Iteration 245, loss = 0.27138068\n",
      "Iteration 246, loss = 0.26967535\n",
      "Iteration 247, loss = 0.26798035\n",
      "Iteration 248, loss = 0.26628775\n",
      "Iteration 249, loss = 0.26460350\n",
      "Iteration 250, loss = 0.26297071\n",
      "Iteration 251, loss = 0.26128572\n",
      "Iteration 252, loss = 0.25964989\n",
      "Iteration 253, loss = 0.25802629\n",
      "Iteration 254, loss = 0.25640288\n",
      "Iteration 255, loss = 0.25479643\n",
      "Iteration 256, loss = 0.25319567\n",
      "Iteration 257, loss = 0.25163081\n",
      "Iteration 258, loss = 0.25004438\n",
      "Iteration 259, loss = 0.24844795\n",
      "Iteration 260, loss = 0.24687385\n",
      "Iteration 261, loss = 0.24532197\n",
      "Iteration 262, loss = 0.24376512\n",
      "Iteration 263, loss = 0.24222273\n",
      "Iteration 264, loss = 0.24070186\n",
      "Iteration 265, loss = 0.23919138\n",
      "Iteration 266, loss = 0.23768513\n",
      "Iteration 267, loss = 0.23619185\n",
      "Iteration 268, loss = 0.23470623\n",
      "Iteration 269, loss = 0.23323678\n",
      "Iteration 270, loss = 0.23175745\n",
      "Iteration 271, loss = 0.23032637\n",
      "Iteration 272, loss = 0.22889260\n",
      "Iteration 273, loss = 0.22745786\n",
      "Iteration 274, loss = 0.22605223\n",
      "Iteration 275, loss = 0.22464072\n",
      "Iteration 276, loss = 0.22323927\n",
      "Iteration 277, loss = 0.22185065\n",
      "Iteration 278, loss = 0.22049221\n",
      "Iteration 279, loss = 0.21909462\n",
      "Iteration 280, loss = 0.21774978\n",
      "Iteration 281, loss = 0.21640436\n",
      "Iteration 282, loss = 0.21507386\n",
      "Iteration 283, loss = 0.21374392\n",
      "Iteration 284, loss = 0.21242286\n",
      "Iteration 285, loss = 0.21110967\n",
      "Iteration 286, loss = 0.20982116\n",
      "Iteration 287, loss = 0.20852334\n",
      "Iteration 288, loss = 0.20723755\n",
      "Iteration 289, loss = 0.20597010\n",
      "Iteration 290, loss = 0.20471098\n",
      "Iteration 291, loss = 0.20344954\n",
      "Iteration 292, loss = 0.20221726\n",
      "Iteration 293, loss = 0.20098459\n",
      "Iteration 294, loss = 0.19975798\n",
      "Iteration 295, loss = 0.19854944\n",
      "Iteration 296, loss = 0.19734715\n",
      "Iteration 297, loss = 0.19614942\n",
      "Iteration 298, loss = 0.19495739\n",
      "Iteration 299, loss = 0.19378283\n",
      "Iteration 300, loss = 0.19263111\n",
      "Iteration 301, loss = 0.19146993\n",
      "Iteration 302, loss = 0.19033093\n",
      "Iteration 303, loss = 0.18921010\n",
      "Iteration 304, loss = 0.18809096\n",
      "Iteration 305, loss = 0.18698644\n",
      "Iteration 306, loss = 0.18588566\n",
      "Iteration 307, loss = 0.18479127\n",
      "Iteration 308, loss = 0.18369892\n",
      "Iteration 309, loss = 0.18262256\n",
      "Iteration 310, loss = 0.18155191\n",
      "Iteration 311, loss = 0.18049420\n",
      "Iteration 312, loss = 0.17943553\n",
      "Iteration 313, loss = 0.17840042\n",
      "Iteration 314, loss = 0.17736134\n",
      "Iteration 315, loss = 0.17632909\n",
      "Iteration 316, loss = 0.17531076\n",
      "Iteration 317, loss = 0.17428511\n",
      "Iteration 318, loss = 0.17328307\n",
      "Iteration 319, loss = 0.17228175\n",
      "Iteration 320, loss = 0.17128526\n",
      "Iteration 321, loss = 0.17030001\n",
      "Iteration 322, loss = 0.16932287\n",
      "Iteration 323, loss = 0.16835301\n",
      "Iteration 324, loss = 0.16740090\n",
      "Iteration 325, loss = 0.16644399\n",
      "Iteration 326, loss = 0.16550747\n",
      "Iteration 327, loss = 0.16456623\n",
      "Iteration 328, loss = 0.16363611\n",
      "Iteration 329, loss = 0.16271913\n",
      "Iteration 330, loss = 0.16180889\n",
      "Iteration 331, loss = 0.16089531\n",
      "Iteration 332, loss = 0.16000111\n",
      "Iteration 333, loss = 0.15911977\n",
      "Iteration 334, loss = 0.15824559\n",
      "Iteration 335, loss = 0.15737248\n",
      "Iteration 336, loss = 0.15651690\n",
      "Iteration 337, loss = 0.15567167\n",
      "Iteration 338, loss = 0.15482116\n",
      "Iteration 339, loss = 0.15399789\n",
      "Iteration 340, loss = 0.15316562\n",
      "Iteration 341, loss = 0.15235234\n",
      "Iteration 342, loss = 0.15153505\n",
      "Iteration 343, loss = 0.15073326\n",
      "Iteration 344, loss = 0.14992712\n",
      "Iteration 345, loss = 0.14913173\n",
      "Iteration 346, loss = 0.14834184\n",
      "Iteration 347, loss = 0.14756833\n",
      "Iteration 348, loss = 0.14679469\n",
      "Iteration 349, loss = 0.14603361\n",
      "Iteration 350, loss = 0.14526922\n",
      "Iteration 351, loss = 0.14451291\n",
      "Iteration 352, loss = 0.14375518\n",
      "Iteration 353, loss = 0.14300150\n",
      "Iteration 354, loss = 0.14224983\n",
      "Iteration 355, loss = 0.14150341\n",
      "Iteration 356, loss = 0.14076130\n",
      "Iteration 357, loss = 0.14002732\n",
      "Iteration 358, loss = 0.13929714\n",
      "Iteration 359, loss = 0.13858778\n",
      "Iteration 360, loss = 0.13787378\n",
      "Iteration 361, loss = 0.13717605\n",
      "Iteration 362, loss = 0.13648039\n",
      "Iteration 363, loss = 0.13578822\n",
      "Iteration 364, loss = 0.13511126\n",
      "Iteration 365, loss = 0.13443641\n",
      "Iteration 366, loss = 0.13375654\n",
      "Iteration 367, loss = 0.13309943\n",
      "Iteration 368, loss = 0.13243749\n",
      "Iteration 369, loss = 0.13178145\n",
      "Iteration 370, loss = 0.13113452\n",
      "Iteration 371, loss = 0.13048851\n",
      "Iteration 372, loss = 0.12985123\n",
      "Iteration 373, loss = 0.12922035\n",
      "Iteration 374, loss = 0.12860132\n",
      "Iteration 375, loss = 0.12797497\n",
      "Iteration 376, loss = 0.12736388\n",
      "Iteration 377, loss = 0.12676287\n",
      "Iteration 378, loss = 0.12616401\n",
      "Iteration 379, loss = 0.12556304\n",
      "Iteration 380, loss = 0.12496859\n",
      "Iteration 381, loss = 0.12437638\n",
      "Iteration 382, loss = 0.12378716\n",
      "Iteration 383, loss = 0.12320345\n",
      "Iteration 384, loss = 0.12263152\n",
      "Iteration 385, loss = 0.12206147\n",
      "Iteration 386, loss = 0.12149580\n",
      "Iteration 387, loss = 0.12093880\n",
      "Iteration 388, loss = 0.12038190\n",
      "Iteration 389, loss = 0.11983358\n",
      "Iteration 390, loss = 0.11929246\n",
      "Iteration 391, loss = 0.11875099\n",
      "Iteration 392, loss = 0.11822524\n",
      "Iteration 393, loss = 0.11769794\n",
      "Iteration 394, loss = 0.11717766\n",
      "Iteration 395, loss = 0.11666457\n",
      "Iteration 396, loss = 0.11614916\n",
      "Iteration 397, loss = 0.11564044\n",
      "Iteration 398, loss = 0.11512900\n",
      "Iteration 399, loss = 0.11462337\n",
      "Iteration 400, loss = 0.11412151\n",
      "Iteration 401, loss = 0.11362999\n",
      "Iteration 402, loss = 0.11312470\n",
      "Iteration 403, loss = 0.11264629\n",
      "Iteration 404, loss = 0.11215513\n",
      "Iteration 405, loss = 0.11167207\n",
      "Iteration 406, loss = 0.11119091\n",
      "Iteration 407, loss = 0.11072330\n",
      "Iteration 408, loss = 0.11025394\n",
      "Iteration 409, loss = 0.10979216\n",
      "Iteration 410, loss = 0.10933163\n",
      "Iteration 411, loss = 0.10887913\n",
      "Iteration 412, loss = 0.10842424\n",
      "Iteration 413, loss = 0.10797791\n",
      "Iteration 414, loss = 0.10752767\n",
      "Iteration 415, loss = 0.10707947\n",
      "Iteration 416, loss = 0.10664620\n",
      "Iteration 417, loss = 0.10621004\n",
      "Iteration 418, loss = 0.10577678\n",
      "Iteration 419, loss = 0.10535361\n",
      "Iteration 420, loss = 0.10493105\n",
      "Iteration 421, loss = 0.10450671\n",
      "Iteration 422, loss = 0.10409483\n",
      "Iteration 423, loss = 0.10366917\n",
      "Iteration 424, loss = 0.10325523\n",
      "Iteration 425, loss = 0.10283891\n",
      "Iteration 426, loss = 0.10242836\n",
      "Iteration 427, loss = 0.10201487\n",
      "Iteration 428, loss = 0.10160042\n",
      "Iteration 429, loss = 0.10119771\n",
      "Iteration 430, loss = 0.10078903\n",
      "Iteration 431, loss = 0.10038521\n",
      "Iteration 432, loss = 0.09998087\n",
      "Iteration 433, loss = 0.09959190\n",
      "Iteration 434, loss = 0.09919391\n",
      "Iteration 435, loss = 0.09880654\n",
      "Iteration 436, loss = 0.09842519\n",
      "Iteration 437, loss = 0.09804465\n",
      "Iteration 438, loss = 0.09766907\n",
      "Iteration 439, loss = 0.09729773\n",
      "Iteration 440, loss = 0.09692805\n",
      "Iteration 441, loss = 0.09656156\n",
      "Iteration 442, loss = 0.09620304\n",
      "Iteration 443, loss = 0.09584325\n",
      "Iteration 444, loss = 0.09547966\n",
      "Iteration 445, loss = 0.09512615\n",
      "Iteration 446, loss = 0.09476844\n",
      "Iteration 447, loss = 0.09441633\n",
      "Iteration 448, loss = 0.09406078\n",
      "Iteration 449, loss = 0.09371857\n",
      "Iteration 450, loss = 0.09337620\n",
      "Iteration 451, loss = 0.09303325\n",
      "Iteration 452, loss = 0.09268890\n",
      "Iteration 453, loss = 0.09235302\n",
      "Iteration 454, loss = 0.09201441\n",
      "Iteration 455, loss = 0.09169000\n",
      "Iteration 456, loss = 0.09135180\n",
      "Iteration 457, loss = 0.09102599\n",
      "Iteration 458, loss = 0.09069932\n",
      "Iteration 459, loss = 0.09037138\n",
      "Iteration 460, loss = 0.09004672\n",
      "Iteration 461, loss = 0.08972316\n",
      "Iteration 462, loss = 0.08940326\n",
      "Iteration 463, loss = 0.08908189\n",
      "Iteration 464, loss = 0.08875868\n",
      "Iteration 465, loss = 0.08844362\n",
      "Iteration 466, loss = 0.08813454\n",
      "Iteration 467, loss = 0.08782000\n",
      "Iteration 468, loss = 0.08751508\n",
      "Iteration 469, loss = 0.08721237\n",
      "Iteration 470, loss = 0.08690997\n",
      "Iteration 471, loss = 0.08661714\n",
      "Iteration 472, loss = 0.08632589\n",
      "Iteration 473, loss = 0.08603006\n",
      "Iteration 474, loss = 0.08574089\n",
      "Iteration 475, loss = 0.08545677\n",
      "Iteration 476, loss = 0.08516814\n",
      "Iteration 477, loss = 0.08489275\n",
      "Iteration 478, loss = 0.08461744\n",
      "Iteration 479, loss = 0.08434082\n",
      "Iteration 480, loss = 0.08406295\n",
      "Iteration 481, loss = 0.08378752\n",
      "Iteration 482, loss = 0.08350658\n",
      "Iteration 483, loss = 0.08323157\n",
      "Iteration 484, loss = 0.08295608\n",
      "Iteration 485, loss = 0.08268520\n",
      "Iteration 486, loss = 0.08241208\n",
      "Iteration 487, loss = 0.08214400\n",
      "Iteration 488, loss = 0.08188360\n",
      "Iteration 489, loss = 0.08161553\n",
      "Iteration 490, loss = 0.08135296\n",
      "Iteration 491, loss = 0.08108466\n",
      "Iteration 492, loss = 0.08083760\n",
      "Iteration 493, loss = 0.08056539\n",
      "Iteration 494, loss = 0.08030947\n",
      "Iteration 495, loss = 0.08005905\n",
      "Iteration 496, loss = 0.07980639\n",
      "Iteration 497, loss = 0.07956185\n",
      "Iteration 498, loss = 0.07931565\n",
      "Iteration 499, loss = 0.07907659\n",
      "Iteration 500, loss = 0.07883827\n",
      "Iteration 501, loss = 0.07859776\n",
      "Iteration 502, loss = 0.07835628\n",
      "Iteration 503, loss = 0.07812666\n",
      "Iteration 504, loss = 0.07789143\n",
      "Iteration 505, loss = 0.07766363\n",
      "Iteration 506, loss = 0.07743382\n",
      "Iteration 507, loss = 0.07720329\n",
      "Iteration 508, loss = 0.07698208\n",
      "Iteration 509, loss = 0.07675933\n",
      "Iteration 510, loss = 0.07653613\n",
      "Iteration 511, loss = 0.07631798\n",
      "Iteration 512, loss = 0.07609986\n",
      "Iteration 513, loss = 0.07588128\n",
      "Iteration 514, loss = 0.07566189\n",
      "Iteration 515, loss = 0.07544239\n",
      "Iteration 516, loss = 0.07522539\n",
      "Iteration 517, loss = 0.07500529\n",
      "Iteration 518, loss = 0.07479388\n",
      "Iteration 519, loss = 0.07457356\n",
      "Iteration 520, loss = 0.07436062\n",
      "Iteration 521, loss = 0.07415600\n",
      "Iteration 522, loss = 0.07393872\n",
      "Iteration 523, loss = 0.07373032\n",
      "Iteration 524, loss = 0.07352126\n",
      "Iteration 525, loss = 0.07332026\n",
      "Iteration 526, loss = 0.07311493\n",
      "Iteration 527, loss = 0.07291429\n",
      "Iteration 528, loss = 0.07271827\n",
      "Iteration 529, loss = 0.07251112\n",
      "Iteration 530, loss = 0.07231652\n",
      "Iteration 531, loss = 0.07211857\n",
      "Iteration 532, loss = 0.07192296\n",
      "Iteration 533, loss = 0.07173130\n",
      "Iteration 534, loss = 0.07154074\n",
      "Iteration 535, loss = 0.07135101\n",
      "Iteration 536, loss = 0.07116068\n",
      "Iteration 537, loss = 0.07096685\n",
      "Iteration 538, loss = 0.07078121\n",
      "Iteration 539, loss = 0.07058473\n",
      "Iteration 540, loss = 0.07039374\n",
      "Iteration 541, loss = 0.07020376\n",
      "Iteration 542, loss = 0.07001798\n",
      "Iteration 543, loss = 0.06982945\n",
      "Iteration 544, loss = 0.06964319\n",
      "Iteration 545, loss = 0.06946357\n",
      "Iteration 546, loss = 0.06927692\n",
      "Iteration 547, loss = 0.06909620\n",
      "Iteration 548, loss = 0.06890987\n",
      "Iteration 549, loss = 0.06873608\n",
      "Iteration 550, loss = 0.06855711\n",
      "Iteration 551, loss = 0.06838018\n",
      "Iteration 552, loss = 0.06820439\n",
      "Iteration 553, loss = 0.06802526\n",
      "Iteration 554, loss = 0.06786447\n",
      "Iteration 555, loss = 0.06768836\n",
      "Iteration 556, loss = 0.06751686\n",
      "Iteration 557, loss = 0.06734331\n",
      "Iteration 558, loss = 0.06718181\n",
      "Iteration 559, loss = 0.06701596\n",
      "Iteration 560, loss = 0.06685057\n",
      "Iteration 561, loss = 0.06668639\n",
      "Iteration 562, loss = 0.06652400\n",
      "Iteration 563, loss = 0.06636874\n",
      "Iteration 564, loss = 0.06620384\n",
      "Iteration 565, loss = 0.06604913\n",
      "Iteration 566, loss = 0.06588995\n",
      "Iteration 567, loss = 0.06573247\n",
      "Iteration 568, loss = 0.06557483\n",
      "Iteration 569, loss = 0.06542128\n",
      "Iteration 570, loss = 0.06525950\n",
      "Iteration 571, loss = 0.06510624\n",
      "Iteration 572, loss = 0.06494747\n",
      "Iteration 573, loss = 0.06479876\n",
      "Iteration 574, loss = 0.06464341\n",
      "Iteration 575, loss = 0.06448131\n",
      "Iteration 576, loss = 0.06433198\n",
      "Iteration 577, loss = 0.06418160\n",
      "Iteration 578, loss = 0.06402352\n",
      "Iteration 579, loss = 0.06387109\n",
      "Iteration 580, loss = 0.06371942\n",
      "Iteration 581, loss = 0.06357092\n",
      "Iteration 582, loss = 0.06341374\n",
      "Iteration 583, loss = 0.06326426\n",
      "Iteration 584, loss = 0.06311719\n",
      "Iteration 585, loss = 0.06297023\n",
      "Iteration 586, loss = 0.06282626\n",
      "Iteration 587, loss = 0.06268149\n",
      "Iteration 588, loss = 0.06253573\n",
      "Iteration 589, loss = 0.06239071\n",
      "Iteration 590, loss = 0.06224665\n",
      "Iteration 591, loss = 0.06210524\n",
      "Iteration 592, loss = 0.06196148\n",
      "Iteration 593, loss = 0.06181708\n",
      "Iteration 594, loss = 0.06168286\n",
      "Iteration 595, loss = 0.06153735\n",
      "Iteration 596, loss = 0.06139504\n",
      "Iteration 597, loss = 0.06125681\n",
      "Iteration 598, loss = 0.06111660\n",
      "Iteration 599, loss = 0.06097822\n",
      "Iteration 600, loss = 0.06084300\n",
      "Iteration 601, loss = 0.06070837\n",
      "Iteration 602, loss = 0.06057660\n",
      "Iteration 603, loss = 0.06043967\n",
      "Iteration 604, loss = 0.06030824\n",
      "Iteration 605, loss = 0.06017525\n",
      "Iteration 606, loss = 0.06004839\n",
      "Iteration 607, loss = 0.05991915\n",
      "Iteration 608, loss = 0.05978944\n",
      "Iteration 609, loss = 0.05966674\n",
      "Iteration 610, loss = 0.05953765\n",
      "Iteration 611, loss = 0.05941488\n",
      "Iteration 612, loss = 0.05928547\n",
      "Iteration 613, loss = 0.05916082\n",
      "Iteration 614, loss = 0.05903934\n",
      "Iteration 615, loss = 0.05891152\n",
      "Iteration 616, loss = 0.05879133\n",
      "Iteration 617, loss = 0.05866951\n",
      "Iteration 618, loss = 0.05854968\n",
      "Iteration 619, loss = 0.05842890\n",
      "Iteration 620, loss = 0.05831209\n",
      "Iteration 621, loss = 0.05819373\n",
      "Iteration 622, loss = 0.05807842\n",
      "Iteration 623, loss = 0.05796128\n",
      "Iteration 624, loss = 0.05784604\n",
      "Iteration 625, loss = 0.05773182\n",
      "Iteration 626, loss = 0.05761626\n",
      "Iteration 627, loss = 0.05750111\n",
      "Iteration 628, loss = 0.05738804\n",
      "Iteration 629, loss = 0.05727492\n",
      "Iteration 630, loss = 0.05716717\n",
      "Iteration 631, loss = 0.05704256\n",
      "Iteration 632, loss = 0.05692981\n",
      "Iteration 633, loss = 0.05681448\n",
      "Iteration 634, loss = 0.05670251\n",
      "Iteration 635, loss = 0.05659044\n",
      "Iteration 636, loss = 0.05648639\n",
      "Iteration 637, loss = 0.05636767\n",
      "Iteration 638, loss = 0.05626357\n",
      "Iteration 639, loss = 0.05615322\n",
      "Iteration 640, loss = 0.05604031\n",
      "Iteration 641, loss = 0.05593343\n",
      "Iteration 642, loss = 0.05582686\n",
      "Iteration 643, loss = 0.05572310\n",
      "Iteration 644, loss = 0.05561501\n",
      "Iteration 645, loss = 0.05551407\n",
      "Iteration 646, loss = 0.05540775\n",
      "Iteration 647, loss = 0.05530133\n",
      "Iteration 648, loss = 0.05519614\n",
      "Iteration 649, loss = 0.05509365\n",
      "Iteration 650, loss = 0.05498901\n",
      "Iteration 651, loss = 0.05488766\n",
      "Iteration 652, loss = 0.05478581\n",
      "Iteration 653, loss = 0.05468136\n",
      "Iteration 654, loss = 0.05457909\n",
      "Iteration 655, loss = 0.05448197\n",
      "Iteration 656, loss = 0.05437481\n",
      "Iteration 657, loss = 0.05427422\n",
      "Iteration 658, loss = 0.05417395\n",
      "Iteration 659, loss = 0.05407389\n",
      "Iteration 660, loss = 0.05397507\n",
      "Iteration 661, loss = 0.05388068\n",
      "Iteration 662, loss = 0.05377670\n",
      "Iteration 663, loss = 0.05367897\n",
      "Iteration 664, loss = 0.05357925\n",
      "Iteration 665, loss = 0.05347968\n",
      "Iteration 666, loss = 0.05338414\n",
      "Iteration 667, loss = 0.05328274\n",
      "Iteration 668, loss = 0.05318725\n",
      "Iteration 669, loss = 0.05309060\n",
      "Iteration 670, loss = 0.05299026\n",
      "Iteration 671, loss = 0.05289611\n",
      "Iteration 672, loss = 0.05280109\n",
      "Iteration 673, loss = 0.05270392\n",
      "Iteration 674, loss = 0.05261161\n",
      "Iteration 675, loss = 0.05251690\n",
      "Iteration 676, loss = 0.05242359\n",
      "Iteration 677, loss = 0.05233273\n",
      "Iteration 678, loss = 0.05223904\n",
      "Iteration 679, loss = 0.05214634\n",
      "Iteration 680, loss = 0.05205632\n",
      "Iteration 681, loss = 0.05196420\n",
      "Iteration 682, loss = 0.05187492\n",
      "Iteration 683, loss = 0.05178273\n",
      "Iteration 684, loss = 0.05168983\n",
      "Iteration 685, loss = 0.05159991\n",
      "Iteration 686, loss = 0.05151093\n",
      "Iteration 687, loss = 0.05142232\n",
      "Iteration 688, loss = 0.05133408\n",
      "Iteration 689, loss = 0.05124587\n",
      "Iteration 690, loss = 0.05115366\n",
      "Iteration 691, loss = 0.05106672\n",
      "Iteration 692, loss = 0.05097788\n",
      "Iteration 693, loss = 0.05089164\n",
      "Iteration 694, loss = 0.05081279\n",
      "Iteration 695, loss = 0.05072114\n",
      "Iteration 696, loss = 0.05063654\n",
      "Iteration 697, loss = 0.05055245\n",
      "Iteration 698, loss = 0.05046569\n",
      "Iteration 699, loss = 0.05038374\n",
      "Iteration 700, loss = 0.05029610\n",
      "Iteration 701, loss = 0.05021364\n",
      "Iteration 702, loss = 0.05012720\n",
      "Iteration 703, loss = 0.05004443\n",
      "Iteration 704, loss = 0.04996361\n",
      "Iteration 705, loss = 0.04987867\n",
      "Iteration 706, loss = 0.04979240\n",
      "Iteration 707, loss = 0.04970664\n",
      "Iteration 708, loss = 0.04962152\n",
      "Iteration 709, loss = 0.04954154\n",
      "Iteration 710, loss = 0.04945672\n",
      "Iteration 711, loss = 0.04937158\n",
      "Iteration 712, loss = 0.04928946\n",
      "Iteration 713, loss = 0.04920705\n",
      "Iteration 714, loss = 0.04912826\n",
      "Iteration 715, loss = 0.04904749\n",
      "Iteration 716, loss = 0.04897117\n",
      "Iteration 717, loss = 0.04889039\n",
      "Iteration 718, loss = 0.04881288\n",
      "Iteration 719, loss = 0.04873432\n",
      "Iteration 720, loss = 0.04865701\n",
      "Iteration 721, loss = 0.04857998\n",
      "Iteration 722, loss = 0.04850390\n",
      "Iteration 723, loss = 0.04842469\n",
      "Iteration 724, loss = 0.04834818\n",
      "Iteration 725, loss = 0.04827270\n",
      "Iteration 726, loss = 0.04819641\n",
      "Iteration 727, loss = 0.04812109\n",
      "Iteration 728, loss = 0.04804663\n",
      "Iteration 729, loss = 0.04797364\n",
      "Iteration 730, loss = 0.04790258\n",
      "Iteration 731, loss = 0.04782535\n",
      "Iteration 732, loss = 0.04774786\n",
      "Iteration 733, loss = 0.04766966\n",
      "Iteration 734, loss = 0.04759170\n",
      "Iteration 735, loss = 0.04751575\n",
      "Iteration 736, loss = 0.04743951\n",
      "Iteration 737, loss = 0.04736441\n",
      "Iteration 738, loss = 0.04729157\n",
      "Iteration 739, loss = 0.04721584\n",
      "Iteration 740, loss = 0.04714472\n",
      "Iteration 741, loss = 0.04707505\n",
      "Iteration 742, loss = 0.04699923\n",
      "Iteration 743, loss = 0.04692730\n",
      "Iteration 744, loss = 0.04685451\n",
      "Iteration 745, loss = 0.04678260\n",
      "Iteration 746, loss = 0.04671190\n",
      "Iteration 747, loss = 0.04663634\n",
      "Iteration 748, loss = 0.04656223\n",
      "Iteration 749, loss = 0.04648962\n",
      "Iteration 750, loss = 0.04641764\n",
      "Iteration 751, loss = 0.04634162\n",
      "Iteration 752, loss = 0.04626919\n",
      "Iteration 753, loss = 0.04620326\n",
      "Iteration 754, loss = 0.04612946\n",
      "Iteration 755, loss = 0.04606291\n",
      "Iteration 756, loss = 0.04599806\n",
      "Iteration 757, loss = 0.04592518\n",
      "Iteration 758, loss = 0.04586136\n",
      "Iteration 759, loss = 0.04579295\n",
      "Iteration 760, loss = 0.04572349\n",
      "Iteration 761, loss = 0.04565868\n",
      "Iteration 762, loss = 0.04558769\n",
      "Iteration 763, loss = 0.04551878\n",
      "Iteration 764, loss = 0.04545247\n",
      "Iteration 765, loss = 0.04538538\n",
      "Iteration 766, loss = 0.04531858\n",
      "Iteration 767, loss = 0.04525798\n",
      "Iteration 768, loss = 0.04518515\n",
      "Iteration 769, loss = 0.04512102\n",
      "Iteration 770, loss = 0.04505243\n",
      "Iteration 771, loss = 0.04498688\n",
      "Iteration 772, loss = 0.04492473\n",
      "Iteration 773, loss = 0.04485634\n",
      "Iteration 774, loss = 0.04479147\n",
      "Iteration 775, loss = 0.04472770\n",
      "Iteration 776, loss = 0.04466186\n",
      "Iteration 777, loss = 0.04459704\n",
      "Iteration 778, loss = 0.04453323\n",
      "Iteration 779, loss = 0.04446657\n",
      "Iteration 780, loss = 0.04440471\n",
      "Iteration 781, loss = 0.04433722\n",
      "Iteration 782, loss = 0.04427300\n",
      "Iteration 783, loss = 0.04420631\n",
      "Iteration 784, loss = 0.04414176\n",
      "Iteration 785, loss = 0.04407957\n",
      "Iteration 786, loss = 0.04401757\n",
      "Iteration 787, loss = 0.04395371\n",
      "Iteration 788, loss = 0.04388689\n",
      "Iteration 789, loss = 0.04382834\n",
      "Iteration 790, loss = 0.04376101\n",
      "Iteration 791, loss = 0.04369818\n",
      "Iteration 792, loss = 0.04363615\n",
      "Iteration 793, loss = 0.04357387\n",
      "Iteration 794, loss = 0.04351365\n",
      "Iteration 795, loss = 0.04345055\n",
      "Iteration 796, loss = 0.04339184\n",
      "Iteration 797, loss = 0.04333128\n",
      "Iteration 798, loss = 0.04326603\n",
      "Iteration 799, loss = 0.04320737\n",
      "Iteration 800, loss = 0.04314606\n",
      "Iteration 801, loss = 0.04308641\n",
      "Iteration 802, loss = 0.04302717\n",
      "Iteration 803, loss = 0.04296958\n",
      "Iteration 804, loss = 0.04291240\n",
      "Iteration 805, loss = 0.04285512\n",
      "Iteration 806, loss = 0.04279722\n",
      "Iteration 807, loss = 0.04273828\n",
      "Iteration 808, loss = 0.04268605\n",
      "Iteration 809, loss = 0.04262664\n",
      "Iteration 810, loss = 0.04257062\n",
      "Iteration 811, loss = 0.04251653\n",
      "Iteration 812, loss = 0.04246130\n",
      "Iteration 813, loss = 0.04240800\n",
      "Iteration 814, loss = 0.04235203\n",
      "Iteration 815, loss = 0.04229910\n",
      "Iteration 816, loss = 0.04224530\n",
      "Iteration 817, loss = 0.04219079\n",
      "Iteration 818, loss = 0.04213634\n",
      "Iteration 819, loss = 0.04207970\n",
      "Iteration 820, loss = 0.04202431\n",
      "Iteration 821, loss = 0.04196843\n",
      "Iteration 822, loss = 0.04191154\n",
      "Iteration 823, loss = 0.04185330\n",
      "Iteration 824, loss = 0.04179064\n",
      "Iteration 825, loss = 0.04173548\n",
      "Iteration 826, loss = 0.04167942\n",
      "Iteration 827, loss = 0.04162092\n",
      "Iteration 828, loss = 0.04156411\n",
      "Iteration 829, loss = 0.04150987\n",
      "Iteration 830, loss = 0.04145384\n",
      "Iteration 831, loss = 0.04140123\n",
      "Iteration 832, loss = 0.04134666\n",
      "Iteration 833, loss = 0.04129588\n",
      "Iteration 834, loss = 0.04124281\n",
      "Iteration 835, loss = 0.04118631\n",
      "Iteration 836, loss = 0.04113279\n",
      "Iteration 837, loss = 0.04107434\n",
      "Iteration 838, loss = 0.04102348\n",
      "Iteration 839, loss = 0.04096783\n",
      "Iteration 840, loss = 0.04091385\n",
      "Iteration 841, loss = 0.04086224\n",
      "Iteration 842, loss = 0.04080997\n",
      "Iteration 843, loss = 0.04075865\n",
      "Iteration 844, loss = 0.04070855\n",
      "Iteration 845, loss = 0.04065759\n",
      "Iteration 846, loss = 0.04060690\n",
      "Iteration 847, loss = 0.04055160\n",
      "Iteration 848, loss = 0.04049898\n",
      "Iteration 849, loss = 0.04044810\n",
      "Iteration 850, loss = 0.04039484\n",
      "Iteration 851, loss = 0.04034751\n",
      "Iteration 852, loss = 0.04029358\n",
      "Iteration 853, loss = 0.04024249\n",
      "Iteration 854, loss = 0.04019051\n",
      "Iteration 855, loss = 0.04013824\n",
      "Iteration 856, loss = 0.04008838\n",
      "Iteration 857, loss = 0.04003637\n",
      "Iteration 858, loss = 0.03998428\n",
      "Iteration 859, loss = 0.03993248\n",
      "Iteration 860, loss = 0.03988514\n",
      "Iteration 861, loss = 0.03983517\n",
      "Iteration 862, loss = 0.03978121\n",
      "Iteration 863, loss = 0.03973266\n",
      "Iteration 864, loss = 0.03968131\n",
      "Iteration 865, loss = 0.03963269\n",
      "Iteration 866, loss = 0.03958200\n",
      "Iteration 867, loss = 0.03953181\n",
      "Iteration 868, loss = 0.03948752\n",
      "Iteration 869, loss = 0.03943234\n",
      "Iteration 870, loss = 0.03938409\n",
      "Iteration 871, loss = 0.03933578\n",
      "Iteration 872, loss = 0.03928560\n",
      "Iteration 873, loss = 0.03923629\n",
      "Iteration 874, loss = 0.03918594\n",
      "Iteration 875, loss = 0.03913770\n",
      "Iteration 876, loss = 0.03909166\n",
      "Iteration 877, loss = 0.03904260\n",
      "Iteration 878, loss = 0.03899585\n",
      "Iteration 879, loss = 0.03895311\n",
      "Iteration 880, loss = 0.03890038\n",
      "Iteration 881, loss = 0.03885601\n",
      "Iteration 882, loss = 0.03881244\n",
      "Iteration 883, loss = 0.03876702\n",
      "Iteration 884, loss = 0.03872267\n",
      "Iteration 885, loss = 0.03867996\n",
      "Iteration 886, loss = 0.03863216\n",
      "Iteration 887, loss = 0.03858798\n",
      "Iteration 888, loss = 0.03854272\n",
      "Iteration 889, loss = 0.03849672\n",
      "Iteration 890, loss = 0.03845326\n",
      "Iteration 891, loss = 0.03841040\n",
      "Iteration 892, loss = 0.03836628\n",
      "Iteration 893, loss = 0.03832323\n",
      "Iteration 894, loss = 0.03827849\n",
      "Iteration 895, loss = 0.03823249\n",
      "Iteration 896, loss = 0.03819020\n",
      "Iteration 897, loss = 0.03814531\n",
      "Iteration 898, loss = 0.03810037\n",
      "Iteration 899, loss = 0.03805409\n",
      "Iteration 900, loss = 0.03801105\n",
      "Iteration 901, loss = 0.03796719\n",
      "Iteration 902, loss = 0.03792147\n",
      "Iteration 903, loss = 0.03787572\n",
      "Iteration 904, loss = 0.03783360\n",
      "Iteration 905, loss = 0.03778533\n",
      "Iteration 906, loss = 0.03773903\n",
      "Iteration 907, loss = 0.03769636\n",
      "Iteration 908, loss = 0.03765405\n",
      "Iteration 909, loss = 0.03760677\n",
      "Iteration 910, loss = 0.03756366\n",
      "Iteration 911, loss = 0.03751892\n",
      "Iteration 912, loss = 0.03747505\n",
      "Iteration 913, loss = 0.03743456\n",
      "Iteration 914, loss = 0.03738711\n",
      "Iteration 915, loss = 0.03734544\n",
      "Iteration 916, loss = 0.03730373\n",
      "Iteration 917, loss = 0.03726173\n",
      "Iteration 918, loss = 0.03721821\n",
      "Iteration 919, loss = 0.03717928\n",
      "Iteration 920, loss = 0.03713571\n",
      "Iteration 921, loss = 0.03709469\n",
      "Iteration 922, loss = 0.03705368\n",
      "Iteration 923, loss = 0.03701264\n",
      "Iteration 924, loss = 0.03697208\n",
      "Iteration 925, loss = 0.03693255\n",
      "Iteration 926, loss = 0.03689354\n",
      "Iteration 927, loss = 0.03685296\n",
      "Iteration 928, loss = 0.03681051\n",
      "Iteration 929, loss = 0.03677138\n",
      "Iteration 930, loss = 0.03673180\n",
      "Iteration 931, loss = 0.03669030\n",
      "Iteration 932, loss = 0.03664811\n",
      "Iteration 933, loss = 0.03660728\n",
      "Iteration 934, loss = 0.03656659\n",
      "Iteration 935, loss = 0.03652633\n",
      "Iteration 936, loss = 0.03648486\n",
      "Iteration 937, loss = 0.03644710\n",
      "Iteration 938, loss = 0.03640924\n",
      "Iteration 939, loss = 0.03636493\n",
      "Iteration 940, loss = 0.03632377\n",
      "Iteration 941, loss = 0.03628255\n",
      "Iteration 942, loss = 0.03624134\n",
      "Iteration 943, loss = 0.03620054\n",
      "Iteration 944, loss = 0.03615943\n",
      "Iteration 945, loss = 0.03611687\n",
      "Iteration 946, loss = 0.03607798\n",
      "Iteration 947, loss = 0.03603521\n",
      "Iteration 948, loss = 0.03599464\n",
      "Iteration 949, loss = 0.03595790\n",
      "Iteration 950, loss = 0.03591553\n",
      "Iteration 951, loss = 0.03587585\n",
      "Iteration 952, loss = 0.03583420\n",
      "Iteration 953, loss = 0.03579883\n",
      "Iteration 954, loss = 0.03575806\n",
      "Iteration 955, loss = 0.03572239\n",
      "Iteration 956, loss = 0.03568148\n",
      "Iteration 957, loss = 0.03564215\n",
      "Iteration 958, loss = 0.03560514\n",
      "Iteration 959, loss = 0.03556639\n",
      "Iteration 960, loss = 0.03552610\n",
      "Iteration 961, loss = 0.03548665\n",
      "Iteration 962, loss = 0.03544791\n",
      "Iteration 963, loss = 0.03540937\n",
      "Iteration 964, loss = 0.03537054\n",
      "Iteration 965, loss = 0.03533249\n",
      "Iteration 966, loss = 0.03529638\n",
      "Iteration 967, loss = 0.03525719\n",
      "Iteration 968, loss = 0.03522042\n",
      "Iteration 969, loss = 0.03518406\n",
      "Iteration 970, loss = 0.03514551\n",
      "Iteration 971, loss = 0.03510837\n",
      "Iteration 972, loss = 0.03507095\n",
      "Iteration 973, loss = 0.03503596\n",
      "Iteration 974, loss = 0.03500052\n",
      "Iteration 975, loss = 0.03496199\n",
      "Iteration 976, loss = 0.03492553\n",
      "Iteration 977, loss = 0.03488999\n",
      "Iteration 978, loss = 0.03485537\n",
      "Iteration 979, loss = 0.03481869\n",
      "Iteration 980, loss = 0.03478356\n",
      "Iteration 981, loss = 0.03474752\n",
      "Iteration 982, loss = 0.03471280\n",
      "Iteration 983, loss = 0.03467711\n",
      "Iteration 984, loss = 0.03464107\n",
      "Iteration 985, loss = 0.03460999\n",
      "Iteration 986, loss = 0.03457171\n",
      "Iteration 987, loss = 0.03453627\n",
      "Iteration 988, loss = 0.03450177\n",
      "Iteration 989, loss = 0.03447080\n",
      "Iteration 990, loss = 0.03443097\n",
      "Iteration 991, loss = 0.03439440\n",
      "Iteration 992, loss = 0.03435962\n",
      "Iteration 993, loss = 0.03432246\n",
      "Iteration 994, loss = 0.03428758\n",
      "Iteration 995, loss = 0.03424647\n",
      "Iteration 996, loss = 0.03421519\n",
      "Iteration 997, loss = 0.03417751\n",
      "Iteration 998, loss = 0.03414356\n",
      "Iteration 999, loss = 0.03410957\n",
      "Iteration 1000, loss = 0.03407246\n",
      "Iteration 1001, loss = 0.03404087\n",
      "Iteration 1002, loss = 0.03400440\n",
      "Iteration 1003, loss = 0.03396868\n",
      "Iteration 1004, loss = 0.03393674\n",
      "Iteration 1005, loss = 0.03390251\n",
      "Iteration 1006, loss = 0.03386917\n",
      "Iteration 1007, loss = 0.03383365\n",
      "Iteration 1008, loss = 0.03379833\n",
      "Iteration 1009, loss = 0.03376407\n",
      "Iteration 1010, loss = 0.03373066\n",
      "Iteration 1011, loss = 0.03369428\n",
      "Iteration 1012, loss = 0.03365877\n",
      "Iteration 1013, loss = 0.03362315\n",
      "Iteration 1014, loss = 0.03358734\n",
      "Iteration 1015, loss = 0.03355483\n",
      "Iteration 1016, loss = 0.03351997\n",
      "Iteration 1017, loss = 0.03348698\n",
      "Iteration 1018, loss = 0.03345421\n",
      "Iteration 1019, loss = 0.03342081\n",
      "Iteration 1020, loss = 0.03338514\n",
      "Iteration 1021, loss = 0.03335048\n",
      "Iteration 1022, loss = 0.03331642\n",
      "Iteration 1023, loss = 0.03328073\n",
      "Iteration 1024, loss = 0.03324687\n",
      "Iteration 1025, loss = 0.03321054\n",
      "Iteration 1026, loss = 0.03317725\n",
      "Iteration 1027, loss = 0.03314629\n",
      "Iteration 1028, loss = 0.03311271\n",
      "Iteration 1029, loss = 0.03308429\n",
      "Iteration 1030, loss = 0.03304566\n",
      "Iteration 1031, loss = 0.03301067\n",
      "Iteration 1032, loss = 0.03297971\n",
      "Iteration 1033, loss = 0.03294648\n",
      "Iteration 1034, loss = 0.03291170\n",
      "Iteration 1035, loss = 0.03287992\n",
      "Iteration 1036, loss = 0.03284751\n",
      "Iteration 1037, loss = 0.03281726\n",
      "Iteration 1038, loss = 0.03278373\n",
      "Iteration 1039, loss = 0.03275178\n",
      "Iteration 1040, loss = 0.03271854\n",
      "Iteration 1041, loss = 0.03268686\n",
      "Iteration 1042, loss = 0.03265199\n",
      "Iteration 1043, loss = 0.03262254\n",
      "Iteration 1044, loss = 0.03258816\n",
      "Iteration 1045, loss = 0.03255625\n",
      "Iteration 1046, loss = 0.03252484\n",
      "Iteration 1047, loss = 0.03249644\n",
      "Iteration 1048, loss = 0.03246374\n",
      "Iteration 1049, loss = 0.03243508\n",
      "Iteration 1050, loss = 0.03240321\n",
      "Iteration 1051, loss = 0.03237247\n",
      "Iteration 1052, loss = 0.03234324\n",
      "Iteration 1053, loss = 0.03231122\n",
      "Iteration 1054, loss = 0.03227979\n",
      "Iteration 1055, loss = 0.03224893\n",
      "Iteration 1056, loss = 0.03221787\n",
      "Iteration 1057, loss = 0.03218697\n",
      "Iteration 1058, loss = 0.03215424\n",
      "Iteration 1059, loss = 0.03212449\n",
      "Iteration 1060, loss = 0.03209457\n",
      "Iteration 1061, loss = 0.03206186\n",
      "Iteration 1062, loss = 0.03202884\n",
      "Iteration 1063, loss = 0.03199757\n",
      "Iteration 1064, loss = 0.03196540\n",
      "Iteration 1065, loss = 0.03193218\n",
      "Iteration 1066, loss = 0.03189984\n",
      "Iteration 1067, loss = 0.03187053\n",
      "Iteration 1068, loss = 0.03183842\n",
      "Iteration 1069, loss = 0.03180759\n",
      "Iteration 1070, loss = 0.03177573\n",
      "Iteration 1071, loss = 0.03174175\n",
      "Iteration 1072, loss = 0.03170931\n",
      "Iteration 1073, loss = 0.03167738\n",
      "Iteration 1074, loss = 0.03164834\n",
      "Iteration 1075, loss = 0.03161748\n",
      "Iteration 1076, loss = 0.03159220\n",
      "Iteration 1077, loss = 0.03155781\n",
      "Iteration 1078, loss = 0.03152714\n",
      "Iteration 1079, loss = 0.03150005\n",
      "Iteration 1080, loss = 0.03146741\n",
      "Iteration 1081, loss = 0.03144082\n",
      "Iteration 1082, loss = 0.03140902\n",
      "Iteration 1083, loss = 0.03137880\n",
      "Iteration 1084, loss = 0.03134937\n",
      "Iteration 1085, loss = 0.03131916\n",
      "Iteration 1086, loss = 0.03128768\n",
      "Iteration 1087, loss = 0.03125862\n",
      "Iteration 1088, loss = 0.03123713\n",
      "Iteration 1089, loss = 0.03120269\n",
      "Iteration 1090, loss = 0.03116918\n",
      "Iteration 1091, loss = 0.03113825\n",
      "Iteration 1092, loss = 0.03111022\n",
      "Iteration 1093, loss = 0.03107894\n",
      "Iteration 1094, loss = 0.03104807\n",
      "Iteration 1095, loss = 0.03102126\n",
      "Iteration 1096, loss = 0.03098889\n",
      "Iteration 1097, loss = 0.03095773\n",
      "Iteration 1098, loss = 0.03093087\n",
      "Iteration 1099, loss = 0.03089733\n",
      "Iteration 1100, loss = 0.03086633\n",
      "Iteration 1101, loss = 0.03083394\n",
      "Iteration 1102, loss = 0.03080346\n",
      "Iteration 1103, loss = 0.03077429\n",
      "Iteration 1104, loss = 0.03074721\n",
      "Iteration 1105, loss = 0.03071667\n",
      "Iteration 1106, loss = 0.03068595\n",
      "Iteration 1107, loss = 0.03065633\n",
      "Iteration 1108, loss = 0.03062989\n",
      "Iteration 1109, loss = 0.03060055\n",
      "Iteration 1110, loss = 0.03056947\n",
      "Iteration 1111, loss = 0.03053988\n",
      "Iteration 1112, loss = 0.03051203\n",
      "Iteration 1113, loss = 0.03048266\n",
      "Iteration 1114, loss = 0.03045736\n",
      "Iteration 1115, loss = 0.03042644\n",
      "Iteration 1116, loss = 0.03039859\n",
      "Iteration 1117, loss = 0.03037109\n",
      "Iteration 1118, loss = 0.03034313\n",
      "Iteration 1119, loss = 0.03031590\n",
      "Iteration 1120, loss = 0.03029098\n",
      "Iteration 1121, loss = 0.03026176\n",
      "Iteration 1122, loss = 0.03023437\n",
      "Iteration 1123, loss = 0.03020601\n",
      "Iteration 1124, loss = 0.03017926\n",
      "Iteration 1125, loss = 0.03015175\n",
      "Iteration 1126, loss = 0.03012544\n",
      "Iteration 1127, loss = 0.03009726\n",
      "Iteration 1128, loss = 0.03006944\n",
      "Iteration 1129, loss = 0.03004433\n",
      "Iteration 1130, loss = 0.03001484\n",
      "Iteration 1131, loss = 0.02998620\n",
      "Iteration 1132, loss = 0.02995671\n",
      "Iteration 1133, loss = 0.02992594\n",
      "Iteration 1134, loss = 0.02990919\n",
      "Iteration 1135, loss = 0.02987607\n",
      "Iteration 1136, loss = 0.02984754\n",
      "Iteration 1137, loss = 0.02982032\n",
      "Iteration 1138, loss = 0.02979197\n",
      "Iteration 1139, loss = 0.02976361\n",
      "Iteration 1140, loss = 0.02973452\n",
      "Iteration 1141, loss = 0.02970635\n",
      "Iteration 1142, loss = 0.02967919\n",
      "Iteration 1143, loss = 0.02965152\n",
      "Iteration 1144, loss = 0.02962581\n",
      "Iteration 1145, loss = 0.02959720\n",
      "Iteration 1146, loss = 0.02957084\n",
      "Iteration 1147, loss = 0.02954309\n",
      "Iteration 1148, loss = 0.02951605\n",
      "Iteration 1149, loss = 0.02948876\n",
      "Iteration 1150, loss = 0.02946090\n",
      "Iteration 1151, loss = 0.02943310\n",
      "Iteration 1152, loss = 0.02941083\n",
      "Iteration 1153, loss = 0.02938405\n",
      "Iteration 1154, loss = 0.02935663\n",
      "Iteration 1155, loss = 0.02933218\n",
      "Iteration 1156, loss = 0.02930489\n",
      "Iteration 1157, loss = 0.02928304\n",
      "Iteration 1158, loss = 0.02925454\n",
      "Iteration 1159, loss = 0.02922937\n",
      "Iteration 1160, loss = 0.02920490\n",
      "Iteration 1161, loss = 0.02917825\n",
      "Iteration 1162, loss = 0.02915218\n",
      "Iteration 1163, loss = 0.02912709\n",
      "Iteration 1164, loss = 0.02910149\n",
      "Iteration 1165, loss = 0.02907933\n",
      "Iteration 1166, loss = 0.02905580\n",
      "Iteration 1167, loss = 0.02903038\n",
      "Iteration 1168, loss = 0.02900483\n",
      "Iteration 1169, loss = 0.02898421\n",
      "Iteration 1170, loss = 0.02895352\n",
      "Iteration 1171, loss = 0.02892992\n",
      "Iteration 1172, loss = 0.02890401\n",
      "Iteration 1173, loss = 0.02887721\n",
      "Iteration 1174, loss = 0.02885161\n",
      "Iteration 1175, loss = 0.02882738\n",
      "Iteration 1176, loss = 0.02880244\n",
      "Iteration 1177, loss = 0.02877916\n",
      "Iteration 1178, loss = 0.02875637\n",
      "Iteration 1179, loss = 0.02873476\n",
      "Iteration 1180, loss = 0.02871284\n",
      "Iteration 1181, loss = 0.02868672\n",
      "Iteration 1182, loss = 0.02866191\n",
      "Iteration 1183, loss = 0.02863663\n",
      "Iteration 1184, loss = 0.02861116\n",
      "Iteration 1185, loss = 0.02858634\n",
      "Iteration 1186, loss = 0.02855993\n",
      "Iteration 1187, loss = 0.02853811\n",
      "Iteration 1188, loss = 0.02851080\n",
      "Iteration 1189, loss = 0.02848708\n",
      "Iteration 1190, loss = 0.02846272\n",
      "Iteration 1191, loss = 0.02844133\n",
      "Iteration 1192, loss = 0.02841559\n",
      "Iteration 1193, loss = 0.02839104\n",
      "Iteration 1194, loss = 0.02836610\n",
      "Iteration 1195, loss = 0.02834473\n",
      "Iteration 1196, loss = 0.02831814\n",
      "Iteration 1197, loss = 0.02829338\n",
      "Iteration 1198, loss = 0.02826831\n",
      "Iteration 1199, loss = 0.02824549\n",
      "Iteration 1200, loss = 0.02822078\n",
      "Iteration 1201, loss = 0.02819536\n",
      "Iteration 1202, loss = 0.02817141\n",
      "Iteration 1203, loss = 0.02814866\n",
      "Iteration 1204, loss = 0.02812280\n",
      "Iteration 1205, loss = 0.02810009\n",
      "Iteration 1206, loss = 0.02807662\n",
      "Iteration 1207, loss = 0.02805247\n",
      "Iteration 1208, loss = 0.02803158\n",
      "Iteration 1209, loss = 0.02800650\n",
      "Iteration 1210, loss = 0.02798464\n",
      "Iteration 1211, loss = 0.02796325\n",
      "Iteration 1212, loss = 0.02794045\n",
      "Iteration 1213, loss = 0.02791826\n",
      "Iteration 1214, loss = 0.02789659\n",
      "Iteration 1215, loss = 0.02787433\n",
      "Iteration 1216, loss = 0.02785325\n",
      "Iteration 1217, loss = 0.02782957\n",
      "Iteration 1218, loss = 0.02780728\n",
      "Iteration 1219, loss = 0.02778403\n",
      "Iteration 1220, loss = 0.02775954\n",
      "Iteration 1221, loss = 0.02774003\n",
      "Iteration 1222, loss = 0.02771393\n",
      "Iteration 1223, loss = 0.02769144\n",
      "Iteration 1224, loss = 0.02766634\n",
      "Iteration 1225, loss = 0.02764939\n",
      "Iteration 1226, loss = 0.02762332\n",
      "Iteration 1227, loss = 0.02759970\n",
      "Iteration 1228, loss = 0.02757281\n",
      "Iteration 1229, loss = 0.02755142\n",
      "Iteration 1230, loss = 0.02752694\n",
      "Iteration 1231, loss = 0.02750382\n",
      "Iteration 1232, loss = 0.02747907\n",
      "Iteration 1233, loss = 0.02745737\n",
      "Iteration 1234, loss = 0.02743373\n",
      "Iteration 1235, loss = 0.02740910\n",
      "Iteration 1236, loss = 0.02738685\n",
      "Iteration 1237, loss = 0.02736755\n",
      "Iteration 1238, loss = 0.02734074\n",
      "Iteration 1239, loss = 0.02731782\n",
      "Iteration 1240, loss = 0.02729813\n",
      "Iteration 1241, loss = 0.02727343\n",
      "Iteration 1242, loss = 0.02725197\n",
      "Iteration 1243, loss = 0.02722971\n",
      "Iteration 1244, loss = 0.02721033\n",
      "Iteration 1245, loss = 0.02718581\n",
      "Iteration 1246, loss = 0.02716089\n",
      "Iteration 1247, loss = 0.02713973\n",
      "Iteration 1248, loss = 0.02711626\n",
      "Iteration 1249, loss = 0.02709286\n",
      "Iteration 1250, loss = 0.02707025\n",
      "Iteration 1251, loss = 0.02704520\n",
      "Iteration 1252, loss = 0.02702431\n",
      "Iteration 1253, loss = 0.02699908\n",
      "Iteration 1254, loss = 0.02697548\n",
      "Iteration 1255, loss = 0.02695191\n",
      "Iteration 1256, loss = 0.02692832\n",
      "Iteration 1257, loss = 0.02690717\n",
      "Iteration 1258, loss = 0.02688248\n",
      "Iteration 1259, loss = 0.02685977\n",
      "Iteration 1260, loss = 0.02683681\n",
      "Iteration 1261, loss = 0.02681431\n",
      "Iteration 1262, loss = 0.02679092\n",
      "Iteration 1263, loss = 0.02676908\n",
      "Iteration 1264, loss = 0.02674701\n",
      "Iteration 1265, loss = 0.02672560\n",
      "Iteration 1266, loss = 0.02670336\n",
      "Iteration 1267, loss = 0.02668237\n",
      "Iteration 1268, loss = 0.02666092\n",
      "Iteration 1269, loss = 0.02663950\n",
      "Iteration 1270, loss = 0.02661647\n",
      "Iteration 1271, loss = 0.02659667\n",
      "Iteration 1272, loss = 0.02657469\n",
      "Iteration 1273, loss = 0.02655287\n",
      "Iteration 1274, loss = 0.02653041\n",
      "Iteration 1275, loss = 0.02650757\n",
      "Iteration 1276, loss = 0.02649328\n",
      "Iteration 1277, loss = 0.02646515\n",
      "Iteration 1278, loss = 0.02644285\n",
      "Iteration 1279, loss = 0.02642200\n",
      "Iteration 1280, loss = 0.02639728\n",
      "Iteration 1281, loss = 0.02637615\n",
      "Iteration 1282, loss = 0.02635506\n",
      "Iteration 1283, loss = 0.02633541\n",
      "Iteration 1284, loss = 0.02631334\n",
      "Iteration 1285, loss = 0.02629451\n",
      "Iteration 1286, loss = 0.02627139\n",
      "Iteration 1287, loss = 0.02625209\n",
      "Iteration 1288, loss = 0.02623055\n",
      "Iteration 1289, loss = 0.02620981\n",
      "Iteration 1290, loss = 0.02618904\n",
      "Iteration 1291, loss = 0.02616780\n",
      "Iteration 1292, loss = 0.02614525\n",
      "Iteration 1293, loss = 0.02612534\n",
      "Iteration 1294, loss = 0.02610573\n",
      "Iteration 1295, loss = 0.02608222\n",
      "Iteration 1296, loss = 0.02606205\n",
      "Iteration 1297, loss = 0.02604180\n",
      "Iteration 1298, loss = 0.02602137\n",
      "Iteration 1299, loss = 0.02599821\n",
      "Iteration 1300, loss = 0.02597691\n",
      "Iteration 1301, loss = 0.02595741\n",
      "Iteration 1302, loss = 0.02593715\n",
      "Iteration 1303, loss = 0.02591509\n",
      "Iteration 1304, loss = 0.02589424\n",
      "Iteration 1305, loss = 0.02587475\n",
      "Iteration 1306, loss = 0.02585265\n",
      "Iteration 1307, loss = 0.02583255\n",
      "Iteration 1308, loss = 0.02580921\n",
      "Iteration 1309, loss = 0.02578752\n",
      "Iteration 1310, loss = 0.02576593\n",
      "Iteration 1311, loss = 0.02574622\n",
      "Iteration 1312, loss = 0.02572058\n",
      "Iteration 1313, loss = 0.02570160\n",
      "Iteration 1314, loss = 0.02567980\n",
      "Iteration 1315, loss = 0.02566141\n",
      "Iteration 1316, loss = 0.02564020\n",
      "Iteration 1317, loss = 0.02561898\n",
      "Iteration 1318, loss = 0.02559796\n",
      "Iteration 1319, loss = 0.02557843\n",
      "Iteration 1320, loss = 0.02555828\n",
      "Iteration 1321, loss = 0.02553949\n",
      "Iteration 1322, loss = 0.02551997\n",
      "Iteration 1323, loss = 0.02549997\n",
      "Iteration 1324, loss = 0.02548031\n",
      "Iteration 1325, loss = 0.02545844\n",
      "Iteration 1326, loss = 0.02543855\n",
      "Iteration 1327, loss = 0.02541964\n",
      "Iteration 1328, loss = 0.02539972\n",
      "Iteration 1329, loss = 0.02538034\n",
      "Iteration 1330, loss = 0.02536060\n",
      "Iteration 1331, loss = 0.02534187\n",
      "Iteration 1332, loss = 0.02532276\n",
      "Iteration 1333, loss = 0.02530310\n",
      "Iteration 1334, loss = 0.02528534\n",
      "Iteration 1335, loss = 0.02526417\n",
      "Iteration 1336, loss = 0.02524535\n",
      "Iteration 1337, loss = 0.02522640\n",
      "Iteration 1338, loss = 0.02520843\n",
      "Iteration 1339, loss = 0.02519014\n",
      "Iteration 1340, loss = 0.02517076\n",
      "Iteration 1341, loss = 0.02515347\n",
      "Iteration 1342, loss = 0.02513227\n",
      "Iteration 1343, loss = 0.02511306\n",
      "Iteration 1344, loss = 0.02509428\n",
      "Iteration 1345, loss = 0.02507560\n",
      "Iteration 1346, loss = 0.02505604\n",
      "Iteration 1347, loss = 0.02503812\n",
      "Iteration 1348, loss = 0.02501714\n",
      "Iteration 1349, loss = 0.02499810\n",
      "Iteration 1350, loss = 0.02497813\n",
      "Iteration 1351, loss = 0.02495997\n",
      "Iteration 1352, loss = 0.02494084\n",
      "Iteration 1353, loss = 0.02492313\n",
      "Iteration 1354, loss = 0.02490626\n",
      "Iteration 1355, loss = 0.02488590\n",
      "Iteration 1356, loss = 0.02486722\n",
      "Iteration 1357, loss = 0.02484818\n",
      "Iteration 1358, loss = 0.02482881\n",
      "Iteration 1359, loss = 0.02481064\n",
      "Iteration 1360, loss = 0.02479202\n",
      "Iteration 1361, loss = 0.02477431\n",
      "Iteration 1362, loss = 0.02475426\n",
      "Iteration 1363, loss = 0.02473582\n",
      "Iteration 1364, loss = 0.02471773\n",
      "Iteration 1365, loss = 0.02470070\n",
      "Iteration 1366, loss = 0.02468146\n",
      "Iteration 1367, loss = 0.02466374\n",
      "Iteration 1368, loss = 0.02464715\n",
      "Iteration 1369, loss = 0.02462882\n",
      "Iteration 1370, loss = 0.02461063\n",
      "Iteration 1371, loss = 0.02459550\n",
      "Iteration 1372, loss = 0.02457712\n",
      "Iteration 1373, loss = 0.02456034\n",
      "Iteration 1374, loss = 0.02454266\n",
      "Iteration 1375, loss = 0.02452681\n",
      "Iteration 1376, loss = 0.02451071\n",
      "Iteration 1377, loss = 0.02449313\n",
      "Iteration 1378, loss = 0.02447188\n",
      "Iteration 1379, loss = 0.02445408\n",
      "Iteration 1380, loss = 0.02443563\n",
      "Iteration 1381, loss = 0.02441759\n",
      "Iteration 1382, loss = 0.02439914\n",
      "Iteration 1383, loss = 0.02438161\n",
      "Iteration 1384, loss = 0.02436405\n",
      "Iteration 1385, loss = 0.02434486\n",
      "Iteration 1386, loss = 0.02432891\n",
      "Iteration 1387, loss = 0.02431052\n",
      "Iteration 1388, loss = 0.02429223\n",
      "Iteration 1389, loss = 0.02427364\n",
      "Iteration 1390, loss = 0.02425745\n",
      "Iteration 1391, loss = 0.02423827\n",
      "Iteration 1392, loss = 0.02422128\n",
      "Iteration 1393, loss = 0.02420347\n",
      "Iteration 1394, loss = 0.02418528\n",
      "Iteration 1395, loss = 0.02416880\n",
      "Iteration 1396, loss = 0.02414948\n",
      "Iteration 1397, loss = 0.02412999\n",
      "Iteration 1398, loss = 0.02411307\n",
      "Iteration 1399, loss = 0.02409058\n",
      "Iteration 1400, loss = 0.02407691\n",
      "Iteration 1401, loss = 0.02405477\n",
      "Iteration 1402, loss = 0.02403909\n",
      "Iteration 1403, loss = 0.02401979\n",
      "Iteration 1404, loss = 0.02400084\n",
      "Iteration 1405, loss = 0.02398059\n",
      "Iteration 1406, loss = 0.02396277\n",
      "Iteration 1407, loss = 0.02394369\n",
      "Iteration 1408, loss = 0.02392839\n",
      "Iteration 1409, loss = 0.02391109\n",
      "Iteration 1410, loss = 0.02388899\n",
      "Iteration 1411, loss = 0.02387386\n",
      "Iteration 1412, loss = 0.02385402\n",
      "Iteration 1413, loss = 0.02383907\n",
      "Iteration 1414, loss = 0.02382002\n",
      "Iteration 1415, loss = 0.02380266\n",
      "Iteration 1416, loss = 0.02378788\n",
      "Iteration 1417, loss = 0.02376847\n",
      "Iteration 1418, loss = 0.02375225\n",
      "Iteration 1419, loss = 0.02373617\n",
      "Iteration 1420, loss = 0.02371557\n",
      "Iteration 1421, loss = 0.02370057\n",
      "Iteration 1422, loss = 0.02368023\n",
      "Iteration 1423, loss = 0.02366100\n",
      "Iteration 1424, loss = 0.02364234\n",
      "Iteration 1425, loss = 0.02362661\n",
      "Iteration 1426, loss = 0.02360862\n",
      "Iteration 1427, loss = 0.02359066\n",
      "Iteration 1428, loss = 0.02357286\n",
      "Iteration 1429, loss = 0.02355534\n",
      "Iteration 1430, loss = 0.02353647\n",
      "Iteration 1431, loss = 0.02351898\n",
      "Iteration 1432, loss = 0.02350367\n",
      "Iteration 1433, loss = 0.02348514\n",
      "Iteration 1434, loss = 0.02346977\n",
      "Iteration 1435, loss = 0.02345159\n",
      "Iteration 1436, loss = 0.02343126\n",
      "Iteration 1437, loss = 0.02341307\n",
      "Iteration 1438, loss = 0.02339356\n",
      "Iteration 1439, loss = 0.02337815\n",
      "Iteration 1440, loss = 0.02335915\n",
      "Iteration 1441, loss = 0.02333955\n",
      "Iteration 1442, loss = 0.02332334\n",
      "Iteration 1443, loss = 0.02330595\n",
      "Iteration 1444, loss = 0.02328713\n",
      "Iteration 1445, loss = 0.02327428\n",
      "Iteration 1446, loss = 0.02325280\n",
      "Iteration 1447, loss = 0.02323468\n",
      "Iteration 1448, loss = 0.02321659\n",
      "Iteration 1449, loss = 0.02320186\n",
      "Iteration 1450, loss = 0.02318325\n",
      "Iteration 1451, loss = 0.02316798\n",
      "Iteration 1452, loss = 0.02314929\n",
      "Iteration 1453, loss = 0.02313567\n",
      "Iteration 1454, loss = 0.02311839\n",
      "Iteration 1455, loss = 0.02310098\n",
      "Iteration 1456, loss = 0.02308490\n",
      "Iteration 1457, loss = 0.02306789\n",
      "Iteration 1458, loss = 0.02305110\n",
      "Iteration 1459, loss = 0.02303623\n",
      "Iteration 1460, loss = 0.02301822\n",
      "Iteration 1461, loss = 0.02300114\n",
      "Iteration 1462, loss = 0.02298516\n",
      "Iteration 1463, loss = 0.02296829\n",
      "Iteration 1464, loss = 0.02295194\n",
      "Iteration 1465, loss = 0.02293474\n",
      "Iteration 1466, loss = 0.02291774\n",
      "Iteration 1467, loss = 0.02290529\n",
      "Iteration 1468, loss = 0.02288673\n",
      "Iteration 1469, loss = 0.02287133\n",
      "Iteration 1470, loss = 0.02285442\n",
      "Iteration 1471, loss = 0.02283916\n",
      "Iteration 1472, loss = 0.02282434\n",
      "Iteration 1473, loss = 0.02280803\n",
      "Iteration 1474, loss = 0.02279128\n",
      "Iteration 1475, loss = 0.02277804\n",
      "Iteration 1476, loss = 0.02276103\n",
      "Iteration 1477, loss = 0.02274320\n",
      "Iteration 1478, loss = 0.02272519\n",
      "Iteration 1479, loss = 0.02270977\n",
      "Iteration 1480, loss = 0.02269236\n",
      "Iteration 1481, loss = 0.02267669\n",
      "Iteration 1482, loss = 0.02266069\n",
      "Iteration 1483, loss = 0.02264414\n",
      "Iteration 1484, loss = 0.02262894\n",
      "Iteration 1485, loss = 0.02261423\n",
      "Iteration 1486, loss = 0.02259818\n",
      "Iteration 1487, loss = 0.02258388\n",
      "Iteration 1488, loss = 0.02256911\n",
      "Iteration 1489, loss = 0.02255138\n",
      "Iteration 1490, loss = 0.02253651\n",
      "Iteration 1491, loss = 0.02252216\n",
      "Iteration 1492, loss = 0.02250459\n",
      "Iteration 1493, loss = 0.02248683\n",
      "Iteration 1494, loss = 0.02246996\n",
      "Iteration 1495, loss = 0.02245226\n",
      "Iteration 1496, loss = 0.02243617\n",
      "Iteration 1497, loss = 0.02241872\n",
      "Iteration 1498, loss = 0.02240177\n",
      "Iteration 1499, loss = 0.02238512\n",
      "Iteration 1500, loss = 0.02236802\n",
      "Iteration 1501, loss = 0.02235179\n",
      "Iteration 1502, loss = 0.02233558\n",
      "Iteration 1503, loss = 0.02232043\n",
      "Iteration 1504, loss = 0.02230431\n",
      "Iteration 1505, loss = 0.02228844\n",
      "Iteration 1506, loss = 0.02227288\n",
      "Iteration 1507, loss = 0.02225729\n",
      "Iteration 1508, loss = 0.02224542\n",
      "Iteration 1509, loss = 0.02222825\n",
      "Iteration 1510, loss = 0.02221387\n",
      "Iteration 1511, loss = 0.02219969\n",
      "Iteration 1512, loss = 0.02218355\n",
      "Iteration 1513, loss = 0.02216680\n",
      "Iteration 1514, loss = 0.02215181\n",
      "Iteration 1515, loss = 0.02213740\n",
      "Iteration 1516, loss = 0.02212022\n",
      "Iteration 1517, loss = 0.02210381\n",
      "Iteration 1518, loss = 0.02208773\n",
      "Iteration 1519, loss = 0.02207164\n",
      "Iteration 1520, loss = 0.02205619\n",
      "Iteration 1521, loss = 0.02204190\n",
      "Iteration 1522, loss = 0.02202660\n",
      "Iteration 1523, loss = 0.02201362\n",
      "Iteration 1524, loss = 0.02199671\n",
      "Iteration 1525, loss = 0.02198238\n",
      "Iteration 1526, loss = 0.02196949\n",
      "Iteration 1527, loss = 0.02195182\n",
      "Iteration 1528, loss = 0.02193529\n",
      "Iteration 1529, loss = 0.02191837\n",
      "Iteration 1530, loss = 0.02190423\n",
      "Iteration 1531, loss = 0.02188704\n",
      "Iteration 1532, loss = 0.02187200\n",
      "Iteration 1533, loss = 0.02185629\n",
      "Iteration 1534, loss = 0.02184231\n",
      "Iteration 1535, loss = 0.02182707\n",
      "Iteration 1536, loss = 0.02181237\n",
      "Iteration 1537, loss = 0.02179709\n",
      "Iteration 1538, loss = 0.02178350\n",
      "Iteration 1539, loss = 0.02176765\n",
      "Iteration 1540, loss = 0.02175270\n",
      "Iteration 1541, loss = 0.02173926\n",
      "Iteration 1542, loss = 0.02172441\n",
      "Iteration 1543, loss = 0.02170935\n",
      "Iteration 1544, loss = 0.02169501\n",
      "Iteration 1545, loss = 0.02167979\n",
      "Iteration 1546, loss = 0.02166621\n",
      "Iteration 1547, loss = 0.02165059\n",
      "Iteration 1548, loss = 0.02163783\n",
      "Iteration 1549, loss = 0.02161988\n",
      "Iteration 1550, loss = 0.02160468\n",
      "Iteration 1551, loss = 0.02158858\n",
      "Iteration 1552, loss = 0.02157414\n",
      "Iteration 1553, loss = 0.02156020\n",
      "Iteration 1554, loss = 0.02154604\n",
      "Iteration 1555, loss = 0.02153082\n",
      "Iteration 1556, loss = 0.02151700\n",
      "Iteration 1557, loss = 0.02150087\n",
      "Iteration 1558, loss = 0.02148720\n",
      "Iteration 1559, loss = 0.02147214\n",
      "Iteration 1560, loss = 0.02145692\n",
      "Iteration 1561, loss = 0.02144233\n",
      "Iteration 1562, loss = 0.02142750\n",
      "Iteration 1563, loss = 0.02141433\n",
      "Iteration 1564, loss = 0.02139830\n",
      "Iteration 1565, loss = 0.02138468\n",
      "Iteration 1566, loss = 0.02136908\n",
      "Iteration 1567, loss = 0.02135643\n",
      "Iteration 1568, loss = 0.02134116\n",
      "Iteration 1569, loss = 0.02132804\n",
      "Iteration 1570, loss = 0.02131144\n",
      "Iteration 1571, loss = 0.02129665\n",
      "Iteration 1572, loss = 0.02128512\n",
      "Iteration 1573, loss = 0.02126586\n",
      "Iteration 1574, loss = 0.02125126\n",
      "Iteration 1575, loss = 0.02123527\n",
      "Iteration 1576, loss = 0.02121901\n",
      "Iteration 1577, loss = 0.02120601\n",
      "Iteration 1578, loss = 0.02118793\n",
      "Iteration 1579, loss = 0.02117296\n",
      "Iteration 1580, loss = 0.02115669\n",
      "Iteration 1581, loss = 0.02114248\n",
      "Iteration 1582, loss = 0.02112756\n",
      "Iteration 1583, loss = 0.02111587\n",
      "Iteration 1584, loss = 0.02110598\n",
      "Iteration 1585, loss = 0.02108916\n",
      "Iteration 1586, loss = 0.02107408\n",
      "Iteration 1587, loss = 0.02105881\n",
      "Iteration 1588, loss = 0.02104521\n",
      "Iteration 1589, loss = 0.02103036\n",
      "Iteration 1590, loss = 0.02101624\n",
      "Iteration 1591, loss = 0.02100059\n",
      "Iteration 1592, loss = 0.02098705\n",
      "Iteration 1593, loss = 0.02097444\n",
      "Iteration 1594, loss = 0.02095884\n",
      "Iteration 1595, loss = 0.02094475\n",
      "Iteration 1596, loss = 0.02092954\n",
      "Iteration 1597, loss = 0.02091539\n",
      "Iteration 1598, loss = 0.02090070\n",
      "Iteration 1599, loss = 0.02088651\n",
      "Iteration 1600, loss = 0.02087290\n",
      "Iteration 1601, loss = 0.02085796\n",
      "Iteration 1602, loss = 0.02084818\n",
      "Iteration 1603, loss = 0.02083243\n",
      "Iteration 1604, loss = 0.02081880\n",
      "Iteration 1605, loss = 0.02080526\n",
      "Iteration 1606, loss = 0.02079364\n",
      "Iteration 1607, loss = 0.02077897\n",
      "Iteration 1608, loss = 0.02076401\n",
      "Iteration 1609, loss = 0.02075247\n",
      "Iteration 1610, loss = 0.02073683\n",
      "Iteration 1611, loss = 0.02072340\n",
      "Iteration 1612, loss = 0.02071335\n",
      "Iteration 1613, loss = 0.02069794\n",
      "Iteration 1614, loss = 0.02068437\n",
      "Iteration 1615, loss = 0.02067075\n",
      "Iteration 1616, loss = 0.02065669\n",
      "Iteration 1617, loss = 0.02064298\n",
      "Iteration 1618, loss = 0.02062970\n",
      "Iteration 1619, loss = 0.02061594\n",
      "Iteration 1620, loss = 0.02060379\n",
      "Iteration 1621, loss = 0.02059002\n",
      "Iteration 1622, loss = 0.02057728\n",
      "Iteration 1623, loss = 0.02056386\n",
      "Iteration 1624, loss = 0.02055168\n",
      "Iteration 1625, loss = 0.02053764\n",
      "Iteration 1626, loss = 0.02052482\n",
      "Iteration 1627, loss = 0.02051122\n",
      "Iteration 1628, loss = 0.02049797\n",
      "Iteration 1629, loss = 0.02048356\n",
      "Iteration 1630, loss = 0.02047264\n",
      "Iteration 1631, loss = 0.02045693\n",
      "Iteration 1632, loss = 0.02044414\n",
      "Iteration 1633, loss = 0.02043440\n",
      "Iteration 1634, loss = 0.02041583\n",
      "Iteration 1635, loss = 0.02040353\n",
      "Iteration 1636, loss = 0.02038990\n",
      "Iteration 1637, loss = 0.02037420\n",
      "Iteration 1638, loss = 0.02035794\n",
      "Iteration 1639, loss = 0.02034544\n",
      "Iteration 1640, loss = 0.02033974\n",
      "Iteration 1641, loss = 0.02031881\n",
      "Iteration 1642, loss = 0.02031123\n",
      "Iteration 1643, loss = 0.02030057\n",
      "Iteration 1644, loss = 0.02028410\n",
      "Iteration 1645, loss = 0.02027307\n",
      "Iteration 1646, loss = 0.02025868\n",
      "Iteration 1647, loss = 0.02024556\n",
      "Iteration 1648, loss = 0.02023355\n",
      "Iteration 1649, loss = 0.02022016\n",
      "Iteration 1650, loss = 0.02020764\n",
      "Iteration 1651, loss = 0.02019496\n",
      "Iteration 1652, loss = 0.02018355\n",
      "Iteration 1653, loss = 0.02017163\n",
      "Iteration 1654, loss = 0.02015886\n",
      "Iteration 1655, loss = 0.02014707\n",
      "Iteration 1656, loss = 0.02013571\n",
      "Iteration 1657, loss = 0.02012383\n",
      "Iteration 1658, loss = 0.02011024\n",
      "Iteration 1659, loss = 0.02009943\n",
      "Iteration 1660, loss = 0.02008554\n",
      "Iteration 1661, loss = 0.02007240\n",
      "Iteration 1662, loss = 0.02005930\n",
      "Iteration 1663, loss = 0.02004669\n",
      "Iteration 1664, loss = 0.02003390\n",
      "Iteration 1665, loss = 0.02002129\n",
      "Iteration 1666, loss = 0.02000913\n",
      "Iteration 1667, loss = 0.01999778\n",
      "Iteration 1668, loss = 0.01998446\n",
      "Iteration 1669, loss = 0.01997161\n",
      "Iteration 1670, loss = 0.01996040\n",
      "Iteration 1671, loss = 0.01994703\n",
      "Iteration 1672, loss = 0.01993359\n",
      "Iteration 1673, loss = 0.01992100\n",
      "Iteration 1674, loss = 0.01990837\n",
      "Iteration 1675, loss = 0.01989646\n",
      "Iteration 1676, loss = 0.01988452\n",
      "Iteration 1677, loss = 0.01986966\n",
      "Iteration 1678, loss = 0.01985690\n",
      "Iteration 1679, loss = 0.01984673\n",
      "Iteration 1680, loss = 0.01983603\n",
      "Iteration 1681, loss = 0.01982203\n",
      "Iteration 1682, loss = 0.01981003\n",
      "Iteration 1683, loss = 0.01979761\n",
      "Iteration 1684, loss = 0.01978541\n",
      "Iteration 1685, loss = 0.01977547\n",
      "Iteration 1686, loss = 0.01976164\n",
      "Iteration 1687, loss = 0.01974931\n",
      "Iteration 1688, loss = 0.01973694\n",
      "Iteration 1689, loss = 0.01972356\n",
      "Iteration 1690, loss = 0.01971031\n",
      "Iteration 1691, loss = 0.01969838\n",
      "Iteration 1692, loss = 0.01968723\n",
      "Iteration 1693, loss = 0.01967313\n",
      "Iteration 1694, loss = 0.01966113\n",
      "Iteration 1695, loss = 0.01965157\n",
      "Iteration 1696, loss = 0.01963721\n",
      "Iteration 1697, loss = 0.01962563\n",
      "Iteration 1698, loss = 0.01961412\n",
      "Iteration 1699, loss = 0.01960331\n",
      "Iteration 1700, loss = 0.01959071\n",
      "Iteration 1701, loss = 0.01957853\n",
      "Iteration 1702, loss = 0.01956638\n",
      "Iteration 1703, loss = 0.01955385\n",
      "Iteration 1704, loss = 0.01954608\n",
      "Iteration 1705, loss = 0.01952975\n",
      "Iteration 1706, loss = 0.01951858\n",
      "Iteration 1707, loss = 0.01950513\n",
      "Iteration 1708, loss = 0.01949272\n",
      "Iteration 1709, loss = 0.01948037\n",
      "Iteration 1710, loss = 0.01946801\n",
      "Iteration 1711, loss = 0.01945753\n",
      "Iteration 1712, loss = 0.01944430\n",
      "Iteration 1713, loss = 0.01943102\n",
      "Iteration 1714, loss = 0.01941899\n",
      "Iteration 1715, loss = 0.01940746\n",
      "Iteration 1716, loss = 0.01939525\n",
      "Iteration 1717, loss = 0.01939222\n",
      "Iteration 1718, loss = 0.01937424\n",
      "Iteration 1719, loss = 0.01936118\n",
      "Iteration 1720, loss = 0.01934890\n",
      "Iteration 1721, loss = 0.01933660\n",
      "Iteration 1722, loss = 0.01932611\n",
      "Iteration 1723, loss = 0.01931426\n",
      "Iteration 1724, loss = 0.01930157\n",
      "Iteration 1725, loss = 0.01928962\n",
      "Iteration 1726, loss = 0.01927775\n",
      "Iteration 1727, loss = 0.01926714\n",
      "Iteration 1728, loss = 0.01925528\n",
      "Iteration 1729, loss = 0.01924263\n",
      "Iteration 1730, loss = 0.01923004\n",
      "Iteration 1731, loss = 0.01922056\n",
      "Iteration 1732, loss = 0.01921175\n",
      "Iteration 1733, loss = 0.01919625\n",
      "Iteration 1734, loss = 0.01918314\n",
      "Iteration 1735, loss = 0.01916948\n",
      "Iteration 1736, loss = 0.01916075\n",
      "Iteration 1737, loss = 0.01915015\n",
      "Iteration 1738, loss = 0.01913669\n",
      "Iteration 1739, loss = 0.01912453\n",
      "Iteration 1740, loss = 0.01911364\n",
      "Iteration 1741, loss = 0.01910081\n",
      "Iteration 1742, loss = 0.01909060\n",
      "Iteration 1743, loss = 0.01907867\n",
      "Iteration 1744, loss = 0.01906669\n",
      "Iteration 1745, loss = 0.01905497\n",
      "Iteration 1746, loss = 0.01904440\n",
      "Iteration 1747, loss = 0.01903235\n",
      "Iteration 1748, loss = 0.01902053\n",
      "Iteration 1749, loss = 0.01900947\n",
      "Iteration 1750, loss = 0.01899921\n",
      "Iteration 1751, loss = 0.01898640\n",
      "Iteration 1752, loss = 0.01897449\n",
      "Iteration 1753, loss = 0.01896456\n",
      "Iteration 1754, loss = 0.01895136\n",
      "Iteration 1755, loss = 0.01893990\n",
      "Iteration 1756, loss = 0.01892719\n",
      "Iteration 1757, loss = 0.01891869\n",
      "Iteration 1758, loss = 0.01890429\n",
      "Iteration 1759, loss = 0.01889261\n",
      "Iteration 1760, loss = 0.01888100\n",
      "Iteration 1761, loss = 0.01886849\n",
      "Iteration 1762, loss = 0.01885679\n",
      "Iteration 1763, loss = 0.01884930\n",
      "Iteration 1764, loss = 0.01883590\n",
      "Iteration 1765, loss = 0.01882372\n",
      "Iteration 1766, loss = 0.01881247\n",
      "Iteration 1767, loss = 0.01880181\n",
      "Iteration 1768, loss = 0.01879083\n",
      "Iteration 1769, loss = 0.01878062\n",
      "Iteration 1770, loss = 0.01877064\n",
      "Iteration 1771, loss = 0.01875894\n",
      "Iteration 1772, loss = 0.01874789\n",
      "Iteration 1773, loss = 0.01873847\n",
      "Iteration 1774, loss = 0.01872486\n",
      "Iteration 1775, loss = 0.01871481\n",
      "Iteration 1776, loss = 0.01870329\n",
      "Iteration 1777, loss = 0.01869048\n",
      "Iteration 1778, loss = 0.01867980\n",
      "Iteration 1779, loss = 0.01866764\n",
      "Iteration 1780, loss = 0.01865623\n",
      "Iteration 1781, loss = 0.01864488\n",
      "Iteration 1782, loss = 0.01863472\n",
      "Iteration 1783, loss = 0.01862215\n",
      "Iteration 1784, loss = 0.01861114\n",
      "Iteration 1785, loss = 0.01860051\n",
      "Iteration 1786, loss = 0.01858731\n",
      "Iteration 1787, loss = 0.01857945\n",
      "Iteration 1788, loss = 0.01856537\n",
      "Iteration 1789, loss = 0.01855615\n",
      "Iteration 1790, loss = 0.01854326\n",
      "Iteration 1791, loss = 0.01853108\n",
      "Iteration 1792, loss = 0.01851884\n",
      "Iteration 1793, loss = 0.01850676\n",
      "Iteration 1794, loss = 0.01849396\n",
      "Iteration 1795, loss = 0.01848296\n",
      "Iteration 1796, loss = 0.01847356\n",
      "Iteration 1797, loss = 0.01846091\n",
      "Iteration 1798, loss = 0.01844979\n",
      "Iteration 1799, loss = 0.01844004\n",
      "Iteration 1800, loss = 0.01842919\n",
      "Iteration 1801, loss = 0.01841921\n",
      "Iteration 1802, loss = 0.01840611\n",
      "Iteration 1803, loss = 0.01839508\n",
      "Iteration 1804, loss = 0.01838436\n",
      "Iteration 1805, loss = 0.01837556\n",
      "Iteration 1806, loss = 0.01836155\n",
      "Iteration 1807, loss = 0.01835395\n",
      "Iteration 1808, loss = 0.01833847\n",
      "Iteration 1809, loss = 0.01832844\n",
      "Iteration 1810, loss = 0.01831676\n",
      "Iteration 1811, loss = 0.01830571\n",
      "Iteration 1812, loss = 0.01829273\n",
      "Iteration 1813, loss = 0.01828495\n",
      "Iteration 1814, loss = 0.01827250\n",
      "Iteration 1815, loss = 0.01826154\n",
      "Iteration 1816, loss = 0.01825024\n",
      "Iteration 1817, loss = 0.01824014\n",
      "Iteration 1818, loss = 0.01823169\n",
      "Iteration 1819, loss = 0.01822006\n",
      "Iteration 1820, loss = 0.01820825\n",
      "Iteration 1821, loss = 0.01819731\n",
      "Iteration 1822, loss = 0.01818655\n",
      "Iteration 1823, loss = 0.01817475\n",
      "Iteration 1824, loss = 0.01816615\n",
      "Iteration 1825, loss = 0.01815445\n",
      "Iteration 1826, loss = 0.01814325\n",
      "Iteration 1827, loss = 0.01813201\n",
      "Iteration 1828, loss = 0.01812226\n",
      "Iteration 1829, loss = 0.01811158\n",
      "Iteration 1830, loss = 0.01810144\n",
      "Iteration 1831, loss = 0.01809012\n",
      "Iteration 1832, loss = 0.01808025\n",
      "Iteration 1833, loss = 0.01806968\n",
      "Iteration 1834, loss = 0.01805908\n",
      "Iteration 1835, loss = 0.01805068\n",
      "Iteration 1836, loss = 0.01803830\n",
      "Iteration 1837, loss = 0.01802806\n",
      "Iteration 1838, loss = 0.01801916\n",
      "Iteration 1839, loss = 0.01800619\n",
      "Iteration 1840, loss = 0.01799508\n",
      "Iteration 1841, loss = 0.01798643\n",
      "Iteration 1842, loss = 0.01797392\n",
      "Iteration 1843, loss = 0.01796218\n",
      "Iteration 1844, loss = 0.01795635\n",
      "Iteration 1845, loss = 0.01794416\n",
      "Iteration 1846, loss = 0.01793421\n",
      "Iteration 1847, loss = 0.01792399\n",
      "Iteration 1848, loss = 0.01791403\n",
      "Iteration 1849, loss = 0.01790635\n",
      "Iteration 1850, loss = 0.01789601\n",
      "Iteration 1851, loss = 0.01788510\n",
      "Iteration 1852, loss = 0.01787465\n",
      "Iteration 1853, loss = 0.01786425\n",
      "Iteration 1854, loss = 0.01785452\n",
      "Iteration 1855, loss = 0.01784623\n",
      "Iteration 1856, loss = 0.01783713\n",
      "Iteration 1857, loss = 0.01782891\n",
      "Iteration 1858, loss = 0.01781781\n",
      "Iteration 1859, loss = 0.01780664\n",
      "Iteration 1860, loss = 0.01779554\n",
      "Iteration 1861, loss = 0.01778566\n",
      "Iteration 1862, loss = 0.01777363\n",
      "Iteration 1863, loss = 0.01776323\n",
      "Iteration 1864, loss = 0.01775302\n",
      "Iteration 1865, loss = 0.01774044\n",
      "Iteration 1866, loss = 0.01773036\n",
      "Iteration 1867, loss = 0.01771857\n",
      "Iteration 1868, loss = 0.01770670\n",
      "Iteration 1869, loss = 0.01769772\n",
      "Iteration 1870, loss = 0.01768665\n",
      "Iteration 1871, loss = 0.01767565\n",
      "Iteration 1872, loss = 0.01766607\n",
      "Iteration 1873, loss = 0.01765386\n",
      "Iteration 1874, loss = 0.01764545\n",
      "Iteration 1875, loss = 0.01763495\n",
      "Iteration 1876, loss = 0.01762507\n",
      "Iteration 1877, loss = 0.01761358\n",
      "Iteration 1878, loss = 0.01760331\n",
      "Iteration 1879, loss = 0.01759382\n",
      "Iteration 1880, loss = 0.01758940\n",
      "Iteration 1881, loss = 0.01757486\n",
      "Iteration 1882, loss = 0.01756440\n",
      "Iteration 1883, loss = 0.01755369\n",
      "Iteration 1884, loss = 0.01754426\n",
      "Iteration 1885, loss = 0.01753408\n",
      "Iteration 1886, loss = 0.01752292\n",
      "Iteration 1887, loss = 0.01751171\n",
      "Iteration 1888, loss = 0.01750108\n",
      "Iteration 1889, loss = 0.01749091\n",
      "Iteration 1890, loss = 0.01748178\n",
      "Iteration 1891, loss = 0.01746948\n",
      "Iteration 1892, loss = 0.01745932\n",
      "Iteration 1893, loss = 0.01745053\n",
      "Iteration 1894, loss = 0.01744061\n",
      "Iteration 1895, loss = 0.01742861\n",
      "Iteration 1896, loss = 0.01741750\n",
      "Iteration 1897, loss = 0.01740823\n",
      "Iteration 1898, loss = 0.01739742\n",
      "Iteration 1899, loss = 0.01739025\n",
      "Iteration 1900, loss = 0.01737566\n",
      "Iteration 1901, loss = 0.01736430\n",
      "Iteration 1902, loss = 0.01735469\n",
      "Iteration 1903, loss = 0.01734322\n",
      "Iteration 1904, loss = 0.01733386\n",
      "Iteration 1905, loss = 0.01732220\n",
      "Iteration 1906, loss = 0.01731440\n",
      "Iteration 1907, loss = 0.01730251\n",
      "Iteration 1908, loss = 0.01729340\n",
      "Iteration 1909, loss = 0.01728272\n",
      "Iteration 1910, loss = 0.01727215\n",
      "Iteration 1911, loss = 0.01726242\n",
      "Iteration 1912, loss = 0.01725188\n",
      "Iteration 1913, loss = 0.01724275\n",
      "Iteration 1914, loss = 0.01723318\n",
      "Iteration 1915, loss = 0.01722292\n",
      "Iteration 1916, loss = 0.01721271\n",
      "Iteration 1917, loss = 0.01720497\n",
      "Iteration 1918, loss = 0.01719520\n",
      "Iteration 1919, loss = 0.01718381\n",
      "Iteration 1920, loss = 0.01717423\n",
      "Iteration 1921, loss = 0.01716503\n",
      "Iteration 1922, loss = 0.01715544\n",
      "Iteration 1923, loss = 0.01714696\n",
      "Iteration 1924, loss = 0.01713725\n",
      "Iteration 1925, loss = 0.01713020\n",
      "Iteration 1926, loss = 0.01711848\n",
      "Iteration 1927, loss = 0.01710954\n",
      "Iteration 1928, loss = 0.01710026\n",
      "Iteration 1929, loss = 0.01709061\n",
      "Iteration 1930, loss = 0.01708247\n",
      "Iteration 1931, loss = 0.01707352\n",
      "Iteration 1932, loss = 0.01706650\n",
      "Iteration 1933, loss = 0.01705793\n",
      "Iteration 1934, loss = 0.01705058\n",
      "Iteration 1935, loss = 0.01704269\n",
      "Iteration 1936, loss = 0.01703519\n",
      "Iteration 1937, loss = 0.01702573\n",
      "Iteration 1938, loss = 0.01701727\n",
      "Iteration 1939, loss = 0.01700846\n",
      "Iteration 1940, loss = 0.01699896\n",
      "Iteration 1941, loss = 0.01698896\n",
      "Iteration 1942, loss = 0.01697985\n",
      "Iteration 1943, loss = 0.01697249\n",
      "Iteration 1944, loss = 0.01696144\n",
      "Iteration 1945, loss = 0.01695295\n",
      "Iteration 1946, loss = 0.01694100\n",
      "Iteration 1947, loss = 0.01693131\n",
      "Iteration 1948, loss = 0.01692068\n",
      "Iteration 1949, loss = 0.01691008\n",
      "Iteration 1950, loss = 0.01690016\n",
      "Iteration 1951, loss = 0.01689081\n",
      "Iteration 1952, loss = 0.01688176\n",
      "Iteration 1953, loss = 0.01687269\n",
      "Iteration 1954, loss = 0.01686445\n",
      "Iteration 1955, loss = 0.01685498\n",
      "Iteration 1956, loss = 0.01684648\n",
      "Iteration 1957, loss = 0.01683786\n",
      "Iteration 1958, loss = 0.01682947\n",
      "Iteration 1959, loss = 0.01682072\n",
      "Iteration 1960, loss = 0.01681271\n",
      "Iteration 1961, loss = 0.01680532\n",
      "Iteration 1962, loss = 0.01679639\n",
      "Iteration 1963, loss = 0.01678876\n",
      "Iteration 1964, loss = 0.01678062\n",
      "Iteration 1965, loss = 0.01677044\n",
      "Iteration 1966, loss = 0.01676141\n",
      "Iteration 1967, loss = 0.01675323\n",
      "Iteration 1968, loss = 0.01674249\n",
      "Iteration 1969, loss = 0.01673324\n",
      "Iteration 1970, loss = 0.01672305\n",
      "Iteration 1971, loss = 0.01671328\n",
      "Iteration 1972, loss = 0.01670493\n",
      "Iteration 1973, loss = 0.01669712\n",
      "Iteration 1974, loss = 0.01668652\n",
      "Iteration 1975, loss = 0.01667700\n",
      "Iteration 1976, loss = 0.01666945\n",
      "Iteration 1977, loss = 0.01666191\n",
      "Iteration 1978, loss = 0.01665138\n",
      "Iteration 1979, loss = 0.01664334\n",
      "Iteration 1980, loss = 0.01663431\n",
      "Iteration 1981, loss = 0.01662364\n",
      "Iteration 1982, loss = 0.01661398\n",
      "Iteration 1983, loss = 0.01660405\n",
      "Iteration 1984, loss = 0.01659345\n",
      "Iteration 1985, loss = 0.01658364\n",
      "Iteration 1986, loss = 0.01657288\n",
      "Iteration 1987, loss = 0.01656530\n",
      "Iteration 1988, loss = 0.01655577\n",
      "Iteration 1989, loss = 0.01654640\n",
      "Iteration 1990, loss = 0.01653581\n",
      "Iteration 1991, loss = 0.01652752\n",
      "Iteration 1992, loss = 0.01651902\n",
      "Iteration 1993, loss = 0.01650910\n",
      "Iteration 1994, loss = 0.01650186\n",
      "Iteration 1995, loss = 0.01649228\n",
      "Iteration 1996, loss = 0.01648304\n",
      "Iteration 1997, loss = 0.01647476\n",
      "Iteration 1998, loss = 0.01646703\n",
      "Iteration 1999, loss = 0.01645729\n",
      "Iteration 2000, loss = 0.01645082\n",
      "Iteration 2001, loss = 0.01644010\n",
      "Iteration 2002, loss = 0.01643023\n",
      "Iteration 2003, loss = 0.01642281\n",
      "Iteration 2004, loss = 0.01641205\n",
      "Iteration 2005, loss = 0.01640402\n",
      "Iteration 2006, loss = 0.01639501\n",
      "Iteration 2007, loss = 0.01638667\n",
      "Iteration 2008, loss = 0.01637755\n",
      "Iteration 2009, loss = 0.01636896\n",
      "Iteration 2010, loss = 0.01636030\n",
      "Iteration 2011, loss = 0.01635162\n",
      "Iteration 2012, loss = 0.01634267\n",
      "Iteration 2013, loss = 0.01633441\n",
      "Iteration 2014, loss = 0.01632564\n",
      "Iteration 2015, loss = 0.01631740\n",
      "Iteration 2016, loss = 0.01631012\n",
      "Iteration 2017, loss = 0.01629776\n",
      "Iteration 2018, loss = 0.01628694\n",
      "Iteration 2019, loss = 0.01627765\n",
      "Iteration 2020, loss = 0.01626743\n",
      "Iteration 2021, loss = 0.01625619\n",
      "Iteration 2022, loss = 0.01624734\n",
      "Iteration 2023, loss = 0.01623782\n",
      "Iteration 2024, loss = 0.01623058\n",
      "Iteration 2025, loss = 0.01621898\n",
      "Iteration 2026, loss = 0.01621099\n",
      "Iteration 2027, loss = 0.01620241\n",
      "Iteration 2028, loss = 0.01619484\n",
      "Iteration 2029, loss = 0.01618614\n",
      "Iteration 2030, loss = 0.01617586\n",
      "Iteration 2031, loss = 0.01616733\n",
      "Iteration 2032, loss = 0.01615874\n",
      "Iteration 2033, loss = 0.01615033\n",
      "Iteration 2034, loss = 0.01614207\n",
      "Iteration 2035, loss = 0.01613192\n",
      "Iteration 2036, loss = 0.01612329\n",
      "Iteration 2037, loss = 0.01611616\n",
      "Iteration 2038, loss = 0.01610637\n",
      "Iteration 2039, loss = 0.01609834\n",
      "Iteration 2040, loss = 0.01608915\n",
      "Iteration 2041, loss = 0.01608245\n",
      "Iteration 2042, loss = 0.01607383\n",
      "Iteration 2043, loss = 0.01606301\n",
      "Iteration 2044, loss = 0.01605305\n",
      "Iteration 2045, loss = 0.01604471\n",
      "Iteration 2046, loss = 0.01603682\n",
      "Iteration 2047, loss = 0.01602636\n",
      "Iteration 2048, loss = 0.01601973\n",
      "Iteration 2049, loss = 0.01600950\n",
      "Iteration 2050, loss = 0.01599884\n",
      "Iteration 2051, loss = 0.01599016\n",
      "Iteration 2052, loss = 0.01598318\n",
      "Iteration 2053, loss = 0.01597315\n",
      "Iteration 2054, loss = 0.01596778\n",
      "Iteration 2055, loss = 0.01595543\n",
      "Iteration 2056, loss = 0.01594741\n",
      "Iteration 2057, loss = 0.01594030\n",
      "Iteration 2058, loss = 0.01592938\n",
      "Iteration 2059, loss = 0.01592211\n",
      "Iteration 2060, loss = 0.01591245\n",
      "Iteration 2061, loss = 0.01590421\n",
      "Iteration 2062, loss = 0.01589871\n",
      "Iteration 2063, loss = 0.01588838\n",
      "Iteration 2064, loss = 0.01587913\n",
      "Iteration 2065, loss = 0.01587111\n",
      "Iteration 2066, loss = 0.01586410\n",
      "Iteration 2067, loss = 0.01585357\n",
      "Iteration 2068, loss = 0.01584487\n",
      "Iteration 2069, loss = 0.01583598\n",
      "Iteration 2070, loss = 0.01582786\n",
      "Iteration 2071, loss = 0.01581987\n",
      "Iteration 2072, loss = 0.01581084\n",
      "Iteration 2073, loss = 0.01580667\n",
      "Iteration 2074, loss = 0.01579354\n",
      "Iteration 2075, loss = 0.01578456\n",
      "Iteration 2076, loss = 0.01577513\n",
      "Iteration 2077, loss = 0.01576548\n",
      "Iteration 2078, loss = 0.01575558\n",
      "Iteration 2079, loss = 0.01574741\n",
      "Iteration 2080, loss = 0.01573656\n",
      "Iteration 2081, loss = 0.01572692\n",
      "Iteration 2082, loss = 0.01571821\n",
      "Iteration 2083, loss = 0.01571040\n",
      "Iteration 2084, loss = 0.01570033\n",
      "Iteration 2085, loss = 0.01569154\n",
      "Iteration 2086, loss = 0.01568214\n",
      "Iteration 2087, loss = 0.01567423\n",
      "Iteration 2088, loss = 0.01566537\n",
      "Iteration 2089, loss = 0.01565984\n",
      "Iteration 2090, loss = 0.01565075\n",
      "Iteration 2091, loss = 0.01564472\n",
      "Iteration 2092, loss = 0.01563565\n",
      "Iteration 2093, loss = 0.01562809\n",
      "Iteration 2094, loss = 0.01562166\n",
      "Iteration 2095, loss = 0.01561354\n",
      "Iteration 2096, loss = 0.01560689\n",
      "Iteration 2097, loss = 0.01559841\n",
      "Iteration 2098, loss = 0.01559004\n",
      "Iteration 2099, loss = 0.01558182\n",
      "Iteration 2100, loss = 0.01557263\n",
      "Iteration 2101, loss = 0.01556364\n",
      "Iteration 2102, loss = 0.01555646\n",
      "Iteration 2103, loss = 0.01554789\n",
      "Iteration 2104, loss = 0.01554002\n",
      "Iteration 2105, loss = 0.01553174\n",
      "Iteration 2106, loss = 0.01552420\n",
      "Iteration 2107, loss = 0.01551519\n",
      "Iteration 2108, loss = 0.01550766\n",
      "Iteration 2109, loss = 0.01549925\n",
      "Iteration 2110, loss = 0.01549083\n",
      "Iteration 2111, loss = 0.01548311\n",
      "Iteration 2112, loss = 0.01547434\n",
      "Iteration 2113, loss = 0.01546593\n",
      "Iteration 2114, loss = 0.01545894\n",
      "Iteration 2115, loss = 0.01545160\n",
      "Iteration 2116, loss = 0.01544590\n",
      "Iteration 2117, loss = 0.01543554\n",
      "Iteration 2118, loss = 0.01542665\n",
      "Iteration 2119, loss = 0.01541846\n",
      "Iteration 2120, loss = 0.01540856\n",
      "Iteration 2121, loss = 0.01540114\n",
      "Iteration 2122, loss = 0.01539246\n",
      "Iteration 2123, loss = 0.01538350\n",
      "Iteration 2124, loss = 0.01537697\n",
      "Iteration 2125, loss = 0.01536930\n",
      "Iteration 2126, loss = 0.01536142\n",
      "Iteration 2127, loss = 0.01535387\n",
      "Iteration 2128, loss = 0.01534390\n",
      "Iteration 2129, loss = 0.01533474\n",
      "Iteration 2130, loss = 0.01532779\n",
      "Iteration 2131, loss = 0.01531934\n",
      "Iteration 2132, loss = 0.01531134\n",
      "Iteration 2133, loss = 0.01530441\n",
      "Iteration 2134, loss = 0.01529295\n",
      "Iteration 2135, loss = 0.01528765\n",
      "Iteration 2136, loss = 0.01527763\n",
      "Iteration 2137, loss = 0.01526888\n",
      "Iteration 2138, loss = 0.01526031\n",
      "Iteration 2139, loss = 0.01525262\n",
      "Iteration 2140, loss = 0.01524500\n",
      "Iteration 2141, loss = 0.01523816\n",
      "Iteration 2142, loss = 0.01522917\n",
      "Iteration 2143, loss = 0.01522285\n",
      "Iteration 2144, loss = 0.01521254\n",
      "Iteration 2145, loss = 0.01520565\n",
      "Iteration 2146, loss = 0.01519616\n",
      "Iteration 2147, loss = 0.01518956\n",
      "Iteration 2148, loss = 0.01518021\n",
      "Iteration 2149, loss = 0.01517228\n",
      "Iteration 2150, loss = 0.01516440\n",
      "Iteration 2151, loss = 0.01515645\n",
      "Iteration 2152, loss = 0.01514853\n",
      "Iteration 2153, loss = 0.01514125\n",
      "Iteration 2154, loss = 0.01513366\n",
      "Iteration 2155, loss = 0.01512472\n",
      "Iteration 2156, loss = 0.01511636\n",
      "Iteration 2157, loss = 0.01510814\n",
      "Iteration 2158, loss = 0.01509812\n",
      "Iteration 2159, loss = 0.01509102\n",
      "Iteration 2160, loss = 0.01508118\n",
      "Iteration 2161, loss = 0.01507291\n",
      "Iteration 2162, loss = 0.01506810\n",
      "Iteration 2163, loss = 0.01505618\n",
      "Iteration 2164, loss = 0.01504820\n",
      "Iteration 2165, loss = 0.01503987\n",
      "Iteration 2166, loss = 0.01503063\n",
      "Iteration 2167, loss = 0.01502322\n",
      "Iteration 2168, loss = 0.01501489\n",
      "Iteration 2169, loss = 0.01500615\n",
      "Iteration 2170, loss = 0.01499947\n",
      "Iteration 2171, loss = 0.01499200\n",
      "Iteration 2172, loss = 0.01498423\n",
      "Iteration 2173, loss = 0.01497718\n",
      "Iteration 2174, loss = 0.01497005\n",
      "Iteration 2175, loss = 0.01496515\n",
      "Iteration 2176, loss = 0.01495786\n",
      "Iteration 2177, loss = 0.01494847\n",
      "Iteration 2178, loss = 0.01493993\n",
      "Iteration 2179, loss = 0.01493274\n",
      "Iteration 2180, loss = 0.01492583\n",
      "Iteration 2181, loss = 0.01491723\n",
      "Iteration 2182, loss = 0.01490869\n",
      "Iteration 2183, loss = 0.01490081\n",
      "Iteration 2184, loss = 0.01489371\n",
      "Iteration 2185, loss = 0.01488491\n",
      "Iteration 2186, loss = 0.01487747\n",
      "Iteration 2187, loss = 0.01486949\n",
      "Iteration 2188, loss = 0.01486312\n",
      "Iteration 2189, loss = 0.01485527\n",
      "Iteration 2190, loss = 0.01484938\n",
      "Iteration 2191, loss = 0.01484051\n",
      "Iteration 2192, loss = 0.01483485\n",
      "Iteration 2193, loss = 0.01482563\n",
      "Iteration 2194, loss = 0.01481887\n",
      "Iteration 2195, loss = 0.01480901\n",
      "Iteration 2196, loss = 0.01480175\n",
      "Iteration 2197, loss = 0.01479353\n",
      "Iteration 2198, loss = 0.01478483\n",
      "Iteration 2199, loss = 0.01477691\n",
      "Iteration 2200, loss = 0.01476918\n",
      "Iteration 2201, loss = 0.01476197\n",
      "Iteration 2202, loss = 0.01475531\n",
      "Iteration 2203, loss = 0.01474794\n",
      "Iteration 2204, loss = 0.01474168\n",
      "Iteration 2205, loss = 0.01473545\n",
      "Iteration 2206, loss = 0.01472836\n",
      "Iteration 2207, loss = 0.01472256\n",
      "Iteration 2208, loss = 0.01471492\n",
      "Iteration 2209, loss = 0.01470823\n",
      "Iteration 2210, loss = 0.01470120\n",
      "Iteration 2211, loss = 0.01469448\n",
      "Iteration 2212, loss = 0.01468740\n",
      "Iteration 2213, loss = 0.01467994\n",
      "Iteration 2214, loss = 0.01467291\n",
      "Iteration 2215, loss = 0.01466596\n",
      "Iteration 2216, loss = 0.01465820\n",
      "Iteration 2217, loss = 0.01465151\n",
      "Iteration 2218, loss = 0.01464389\n",
      "Iteration 2219, loss = 0.01463678\n",
      "Iteration 2220, loss = 0.01462829\n",
      "Iteration 2221, loss = 0.01462081\n",
      "Iteration 2222, loss = 0.01461422\n",
      "Iteration 2223, loss = 0.01460502\n",
      "Iteration 2224, loss = 0.01459811\n",
      "Iteration 2225, loss = 0.01459047\n",
      "Iteration 2226, loss = 0.01458324\n",
      "Iteration 2227, loss = 0.01457665\n",
      "Iteration 2228, loss = 0.01457013\n",
      "Iteration 2229, loss = 0.01456496\n",
      "Iteration 2230, loss = 0.01455705\n",
      "Iteration 2231, loss = 0.01455079\n",
      "Iteration 2232, loss = 0.01454474\n",
      "Iteration 2233, loss = 0.01453678\n",
      "Iteration 2234, loss = 0.01453070\n",
      "Iteration 2235, loss = 0.01452396\n",
      "Iteration 2236, loss = 0.01451785\n",
      "Iteration 2237, loss = 0.01451102\n",
      "Iteration 2238, loss = 0.01450285\n",
      "Iteration 2239, loss = 0.01449466\n",
      "Iteration 2240, loss = 0.01448515\n",
      "Iteration 2241, loss = 0.01447811\n",
      "Iteration 2242, loss = 0.01446769\n",
      "Iteration 2243, loss = 0.01445613\n",
      "Iteration 2244, loss = 0.01444979\n",
      "Iteration 2245, loss = 0.01444334\n",
      "Iteration 2246, loss = 0.01443327\n",
      "Iteration 2247, loss = 0.01442595\n",
      "Iteration 2248, loss = 0.01441838\n",
      "Iteration 2249, loss = 0.01441086\n",
      "Iteration 2250, loss = 0.01440189\n",
      "Iteration 2251, loss = 0.01439705\n",
      "Iteration 2252, loss = 0.01439213\n",
      "Iteration 2253, loss = 0.01438301\n",
      "Iteration 2254, loss = 0.01437441\n",
      "Iteration 2255, loss = 0.01436825\n",
      "Iteration 2256, loss = 0.01436074\n",
      "Iteration 2257, loss = 0.01435412\n",
      "Iteration 2258, loss = 0.01434763\n",
      "Iteration 2259, loss = 0.01434122\n",
      "Iteration 2260, loss = 0.01433315\n",
      "Iteration 2261, loss = 0.01432689\n",
      "Iteration 2262, loss = 0.01431902\n",
      "Iteration 2263, loss = 0.01431147\n",
      "Iteration 2264, loss = 0.01430499\n",
      "Iteration 2265, loss = 0.01429655\n",
      "Iteration 2266, loss = 0.01428987\n",
      "Iteration 2267, loss = 0.01428323\n",
      "Iteration 2268, loss = 0.01427596\n",
      "Iteration 2269, loss = 0.01426955\n",
      "Iteration 2270, loss = 0.01426300\n",
      "Iteration 2271, loss = 0.01425668\n",
      "Iteration 2272, loss = 0.01425200\n",
      "Iteration 2273, loss = 0.01424461\n",
      "Iteration 2274, loss = 0.01423673\n",
      "Iteration 2275, loss = 0.01422991\n",
      "Iteration 2276, loss = 0.01422162\n",
      "Iteration 2277, loss = 0.01421400\n",
      "Iteration 2278, loss = 0.01420637\n",
      "Iteration 2279, loss = 0.01419884\n",
      "Iteration 2280, loss = 0.01419162\n",
      "Iteration 2281, loss = 0.01418445\n",
      "Iteration 2282, loss = 0.01417602\n",
      "Iteration 2283, loss = 0.01416964\n",
      "Iteration 2284, loss = 0.01416172\n",
      "Iteration 2285, loss = 0.01415399\n",
      "Iteration 2286, loss = 0.01414866\n",
      "Iteration 2287, loss = 0.01414003\n",
      "Iteration 2288, loss = 0.01413241\n",
      "Iteration 2289, loss = 0.01412548\n",
      "Iteration 2290, loss = 0.01411809\n",
      "Iteration 2291, loss = 0.01411151\n",
      "Iteration 2292, loss = 0.01410429\n",
      "Iteration 2293, loss = 0.01409719\n",
      "Iteration 2294, loss = 0.01409024\n",
      "Iteration 2295, loss = 0.01408370\n",
      "Iteration 2296, loss = 0.01407763\n",
      "Iteration 2297, loss = 0.01407098\n",
      "Iteration 2298, loss = 0.01406586\n",
      "Iteration 2299, loss = 0.01405868\n",
      "Iteration 2300, loss = 0.01405242\n",
      "Iteration 2301, loss = 0.01404611\n",
      "Iteration 2302, loss = 0.01403921\n",
      "Iteration 2303, loss = 0.01403294\n",
      "Iteration 2304, loss = 0.01402662\n",
      "Iteration 2305, loss = 0.01401810\n",
      "Iteration 2306, loss = 0.01401084\n",
      "Iteration 2307, loss = 0.01400442\n",
      "Iteration 2308, loss = 0.01399797\n",
      "Iteration 2309, loss = 0.01399018\n",
      "Iteration 2310, loss = 0.01398353\n",
      "Iteration 2311, loss = 0.01397743\n",
      "Iteration 2312, loss = 0.01397147\n",
      "Iteration 2313, loss = 0.01396347\n",
      "Iteration 2314, loss = 0.01395678\n",
      "Iteration 2315, loss = 0.01395008\n",
      "Iteration 2316, loss = 0.01394349\n",
      "Iteration 2317, loss = 0.01393634\n",
      "Iteration 2318, loss = 0.01393022\n",
      "Iteration 2319, loss = 0.01392350\n",
      "Iteration 2320, loss = 0.01391732\n",
      "Iteration 2321, loss = 0.01391165\n",
      "Iteration 2322, loss = 0.01390428\n",
      "Iteration 2323, loss = 0.01389734\n",
      "Iteration 2324, loss = 0.01389118\n",
      "Iteration 2325, loss = 0.01388448\n",
      "Iteration 2326, loss = 0.01387747\n",
      "Iteration 2327, loss = 0.01386981\n",
      "Iteration 2328, loss = 0.01386247\n",
      "Iteration 2329, loss = 0.01385338\n",
      "Iteration 2330, loss = 0.01384974\n",
      "Iteration 2331, loss = 0.01384068\n",
      "Iteration 2332, loss = 0.01383321\n",
      "Iteration 2333, loss = 0.01382675\n",
      "Iteration 2334, loss = 0.01381763\n",
      "Iteration 2335, loss = 0.01380995\n",
      "Iteration 2336, loss = 0.01380432\n",
      "Iteration 2337, loss = 0.01379635\n",
      "Iteration 2338, loss = 0.01378953\n",
      "Iteration 2339, loss = 0.01378116\n",
      "Iteration 2340, loss = 0.01377589\n",
      "Iteration 2341, loss = 0.01376825\n",
      "Iteration 2342, loss = 0.01376007\n",
      "Iteration 2343, loss = 0.01375310\n",
      "Iteration 2344, loss = 0.01374580\n",
      "Iteration 2345, loss = 0.01373870\n",
      "Iteration 2346, loss = 0.01373339\n",
      "Iteration 2347, loss = 0.01372522\n",
      "Iteration 2348, loss = 0.01371647\n",
      "Iteration 2349, loss = 0.01370907\n",
      "Iteration 2350, loss = 0.01370266\n",
      "Iteration 2351, loss = 0.01369574\n",
      "Iteration 2352, loss = 0.01368789\n",
      "Iteration 2353, loss = 0.01368103\n",
      "Iteration 2354, loss = 0.01367748\n",
      "Iteration 2355, loss = 0.01366765\n",
      "Iteration 2356, loss = 0.01366379\n",
      "Iteration 2357, loss = 0.01365398\n",
      "Iteration 2358, loss = 0.01364694\n",
      "Iteration 2359, loss = 0.01364097\n",
      "Iteration 2360, loss = 0.01363356\n",
      "Iteration 2361, loss = 0.01362686\n",
      "Iteration 2362, loss = 0.01362138\n",
      "Iteration 2363, loss = 0.01361395\n",
      "Iteration 2364, loss = 0.01360690\n",
      "Iteration 2365, loss = 0.01359964\n",
      "Iteration 2366, loss = 0.01359275\n",
      "Iteration 2367, loss = 0.01358548\n",
      "Iteration 2368, loss = 0.01357864\n",
      "Iteration 2369, loss = 0.01357075\n",
      "Iteration 2370, loss = 0.01356386\n",
      "Iteration 2371, loss = 0.01355811\n",
      "Iteration 2372, loss = 0.01355337\n",
      "Iteration 2373, loss = 0.01354457\n",
      "Iteration 2374, loss = 0.01353787\n",
      "Iteration 2375, loss = 0.01353112\n",
      "Iteration 2376, loss = 0.01352478\n",
      "Iteration 2377, loss = 0.01351778\n",
      "Iteration 2378, loss = 0.01351151\n",
      "Iteration 2379, loss = 0.01350563\n",
      "Iteration 2380, loss = 0.01349894\n",
      "Iteration 2381, loss = 0.01349253\n",
      "Iteration 2382, loss = 0.01348692\n",
      "Iteration 2383, loss = 0.01348136\n",
      "Iteration 2384, loss = 0.01347485\n",
      "Iteration 2385, loss = 0.01346960\n",
      "Iteration 2386, loss = 0.01346292\n",
      "Iteration 2387, loss = 0.01345710\n",
      "Iteration 2388, loss = 0.01345119\n",
      "Iteration 2389, loss = 0.01344401\n",
      "Iteration 2390, loss = 0.01343802\n",
      "Iteration 2391, loss = 0.01343075\n",
      "Iteration 2392, loss = 0.01342459\n",
      "Iteration 2393, loss = 0.01341852\n",
      "Iteration 2394, loss = 0.01341207\n",
      "Iteration 2395, loss = 0.01340649\n",
      "Iteration 2396, loss = 0.01339747\n",
      "Iteration 2397, loss = 0.01339160\n",
      "Iteration 2398, loss = 0.01338396\n",
      "Iteration 2399, loss = 0.01337620\n",
      "Iteration 2400, loss = 0.01337099\n",
      "Iteration 2401, loss = 0.01336465\n",
      "Iteration 2402, loss = 0.01335645\n",
      "Iteration 2403, loss = 0.01334990\n",
      "Iteration 2404, loss = 0.01334293\n",
      "Iteration 2405, loss = 0.01333904\n",
      "Iteration 2406, loss = 0.01332997\n",
      "Iteration 2407, loss = 0.01332316\n",
      "Iteration 2408, loss = 0.01331700\n",
      "Iteration 2409, loss = 0.01331043\n",
      "Iteration 2410, loss = 0.01330419\n",
      "Iteration 2411, loss = 0.01329731\n",
      "Iteration 2412, loss = 0.01329158\n",
      "Iteration 2413, loss = 0.01328515\n",
      "Iteration 2414, loss = 0.01327933\n",
      "Iteration 2415, loss = 0.01326981\n",
      "Iteration 2416, loss = 0.01326394\n",
      "Iteration 2417, loss = 0.01325599\n",
      "Iteration 2418, loss = 0.01325156\n",
      "Iteration 2419, loss = 0.01324363\n",
      "Iteration 2420, loss = 0.01323708\n",
      "Iteration 2421, loss = 0.01323056\n",
      "Iteration 2422, loss = 0.01322402\n",
      "Iteration 2423, loss = 0.01321843\n",
      "Iteration 2424, loss = 0.01321147\n",
      "Iteration 2425, loss = 0.01320528\n",
      "Iteration 2426, loss = 0.01319934\n",
      "Iteration 2427, loss = 0.01319366\n",
      "Iteration 2428, loss = 0.01318836\n",
      "Iteration 2429, loss = 0.01318249\n",
      "Iteration 2430, loss = 0.01317670\n",
      "Iteration 2431, loss = 0.01317089\n",
      "Iteration 2432, loss = 0.01316488\n",
      "Iteration 2433, loss = 0.01316053\n",
      "Iteration 2434, loss = 0.01315380\n",
      "Iteration 2435, loss = 0.01314863\n",
      "Iteration 2436, loss = 0.01314289\n",
      "Iteration 2437, loss = 0.01313780\n",
      "Iteration 2438, loss = 0.01313233\n",
      "Iteration 2439, loss = 0.01312716\n",
      "Iteration 2440, loss = 0.01312084\n",
      "Iteration 2441, loss = 0.01311502\n",
      "Iteration 2442, loss = 0.01310978\n",
      "Iteration 2443, loss = 0.01310327\n",
      "Iteration 2444, loss = 0.01309748\n",
      "Iteration 2445, loss = 0.01309123\n",
      "Iteration 2446, loss = 0.01308558\n",
      "Iteration 2447, loss = 0.01308113\n",
      "Iteration 2448, loss = 0.01307218\n",
      "Iteration 2449, loss = 0.01306622\n",
      "Iteration 2450, loss = 0.01305916\n",
      "Iteration 2451, loss = 0.01305343\n",
      "Iteration 2452, loss = 0.01304710\n",
      "Iteration 2453, loss = 0.01304160\n",
      "Iteration 2454, loss = 0.01303621\n",
      "Iteration 2455, loss = 0.01302983\n",
      "Iteration 2456, loss = 0.01302424\n",
      "Iteration 2457, loss = 0.01301789\n",
      "Iteration 2458, loss = 0.01301197\n",
      "Iteration 2459, loss = 0.01300773\n",
      "Iteration 2460, loss = 0.01300050\n",
      "Iteration 2461, loss = 0.01299286\n",
      "Iteration 2462, loss = 0.01298618\n",
      "Iteration 2463, loss = 0.01298045\n",
      "Iteration 2464, loss = 0.01297255\n",
      "Iteration 2465, loss = 0.01296534\n",
      "Iteration 2466, loss = 0.01296118\n",
      "Iteration 2467, loss = 0.01295177\n",
      "Iteration 2468, loss = 0.01294659\n",
      "Iteration 2469, loss = 0.01293876\n",
      "Iteration 2470, loss = 0.01293209\n",
      "Iteration 2471, loss = 0.01292565\n",
      "Iteration 2472, loss = 0.01291901\n",
      "Iteration 2473, loss = 0.01291320\n",
      "Iteration 2474, loss = 0.01290646\n",
      "Iteration 2475, loss = 0.01289969\n",
      "Iteration 2476, loss = 0.01289420\n",
      "Iteration 2477, loss = 0.01288680\n",
      "Iteration 2478, loss = 0.01288048\n",
      "Iteration 2479, loss = 0.01287425\n",
      "Iteration 2480, loss = 0.01286803\n",
      "Iteration 2481, loss = 0.01286225\n",
      "Iteration 2482, loss = 0.01285627\n",
      "Iteration 2483, loss = 0.01285066\n",
      "Iteration 2484, loss = 0.01284529\n",
      "Iteration 2485, loss = 0.01283940\n",
      "Iteration 2486, loss = 0.01283406\n",
      "Iteration 2487, loss = 0.01282934\n",
      "Iteration 2488, loss = 0.01282354\n",
      "Iteration 2489, loss = 0.01281830\n",
      "Iteration 2490, loss = 0.01281452\n",
      "Iteration 2491, loss = 0.01280803\n",
      "Iteration 2492, loss = 0.01280246\n",
      "Iteration 2493, loss = 0.01279828\n",
      "Iteration 2494, loss = 0.01279225\n",
      "Iteration 2495, loss = 0.01278640\n",
      "Iteration 2496, loss = 0.01278158\n",
      "Iteration 2497, loss = 0.01277565\n",
      "Iteration 2498, loss = 0.01277209\n",
      "Iteration 2499, loss = 0.01276588\n",
      "Iteration 2500, loss = 0.01276067\n",
      "Iteration 2501, loss = 0.01275387\n",
      "Iteration 2502, loss = 0.01274829\n",
      "Iteration 2503, loss = 0.01274190\n",
      "Iteration 2504, loss = 0.01273565\n",
      "Iteration 2505, loss = 0.01272952\n",
      "Iteration 2506, loss = 0.01272407\n",
      "Iteration 2507, loss = 0.01271795\n",
      "Iteration 2508, loss = 0.01271144\n",
      "Iteration 2509, loss = 0.01270520\n",
      "Iteration 2510, loss = 0.01269983\n",
      "Iteration 2511, loss = 0.01269366\n",
      "Iteration 2512, loss = 0.01268803\n",
      "Iteration 2513, loss = 0.01268242\n",
      "Iteration 2514, loss = 0.01267686\n",
      "Iteration 2515, loss = 0.01267156\n",
      "Iteration 2516, loss = 0.01266641\n",
      "Iteration 2517, loss = 0.01266145\n",
      "Iteration 2518, loss = 0.01265842\n",
      "Iteration 2519, loss = 0.01265184\n",
      "Iteration 2520, loss = 0.01264640\n",
      "Iteration 2521, loss = 0.01264208\n",
      "Iteration 2522, loss = 0.01263587\n",
      "Iteration 2523, loss = 0.01262996\n",
      "Iteration 2524, loss = 0.01262431\n",
      "Iteration 2525, loss = 0.01261865\n",
      "Iteration 2526, loss = 0.01261237\n",
      "Iteration 2527, loss = 0.01260673\n",
      "Iteration 2528, loss = 0.01260137\n",
      "Iteration 2529, loss = 0.01259576\n",
      "Iteration 2530, loss = 0.01259185\n",
      "Iteration 2531, loss = 0.01258536\n",
      "Iteration 2532, loss = 0.01257920\n",
      "Iteration 2533, loss = 0.01257423\n",
      "Iteration 2534, loss = 0.01256854\n",
      "Iteration 2535, loss = 0.01256374\n",
      "Iteration 2536, loss = 0.01255751\n",
      "Iteration 2537, loss = 0.01255241\n",
      "Iteration 2538, loss = 0.01254754\n",
      "Iteration 2539, loss = 0.01254060\n",
      "Iteration 2540, loss = 0.01253563\n",
      "Iteration 2541, loss = 0.01252995\n",
      "Iteration 2542, loss = 0.01252424\n",
      "Iteration 2543, loss = 0.01251800\n",
      "Iteration 2544, loss = 0.01251216\n",
      "Iteration 2545, loss = 0.01250698\n",
      "Iteration 2546, loss = 0.01249969\n",
      "Iteration 2547, loss = 0.01249237\n",
      "Iteration 2548, loss = 0.01248765\n",
      "Iteration 2549, loss = 0.01247866\n",
      "Iteration 2550, loss = 0.01247225\n",
      "Iteration 2551, loss = 0.01246604\n",
      "Iteration 2552, loss = 0.01245883\n",
      "Iteration 2553, loss = 0.01245365\n",
      "Iteration 2554, loss = 0.01244718\n",
      "Iteration 2555, loss = 0.01244120\n",
      "Iteration 2556, loss = 0.01243568\n",
      "Iteration 2557, loss = 0.01243007\n",
      "Iteration 2558, loss = 0.01242511\n",
      "Iteration 2559, loss = 0.01241903\n",
      "Iteration 2560, loss = 0.01241357\n",
      "Iteration 2561, loss = 0.01240845\n",
      "Iteration 2562, loss = 0.01240253\n",
      "Iteration 2563, loss = 0.01239639\n",
      "Iteration 2564, loss = 0.01239204\n",
      "Iteration 2565, loss = 0.01238531\n",
      "Iteration 2566, loss = 0.01238060\n",
      "Iteration 2567, loss = 0.01237369\n",
      "Iteration 2568, loss = 0.01236785\n",
      "Iteration 2569, loss = 0.01236144\n",
      "Iteration 2570, loss = 0.01235577\n",
      "Iteration 2571, loss = 0.01235230\n",
      "Iteration 2572, loss = 0.01234442\n",
      "Iteration 2573, loss = 0.01234065\n",
      "Iteration 2574, loss = 0.01233511\n",
      "Iteration 2575, loss = 0.01232926\n",
      "Iteration 2576, loss = 0.01232435\n",
      "Iteration 2577, loss = 0.01231890\n",
      "Iteration 2578, loss = 0.01231312\n",
      "Iteration 2579, loss = 0.01230812\n",
      "Iteration 2580, loss = 0.01230215\n",
      "Iteration 2581, loss = 0.01229669\n",
      "Iteration 2582, loss = 0.01229203\n",
      "Iteration 2583, loss = 0.01228752\n",
      "Iteration 2584, loss = 0.01228120\n",
      "Iteration 2585, loss = 0.01227566\n",
      "Iteration 2586, loss = 0.01227048\n",
      "Iteration 2587, loss = 0.01226552\n",
      "Iteration 2588, loss = 0.01226029\n",
      "Iteration 2589, loss = 0.01225587\n",
      "Iteration 2590, loss = 0.01225095\n",
      "Iteration 2591, loss = 0.01224612\n",
      "Iteration 2592, loss = 0.01224067\n",
      "Iteration 2593, loss = 0.01223597\n",
      "Iteration 2594, loss = 0.01223031\n",
      "Iteration 2595, loss = 0.01222538\n",
      "Iteration 2596, loss = 0.01222093\n",
      "Iteration 2597, loss = 0.01221432\n",
      "Iteration 2598, loss = 0.01220896\n",
      "Iteration 2599, loss = 0.01220283\n",
      "Iteration 2600, loss = 0.01219861\n",
      "Iteration 2601, loss = 0.01219119\n",
      "Iteration 2602, loss = 0.01218572\n",
      "Iteration 2603, loss = 0.01217973\n",
      "Iteration 2604, loss = 0.01217463\n",
      "Iteration 2605, loss = 0.01216950\n",
      "Iteration 2606, loss = 0.01216402\n",
      "Iteration 2607, loss = 0.01215891\n",
      "Iteration 2608, loss = 0.01215406\n",
      "Iteration 2609, loss = 0.01215002\n",
      "Iteration 2610, loss = 0.01214371\n",
      "Iteration 2611, loss = 0.01213902\n",
      "Iteration 2612, loss = 0.01213528\n",
      "Iteration 2613, loss = 0.01212968\n",
      "Iteration 2614, loss = 0.01212237\n",
      "Iteration 2615, loss = 0.01211687\n",
      "Iteration 2616, loss = 0.01211133\n",
      "Iteration 2617, loss = 0.01210612\n",
      "Iteration 2618, loss = 0.01210124\n",
      "Iteration 2619, loss = 0.01209492\n",
      "Iteration 2620, loss = 0.01208964\n",
      "Iteration 2621, loss = 0.01208483\n",
      "Iteration 2622, loss = 0.01208008\n",
      "Iteration 2623, loss = 0.01207692\n",
      "Iteration 2624, loss = 0.01207138\n",
      "Iteration 2625, loss = 0.01206634\n",
      "Iteration 2626, loss = 0.01206142\n",
      "Iteration 2627, loss = 0.01205681\n",
      "Iteration 2628, loss = 0.01205229\n",
      "Iteration 2629, loss = 0.01204909\n",
      "Iteration 2630, loss = 0.01204352\n",
      "Iteration 2631, loss = 0.01203947\n",
      "Iteration 2632, loss = 0.01203457\n",
      "Iteration 2633, loss = 0.01202920\n",
      "Iteration 2634, loss = 0.01202455\n",
      "Iteration 2635, loss = 0.01202081\n",
      "Iteration 2636, loss = 0.01201422\n",
      "Iteration 2637, loss = 0.01200737\n",
      "Iteration 2638, loss = 0.01200231\n",
      "Iteration 2639, loss = 0.01199517\n",
      "Iteration 2640, loss = 0.01198974\n",
      "Iteration 2641, loss = 0.01198477\n",
      "Iteration 2642, loss = 0.01197916\n",
      "Iteration 2643, loss = 0.01197343\n",
      "Iteration 2644, loss = 0.01196852\n",
      "Iteration 2645, loss = 0.01196384\n",
      "Iteration 2646, loss = 0.01195868\n",
      "Iteration 2647, loss = 0.01195396\n",
      "Iteration 2648, loss = 0.01194970\n",
      "Iteration 2649, loss = 0.01194547\n",
      "Iteration 2650, loss = 0.01194066\n",
      "Iteration 2651, loss = 0.01193584\n",
      "Iteration 2652, loss = 0.01193092\n",
      "Iteration 2653, loss = 0.01192645\n",
      "Iteration 2654, loss = 0.01192218\n",
      "Iteration 2655, loss = 0.01191841\n",
      "Iteration 2656, loss = 0.01191334\n",
      "Iteration 2657, loss = 0.01190852\n",
      "Iteration 2658, loss = 0.01190344\n",
      "Iteration 2659, loss = 0.01189856\n",
      "Iteration 2660, loss = 0.01189174\n",
      "Iteration 2661, loss = 0.01188600\n",
      "Iteration 2662, loss = 0.01188050\n",
      "Iteration 2663, loss = 0.01187467\n",
      "Iteration 2664, loss = 0.01186909\n",
      "Iteration 2665, loss = 0.01186325\n",
      "Iteration 2666, loss = 0.01185755\n",
      "Iteration 2667, loss = 0.01185196\n",
      "Iteration 2668, loss = 0.01184587\n",
      "Iteration 2669, loss = 0.01184140\n",
      "Iteration 2670, loss = 0.01183617\n",
      "Iteration 2671, loss = 0.01183328\n",
      "Iteration 2672, loss = 0.01182514\n",
      "Iteration 2673, loss = 0.01181845\n",
      "Iteration 2674, loss = 0.01181390\n",
      "Iteration 2675, loss = 0.01180539\n",
      "Iteration 2676, loss = 0.01180109\n",
      "Iteration 2677, loss = 0.01179329\n",
      "Iteration 2678, loss = 0.01178810\n",
      "Iteration 2679, loss = 0.01178233\n",
      "Iteration 2680, loss = 0.01177630\n",
      "Iteration 2681, loss = 0.01177212\n",
      "Iteration 2682, loss = 0.01176345\n",
      "Iteration 2683, loss = 0.01175687\n",
      "Iteration 2684, loss = 0.01175101\n",
      "Iteration 2685, loss = 0.01174391\n",
      "Iteration 2686, loss = 0.01173752\n",
      "Iteration 2687, loss = 0.01173105\n",
      "Iteration 2688, loss = 0.01172727\n",
      "Iteration 2689, loss = 0.01171949\n",
      "Iteration 2690, loss = 0.01171474\n",
      "Iteration 2691, loss = 0.01170795\n",
      "Iteration 2692, loss = 0.01170197\n",
      "Iteration 2693, loss = 0.01169556\n",
      "Iteration 2694, loss = 0.01169110\n",
      "Iteration 2695, loss = 0.01168565\n",
      "Iteration 2696, loss = 0.01167812\n",
      "Iteration 2697, loss = 0.01167390\n",
      "Iteration 2698, loss = 0.01166624\n",
      "Iteration 2699, loss = 0.01165925\n",
      "Iteration 2700, loss = 0.01165449\n",
      "Iteration 2701, loss = 0.01165307\n",
      "Iteration 2702, loss = 0.01164311\n",
      "Iteration 2703, loss = 0.01163867\n",
      "Iteration 2704, loss = 0.01163397\n",
      "Iteration 2705, loss = 0.01162801\n",
      "Iteration 2706, loss = 0.01162332\n",
      "Iteration 2707, loss = 0.01161830\n",
      "Iteration 2708, loss = 0.01161314\n",
      "Iteration 2709, loss = 0.01160996\n",
      "Iteration 2710, loss = 0.01160346\n",
      "Iteration 2711, loss = 0.01159739\n",
      "Iteration 2712, loss = 0.01159279\n",
      "Iteration 2713, loss = 0.01158690\n",
      "Iteration 2714, loss = 0.01158186\n",
      "Iteration 2715, loss = 0.01157708\n",
      "Iteration 2716, loss = 0.01157153\n",
      "Iteration 2717, loss = 0.01156595\n",
      "Iteration 2718, loss = 0.01156086\n",
      "Iteration 2719, loss = 0.01155600\n",
      "Iteration 2720, loss = 0.01155085\n",
      "Iteration 2721, loss = 0.01154588\n",
      "Iteration 2722, loss = 0.01154155\n",
      "Iteration 2723, loss = 0.01153583\n",
      "Iteration 2724, loss = 0.01153027\n",
      "Iteration 2725, loss = 0.01152503\n",
      "Iteration 2726, loss = 0.01152008\n",
      "Iteration 2727, loss = 0.01151477\n",
      "Iteration 2728, loss = 0.01150981\n",
      "Iteration 2729, loss = 0.01150381\n",
      "Iteration 2730, loss = 0.01149864\n",
      "Iteration 2731, loss = 0.01149361\n",
      "Iteration 2732, loss = 0.01148795\n",
      "Iteration 2733, loss = 0.01148356\n",
      "Iteration 2734, loss = 0.01147787\n",
      "Iteration 2735, loss = 0.01147218\n",
      "Iteration 2736, loss = 0.01146726\n",
      "Iteration 2737, loss = 0.01146204\n",
      "Iteration 2738, loss = 0.01145781\n",
      "Iteration 2739, loss = 0.01145248\n",
      "Iteration 2740, loss = 0.01144800\n",
      "Iteration 2741, loss = 0.01144288\n",
      "Iteration 2742, loss = 0.01143744\n",
      "Iteration 2743, loss = 0.01143506\n",
      "Iteration 2744, loss = 0.01142775\n",
      "Iteration 2745, loss = 0.01142214\n",
      "Iteration 2746, loss = 0.01141747\n",
      "Iteration 2747, loss = 0.01141140\n",
      "Iteration 2748, loss = 0.01140583\n",
      "Iteration 2749, loss = 0.01140002\n",
      "Iteration 2750, loss = 0.01139470\n",
      "Iteration 2751, loss = 0.01138892\n",
      "Iteration 2752, loss = 0.01138434\n",
      "Iteration 2753, loss = 0.01137961\n",
      "Iteration 2754, loss = 0.01137339\n",
      "Iteration 2755, loss = 0.01136796\n",
      "Iteration 2756, loss = 0.01136275\n",
      "Iteration 2757, loss = 0.01135793\n",
      "Iteration 2758, loss = 0.01135239\n",
      "Iteration 2759, loss = 0.01134732\n",
      "Iteration 2760, loss = 0.01134267\n",
      "Iteration 2761, loss = 0.01133671\n",
      "Iteration 2762, loss = 0.01133215\n",
      "Iteration 2763, loss = 0.01132748\n",
      "Iteration 2764, loss = 0.01132182\n",
      "Iteration 2765, loss = 0.01131624\n",
      "Iteration 2766, loss = 0.01131039\n",
      "Iteration 2767, loss = 0.01130699\n",
      "Iteration 2768, loss = 0.01130047\n",
      "Iteration 2769, loss = 0.01129527\n",
      "Iteration 2770, loss = 0.01129084\n",
      "Iteration 2771, loss = 0.01128552\n",
      "Iteration 2772, loss = 0.01128110\n",
      "Iteration 2773, loss = 0.01127570\n",
      "Iteration 2774, loss = 0.01127201\n",
      "Iteration 2775, loss = 0.01126669\n",
      "Iteration 2776, loss = 0.01126155\n",
      "Iteration 2777, loss = 0.01125641\n",
      "Iteration 2778, loss = 0.01125193\n",
      "Iteration 2779, loss = 0.01124747\n",
      "Iteration 2780, loss = 0.01124326\n",
      "Iteration 2781, loss = 0.01123917\n",
      "Iteration 2782, loss = 0.01123256\n",
      "Iteration 2783, loss = 0.01122644\n",
      "Iteration 2784, loss = 0.01122184\n",
      "Iteration 2785, loss = 0.01121702\n",
      "Iteration 2786, loss = 0.01121284\n",
      "Iteration 2787, loss = 0.01120717\n",
      "Iteration 2788, loss = 0.01120160\n",
      "Iteration 2789, loss = 0.01119652\n",
      "Iteration 2790, loss = 0.01119234\n",
      "Iteration 2791, loss = 0.01118712\n",
      "Iteration 2792, loss = 0.01118299\n",
      "Iteration 2793, loss = 0.01117861\n",
      "Iteration 2794, loss = 0.01117326\n",
      "Iteration 2795, loss = 0.01116917\n",
      "Iteration 2796, loss = 0.01116447\n",
      "Iteration 2797, loss = 0.01115917\n",
      "Iteration 2798, loss = 0.01115425\n",
      "Iteration 2799, loss = 0.01114937\n",
      "Iteration 2800, loss = 0.01114472\n",
      "Iteration 2801, loss = 0.01113950\n",
      "Iteration 2802, loss = 0.01113417\n",
      "Iteration 2803, loss = 0.01112914\n",
      "Iteration 2804, loss = 0.01112589\n",
      "Iteration 2805, loss = 0.01112135\n",
      "Iteration 2806, loss = 0.01111633\n",
      "Iteration 2807, loss = 0.01111111\n",
      "Iteration 2808, loss = 0.01110603\n",
      "Iteration 2809, loss = 0.01110139\n",
      "Iteration 2810, loss = 0.01109704\n",
      "Iteration 2811, loss = 0.01109254\n",
      "Iteration 2812, loss = 0.01108888\n",
      "Iteration 2813, loss = 0.01108522\n",
      "Iteration 2814, loss = 0.01107966\n",
      "Iteration 2815, loss = 0.01107572\n",
      "Iteration 2816, loss = 0.01107018\n",
      "Iteration 2817, loss = 0.01106451\n",
      "Iteration 2818, loss = 0.01105952\n",
      "Iteration 2819, loss = 0.01105388\n",
      "Iteration 2820, loss = 0.01104981\n",
      "Iteration 2821, loss = 0.01104467\n",
      "Iteration 2822, loss = 0.01104066\n",
      "Iteration 2823, loss = 0.01103524\n",
      "Iteration 2824, loss = 0.01102942\n",
      "Iteration 2825, loss = 0.01102555\n",
      "Iteration 2826, loss = 0.01101942\n",
      "Iteration 2827, loss = 0.01101553\n",
      "Iteration 2828, loss = 0.01101087\n",
      "Iteration 2829, loss = 0.01100585\n",
      "Iteration 2830, loss = 0.01100097\n",
      "Iteration 2831, loss = 0.01099605\n",
      "Iteration 2832, loss = 0.01099131\n",
      "Iteration 2833, loss = 0.01098623\n",
      "Iteration 2834, loss = 0.01098130\n",
      "Iteration 2835, loss = 0.01097619\n",
      "Iteration 2836, loss = 0.01097317\n",
      "Iteration 2837, loss = 0.01096702\n",
      "Iteration 2838, loss = 0.01096252\n",
      "Iteration 2839, loss = 0.01095711\n",
      "Iteration 2840, loss = 0.01095294\n",
      "Iteration 2841, loss = 0.01094757\n",
      "Iteration 2842, loss = 0.01094180\n",
      "Iteration 2843, loss = 0.01093843\n",
      "Iteration 2844, loss = 0.01093240\n",
      "Iteration 2845, loss = 0.01092653\n",
      "Iteration 2846, loss = 0.01092183\n",
      "Iteration 2847, loss = 0.01091590\n",
      "Iteration 2848, loss = 0.01091149\n",
      "Iteration 2849, loss = 0.01090597\n",
      "Iteration 2850, loss = 0.01090112\n",
      "Iteration 2851, loss = 0.01089499\n",
      "Iteration 2852, loss = 0.01088930\n",
      "Iteration 2853, loss = 0.01088425\n",
      "Iteration 2854, loss = 0.01087865\n",
      "Iteration 2855, loss = 0.01087702\n",
      "Iteration 2856, loss = 0.01087125\n",
      "Iteration 2857, loss = 0.01086596\n",
      "Iteration 2858, loss = 0.01086135\n",
      "Iteration 2859, loss = 0.01085585\n",
      "Iteration 2860, loss = 0.01085134\n",
      "Iteration 2861, loss = 0.01084543\n",
      "Iteration 2862, loss = 0.01084037\n",
      "Iteration 2863, loss = 0.01083543\n",
      "Iteration 2864, loss = 0.01082999\n",
      "Iteration 2865, loss = 0.01082464\n",
      "Iteration 2866, loss = 0.01081958\n",
      "Iteration 2867, loss = 0.01081439\n",
      "Iteration 2868, loss = 0.01080961\n",
      "Iteration 2869, loss = 0.01080427\n",
      "Iteration 2870, loss = 0.01079858\n",
      "Iteration 2871, loss = 0.01079379\n",
      "Iteration 2872, loss = 0.01078838\n",
      "Iteration 2873, loss = 0.01078513\n",
      "Iteration 2874, loss = 0.01077865\n",
      "Iteration 2875, loss = 0.01077424\n",
      "Iteration 2876, loss = 0.01076941\n",
      "Iteration 2877, loss = 0.01076524\n",
      "Iteration 2878, loss = 0.01076043\n",
      "Iteration 2879, loss = 0.01075513\n",
      "Iteration 2880, loss = 0.01075293\n",
      "Iteration 2881, loss = 0.01074670\n",
      "Iteration 2882, loss = 0.01074074\n",
      "Iteration 2883, loss = 0.01073643\n",
      "Iteration 2884, loss = 0.01073177\n",
      "Iteration 2885, loss = 0.01072792\n",
      "Iteration 2886, loss = 0.01072284\n",
      "Iteration 2887, loss = 0.01071767\n",
      "Iteration 2888, loss = 0.01071434\n",
      "Iteration 2889, loss = 0.01070863\n",
      "Iteration 2890, loss = 0.01070333\n",
      "Iteration 2891, loss = 0.01069833\n",
      "Iteration 2892, loss = 0.01069561\n",
      "Iteration 2893, loss = 0.01068917\n",
      "Iteration 2894, loss = 0.01068401\n",
      "Iteration 2895, loss = 0.01067903\n",
      "Iteration 2896, loss = 0.01067364\n",
      "Iteration 2897, loss = 0.01066881\n",
      "Iteration 2898, loss = 0.01066359\n",
      "Iteration 2899, loss = 0.01066084\n",
      "Iteration 2900, loss = 0.01065371\n",
      "Iteration 2901, loss = 0.01064883\n",
      "Iteration 2902, loss = 0.01064381\n",
      "Iteration 2903, loss = 0.01063961\n",
      "Iteration 2904, loss = 0.01063539\n",
      "Iteration 2905, loss = 0.01062966\n",
      "Iteration 2906, loss = 0.01062520\n",
      "Iteration 2907, loss = 0.01062166\n",
      "Iteration 2908, loss = 0.01061569\n",
      "Iteration 2909, loss = 0.01061097\n",
      "Iteration 2910, loss = 0.01060619\n",
      "Iteration 2911, loss = 0.01060260\n",
      "Iteration 2912, loss = 0.01059744\n",
      "Iteration 2913, loss = 0.01059201\n",
      "Iteration 2914, loss = 0.01058747\n",
      "Iteration 2915, loss = 0.01058299\n",
      "Iteration 2916, loss = 0.01057903\n",
      "Iteration 2917, loss = 0.01057464\n",
      "Iteration 2918, loss = 0.01057014\n",
      "Iteration 2919, loss = 0.01056481\n",
      "Iteration 2920, loss = 0.01056053\n",
      "Iteration 2921, loss = 0.01055634\n",
      "Iteration 2922, loss = 0.01055117\n",
      "Iteration 2923, loss = 0.01054729\n",
      "Iteration 2924, loss = 0.01054286\n",
      "Iteration 2925, loss = 0.01053773\n",
      "Iteration 2926, loss = 0.01053334\n",
      "Iteration 2927, loss = 0.01052908\n",
      "Iteration 2928, loss = 0.01052368\n",
      "Iteration 2929, loss = 0.01051950\n",
      "Iteration 2930, loss = 0.01051543\n",
      "Iteration 2931, loss = 0.01051063\n",
      "Iteration 2932, loss = 0.01050643\n",
      "Iteration 2933, loss = 0.01050197\n",
      "Iteration 2934, loss = 0.01049940\n",
      "Iteration 2935, loss = 0.01049269\n",
      "Iteration 2936, loss = 0.01048904\n",
      "Iteration 2937, loss = 0.01048463\n",
      "Iteration 2938, loss = 0.01048068\n",
      "Iteration 2939, loss = 0.01047557\n",
      "Iteration 2940, loss = 0.01047244\n",
      "Iteration 2941, loss = 0.01046620\n",
      "Iteration 2942, loss = 0.01046291\n",
      "Iteration 2943, loss = 0.01045820\n",
      "Iteration 2944, loss = 0.01045406\n",
      "Iteration 2945, loss = 0.01044849\n",
      "Iteration 2946, loss = 0.01044341\n",
      "Iteration 2947, loss = 0.01044049\n",
      "Iteration 2948, loss = 0.01043601\n",
      "Iteration 2949, loss = 0.01042948\n",
      "Iteration 2950, loss = 0.01042469\n",
      "Iteration 2951, loss = 0.01041949\n",
      "Iteration 2952, loss = 0.01041604\n",
      "Iteration 2953, loss = 0.01041084\n",
      "Iteration 2954, loss = 0.01040625\n",
      "Iteration 2955, loss = 0.01040165\n",
      "Iteration 2956, loss = 0.01039771\n",
      "Iteration 2957, loss = 0.01039345\n",
      "Iteration 2958, loss = 0.01038912\n",
      "Iteration 2959, loss = 0.01038423\n",
      "Iteration 2960, loss = 0.01037990\n",
      "Iteration 2961, loss = 0.01037637\n",
      "Iteration 2962, loss = 0.01037154\n",
      "Iteration 2963, loss = 0.01036711\n",
      "Iteration 2964, loss = 0.01036298\n",
      "Iteration 2965, loss = 0.01035934\n",
      "Iteration 2966, loss = 0.01035443\n",
      "Iteration 2967, loss = 0.01034985\n",
      "Iteration 2968, loss = 0.01034500\n",
      "Iteration 2969, loss = 0.01034264\n",
      "Iteration 2970, loss = 0.01033637\n",
      "Iteration 2971, loss = 0.01033249\n",
      "Iteration 2972, loss = 0.01032765\n",
      "Iteration 2973, loss = 0.01032406\n",
      "Iteration 2974, loss = 0.01031855\n",
      "Iteration 2975, loss = 0.01031362\n",
      "Iteration 2976, loss = 0.01030949\n",
      "Iteration 2977, loss = 0.01030514\n",
      "Iteration 2978, loss = 0.01030133\n",
      "Iteration 2979, loss = 0.01029726\n",
      "Iteration 2980, loss = 0.01029308\n",
      "Iteration 2981, loss = 0.01028861\n",
      "Iteration 2982, loss = 0.01028456\n",
      "Iteration 2983, loss = 0.01028002\n",
      "Iteration 2984, loss = 0.01027637\n",
      "Iteration 2985, loss = 0.01027199\n",
      "Iteration 2986, loss = 0.01026863\n",
      "Iteration 2987, loss = 0.01026386\n",
      "Iteration 2988, loss = 0.01026101\n",
      "Iteration 2989, loss = 0.01025748\n",
      "Iteration 2990, loss = 0.01025358\n",
      "Iteration 2991, loss = 0.01024987\n",
      "Iteration 2992, loss = 0.01024620\n",
      "Iteration 2993, loss = 0.01024286\n",
      "Iteration 2994, loss = 0.01023926\n",
      "Iteration 2995, loss = 0.01023546\n",
      "Iteration 2996, loss = 0.01023250\n",
      "Iteration 2997, loss = 0.01022895\n",
      "Iteration 2998, loss = 0.01022557\n",
      "Iteration 2999, loss = 0.01022205\n",
      "Iteration 3000, loss = 0.01021864\n",
      "Iteration 3001, loss = 0.01021507\n",
      "Iteration 3002, loss = 0.01021258\n",
      "Iteration 3003, loss = 0.01020783\n",
      "Iteration 3004, loss = 0.01020405\n",
      "Iteration 3005, loss = 0.01020042\n",
      "Iteration 3006, loss = 0.01019603\n",
      "Iteration 3007, loss = 0.01019292\n",
      "Iteration 3008, loss = 0.01018886\n",
      "Iteration 3009, loss = 0.01018504\n",
      "Iteration 3010, loss = 0.01018186\n",
      "Iteration 3011, loss = 0.01017727\n",
      "Iteration 3012, loss = 0.01017269\n",
      "Iteration 3013, loss = 0.01016901\n",
      "Iteration 3014, loss = 0.01016383\n",
      "Iteration 3015, loss = 0.01015985\n",
      "Iteration 3016, loss = 0.01015563\n",
      "Iteration 3017, loss = 0.01014995\n",
      "Iteration 3018, loss = 0.01014449\n",
      "Iteration 3019, loss = 0.01013834\n",
      "Iteration 3020, loss = 0.01013253\n",
      "Iteration 3021, loss = 0.01013069\n",
      "Iteration 3022, loss = 0.01012296\n",
      "Iteration 3023, loss = 0.01011837\n",
      "Iteration 3024, loss = 0.01011346\n",
      "Iteration 3025, loss = 0.01010847\n",
      "Iteration 3026, loss = 0.01010488\n",
      "Iteration 3027, loss = 0.01010077\n",
      "Iteration 3028, loss = 0.01009693\n",
      "Iteration 3029, loss = 0.01009273\n",
      "Iteration 3030, loss = 0.01008863\n",
      "Iteration 3031, loss = 0.01008420\n",
      "Iteration 3032, loss = 0.01008012\n",
      "Iteration 3033, loss = 0.01007624\n",
      "Iteration 3034, loss = 0.01007230\n",
      "Iteration 3035, loss = 0.01006812\n",
      "Iteration 3036, loss = 0.01006461\n",
      "Iteration 3037, loss = 0.01006061\n",
      "Iteration 3038, loss = 0.01005624\n",
      "Iteration 3039, loss = 0.01005189\n",
      "Iteration 3040, loss = 0.01004817\n",
      "Iteration 3041, loss = 0.01004433\n",
      "Iteration 3042, loss = 0.01004035\n",
      "Iteration 3043, loss = 0.01003654\n",
      "Iteration 3044, loss = 0.01003287\n",
      "Iteration 3045, loss = 0.01002902\n",
      "Iteration 3046, loss = 0.01002499\n",
      "Iteration 3047, loss = 0.01002176\n",
      "Iteration 3048, loss = 0.01001702\n",
      "Iteration 3049, loss = 0.01001363\n",
      "Iteration 3050, loss = 0.01001069\n",
      "Iteration 3051, loss = 0.01000423\n",
      "Iteration 3052, loss = 0.00999908\n",
      "Iteration 3053, loss = 0.00999324\n",
      "Iteration 3054, loss = 0.00999141\n",
      "Iteration 3055, loss = 0.00998598\n",
      "Iteration 3056, loss = 0.00998055\n",
      "Iteration 3057, loss = 0.00997759\n",
      "Iteration 3058, loss = 0.00997203\n",
      "Iteration 3059, loss = 0.00996794\n",
      "Iteration 3060, loss = 0.00996452\n",
      "Iteration 3061, loss = 0.00996057\n",
      "Iteration 3062, loss = 0.00995592\n",
      "Iteration 3063, loss = 0.00995199\n",
      "Iteration 3064, loss = 0.00994813\n",
      "Iteration 3065, loss = 0.00994523\n",
      "Iteration 3066, loss = 0.00994050\n",
      "Iteration 3067, loss = 0.00993594\n",
      "Iteration 3068, loss = 0.00993149\n",
      "Iteration 3069, loss = 0.00992872\n",
      "Iteration 3070, loss = 0.00992462\n",
      "Iteration 3071, loss = 0.00991946\n",
      "Iteration 3072, loss = 0.00991615\n",
      "Iteration 3073, loss = 0.00991094\n",
      "Iteration 3074, loss = 0.00990712\n",
      "Iteration 3075, loss = 0.00990317\n",
      "Iteration 3076, loss = 0.00989874\n",
      "Iteration 3077, loss = 0.00989447\n",
      "Iteration 3078, loss = 0.00989070\n",
      "Iteration 3079, loss = 0.00988664\n",
      "Iteration 3080, loss = 0.00988269\n",
      "Iteration 3081, loss = 0.00987878\n",
      "Iteration 3082, loss = 0.00987534\n",
      "Iteration 3083, loss = 0.00987110\n",
      "Iteration 3084, loss = 0.00986758\n",
      "Iteration 3085, loss = 0.00986473\n",
      "Iteration 3086, loss = 0.00985991\n",
      "Iteration 3087, loss = 0.00985605\n",
      "Iteration 3088, loss = 0.00985251\n",
      "Iteration 3089, loss = 0.00984907\n",
      "Iteration 3090, loss = 0.00984490\n",
      "Iteration 3091, loss = 0.00984182\n",
      "Iteration 3092, loss = 0.00983764\n",
      "Iteration 3093, loss = 0.00983432\n",
      "Iteration 3094, loss = 0.00983078\n",
      "Iteration 3095, loss = 0.00982805\n",
      "Iteration 3096, loss = 0.00982361\n",
      "Iteration 3097, loss = 0.00981927\n",
      "Iteration 3098, loss = 0.00981531\n",
      "Iteration 3099, loss = 0.00981055\n",
      "Iteration 3100, loss = 0.00980669\n",
      "Iteration 3101, loss = 0.00980295\n",
      "Iteration 3102, loss = 0.00980077\n",
      "Iteration 3103, loss = 0.00979650\n",
      "Iteration 3104, loss = 0.00979263\n",
      "Iteration 3105, loss = 0.00978798\n",
      "Iteration 3106, loss = 0.00978396\n",
      "Iteration 3107, loss = 0.00978036\n",
      "Iteration 3108, loss = 0.00977657\n",
      "Iteration 3109, loss = 0.00977253\n",
      "Iteration 3110, loss = 0.00976833\n",
      "Iteration 3111, loss = 0.00976508\n",
      "Iteration 3112, loss = 0.00976095\n",
      "Iteration 3113, loss = 0.00975721\n",
      "Iteration 3114, loss = 0.00975389\n",
      "Iteration 3115, loss = 0.00975019\n",
      "Iteration 3116, loss = 0.00974698\n",
      "Iteration 3117, loss = 0.00974269\n",
      "Iteration 3118, loss = 0.00973898\n",
      "Iteration 3119, loss = 0.00973519\n",
      "Iteration 3120, loss = 0.00973149\n",
      "Iteration 3121, loss = 0.00972829\n",
      "Iteration 3122, loss = 0.00972490\n",
      "Iteration 3123, loss = 0.00972119\n",
      "Iteration 3124, loss = 0.00971797\n",
      "Iteration 3125, loss = 0.00971327\n",
      "Iteration 3126, loss = 0.00970954\n",
      "Iteration 3127, loss = 0.00970550\n",
      "Iteration 3128, loss = 0.00970200\n",
      "Iteration 3129, loss = 0.00969782\n",
      "Iteration 3130, loss = 0.00969385\n",
      "Iteration 3131, loss = 0.00968957\n",
      "Iteration 3132, loss = 0.00968459\n",
      "Iteration 3133, loss = 0.00968191\n",
      "Iteration 3134, loss = 0.00967637\n",
      "Iteration 3135, loss = 0.00967301\n",
      "Iteration 3136, loss = 0.00966814\n",
      "Iteration 3137, loss = 0.00966458\n",
      "Iteration 3138, loss = 0.00966066\n",
      "Iteration 3139, loss = 0.00965658\n",
      "Iteration 3140, loss = 0.00965306\n",
      "Iteration 3141, loss = 0.00964991\n",
      "Iteration 3142, loss = 0.00964578\n",
      "Iteration 3143, loss = 0.00964200\n",
      "Iteration 3144, loss = 0.00963937\n",
      "Iteration 3145, loss = 0.00963579\n",
      "Iteration 3146, loss = 0.00963359\n",
      "Iteration 3147, loss = 0.00962970\n",
      "Iteration 3148, loss = 0.00962631\n",
      "Iteration 3149, loss = 0.00962168\n",
      "Iteration 3150, loss = 0.00961846\n",
      "Iteration 3151, loss = 0.00961517\n",
      "Iteration 3152, loss = 0.00961104\n",
      "Iteration 3153, loss = 0.00960749\n",
      "Iteration 3154, loss = 0.00960383\n",
      "Iteration 3155, loss = 0.00960063\n",
      "Iteration 3156, loss = 0.00959709\n",
      "Iteration 3157, loss = 0.00959199\n",
      "Iteration 3158, loss = 0.00958683\n",
      "Iteration 3159, loss = 0.00958414\n",
      "Iteration 3160, loss = 0.00957876\n",
      "Iteration 3161, loss = 0.00957415\n",
      "Iteration 3162, loss = 0.00956954\n",
      "Iteration 3163, loss = 0.00956547\n",
      "Iteration 3164, loss = 0.00956171\n",
      "Iteration 3165, loss = 0.00955863\n",
      "Iteration 3166, loss = 0.00955377\n",
      "Iteration 3167, loss = 0.00955036\n",
      "Iteration 3168, loss = 0.00954597\n",
      "Iteration 3169, loss = 0.00954066\n",
      "Iteration 3170, loss = 0.00953691\n",
      "Iteration 3171, loss = 0.00953295\n",
      "Iteration 3172, loss = 0.00952888\n",
      "Iteration 3173, loss = 0.00952471\n",
      "Iteration 3174, loss = 0.00952055\n",
      "Iteration 3175, loss = 0.00951676\n",
      "Iteration 3176, loss = 0.00951317\n",
      "Iteration 3177, loss = 0.00950957\n",
      "Iteration 3178, loss = 0.00950616\n",
      "Iteration 3179, loss = 0.00950283\n",
      "Iteration 3180, loss = 0.00949959\n",
      "Iteration 3181, loss = 0.00949577\n",
      "Iteration 3182, loss = 0.00949244\n",
      "Iteration 3183, loss = 0.00948851\n",
      "Iteration 3184, loss = 0.00948513\n",
      "Iteration 3185, loss = 0.00948197\n",
      "Iteration 3186, loss = 0.00947776\n",
      "Iteration 3187, loss = 0.00947418\n",
      "Iteration 3188, loss = 0.00947040\n",
      "Iteration 3189, loss = 0.00946738\n",
      "Iteration 3190, loss = 0.00946284\n",
      "Iteration 3191, loss = 0.00945927\n",
      "Iteration 3192, loss = 0.00945491\n",
      "Iteration 3193, loss = 0.00945139\n",
      "Iteration 3194, loss = 0.00944779\n",
      "Iteration 3195, loss = 0.00944410\n",
      "Iteration 3196, loss = 0.00943997\n",
      "Iteration 3197, loss = 0.00943640\n",
      "Iteration 3198, loss = 0.00943258\n",
      "Iteration 3199, loss = 0.00942900\n",
      "Iteration 3200, loss = 0.00942502\n",
      "Iteration 3201, loss = 0.00942169\n",
      "Iteration 3202, loss = 0.00941769\n",
      "Iteration 3203, loss = 0.00941413\n",
      "Iteration 3204, loss = 0.00941296\n",
      "Iteration 3205, loss = 0.00940743\n",
      "Iteration 3206, loss = 0.00940350\n",
      "Iteration 3207, loss = 0.00939961\n",
      "Iteration 3208, loss = 0.00939524\n",
      "Iteration 3209, loss = 0.00939125\n",
      "Iteration 3210, loss = 0.00938737\n",
      "Iteration 3211, loss = 0.00938370\n",
      "Iteration 3212, loss = 0.00937939\n",
      "Iteration 3213, loss = 0.00937657\n",
      "Iteration 3214, loss = 0.00937165\n",
      "Iteration 3215, loss = 0.00936801\n",
      "Iteration 3216, loss = 0.00936540\n",
      "Iteration 3217, loss = 0.00936019\n",
      "Iteration 3218, loss = 0.00935628\n",
      "Iteration 3219, loss = 0.00935240\n",
      "Iteration 3220, loss = 0.00934803\n",
      "Iteration 3221, loss = 0.00934530\n",
      "Iteration 3222, loss = 0.00934174\n",
      "Iteration 3223, loss = 0.00933849\n",
      "Iteration 3224, loss = 0.00933550\n",
      "Iteration 3225, loss = 0.00933177\n",
      "Iteration 3226, loss = 0.00932807\n",
      "Iteration 3227, loss = 0.00932467\n",
      "Iteration 3228, loss = 0.00932108\n",
      "Iteration 3229, loss = 0.00931896\n",
      "Iteration 3230, loss = 0.00931493\n",
      "Iteration 3231, loss = 0.00931219\n",
      "Iteration 3232, loss = 0.00930842\n",
      "Iteration 3233, loss = 0.00930717\n",
      "Iteration 3234, loss = 0.00930176\n",
      "Iteration 3235, loss = 0.00929846\n",
      "Iteration 3236, loss = 0.00929463\n",
      "Iteration 3237, loss = 0.00929144\n",
      "Iteration 3238, loss = 0.00928808\n",
      "Iteration 3239, loss = 0.00928454\n",
      "Iteration 3240, loss = 0.00928161\n",
      "Iteration 3241, loss = 0.00927838\n",
      "Iteration 3242, loss = 0.00927545\n",
      "Iteration 3243, loss = 0.00927286\n",
      "Iteration 3244, loss = 0.00926874\n",
      "Iteration 3245, loss = 0.00926503\n",
      "Iteration 3246, loss = 0.00926106\n",
      "Iteration 3247, loss = 0.00925664\n",
      "Iteration 3248, loss = 0.00925409\n",
      "Iteration 3249, loss = 0.00925009\n",
      "Iteration 3250, loss = 0.00924508\n",
      "Iteration 3251, loss = 0.00924296\n",
      "Iteration 3252, loss = 0.00923758\n",
      "Iteration 3253, loss = 0.00923274\n",
      "Iteration 3254, loss = 0.00922881\n",
      "Iteration 3255, loss = 0.00922518\n",
      "Iteration 3256, loss = 0.00922075\n",
      "Iteration 3257, loss = 0.00921734\n",
      "Iteration 3258, loss = 0.00921268\n",
      "Iteration 3259, loss = 0.00920937\n",
      "Iteration 3260, loss = 0.00920531\n",
      "Iteration 3261, loss = 0.00920208\n",
      "Iteration 3262, loss = 0.00919815\n",
      "Iteration 3263, loss = 0.00919456\n",
      "Iteration 3264, loss = 0.00919074\n",
      "Iteration 3265, loss = 0.00918697\n",
      "Iteration 3266, loss = 0.00918307\n",
      "Iteration 3267, loss = 0.00917961\n",
      "Iteration 3268, loss = 0.00917620\n",
      "Iteration 3269, loss = 0.00917264\n",
      "Iteration 3270, loss = 0.00916906\n",
      "Iteration 3271, loss = 0.00916689\n",
      "Iteration 3272, loss = 0.00916266\n",
      "Iteration 3273, loss = 0.00915921\n",
      "Iteration 3274, loss = 0.00915560\n",
      "Iteration 3275, loss = 0.00915183\n",
      "Iteration 3276, loss = 0.00914860\n",
      "Iteration 3277, loss = 0.00914582\n",
      "Iteration 3278, loss = 0.00914250\n",
      "Iteration 3279, loss = 0.00913902\n",
      "Iteration 3280, loss = 0.00913545\n",
      "Iteration 3281, loss = 0.00913208\n",
      "Iteration 3282, loss = 0.00912808\n",
      "Iteration 3283, loss = 0.00912429\n",
      "Iteration 3284, loss = 0.00912058\n",
      "Iteration 3285, loss = 0.00911705\n",
      "Iteration 3286, loss = 0.00911353\n",
      "Iteration 3287, loss = 0.00911051\n",
      "Iteration 3288, loss = 0.00910664\n",
      "Iteration 3289, loss = 0.00910294\n",
      "Iteration 3290, loss = 0.00909968\n",
      "Iteration 3291, loss = 0.00909654\n",
      "Iteration 3292, loss = 0.00909486\n",
      "Iteration 3293, loss = 0.00908991\n",
      "Iteration 3294, loss = 0.00908628\n",
      "Iteration 3295, loss = 0.00908252\n",
      "Iteration 3296, loss = 0.00907855\n",
      "Iteration 3297, loss = 0.00907490\n",
      "Iteration 3298, loss = 0.00907110\n",
      "Iteration 3299, loss = 0.00906866\n",
      "Iteration 3300, loss = 0.00906326\n",
      "Iteration 3301, loss = 0.00905934\n",
      "Iteration 3302, loss = 0.00905619\n",
      "Iteration 3303, loss = 0.00905155\n",
      "Iteration 3304, loss = 0.00904846\n",
      "Iteration 3305, loss = 0.00904635\n",
      "Iteration 3306, loss = 0.00904094\n",
      "Iteration 3307, loss = 0.00903737\n",
      "Iteration 3308, loss = 0.00903296\n",
      "Iteration 3309, loss = 0.00903007\n",
      "Iteration 3310, loss = 0.00902570\n",
      "Iteration 3311, loss = 0.00902197\n",
      "Iteration 3312, loss = 0.00901943\n",
      "Iteration 3313, loss = 0.00901520\n",
      "Iteration 3314, loss = 0.00901170\n",
      "Iteration 3315, loss = 0.00900792\n",
      "Iteration 3316, loss = 0.00900452\n",
      "Iteration 3317, loss = 0.00900082\n",
      "Iteration 3318, loss = 0.00899736\n",
      "Iteration 3319, loss = 0.00899365\n",
      "Iteration 3320, loss = 0.00899001\n",
      "Iteration 3321, loss = 0.00898694\n",
      "Iteration 3322, loss = 0.00898560\n",
      "Iteration 3323, loss = 0.00898041\n",
      "Iteration 3324, loss = 0.00897663\n",
      "Iteration 3325, loss = 0.00897348\n",
      "Iteration 3326, loss = 0.00896958\n",
      "Iteration 3327, loss = 0.00896586\n",
      "Iteration 3328, loss = 0.00896345\n",
      "Iteration 3329, loss = 0.00895956\n",
      "Iteration 3330, loss = 0.00895540\n",
      "Iteration 3331, loss = 0.00895206\n",
      "Iteration 3332, loss = 0.00894813\n",
      "Iteration 3333, loss = 0.00894461\n",
      "Iteration 3334, loss = 0.00894069\n",
      "Iteration 3335, loss = 0.00893755\n",
      "Iteration 3336, loss = 0.00893363\n",
      "Iteration 3337, loss = 0.00893079\n",
      "Iteration 3338, loss = 0.00892632\n",
      "Iteration 3339, loss = 0.00892404\n",
      "Iteration 3340, loss = 0.00891919\n",
      "Iteration 3341, loss = 0.00891528\n",
      "Iteration 3342, loss = 0.00891273\n",
      "Iteration 3343, loss = 0.00890860\n",
      "Iteration 3344, loss = 0.00890539\n",
      "Iteration 3345, loss = 0.00890137\n",
      "Iteration 3346, loss = 0.00889851\n",
      "Iteration 3347, loss = 0.00889430\n",
      "Iteration 3348, loss = 0.00889110\n",
      "Iteration 3349, loss = 0.00888765\n",
      "Iteration 3350, loss = 0.00888541\n",
      "Iteration 3351, loss = 0.00888192\n",
      "Iteration 3352, loss = 0.00887758\n",
      "Iteration 3353, loss = 0.00887447\n",
      "Iteration 3354, loss = 0.00887146\n",
      "Iteration 3355, loss = 0.00886715\n",
      "Iteration 3356, loss = 0.00886333\n",
      "Iteration 3357, loss = 0.00886047\n",
      "Iteration 3358, loss = 0.00885672\n",
      "Iteration 3359, loss = 0.00885303\n",
      "Iteration 3360, loss = 0.00885026\n",
      "Iteration 3361, loss = 0.00884676\n",
      "Iteration 3362, loss = 0.00884431\n",
      "Iteration 3363, loss = 0.00883848\n",
      "Iteration 3364, loss = 0.00883483\n",
      "Iteration 3365, loss = 0.00883057\n",
      "Iteration 3366, loss = 0.00882824\n",
      "Iteration 3367, loss = 0.00882631\n",
      "Iteration 3368, loss = 0.00882061\n",
      "Iteration 3369, loss = 0.00881838\n",
      "Iteration 3370, loss = 0.00881415\n",
      "Iteration 3371, loss = 0.00881051\n",
      "Iteration 3372, loss = 0.00880721\n",
      "Iteration 3373, loss = 0.00880407\n",
      "Iteration 3374, loss = 0.00880160\n",
      "Iteration 3375, loss = 0.00879762\n",
      "Iteration 3376, loss = 0.00879376\n",
      "Iteration 3377, loss = 0.00878916\n",
      "Iteration 3378, loss = 0.00878579\n",
      "Iteration 3379, loss = 0.00878246\n",
      "Iteration 3380, loss = 0.00877830\n",
      "Iteration 3381, loss = 0.00877521\n",
      "Iteration 3382, loss = 0.00877315\n",
      "Iteration 3383, loss = 0.00876802\n",
      "Iteration 3384, loss = 0.00876470\n",
      "Iteration 3385, loss = 0.00876097\n",
      "Iteration 3386, loss = 0.00875723\n",
      "Iteration 3387, loss = 0.00875394\n",
      "Iteration 3388, loss = 0.00875007\n",
      "Iteration 3389, loss = 0.00874675\n",
      "Iteration 3390, loss = 0.00874249\n",
      "Iteration 3391, loss = 0.00873908\n",
      "Iteration 3392, loss = 0.00873629\n",
      "Iteration 3393, loss = 0.00873210\n",
      "Iteration 3394, loss = 0.00872827\n",
      "Iteration 3395, loss = 0.00872535\n",
      "Iteration 3396, loss = 0.00872277\n",
      "Iteration 3397, loss = 0.00871934\n",
      "Iteration 3398, loss = 0.00871612\n",
      "Iteration 3399, loss = 0.00871291\n",
      "Iteration 3400, loss = 0.00870968\n",
      "Iteration 3401, loss = 0.00870604\n",
      "Iteration 3402, loss = 0.00870316\n",
      "Iteration 3403, loss = 0.00869914\n",
      "Iteration 3404, loss = 0.00869586\n",
      "Iteration 3405, loss = 0.00869314\n",
      "Iteration 3406, loss = 0.00868895\n",
      "Iteration 3407, loss = 0.00868544\n",
      "Iteration 3408, loss = 0.00868190\n",
      "Iteration 3409, loss = 0.00867876\n",
      "Iteration 3410, loss = 0.00867555\n",
      "Iteration 3411, loss = 0.00867181\n",
      "Iteration 3412, loss = 0.00866835\n",
      "Iteration 3413, loss = 0.00866513\n",
      "Iteration 3414, loss = 0.00866271\n",
      "Iteration 3415, loss = 0.00865888\n",
      "Iteration 3416, loss = 0.00865622\n",
      "Iteration 3417, loss = 0.00865288\n",
      "Iteration 3418, loss = 0.00864976\n",
      "Iteration 3419, loss = 0.00864627\n",
      "Iteration 3420, loss = 0.00864309\n",
      "Iteration 3421, loss = 0.00864020\n",
      "Iteration 3422, loss = 0.00863710\n",
      "Iteration 3423, loss = 0.00863351\n",
      "Iteration 3424, loss = 0.00863030\n",
      "Iteration 3425, loss = 0.00862749\n",
      "Iteration 3426, loss = 0.00862417\n",
      "Iteration 3427, loss = 0.00862187\n",
      "Iteration 3428, loss = 0.00861731\n",
      "Iteration 3429, loss = 0.00861527\n",
      "Iteration 3430, loss = 0.00861050\n",
      "Iteration 3431, loss = 0.00860696\n",
      "Iteration 3432, loss = 0.00860395\n",
      "Iteration 3433, loss = 0.00860072\n",
      "Iteration 3434, loss = 0.00859728\n",
      "Iteration 3435, loss = 0.00859418\n",
      "Iteration 3436, loss = 0.00859105\n",
      "Iteration 3437, loss = 0.00858839\n",
      "Iteration 3438, loss = 0.00858468\n",
      "Iteration 3439, loss = 0.00858109\n",
      "Iteration 3440, loss = 0.00857793\n",
      "Iteration 3441, loss = 0.00857480\n",
      "Iteration 3442, loss = 0.00857171\n",
      "Iteration 3443, loss = 0.00856856\n",
      "Iteration 3444, loss = 0.00856592\n",
      "Iteration 3445, loss = 0.00856271\n",
      "Iteration 3446, loss = 0.00855947\n",
      "Iteration 3447, loss = 0.00855628\n",
      "Iteration 3448, loss = 0.00855313\n",
      "Iteration 3449, loss = 0.00855010\n",
      "Iteration 3450, loss = 0.00854703\n",
      "Iteration 3451, loss = 0.00854537\n",
      "Iteration 3452, loss = 0.00854074\n",
      "Iteration 3453, loss = 0.00853670\n",
      "Iteration 3454, loss = 0.00853530\n",
      "Iteration 3455, loss = 0.00853167\n",
      "Iteration 3456, loss = 0.00852923\n",
      "Iteration 3457, loss = 0.00852512\n",
      "Iteration 3458, loss = 0.00852231\n",
      "Iteration 3459, loss = 0.00851900\n",
      "Iteration 3460, loss = 0.00851575\n",
      "Iteration 3461, loss = 0.00851276\n",
      "Iteration 3462, loss = 0.00850978\n",
      "Iteration 3463, loss = 0.00850640\n",
      "Iteration 3464, loss = 0.00850290\n",
      "Iteration 3465, loss = 0.00850088\n",
      "Iteration 3466, loss = 0.00849639\n",
      "Iteration 3467, loss = 0.00849302\n",
      "Iteration 3468, loss = 0.00848985\n",
      "Iteration 3469, loss = 0.00848705\n",
      "Iteration 3470, loss = 0.00848377\n",
      "Iteration 3471, loss = 0.00848044\n",
      "Iteration 3472, loss = 0.00847738\n",
      "Iteration 3473, loss = 0.00847387\n",
      "Iteration 3474, loss = 0.00847057\n",
      "Iteration 3475, loss = 0.00846740\n",
      "Iteration 3476, loss = 0.00846357\n",
      "Iteration 3477, loss = 0.00846081\n",
      "Iteration 3478, loss = 0.00845798\n",
      "Iteration 3479, loss = 0.00845422\n",
      "Iteration 3480, loss = 0.00845165\n",
      "Iteration 3481, loss = 0.00844810\n",
      "Iteration 3482, loss = 0.00844590\n",
      "Iteration 3483, loss = 0.00844226\n",
      "Iteration 3484, loss = 0.00844044\n",
      "Iteration 3485, loss = 0.00843665\n",
      "Iteration 3486, loss = 0.00843388\n",
      "Iteration 3487, loss = 0.00843055\n",
      "Iteration 3488, loss = 0.00842713\n",
      "Iteration 3489, loss = 0.00842502\n",
      "Iteration 3490, loss = 0.00842075\n",
      "Iteration 3491, loss = 0.00841732\n",
      "Iteration 3492, loss = 0.00841502\n",
      "Iteration 3493, loss = 0.00841139\n",
      "Iteration 3494, loss = 0.00840809\n",
      "Iteration 3495, loss = 0.00840552\n",
      "Iteration 3496, loss = 0.00840186\n",
      "Iteration 3497, loss = 0.00839860\n",
      "Iteration 3498, loss = 0.00839595\n",
      "Iteration 3499, loss = 0.00839291\n",
      "Iteration 3500, loss = 0.00838943\n",
      "Iteration 3501, loss = 0.00838604\n",
      "Iteration 3502, loss = 0.00838319\n",
      "Iteration 3503, loss = 0.00837981\n",
      "Iteration 3504, loss = 0.00837660\n",
      "Iteration 3505, loss = 0.00837319\n",
      "Iteration 3506, loss = 0.00836992\n",
      "Iteration 3507, loss = 0.00836875\n",
      "Iteration 3508, loss = 0.00836372\n",
      "Iteration 3509, loss = 0.00836150\n",
      "Iteration 3510, loss = 0.00835746\n",
      "Iteration 3511, loss = 0.00835354\n",
      "Iteration 3512, loss = 0.00835108\n",
      "Iteration 3513, loss = 0.00834673\n",
      "Iteration 3514, loss = 0.00834404\n",
      "Iteration 3515, loss = 0.00834009\n",
      "Iteration 3516, loss = 0.00833667\n",
      "Iteration 3517, loss = 0.00833483\n",
      "Iteration 3518, loss = 0.00833058\n",
      "Iteration 3519, loss = 0.00832729\n",
      "Iteration 3520, loss = 0.00832411\n",
      "Iteration 3521, loss = 0.00832084\n",
      "Iteration 3522, loss = 0.00831849\n",
      "Iteration 3523, loss = 0.00831425\n",
      "Iteration 3524, loss = 0.00831085\n",
      "Iteration 3525, loss = 0.00830724\n",
      "Iteration 3526, loss = 0.00830585\n",
      "Iteration 3527, loss = 0.00830093\n",
      "Iteration 3528, loss = 0.00829764\n",
      "Iteration 3529, loss = 0.00829421\n",
      "Iteration 3530, loss = 0.00829066\n",
      "Iteration 3531, loss = 0.00828779\n",
      "Iteration 3532, loss = 0.00828393\n",
      "Iteration 3533, loss = 0.00828125\n",
      "Iteration 3534, loss = 0.00827774\n",
      "Iteration 3535, loss = 0.00827451\n",
      "Iteration 3536, loss = 0.00827110\n",
      "Iteration 3537, loss = 0.00826834\n",
      "Iteration 3538, loss = 0.00826501\n",
      "Iteration 3539, loss = 0.00826219\n",
      "Iteration 3540, loss = 0.00825908\n",
      "Iteration 3541, loss = 0.00825591\n",
      "Iteration 3542, loss = 0.00825268\n",
      "Iteration 3543, loss = 0.00824985\n",
      "Iteration 3544, loss = 0.00824690\n",
      "Iteration 3545, loss = 0.00824474\n",
      "Iteration 3546, loss = 0.00824165\n",
      "Iteration 3547, loss = 0.00823868\n",
      "Iteration 3548, loss = 0.00823559\n",
      "Iteration 3549, loss = 0.00823200\n",
      "Iteration 3550, loss = 0.00822898\n",
      "Iteration 3551, loss = 0.00822565\n",
      "Iteration 3552, loss = 0.00822380\n",
      "Iteration 3553, loss = 0.00821968\n",
      "Iteration 3554, loss = 0.00821634\n",
      "Iteration 3555, loss = 0.00821340\n",
      "Iteration 3556, loss = 0.00820982\n",
      "Iteration 3557, loss = 0.00820666\n",
      "Iteration 3558, loss = 0.00820353\n",
      "Iteration 3559, loss = 0.00820060\n",
      "Iteration 3560, loss = 0.00819754\n",
      "Iteration 3561, loss = 0.00819456\n",
      "Iteration 3562, loss = 0.00819138\n",
      "Iteration 3563, loss = 0.00818853\n",
      "Iteration 3564, loss = 0.00818574\n",
      "Iteration 3565, loss = 0.00818283\n",
      "Iteration 3566, loss = 0.00817994\n",
      "Iteration 3567, loss = 0.00817829\n",
      "Iteration 3568, loss = 0.00817426\n",
      "Iteration 3569, loss = 0.00817110\n",
      "Iteration 3570, loss = 0.00816771\n",
      "Iteration 3571, loss = 0.00816534\n",
      "Iteration 3572, loss = 0.00816160\n",
      "Iteration 3573, loss = 0.00815840\n",
      "Iteration 3574, loss = 0.00815427\n",
      "Iteration 3575, loss = 0.00815164\n",
      "Iteration 3576, loss = 0.00814855\n",
      "Iteration 3577, loss = 0.00814431\n",
      "Iteration 3578, loss = 0.00814101\n",
      "Iteration 3579, loss = 0.00813776\n",
      "Iteration 3580, loss = 0.00813626\n",
      "Iteration 3581, loss = 0.00813196\n",
      "Iteration 3582, loss = 0.00812888\n",
      "Iteration 3583, loss = 0.00812621\n",
      "Iteration 3584, loss = 0.00812297\n",
      "Iteration 3585, loss = 0.00812019\n",
      "Iteration 3586, loss = 0.00811677\n",
      "Iteration 3587, loss = 0.00811395\n",
      "Iteration 3588, loss = 0.00811101\n",
      "Iteration 3589, loss = 0.00810813\n",
      "Iteration 3590, loss = 0.00810452\n",
      "Iteration 3591, loss = 0.00810182\n",
      "Iteration 3592, loss = 0.00809863\n",
      "Iteration 3593, loss = 0.00809593\n",
      "Iteration 3594, loss = 0.00809363\n",
      "Iteration 3595, loss = 0.00809040\n",
      "Iteration 3596, loss = 0.00808643\n",
      "Iteration 3597, loss = 0.00808442\n",
      "Iteration 3598, loss = 0.00808076\n",
      "Iteration 3599, loss = 0.00807793\n",
      "Iteration 3600, loss = 0.00807485\n",
      "Iteration 3601, loss = 0.00807190\n",
      "Iteration 3602, loss = 0.00806942\n",
      "Iteration 3603, loss = 0.00806665\n",
      "Iteration 3604, loss = 0.00806429\n",
      "Iteration 3605, loss = 0.00806111\n",
      "Iteration 3606, loss = 0.00805804\n",
      "Iteration 3607, loss = 0.00805595\n",
      "Iteration 3608, loss = 0.00805303\n",
      "Iteration 3609, loss = 0.00804963\n",
      "Iteration 3610, loss = 0.00804684\n",
      "Iteration 3611, loss = 0.00804435\n",
      "Iteration 3612, loss = 0.00804197\n",
      "Iteration 3613, loss = 0.00803904\n",
      "Iteration 3614, loss = 0.00803655\n",
      "Iteration 3615, loss = 0.00803403\n",
      "Iteration 3616, loss = 0.00803142\n",
      "Iteration 3617, loss = 0.00802889\n",
      "Iteration 3618, loss = 0.00802699\n",
      "Iteration 3619, loss = 0.00802357\n",
      "Iteration 3620, loss = 0.00802086\n",
      "Iteration 3621, loss = 0.00801855\n",
      "Iteration 3622, loss = 0.00801597\n",
      "Iteration 3623, loss = 0.00801382\n",
      "Iteration 3624, loss = 0.00800997\n",
      "Iteration 3625, loss = 0.00800754\n",
      "Iteration 3626, loss = 0.00800433\n",
      "Iteration 3627, loss = 0.00800181\n",
      "Iteration 3628, loss = 0.00799878\n",
      "Iteration 3629, loss = 0.00799593\n",
      "Iteration 3630, loss = 0.00799299\n",
      "Iteration 3631, loss = 0.00799060\n",
      "Iteration 3632, loss = 0.00798771\n",
      "Iteration 3633, loss = 0.00798535\n",
      "Iteration 3634, loss = 0.00798287\n",
      "Iteration 3635, loss = 0.00798046\n",
      "Iteration 3636, loss = 0.00797834\n",
      "Iteration 3637, loss = 0.00797563\n",
      "Iteration 3638, loss = 0.00797286\n",
      "Iteration 3639, loss = 0.00797077\n",
      "Iteration 3640, loss = 0.00796794\n",
      "Iteration 3641, loss = 0.00796498\n",
      "Iteration 3642, loss = 0.00796202\n",
      "Iteration 3643, loss = 0.00795904\n",
      "Iteration 3644, loss = 0.00795574\n",
      "Iteration 3645, loss = 0.00795360\n",
      "Iteration 3646, loss = 0.00794995\n",
      "Iteration 3647, loss = 0.00794695\n",
      "Iteration 3648, loss = 0.00794440\n",
      "Iteration 3649, loss = 0.00794191\n",
      "Iteration 3650, loss = 0.00793859\n",
      "Iteration 3651, loss = 0.00793706\n",
      "Iteration 3652, loss = 0.00793279\n",
      "Iteration 3653, loss = 0.00792959\n",
      "Iteration 3654, loss = 0.00792674\n",
      "Iteration 3655, loss = 0.00792322\n",
      "Iteration 3656, loss = 0.00792025\n",
      "Iteration 3657, loss = 0.00791778\n",
      "Iteration 3658, loss = 0.00791448\n",
      "Iteration 3659, loss = 0.00791193\n",
      "Iteration 3660, loss = 0.00790881\n",
      "Iteration 3661, loss = 0.00790655\n",
      "Iteration 3662, loss = 0.00790253\n",
      "Iteration 3663, loss = 0.00790004\n",
      "Iteration 3664, loss = 0.00789675\n",
      "Iteration 3665, loss = 0.00789391\n",
      "Iteration 3666, loss = 0.00789158\n",
      "Iteration 3667, loss = 0.00788857\n",
      "Iteration 3668, loss = 0.00788704\n",
      "Iteration 3669, loss = 0.00788434\n",
      "Iteration 3670, loss = 0.00788137\n",
      "Iteration 3671, loss = 0.00787877\n",
      "Iteration 3672, loss = 0.00787623\n",
      "Iteration 3673, loss = 0.00787374\n",
      "Iteration 3674, loss = 0.00787150\n",
      "Iteration 3675, loss = 0.00786923\n",
      "Iteration 3676, loss = 0.00786633\n",
      "Iteration 3677, loss = 0.00786377\n",
      "Iteration 3678, loss = 0.00786143\n",
      "Iteration 3679, loss = 0.00785911\n",
      "Iteration 3680, loss = 0.00785669\n",
      "Iteration 3681, loss = 0.00785421\n",
      "Iteration 3682, loss = 0.00785205\n",
      "Iteration 3683, loss = 0.00785003\n",
      "Iteration 3684, loss = 0.00784684\n",
      "Iteration 3685, loss = 0.00784411\n",
      "Iteration 3686, loss = 0.00784100\n",
      "Iteration 3687, loss = 0.00783832\n",
      "Iteration 3688, loss = 0.00783547\n",
      "Iteration 3689, loss = 0.00783322\n",
      "Iteration 3690, loss = 0.00783041\n",
      "Iteration 3691, loss = 0.00782798\n",
      "Iteration 3692, loss = 0.00782547\n",
      "Iteration 3693, loss = 0.00782371\n",
      "Iteration 3694, loss = 0.00782156\n",
      "Iteration 3695, loss = 0.00782028\n",
      "Iteration 3696, loss = 0.00781757\n",
      "Iteration 3697, loss = 0.00781552\n",
      "Iteration 3698, loss = 0.00781359\n",
      "Iteration 3699, loss = 0.00781034\n",
      "Iteration 3700, loss = 0.00780761\n",
      "Iteration 3701, loss = 0.00780508\n",
      "Iteration 3702, loss = 0.00780264\n",
      "Iteration 3703, loss = 0.00780050\n",
      "Iteration 3704, loss = 0.00779753\n",
      "Iteration 3705, loss = 0.00779328\n",
      "Iteration 3706, loss = 0.00779047\n",
      "Iteration 3707, loss = 0.00778782\n",
      "Iteration 3708, loss = 0.00778511\n",
      "Iteration 3709, loss = 0.00778244\n",
      "Iteration 3710, loss = 0.00777985\n",
      "Iteration 3711, loss = 0.00777768\n",
      "Iteration 3712, loss = 0.00777498\n",
      "Iteration 3713, loss = 0.00777257\n",
      "Iteration 3714, loss = 0.00777026\n",
      "Iteration 3715, loss = 0.00776754\n",
      "Iteration 3716, loss = 0.00776585\n",
      "Iteration 3717, loss = 0.00776321\n",
      "Iteration 3718, loss = 0.00776039\n",
      "Iteration 3719, loss = 0.00775829\n",
      "Iteration 3720, loss = 0.00775522\n",
      "Iteration 3721, loss = 0.00775332\n",
      "Iteration 3722, loss = 0.00775088\n",
      "Iteration 3723, loss = 0.00774731\n",
      "Iteration 3724, loss = 0.00774455\n",
      "Iteration 3725, loss = 0.00774205\n",
      "Iteration 3726, loss = 0.00773902\n",
      "Iteration 3727, loss = 0.00773643\n",
      "Iteration 3728, loss = 0.00773375\n",
      "Iteration 3729, loss = 0.00773167\n",
      "Iteration 3730, loss = 0.00772837\n",
      "Iteration 3731, loss = 0.00772484\n",
      "Iteration 3732, loss = 0.00772191\n",
      "Iteration 3733, loss = 0.00771880\n",
      "Iteration 3734, loss = 0.00771609\n",
      "Iteration 3735, loss = 0.00771298\n",
      "Iteration 3736, loss = 0.00770985\n",
      "Iteration 3737, loss = 0.00770596\n",
      "Iteration 3738, loss = 0.00770314\n",
      "Iteration 3739, loss = 0.00769953\n",
      "Iteration 3740, loss = 0.00769592\n",
      "Iteration 3741, loss = 0.00769341\n",
      "Iteration 3742, loss = 0.00768966\n",
      "Iteration 3743, loss = 0.00768707\n",
      "Iteration 3744, loss = 0.00768378\n",
      "Iteration 3745, loss = 0.00768032\n",
      "Iteration 3746, loss = 0.00767795\n",
      "Iteration 3747, loss = 0.00767477\n",
      "Iteration 3748, loss = 0.00767247\n",
      "Iteration 3749, loss = 0.00766976\n",
      "Iteration 3750, loss = 0.00766753\n",
      "Iteration 3751, loss = 0.00766517\n",
      "Iteration 3752, loss = 0.00766279\n",
      "Iteration 3753, loss = 0.00766143\n",
      "Iteration 3754, loss = 0.00765787\n",
      "Iteration 3755, loss = 0.00765440\n",
      "Iteration 3756, loss = 0.00765196\n",
      "Iteration 3757, loss = 0.00764851\n",
      "Iteration 3758, loss = 0.00764603\n",
      "Iteration 3759, loss = 0.00764280\n",
      "Iteration 3760, loss = 0.00763951\n",
      "Iteration 3761, loss = 0.00763602\n",
      "Iteration 3762, loss = 0.00763366\n",
      "Iteration 3763, loss = 0.00763079\n",
      "Iteration 3764, loss = 0.00762712\n",
      "Iteration 3765, loss = 0.00762520\n",
      "Iteration 3766, loss = 0.00762178\n",
      "Iteration 3767, loss = 0.00761936\n",
      "Iteration 3768, loss = 0.00761642\n",
      "Iteration 3769, loss = 0.00761375\n",
      "Iteration 3770, loss = 0.00761117\n",
      "Iteration 3771, loss = 0.00760838\n",
      "Iteration 3772, loss = 0.00760600\n",
      "Iteration 3773, loss = 0.00760359\n",
      "Iteration 3774, loss = 0.00760023\n",
      "Iteration 3775, loss = 0.00759770\n",
      "Iteration 3776, loss = 0.00759507\n",
      "Iteration 3777, loss = 0.00759264\n",
      "Iteration 3778, loss = 0.00758947\n",
      "Iteration 3779, loss = 0.00758695\n",
      "Iteration 3780, loss = 0.00758427\n",
      "Iteration 3781, loss = 0.00758162\n",
      "Iteration 3782, loss = 0.00757915\n",
      "Iteration 3783, loss = 0.00757651\n",
      "Iteration 3784, loss = 0.00757403\n",
      "Iteration 3785, loss = 0.00757153\n",
      "Iteration 3786, loss = 0.00756875\n",
      "Iteration 3787, loss = 0.00756651\n",
      "Iteration 3788, loss = 0.00756443\n",
      "Iteration 3789, loss = 0.00756188\n",
      "Iteration 3790, loss = 0.00755881\n",
      "Iteration 3791, loss = 0.00755651\n",
      "Iteration 3792, loss = 0.00755377\n",
      "Iteration 3793, loss = 0.00755137\n",
      "Iteration 3794, loss = 0.00754887\n",
      "Iteration 3795, loss = 0.00754663\n",
      "Iteration 3796, loss = 0.00754442\n",
      "Iteration 3797, loss = 0.00754184\n",
      "Iteration 3798, loss = 0.00753953\n",
      "Iteration 3799, loss = 0.00753719\n",
      "Iteration 3800, loss = 0.00753459\n",
      "Iteration 3801, loss = 0.00753172\n",
      "Iteration 3802, loss = 0.00752984\n",
      "Iteration 3803, loss = 0.00752690\n",
      "Iteration 3804, loss = 0.00752447\n",
      "Iteration 3805, loss = 0.00752176\n",
      "Iteration 3806, loss = 0.00751888\n",
      "Iteration 3807, loss = 0.00751657\n",
      "Iteration 3808, loss = 0.00751506\n",
      "Iteration 3809, loss = 0.00751164\n",
      "Iteration 3810, loss = 0.00750923\n",
      "Iteration 3811, loss = 0.00750641\n",
      "Iteration 3812, loss = 0.00750455\n",
      "Iteration 3813, loss = 0.00750168\n",
      "Iteration 3814, loss = 0.00749901\n",
      "Iteration 3815, loss = 0.00749689\n",
      "Iteration 3816, loss = 0.00749454\n",
      "Iteration 3817, loss = 0.00749194\n",
      "Iteration 3818, loss = 0.00748936\n",
      "Iteration 3819, loss = 0.00748696\n",
      "Iteration 3820, loss = 0.00748416\n",
      "Iteration 3821, loss = 0.00748159\n",
      "Iteration 3822, loss = 0.00747868\n",
      "Iteration 3823, loss = 0.00747675\n",
      "Iteration 3824, loss = 0.00747350\n",
      "Iteration 3825, loss = 0.00747142\n",
      "Iteration 3826, loss = 0.00746941\n",
      "Iteration 3827, loss = 0.00746665\n",
      "Iteration 3828, loss = 0.00746409\n",
      "Iteration 3829, loss = 0.00746178\n",
      "Iteration 3830, loss = 0.00745977\n",
      "Iteration 3831, loss = 0.00745815\n",
      "Iteration 3832, loss = 0.00745587\n",
      "Iteration 3833, loss = 0.00745291\n",
      "Iteration 3834, loss = 0.00745082\n",
      "Iteration 3835, loss = 0.00744824\n",
      "Iteration 3836, loss = 0.00744547\n",
      "Iteration 3837, loss = 0.00744285\n",
      "Iteration 3838, loss = 0.00744002\n",
      "Iteration 3839, loss = 0.00743792\n",
      "Iteration 3840, loss = 0.00743499\n",
      "Iteration 3841, loss = 0.00743255\n",
      "Iteration 3842, loss = 0.00742989\n",
      "Iteration 3843, loss = 0.00742736\n",
      "Iteration 3844, loss = 0.00742494\n",
      "Iteration 3845, loss = 0.00742222\n",
      "Iteration 3846, loss = 0.00741943\n",
      "Iteration 3847, loss = 0.00741689\n",
      "Iteration 3848, loss = 0.00741449\n",
      "Iteration 3849, loss = 0.00741172\n",
      "Iteration 3850, loss = 0.00740924\n",
      "Iteration 3851, loss = 0.00740711\n",
      "Iteration 3852, loss = 0.00740462\n",
      "Iteration 3853, loss = 0.00740288\n",
      "Iteration 3854, loss = 0.00740042\n",
      "Iteration 3855, loss = 0.00739783\n",
      "Iteration 3856, loss = 0.00739560\n",
      "Iteration 3857, loss = 0.00739340\n",
      "Iteration 3858, loss = 0.00739095\n",
      "Iteration 3859, loss = 0.00738834\n",
      "Iteration 3860, loss = 0.00738587\n",
      "Iteration 3861, loss = 0.00738377\n",
      "Iteration 3862, loss = 0.00738123\n",
      "Iteration 3863, loss = 0.00737889\n",
      "Iteration 3864, loss = 0.00737656\n",
      "Iteration 3865, loss = 0.00737654\n",
      "Iteration 3866, loss = 0.00737210\n",
      "Iteration 3867, loss = 0.00736919\n",
      "Iteration 3868, loss = 0.00736690\n",
      "Iteration 3869, loss = 0.00736435\n",
      "Iteration 3870, loss = 0.00736200\n",
      "Iteration 3871, loss = 0.00735990\n",
      "Iteration 3872, loss = 0.00735749\n",
      "Iteration 3873, loss = 0.00735484\n",
      "Iteration 3874, loss = 0.00735220\n",
      "Iteration 3875, loss = 0.00734964\n",
      "Iteration 3876, loss = 0.00734733\n",
      "Iteration 3877, loss = 0.00734444\n",
      "Iteration 3878, loss = 0.00734217\n",
      "Iteration 3879, loss = 0.00733970\n",
      "Iteration 3880, loss = 0.00733754\n",
      "Iteration 3881, loss = 0.00733442\n",
      "Iteration 3882, loss = 0.00733288\n",
      "Iteration 3883, loss = 0.00732975\n",
      "Iteration 3884, loss = 0.00732694\n",
      "Iteration 3885, loss = 0.00732496\n",
      "Iteration 3886, loss = 0.00732205\n",
      "Iteration 3887, loss = 0.00731956\n",
      "Iteration 3888, loss = 0.00731721\n",
      "Iteration 3889, loss = 0.00731500\n",
      "Iteration 3890, loss = 0.00731266\n",
      "Iteration 3891, loss = 0.00731021\n",
      "Iteration 3892, loss = 0.00730841\n",
      "Iteration 3893, loss = 0.00730621\n",
      "Iteration 3894, loss = 0.00730370\n",
      "Iteration 3895, loss = 0.00730158\n",
      "Iteration 3896, loss = 0.00729930\n",
      "Iteration 3897, loss = 0.00729639\n",
      "Iteration 3898, loss = 0.00729334\n",
      "Iteration 3899, loss = 0.00729090\n",
      "Iteration 3900, loss = 0.00728903\n",
      "Iteration 3901, loss = 0.00728573\n",
      "Iteration 3902, loss = 0.00728329\n",
      "Iteration 3903, loss = 0.00728150\n",
      "Iteration 3904, loss = 0.00727853\n",
      "Iteration 3905, loss = 0.00727626\n",
      "Iteration 3906, loss = 0.00727350\n",
      "Iteration 3907, loss = 0.00727123\n",
      "Iteration 3908, loss = 0.00726907\n",
      "Iteration 3909, loss = 0.00726643\n",
      "Iteration 3910, loss = 0.00726363\n",
      "Iteration 3911, loss = 0.00726126\n",
      "Iteration 3912, loss = 0.00725943\n",
      "Iteration 3913, loss = 0.00725600\n",
      "Iteration 3914, loss = 0.00725439\n",
      "Iteration 3915, loss = 0.00725078\n",
      "Iteration 3916, loss = 0.00724811\n",
      "Iteration 3917, loss = 0.00724496\n",
      "Iteration 3918, loss = 0.00724292\n",
      "Iteration 3919, loss = 0.00724031\n",
      "Iteration 3920, loss = 0.00723757\n",
      "Iteration 3921, loss = 0.00723589\n",
      "Iteration 3922, loss = 0.00723332\n",
      "Iteration 3923, loss = 0.00723099\n",
      "Iteration 3924, loss = 0.00722874\n",
      "Iteration 3925, loss = 0.00722550\n",
      "Iteration 3926, loss = 0.00722327\n",
      "Iteration 3927, loss = 0.00722021\n",
      "Iteration 3928, loss = 0.00721740\n",
      "Iteration 3929, loss = 0.00721447\n",
      "Iteration 3930, loss = 0.00721224\n",
      "Iteration 3931, loss = 0.00720921\n",
      "Iteration 3932, loss = 0.00720608\n",
      "Iteration 3933, loss = 0.00720512\n",
      "Iteration 3934, loss = 0.00720219\n",
      "Iteration 3935, loss = 0.00719973\n",
      "Iteration 3936, loss = 0.00719717\n",
      "Iteration 3937, loss = 0.00719417\n",
      "Iteration 3938, loss = 0.00719147\n",
      "Iteration 3939, loss = 0.00718874\n",
      "Iteration 3940, loss = 0.00718691\n",
      "Iteration 3941, loss = 0.00718377\n",
      "Iteration 3942, loss = 0.00718087\n",
      "Iteration 3943, loss = 0.00717862\n",
      "Iteration 3944, loss = 0.00717575\n",
      "Iteration 3945, loss = 0.00717314\n",
      "Iteration 3946, loss = 0.00717077\n",
      "Iteration 3947, loss = 0.00716855\n",
      "Iteration 3948, loss = 0.00716636\n",
      "Iteration 3949, loss = 0.00716387\n",
      "Iteration 3950, loss = 0.00716177\n",
      "Iteration 3951, loss = 0.00715939\n",
      "Iteration 3952, loss = 0.00715704\n",
      "Iteration 3953, loss = 0.00715522\n",
      "Iteration 3954, loss = 0.00715259\n",
      "Iteration 3955, loss = 0.00715003\n",
      "Iteration 3956, loss = 0.00714731\n",
      "Iteration 3957, loss = 0.00714571\n",
      "Iteration 3958, loss = 0.00714353\n",
      "Iteration 3959, loss = 0.00714119\n",
      "Iteration 3960, loss = 0.00714010\n",
      "Iteration 3961, loss = 0.00713729\n",
      "Iteration 3962, loss = 0.00713469\n",
      "Iteration 3963, loss = 0.00713363\n",
      "Iteration 3964, loss = 0.00713011\n",
      "Iteration 3965, loss = 0.00712743\n",
      "Iteration 3966, loss = 0.00712582\n",
      "Iteration 3967, loss = 0.00712348\n",
      "Iteration 3968, loss = 0.00712044\n",
      "Iteration 3969, loss = 0.00711807\n",
      "Iteration 3970, loss = 0.00711529\n",
      "Iteration 3971, loss = 0.00711303\n",
      "Iteration 3972, loss = 0.00711039\n",
      "Iteration 3973, loss = 0.00710764\n",
      "Iteration 3974, loss = 0.00710409\n",
      "Iteration 3975, loss = 0.00710210\n",
      "Iteration 3976, loss = 0.00710077\n",
      "Iteration 3977, loss = 0.00709695\n",
      "Iteration 3978, loss = 0.00709476\n",
      "Iteration 3979, loss = 0.00709279\n",
      "Iteration 3980, loss = 0.00709004\n",
      "Iteration 3981, loss = 0.00708807\n",
      "Iteration 3982, loss = 0.00708562\n",
      "Iteration 3983, loss = 0.00708397\n",
      "Iteration 3984, loss = 0.00708122\n",
      "Iteration 3985, loss = 0.00707938\n",
      "Iteration 3986, loss = 0.00707627\n",
      "Iteration 3987, loss = 0.00707399\n",
      "Iteration 3988, loss = 0.00707175\n",
      "Iteration 3989, loss = 0.00706918\n",
      "Iteration 3990, loss = 0.00706683\n",
      "Iteration 3991, loss = 0.00706454\n",
      "Iteration 3992, loss = 0.00706236\n",
      "Iteration 3993, loss = 0.00705950\n",
      "Iteration 3994, loss = 0.00705705\n",
      "Iteration 3995, loss = 0.00705479\n",
      "Iteration 3996, loss = 0.00705249\n",
      "Iteration 3997, loss = 0.00705027\n",
      "Iteration 3998, loss = 0.00704785\n",
      "Iteration 3999, loss = 0.00704557\n",
      "Iteration 4000, loss = 0.00704348\n",
      "Iteration 4001, loss = 0.00704086\n",
      "Iteration 4002, loss = 0.00703859\n",
      "Iteration 4003, loss = 0.00703606\n",
      "Iteration 4004, loss = 0.00703383\n",
      "Iteration 4005, loss = 0.00703187\n",
      "Iteration 4006, loss = 0.00702936\n",
      "Iteration 4007, loss = 0.00702698\n",
      "Iteration 4008, loss = 0.00702438\n",
      "Iteration 4009, loss = 0.00702201\n",
      "Iteration 4010, loss = 0.00701977\n",
      "Iteration 4011, loss = 0.00701703\n",
      "Iteration 4012, loss = 0.00701409\n",
      "Iteration 4013, loss = 0.00701198\n",
      "Iteration 4014, loss = 0.00700918\n",
      "Iteration 4015, loss = 0.00700685\n",
      "Iteration 4016, loss = 0.00700390\n",
      "Iteration 4017, loss = 0.00700216\n",
      "Iteration 4018, loss = 0.00699941\n",
      "Iteration 4019, loss = 0.00699699\n",
      "Iteration 4020, loss = 0.00699461\n",
      "Iteration 4021, loss = 0.00699240\n",
      "Iteration 4022, loss = 0.00699009\n",
      "Iteration 4023, loss = 0.00698876\n",
      "Iteration 4024, loss = 0.00698598\n",
      "Iteration 4025, loss = 0.00698401\n",
      "Iteration 4026, loss = 0.00698244\n",
      "Iteration 4027, loss = 0.00697997\n",
      "Iteration 4028, loss = 0.00697748\n",
      "Iteration 4029, loss = 0.00697522\n",
      "Iteration 4030, loss = 0.00697321\n",
      "Iteration 4031, loss = 0.00697099\n",
      "Iteration 4032, loss = 0.00696828\n",
      "Iteration 4033, loss = 0.00696661\n",
      "Iteration 4034, loss = 0.00696445\n",
      "Iteration 4035, loss = 0.00696183\n",
      "Iteration 4036, loss = 0.00695969\n",
      "Iteration 4037, loss = 0.00695757\n",
      "Iteration 4038, loss = 0.00695504\n",
      "Iteration 4039, loss = 0.00695269\n",
      "Iteration 4040, loss = 0.00695024\n",
      "Iteration 4041, loss = 0.00694778\n",
      "Iteration 4042, loss = 0.00694657\n",
      "Iteration 4043, loss = 0.00694327\n",
      "Iteration 4044, loss = 0.00694100\n",
      "Iteration 4045, loss = 0.00693834\n",
      "Iteration 4046, loss = 0.00693708\n",
      "Iteration 4047, loss = 0.00693475\n",
      "Iteration 4048, loss = 0.00693318\n",
      "Iteration 4049, loss = 0.00693073\n",
      "Iteration 4050, loss = 0.00692848\n",
      "Iteration 4051, loss = 0.00692592\n",
      "Iteration 4052, loss = 0.00692356\n",
      "Iteration 4053, loss = 0.00692125\n",
      "Iteration 4054, loss = 0.00691893\n",
      "Iteration 4055, loss = 0.00691706\n",
      "Iteration 4056, loss = 0.00691432\n",
      "Iteration 4057, loss = 0.00691190\n",
      "Iteration 4058, loss = 0.00691038\n",
      "Iteration 4059, loss = 0.00690748\n",
      "Iteration 4060, loss = 0.00690523\n",
      "Iteration 4061, loss = 0.00690248\n",
      "Iteration 4062, loss = 0.00690033\n",
      "Iteration 4063, loss = 0.00689817\n",
      "Iteration 4064, loss = 0.00689537\n",
      "Iteration 4065, loss = 0.00689293\n",
      "Iteration 4066, loss = 0.00689046\n",
      "Iteration 4067, loss = 0.00688921\n",
      "Iteration 4068, loss = 0.00688615\n",
      "Iteration 4069, loss = 0.00688413\n",
      "Iteration 4070, loss = 0.00688171\n",
      "Iteration 4071, loss = 0.00687970\n",
      "Iteration 4072, loss = 0.00687749\n",
      "Iteration 4073, loss = 0.00687526\n",
      "Iteration 4074, loss = 0.00687364\n",
      "Iteration 4075, loss = 0.00687012\n",
      "Iteration 4076, loss = 0.00686745\n",
      "Iteration 4077, loss = 0.00686767\n",
      "Iteration 4078, loss = 0.00686296\n",
      "Iteration 4079, loss = 0.00686093\n",
      "Iteration 4080, loss = 0.00685863\n",
      "Iteration 4081, loss = 0.00685628\n",
      "Iteration 4082, loss = 0.00685400\n",
      "Iteration 4083, loss = 0.00685206\n",
      "Iteration 4084, loss = 0.00685001\n",
      "Iteration 4085, loss = 0.00684777\n",
      "Iteration 4086, loss = 0.00684559\n",
      "Iteration 4087, loss = 0.00684354\n",
      "Iteration 4088, loss = 0.00684120\n",
      "Iteration 4089, loss = 0.00683886\n",
      "Iteration 4090, loss = 0.00683656\n",
      "Iteration 4091, loss = 0.00683453\n",
      "Iteration 4092, loss = 0.00683201\n",
      "Iteration 4093, loss = 0.00683001\n",
      "Iteration 4094, loss = 0.00682797\n",
      "Iteration 4095, loss = 0.00682579\n",
      "Iteration 4096, loss = 0.00682384\n",
      "Iteration 4097, loss = 0.00682245\n",
      "Iteration 4098, loss = 0.00681994\n",
      "Iteration 4099, loss = 0.00681802\n",
      "Iteration 4100, loss = 0.00681613\n",
      "Iteration 4101, loss = 0.00681384\n",
      "Iteration 4102, loss = 0.00681163\n",
      "Iteration 4103, loss = 0.00680963\n",
      "Iteration 4104, loss = 0.00680754\n",
      "Iteration 4105, loss = 0.00680547\n",
      "Iteration 4106, loss = 0.00680347\n",
      "Iteration 4107, loss = 0.00680185\n",
      "Iteration 4108, loss = 0.00679953\n",
      "Iteration 4109, loss = 0.00679761\n",
      "Iteration 4110, loss = 0.00679560\n",
      "Iteration 4111, loss = 0.00679357\n",
      "Iteration 4112, loss = 0.00679170\n",
      "Iteration 4113, loss = 0.00678978\n",
      "Iteration 4114, loss = 0.00678779\n",
      "Iteration 4115, loss = 0.00678676\n",
      "Iteration 4116, loss = 0.00678473\n",
      "Iteration 4117, loss = 0.00678233\n",
      "Iteration 4118, loss = 0.00677999\n",
      "Iteration 4119, loss = 0.00677763\n",
      "Iteration 4120, loss = 0.00677551\n",
      "Iteration 4121, loss = 0.00677345\n",
      "Iteration 4122, loss = 0.00677179\n",
      "Iteration 4123, loss = 0.00676956\n",
      "Iteration 4124, loss = 0.00676713\n",
      "Iteration 4125, loss = 0.00676539\n",
      "Iteration 4126, loss = 0.00676332\n",
      "Iteration 4127, loss = 0.00676121\n",
      "Iteration 4128, loss = 0.00675953\n",
      "Iteration 4129, loss = 0.00675863\n",
      "Iteration 4130, loss = 0.00675626\n",
      "Iteration 4131, loss = 0.00675516\n",
      "Iteration 4132, loss = 0.00675295\n",
      "Iteration 4133, loss = 0.00675165\n",
      "Iteration 4134, loss = 0.00674919\n",
      "Iteration 4135, loss = 0.00674741\n",
      "Iteration 4136, loss = 0.00674532\n",
      "Iteration 4137, loss = 0.00674340\n",
      "Iteration 4138, loss = 0.00674095\n",
      "Iteration 4139, loss = 0.00673878\n",
      "Iteration 4140, loss = 0.00673696\n",
      "Iteration 4141, loss = 0.00673576\n",
      "Iteration 4142, loss = 0.00673317\n",
      "Iteration 4143, loss = 0.00673210\n",
      "Iteration 4144, loss = 0.00673110\n",
      "Iteration 4145, loss = 0.00672861\n",
      "Iteration 4146, loss = 0.00672625\n",
      "Iteration 4147, loss = 0.00672456\n",
      "Iteration 4148, loss = 0.00672150\n",
      "Iteration 4149, loss = 0.00671921\n",
      "Iteration 4150, loss = 0.00671634\n",
      "Iteration 4151, loss = 0.00671316\n",
      "Iteration 4152, loss = 0.00671141\n",
      "Iteration 4153, loss = 0.00670766\n",
      "Iteration 4154, loss = 0.00670545\n",
      "Iteration 4155, loss = 0.00670286\n",
      "Iteration 4156, loss = 0.00670051\n",
      "Iteration 4157, loss = 0.00669839\n",
      "Iteration 4158, loss = 0.00669599\n",
      "Iteration 4159, loss = 0.00669352\n",
      "Iteration 4160, loss = 0.00669104\n",
      "Iteration 4161, loss = 0.00668892\n",
      "Iteration 4162, loss = 0.00668596\n",
      "Iteration 4163, loss = 0.00668331\n",
      "Iteration 4164, loss = 0.00668196\n",
      "Iteration 4165, loss = 0.00667885\n",
      "Iteration 4166, loss = 0.00667620\n",
      "Iteration 4167, loss = 0.00667427\n",
      "Iteration 4168, loss = 0.00667303\n",
      "Iteration 4169, loss = 0.00666942\n",
      "Iteration 4170, loss = 0.00666716\n",
      "Iteration 4171, loss = 0.00666494\n",
      "Iteration 4172, loss = 0.00666281\n",
      "Iteration 4173, loss = 0.00666017\n",
      "Iteration 4174, loss = 0.00665852\n",
      "Iteration 4175, loss = 0.00665547\n",
      "Iteration 4176, loss = 0.00665307\n",
      "Iteration 4177, loss = 0.00665126\n",
      "Iteration 4178, loss = 0.00664848\n",
      "Iteration 4179, loss = 0.00664625\n",
      "Iteration 4180, loss = 0.00664414\n",
      "Iteration 4181, loss = 0.00664151\n",
      "Iteration 4182, loss = 0.00663902\n",
      "Iteration 4183, loss = 0.00663706\n",
      "Iteration 4184, loss = 0.00663463\n",
      "Iteration 4185, loss = 0.00663348\n",
      "Iteration 4186, loss = 0.00663025\n",
      "Iteration 4187, loss = 0.00662785\n",
      "Iteration 4188, loss = 0.00662570\n",
      "Iteration 4189, loss = 0.00662343\n",
      "Iteration 4190, loss = 0.00662126\n",
      "Iteration 4191, loss = 0.00661927\n",
      "Iteration 4192, loss = 0.00661721\n",
      "Iteration 4193, loss = 0.00661505\n",
      "Iteration 4194, loss = 0.00661390\n",
      "Iteration 4195, loss = 0.00661052\n",
      "Iteration 4196, loss = 0.00660821\n",
      "Iteration 4197, loss = 0.00660607\n",
      "Iteration 4198, loss = 0.00660398\n",
      "Iteration 4199, loss = 0.00660187\n",
      "Iteration 4200, loss = 0.00659956\n",
      "Iteration 4201, loss = 0.00659773\n",
      "Iteration 4202, loss = 0.00659540\n",
      "Iteration 4203, loss = 0.00659346\n",
      "Iteration 4204, loss = 0.00659119\n",
      "Iteration 4205, loss = 0.00658897\n",
      "Iteration 4206, loss = 0.00658677\n",
      "Iteration 4207, loss = 0.00658451\n",
      "Iteration 4208, loss = 0.00658188\n",
      "Iteration 4209, loss = 0.00657977\n",
      "Iteration 4210, loss = 0.00657708\n",
      "Iteration 4211, loss = 0.00657568\n",
      "Iteration 4212, loss = 0.00657288\n",
      "Iteration 4213, loss = 0.00657092\n",
      "Iteration 4214, loss = 0.00656943\n",
      "Iteration 4215, loss = 0.00656748\n",
      "Iteration 4216, loss = 0.00656503\n",
      "Iteration 4217, loss = 0.00656299\n",
      "Iteration 4218, loss = 0.00656115\n",
      "Iteration 4219, loss = 0.00655962\n",
      "Iteration 4220, loss = 0.00655732\n",
      "Iteration 4221, loss = 0.00655509\n",
      "Iteration 4222, loss = 0.00655309\n",
      "Iteration 4223, loss = 0.00655119\n",
      "Iteration 4224, loss = 0.00654948\n",
      "Iteration 4225, loss = 0.00654718\n",
      "Iteration 4226, loss = 0.00654512\n",
      "Iteration 4227, loss = 0.00654345\n",
      "Iteration 4228, loss = 0.00654137\n",
      "Iteration 4229, loss = 0.00653916\n",
      "Iteration 4230, loss = 0.00653727\n",
      "Iteration 4231, loss = 0.00653480\n",
      "Iteration 4232, loss = 0.00653288\n",
      "Iteration 4233, loss = 0.00653077\n",
      "Iteration 4234, loss = 0.00652815\n",
      "Iteration 4235, loss = 0.00652631\n",
      "Iteration 4236, loss = 0.00652382\n",
      "Iteration 4237, loss = 0.00652141\n",
      "Iteration 4238, loss = 0.00651950\n",
      "Iteration 4239, loss = 0.00651748\n",
      "Iteration 4240, loss = 0.00651514\n",
      "Iteration 4241, loss = 0.00651248\n",
      "Iteration 4242, loss = 0.00651037\n",
      "Iteration 4243, loss = 0.00650841\n",
      "Iteration 4244, loss = 0.00650661\n",
      "Iteration 4245, loss = 0.00650430\n",
      "Iteration 4246, loss = 0.00650250\n",
      "Iteration 4247, loss = 0.00650086\n",
      "Iteration 4248, loss = 0.00649825\n",
      "Iteration 4249, loss = 0.00649630\n",
      "Iteration 4250, loss = 0.00649498\n",
      "Iteration 4251, loss = 0.00649245\n",
      "Iteration 4252, loss = 0.00649058\n",
      "Iteration 4253, loss = 0.00648866\n",
      "Iteration 4254, loss = 0.00648678\n",
      "Iteration 4255, loss = 0.00648511\n",
      "Iteration 4256, loss = 0.00648385\n",
      "Iteration 4257, loss = 0.00648134\n",
      "Iteration 4258, loss = 0.00647911\n",
      "Iteration 4259, loss = 0.00647715\n",
      "Iteration 4260, loss = 0.00647491\n",
      "Iteration 4261, loss = 0.00647284\n",
      "Iteration 4262, loss = 0.00647103\n",
      "Iteration 4263, loss = 0.00646917\n",
      "Iteration 4264, loss = 0.00646686\n",
      "Iteration 4265, loss = 0.00646504\n",
      "Iteration 4266, loss = 0.00646270\n",
      "Iteration 4267, loss = 0.00646044\n",
      "Iteration 4268, loss = 0.00645955\n",
      "Iteration 4269, loss = 0.00645667\n",
      "Iteration 4270, loss = 0.00645465\n",
      "Iteration 4271, loss = 0.00645244\n",
      "Iteration 4272, loss = 0.00645026\n",
      "Iteration 4273, loss = 0.00644817\n",
      "Iteration 4274, loss = 0.00644634\n",
      "Iteration 4275, loss = 0.00644430\n",
      "Iteration 4276, loss = 0.00644183\n",
      "Iteration 4277, loss = 0.00643960\n",
      "Iteration 4278, loss = 0.00643749\n",
      "Iteration 4279, loss = 0.00643508\n",
      "Iteration 4280, loss = 0.00643266\n",
      "Iteration 4281, loss = 0.00643062\n",
      "Iteration 4282, loss = 0.00642822\n",
      "Iteration 4283, loss = 0.00642646\n",
      "Iteration 4284, loss = 0.00642423\n",
      "Iteration 4285, loss = 0.00642198\n",
      "Iteration 4286, loss = 0.00641987\n",
      "Iteration 4287, loss = 0.00641792\n",
      "Iteration 4288, loss = 0.00641605\n",
      "Iteration 4289, loss = 0.00641395\n",
      "Iteration 4290, loss = 0.00641189\n",
      "Iteration 4291, loss = 0.00641006\n",
      "Iteration 4292, loss = 0.00640822\n",
      "Iteration 4293, loss = 0.00640612\n",
      "Iteration 4294, loss = 0.00640392\n",
      "Iteration 4295, loss = 0.00640210\n",
      "Iteration 4296, loss = 0.00640025\n",
      "Iteration 4297, loss = 0.00639820\n",
      "Iteration 4298, loss = 0.00639702\n",
      "Iteration 4299, loss = 0.00639538\n",
      "Iteration 4300, loss = 0.00639337\n",
      "Iteration 4301, loss = 0.00639143\n",
      "Iteration 4302, loss = 0.00638893\n",
      "Iteration 4303, loss = 0.00638771\n",
      "Iteration 4304, loss = 0.00638516\n",
      "Iteration 4305, loss = 0.00638354\n",
      "Iteration 4306, loss = 0.00638138\n",
      "Iteration 4307, loss = 0.00637917\n",
      "Iteration 4308, loss = 0.00637696\n",
      "Iteration 4309, loss = 0.00637521\n",
      "Iteration 4310, loss = 0.00637354\n",
      "Iteration 4311, loss = 0.00637175\n",
      "Iteration 4312, loss = 0.00636964\n",
      "Iteration 4313, loss = 0.00636712\n",
      "Iteration 4314, loss = 0.00636539\n",
      "Iteration 4315, loss = 0.00636306\n",
      "Iteration 4316, loss = 0.00636123\n",
      "Iteration 4317, loss = 0.00635905\n",
      "Iteration 4318, loss = 0.00635689\n",
      "Iteration 4319, loss = 0.00635509\n",
      "Iteration 4320, loss = 0.00635311\n",
      "Iteration 4321, loss = 0.00635099\n",
      "Iteration 4322, loss = 0.00634874\n",
      "Iteration 4323, loss = 0.00634705\n",
      "Iteration 4324, loss = 0.00634453\n",
      "Iteration 4325, loss = 0.00634345\n",
      "Iteration 4326, loss = 0.00634109\n",
      "Iteration 4327, loss = 0.00633829\n",
      "Iteration 4328, loss = 0.00633617\n",
      "Iteration 4329, loss = 0.00633416\n",
      "Iteration 4330, loss = 0.00633149\n",
      "Iteration 4331, loss = 0.00633006\n",
      "Iteration 4332, loss = 0.00632721\n",
      "Iteration 4333, loss = 0.00632518\n",
      "Iteration 4334, loss = 0.00632370\n",
      "Iteration 4335, loss = 0.00632097\n",
      "Iteration 4336, loss = 0.00632006\n",
      "Iteration 4337, loss = 0.00631737\n",
      "Iteration 4338, loss = 0.00631522\n",
      "Iteration 4339, loss = 0.00631274\n",
      "Iteration 4340, loss = 0.00631063\n",
      "Iteration 4341, loss = 0.00630857\n",
      "Iteration 4342, loss = 0.00630736\n",
      "Iteration 4343, loss = 0.00630493\n",
      "Iteration 4344, loss = 0.00630287\n",
      "Iteration 4345, loss = 0.00630129\n",
      "Iteration 4346, loss = 0.00629914\n",
      "Iteration 4347, loss = 0.00629716\n",
      "Iteration 4348, loss = 0.00629516\n",
      "Iteration 4349, loss = 0.00629333\n",
      "Iteration 4350, loss = 0.00629146\n",
      "Iteration 4351, loss = 0.00628955\n",
      "Iteration 4352, loss = 0.00628784\n",
      "Iteration 4353, loss = 0.00628636\n",
      "Iteration 4354, loss = 0.00628437\n",
      "Iteration 4355, loss = 0.00628256\n",
      "Iteration 4356, loss = 0.00628122\n",
      "Iteration 4357, loss = 0.00627929\n",
      "Iteration 4358, loss = 0.00627730\n",
      "Iteration 4359, loss = 0.00627527\n",
      "Iteration 4360, loss = 0.00627305\n",
      "Iteration 4361, loss = 0.00627148\n",
      "Iteration 4362, loss = 0.00626914\n",
      "Iteration 4363, loss = 0.00626745\n",
      "Iteration 4364, loss = 0.00626515\n",
      "Iteration 4365, loss = 0.00626350\n",
      "Iteration 4366, loss = 0.00626112\n",
      "Iteration 4367, loss = 0.00625917\n",
      "Iteration 4368, loss = 0.00625761\n",
      "Iteration 4369, loss = 0.00625529\n",
      "Iteration 4370, loss = 0.00625379\n",
      "Iteration 4371, loss = 0.00625199\n",
      "Iteration 4372, loss = 0.00624979\n",
      "Iteration 4373, loss = 0.00624819\n",
      "Iteration 4374, loss = 0.00624641\n",
      "Iteration 4375, loss = 0.00624415\n",
      "Iteration 4376, loss = 0.00624213\n",
      "Iteration 4377, loss = 0.00624074\n",
      "Iteration 4378, loss = 0.00623858\n",
      "Iteration 4379, loss = 0.00623738\n",
      "Iteration 4380, loss = 0.00623492\n",
      "Iteration 4381, loss = 0.00623322\n",
      "Iteration 4382, loss = 0.00623101\n",
      "Iteration 4383, loss = 0.00622924\n",
      "Iteration 4384, loss = 0.00622800\n",
      "Iteration 4385, loss = 0.00622543\n",
      "Iteration 4386, loss = 0.00622347\n",
      "Iteration 4387, loss = 0.00622135\n",
      "Iteration 4388, loss = 0.00622012\n",
      "Iteration 4389, loss = 0.00621804\n",
      "Iteration 4390, loss = 0.00621681\n",
      "Iteration 4391, loss = 0.00621425\n",
      "Iteration 4392, loss = 0.00621214\n",
      "Iteration 4393, loss = 0.00621033\n",
      "Iteration 4394, loss = 0.00620889\n",
      "Iteration 4395, loss = 0.00620749\n",
      "Iteration 4396, loss = 0.00620462\n",
      "Iteration 4397, loss = 0.00620271\n",
      "Iteration 4398, loss = 0.00620084\n",
      "Iteration 4399, loss = 0.00619844\n",
      "Iteration 4400, loss = 0.00619649\n",
      "Iteration 4401, loss = 0.00619484\n",
      "Iteration 4402, loss = 0.00619359\n",
      "Iteration 4403, loss = 0.00619128\n",
      "Iteration 4404, loss = 0.00618942\n",
      "Iteration 4405, loss = 0.00618802\n",
      "Iteration 4406, loss = 0.00618551\n",
      "Iteration 4407, loss = 0.00618351\n",
      "Iteration 4408, loss = 0.00618147\n",
      "Iteration 4409, loss = 0.00618009\n",
      "Iteration 4410, loss = 0.00617799\n",
      "Iteration 4411, loss = 0.00617612\n",
      "Iteration 4412, loss = 0.00617409\n",
      "Iteration 4413, loss = 0.00617224\n",
      "Iteration 4414, loss = 0.00617042\n",
      "Iteration 4415, loss = 0.00616869\n",
      "Iteration 4416, loss = 0.00616678\n",
      "Iteration 4417, loss = 0.00616626\n",
      "Iteration 4418, loss = 0.00616337\n",
      "Iteration 4419, loss = 0.00616161\n",
      "Iteration 4420, loss = 0.00615956\n",
      "Iteration 4421, loss = 0.00615782\n",
      "Iteration 4422, loss = 0.00615571\n",
      "Iteration 4423, loss = 0.00615391\n",
      "Iteration 4424, loss = 0.00615195\n",
      "Iteration 4425, loss = 0.00615022\n",
      "Iteration 4426, loss = 0.00614838\n",
      "Iteration 4427, loss = 0.00614656\n",
      "Iteration 4428, loss = 0.00614486\n",
      "Iteration 4429, loss = 0.00614353\n",
      "Iteration 4430, loss = 0.00614160\n",
      "Iteration 4431, loss = 0.00613996\n",
      "Iteration 4432, loss = 0.00613842\n",
      "Iteration 4433, loss = 0.00613673\n",
      "Iteration 4434, loss = 0.00613492\n",
      "Iteration 4435, loss = 0.00613330\n",
      "Iteration 4436, loss = 0.00613159\n",
      "Iteration 4437, loss = 0.00612958\n",
      "Iteration 4438, loss = 0.00612802\n",
      "Iteration 4439, loss = 0.00612587\n",
      "Iteration 4440, loss = 0.00612454\n",
      "Iteration 4441, loss = 0.00612353\n",
      "Iteration 4442, loss = 0.00612064\n",
      "Iteration 4443, loss = 0.00611866\n",
      "Iteration 4444, loss = 0.00611668\n",
      "Iteration 4445, loss = 0.00611525\n",
      "Iteration 4446, loss = 0.00611333\n",
      "Iteration 4447, loss = 0.00611123\n",
      "Iteration 4448, loss = 0.00610921\n",
      "Iteration 4449, loss = 0.00610742\n",
      "Iteration 4450, loss = 0.00610556\n",
      "Iteration 4451, loss = 0.00610382\n",
      "Iteration 4452, loss = 0.00610169\n",
      "Iteration 4453, loss = 0.00609981\n",
      "Iteration 4454, loss = 0.00609814\n",
      "Iteration 4455, loss = 0.00609642\n",
      "Iteration 4456, loss = 0.00609438\n",
      "Iteration 4457, loss = 0.00609257\n",
      "Iteration 4458, loss = 0.00609085\n",
      "Iteration 4459, loss = 0.00608982\n",
      "Iteration 4460, loss = 0.00608706\n",
      "Iteration 4461, loss = 0.00608555\n",
      "Iteration 4462, loss = 0.00608343\n",
      "Iteration 4463, loss = 0.00608162\n",
      "Iteration 4464, loss = 0.00607984\n",
      "Iteration 4465, loss = 0.00607800\n",
      "Iteration 4466, loss = 0.00607678\n",
      "Iteration 4467, loss = 0.00607469\n",
      "Iteration 4468, loss = 0.00607278\n",
      "Iteration 4469, loss = 0.00607139\n",
      "Iteration 4470, loss = 0.00606973\n",
      "Iteration 4471, loss = 0.00606819\n",
      "Iteration 4472, loss = 0.00606627\n",
      "Iteration 4473, loss = 0.00606470\n",
      "Iteration 4474, loss = 0.00606300\n",
      "Iteration 4475, loss = 0.00606091\n",
      "Iteration 4476, loss = 0.00605874\n",
      "Iteration 4477, loss = 0.00605751\n",
      "Iteration 4478, loss = 0.00605468\n",
      "Iteration 4479, loss = 0.00605298\n",
      "Iteration 4480, loss = 0.00605089\n",
      "Iteration 4481, loss = 0.00604925\n",
      "Iteration 4482, loss = 0.00604714\n",
      "Iteration 4483, loss = 0.00604520\n",
      "Iteration 4484, loss = 0.00604334\n",
      "Iteration 4485, loss = 0.00604151\n",
      "Iteration 4486, loss = 0.00604003\n",
      "Iteration 4487, loss = 0.00603818\n",
      "Iteration 4488, loss = 0.00603620\n",
      "Iteration 4489, loss = 0.00603434\n",
      "Iteration 4490, loss = 0.00603245\n",
      "Iteration 4491, loss = 0.00603071\n",
      "Iteration 4492, loss = 0.00602890\n",
      "Iteration 4493, loss = 0.00602674\n",
      "Iteration 4494, loss = 0.00602513\n",
      "Iteration 4495, loss = 0.00602301\n",
      "Iteration 4496, loss = 0.00602143\n",
      "Iteration 4497, loss = 0.00601921\n",
      "Iteration 4498, loss = 0.00601750\n",
      "Iteration 4499, loss = 0.00601556\n",
      "Iteration 4500, loss = 0.00601412\n",
      "Iteration 4501, loss = 0.00601202\n",
      "Iteration 4502, loss = 0.00601040\n",
      "Iteration 4503, loss = 0.00600873\n",
      "Iteration 4504, loss = 0.00600744\n",
      "Iteration 4505, loss = 0.00600537\n",
      "Iteration 4506, loss = 0.00600393\n",
      "Iteration 4507, loss = 0.00600199\n",
      "Iteration 4508, loss = 0.00600031\n",
      "Iteration 4509, loss = 0.00599847\n",
      "Iteration 4510, loss = 0.00599715\n",
      "Iteration 4511, loss = 0.00599473\n",
      "Iteration 4512, loss = 0.00599329\n",
      "Iteration 4513, loss = 0.00599142\n",
      "Iteration 4514, loss = 0.00598938\n",
      "Iteration 4515, loss = 0.00598705\n",
      "Iteration 4516, loss = 0.00598439\n",
      "Iteration 4517, loss = 0.00598305\n",
      "Iteration 4518, loss = 0.00598104\n",
      "Iteration 4519, loss = 0.00597960\n",
      "Iteration 4520, loss = 0.00597871\n",
      "Iteration 4521, loss = 0.00597658\n",
      "Iteration 4522, loss = 0.00597419\n",
      "Iteration 4523, loss = 0.00597242\n",
      "Iteration 4524, loss = 0.00597038\n",
      "Iteration 4525, loss = 0.00596857\n",
      "Iteration 4526, loss = 0.00596683\n",
      "Iteration 4527, loss = 0.00596516\n",
      "Iteration 4528, loss = 0.00596303\n",
      "Iteration 4529, loss = 0.00596142\n",
      "Iteration 4530, loss = 0.00595956\n",
      "Iteration 4531, loss = 0.00595731\n",
      "Iteration 4532, loss = 0.00595559\n",
      "Iteration 4533, loss = 0.00595365\n",
      "Iteration 4534, loss = 0.00595238\n",
      "Iteration 4535, loss = 0.00595067\n",
      "Iteration 4536, loss = 0.00594849\n",
      "Iteration 4537, loss = 0.00594685\n",
      "Iteration 4538, loss = 0.00594532\n",
      "Iteration 4539, loss = 0.00594334\n",
      "Iteration 4540, loss = 0.00594172\n",
      "Iteration 4541, loss = 0.00594058\n",
      "Iteration 4542, loss = 0.00593844\n",
      "Iteration 4543, loss = 0.00593736\n",
      "Iteration 4544, loss = 0.00593494\n",
      "Iteration 4545, loss = 0.00593322\n",
      "Iteration 4546, loss = 0.00593159\n",
      "Iteration 4547, loss = 0.00592975\n",
      "Iteration 4548, loss = 0.00592776\n",
      "Iteration 4549, loss = 0.00592600\n",
      "Iteration 4550, loss = 0.00592406\n",
      "Iteration 4551, loss = 0.00592212\n",
      "Iteration 4552, loss = 0.00592027\n",
      "Iteration 4553, loss = 0.00591845\n",
      "Iteration 4554, loss = 0.00591616\n",
      "Iteration 4555, loss = 0.00591429\n",
      "Iteration 4556, loss = 0.00591251\n",
      "Iteration 4557, loss = 0.00591044\n",
      "Iteration 4558, loss = 0.00590936\n",
      "Iteration 4559, loss = 0.00590738\n",
      "Iteration 4560, loss = 0.00590505\n",
      "Iteration 4561, loss = 0.00590302\n",
      "Iteration 4562, loss = 0.00590091\n",
      "Iteration 4563, loss = 0.00589926\n",
      "Iteration 4564, loss = 0.00589708\n",
      "Iteration 4565, loss = 0.00589526\n",
      "Iteration 4566, loss = 0.00589399\n",
      "Iteration 4567, loss = 0.00589214\n",
      "Iteration 4568, loss = 0.00588999\n",
      "Iteration 4569, loss = 0.00588890\n",
      "Iteration 4570, loss = 0.00588630\n",
      "Iteration 4571, loss = 0.00588470\n",
      "Iteration 4572, loss = 0.00588239\n",
      "Iteration 4573, loss = 0.00588075\n",
      "Iteration 4574, loss = 0.00587894\n",
      "Iteration 4575, loss = 0.00587708\n",
      "Iteration 4576, loss = 0.00587599\n",
      "Iteration 4577, loss = 0.00587368\n",
      "Iteration 4578, loss = 0.00587217\n",
      "Iteration 4579, loss = 0.00587107\n",
      "Iteration 4580, loss = 0.00586808\n",
      "Iteration 4581, loss = 0.00586726\n",
      "Iteration 4582, loss = 0.00586507\n",
      "Iteration 4583, loss = 0.00586396\n",
      "Iteration 4584, loss = 0.00586147\n",
      "Iteration 4585, loss = 0.00585999\n",
      "Iteration 4586, loss = 0.00585819\n",
      "Iteration 4587, loss = 0.00585604\n",
      "Iteration 4588, loss = 0.00585429\n",
      "Iteration 4589, loss = 0.00585245\n",
      "Iteration 4590, loss = 0.00585063\n",
      "Iteration 4591, loss = 0.00584865\n",
      "Iteration 4592, loss = 0.00584688\n",
      "Iteration 4593, loss = 0.00584545\n",
      "Iteration 4594, loss = 0.00584364\n",
      "Iteration 4595, loss = 0.00584175\n",
      "Iteration 4596, loss = 0.00583988\n",
      "Iteration 4597, loss = 0.00583795\n",
      "Iteration 4598, loss = 0.00583598\n",
      "Iteration 4599, loss = 0.00583470\n",
      "Iteration 4600, loss = 0.00583208\n",
      "Iteration 4601, loss = 0.00583035\n",
      "Iteration 4602, loss = 0.00582860\n",
      "Iteration 4603, loss = 0.00582687\n",
      "Iteration 4604, loss = 0.00582516\n",
      "Iteration 4605, loss = 0.00582370\n",
      "Iteration 4606, loss = 0.00582171\n",
      "Iteration 4607, loss = 0.00581997\n",
      "Iteration 4608, loss = 0.00581852\n",
      "Iteration 4609, loss = 0.00581668\n",
      "Iteration 4610, loss = 0.00581487\n",
      "Iteration 4611, loss = 0.00581342\n",
      "Iteration 4612, loss = 0.00581150\n",
      "Iteration 4613, loss = 0.00581027\n",
      "Iteration 4614, loss = 0.00580818\n",
      "Iteration 4615, loss = 0.00580689\n",
      "Iteration 4616, loss = 0.00580473\n",
      "Iteration 4617, loss = 0.00580303\n",
      "Iteration 4618, loss = 0.00580174\n",
      "Iteration 4619, loss = 0.00579934\n",
      "Iteration 4620, loss = 0.00579768\n",
      "Iteration 4621, loss = 0.00579584\n",
      "Iteration 4622, loss = 0.00579439\n",
      "Iteration 4623, loss = 0.00579220\n",
      "Iteration 4624, loss = 0.00579052\n",
      "Iteration 4625, loss = 0.00578880\n",
      "Iteration 4626, loss = 0.00578732\n",
      "Iteration 4627, loss = 0.00578574\n",
      "Iteration 4628, loss = 0.00578388\n",
      "Iteration 4629, loss = 0.00578231\n",
      "Iteration 4630, loss = 0.00578111\n",
      "Iteration 4631, loss = 0.00577883\n",
      "Iteration 4632, loss = 0.00577761\n",
      "Iteration 4633, loss = 0.00577539\n",
      "Iteration 4634, loss = 0.00577433\n",
      "Iteration 4635, loss = 0.00577181\n",
      "Iteration 4636, loss = 0.00577018\n",
      "Iteration 4637, loss = 0.00576848\n",
      "Iteration 4638, loss = 0.00576645\n",
      "Iteration 4639, loss = 0.00576482\n",
      "Iteration 4640, loss = 0.00576368\n",
      "Iteration 4641, loss = 0.00576162\n",
      "Iteration 4642, loss = 0.00575963\n",
      "Iteration 4643, loss = 0.00575793\n",
      "Iteration 4644, loss = 0.00575618\n",
      "Iteration 4645, loss = 0.00575461\n",
      "Iteration 4646, loss = 0.00575279\n",
      "Iteration 4647, loss = 0.00575109\n",
      "Iteration 4648, loss = 0.00574949\n",
      "Iteration 4649, loss = 0.00574817\n",
      "Iteration 4650, loss = 0.00574641\n",
      "Iteration 4651, loss = 0.00574459\n",
      "Iteration 4652, loss = 0.00574275\n",
      "Iteration 4653, loss = 0.00574130\n",
      "Iteration 4654, loss = 0.00574039\n",
      "Iteration 4655, loss = 0.00573812\n",
      "Iteration 4656, loss = 0.00573627\n",
      "Iteration 4657, loss = 0.00573468\n",
      "Iteration 4658, loss = 0.00573304\n",
      "Iteration 4659, loss = 0.00573154\n",
      "Iteration 4660, loss = 0.00572957\n",
      "Iteration 4661, loss = 0.00572788\n",
      "Iteration 4662, loss = 0.00572638\n",
      "Iteration 4663, loss = 0.00572427\n",
      "Iteration 4664, loss = 0.00572240\n",
      "Iteration 4665, loss = 0.00572084\n",
      "Iteration 4666, loss = 0.00571902\n",
      "Iteration 4667, loss = 0.00571735\n",
      "Iteration 4668, loss = 0.00571559\n",
      "Iteration 4669, loss = 0.00571426\n",
      "Iteration 4670, loss = 0.00571261\n",
      "Iteration 4671, loss = 0.00571078\n",
      "Iteration 4672, loss = 0.00571036\n",
      "Iteration 4673, loss = 0.00570770\n",
      "Iteration 4674, loss = 0.00570603\n",
      "Iteration 4675, loss = 0.00570407\n",
      "Iteration 4676, loss = 0.00570243\n",
      "Iteration 4677, loss = 0.00570098\n",
      "Iteration 4678, loss = 0.00569935\n",
      "Iteration 4679, loss = 0.00569750\n",
      "Iteration 4680, loss = 0.00569618\n",
      "Iteration 4681, loss = 0.00569444\n",
      "Iteration 4682, loss = 0.00569254\n",
      "Iteration 4683, loss = 0.00569109\n",
      "Iteration 4684, loss = 0.00568930\n",
      "Iteration 4685, loss = 0.00568767\n",
      "Iteration 4686, loss = 0.00568619\n",
      "Iteration 4687, loss = 0.00568474\n",
      "Iteration 4688, loss = 0.00568313\n",
      "Iteration 4689, loss = 0.00568179\n",
      "Iteration 4690, loss = 0.00568048\n",
      "Iteration 4691, loss = 0.00567862\n",
      "Iteration 4692, loss = 0.00567678\n",
      "Iteration 4693, loss = 0.00567540\n",
      "Iteration 4694, loss = 0.00567361\n",
      "Iteration 4695, loss = 0.00567206\n",
      "Iteration 4696, loss = 0.00567068\n",
      "Iteration 4697, loss = 0.00566906\n",
      "Iteration 4698, loss = 0.00566759\n",
      "Iteration 4699, loss = 0.00566711\n",
      "Iteration 4700, loss = 0.00566455\n",
      "Iteration 4701, loss = 0.00566304\n",
      "Iteration 4702, loss = 0.00566144\n",
      "Iteration 4703, loss = 0.00566002\n",
      "Iteration 4704, loss = 0.00565828\n",
      "Iteration 4705, loss = 0.00565652\n",
      "Iteration 4706, loss = 0.00565555\n",
      "Iteration 4707, loss = 0.00565369\n",
      "Iteration 4708, loss = 0.00565273\n",
      "Iteration 4709, loss = 0.00565080\n",
      "Iteration 4710, loss = 0.00564937\n",
      "Iteration 4711, loss = 0.00564796\n",
      "Iteration 4712, loss = 0.00564644\n",
      "Iteration 4713, loss = 0.00564498\n",
      "Iteration 4714, loss = 0.00564362\n",
      "Iteration 4715, loss = 0.00564216\n",
      "Iteration 4716, loss = 0.00564063\n",
      "Iteration 4717, loss = 0.00563888\n",
      "Iteration 4718, loss = 0.00563842\n",
      "Iteration 4719, loss = 0.00563556\n",
      "Iteration 4720, loss = 0.00563409\n",
      "Iteration 4721, loss = 0.00563247\n",
      "Iteration 4722, loss = 0.00563060\n",
      "Iteration 4723, loss = 0.00562907\n",
      "Iteration 4724, loss = 0.00562686\n",
      "Iteration 4725, loss = 0.00562518\n",
      "Iteration 4726, loss = 0.00562340\n",
      "Iteration 4727, loss = 0.00562182\n",
      "Iteration 4728, loss = 0.00562053\n",
      "Iteration 4729, loss = 0.00561864\n",
      "Iteration 4730, loss = 0.00561708\n",
      "Iteration 4731, loss = 0.00561561\n",
      "Iteration 4732, loss = 0.00561417\n",
      "Iteration 4733, loss = 0.00561263\n",
      "Iteration 4734, loss = 0.00561133\n",
      "Iteration 4735, loss = 0.00561017\n",
      "Iteration 4736, loss = 0.00560862\n",
      "Iteration 4737, loss = 0.00560712\n",
      "Iteration 4738, loss = 0.00560560\n",
      "Iteration 4739, loss = 0.00560429\n",
      "Iteration 4740, loss = 0.00560294\n",
      "Iteration 4741, loss = 0.00560145\n",
      "Iteration 4742, loss = 0.00559971\n",
      "Iteration 4743, loss = 0.00559829\n",
      "Iteration 4744, loss = 0.00559690\n",
      "Iteration 4745, loss = 0.00559547\n",
      "Iteration 4746, loss = 0.00559407\n",
      "Iteration 4747, loss = 0.00559278\n",
      "Iteration 4748, loss = 0.00559148\n",
      "Iteration 4749, loss = 0.00559006\n",
      "Iteration 4750, loss = 0.00558843\n",
      "Iteration 4751, loss = 0.00558657\n",
      "Iteration 4752, loss = 0.00558518\n",
      "Iteration 4753, loss = 0.00558321\n",
      "Iteration 4754, loss = 0.00558169\n",
      "Iteration 4755, loss = 0.00558023\n",
      "Iteration 4756, loss = 0.00557877\n",
      "Iteration 4757, loss = 0.00557671\n",
      "Iteration 4758, loss = 0.00557582\n",
      "Iteration 4759, loss = 0.00557378\n",
      "Iteration 4760, loss = 0.00557219\n",
      "Iteration 4761, loss = 0.00557099\n",
      "Iteration 4762, loss = 0.00556941\n",
      "Iteration 4763, loss = 0.00556791\n",
      "Iteration 4764, loss = 0.00556689\n",
      "Iteration 4765, loss = 0.00556465\n",
      "Iteration 4766, loss = 0.00556282\n",
      "Iteration 4767, loss = 0.00556138\n",
      "Iteration 4768, loss = 0.00555955\n",
      "Iteration 4769, loss = 0.00555779\n",
      "Iteration 4770, loss = 0.00555622\n",
      "Iteration 4771, loss = 0.00555472\n",
      "Iteration 4772, loss = 0.00555305\n",
      "Iteration 4773, loss = 0.00555136\n",
      "Iteration 4774, loss = 0.00554992\n",
      "Iteration 4775, loss = 0.00554868\n",
      "Iteration 4776, loss = 0.00554697\n",
      "Iteration 4777, loss = 0.00554516\n",
      "Iteration 4778, loss = 0.00554336\n",
      "Iteration 4779, loss = 0.00554224\n",
      "Iteration 4780, loss = 0.00554054\n",
      "Iteration 4781, loss = 0.00553876\n",
      "Iteration 4782, loss = 0.00553713\n",
      "Iteration 4783, loss = 0.00553562\n",
      "Iteration 4784, loss = 0.00553446\n",
      "Iteration 4785, loss = 0.00553273\n",
      "Iteration 4786, loss = 0.00553098\n",
      "Iteration 4787, loss = 0.00552949\n",
      "Iteration 4788, loss = 0.00552770\n",
      "Iteration 4789, loss = 0.00552632\n",
      "Iteration 4790, loss = 0.00552443\n",
      "Iteration 4791, loss = 0.00552243\n",
      "Iteration 4792, loss = 0.00552087\n",
      "Iteration 4793, loss = 0.00551909\n",
      "Iteration 4794, loss = 0.00551752\n",
      "Iteration 4795, loss = 0.00551577\n",
      "Iteration 4796, loss = 0.00551432\n",
      "Iteration 4797, loss = 0.00551242\n",
      "Iteration 4798, loss = 0.00551077\n",
      "Iteration 4799, loss = 0.00550930\n",
      "Iteration 4800, loss = 0.00550771\n",
      "Iteration 4801, loss = 0.00550651\n",
      "Iteration 4802, loss = 0.00550500\n",
      "Iteration 4803, loss = 0.00550359\n",
      "Iteration 4804, loss = 0.00550188\n",
      "Iteration 4805, loss = 0.00550043\n",
      "Iteration 4806, loss = 0.00549874\n",
      "Iteration 4807, loss = 0.00549746\n",
      "Iteration 4808, loss = 0.00549569\n",
      "Iteration 4809, loss = 0.00549408\n",
      "Iteration 4810, loss = 0.00549254\n",
      "Iteration 4811, loss = 0.00549090\n",
      "Iteration 4812, loss = 0.00548921\n",
      "Iteration 4813, loss = 0.00548775\n",
      "Iteration 4814, loss = 0.00548624\n",
      "Iteration 4815, loss = 0.00548449\n",
      "Iteration 4816, loss = 0.00548262\n",
      "Iteration 4817, loss = 0.00548063\n",
      "Iteration 4818, loss = 0.00547889\n",
      "Iteration 4819, loss = 0.00547673\n",
      "Iteration 4820, loss = 0.00547600\n",
      "Iteration 4821, loss = 0.00547396\n",
      "Iteration 4822, loss = 0.00547216\n",
      "Iteration 4823, loss = 0.00547053\n",
      "Iteration 4824, loss = 0.00546884\n",
      "Iteration 4825, loss = 0.00546738\n",
      "Iteration 4826, loss = 0.00546575\n",
      "Iteration 4827, loss = 0.00546423\n",
      "Iteration 4828, loss = 0.00546243\n",
      "Iteration 4829, loss = 0.00546082\n",
      "Iteration 4830, loss = 0.00545937\n",
      "Iteration 4831, loss = 0.00545766\n",
      "Iteration 4832, loss = 0.00545571\n",
      "Iteration 4833, loss = 0.00545399\n",
      "Iteration 4834, loss = 0.00545313\n",
      "Iteration 4835, loss = 0.00545086\n",
      "Iteration 4836, loss = 0.00544969\n",
      "Iteration 4837, loss = 0.00544820\n",
      "Iteration 4838, loss = 0.00544590\n",
      "Iteration 4839, loss = 0.00544418\n",
      "Iteration 4840, loss = 0.00544333\n",
      "Iteration 4841, loss = 0.00544135\n",
      "Iteration 4842, loss = 0.00544007\n",
      "Iteration 4843, loss = 0.00543849\n",
      "Iteration 4844, loss = 0.00543702\n",
      "Iteration 4845, loss = 0.00543558\n",
      "Iteration 4846, loss = 0.00543413\n",
      "Iteration 4847, loss = 0.00543244\n",
      "Iteration 4848, loss = 0.00543073\n",
      "Iteration 4849, loss = 0.00542926\n",
      "Iteration 4850, loss = 0.00542763\n",
      "Iteration 4851, loss = 0.00542647\n",
      "Iteration 4852, loss = 0.00542473\n",
      "Iteration 4853, loss = 0.00542323\n",
      "Iteration 4854, loss = 0.00542179\n",
      "Iteration 4855, loss = 0.00542041\n",
      "Iteration 4856, loss = 0.00541847\n",
      "Iteration 4857, loss = 0.00541701\n",
      "Iteration 4858, loss = 0.00541533\n",
      "Iteration 4859, loss = 0.00541356\n",
      "Iteration 4860, loss = 0.00541189\n",
      "Iteration 4861, loss = 0.00541036\n",
      "Iteration 4862, loss = 0.00540866\n",
      "Iteration 4863, loss = 0.00540732\n",
      "Iteration 4864, loss = 0.00540565\n",
      "Iteration 4865, loss = 0.00540419\n",
      "Iteration 4866, loss = 0.00540268\n",
      "Iteration 4867, loss = 0.00540133\n",
      "Iteration 4868, loss = 0.00539959\n",
      "Iteration 4869, loss = 0.00539855\n",
      "Iteration 4870, loss = 0.00539706\n",
      "Iteration 4871, loss = 0.00539603\n",
      "Iteration 4872, loss = 0.00539493\n",
      "Iteration 4873, loss = 0.00539384\n",
      "Iteration 4874, loss = 0.00539208\n",
      "Iteration 4875, loss = 0.00539073\n",
      "Iteration 4876, loss = 0.00538953\n",
      "Iteration 4877, loss = 0.00538797\n",
      "Iteration 4878, loss = 0.00538642\n",
      "Iteration 4879, loss = 0.00538487\n",
      "Iteration 4880, loss = 0.00538355\n",
      "Iteration 4881, loss = 0.00538292\n",
      "Iteration 4882, loss = 0.00538080\n",
      "Iteration 4883, loss = 0.00537942\n",
      "Iteration 4884, loss = 0.00537800\n",
      "Iteration 4885, loss = 0.00537639\n",
      "Iteration 4886, loss = 0.00537528\n",
      "Iteration 4887, loss = 0.00537337\n",
      "Iteration 4888, loss = 0.00537183\n",
      "Iteration 4889, loss = 0.00537008\n",
      "Iteration 4890, loss = 0.00536862\n",
      "Iteration 4891, loss = 0.00536692\n",
      "Iteration 4892, loss = 0.00536512\n",
      "Iteration 4893, loss = 0.00536337\n",
      "Iteration 4894, loss = 0.00536202\n",
      "Iteration 4895, loss = 0.00536023\n",
      "Iteration 4896, loss = 0.00535875\n",
      "Iteration 4897, loss = 0.00535723\n",
      "Iteration 4898, loss = 0.00535558\n",
      "Iteration 4899, loss = 0.00535394\n",
      "Iteration 4900, loss = 0.00535274\n",
      "Iteration 4901, loss = 0.00535086\n",
      "Iteration 4902, loss = 0.00534966\n",
      "Iteration 4903, loss = 0.00534819\n",
      "Iteration 4904, loss = 0.00534662\n",
      "Iteration 4905, loss = 0.00534506\n",
      "Iteration 4906, loss = 0.00534384\n",
      "Iteration 4907, loss = 0.00534216\n",
      "Iteration 4908, loss = 0.00534077\n",
      "Iteration 4909, loss = 0.00533899\n",
      "Iteration 4910, loss = 0.00533766\n",
      "Iteration 4911, loss = 0.00533610\n",
      "Iteration 4912, loss = 0.00533463\n",
      "Iteration 4913, loss = 0.00533310\n",
      "Iteration 4914, loss = 0.00533181\n",
      "Iteration 4915, loss = 0.00533019\n",
      "Iteration 4916, loss = 0.00532876\n",
      "Iteration 4917, loss = 0.00532675\n",
      "Iteration 4918, loss = 0.00532546\n",
      "Iteration 4919, loss = 0.00532416\n",
      "Iteration 4920, loss = 0.00532255\n",
      "Iteration 4921, loss = 0.00532117\n",
      "Iteration 4922, loss = 0.00531962\n",
      "Iteration 4923, loss = 0.00531795\n",
      "Iteration 4924, loss = 0.00531663\n",
      "Iteration 4925, loss = 0.00531529\n",
      "Iteration 4926, loss = 0.00531362\n",
      "Iteration 4927, loss = 0.00531204\n",
      "Iteration 4928, loss = 0.00531112\n",
      "Iteration 4929, loss = 0.00530925\n",
      "Iteration 4930, loss = 0.00530787\n",
      "Iteration 4931, loss = 0.00530627\n",
      "Iteration 4932, loss = 0.00530475\n",
      "Iteration 4933, loss = 0.00530349\n",
      "Iteration 4934, loss = 0.00530222\n",
      "Iteration 4935, loss = 0.00530044\n",
      "Iteration 4936, loss = 0.00529870\n",
      "Iteration 4937, loss = 0.00529772\n",
      "Iteration 4938, loss = 0.00529600\n",
      "Iteration 4939, loss = 0.00529442\n",
      "Iteration 4940, loss = 0.00529291\n",
      "Iteration 4941, loss = 0.00529070\n",
      "Iteration 4942, loss = 0.00528992\n",
      "Iteration 4943, loss = 0.00528791\n",
      "Iteration 4944, loss = 0.00528635\n",
      "Iteration 4945, loss = 0.00528459\n",
      "Iteration 4946, loss = 0.00528324\n",
      "Iteration 4947, loss = 0.00528179\n",
      "Iteration 4948, loss = 0.00528033\n",
      "Iteration 4949, loss = 0.00527922\n",
      "Iteration 4950, loss = 0.00527810\n",
      "Iteration 4951, loss = 0.00527708\n",
      "Iteration 4952, loss = 0.00527580\n",
      "Iteration 4953, loss = 0.00527429\n",
      "Iteration 4954, loss = 0.00527292\n",
      "Iteration 4955, loss = 0.00527148\n",
      "Iteration 4956, loss = 0.00527022\n",
      "Iteration 4957, loss = 0.00526851\n",
      "Iteration 4958, loss = 0.00526740\n",
      "Iteration 4959, loss = 0.00526566\n",
      "Iteration 4960, loss = 0.00526431\n",
      "Iteration 4961, loss = 0.00526299\n",
      "Iteration 4962, loss = 0.00526144\n",
      "Iteration 4963, loss = 0.00526008\n",
      "Iteration 4964, loss = 0.00525864\n",
      "Iteration 4965, loss = 0.00525740\n",
      "Iteration 4966, loss = 0.00525589\n",
      "Iteration 4967, loss = 0.00525458\n",
      "Iteration 4968, loss = 0.00525311\n",
      "Iteration 4969, loss = 0.00525143\n",
      "Iteration 4970, loss = 0.00524995\n",
      "Iteration 4971, loss = 0.00524919\n",
      "Iteration 4972, loss = 0.00524688\n",
      "Iteration 4973, loss = 0.00524564\n",
      "Iteration 4974, loss = 0.00524424\n",
      "Iteration 4975, loss = 0.00524266\n",
      "Iteration 4976, loss = 0.00524117\n",
      "Iteration 4977, loss = 0.00523986\n",
      "Iteration 4978, loss = 0.00523847\n",
      "Iteration 4979, loss = 0.00523706\n",
      "Iteration 4980, loss = 0.00523560\n",
      "Iteration 4981, loss = 0.00523423\n",
      "Iteration 4982, loss = 0.00523315\n",
      "Iteration 4983, loss = 0.00523232\n",
      "Iteration 4984, loss = 0.00523058\n",
      "Iteration 4985, loss = 0.00522923\n",
      "Iteration 4986, loss = 0.00522798\n",
      "Iteration 4987, loss = 0.00522691\n",
      "Iteration 4988, loss = 0.00522514\n",
      "Iteration 4989, loss = 0.00522379\n",
      "Iteration 4990, loss = 0.00522226\n",
      "Iteration 4991, loss = 0.00522165\n",
      "Iteration 4992, loss = 0.00521995\n",
      "Iteration 4993, loss = 0.00521886\n",
      "Iteration 4994, loss = 0.00521750\n",
      "Iteration 4995, loss = 0.00521595\n",
      "Iteration 4996, loss = 0.00521460\n",
      "Iteration 4997, loss = 0.00521351\n",
      "Iteration 4998, loss = 0.00521197\n",
      "Iteration 4999, loss = 0.00521082\n",
      "Iteration 5000, loss = 0.00520911\n",
      "Iteration 5001, loss = 0.00520765\n",
      "Iteration 5002, loss = 0.00520629\n",
      "Iteration 5003, loss = 0.00520491\n",
      "Iteration 5004, loss = 0.00520361\n",
      "Iteration 5005, loss = 0.00520231\n",
      "Iteration 5006, loss = 0.00520139\n",
      "Iteration 5007, loss = 0.00519966\n",
      "Iteration 5008, loss = 0.00519843\n",
      "Iteration 5009, loss = 0.00519713\n",
      "Iteration 5010, loss = 0.00519591\n",
      "Iteration 5011, loss = 0.00519469\n",
      "Iteration 5012, loss = 0.00519352\n",
      "Iteration 5013, loss = 0.00519238\n",
      "Iteration 5014, loss = 0.00519078\n",
      "Iteration 5015, loss = 0.00518904\n",
      "Iteration 5016, loss = 0.00518778\n",
      "Iteration 5017, loss = 0.00518628\n",
      "Iteration 5018, loss = 0.00518470\n",
      "Iteration 5019, loss = 0.00518342\n",
      "Iteration 5020, loss = 0.00518182\n",
      "Iteration 5021, loss = 0.00518073\n",
      "Iteration 5022, loss = 0.00517914\n",
      "Iteration 5023, loss = 0.00517792\n",
      "Iteration 5024, loss = 0.00517668\n",
      "Iteration 5025, loss = 0.00517546\n",
      "Iteration 5026, loss = 0.00517418\n",
      "Iteration 5027, loss = 0.00517304\n",
      "Iteration 5028, loss = 0.00517263\n",
      "Iteration 5029, loss = 0.00517140\n",
      "Iteration 5030, loss = 0.00516976\n",
      "Iteration 5031, loss = 0.00516838\n",
      "Iteration 5032, loss = 0.00516715\n",
      "Iteration 5033, loss = 0.00516597\n",
      "Iteration 5034, loss = 0.00516458\n",
      "Iteration 5035, loss = 0.00516332\n",
      "Iteration 5036, loss = 0.00516198\n",
      "Iteration 5037, loss = 0.00516072\n",
      "Iteration 5038, loss = 0.00515907\n",
      "Iteration 5039, loss = 0.00515767\n",
      "Iteration 5040, loss = 0.00515631\n",
      "Iteration 5041, loss = 0.00515496\n",
      "Iteration 5042, loss = 0.00515328\n",
      "Iteration 5043, loss = 0.00515255\n",
      "Iteration 5044, loss = 0.00515062\n",
      "Iteration 5045, loss = 0.00514931\n",
      "Iteration 5046, loss = 0.00514773\n",
      "Iteration 5047, loss = 0.00514622\n",
      "Iteration 5048, loss = 0.00514490\n",
      "Iteration 5049, loss = 0.00514334\n",
      "Iteration 5050, loss = 0.00514206\n",
      "Iteration 5051, loss = 0.00514089\n",
      "Iteration 5052, loss = 0.00513955\n",
      "Iteration 5053, loss = 0.00513770\n",
      "Iteration 5054, loss = 0.00513634\n",
      "Iteration 5055, loss = 0.00513512\n",
      "Iteration 5056, loss = 0.00513379\n",
      "Iteration 5057, loss = 0.00513249\n",
      "Iteration 5058, loss = 0.00513110\n",
      "Iteration 5059, loss = 0.00512974\n",
      "Iteration 5060, loss = 0.00512832\n",
      "Iteration 5061, loss = 0.00512701\n",
      "Iteration 5062, loss = 0.00512556\n",
      "Iteration 5063, loss = 0.00512420\n",
      "Iteration 5064, loss = 0.00512299\n",
      "Iteration 5065, loss = 0.00512177\n",
      "Iteration 5066, loss = 0.00512032\n",
      "Iteration 5067, loss = 0.00511922\n",
      "Iteration 5068, loss = 0.00511782\n",
      "Iteration 5069, loss = 0.00511639\n",
      "Iteration 5070, loss = 0.00511508\n",
      "Iteration 5071, loss = 0.00511378\n",
      "Iteration 5072, loss = 0.00511234\n",
      "Iteration 5073, loss = 0.00511118\n",
      "Iteration 5074, loss = 0.00510992\n",
      "Iteration 5075, loss = 0.00510877\n",
      "Iteration 5076, loss = 0.00510761\n",
      "Iteration 5077, loss = 0.00510623\n",
      "Iteration 5078, loss = 0.00510531\n",
      "Iteration 5079, loss = 0.00510325\n",
      "Iteration 5080, loss = 0.00510142\n",
      "Iteration 5081, loss = 0.00509963\n",
      "Iteration 5082, loss = 0.00509898\n",
      "Iteration 5083, loss = 0.00509711\n",
      "Iteration 5084, loss = 0.00509526\n",
      "Iteration 5085, loss = 0.00509371\n",
      "Iteration 5086, loss = 0.00509258\n",
      "Iteration 5087, loss = 0.00509087\n",
      "Iteration 5088, loss = 0.00508945\n",
      "Iteration 5089, loss = 0.00508791\n",
      "Iteration 5090, loss = 0.00508654\n",
      "Iteration 5091, loss = 0.00508551\n",
      "Iteration 5092, loss = 0.00508378\n",
      "Iteration 5093, loss = 0.00508192\n",
      "Iteration 5094, loss = 0.00508065\n",
      "Iteration 5095, loss = 0.00507925\n",
      "Iteration 5096, loss = 0.00507798\n",
      "Iteration 5097, loss = 0.00507642\n",
      "Iteration 5098, loss = 0.00507483\n",
      "Iteration 5099, loss = 0.00507355\n",
      "Iteration 5100, loss = 0.00507233\n",
      "Iteration 5101, loss = 0.00507090\n",
      "Iteration 5102, loss = 0.00506987\n",
      "Iteration 5103, loss = 0.00506864\n",
      "Iteration 5104, loss = 0.00506815\n",
      "Iteration 5105, loss = 0.00506597\n",
      "Iteration 5106, loss = 0.00506467\n",
      "Iteration 5107, loss = 0.00506338\n",
      "Iteration 5108, loss = 0.00506208\n",
      "Iteration 5109, loss = 0.00506066\n",
      "Iteration 5110, loss = 0.00505936\n",
      "Iteration 5111, loss = 0.00505822\n",
      "Iteration 5112, loss = 0.00505664\n",
      "Iteration 5113, loss = 0.00505540\n",
      "Iteration 5114, loss = 0.00505359\n",
      "Iteration 5115, loss = 0.00505208\n",
      "Iteration 5116, loss = 0.00505101\n",
      "Iteration 5117, loss = 0.00505003\n",
      "Iteration 5118, loss = 0.00504825\n",
      "Iteration 5119, loss = 0.00504726\n",
      "Iteration 5120, loss = 0.00504566\n",
      "Iteration 5121, loss = 0.00504443\n",
      "Iteration 5122, loss = 0.00504287\n",
      "Iteration 5123, loss = 0.00504276\n",
      "Iteration 5124, loss = 0.00504063\n",
      "Iteration 5125, loss = 0.00503897\n",
      "Iteration 5126, loss = 0.00503846\n",
      "Iteration 5127, loss = 0.00503643\n",
      "Iteration 5128, loss = 0.00503487\n",
      "Iteration 5129, loss = 0.00503405\n",
      "Iteration 5130, loss = 0.00503212\n",
      "Iteration 5131, loss = 0.00503110\n",
      "Iteration 5132, loss = 0.00502940\n",
      "Iteration 5133, loss = 0.00502773\n",
      "Iteration 5134, loss = 0.00502641\n",
      "Iteration 5135, loss = 0.00502480\n",
      "Iteration 5136, loss = 0.00502318\n",
      "Iteration 5137, loss = 0.00502168\n",
      "Iteration 5138, loss = 0.00502053\n",
      "Iteration 5139, loss = 0.00501885\n",
      "Iteration 5140, loss = 0.00501800\n",
      "Iteration 5141, loss = 0.00501622\n",
      "Iteration 5142, loss = 0.00501484\n",
      "Iteration 5143, loss = 0.00501351\n",
      "Iteration 5144, loss = 0.00501207\n",
      "Iteration 5145, loss = 0.00501091\n",
      "Iteration 5146, loss = 0.00500938\n",
      "Iteration 5147, loss = 0.00500791\n",
      "Iteration 5148, loss = 0.00500645\n",
      "Iteration 5149, loss = 0.00500511\n",
      "Iteration 5150, loss = 0.00500375\n",
      "Iteration 5151, loss = 0.00500279\n",
      "Iteration 5152, loss = 0.00500114\n",
      "Iteration 5153, loss = 0.00499966\n",
      "Iteration 5154, loss = 0.00499886\n",
      "Iteration 5155, loss = 0.00499697\n",
      "Iteration 5156, loss = 0.00499571\n",
      "Iteration 5157, loss = 0.00499436\n",
      "Iteration 5158, loss = 0.00499313\n",
      "Iteration 5159, loss = 0.00499195\n",
      "Iteration 5160, loss = 0.00499062\n",
      "Iteration 5161, loss = 0.00498921\n",
      "Iteration 5162, loss = 0.00498807\n",
      "Iteration 5163, loss = 0.00498692\n",
      "Iteration 5164, loss = 0.00498527\n",
      "Iteration 5165, loss = 0.00498419\n",
      "Iteration 5166, loss = 0.00498278\n",
      "Iteration 5167, loss = 0.00498143\n",
      "Iteration 5168, loss = 0.00498022\n",
      "Iteration 5169, loss = 0.00497904\n",
      "Iteration 5170, loss = 0.00497786\n",
      "Iteration 5171, loss = 0.00497692\n",
      "Iteration 5172, loss = 0.00497567\n",
      "Iteration 5173, loss = 0.00497409\n",
      "Iteration 5174, loss = 0.00497272\n",
      "Iteration 5175, loss = 0.00497088\n",
      "Iteration 5176, loss = 0.00497009\n",
      "Iteration 5177, loss = 0.00496868\n",
      "Iteration 5178, loss = 0.00496739\n",
      "Iteration 5179, loss = 0.00496621\n",
      "Iteration 5180, loss = 0.00496468\n",
      "Iteration 5181, loss = 0.00496420\n",
      "Iteration 5182, loss = 0.00496205\n",
      "Iteration 5183, loss = 0.00496116\n",
      "Iteration 5184, loss = 0.00495948\n",
      "Iteration 5185, loss = 0.00495806\n",
      "Iteration 5186, loss = 0.00495656\n",
      "Iteration 5187, loss = 0.00495543\n",
      "Iteration 5188, loss = 0.00495369\n",
      "Iteration 5189, loss = 0.00495261\n",
      "Iteration 5190, loss = 0.00495089\n",
      "Iteration 5191, loss = 0.00494965\n",
      "Iteration 5192, loss = 0.00494834\n",
      "Iteration 5193, loss = 0.00494710\n",
      "Iteration 5194, loss = 0.00494563\n",
      "Iteration 5195, loss = 0.00494441\n",
      "Iteration 5196, loss = 0.00494290\n",
      "Iteration 5197, loss = 0.00494168\n",
      "Iteration 5198, loss = 0.00494044\n",
      "Iteration 5199, loss = 0.00493913\n",
      "Iteration 5200, loss = 0.00493795\n",
      "Iteration 5201, loss = 0.00493702\n",
      "Iteration 5202, loss = 0.00493519\n",
      "Iteration 5203, loss = 0.00493417\n",
      "Iteration 5204, loss = 0.00493253\n",
      "Iteration 5205, loss = 0.00493133\n",
      "Iteration 5206, loss = 0.00492995\n",
      "Iteration 5207, loss = 0.00492873\n",
      "Iteration 5208, loss = 0.00492743\n",
      "Iteration 5209, loss = 0.00492613\n",
      "Iteration 5210, loss = 0.00492472\n",
      "Iteration 5211, loss = 0.00492331\n",
      "Iteration 5212, loss = 0.00492225\n",
      "Iteration 5213, loss = 0.00492110\n",
      "Iteration 5214, loss = 0.00491995\n",
      "Iteration 5215, loss = 0.00491857\n",
      "Iteration 5216, loss = 0.00491787\n",
      "Iteration 5217, loss = 0.00491665\n",
      "Iteration 5218, loss = 0.00491520\n",
      "Iteration 5219, loss = 0.00491426\n",
      "Iteration 5220, loss = 0.00491271\n",
      "Iteration 5221, loss = 0.00491118\n",
      "Iteration 5222, loss = 0.00491005\n",
      "Iteration 5223, loss = 0.00490864\n",
      "Iteration 5224, loss = 0.00490739\n",
      "Iteration 5225, loss = 0.00490606\n",
      "Iteration 5226, loss = 0.00490539\n",
      "Iteration 5227, loss = 0.00490391\n",
      "Iteration 5228, loss = 0.00490261\n",
      "Iteration 5229, loss = 0.00490136\n",
      "Iteration 5230, loss = 0.00490013\n",
      "Iteration 5231, loss = 0.00489900\n",
      "Iteration 5232, loss = 0.00489820\n",
      "Iteration 5233, loss = 0.00489693\n",
      "Iteration 5234, loss = 0.00489573\n",
      "Iteration 5235, loss = 0.00489455\n",
      "Iteration 5236, loss = 0.00489375\n",
      "Iteration 5237, loss = 0.00489241\n",
      "Iteration 5238, loss = 0.00489102\n",
      "Iteration 5239, loss = 0.00488980\n",
      "Iteration 5240, loss = 0.00488874\n",
      "Iteration 5241, loss = 0.00488709\n",
      "Iteration 5242, loss = 0.00488601\n",
      "Iteration 5243, loss = 0.00488457\n",
      "Iteration 5244, loss = 0.00488373\n",
      "Iteration 5245, loss = 0.00488214\n",
      "Iteration 5246, loss = 0.00488115\n",
      "Iteration 5247, loss = 0.00487987\n",
      "Iteration 5248, loss = 0.00487886\n",
      "Iteration 5249, loss = 0.00487773\n",
      "Iteration 5250, loss = 0.00487600\n",
      "Iteration 5251, loss = 0.00487459\n",
      "Iteration 5252, loss = 0.00487325\n",
      "Iteration 5253, loss = 0.00487195\n",
      "Iteration 5254, loss = 0.00487090\n",
      "Iteration 5255, loss = 0.00486941\n",
      "Iteration 5256, loss = 0.00486815\n",
      "Iteration 5257, loss = 0.00486671\n",
      "Iteration 5258, loss = 0.00486534\n",
      "Iteration 5259, loss = 0.00486431\n",
      "Iteration 5260, loss = 0.00486287\n",
      "Iteration 5261, loss = 0.00486150\n",
      "Iteration 5262, loss = 0.00486028\n",
      "Iteration 5263, loss = 0.00485888\n",
      "Iteration 5264, loss = 0.00485776\n",
      "Iteration 5265, loss = 0.00485643\n",
      "Iteration 5266, loss = 0.00485568\n",
      "Iteration 5267, loss = 0.00485419\n",
      "Iteration 5268, loss = 0.00485268\n",
      "Iteration 5269, loss = 0.00485144\n",
      "Iteration 5270, loss = 0.00485008\n",
      "Iteration 5271, loss = 0.00484904\n",
      "Iteration 5272, loss = 0.00484771\n",
      "Iteration 5273, loss = 0.00484729\n",
      "Iteration 5274, loss = 0.00484563\n",
      "Iteration 5275, loss = 0.00484472\n",
      "Iteration 5276, loss = 0.00484457\n",
      "Iteration 5277, loss = 0.00484272\n",
      "Iteration 5278, loss = 0.00484146\n",
      "Iteration 5279, loss = 0.00484029\n",
      "Iteration 5280, loss = 0.00483924\n",
      "Iteration 5281, loss = 0.00483782\n",
      "Iteration 5282, loss = 0.00483671\n",
      "Iteration 5283, loss = 0.00483553\n",
      "Iteration 5284, loss = 0.00483435\n",
      "Iteration 5285, loss = 0.00483302\n",
      "Iteration 5286, loss = 0.00483179\n",
      "Iteration 5287, loss = 0.00483041\n",
      "Iteration 5288, loss = 0.00482918\n",
      "Iteration 5289, loss = 0.00482784\n",
      "Iteration 5290, loss = 0.00482650\n",
      "Iteration 5291, loss = 0.00482537\n",
      "Iteration 5292, loss = 0.00482407\n",
      "Iteration 5293, loss = 0.00482279\n",
      "Iteration 5294, loss = 0.00482176\n",
      "Iteration 5295, loss = 0.00482039\n",
      "Iteration 5296, loss = 0.00481928\n",
      "Iteration 5297, loss = 0.00481779\n",
      "Iteration 5298, loss = 0.00481685\n",
      "Iteration 5299, loss = 0.00481552\n",
      "Iteration 5300, loss = 0.00481415\n",
      "Iteration 5301, loss = 0.00481301\n",
      "Iteration 5302, loss = 0.00481194\n",
      "Iteration 5303, loss = 0.00481041\n",
      "Iteration 5304, loss = 0.00480987\n",
      "Iteration 5305, loss = 0.00480782\n",
      "Iteration 5306, loss = 0.00480651\n",
      "Iteration 5307, loss = 0.00480521\n",
      "Iteration 5308, loss = 0.00480403\n",
      "Iteration 5309, loss = 0.00480254\n",
      "Iteration 5310, loss = 0.00480166\n",
      "Iteration 5311, loss = 0.00480005\n",
      "Iteration 5312, loss = 0.00479904\n",
      "Iteration 5313, loss = 0.00479779\n",
      "Iteration 5314, loss = 0.00479654\n",
      "Iteration 5315, loss = 0.00479543\n",
      "Iteration 5316, loss = 0.00479424\n",
      "Iteration 5317, loss = 0.00479372\n",
      "Iteration 5318, loss = 0.00479157\n",
      "Iteration 5319, loss = 0.00479067\n",
      "Iteration 5320, loss = 0.00478923\n",
      "Iteration 5321, loss = 0.00478791\n",
      "Iteration 5322, loss = 0.00478635\n",
      "Iteration 5323, loss = 0.00478513\n",
      "Iteration 5324, loss = 0.00478371\n",
      "Iteration 5325, loss = 0.00478258\n",
      "Iteration 5326, loss = 0.00478120\n",
      "Iteration 5327, loss = 0.00477976\n",
      "Iteration 5328, loss = 0.00477860\n",
      "Iteration 5329, loss = 0.00477758\n",
      "Iteration 5330, loss = 0.00477619\n",
      "Iteration 5331, loss = 0.00477495\n",
      "Iteration 5332, loss = 0.00477353\n",
      "Iteration 5333, loss = 0.00477253\n",
      "Iteration 5334, loss = 0.00477103\n",
      "Iteration 5335, loss = 0.00476967\n",
      "Iteration 5336, loss = 0.00476846\n",
      "Iteration 5337, loss = 0.00476728\n",
      "Iteration 5338, loss = 0.00476593\n",
      "Iteration 5339, loss = 0.00476466\n",
      "Iteration 5340, loss = 0.00476350\n",
      "Iteration 5341, loss = 0.00476228\n",
      "Iteration 5342, loss = 0.00476133\n",
      "Iteration 5343, loss = 0.00475980\n",
      "Iteration 5344, loss = 0.00475887\n",
      "Iteration 5345, loss = 0.00475765\n",
      "Iteration 5346, loss = 0.00475655\n",
      "Iteration 5347, loss = 0.00475544\n",
      "Iteration 5348, loss = 0.00475403\n",
      "Iteration 5349, loss = 0.00475300\n",
      "Iteration 5350, loss = 0.00475174\n",
      "Iteration 5351, loss = 0.00475096\n",
      "Iteration 5352, loss = 0.00474949\n",
      "Iteration 5353, loss = 0.00474812\n",
      "Iteration 5354, loss = 0.00474732\n",
      "Iteration 5355, loss = 0.00474629\n",
      "Iteration 5356, loss = 0.00474443\n",
      "Iteration 5357, loss = 0.00474294\n",
      "Iteration 5358, loss = 0.00474150\n",
      "Iteration 5359, loss = 0.00474045\n",
      "Iteration 5360, loss = 0.00473887\n",
      "Iteration 5361, loss = 0.00473770\n",
      "Iteration 5362, loss = 0.00473644\n",
      "Iteration 5363, loss = 0.00473506\n",
      "Iteration 5364, loss = 0.00473399\n",
      "Iteration 5365, loss = 0.00473274\n",
      "Iteration 5366, loss = 0.00473159\n",
      "Iteration 5367, loss = 0.00473064\n",
      "Iteration 5368, loss = 0.00472905\n",
      "Iteration 5369, loss = 0.00472784\n",
      "Iteration 5370, loss = 0.00472663\n",
      "Iteration 5371, loss = 0.00472563\n",
      "Iteration 5372, loss = 0.00472439\n",
      "Iteration 5373, loss = 0.00472318\n",
      "Iteration 5374, loss = 0.00472202\n",
      "Iteration 5375, loss = 0.00472086\n",
      "Iteration 5376, loss = 0.00471960\n",
      "Iteration 5377, loss = 0.00471846\n",
      "Iteration 5378, loss = 0.00471781\n",
      "Iteration 5379, loss = 0.00471620\n",
      "Iteration 5380, loss = 0.00471483\n",
      "Iteration 5381, loss = 0.00471357\n",
      "Iteration 5382, loss = 0.00471224\n",
      "Iteration 5383, loss = 0.00471096\n",
      "Iteration 5384, loss = 0.00471016\n",
      "Iteration 5385, loss = 0.00470894\n",
      "Iteration 5386, loss = 0.00470762\n",
      "Iteration 5387, loss = 0.00470645\n",
      "Iteration 5388, loss = 0.00470562\n",
      "Iteration 5389, loss = 0.00470466\n",
      "Iteration 5390, loss = 0.00470283\n",
      "Iteration 5391, loss = 0.00470159\n",
      "Iteration 5392, loss = 0.00470047\n",
      "Iteration 5393, loss = 0.00469930\n",
      "Iteration 5394, loss = 0.00469815\n",
      "Iteration 5395, loss = 0.00469718\n",
      "Iteration 5396, loss = 0.00469613\n",
      "Iteration 5397, loss = 0.00469485\n",
      "Iteration 5398, loss = 0.00469384\n",
      "Iteration 5399, loss = 0.00469275\n",
      "Iteration 5400, loss = 0.00469121\n",
      "Iteration 5401, loss = 0.00468980\n",
      "Iteration 5402, loss = 0.00468906\n",
      "Iteration 5403, loss = 0.00468757\n",
      "Iteration 5404, loss = 0.00468618\n",
      "Iteration 5405, loss = 0.00468488\n",
      "Iteration 5406, loss = 0.00468436\n",
      "Iteration 5407, loss = 0.00468237\n",
      "Iteration 5408, loss = 0.00468104\n",
      "Iteration 5409, loss = 0.00467975\n",
      "Iteration 5410, loss = 0.00467812\n",
      "Iteration 5411, loss = 0.00467716\n",
      "Iteration 5412, loss = 0.00467607\n",
      "Iteration 5413, loss = 0.00467618\n",
      "Iteration 5414, loss = 0.00467406\n",
      "Iteration 5415, loss = 0.00467269\n",
      "Iteration 5416, loss = 0.00467127\n",
      "Iteration 5417, loss = 0.00467027\n",
      "Iteration 5418, loss = 0.00466926\n",
      "Iteration 5419, loss = 0.00466802\n",
      "Iteration 5420, loss = 0.00466665\n",
      "Iteration 5421, loss = 0.00466546\n",
      "Iteration 5422, loss = 0.00466428\n",
      "Iteration 5423, loss = 0.00466319\n",
      "Iteration 5424, loss = 0.00466210\n",
      "Iteration 5425, loss = 0.00466105\n",
      "Iteration 5426, loss = 0.00465966\n",
      "Iteration 5427, loss = 0.00465831\n",
      "Iteration 5428, loss = 0.00465707\n",
      "Iteration 5429, loss = 0.00465607\n",
      "Iteration 5430, loss = 0.00465469\n",
      "Iteration 5431, loss = 0.00465364\n",
      "Iteration 5432, loss = 0.00465237\n",
      "Iteration 5433, loss = 0.00465125\n",
      "Iteration 5434, loss = 0.00465003\n",
      "Iteration 5435, loss = 0.00464866\n",
      "Iteration 5436, loss = 0.00464754\n",
      "Iteration 5437, loss = 0.00464658\n",
      "Iteration 5438, loss = 0.00464520\n",
      "Iteration 5439, loss = 0.00464398\n",
      "Iteration 5440, loss = 0.00464282\n",
      "Iteration 5441, loss = 0.00464162\n",
      "Iteration 5442, loss = 0.00464041\n",
      "Iteration 5443, loss = 0.00463909\n",
      "Iteration 5444, loss = 0.00463782\n",
      "Iteration 5445, loss = 0.00463669\n",
      "Iteration 5446, loss = 0.00463541\n",
      "Iteration 5447, loss = 0.00463402\n",
      "Iteration 5448, loss = 0.00463261\n",
      "Iteration 5449, loss = 0.00463178\n",
      "Iteration 5450, loss = 0.00463063\n",
      "Iteration 5451, loss = 0.00462925\n",
      "Iteration 5452, loss = 0.00462817\n",
      "Iteration 5453, loss = 0.00462711\n",
      "Iteration 5454, loss = 0.00462628\n",
      "Iteration 5455, loss = 0.00462483\n",
      "Iteration 5456, loss = 0.00462395\n",
      "Iteration 5457, loss = 0.00462267\n",
      "Iteration 5458, loss = 0.00462150\n",
      "Iteration 5459, loss = 0.00462050\n",
      "Iteration 5460, loss = 0.00461960\n",
      "Iteration 5461, loss = 0.00461867\n",
      "Iteration 5462, loss = 0.00461756\n",
      "Iteration 5463, loss = 0.00461632\n",
      "Iteration 5464, loss = 0.00461534\n",
      "Iteration 5465, loss = 0.00461418\n",
      "Iteration 5466, loss = 0.00461310\n",
      "Iteration 5467, loss = 0.00461204\n",
      "Iteration 5468, loss = 0.00461088\n",
      "Iteration 5469, loss = 0.00461035\n",
      "Iteration 5470, loss = 0.00460890\n",
      "Iteration 5471, loss = 0.00460777\n",
      "Iteration 5472, loss = 0.00460695\n",
      "Iteration 5473, loss = 0.00460594\n",
      "Iteration 5474, loss = 0.00460480\n",
      "Iteration 5475, loss = 0.00460395\n",
      "Iteration 5476, loss = 0.00460279\n",
      "Iteration 5477, loss = 0.00460136\n",
      "Iteration 5478, loss = 0.00460020\n",
      "Iteration 5479, loss = 0.00459939\n",
      "Iteration 5480, loss = 0.00459808\n",
      "Iteration 5481, loss = 0.00459695\n",
      "Iteration 5482, loss = 0.00459601\n",
      "Iteration 5483, loss = 0.00459543\n",
      "Iteration 5484, loss = 0.00459386\n",
      "Iteration 5485, loss = 0.00459278\n",
      "Iteration 5486, loss = 0.00459169\n",
      "Iteration 5487, loss = 0.00459062\n",
      "Iteration 5488, loss = 0.00458957\n",
      "Iteration 5489, loss = 0.00458843\n",
      "Iteration 5490, loss = 0.00458742\n",
      "Iteration 5491, loss = 0.00458650\n",
      "Iteration 5492, loss = 0.00458579\n",
      "Iteration 5493, loss = 0.00458454\n",
      "Iteration 5494, loss = 0.00458364\n",
      "Iteration 5495, loss = 0.00458229\n",
      "Iteration 5496, loss = 0.00458116\n",
      "Iteration 5497, loss = 0.00458007\n",
      "Iteration 5498, loss = 0.00457877\n",
      "Iteration 5499, loss = 0.00457768\n",
      "Iteration 5500, loss = 0.00457614\n",
      "Iteration 5501, loss = 0.00457510\n",
      "Iteration 5502, loss = 0.00457413\n",
      "Iteration 5503, loss = 0.00457281\n",
      "Iteration 5504, loss = 0.00457149\n",
      "Iteration 5505, loss = 0.00457052\n",
      "Iteration 5506, loss = 0.00456952\n",
      "Iteration 5507, loss = 0.00456823\n",
      "Iteration 5508, loss = 0.00456720\n",
      "Iteration 5509, loss = 0.00456644\n",
      "Iteration 5510, loss = 0.00456522\n",
      "Iteration 5511, loss = 0.00456424\n",
      "Iteration 5512, loss = 0.00456336\n",
      "Iteration 5513, loss = 0.00456215\n",
      "Iteration 5514, loss = 0.00456115\n",
      "Iteration 5515, loss = 0.00456021\n",
      "Iteration 5516, loss = 0.00455965\n",
      "Iteration 5517, loss = 0.00455837\n",
      "Iteration 5518, loss = 0.00455734\n",
      "Iteration 5519, loss = 0.00455623\n",
      "Iteration 5520, loss = 0.00455529\n",
      "Iteration 5521, loss = 0.00455418\n",
      "Iteration 5522, loss = 0.00455328\n",
      "Iteration 5523, loss = 0.00455208\n",
      "Iteration 5524, loss = 0.00455085\n",
      "Iteration 5525, loss = 0.00454951\n",
      "Iteration 5526, loss = 0.00454860\n",
      "Iteration 5527, loss = 0.00454744\n",
      "Iteration 5528, loss = 0.00454632\n",
      "Iteration 5529, loss = 0.00454515\n",
      "Iteration 5530, loss = 0.00454427\n",
      "Iteration 5531, loss = 0.00454271\n",
      "Iteration 5532, loss = 0.00454182\n",
      "Iteration 5533, loss = 0.00454015\n",
      "Iteration 5534, loss = 0.00453920\n",
      "Iteration 5535, loss = 0.00453789\n",
      "Iteration 5536, loss = 0.00453687\n",
      "Iteration 5537, loss = 0.00453563\n",
      "Iteration 5538, loss = 0.00453452\n",
      "Iteration 5539, loss = 0.00453422\n",
      "Iteration 5540, loss = 0.00453225\n",
      "Iteration 5541, loss = 0.00453084\n",
      "Iteration 5542, loss = 0.00452977\n",
      "Iteration 5543, loss = 0.00452874\n",
      "Iteration 5544, loss = 0.00452717\n",
      "Iteration 5545, loss = 0.00452605\n",
      "Iteration 5546, loss = 0.00452480\n",
      "Iteration 5547, loss = 0.00452345\n",
      "Iteration 5548, loss = 0.00452219\n",
      "Iteration 5549, loss = 0.00452087\n",
      "Iteration 5550, loss = 0.00452045\n",
      "Iteration 5551, loss = 0.00451853\n",
      "Iteration 5552, loss = 0.00451766\n",
      "Iteration 5553, loss = 0.00451623\n",
      "Iteration 5554, loss = 0.00451500\n",
      "Iteration 5555, loss = 0.00451369\n",
      "Iteration 5556, loss = 0.00451318\n",
      "Iteration 5557, loss = 0.00451148\n",
      "Iteration 5558, loss = 0.00451050\n",
      "Iteration 5559, loss = 0.00450925\n",
      "Iteration 5560, loss = 0.00450813\n",
      "Iteration 5561, loss = 0.00450707\n",
      "Iteration 5562, loss = 0.00450595\n",
      "Iteration 5563, loss = 0.00450484\n",
      "Iteration 5564, loss = 0.00450367\n",
      "Iteration 5565, loss = 0.00450266\n",
      "Iteration 5566, loss = 0.00450124\n",
      "Iteration 5567, loss = 0.00450037\n",
      "Iteration 5568, loss = 0.00449891\n",
      "Iteration 5569, loss = 0.00449781\n",
      "Iteration 5570, loss = 0.00449665\n",
      "Iteration 5571, loss = 0.00449550\n",
      "Iteration 5572, loss = 0.00449455\n",
      "Iteration 5573, loss = 0.00449379\n",
      "Iteration 5574, loss = 0.00449252\n",
      "Iteration 5575, loss = 0.00449108\n",
      "Iteration 5576, loss = 0.00449031\n",
      "Iteration 5577, loss = 0.00448879\n",
      "Iteration 5578, loss = 0.00448842\n",
      "Iteration 5579, loss = 0.00448654\n",
      "Iteration 5580, loss = 0.00448539\n",
      "Iteration 5581, loss = 0.00448429\n",
      "Iteration 5582, loss = 0.00448313\n",
      "Iteration 5583, loss = 0.00448203\n",
      "Iteration 5584, loss = 0.00448109\n",
      "Iteration 5585, loss = 0.00448022\n",
      "Iteration 5586, loss = 0.00447934\n",
      "Iteration 5587, loss = 0.00447844\n",
      "Iteration 5588, loss = 0.00447766\n",
      "Iteration 5589, loss = 0.00447681\n",
      "Iteration 5590, loss = 0.00447559\n",
      "Iteration 5591, loss = 0.00447459\n",
      "Iteration 5592, loss = 0.00447354\n",
      "Iteration 5593, loss = 0.00447267\n",
      "Iteration 5594, loss = 0.00447185\n",
      "Iteration 5595, loss = 0.00447066\n",
      "Iteration 5596, loss = 0.00446976\n",
      "Iteration 5597, loss = 0.00446902\n",
      "Iteration 5598, loss = 0.00446846\n",
      "Iteration 5599, loss = 0.00446664\n",
      "Iteration 5600, loss = 0.00446530\n",
      "Iteration 5601, loss = 0.00446462\n",
      "Iteration 5602, loss = 0.00446375\n",
      "Iteration 5603, loss = 0.00446231\n",
      "Iteration 5604, loss = 0.00446121\n",
      "Iteration 5605, loss = 0.00446021\n",
      "Iteration 5606, loss = 0.00445914\n",
      "Iteration 5607, loss = 0.00445815\n",
      "Iteration 5608, loss = 0.00445711\n",
      "Iteration 5609, loss = 0.00445616\n",
      "Iteration 5610, loss = 0.00445462\n",
      "Iteration 5611, loss = 0.00445336\n",
      "Iteration 5612, loss = 0.00445229\n",
      "Iteration 5613, loss = 0.00445098\n",
      "Iteration 5614, loss = 0.00444954\n",
      "Iteration 5615, loss = 0.00444826\n",
      "Iteration 5616, loss = 0.00444732\n",
      "Iteration 5617, loss = 0.00444571\n",
      "Iteration 5618, loss = 0.00444467\n",
      "Iteration 5619, loss = 0.00444364\n",
      "Iteration 5620, loss = 0.00444237\n",
      "Iteration 5621, loss = 0.00444109\n",
      "Iteration 5622, loss = 0.00444022\n",
      "Iteration 5623, loss = 0.00443904\n",
      "Iteration 5624, loss = 0.00443798\n",
      "Iteration 5625, loss = 0.00443668\n",
      "Iteration 5626, loss = 0.00443560\n",
      "Iteration 5627, loss = 0.00443451\n",
      "Iteration 5628, loss = 0.00443354\n",
      "Iteration 5629, loss = 0.00443276\n",
      "Iteration 5630, loss = 0.00443169\n",
      "Iteration 5631, loss = 0.00443093\n",
      "Iteration 5632, loss = 0.00442974\n",
      "Iteration 5633, loss = 0.00442848\n",
      "Iteration 5634, loss = 0.00442741\n",
      "Iteration 5635, loss = 0.00442627\n",
      "Iteration 5636, loss = 0.00442530\n",
      "Iteration 5637, loss = 0.00442425\n",
      "Iteration 5638, loss = 0.00442309\n",
      "Iteration 5639, loss = 0.00442180\n",
      "Iteration 5640, loss = 0.00442071\n",
      "Iteration 5641, loss = 0.00441959\n",
      "Iteration 5642, loss = 0.00441865\n",
      "Iteration 5643, loss = 0.00441740\n",
      "Iteration 5644, loss = 0.00441573\n",
      "Iteration 5645, loss = 0.00441464\n",
      "Iteration 5646, loss = 0.00441358\n",
      "Iteration 5647, loss = 0.00441234\n",
      "Iteration 5648, loss = 0.00441132\n",
      "Iteration 5649, loss = 0.00441000\n",
      "Iteration 5650, loss = 0.00440884\n",
      "Iteration 5651, loss = 0.00440781\n",
      "Iteration 5652, loss = 0.00440710\n",
      "Iteration 5653, loss = 0.00440591\n",
      "Iteration 5654, loss = 0.00440479\n",
      "Iteration 5655, loss = 0.00440371\n",
      "Iteration 5656, loss = 0.00440268\n",
      "Iteration 5657, loss = 0.00440163\n",
      "Iteration 5658, loss = 0.00440072\n",
      "Iteration 5659, loss = 0.00439957\n",
      "Iteration 5660, loss = 0.00439854\n",
      "Iteration 5661, loss = 0.00439751\n",
      "Iteration 5662, loss = 0.00439656\n",
      "Iteration 5663, loss = 0.00439553\n",
      "Iteration 5664, loss = 0.00439461\n",
      "Iteration 5665, loss = 0.00439377\n",
      "Iteration 5666, loss = 0.00439271\n",
      "Iteration 5667, loss = 0.00439168\n",
      "Iteration 5668, loss = 0.00439059\n",
      "Iteration 5669, loss = 0.00438962\n",
      "Iteration 5670, loss = 0.00438865\n",
      "Iteration 5671, loss = 0.00438783\n",
      "Iteration 5672, loss = 0.00438672\n",
      "Iteration 5673, loss = 0.00438579\n",
      "Iteration 5674, loss = 0.00438461\n",
      "Iteration 5675, loss = 0.00438375\n",
      "Iteration 5676, loss = 0.00438278\n",
      "Iteration 5677, loss = 0.00438150\n",
      "Iteration 5678, loss = 0.00438067\n",
      "Iteration 5679, loss = 0.00437932\n",
      "Iteration 5680, loss = 0.00437824\n",
      "Iteration 5681, loss = 0.00437718\n",
      "Iteration 5682, loss = 0.00437644\n",
      "Iteration 5683, loss = 0.00437522\n",
      "Iteration 5684, loss = 0.00437444\n",
      "Iteration 5685, loss = 0.00437325\n",
      "Iteration 5686, loss = 0.00437215\n",
      "Iteration 5687, loss = 0.00437120\n",
      "Iteration 5688, loss = 0.00437012\n",
      "Iteration 5689, loss = 0.00436923\n",
      "Iteration 5690, loss = 0.00436822\n",
      "Iteration 5691, loss = 0.00436730\n",
      "Iteration 5692, loss = 0.00436635\n",
      "Iteration 5693, loss = 0.00436530\n",
      "Iteration 5694, loss = 0.00436416\n",
      "Iteration 5695, loss = 0.00436307\n",
      "Iteration 5696, loss = 0.00436198\n",
      "Iteration 5697, loss = 0.00436074\n",
      "Iteration 5698, loss = 0.00435954\n",
      "Iteration 5699, loss = 0.00435905\n",
      "Iteration 5700, loss = 0.00435803\n",
      "Iteration 5701, loss = 0.00435672\n",
      "Iteration 5702, loss = 0.00435566\n",
      "Iteration 5703, loss = 0.00435453\n",
      "Iteration 5704, loss = 0.00435357\n",
      "Iteration 5705, loss = 0.00435281\n",
      "Iteration 5706, loss = 0.00435164\n",
      "Iteration 5707, loss = 0.00435059\n",
      "Iteration 5708, loss = 0.00434973\n",
      "Iteration 5709, loss = 0.00434856\n",
      "Iteration 5710, loss = 0.00434772\n",
      "Iteration 5711, loss = 0.00434655\n",
      "Iteration 5712, loss = 0.00434583\n",
      "Iteration 5713, loss = 0.00434490\n",
      "Iteration 5714, loss = 0.00434331\n",
      "Iteration 5715, loss = 0.00434210\n",
      "Iteration 5716, loss = 0.00434186\n",
      "Iteration 5717, loss = 0.00434023\n",
      "Iteration 5718, loss = 0.00433908\n",
      "Iteration 5719, loss = 0.00433820\n",
      "Iteration 5720, loss = 0.00433700\n",
      "Iteration 5721, loss = 0.00433599\n",
      "Iteration 5722, loss = 0.00433496\n",
      "Iteration 5723, loss = 0.00433394\n",
      "Iteration 5724, loss = 0.00433287\n",
      "Iteration 5725, loss = 0.00433175\n",
      "Iteration 5726, loss = 0.00433076\n",
      "Iteration 5727, loss = 0.00433026\n",
      "Iteration 5728, loss = 0.00432954\n",
      "Iteration 5729, loss = 0.00432810\n",
      "Iteration 5730, loss = 0.00432731\n",
      "Iteration 5731, loss = 0.00432633\n",
      "Iteration 5732, loss = 0.00432657\n",
      "Iteration 5733, loss = 0.00432474\n",
      "Iteration 5734, loss = 0.00432373\n",
      "Iteration 5735, loss = 0.00432257\n",
      "Iteration 5736, loss = 0.00432139\n",
      "Iteration 5737, loss = 0.00432053\n",
      "Iteration 5738, loss = 0.00431947\n",
      "Iteration 5739, loss = 0.00431837\n",
      "Iteration 5740, loss = 0.00431746\n",
      "Iteration 5741, loss = 0.00431651\n",
      "Iteration 5742, loss = 0.00431549\n",
      "Iteration 5743, loss = 0.00431462\n",
      "Iteration 5744, loss = 0.00431371\n",
      "Iteration 5745, loss = 0.00431270\n",
      "Iteration 5746, loss = 0.00431210\n",
      "Iteration 5747, loss = 0.00431083\n",
      "Iteration 5748, loss = 0.00430967\n",
      "Iteration 5749, loss = 0.00430867\n",
      "Iteration 5750, loss = 0.00430756\n",
      "Iteration 5751, loss = 0.00430683\n",
      "Iteration 5752, loss = 0.00430563\n",
      "Iteration 5753, loss = 0.00430475\n",
      "Iteration 5754, loss = 0.00430390\n",
      "Iteration 5755, loss = 0.00430292\n",
      "Iteration 5756, loss = 0.00430188\n",
      "Iteration 5757, loss = 0.00430080\n",
      "Iteration 5758, loss = 0.00429962\n",
      "Iteration 5759, loss = 0.00429906\n",
      "Iteration 5760, loss = 0.00429764\n",
      "Iteration 5761, loss = 0.00429622\n",
      "Iteration 5762, loss = 0.00429539\n",
      "Iteration 5763, loss = 0.00429411\n",
      "Iteration 5764, loss = 0.00429275\n",
      "Iteration 5765, loss = 0.00429164\n",
      "Iteration 5766, loss = 0.00429074\n",
      "Iteration 5767, loss = 0.00428947\n",
      "Iteration 5768, loss = 0.00428845\n",
      "Iteration 5769, loss = 0.00428736\n",
      "Iteration 5770, loss = 0.00428622\n",
      "Iteration 5771, loss = 0.00428521\n",
      "Iteration 5772, loss = 0.00428412\n",
      "Iteration 5773, loss = 0.00428304\n",
      "Iteration 5774, loss = 0.00428219\n",
      "Iteration 5775, loss = 0.00428127\n",
      "Iteration 5776, loss = 0.00428008\n",
      "Iteration 5777, loss = 0.00427917\n",
      "Iteration 5778, loss = 0.00427803\n",
      "Iteration 5779, loss = 0.00427689\n",
      "Iteration 5780, loss = 0.00427595\n",
      "Iteration 5781, loss = 0.00427484\n",
      "Iteration 5782, loss = 0.00427387\n",
      "Iteration 5783, loss = 0.00427391\n",
      "Iteration 5784, loss = 0.00427201\n",
      "Iteration 5785, loss = 0.00427079\n",
      "Iteration 5786, loss = 0.00426971\n",
      "Iteration 5787, loss = 0.00426861\n",
      "Iteration 5788, loss = 0.00426748\n",
      "Iteration 5789, loss = 0.00426633\n",
      "Iteration 5790, loss = 0.00426520\n",
      "Iteration 5791, loss = 0.00426405\n",
      "Iteration 5792, loss = 0.00426285\n",
      "Iteration 5793, loss = 0.00426191\n",
      "Iteration 5794, loss = 0.00426143\n",
      "Iteration 5795, loss = 0.00425983\n",
      "Iteration 5796, loss = 0.00425874\n",
      "Iteration 5797, loss = 0.00425785\n",
      "Iteration 5798, loss = 0.00425682\n",
      "Iteration 5799, loss = 0.00425584\n",
      "Iteration 5800, loss = 0.00425475\n",
      "Iteration 5801, loss = 0.00425381\n",
      "Iteration 5802, loss = 0.00425264\n",
      "Iteration 5803, loss = 0.00425154\n",
      "Iteration 5804, loss = 0.00425045\n",
      "Iteration 5805, loss = 0.00424938\n",
      "Iteration 5806, loss = 0.00424815\n",
      "Iteration 5807, loss = 0.00424716\n",
      "Iteration 5808, loss = 0.00424600\n",
      "Iteration 5809, loss = 0.00424530\n",
      "Iteration 5810, loss = 0.00424413\n",
      "Iteration 5811, loss = 0.00424306\n",
      "Iteration 5812, loss = 0.00424219\n",
      "Iteration 5813, loss = 0.00424121\n",
      "Iteration 5814, loss = 0.00424027\n",
      "Iteration 5815, loss = 0.00423968\n",
      "Iteration 5816, loss = 0.00423828\n",
      "Iteration 5817, loss = 0.00423733\n",
      "Iteration 5818, loss = 0.00423637\n",
      "Iteration 5819, loss = 0.00423542\n",
      "Iteration 5820, loss = 0.00423455\n",
      "Iteration 5821, loss = 0.00423361\n",
      "Iteration 5822, loss = 0.00423274\n",
      "Iteration 5823, loss = 0.00423178\n",
      "Iteration 5824, loss = 0.00423097\n",
      "Iteration 5825, loss = 0.00422981\n",
      "Iteration 5826, loss = 0.00422903\n",
      "Iteration 5827, loss = 0.00422813\n",
      "Iteration 5828, loss = 0.00422693\n",
      "Iteration 5829, loss = 0.00422602\n",
      "Iteration 5830, loss = 0.00422517\n",
      "Iteration 5831, loss = 0.00422407\n",
      "Iteration 5832, loss = 0.00422317\n",
      "Iteration 5833, loss = 0.00422229\n",
      "Iteration 5834, loss = 0.00422158\n",
      "Iteration 5835, loss = 0.00422062\n",
      "Iteration 5836, loss = 0.00421965\n",
      "Iteration 5837, loss = 0.00421860\n",
      "Iteration 5838, loss = 0.00421785\n",
      "Iteration 5839, loss = 0.00421663\n",
      "Iteration 5840, loss = 0.00421565\n",
      "Iteration 5841, loss = 0.00421472\n",
      "Iteration 5842, loss = 0.00421354\n",
      "Iteration 5843, loss = 0.00421256\n",
      "Iteration 5844, loss = 0.00421194\n",
      "Iteration 5845, loss = 0.00421059\n",
      "Iteration 5846, loss = 0.00420947\n",
      "Iteration 5847, loss = 0.00420868\n",
      "Iteration 5848, loss = 0.00420751\n",
      "Iteration 5849, loss = 0.00420731\n",
      "Iteration 5850, loss = 0.00420572\n",
      "Iteration 5851, loss = 0.00420489\n",
      "Iteration 5852, loss = 0.00420364\n",
      "Iteration 5853, loss = 0.00420251\n",
      "Iteration 5854, loss = 0.00420150\n",
      "Iteration 5855, loss = 0.00420032\n",
      "Iteration 5856, loss = 0.00419938\n",
      "Iteration 5857, loss = 0.00419817\n",
      "Iteration 5858, loss = 0.00419734\n",
      "Iteration 5859, loss = 0.00419585\n",
      "Iteration 5860, loss = 0.00419486\n",
      "Iteration 5861, loss = 0.00419365\n",
      "Iteration 5862, loss = 0.00419273\n",
      "Iteration 5863, loss = 0.00419169\n",
      "Iteration 5864, loss = 0.00419068\n",
      "Iteration 5865, loss = 0.00418972\n",
      "Iteration 5866, loss = 0.00418866\n",
      "Iteration 5867, loss = 0.00418773\n",
      "Iteration 5868, loss = 0.00418692\n",
      "Iteration 5869, loss = 0.00418580\n",
      "Iteration 5870, loss = 0.00418499\n",
      "Iteration 5871, loss = 0.00418387\n",
      "Iteration 5872, loss = 0.00418311\n",
      "Iteration 5873, loss = 0.00418194\n",
      "Iteration 5874, loss = 0.00418098\n",
      "Iteration 5875, loss = 0.00417994\n",
      "Iteration 5876, loss = 0.00417891\n",
      "Iteration 5877, loss = 0.00417789\n",
      "Iteration 5878, loss = 0.00417684\n",
      "Iteration 5879, loss = 0.00417573\n",
      "Iteration 5880, loss = 0.00417463\n",
      "Iteration 5881, loss = 0.00417374\n",
      "Iteration 5882, loss = 0.00417250\n",
      "Iteration 5883, loss = 0.00417164\n",
      "Iteration 5884, loss = 0.00417049\n",
      "Iteration 5885, loss = 0.00416949\n",
      "Iteration 5886, loss = 0.00416869\n",
      "Iteration 5887, loss = 0.00416789\n",
      "Iteration 5888, loss = 0.00416673\n",
      "Iteration 5889, loss = 0.00416580\n",
      "Iteration 5890, loss = 0.00416509\n",
      "Iteration 5891, loss = 0.00416380\n",
      "Iteration 5892, loss = 0.00416264\n",
      "Iteration 5893, loss = 0.00416173\n",
      "Iteration 5894, loss = 0.00416076\n",
      "Iteration 5895, loss = 0.00415966\n",
      "Iteration 5896, loss = 0.00415901\n",
      "Iteration 5897, loss = 0.00415782\n",
      "Iteration 5898, loss = 0.00415689\n",
      "Iteration 5899, loss = 0.00415585\n",
      "Iteration 5900, loss = 0.00415487\n",
      "Iteration 5901, loss = 0.00415461\n",
      "Iteration 5902, loss = 0.00415303\n",
      "Iteration 5903, loss = 0.00415201\n",
      "Iteration 5904, loss = 0.00415096\n",
      "Iteration 5905, loss = 0.00414992\n",
      "Iteration 5906, loss = 0.00414895\n",
      "Iteration 5907, loss = 0.00414832\n",
      "Iteration 5908, loss = 0.00414724\n",
      "Iteration 5909, loss = 0.00414607\n",
      "Iteration 5910, loss = 0.00414514\n",
      "Iteration 5911, loss = 0.00414452\n",
      "Iteration 5912, loss = 0.00414322\n",
      "Iteration 5913, loss = 0.00414231\n",
      "Iteration 5914, loss = 0.00414149\n",
      "Iteration 5915, loss = 0.00414041\n",
      "Iteration 5916, loss = 0.00413925\n",
      "Iteration 5917, loss = 0.00413819\n",
      "Iteration 5918, loss = 0.00413712\n",
      "Iteration 5919, loss = 0.00413595\n",
      "Iteration 5920, loss = 0.00413506\n",
      "Iteration 5921, loss = 0.00413438\n",
      "Iteration 5922, loss = 0.00413301\n",
      "Iteration 5923, loss = 0.00413243\n",
      "Iteration 5924, loss = 0.00413126\n",
      "Iteration 5925, loss = 0.00413005\n",
      "Iteration 5926, loss = 0.00412925\n",
      "Iteration 5927, loss = 0.00412819\n",
      "Iteration 5928, loss = 0.00412725\n",
      "Iteration 5929, loss = 0.00412645\n",
      "Iteration 5930, loss = 0.00412533\n",
      "Iteration 5931, loss = 0.00412449\n",
      "Iteration 5932, loss = 0.00412345\n",
      "Iteration 5933, loss = 0.00412251\n",
      "Iteration 5934, loss = 0.00412191\n",
      "Iteration 5935, loss = 0.00412084\n",
      "Iteration 5936, loss = 0.00411999\n",
      "Iteration 5937, loss = 0.00411920\n",
      "Iteration 5938, loss = 0.00411812\n",
      "Iteration 5939, loss = 0.00411723\n",
      "Iteration 5940, loss = 0.00411628\n",
      "Iteration 5941, loss = 0.00411530\n",
      "Iteration 5942, loss = 0.00411440\n",
      "Iteration 5943, loss = 0.00411370\n",
      "Iteration 5944, loss = 0.00411267\n",
      "Iteration 5945, loss = 0.00411195\n",
      "Iteration 5946, loss = 0.00411092\n",
      "Iteration 5947, loss = 0.00410974\n",
      "Iteration 5948, loss = 0.00410878\n",
      "Iteration 5949, loss = 0.00410764\n",
      "Iteration 5950, loss = 0.00410688\n",
      "Iteration 5951, loss = 0.00410583\n",
      "Iteration 5952, loss = 0.00410476\n",
      "Iteration 5953, loss = 0.00410357\n",
      "Iteration 5954, loss = 0.00410263\n",
      "Iteration 5955, loss = 0.00410142\n",
      "Iteration 5956, loss = 0.00410013\n",
      "Iteration 5957, loss = 0.00409941\n",
      "Iteration 5958, loss = 0.00409868\n",
      "Iteration 5959, loss = 0.00409737\n",
      "Iteration 5960, loss = 0.00409613\n",
      "Iteration 5961, loss = 0.00409519\n",
      "Iteration 5962, loss = 0.00409390\n",
      "Iteration 5963, loss = 0.00409308\n",
      "Iteration 5964, loss = 0.00409171\n",
      "Iteration 5965, loss = 0.00409080\n",
      "Iteration 5966, loss = 0.00408976\n",
      "Iteration 5967, loss = 0.00408882\n",
      "Iteration 5968, loss = 0.00408777\n",
      "Iteration 5969, loss = 0.00408689\n",
      "Iteration 5970, loss = 0.00408603\n",
      "Iteration 5971, loss = 0.00408508\n",
      "Iteration 5972, loss = 0.00408418\n",
      "Iteration 5973, loss = 0.00408336\n",
      "Iteration 5974, loss = 0.00408238\n",
      "Iteration 5975, loss = 0.00408161\n",
      "Iteration 5976, loss = 0.00408079\n",
      "Iteration 5977, loss = 0.00407993\n",
      "Iteration 5978, loss = 0.00407861\n",
      "Iteration 5979, loss = 0.00407772\n",
      "Iteration 5980, loss = 0.00407671\n",
      "Iteration 5981, loss = 0.00407603\n",
      "Iteration 5982, loss = 0.00407484\n",
      "Iteration 5983, loss = 0.00407410\n",
      "Iteration 5984, loss = 0.00407284\n",
      "Iteration 5985, loss = 0.00407196\n",
      "Iteration 5986, loss = 0.00407118\n",
      "Iteration 5987, loss = 0.00407011\n",
      "Iteration 5988, loss = 0.00406936\n",
      "Iteration 5989, loss = 0.00406833\n",
      "Iteration 5990, loss = 0.00406723\n",
      "Iteration 5991, loss = 0.00406632\n",
      "Iteration 5992, loss = 0.00406528\n",
      "Iteration 5993, loss = 0.00406429\n",
      "Iteration 5994, loss = 0.00406335\n",
      "Iteration 5995, loss = 0.00406267\n",
      "Iteration 5996, loss = 0.00406137\n",
      "Iteration 5997, loss = 0.00406070\n",
      "Iteration 5998, loss = 0.00405959\n",
      "Iteration 5999, loss = 0.00405885\n",
      "Iteration 6000, loss = 0.00405776\n",
      "Iteration 6001, loss = 0.00405689\n",
      "Iteration 6002, loss = 0.00405595\n",
      "Iteration 6003, loss = 0.00405501\n",
      "Iteration 6004, loss = 0.00405389\n",
      "Iteration 6005, loss = 0.00405313\n",
      "Iteration 6006, loss = 0.00405209\n",
      "Iteration 6007, loss = 0.00405104\n",
      "Iteration 6008, loss = 0.00405019\n",
      "Iteration 6009, loss = 0.00404916\n",
      "Iteration 6010, loss = 0.00404830\n",
      "Iteration 6011, loss = 0.00404739\n",
      "Iteration 6012, loss = 0.00404651\n",
      "Iteration 6013, loss = 0.00404551\n",
      "Iteration 6014, loss = 0.00404464\n",
      "Iteration 6015, loss = 0.00404373\n",
      "Iteration 6016, loss = 0.00404289\n",
      "Iteration 6017, loss = 0.00404197\n",
      "Iteration 6018, loss = 0.00404100\n",
      "Iteration 6019, loss = 0.00404018\n",
      "Iteration 6020, loss = 0.00403915\n",
      "Iteration 6021, loss = 0.00403815\n",
      "Iteration 6022, loss = 0.00403717\n",
      "Iteration 6023, loss = 0.00403724\n",
      "Iteration 6024, loss = 0.00403584\n",
      "Iteration 6025, loss = 0.00403484\n",
      "Iteration 6026, loss = 0.00403440\n",
      "Iteration 6027, loss = 0.00403328\n",
      "Iteration 6028, loss = 0.00403272\n",
      "Iteration 6029, loss = 0.00403168\n",
      "Iteration 6030, loss = 0.00403072\n",
      "Iteration 6031, loss = 0.00402999\n",
      "Iteration 6032, loss = 0.00402925\n",
      "Iteration 6033, loss = 0.00402822\n",
      "Iteration 6034, loss = 0.00402745\n",
      "Iteration 6035, loss = 0.00402650\n",
      "Iteration 6036, loss = 0.00402557\n",
      "Iteration 6037, loss = 0.00402472\n",
      "Iteration 6038, loss = 0.00402388\n",
      "Iteration 6039, loss = 0.00402323\n",
      "Iteration 6040, loss = 0.00402227\n",
      "Iteration 6041, loss = 0.00402144\n",
      "Iteration 6042, loss = 0.00402066\n",
      "Iteration 6043, loss = 0.00401977\n",
      "Iteration 6044, loss = 0.00401899\n",
      "Iteration 6045, loss = 0.00401830\n",
      "Iteration 6046, loss = 0.00401716\n",
      "Iteration 6047, loss = 0.00401626\n",
      "Iteration 6048, loss = 0.00401537\n",
      "Iteration 6049, loss = 0.00401450\n",
      "Iteration 6050, loss = 0.00401362\n",
      "Iteration 6051, loss = 0.00401269\n",
      "Iteration 6052, loss = 0.00401206\n",
      "Iteration 6053, loss = 0.00401116\n",
      "Iteration 6054, loss = 0.00401029\n",
      "Iteration 6055, loss = 0.00400979\n",
      "Iteration 6056, loss = 0.00400904\n",
      "Iteration 6057, loss = 0.00400762\n",
      "Iteration 6058, loss = 0.00400671\n",
      "Iteration 6059, loss = 0.00400572\n",
      "Iteration 6060, loss = 0.00400522\n",
      "Iteration 6061, loss = 0.00400417\n",
      "Iteration 6062, loss = 0.00400321\n",
      "Iteration 6063, loss = 0.00400262\n",
      "Iteration 6064, loss = 0.00400160\n",
      "Iteration 6065, loss = 0.00400066\n",
      "Iteration 6066, loss = 0.00400009\n",
      "Iteration 6067, loss = 0.00399926\n",
      "Iteration 6068, loss = 0.00399813\n",
      "Iteration 6069, loss = 0.00399727\n",
      "Iteration 6070, loss = 0.00399644\n",
      "Iteration 6071, loss = 0.00399561\n",
      "Iteration 6072, loss = 0.00399466\n",
      "Iteration 6073, loss = 0.00399442\n",
      "Iteration 6074, loss = 0.00399306\n",
      "Iteration 6075, loss = 0.00399236\n",
      "Iteration 6076, loss = 0.00399148\n",
      "Iteration 6077, loss = 0.00399034\n",
      "Iteration 6078, loss = 0.00398952\n",
      "Iteration 6079, loss = 0.00398871\n",
      "Iteration 6080, loss = 0.00398785\n",
      "Iteration 6081, loss = 0.00398675\n",
      "Iteration 6082, loss = 0.00398602\n",
      "Iteration 6083, loss = 0.00398511\n",
      "Iteration 6084, loss = 0.00398431\n",
      "Iteration 6085, loss = 0.00398361\n",
      "Iteration 6086, loss = 0.00398257\n",
      "Iteration 6087, loss = 0.00398222\n",
      "Iteration 6088, loss = 0.00398130\n",
      "Iteration 6089, loss = 0.00398058\n",
      "Iteration 6090, loss = 0.00397976\n",
      "Iteration 6091, loss = 0.00397916\n",
      "Iteration 6092, loss = 0.00397878\n",
      "Iteration 6093, loss = 0.00397755\n",
      "Iteration 6094, loss = 0.00397667\n",
      "Iteration 6095, loss = 0.00397585\n",
      "Iteration 6096, loss = 0.00397471\n",
      "Iteration 6097, loss = 0.00397408\n",
      "Iteration 6098, loss = 0.00397296\n",
      "Iteration 6099, loss = 0.00397204\n",
      "Iteration 6100, loss = 0.00397126\n",
      "Iteration 6101, loss = 0.00397016\n",
      "Iteration 6102, loss = 0.00396938\n",
      "Iteration 6103, loss = 0.00396839\n",
      "Iteration 6104, loss = 0.00396769\n",
      "Iteration 6105, loss = 0.00396678\n",
      "Iteration 6106, loss = 0.00396625\n",
      "Iteration 6107, loss = 0.00396514\n",
      "Iteration 6108, loss = 0.00396463\n",
      "Iteration 6109, loss = 0.00396345\n",
      "Iteration 6110, loss = 0.00396226\n",
      "Iteration 6111, loss = 0.00396125\n",
      "Iteration 6112, loss = 0.00396040\n",
      "Iteration 6113, loss = 0.00395932\n",
      "Iteration 6114, loss = 0.00395825\n",
      "Iteration 6115, loss = 0.00395747\n",
      "Iteration 6116, loss = 0.00395643\n",
      "Iteration 6117, loss = 0.00395546\n",
      "Iteration 6118, loss = 0.00395448\n",
      "Iteration 6119, loss = 0.00395362\n",
      "Iteration 6120, loss = 0.00395294\n",
      "Iteration 6121, loss = 0.00395217\n",
      "Iteration 6122, loss = 0.00395121\n",
      "Iteration 6123, loss = 0.00395018\n",
      "Iteration 6124, loss = 0.00394933\n",
      "Iteration 6125, loss = 0.00394848\n",
      "Iteration 6126, loss = 0.00394754\n",
      "Iteration 6127, loss = 0.00394628\n",
      "Iteration 6128, loss = 0.00394519\n",
      "Iteration 6129, loss = 0.00394477\n",
      "Iteration 6130, loss = 0.00394359\n",
      "Iteration 6131, loss = 0.00394235\n",
      "Iteration 6132, loss = 0.00394149\n",
      "Iteration 6133, loss = 0.00394033\n",
      "Iteration 6134, loss = 0.00393963\n",
      "Iteration 6135, loss = 0.00393832\n",
      "Iteration 6136, loss = 0.00393790\n",
      "Iteration 6137, loss = 0.00393695\n",
      "Iteration 6138, loss = 0.00393610\n",
      "Iteration 6139, loss = 0.00393541\n",
      "Iteration 6140, loss = 0.00393446\n",
      "Iteration 6141, loss = 0.00393368\n",
      "Iteration 6142, loss = 0.00393297\n",
      "Iteration 6143, loss = 0.00393213\n",
      "Iteration 6144, loss = 0.00393145\n",
      "Iteration 6145, loss = 0.00393093\n",
      "Iteration 6146, loss = 0.00392953\n",
      "Iteration 6147, loss = 0.00392886\n",
      "Iteration 6148, loss = 0.00392792\n",
      "Iteration 6149, loss = 0.00392665\n",
      "Iteration 6150, loss = 0.00392564\n",
      "Iteration 6151, loss = 0.00392474\n",
      "Iteration 6152, loss = 0.00392398\n",
      "Iteration 6153, loss = 0.00392286\n",
      "Iteration 6154, loss = 0.00392241\n",
      "Iteration 6155, loss = 0.00392122\n",
      "Iteration 6156, loss = 0.00392001\n",
      "Iteration 6157, loss = 0.00391910\n",
      "Iteration 6158, loss = 0.00391813\n",
      "Iteration 6159, loss = 0.00391766\n",
      "Iteration 6160, loss = 0.00391638\n",
      "Iteration 6161, loss = 0.00391541\n",
      "Iteration 6162, loss = 0.00391423\n",
      "Iteration 6163, loss = 0.00391360\n",
      "Iteration 6164, loss = 0.00391269\n",
      "Iteration 6165, loss = 0.00391141\n",
      "Iteration 6166, loss = 0.00391069\n",
      "Iteration 6167, loss = 0.00390956\n",
      "Iteration 6168, loss = 0.00390862\n",
      "Iteration 6169, loss = 0.00390766\n",
      "Iteration 6170, loss = 0.00390677\n",
      "Iteration 6171, loss = 0.00390581\n",
      "Iteration 6172, loss = 0.00390514\n",
      "Iteration 6173, loss = 0.00390404\n",
      "Iteration 6174, loss = 0.00390313\n",
      "Iteration 6175, loss = 0.00390230\n",
      "Iteration 6176, loss = 0.00390150\n",
      "Iteration 6177, loss = 0.00390058\n",
      "Iteration 6178, loss = 0.00389948\n",
      "Iteration 6179, loss = 0.00389876\n",
      "Iteration 6180, loss = 0.00389791\n",
      "Iteration 6181, loss = 0.00389729\n",
      "Iteration 6182, loss = 0.00389634\n",
      "Iteration 6183, loss = 0.00389547\n",
      "Iteration 6184, loss = 0.00389462\n",
      "Iteration 6185, loss = 0.00389384\n",
      "Iteration 6186, loss = 0.00389298\n",
      "Iteration 6187, loss = 0.00389199\n",
      "Iteration 6188, loss = 0.00389104\n",
      "Iteration 6189, loss = 0.00389028\n",
      "Iteration 6190, loss = 0.00388944\n",
      "Iteration 6191, loss = 0.00388852\n",
      "Iteration 6192, loss = 0.00388758\n",
      "Iteration 6193, loss = 0.00388673\n",
      "Iteration 6194, loss = 0.00388599\n",
      "Iteration 6195, loss = 0.00388498\n",
      "Iteration 6196, loss = 0.00388397\n",
      "Iteration 6197, loss = 0.00388311\n",
      "Iteration 6198, loss = 0.00388201\n",
      "Iteration 6199, loss = 0.00388132\n",
      "Iteration 6200, loss = 0.00388027\n",
      "Iteration 6201, loss = 0.00387937\n",
      "Iteration 6202, loss = 0.00387844\n",
      "Iteration 6203, loss = 0.00387782\n",
      "Iteration 6204, loss = 0.00387673\n",
      "Iteration 6205, loss = 0.00387575\n",
      "Iteration 6206, loss = 0.00387501\n",
      "Iteration 6207, loss = 0.00387390\n",
      "Iteration 6208, loss = 0.00387309\n",
      "Iteration 6209, loss = 0.00387261\n",
      "Iteration 6210, loss = 0.00387131\n",
      "Iteration 6211, loss = 0.00387031\n",
      "Iteration 6212, loss = 0.00386968\n",
      "Iteration 6213, loss = 0.00386868\n",
      "Iteration 6214, loss = 0.00386768\n",
      "Iteration 6215, loss = 0.00386692\n",
      "Iteration 6216, loss = 0.00386586\n",
      "Iteration 6217, loss = 0.00386509\n",
      "Iteration 6218, loss = 0.00386427\n",
      "Iteration 6219, loss = 0.00386320\n",
      "Iteration 6220, loss = 0.00386250\n",
      "Iteration 6221, loss = 0.00386157\n",
      "Iteration 6222, loss = 0.00386080\n",
      "Iteration 6223, loss = 0.00386011\n",
      "Iteration 6224, loss = 0.00385898\n",
      "Iteration 6225, loss = 0.00385804\n",
      "Iteration 6226, loss = 0.00385721\n",
      "Iteration 6227, loss = 0.00385596\n",
      "Iteration 6228, loss = 0.00385486\n",
      "Iteration 6229, loss = 0.00385411\n",
      "Iteration 6230, loss = 0.00385333\n",
      "Iteration 6231, loss = 0.00385245\n",
      "Iteration 6232, loss = 0.00385135\n",
      "Iteration 6233, loss = 0.00385044\n",
      "Iteration 6234, loss = 0.00384985\n",
      "Iteration 6235, loss = 0.00384873\n",
      "Iteration 6236, loss = 0.00384787\n",
      "Iteration 6237, loss = 0.00384699\n",
      "Iteration 6238, loss = 0.00384613\n",
      "Iteration 6239, loss = 0.00384557\n",
      "Iteration 6240, loss = 0.00384454\n",
      "Iteration 6241, loss = 0.00384371\n",
      "Iteration 6242, loss = 0.00384326\n",
      "Iteration 6243, loss = 0.00384220\n",
      "Iteration 6244, loss = 0.00384158\n",
      "Iteration 6245, loss = 0.00384059\n",
      "Iteration 6246, loss = 0.00383971\n",
      "Iteration 6247, loss = 0.00383873\n",
      "Iteration 6248, loss = 0.00383798\n",
      "Iteration 6249, loss = 0.00383701\n",
      "Iteration 6250, loss = 0.00383622\n",
      "Iteration 6251, loss = 0.00383550\n",
      "Iteration 6252, loss = 0.00383459\n",
      "Iteration 6253, loss = 0.00383388\n",
      "Iteration 6254, loss = 0.00383311\n",
      "Iteration 6255, loss = 0.00383241\n",
      "Iteration 6256, loss = 0.00383152\n",
      "Iteration 6257, loss = 0.00383090\n",
      "Iteration 6258, loss = 0.00382997\n",
      "Iteration 6259, loss = 0.00382911\n",
      "Iteration 6260, loss = 0.00382837\n",
      "Iteration 6261, loss = 0.00382766\n",
      "Iteration 6262, loss = 0.00382689\n",
      "Iteration 6263, loss = 0.00382627\n",
      "Iteration 6264, loss = 0.00382549\n",
      "Iteration 6265, loss = 0.00382495\n",
      "Iteration 6266, loss = 0.00382409\n",
      "Iteration 6267, loss = 0.00382337\n",
      "Iteration 6268, loss = 0.00382252\n",
      "Iteration 6269, loss = 0.00382184\n",
      "Iteration 6270, loss = 0.00382110\n",
      "Iteration 6271, loss = 0.00382037\n",
      "Iteration 6272, loss = 0.00381970\n",
      "Iteration 6273, loss = 0.00381926\n",
      "Iteration 6274, loss = 0.00381854\n",
      "Iteration 6275, loss = 0.00381766\n",
      "Iteration 6276, loss = 0.00381687\n",
      "Iteration 6277, loss = 0.00381613\n",
      "Iteration 6278, loss = 0.00381553\n",
      "Iteration 6279, loss = 0.00381472\n",
      "Iteration 6280, loss = 0.00381369\n",
      "Iteration 6281, loss = 0.00381331\n",
      "Iteration 6282, loss = 0.00381210\n",
      "Iteration 6283, loss = 0.00381127\n",
      "Iteration 6284, loss = 0.00381076\n",
      "Iteration 6285, loss = 0.00380965\n",
      "Iteration 6286, loss = 0.00380919\n",
      "Iteration 6287, loss = 0.00380816\n",
      "Iteration 6288, loss = 0.00380739\n",
      "Iteration 6289, loss = 0.00380670\n",
      "Iteration 6290, loss = 0.00380589\n",
      "Iteration 6291, loss = 0.00380521\n",
      "Iteration 6292, loss = 0.00380440\n",
      "Iteration 6293, loss = 0.00380376\n",
      "Iteration 6294, loss = 0.00380285\n",
      "Iteration 6295, loss = 0.00380214\n",
      "Iteration 6296, loss = 0.00380124\n",
      "Iteration 6297, loss = 0.00380060\n",
      "Iteration 6298, loss = 0.00379986\n",
      "Iteration 6299, loss = 0.00379941\n",
      "Iteration 6300, loss = 0.00379855\n",
      "Iteration 6301, loss = 0.00379784\n",
      "Iteration 6302, loss = 0.00379739\n",
      "Iteration 6303, loss = 0.00379652\n",
      "Iteration 6304, loss = 0.00379589\n",
      "Iteration 6305, loss = 0.00379508\n",
      "Iteration 6306, loss = 0.00379410\n",
      "Iteration 6307, loss = 0.00379334\n",
      "Iteration 6308, loss = 0.00379260\n",
      "Iteration 6309, loss = 0.00379190\n",
      "Iteration 6310, loss = 0.00379108\n",
      "Iteration 6311, loss = 0.00379050\n",
      "Iteration 6312, loss = 0.00378979\n",
      "Iteration 6313, loss = 0.00378895\n",
      "Iteration 6314, loss = 0.00378842\n",
      "Iteration 6315, loss = 0.00378758\n",
      "Iteration 6316, loss = 0.00378711\n",
      "Iteration 6317, loss = 0.00378602\n",
      "Iteration 6318, loss = 0.00378536\n",
      "Iteration 6319, loss = 0.00378456\n",
      "Iteration 6320, loss = 0.00378404\n",
      "Iteration 6321, loss = 0.00378312\n",
      "Iteration 6322, loss = 0.00378264\n",
      "Iteration 6323, loss = 0.00378175\n",
      "Iteration 6324, loss = 0.00378113\n",
      "Iteration 6325, loss = 0.00378029\n",
      "Iteration 6326, loss = 0.00377969\n",
      "Iteration 6327, loss = 0.00377903\n",
      "Iteration 6328, loss = 0.00377852\n",
      "Iteration 6329, loss = 0.00377789\n",
      "Iteration 6330, loss = 0.00377702\n",
      "Iteration 6331, loss = 0.00377717\n",
      "Iteration 6332, loss = 0.00377590\n",
      "Iteration 6333, loss = 0.00377510\n",
      "Iteration 6334, loss = 0.00377426\n",
      "Iteration 6335, loss = 0.00377369\n",
      "Iteration 6336, loss = 0.00377312\n",
      "Iteration 6337, loss = 0.00377266\n",
      "Iteration 6338, loss = 0.00377203\n",
      "Iteration 6339, loss = 0.00377140\n",
      "Iteration 6340, loss = 0.00377081\n",
      "Iteration 6341, loss = 0.00377019\n",
      "Iteration 6342, loss = 0.00376979\n",
      "Iteration 6343, loss = 0.00376911\n",
      "Iteration 6344, loss = 0.00376860\n",
      "Iteration 6345, loss = 0.00376819\n",
      "Iteration 6346, loss = 0.00376763\n",
      "Iteration 6347, loss = 0.00376688\n",
      "Iteration 6348, loss = 0.00376625\n",
      "Iteration 6349, loss = 0.00376541\n",
      "Iteration 6350, loss = 0.00376460\n",
      "Iteration 6351, loss = 0.00376356\n",
      "Iteration 6352, loss = 0.00376241\n",
      "Iteration 6353, loss = 0.00376130\n",
      "Iteration 6354, loss = 0.00375996\n",
      "Iteration 6355, loss = 0.00375902\n",
      "Iteration 6356, loss = 0.00375887\n",
      "Iteration 6357, loss = 0.00375711\n",
      "Iteration 6358, loss = 0.00375604\n",
      "Iteration 6359, loss = 0.00375512\n",
      "Iteration 6360, loss = 0.00375431\n",
      "Iteration 6361, loss = 0.00375306\n",
      "Iteration 6362, loss = 0.00375221\n",
      "Iteration 6363, loss = 0.00375109\n",
      "Iteration 6364, loss = 0.00374992\n",
      "Iteration 6365, loss = 0.00374911\n",
      "Iteration 6366, loss = 0.00374796\n",
      "Iteration 6367, loss = 0.00374703\n",
      "Iteration 6368, loss = 0.00374611\n",
      "Iteration 6369, loss = 0.00374523\n",
      "Iteration 6370, loss = 0.00374440\n",
      "Iteration 6371, loss = 0.00374353\n",
      "Iteration 6372, loss = 0.00374270\n",
      "Iteration 6373, loss = 0.00374204\n",
      "Iteration 6374, loss = 0.00374128\n",
      "Iteration 6375, loss = 0.00374068\n",
      "Iteration 6376, loss = 0.00373996\n",
      "Iteration 6377, loss = 0.00373922\n",
      "Iteration 6378, loss = 0.00373882\n",
      "Iteration 6379, loss = 0.00373803\n",
      "Iteration 6380, loss = 0.00373732\n",
      "Iteration 6381, loss = 0.00373662\n",
      "Iteration 6382, loss = 0.00373571\n",
      "Iteration 6383, loss = 0.00373475\n",
      "Iteration 6384, loss = 0.00373400\n",
      "Iteration 6385, loss = 0.00373278\n",
      "Iteration 6386, loss = 0.00373198\n",
      "Iteration 6387, loss = 0.00373114\n",
      "Iteration 6388, loss = 0.00373040\n",
      "Iteration 6389, loss = 0.00372963\n",
      "Iteration 6390, loss = 0.00372864\n",
      "Iteration 6391, loss = 0.00372787\n",
      "Iteration 6392, loss = 0.00372729\n",
      "Iteration 6393, loss = 0.00372634\n",
      "Iteration 6394, loss = 0.00372581\n",
      "Iteration 6395, loss = 0.00372484\n",
      "Iteration 6396, loss = 0.00372391\n",
      "Iteration 6397, loss = 0.00372298\n",
      "Iteration 6398, loss = 0.00372213\n",
      "Iteration 6399, loss = 0.00372157\n",
      "Iteration 6400, loss = 0.00372022\n",
      "Iteration 6401, loss = 0.00371909\n",
      "Iteration 6402, loss = 0.00371891\n",
      "Iteration 6403, loss = 0.00371734\n",
      "Iteration 6404, loss = 0.00371664\n",
      "Iteration 6405, loss = 0.00371548\n",
      "Iteration 6406, loss = 0.00371459\n",
      "Iteration 6407, loss = 0.00371373\n",
      "Iteration 6408, loss = 0.00371291\n",
      "Iteration 6409, loss = 0.00371214\n",
      "Iteration 6410, loss = 0.00371132\n",
      "Iteration 6411, loss = 0.00371079\n",
      "Iteration 6412, loss = 0.00370969\n",
      "Iteration 6413, loss = 0.00370897\n",
      "Iteration 6414, loss = 0.00370801\n",
      "Iteration 6415, loss = 0.00370707\n",
      "Iteration 6416, loss = 0.00370641\n",
      "Iteration 6417, loss = 0.00370560\n",
      "Iteration 6418, loss = 0.00370420\n",
      "Iteration 6419, loss = 0.00370329\n",
      "Iteration 6420, loss = 0.00370231\n",
      "Iteration 6421, loss = 0.00370172\n",
      "Iteration 6422, loss = 0.00370056\n",
      "Iteration 6423, loss = 0.00369991\n",
      "Iteration 6424, loss = 0.00369874\n",
      "Iteration 6425, loss = 0.00369804\n",
      "Iteration 6426, loss = 0.00369734\n",
      "Iteration 6427, loss = 0.00369632\n",
      "Iteration 6428, loss = 0.00369543\n",
      "Iteration 6429, loss = 0.00369479\n",
      "Iteration 6430, loss = 0.00369380\n",
      "Iteration 6431, loss = 0.00369318\n",
      "Iteration 6432, loss = 0.00369227\n",
      "Iteration 6433, loss = 0.00369174\n",
      "Iteration 6434, loss = 0.00369070\n",
      "Iteration 6435, loss = 0.00368971\n",
      "Iteration 6436, loss = 0.00368927\n",
      "Iteration 6437, loss = 0.00368804\n",
      "Iteration 6438, loss = 0.00368727\n",
      "Iteration 6439, loss = 0.00368634\n",
      "Iteration 6440, loss = 0.00368554\n",
      "Iteration 6441, loss = 0.00368476\n",
      "Iteration 6442, loss = 0.00368403\n",
      "Iteration 6443, loss = 0.00368333\n",
      "Iteration 6444, loss = 0.00368276\n",
      "Iteration 6445, loss = 0.00368198\n",
      "Iteration 6446, loss = 0.00368135\n",
      "Iteration 6447, loss = 0.00368069\n",
      "Iteration 6448, loss = 0.00367973\n",
      "Iteration 6449, loss = 0.00367874\n",
      "Iteration 6450, loss = 0.00367786\n",
      "Iteration 6451, loss = 0.00367675\n",
      "Iteration 6452, loss = 0.00367633\n",
      "Iteration 6453, loss = 0.00367495\n",
      "Iteration 6454, loss = 0.00367425\n",
      "Iteration 6455, loss = 0.00367318\n",
      "Iteration 6456, loss = 0.00367225\n",
      "Iteration 6457, loss = 0.00367133\n",
      "Iteration 6458, loss = 0.00367052\n",
      "Iteration 6459, loss = 0.00366982\n",
      "Iteration 6460, loss = 0.00366905\n",
      "Iteration 6461, loss = 0.00366833\n",
      "Iteration 6462, loss = 0.00366759\n",
      "Iteration 6463, loss = 0.00366670\n",
      "Iteration 6464, loss = 0.00366600\n",
      "Iteration 6465, loss = 0.00366539\n",
      "Iteration 6466, loss = 0.00366440\n",
      "Iteration 6467, loss = 0.00366354\n",
      "Iteration 6468, loss = 0.00366263\n",
      "Iteration 6469, loss = 0.00366224\n",
      "Iteration 6470, loss = 0.00366116\n",
      "Iteration 6471, loss = 0.00366031\n",
      "Iteration 6472, loss = 0.00365940\n",
      "Iteration 6473, loss = 0.00365859\n",
      "Iteration 6474, loss = 0.00365772\n",
      "Iteration 6475, loss = 0.00365701\n",
      "Iteration 6476, loss = 0.00365610\n",
      "Iteration 6477, loss = 0.00365527\n",
      "Iteration 6478, loss = 0.00365451\n",
      "Iteration 6479, loss = 0.00365371\n",
      "Iteration 6480, loss = 0.00365294\n",
      "Iteration 6481, loss = 0.00365202\n",
      "Iteration 6482, loss = 0.00365139\n",
      "Iteration 6483, loss = 0.00365038\n",
      "Iteration 6484, loss = 0.00364974\n",
      "Iteration 6485, loss = 0.00364892\n",
      "Iteration 6486, loss = 0.00364806\n",
      "Iteration 6487, loss = 0.00364729\n",
      "Iteration 6488, loss = 0.00364649\n",
      "Iteration 6489, loss = 0.00364559\n",
      "Iteration 6490, loss = 0.00364489\n",
      "Iteration 6491, loss = 0.00364392\n",
      "Iteration 6492, loss = 0.00364343\n",
      "Iteration 6493, loss = 0.00364249\n",
      "Iteration 6494, loss = 0.00364159\n",
      "Iteration 6495, loss = 0.00364066\n",
      "Iteration 6496, loss = 0.00363984\n",
      "Iteration 6497, loss = 0.00363924\n",
      "Iteration 6498, loss = 0.00363822\n",
      "Iteration 6499, loss = 0.00363731\n",
      "Iteration 6500, loss = 0.00363665\n",
      "Iteration 6501, loss = 0.00363581\n",
      "Iteration 6502, loss = 0.00363502\n",
      "Iteration 6503, loss = 0.00363465\n",
      "Iteration 6504, loss = 0.00363375\n",
      "Iteration 6505, loss = 0.00363262\n",
      "Iteration 6506, loss = 0.00363211\n",
      "Iteration 6507, loss = 0.00363122\n",
      "Iteration 6508, loss = 0.00363039\n",
      "Iteration 6509, loss = 0.00362964\n",
      "Iteration 6510, loss = 0.00362872\n",
      "Iteration 6511, loss = 0.00362792\n",
      "Iteration 6512, loss = 0.00362727\n",
      "Iteration 6513, loss = 0.00362649\n",
      "Iteration 6514, loss = 0.00362574\n",
      "Iteration 6515, loss = 0.00362521\n",
      "Iteration 6516, loss = 0.00362422\n",
      "Iteration 6517, loss = 0.00362349\n",
      "Iteration 6518, loss = 0.00362259\n",
      "Iteration 6519, loss = 0.00362188\n",
      "Iteration 6520, loss = 0.00362167\n",
      "Iteration 6521, loss = 0.00362028\n",
      "Iteration 6522, loss = 0.00361969\n",
      "Iteration 6523, loss = 0.00361885\n",
      "Iteration 6524, loss = 0.00361806\n",
      "Iteration 6525, loss = 0.00361725\n",
      "Iteration 6526, loss = 0.00361628\n",
      "Iteration 6527, loss = 0.00361557\n",
      "Iteration 6528, loss = 0.00361463\n",
      "Iteration 6529, loss = 0.00361394\n",
      "Iteration 6530, loss = 0.00361328\n",
      "Iteration 6531, loss = 0.00361243\n",
      "Iteration 6532, loss = 0.00361154\n",
      "Iteration 6533, loss = 0.00361101\n",
      "Iteration 6534, loss = 0.00361020\n",
      "Iteration 6535, loss = 0.00360932\n",
      "Iteration 6536, loss = 0.00360857\n",
      "Iteration 6537, loss = 0.00360773\n",
      "Iteration 6538, loss = 0.00360709\n",
      "Iteration 6539, loss = 0.00360629\n",
      "Iteration 6540, loss = 0.00360569\n",
      "Iteration 6541, loss = 0.00360488\n",
      "Iteration 6542, loss = 0.00360426\n",
      "Iteration 6543, loss = 0.00360348\n",
      "Iteration 6544, loss = 0.00360274\n",
      "Iteration 6545, loss = 0.00360206\n",
      "Iteration 6546, loss = 0.00360155\n",
      "Iteration 6547, loss = 0.00360085\n",
      "Iteration 6548, loss = 0.00360047\n",
      "Iteration 6549, loss = 0.00359937\n",
      "Iteration 6550, loss = 0.00359871\n",
      "Iteration 6551, loss = 0.00359800\n",
      "Iteration 6552, loss = 0.00359720\n",
      "Iteration 6553, loss = 0.00359652\n",
      "Iteration 6554, loss = 0.00359572\n",
      "Iteration 6555, loss = 0.00359490\n",
      "Iteration 6556, loss = 0.00359400\n",
      "Iteration 6557, loss = 0.00359332\n",
      "Iteration 6558, loss = 0.00359255\n",
      "Iteration 6559, loss = 0.00359172\n",
      "Iteration 6560, loss = 0.00359113\n",
      "Iteration 6561, loss = 0.00359029\n",
      "Iteration 6562, loss = 0.00358938\n",
      "Iteration 6563, loss = 0.00358861\n",
      "Iteration 6564, loss = 0.00358774\n",
      "Iteration 6565, loss = 0.00358713\n",
      "Iteration 6566, loss = 0.00358618\n",
      "Iteration 6567, loss = 0.00358562\n",
      "Iteration 6568, loss = 0.00358462\n",
      "Iteration 6569, loss = 0.00358372\n",
      "Iteration 6570, loss = 0.00358318\n",
      "Iteration 6571, loss = 0.00358225\n",
      "Iteration 6572, loss = 0.00358165\n",
      "Iteration 6573, loss = 0.00358070\n",
      "Iteration 6574, loss = 0.00357996\n",
      "Iteration 6575, loss = 0.00357931\n",
      "Iteration 6576, loss = 0.00357856\n",
      "Iteration 6577, loss = 0.00357769\n",
      "Iteration 6578, loss = 0.00357702\n",
      "Iteration 6579, loss = 0.00357625\n",
      "Iteration 6580, loss = 0.00357543\n",
      "Iteration 6581, loss = 0.00357467\n",
      "Iteration 6582, loss = 0.00357394\n",
      "Iteration 6583, loss = 0.00357314\n",
      "Iteration 6584, loss = 0.00357244\n",
      "Iteration 6585, loss = 0.00357162\n",
      "Iteration 6586, loss = 0.00357059\n",
      "Iteration 6587, loss = 0.00356992\n",
      "Iteration 6588, loss = 0.00356918\n",
      "Iteration 6589, loss = 0.00356843\n",
      "Iteration 6590, loss = 0.00356788\n",
      "Iteration 6591, loss = 0.00356691\n",
      "Iteration 6592, loss = 0.00356634\n",
      "Iteration 6593, loss = 0.00356541\n",
      "Iteration 6594, loss = 0.00356473\n",
      "Iteration 6595, loss = 0.00356396\n",
      "Iteration 6596, loss = 0.00356357\n",
      "Iteration 6597, loss = 0.00356254\n",
      "Iteration 6598, loss = 0.00356167\n",
      "Iteration 6599, loss = 0.00356075\n",
      "Iteration 6600, loss = 0.00355992\n",
      "Iteration 6601, loss = 0.00355912\n",
      "Iteration 6602, loss = 0.00355860\n",
      "Iteration 6603, loss = 0.00355784\n",
      "Iteration 6604, loss = 0.00355702\n",
      "Iteration 6605, loss = 0.00355639\n",
      "Iteration 6606, loss = 0.00355578\n",
      "Iteration 6607, loss = 0.00355474\n",
      "Iteration 6608, loss = 0.00355392\n",
      "Iteration 6609, loss = 0.00355319\n",
      "Iteration 6610, loss = 0.00355250\n",
      "Iteration 6611, loss = 0.00355187\n",
      "Iteration 6612, loss = 0.00355115\n",
      "Iteration 6613, loss = 0.00355037\n",
      "Iteration 6614, loss = 0.00354987\n",
      "Iteration 6615, loss = 0.00354906\n",
      "Iteration 6616, loss = 0.00354834\n",
      "Iteration 6617, loss = 0.00354767\n",
      "Iteration 6618, loss = 0.00354690\n",
      "Iteration 6619, loss = 0.00354628\n",
      "Iteration 6620, loss = 0.00354576\n",
      "Iteration 6621, loss = 0.00354482\n",
      "Iteration 6622, loss = 0.00354413\n",
      "Iteration 6623, loss = 0.00354340\n",
      "Iteration 6624, loss = 0.00354289\n",
      "Iteration 6625, loss = 0.00354205\n",
      "Iteration 6626, loss = 0.00354124\n",
      "Iteration 6627, loss = 0.00354044\n",
      "Iteration 6628, loss = 0.00353980\n",
      "Iteration 6629, loss = 0.00353935\n",
      "Iteration 6630, loss = 0.00353838\n",
      "Iteration 6631, loss = 0.00353791\n",
      "Iteration 6632, loss = 0.00353685\n",
      "Iteration 6633, loss = 0.00353574\n",
      "Iteration 6634, loss = 0.00353514\n",
      "Iteration 6635, loss = 0.00353464\n",
      "Iteration 6636, loss = 0.00353372\n",
      "Iteration 6637, loss = 0.00353295\n",
      "Iteration 6638, loss = 0.00353276\n",
      "Iteration 6639, loss = 0.00353156\n",
      "Iteration 6640, loss = 0.00353095\n",
      "Iteration 6641, loss = 0.00353029\n",
      "Iteration 6642, loss = 0.00352941\n",
      "Iteration 6643, loss = 0.00352856\n",
      "Iteration 6644, loss = 0.00352795\n",
      "Iteration 6645, loss = 0.00352707\n",
      "Iteration 6646, loss = 0.00352650\n",
      "Iteration 6647, loss = 0.00352551\n",
      "Iteration 6648, loss = 0.00352504\n",
      "Iteration 6649, loss = 0.00352401\n",
      "Iteration 6650, loss = 0.00352323\n",
      "Iteration 6651, loss = 0.00352244\n",
      "Iteration 6652, loss = 0.00352203\n",
      "Iteration 6653, loss = 0.00352097\n",
      "Iteration 6654, loss = 0.00352021\n",
      "Iteration 6655, loss = 0.00351942\n",
      "Iteration 6656, loss = 0.00351871\n",
      "Iteration 6657, loss = 0.00351799\n",
      "Iteration 6658, loss = 0.00351738\n",
      "Iteration 6659, loss = 0.00351686\n",
      "Iteration 6660, loss = 0.00351596\n",
      "Iteration 6661, loss = 0.00351525\n",
      "Iteration 6662, loss = 0.00351445\n",
      "Iteration 6663, loss = 0.00351399\n",
      "Iteration 6664, loss = 0.00351317\n",
      "Iteration 6665, loss = 0.00351233\n",
      "Iteration 6666, loss = 0.00351207\n",
      "Iteration 6667, loss = 0.00351100\n",
      "Iteration 6668, loss = 0.00351033\n",
      "Iteration 6669, loss = 0.00350961\n",
      "Iteration 6670, loss = 0.00350886\n",
      "Iteration 6671, loss = 0.00350828\n",
      "Iteration 6672, loss = 0.00350752\n",
      "Iteration 6673, loss = 0.00350690\n",
      "Iteration 6674, loss = 0.00350640\n",
      "Iteration 6675, loss = 0.00350554\n",
      "Iteration 6676, loss = 0.00350463\n",
      "Iteration 6677, loss = 0.00350380\n",
      "Iteration 6678, loss = 0.00350322\n",
      "Iteration 6679, loss = 0.00350226\n",
      "Iteration 6680, loss = 0.00350142\n",
      "Iteration 6681, loss = 0.00350076\n",
      "Iteration 6682, loss = 0.00349987\n",
      "Iteration 6683, loss = 0.00349936\n",
      "Iteration 6684, loss = 0.00349855\n",
      "Iteration 6685, loss = 0.00349784\n",
      "Iteration 6686, loss = 0.00349706\n",
      "Iteration 6687, loss = 0.00349642\n",
      "Iteration 6688, loss = 0.00349566\n",
      "Iteration 6689, loss = 0.00349498\n",
      "Iteration 6690, loss = 0.00349419\n",
      "Iteration 6691, loss = 0.00349349\n",
      "Iteration 6692, loss = 0.00349275\n",
      "Iteration 6693, loss = 0.00349200\n",
      "Iteration 6694, loss = 0.00349137\n",
      "Iteration 6695, loss = 0.00349060\n",
      "Iteration 6696, loss = 0.00348996\n",
      "Iteration 6697, loss = 0.00348933\n",
      "Iteration 6698, loss = 0.00348848\n",
      "Iteration 6699, loss = 0.00348791\n",
      "Iteration 6700, loss = 0.00348715\n",
      "Iteration 6701, loss = 0.00348685\n",
      "Iteration 6702, loss = 0.00348554\n",
      "Iteration 6703, loss = 0.00348498\n",
      "Iteration 6704, loss = 0.00348407\n",
      "Iteration 6705, loss = 0.00348337\n",
      "Iteration 6706, loss = 0.00348254\n",
      "Iteration 6707, loss = 0.00348172\n",
      "Iteration 6708, loss = 0.00348100\n",
      "Iteration 6709, loss = 0.00348015\n",
      "Iteration 6710, loss = 0.00347938\n",
      "Iteration 6711, loss = 0.00347861\n",
      "Iteration 6712, loss = 0.00347777\n",
      "Iteration 6713, loss = 0.00347705\n",
      "Iteration 6714, loss = 0.00347647\n",
      "Iteration 6715, loss = 0.00347556\n",
      "Iteration 6716, loss = 0.00347557\n",
      "Iteration 6717, loss = 0.00347416\n",
      "Iteration 6718, loss = 0.00347340\n",
      "Iteration 6719, loss = 0.00347270\n",
      "Iteration 6720, loss = 0.00347189\n",
      "Iteration 6721, loss = 0.00347118\n",
      "Iteration 6722, loss = 0.00347077\n",
      "Iteration 6723, loss = 0.00346977\n",
      "Iteration 6724, loss = 0.00346906\n",
      "Iteration 6725, loss = 0.00346832\n",
      "Iteration 6726, loss = 0.00346764\n",
      "Iteration 6727, loss = 0.00346691\n",
      "Iteration 6728, loss = 0.00346626\n",
      "Iteration 6729, loss = 0.00346546\n",
      "Iteration 6730, loss = 0.00346472\n",
      "Iteration 6731, loss = 0.00346393\n",
      "Iteration 6732, loss = 0.00346348\n",
      "Iteration 6733, loss = 0.00346256\n",
      "Iteration 6734, loss = 0.00346167\n",
      "Iteration 6735, loss = 0.00346101\n",
      "Iteration 6736, loss = 0.00346028\n",
      "Iteration 6737, loss = 0.00345960\n",
      "Iteration 6738, loss = 0.00345890\n",
      "Iteration 6739, loss = 0.00345820\n",
      "Iteration 6740, loss = 0.00345754\n",
      "Iteration 6741, loss = 0.00345702\n",
      "Iteration 6742, loss = 0.00345634\n",
      "Iteration 6743, loss = 0.00345557\n",
      "Iteration 6744, loss = 0.00345499\n",
      "Iteration 6745, loss = 0.00345429\n",
      "Iteration 6746, loss = 0.00345374\n",
      "Iteration 6747, loss = 0.00345309\n",
      "Iteration 6748, loss = 0.00345244\n",
      "Iteration 6749, loss = 0.00345182\n",
      "Iteration 6750, loss = 0.00345109\n",
      "Iteration 6751, loss = 0.00345052\n",
      "Iteration 6752, loss = 0.00344983\n",
      "Iteration 6753, loss = 0.00344904\n",
      "Iteration 6754, loss = 0.00344840\n",
      "Iteration 6755, loss = 0.00344774\n",
      "Iteration 6756, loss = 0.00344721\n",
      "Iteration 6757, loss = 0.00344639\n",
      "Iteration 6758, loss = 0.00344604\n",
      "Iteration 6759, loss = 0.00344506\n",
      "Iteration 6760, loss = 0.00344436\n",
      "Iteration 6761, loss = 0.00344400\n",
      "Iteration 6762, loss = 0.00344286\n",
      "Iteration 6763, loss = 0.00344214\n",
      "Iteration 6764, loss = 0.00344149\n",
      "Iteration 6765, loss = 0.00344076\n",
      "Iteration 6766, loss = 0.00344006\n",
      "Iteration 6767, loss = 0.00343939\n",
      "Iteration 6768, loss = 0.00343874\n",
      "Iteration 6769, loss = 0.00343819\n",
      "Iteration 6770, loss = 0.00343727\n",
      "Iteration 6771, loss = 0.00343680\n",
      "Iteration 6772, loss = 0.00343598\n",
      "Iteration 6773, loss = 0.00343580\n",
      "Iteration 6774, loss = 0.00343456\n",
      "Iteration 6775, loss = 0.00343381\n",
      "Iteration 6776, loss = 0.00343337\n",
      "Iteration 6777, loss = 0.00343245\n",
      "Iteration 6778, loss = 0.00343175\n",
      "Iteration 6779, loss = 0.00343078\n",
      "Iteration 6780, loss = 0.00343001\n",
      "Iteration 6781, loss = 0.00342932\n",
      "Iteration 6782, loss = 0.00342864\n",
      "Iteration 6783, loss = 0.00342771\n",
      "Iteration 6784, loss = 0.00342701\n",
      "Iteration 6785, loss = 0.00342633\n",
      "Iteration 6786, loss = 0.00342557\n",
      "Iteration 6787, loss = 0.00342483\n",
      "Iteration 6788, loss = 0.00342413\n",
      "Iteration 6789, loss = 0.00342336\n",
      "Iteration 6790, loss = 0.00342260\n",
      "Iteration 6791, loss = 0.00342186\n",
      "Iteration 6792, loss = 0.00342125\n",
      "Iteration 6793, loss = 0.00342065\n",
      "Iteration 6794, loss = 0.00342005\n",
      "Iteration 6795, loss = 0.00341938\n",
      "Iteration 6796, loss = 0.00341854\n",
      "Iteration 6797, loss = 0.00341770\n",
      "Iteration 6798, loss = 0.00341702\n",
      "Iteration 6799, loss = 0.00341628\n",
      "Iteration 6800, loss = 0.00341565\n",
      "Iteration 6801, loss = 0.00341508\n",
      "Iteration 6802, loss = 0.00341434\n",
      "Iteration 6803, loss = 0.00341369\n",
      "Iteration 6804, loss = 0.00341301\n",
      "Iteration 6805, loss = 0.00341239\n",
      "Iteration 6806, loss = 0.00341174\n",
      "Iteration 6807, loss = 0.00341129\n",
      "Iteration 6808, loss = 0.00341061\n",
      "Iteration 6809, loss = 0.00340976\n",
      "Iteration 6810, loss = 0.00340907\n",
      "Iteration 6811, loss = 0.00340861\n",
      "Iteration 6812, loss = 0.00340793\n",
      "Iteration 6813, loss = 0.00340723\n",
      "Iteration 6814, loss = 0.00340654\n",
      "Iteration 6815, loss = 0.00340599\n",
      "Iteration 6816, loss = 0.00340586\n",
      "Iteration 6817, loss = 0.00340455\n",
      "Iteration 6818, loss = 0.00340396\n",
      "Iteration 6819, loss = 0.00340324\n",
      "Iteration 6820, loss = 0.00340245\n",
      "Iteration 6821, loss = 0.00340178\n",
      "Iteration 6822, loss = 0.00340115\n",
      "Iteration 6823, loss = 0.00340049\n",
      "Iteration 6824, loss = 0.00339987\n",
      "Iteration 6825, loss = 0.00339904\n",
      "Iteration 6826, loss = 0.00339828\n",
      "Iteration 6827, loss = 0.00339772\n",
      "Iteration 6828, loss = 0.00339700\n",
      "Iteration 6829, loss = 0.00339612\n",
      "Iteration 6830, loss = 0.00339539\n",
      "Iteration 6831, loss = 0.00339471\n",
      "Iteration 6832, loss = 0.00339403\n",
      "Iteration 6833, loss = 0.00339344\n",
      "Iteration 6834, loss = 0.00339253\n",
      "Iteration 6835, loss = 0.00339180\n",
      "Iteration 6836, loss = 0.00339111\n",
      "Iteration 6837, loss = 0.00339036\n",
      "Iteration 6838, loss = 0.00338970\n",
      "Iteration 6839, loss = 0.00338888\n",
      "Iteration 6840, loss = 0.00338878\n",
      "Iteration 6841, loss = 0.00338799\n",
      "Iteration 6842, loss = 0.00338686\n",
      "Iteration 6843, loss = 0.00338612\n",
      "Iteration 6844, loss = 0.00338533\n",
      "Iteration 6845, loss = 0.00338461\n",
      "Iteration 6846, loss = 0.00338389\n",
      "Iteration 6847, loss = 0.00338316\n",
      "Iteration 6848, loss = 0.00338245\n",
      "Iteration 6849, loss = 0.00338169\n",
      "Iteration 6850, loss = 0.00338107\n",
      "Iteration 6851, loss = 0.00338035\n",
      "Iteration 6852, loss = 0.00337968\n",
      "Iteration 6853, loss = 0.00337918\n",
      "Iteration 6854, loss = 0.00337847\n",
      "Iteration 6855, loss = 0.00337772\n",
      "Iteration 6856, loss = 0.00337719\n",
      "Iteration 6857, loss = 0.00337663\n",
      "Iteration 6858, loss = 0.00337572\n",
      "Iteration 6859, loss = 0.00337501\n",
      "Iteration 6860, loss = 0.00337419\n",
      "Iteration 6861, loss = 0.00337435\n",
      "Iteration 6862, loss = 0.00337294\n",
      "Iteration 6863, loss = 0.00337226\n",
      "Iteration 6864, loss = 0.00337149\n",
      "Iteration 6865, loss = 0.00337109\n",
      "Iteration 6866, loss = 0.00337027\n",
      "Iteration 6867, loss = 0.00336953\n",
      "Iteration 6868, loss = 0.00336902\n",
      "Iteration 6869, loss = 0.00336816\n",
      "Iteration 6870, loss = 0.00336759\n",
      "Iteration 6871, loss = 0.00336689\n",
      "Iteration 6872, loss = 0.00336663\n",
      "Iteration 6873, loss = 0.00336562\n",
      "Iteration 6874, loss = 0.00336503\n",
      "Iteration 6875, loss = 0.00336433\n",
      "Iteration 6876, loss = 0.00336366\n",
      "Iteration 6877, loss = 0.00336305\n",
      "Iteration 6878, loss = 0.00336289\n",
      "Iteration 6879, loss = 0.00336180\n",
      "Iteration 6880, loss = 0.00336109\n",
      "Iteration 6881, loss = 0.00336040\n",
      "Iteration 6882, loss = 0.00335991\n",
      "Iteration 6883, loss = 0.00335907\n",
      "Iteration 6884, loss = 0.00335850\n",
      "Iteration 6885, loss = 0.00335775\n",
      "Iteration 6886, loss = 0.00335716\n",
      "Iteration 6887, loss = 0.00335645\n",
      "Iteration 6888, loss = 0.00335581\n",
      "Iteration 6889, loss = 0.00335510\n",
      "Iteration 6890, loss = 0.00335446\n",
      "Iteration 6891, loss = 0.00335389\n",
      "Iteration 6892, loss = 0.00335331\n",
      "Iteration 6893, loss = 0.00335256\n",
      "Iteration 6894, loss = 0.00335187\n",
      "Iteration 6895, loss = 0.00335119\n",
      "Iteration 6896, loss = 0.00335059\n",
      "Iteration 6897, loss = 0.00335000\n",
      "Iteration 6898, loss = 0.00334937\n",
      "Iteration 6899, loss = 0.00334879\n",
      "Iteration 6900, loss = 0.00334800\n",
      "Iteration 6901, loss = 0.00334744\n",
      "Iteration 6902, loss = 0.00334692\n",
      "Iteration 6903, loss = 0.00334591\n",
      "Iteration 6904, loss = 0.00334523\n",
      "Iteration 6905, loss = 0.00334473\n",
      "Iteration 6906, loss = 0.00334406\n",
      "Iteration 6907, loss = 0.00334367\n",
      "Iteration 6908, loss = 0.00334269\n",
      "Iteration 6909, loss = 0.00334205\n",
      "Iteration 6910, loss = 0.00334131\n",
      "Iteration 6911, loss = 0.00334059\n",
      "Iteration 6912, loss = 0.00333984\n",
      "Iteration 6913, loss = 0.00333953\n",
      "Iteration 6914, loss = 0.00333843\n",
      "Iteration 6915, loss = 0.00333767\n",
      "Iteration 6916, loss = 0.00333711\n",
      "Iteration 6917, loss = 0.00333618\n",
      "Iteration 6918, loss = 0.00333558\n",
      "Iteration 6919, loss = 0.00333489\n",
      "Iteration 6920, loss = 0.00333409\n",
      "Iteration 6921, loss = 0.00333340\n",
      "Iteration 6922, loss = 0.00333292\n",
      "Iteration 6923, loss = 0.00333214\n",
      "Iteration 6924, loss = 0.00333154\n",
      "Iteration 6925, loss = 0.00333072\n",
      "Iteration 6926, loss = 0.00333013\n",
      "Iteration 6927, loss = 0.00332933\n",
      "Iteration 6928, loss = 0.00332874\n",
      "Iteration 6929, loss = 0.00332796\n",
      "Iteration 6930, loss = 0.00332748\n",
      "Iteration 6931, loss = 0.00332662\n",
      "Iteration 6932, loss = 0.00332618\n",
      "Iteration 6933, loss = 0.00332532\n",
      "Iteration 6934, loss = 0.00332471\n",
      "Iteration 6935, loss = 0.00332402\n",
      "Iteration 6936, loss = 0.00332316\n",
      "Iteration 6937, loss = 0.00332261\n",
      "Iteration 6938, loss = 0.00332183\n",
      "Iteration 6939, loss = 0.00332112\n",
      "Iteration 6940, loss = 0.00332056\n",
      "Iteration 6941, loss = 0.00331963\n",
      "Iteration 6942, loss = 0.00331894\n",
      "Iteration 6943, loss = 0.00331818\n",
      "Iteration 6944, loss = 0.00331766\n",
      "Iteration 6945, loss = 0.00331681\n",
      "Iteration 6946, loss = 0.00331614\n",
      "Iteration 6947, loss = 0.00331539\n",
      "Iteration 6948, loss = 0.00331465\n",
      "Iteration 6949, loss = 0.00331383\n",
      "Iteration 6950, loss = 0.00331296\n",
      "Iteration 6951, loss = 0.00331259\n",
      "Iteration 6952, loss = 0.00331192\n",
      "Iteration 6953, loss = 0.00331145\n",
      "Iteration 6954, loss = 0.00331046\n",
      "Iteration 6955, loss = 0.00330985\n",
      "Iteration 6956, loss = 0.00330914\n",
      "Iteration 6957, loss = 0.00330859\n",
      "Iteration 6958, loss = 0.00330779\n",
      "Iteration 6959, loss = 0.00330737\n",
      "Iteration 6960, loss = 0.00330644\n",
      "Iteration 6961, loss = 0.00330585\n",
      "Iteration 6962, loss = 0.00330521\n",
      "Iteration 6963, loss = 0.00330449\n",
      "Iteration 6964, loss = 0.00330388\n",
      "Iteration 6965, loss = 0.00330316\n",
      "Iteration 6966, loss = 0.00330267\n",
      "Iteration 6967, loss = 0.00330192\n",
      "Iteration 6968, loss = 0.00330133\n",
      "Iteration 6969, loss = 0.00330066\n",
      "Iteration 6970, loss = 0.00330009\n",
      "Iteration 6971, loss = 0.00329944\n",
      "Iteration 6972, loss = 0.00329894\n",
      "Iteration 6973, loss = 0.00329805\n",
      "Iteration 6974, loss = 0.00329757\n",
      "Iteration 6975, loss = 0.00329661\n",
      "Iteration 6976, loss = 0.00329584\n",
      "Iteration 6977, loss = 0.00329557\n",
      "Iteration 6978, loss = 0.00329470\n",
      "Iteration 6979, loss = 0.00329385\n",
      "Iteration 6980, loss = 0.00329313\n",
      "Iteration 6981, loss = 0.00329243\n",
      "Iteration 6982, loss = 0.00329203\n",
      "Iteration 6983, loss = 0.00329105\n",
      "Iteration 6984, loss = 0.00329023\n",
      "Iteration 6985, loss = 0.00328972\n",
      "Iteration 6986, loss = 0.00328917\n",
      "Iteration 6987, loss = 0.00328834\n",
      "Iteration 6988, loss = 0.00328763\n",
      "Iteration 6989, loss = 0.00328697\n",
      "Iteration 6990, loss = 0.00328643\n",
      "Iteration 6991, loss = 0.00328566\n",
      "Iteration 6992, loss = 0.00328499\n",
      "Iteration 6993, loss = 0.00328440\n",
      "Iteration 6994, loss = 0.00328383\n",
      "Iteration 6995, loss = 0.00328325\n",
      "Iteration 6996, loss = 0.00328260\n",
      "Iteration 6997, loss = 0.00328239\n",
      "Iteration 6998, loss = 0.00328128\n",
      "Iteration 6999, loss = 0.00328064\n",
      "Iteration 7000, loss = 0.00328015\n",
      "Iteration 7001, loss = 0.00327939\n",
      "Iteration 7002, loss = 0.00327889\n",
      "Iteration 7003, loss = 0.00327810\n",
      "Iteration 7004, loss = 0.00327752\n",
      "Iteration 7005, loss = 0.00327680\n",
      "Iteration 7006, loss = 0.00327627\n",
      "Iteration 7007, loss = 0.00327571\n",
      "Iteration 7008, loss = 0.00327511\n",
      "Iteration 7009, loss = 0.00327439\n",
      "Iteration 7010, loss = 0.00327363\n",
      "Iteration 7011, loss = 0.00327318\n",
      "Iteration 7012, loss = 0.00327221\n",
      "Iteration 7013, loss = 0.00327145\n",
      "Iteration 7014, loss = 0.00327118\n",
      "Iteration 7015, loss = 0.00326996\n",
      "Iteration 7016, loss = 0.00326913\n",
      "Iteration 7017, loss = 0.00326884\n",
      "Iteration 7018, loss = 0.00326766\n",
      "Iteration 7019, loss = 0.00326735\n",
      "Iteration 7020, loss = 0.00326621\n",
      "Iteration 7021, loss = 0.00326575\n",
      "Iteration 7022, loss = 0.00326491\n",
      "Iteration 7023, loss = 0.00326410\n",
      "Iteration 7024, loss = 0.00326344\n",
      "Iteration 7025, loss = 0.00326274\n",
      "Iteration 7026, loss = 0.00326218\n",
      "Iteration 7027, loss = 0.00326139\n",
      "Iteration 7028, loss = 0.00326084\n",
      "Iteration 7029, loss = 0.00326007\n",
      "Iteration 7030, loss = 0.00325957\n",
      "Iteration 7031, loss = 0.00325895\n",
      "Iteration 7032, loss = 0.00325790\n",
      "Iteration 7033, loss = 0.00325732\n",
      "Iteration 7034, loss = 0.00325659\n",
      "Iteration 7035, loss = 0.00325616\n",
      "Iteration 7036, loss = 0.00325541\n",
      "Iteration 7037, loss = 0.00325514\n",
      "Iteration 7038, loss = 0.00325461\n",
      "Iteration 7039, loss = 0.00325373\n",
      "Iteration 7040, loss = 0.00325306\n",
      "Iteration 7041, loss = 0.00325258\n",
      "Iteration 7042, loss = 0.00325185\n",
      "Iteration 7043, loss = 0.00325114\n",
      "Iteration 7044, loss = 0.00325045\n",
      "Iteration 7045, loss = 0.00324998\n",
      "Iteration 7046, loss = 0.00324931\n",
      "Iteration 7047, loss = 0.00324856\n",
      "Iteration 7048, loss = 0.00324781\n",
      "Iteration 7049, loss = 0.00324727\n",
      "Iteration 7050, loss = 0.00324651\n",
      "Iteration 7051, loss = 0.00324592\n",
      "Iteration 7052, loss = 0.00324526\n",
      "Iteration 7053, loss = 0.00324476\n",
      "Iteration 7054, loss = 0.00324387\n",
      "Iteration 7055, loss = 0.00324321\n",
      "Iteration 7056, loss = 0.00324245\n",
      "Iteration 7057, loss = 0.00324182\n",
      "Iteration 7058, loss = 0.00324115\n",
      "Iteration 7059, loss = 0.00324058\n",
      "Iteration 7060, loss = 0.00323999\n",
      "Iteration 7061, loss = 0.00323941\n",
      "Iteration 7062, loss = 0.00323876\n",
      "Iteration 7063, loss = 0.00323812\n",
      "Iteration 7064, loss = 0.00323751\n",
      "Iteration 7065, loss = 0.00323687\n",
      "Iteration 7066, loss = 0.00323617\n",
      "Iteration 7067, loss = 0.00323556\n",
      "Iteration 7068, loss = 0.00323494\n",
      "Iteration 7069, loss = 0.00323423\n",
      "Iteration 7070, loss = 0.00323363\n",
      "Iteration 7071, loss = 0.00323291\n",
      "Iteration 7072, loss = 0.00323256\n",
      "Iteration 7073, loss = 0.00323169\n",
      "Iteration 7074, loss = 0.00323108\n",
      "Iteration 7075, loss = 0.00323032\n",
      "Iteration 7076, loss = 0.00322990\n",
      "Iteration 7077, loss = 0.00322880\n",
      "Iteration 7078, loss = 0.00322821\n",
      "Iteration 7079, loss = 0.00322750\n",
      "Iteration 7080, loss = 0.00322684\n",
      "Iteration 7081, loss = 0.00322638\n",
      "Iteration 7082, loss = 0.00322573\n",
      "Iteration 7083, loss = 0.00322497\n",
      "Iteration 7084, loss = 0.00322454\n",
      "Iteration 7085, loss = 0.00322358\n",
      "Iteration 7086, loss = 0.00322293\n",
      "Iteration 7087, loss = 0.00322264\n",
      "Iteration 7088, loss = 0.00322175\n",
      "Iteration 7089, loss = 0.00322127\n",
      "Iteration 7090, loss = 0.00322047\n",
      "Iteration 7091, loss = 0.00321989\n",
      "Iteration 7092, loss = 0.00321931\n",
      "Iteration 7093, loss = 0.00321864\n",
      "Iteration 7094, loss = 0.00321795\n",
      "Iteration 7095, loss = 0.00321735\n",
      "Iteration 7096, loss = 0.00321679\n",
      "Iteration 7097, loss = 0.00321621\n",
      "Iteration 7098, loss = 0.00321596\n",
      "Iteration 7099, loss = 0.00321508\n",
      "Iteration 7100, loss = 0.00321447\n",
      "Iteration 7101, loss = 0.00321371\n",
      "Iteration 7102, loss = 0.00321300\n",
      "Iteration 7103, loss = 0.00321246\n",
      "Iteration 7104, loss = 0.00321202\n",
      "Iteration 7105, loss = 0.00321123\n",
      "Iteration 7106, loss = 0.00321064\n",
      "Iteration 7107, loss = 0.00321005\n",
      "Iteration 7108, loss = 0.00320948\n",
      "Iteration 7109, loss = 0.00320904\n",
      "Iteration 7110, loss = 0.00320826\n",
      "Iteration 7111, loss = 0.00320766\n",
      "Iteration 7112, loss = 0.00320736\n",
      "Iteration 7113, loss = 0.00320656\n",
      "Iteration 7114, loss = 0.00320600\n",
      "Iteration 7115, loss = 0.00320571\n",
      "Iteration 7116, loss = 0.00320469\n",
      "Iteration 7117, loss = 0.00320423\n",
      "Iteration 7118, loss = 0.00320357\n",
      "Iteration 7119, loss = 0.00320290\n",
      "Iteration 7120, loss = 0.00320228\n",
      "Iteration 7121, loss = 0.00320161\n",
      "Iteration 7122, loss = 0.00320088\n",
      "Iteration 7123, loss = 0.00320050\n",
      "Iteration 7124, loss = 0.00319993\n",
      "Iteration 7125, loss = 0.00319924\n",
      "Iteration 7126, loss = 0.00319859\n",
      "Iteration 7127, loss = 0.00319797\n",
      "Iteration 7128, loss = 0.00319751\n",
      "Iteration 7129, loss = 0.00319692\n",
      "Iteration 7130, loss = 0.00319625\n",
      "Iteration 7131, loss = 0.00319559\n",
      "Iteration 7132, loss = 0.00319510\n",
      "Iteration 7133, loss = 0.00319436\n",
      "Iteration 7134, loss = 0.00319364\n",
      "Iteration 7135, loss = 0.00319305\n",
      "Iteration 7136, loss = 0.00319236\n",
      "Iteration 7137, loss = 0.00319171\n",
      "Iteration 7138, loss = 0.00319108\n",
      "Iteration 7139, loss = 0.00319050\n",
      "Iteration 7140, loss = 0.00318989\n",
      "Iteration 7141, loss = 0.00318937\n",
      "Iteration 7142, loss = 0.00318876\n",
      "Iteration 7143, loss = 0.00318814\n",
      "Iteration 7144, loss = 0.00318752\n",
      "Iteration 7145, loss = 0.00318695\n",
      "Iteration 7146, loss = 0.00318628\n",
      "Iteration 7147, loss = 0.00318579\n",
      "Iteration 7148, loss = 0.00318526\n",
      "Iteration 7149, loss = 0.00318497\n",
      "Iteration 7150, loss = 0.00318411\n",
      "Iteration 7151, loss = 0.00318347\n",
      "Iteration 7152, loss = 0.00318287\n",
      "Iteration 7153, loss = 0.00318225\n",
      "Iteration 7154, loss = 0.00318161\n",
      "Iteration 7155, loss = 0.00318104\n",
      "Iteration 7156, loss = 0.00318040\n",
      "Iteration 7157, loss = 0.00317984\n",
      "Iteration 7158, loss = 0.00317922\n",
      "Iteration 7159, loss = 0.00317892\n",
      "Iteration 7160, loss = 0.00317806\n",
      "Iteration 7161, loss = 0.00317739\n",
      "Iteration 7162, loss = 0.00317676\n",
      "Iteration 7163, loss = 0.00317607\n",
      "Iteration 7164, loss = 0.00317559\n",
      "Iteration 7165, loss = 0.00317471\n",
      "Iteration 7166, loss = 0.00317403\n",
      "Iteration 7167, loss = 0.00317339\n",
      "Iteration 7168, loss = 0.00317290\n",
      "Iteration 7169, loss = 0.00317206\n",
      "Iteration 7170, loss = 0.00317174\n",
      "Iteration 7171, loss = 0.00317089\n",
      "Iteration 7172, loss = 0.00317031\n",
      "Iteration 7173, loss = 0.00316974\n",
      "Iteration 7174, loss = 0.00316913\n",
      "Iteration 7175, loss = 0.00316860\n",
      "Iteration 7176, loss = 0.00316798\n",
      "Iteration 7177, loss = 0.00316739\n",
      "Iteration 7178, loss = 0.00316681\n",
      "Iteration 7179, loss = 0.00316624\n",
      "Iteration 7180, loss = 0.00316565\n",
      "Iteration 7181, loss = 0.00316526\n",
      "Iteration 7182, loss = 0.00316439\n",
      "Iteration 7183, loss = 0.00316377\n",
      "Iteration 7184, loss = 0.00316317\n",
      "Iteration 7185, loss = 0.00316248\n",
      "Iteration 7186, loss = 0.00316203\n",
      "Iteration 7187, loss = 0.00316121\n",
      "Iteration 7188, loss = 0.00316075\n",
      "Iteration 7189, loss = 0.00316008\n",
      "Iteration 7190, loss = 0.00315953\n",
      "Iteration 7191, loss = 0.00315892\n",
      "Iteration 7192, loss = 0.00315825\n",
      "Iteration 7193, loss = 0.00315749\n",
      "Iteration 7194, loss = 0.00315707\n",
      "Iteration 7195, loss = 0.00315648\n",
      "Iteration 7196, loss = 0.00315599\n",
      "Iteration 7197, loss = 0.00315520\n",
      "Iteration 7198, loss = 0.00315476\n",
      "Iteration 7199, loss = 0.00315398\n",
      "Iteration 7200, loss = 0.00315358\n",
      "Iteration 7201, loss = 0.00315288\n",
      "Iteration 7202, loss = 0.00315237\n",
      "Iteration 7203, loss = 0.00315171\n",
      "Iteration 7204, loss = 0.00315114\n",
      "Iteration 7205, loss = 0.00315059\n",
      "Iteration 7206, loss = 0.00314998\n",
      "Iteration 7207, loss = 0.00314987\n",
      "Iteration 7208, loss = 0.00314897\n",
      "Iteration 7209, loss = 0.00314841\n",
      "Iteration 7210, loss = 0.00314788\n",
      "Iteration 7211, loss = 0.00314737\n",
      "Iteration 7212, loss = 0.00314668\n",
      "Iteration 7213, loss = 0.00314599\n",
      "Iteration 7214, loss = 0.00314544\n",
      "Iteration 7215, loss = 0.00314481\n",
      "Iteration 7216, loss = 0.00314432\n",
      "Iteration 7217, loss = 0.00314339\n",
      "Iteration 7218, loss = 0.00314278\n",
      "Iteration 7219, loss = 0.00314230\n",
      "Iteration 7220, loss = 0.00314164\n",
      "Iteration 7221, loss = 0.00314105\n",
      "Iteration 7222, loss = 0.00314046\n",
      "Iteration 7223, loss = 0.00313988\n",
      "Iteration 7224, loss = 0.00313923\n",
      "Iteration 7225, loss = 0.00313873\n",
      "Iteration 7226, loss = 0.00313799\n",
      "Iteration 7227, loss = 0.00313741\n",
      "Iteration 7228, loss = 0.00313687\n",
      "Iteration 7229, loss = 0.00313626\n",
      "Iteration 7230, loss = 0.00313572\n",
      "Iteration 7231, loss = 0.00313510\n",
      "Iteration 7232, loss = 0.00313458\n",
      "Iteration 7233, loss = 0.00313385\n",
      "Iteration 7234, loss = 0.00313326\n",
      "Iteration 7235, loss = 0.00313266\n",
      "Iteration 7236, loss = 0.00313201\n",
      "Iteration 7237, loss = 0.00313141\n",
      "Iteration 7238, loss = 0.00313091\n",
      "Iteration 7239, loss = 0.00313039\n",
      "Iteration 7240, loss = 0.00312971\n",
      "Iteration 7241, loss = 0.00312903\n",
      "Iteration 7242, loss = 0.00312850\n",
      "Iteration 7243, loss = 0.00312801\n",
      "Iteration 7244, loss = 0.00312732\n",
      "Iteration 7245, loss = 0.00312667\n",
      "Iteration 7246, loss = 0.00312612\n",
      "Iteration 7247, loss = 0.00312553\n",
      "Iteration 7248, loss = 0.00312465\n",
      "Iteration 7249, loss = 0.00312446\n",
      "Iteration 7250, loss = 0.00312346\n",
      "Iteration 7251, loss = 0.00312303\n",
      "Iteration 7252, loss = 0.00312244\n",
      "Iteration 7253, loss = 0.00312182\n",
      "Iteration 7254, loss = 0.00312141\n",
      "Iteration 7255, loss = 0.00312074\n",
      "Iteration 7256, loss = 0.00312046\n",
      "Iteration 7257, loss = 0.00311960\n",
      "Iteration 7258, loss = 0.00311905\n",
      "Iteration 7259, loss = 0.00311846\n",
      "Iteration 7260, loss = 0.00311818\n",
      "Iteration 7261, loss = 0.00311743\n",
      "Iteration 7262, loss = 0.00311672\n",
      "Iteration 7263, loss = 0.00311648\n",
      "Iteration 7264, loss = 0.00311582\n",
      "Iteration 7265, loss = 0.00311507\n",
      "Iteration 7266, loss = 0.00311452\n",
      "Iteration 7267, loss = 0.00311399\n",
      "Iteration 7268, loss = 0.00311333\n",
      "Iteration 7269, loss = 0.00311281\n",
      "Iteration 7270, loss = 0.00311253\n",
      "Iteration 7271, loss = 0.00311174\n",
      "Iteration 7272, loss = 0.00311114\n",
      "Iteration 7273, loss = 0.00311061\n",
      "Iteration 7274, loss = 0.00311003\n",
      "Iteration 7275, loss = 0.00310964\n",
      "Iteration 7276, loss = 0.00310893\n",
      "Iteration 7277, loss = 0.00310838\n",
      "Iteration 7278, loss = 0.00310783\n",
      "Iteration 7279, loss = 0.00310731\n",
      "Iteration 7280, loss = 0.00310674\n",
      "Iteration 7281, loss = 0.00310610\n",
      "Iteration 7282, loss = 0.00310544\n",
      "Iteration 7283, loss = 0.00310478\n",
      "Iteration 7284, loss = 0.00310421\n",
      "Iteration 7285, loss = 0.00310365\n",
      "Iteration 7286, loss = 0.00310302\n",
      "Iteration 7287, loss = 0.00310239\n",
      "Iteration 7288, loss = 0.00310192\n",
      "Iteration 7289, loss = 0.00310110\n",
      "Iteration 7290, loss = 0.00310075\n",
      "Iteration 7291, loss = 0.00310003\n",
      "Iteration 7292, loss = 0.00309933\n",
      "Iteration 7293, loss = 0.00309881\n",
      "Iteration 7294, loss = 0.00309806\n",
      "Iteration 7295, loss = 0.00309754\n",
      "Iteration 7296, loss = 0.00309674\n",
      "Iteration 7297, loss = 0.00309625\n",
      "Iteration 7298, loss = 0.00309558\n",
      "Iteration 7299, loss = 0.00309494\n",
      "Iteration 7300, loss = 0.00309453\n",
      "Iteration 7301, loss = 0.00309378\n",
      "Iteration 7302, loss = 0.00309328\n",
      "Iteration 7303, loss = 0.00309273\n",
      "Iteration 7304, loss = 0.00309222\n",
      "Iteration 7305, loss = 0.00309155\n",
      "Iteration 7306, loss = 0.00309096\n",
      "Iteration 7307, loss = 0.00309040\n",
      "Iteration 7308, loss = 0.00308977\n",
      "Iteration 7309, loss = 0.00308914\n",
      "Iteration 7310, loss = 0.00308845\n",
      "Iteration 7311, loss = 0.00308778\n",
      "Iteration 7312, loss = 0.00308746\n",
      "Iteration 7313, loss = 0.00308710\n",
      "Iteration 7314, loss = 0.00308640\n",
      "Iteration 7315, loss = 0.00308539\n",
      "Iteration 7316, loss = 0.00308466\n",
      "Iteration 7317, loss = 0.00308474\n",
      "Iteration 7318, loss = 0.00308355\n",
      "Iteration 7319, loss = 0.00308296\n",
      "Iteration 7320, loss = 0.00308231\n",
      "Iteration 7321, loss = 0.00308178\n",
      "Iteration 7322, loss = 0.00308115\n",
      "Iteration 7323, loss = 0.00308049\n",
      "Iteration 7324, loss = 0.00307990\n",
      "Iteration 7325, loss = 0.00307935\n",
      "Iteration 7326, loss = 0.00307872\n",
      "Iteration 7327, loss = 0.00307809\n",
      "Iteration 7328, loss = 0.00307771\n",
      "Iteration 7329, loss = 0.00307700\n",
      "Iteration 7330, loss = 0.00307673\n",
      "Iteration 7331, loss = 0.00307596\n",
      "Iteration 7332, loss = 0.00307509\n",
      "Iteration 7333, loss = 0.00307417\n",
      "Iteration 7334, loss = 0.00307398\n",
      "Iteration 7335, loss = 0.00307299\n",
      "Iteration 7336, loss = 0.00307273\n",
      "Iteration 7337, loss = 0.00307187\n",
      "Iteration 7338, loss = 0.00307118\n",
      "Iteration 7339, loss = 0.00307052\n",
      "Iteration 7340, loss = 0.00306988\n",
      "Iteration 7341, loss = 0.00306934\n",
      "Iteration 7342, loss = 0.00306877\n",
      "Iteration 7343, loss = 0.00306837\n",
      "Iteration 7344, loss = 0.00306772\n",
      "Iteration 7345, loss = 0.00306717\n",
      "Iteration 7346, loss = 0.00306661\n",
      "Iteration 7347, loss = 0.00306615\n",
      "Iteration 7348, loss = 0.00306554\n",
      "Iteration 7349, loss = 0.00306511\n",
      "Iteration 7350, loss = 0.00306418\n",
      "Iteration 7351, loss = 0.00306388\n",
      "Iteration 7352, loss = 0.00306323\n",
      "Iteration 7353, loss = 0.00306264\n",
      "Iteration 7354, loss = 0.00306213\n",
      "Iteration 7355, loss = 0.00306164\n",
      "Iteration 7356, loss = 0.00306110\n",
      "Iteration 7357, loss = 0.00306049\n",
      "Iteration 7358, loss = 0.00305997\n",
      "Iteration 7359, loss = 0.00305935\n",
      "Iteration 7360, loss = 0.00305905\n",
      "Iteration 7361, loss = 0.00305830\n",
      "Iteration 7362, loss = 0.00305766\n",
      "Iteration 7363, loss = 0.00305705\n",
      "Iteration 7364, loss = 0.00305672\n",
      "Iteration 7365, loss = 0.00305584\n",
      "Iteration 7366, loss = 0.00305529\n",
      "Iteration 7367, loss = 0.00305453\n",
      "Iteration 7368, loss = 0.00305406\n",
      "Iteration 7369, loss = 0.00305343\n",
      "Iteration 7370, loss = 0.00305277\n",
      "Iteration 7371, loss = 0.00305222\n",
      "Iteration 7372, loss = 0.00305161\n",
      "Iteration 7373, loss = 0.00305104\n",
      "Iteration 7374, loss = 0.00305034\n",
      "Iteration 7375, loss = 0.00304980\n",
      "Iteration 7376, loss = 0.00304923\n",
      "Iteration 7377, loss = 0.00304848\n",
      "Iteration 7378, loss = 0.00304811\n",
      "Iteration 7379, loss = 0.00304724\n",
      "Iteration 7380, loss = 0.00304669\n",
      "Iteration 7381, loss = 0.00304637\n",
      "Iteration 7382, loss = 0.00304543\n",
      "Iteration 7383, loss = 0.00304472\n",
      "Iteration 7384, loss = 0.00304418\n",
      "Iteration 7385, loss = 0.00304351\n",
      "Iteration 7386, loss = 0.00304292\n",
      "Iteration 7387, loss = 0.00304245\n",
      "Iteration 7388, loss = 0.00304171\n",
      "Iteration 7389, loss = 0.00304113\n",
      "Iteration 7390, loss = 0.00304049\n",
      "Iteration 7391, loss = 0.00303987\n",
      "Iteration 7392, loss = 0.00303927\n",
      "Iteration 7393, loss = 0.00303861\n",
      "Iteration 7394, loss = 0.00303799\n",
      "Iteration 7395, loss = 0.00303737\n",
      "Iteration 7396, loss = 0.00303693\n",
      "Iteration 7397, loss = 0.00303621\n",
      "Iteration 7398, loss = 0.00303597\n",
      "Iteration 7399, loss = 0.00303510\n",
      "Iteration 7400, loss = 0.00303449\n",
      "Iteration 7401, loss = 0.00303369\n",
      "Iteration 7402, loss = 0.00303341\n",
      "Iteration 7403, loss = 0.00303274\n",
      "Iteration 7404, loss = 0.00303202\n",
      "Iteration 7405, loss = 0.00303145\n",
      "Iteration 7406, loss = 0.00303083\n",
      "Iteration 7407, loss = 0.00303037\n",
      "Iteration 7408, loss = 0.00302985\n",
      "Iteration 7409, loss = 0.00302944\n",
      "Iteration 7410, loss = 0.00302911\n",
      "Iteration 7411, loss = 0.00302830\n",
      "Iteration 7412, loss = 0.00302771\n",
      "Iteration 7413, loss = 0.00302710\n",
      "Iteration 7414, loss = 0.00302665\n",
      "Iteration 7415, loss = 0.00302606\n",
      "Iteration 7416, loss = 0.00302547\n",
      "Iteration 7417, loss = 0.00302496\n",
      "Iteration 7418, loss = 0.00302438\n",
      "Iteration 7419, loss = 0.00302386\n",
      "Iteration 7420, loss = 0.00302332\n",
      "Iteration 7421, loss = 0.00302286\n",
      "Iteration 7422, loss = 0.00302237\n",
      "Iteration 7423, loss = 0.00302187\n",
      "Iteration 7424, loss = 0.00302126\n",
      "Iteration 7425, loss = 0.00302076\n",
      "Iteration 7426, loss = 0.00302023\n",
      "Iteration 7427, loss = 0.00301964\n",
      "Iteration 7428, loss = 0.00301915\n",
      "Iteration 7429, loss = 0.00301860\n",
      "Iteration 7430, loss = 0.00301815\n",
      "Iteration 7431, loss = 0.00301752\n",
      "Iteration 7432, loss = 0.00301719\n",
      "Iteration 7433, loss = 0.00301640\n",
      "Iteration 7434, loss = 0.00301578\n",
      "Iteration 7435, loss = 0.00301511\n",
      "Iteration 7436, loss = 0.00301453\n",
      "Iteration 7437, loss = 0.00301396\n",
      "Iteration 7438, loss = 0.00301348\n",
      "Iteration 7439, loss = 0.00301280\n",
      "Iteration 7440, loss = 0.00301210\n",
      "Iteration 7441, loss = 0.00301152\n",
      "Iteration 7442, loss = 0.00301109\n",
      "Iteration 7443, loss = 0.00301033\n",
      "Iteration 7444, loss = 0.00300980\n",
      "Iteration 7445, loss = 0.00300925\n",
      "Iteration 7446, loss = 0.00300855\n",
      "Iteration 7447, loss = 0.00300798\n",
      "Iteration 7448, loss = 0.00300763\n",
      "Iteration 7449, loss = 0.00300697\n",
      "Iteration 7450, loss = 0.00300632\n",
      "Iteration 7451, loss = 0.00300578\n",
      "Iteration 7452, loss = 0.00300525\n",
      "Iteration 7453, loss = 0.00300484\n",
      "Iteration 7454, loss = 0.00300431\n",
      "Iteration 7455, loss = 0.00300388\n",
      "Iteration 7456, loss = 0.00300331\n",
      "Iteration 7457, loss = 0.00300291\n",
      "Iteration 7458, loss = 0.00300226\n",
      "Iteration 7459, loss = 0.00300168\n",
      "Iteration 7460, loss = 0.00300104\n",
      "Iteration 7461, loss = 0.00300038\n",
      "Iteration 7462, loss = 0.00299998\n",
      "Iteration 7463, loss = 0.00299934\n",
      "Iteration 7464, loss = 0.00299859\n",
      "Iteration 7465, loss = 0.00299818\n",
      "Iteration 7466, loss = 0.00299754\n",
      "Iteration 7467, loss = 0.00299692\n",
      "Iteration 7468, loss = 0.00299644\n",
      "Iteration 7469, loss = 0.00299572\n",
      "Iteration 7470, loss = 0.00299538\n",
      "Iteration 7471, loss = 0.00299479\n",
      "Iteration 7472, loss = 0.00299409\n",
      "Iteration 7473, loss = 0.00299385\n",
      "Iteration 7474, loss = 0.00299300\n",
      "Iteration 7475, loss = 0.00299243\n",
      "Iteration 7476, loss = 0.00299176\n",
      "Iteration 7477, loss = 0.00299129\n",
      "Iteration 7478, loss = 0.00299066\n",
      "Iteration 7479, loss = 0.00299053\n",
      "Iteration 7480, loss = 0.00298966\n",
      "Iteration 7481, loss = 0.00298925\n",
      "Iteration 7482, loss = 0.00298852\n",
      "Iteration 7483, loss = 0.00298780\n",
      "Iteration 7484, loss = 0.00298727\n",
      "Iteration 7485, loss = 0.00298665\n",
      "Iteration 7486, loss = 0.00298610\n",
      "Iteration 7487, loss = 0.00298550\n",
      "Iteration 7488, loss = 0.00298493\n",
      "Iteration 7489, loss = 0.00298442\n",
      "Iteration 7490, loss = 0.00298391\n",
      "Iteration 7491, loss = 0.00298343\n",
      "Iteration 7492, loss = 0.00298275\n",
      "Iteration 7493, loss = 0.00298221\n",
      "Iteration 7494, loss = 0.00298166\n",
      "Iteration 7495, loss = 0.00298112\n",
      "Iteration 7496, loss = 0.00298056\n",
      "Iteration 7497, loss = 0.00298002\n",
      "Iteration 7498, loss = 0.00297958\n",
      "Iteration 7499, loss = 0.00297883\n",
      "Iteration 7500, loss = 0.00297821\n",
      "Iteration 7501, loss = 0.00297760\n",
      "Iteration 7502, loss = 0.00297699\n",
      "Iteration 7503, loss = 0.00297640\n",
      "Iteration 7504, loss = 0.00297582\n",
      "Iteration 7505, loss = 0.00297514\n",
      "Iteration 7506, loss = 0.00297456\n",
      "Iteration 7507, loss = 0.00297414\n",
      "Iteration 7508, loss = 0.00297337\n",
      "Iteration 7509, loss = 0.00297327\n",
      "Iteration 7510, loss = 0.00297223\n",
      "Iteration 7511, loss = 0.00297173\n",
      "Iteration 7512, loss = 0.00297114\n",
      "Iteration 7513, loss = 0.00297054\n",
      "Iteration 7514, loss = 0.00296998\n",
      "Iteration 7515, loss = 0.00296941\n",
      "Iteration 7516, loss = 0.00296884\n",
      "Iteration 7517, loss = 0.00296846\n",
      "Iteration 7518, loss = 0.00296769\n",
      "Iteration 7519, loss = 0.00296706\n",
      "Iteration 7520, loss = 0.00296703\n",
      "Iteration 7521, loss = 0.00296612\n",
      "Iteration 7522, loss = 0.00296557\n",
      "Iteration 7523, loss = 0.00296512\n",
      "Iteration 7524, loss = 0.00296462\n",
      "Iteration 7525, loss = 0.00296411\n",
      "Iteration 7526, loss = 0.00296344\n",
      "Iteration 7527, loss = 0.00296294\n",
      "Iteration 7528, loss = 0.00296237\n",
      "Iteration 7529, loss = 0.00296195\n",
      "Iteration 7530, loss = 0.00296125\n",
      "Iteration 7531, loss = 0.00296074\n",
      "Iteration 7532, loss = 0.00296016\n",
      "Iteration 7533, loss = 0.00295990\n",
      "Iteration 7534, loss = 0.00295924\n",
      "Iteration 7535, loss = 0.00295870\n",
      "Iteration 7536, loss = 0.00295820\n",
      "Iteration 7537, loss = 0.00295766\n",
      "Iteration 7538, loss = 0.00295740\n",
      "Iteration 7539, loss = 0.00295650\n",
      "Iteration 7540, loss = 0.00295600\n",
      "Iteration 7541, loss = 0.00295567\n",
      "Iteration 7542, loss = 0.00295492\n",
      "Iteration 7543, loss = 0.00295446\n",
      "Iteration 7544, loss = 0.00295395\n",
      "Iteration 7545, loss = 0.00295329\n",
      "Iteration 7546, loss = 0.00295271\n",
      "Iteration 7547, loss = 0.00295232\n",
      "Iteration 7548, loss = 0.00295172\n",
      "Iteration 7549, loss = 0.00295118\n",
      "Iteration 7550, loss = 0.00295055\n",
      "Iteration 7551, loss = 0.00295016\n",
      "Iteration 7552, loss = 0.00294955\n",
      "Iteration 7553, loss = 0.00294903\n",
      "Iteration 7554, loss = 0.00294862\n",
      "Iteration 7555, loss = 0.00294827\n",
      "Iteration 7556, loss = 0.00294765\n",
      "Iteration 7557, loss = 0.00294711\n",
      "Iteration 7558, loss = 0.00294649\n",
      "Iteration 7559, loss = 0.00294594\n",
      "Iteration 7560, loss = 0.00294546\n",
      "Iteration 7561, loss = 0.00294484\n",
      "Iteration 7562, loss = 0.00294420\n",
      "Iteration 7563, loss = 0.00294364\n",
      "Iteration 7564, loss = 0.00294308\n",
      "Iteration 7565, loss = 0.00294265\n",
      "Iteration 7566, loss = 0.00294202\n",
      "Iteration 7567, loss = 0.00294165\n",
      "Iteration 7568, loss = 0.00294080\n",
      "Iteration 7569, loss = 0.00294021\n",
      "Iteration 7570, loss = 0.00293961\n",
      "Iteration 7571, loss = 0.00293935\n",
      "Iteration 7572, loss = 0.00293887\n",
      "Iteration 7573, loss = 0.00293831\n",
      "Iteration 7574, loss = 0.00293774\n",
      "Iteration 7575, loss = 0.00293711\n",
      "Iteration 7576, loss = 0.00293704\n",
      "Iteration 7577, loss = 0.00293658\n",
      "Iteration 7578, loss = 0.00293593\n",
      "Iteration 7579, loss = 0.00293548\n",
      "Iteration 7580, loss = 0.00293494\n",
      "Iteration 7581, loss = 0.00293435\n",
      "Iteration 7582, loss = 0.00293389\n",
      "Iteration 7583, loss = 0.00293330\n",
      "Iteration 7584, loss = 0.00293266\n",
      "Iteration 7585, loss = 0.00293222\n",
      "Iteration 7586, loss = 0.00293154\n",
      "Iteration 7587, loss = 0.00293109\n",
      "Iteration 7588, loss = 0.00293048\n",
      "Iteration 7589, loss = 0.00292995\n",
      "Iteration 7590, loss = 0.00292933\n",
      "Iteration 7591, loss = 0.00292870\n",
      "Iteration 7592, loss = 0.00292820\n",
      "Iteration 7593, loss = 0.00292757\n",
      "Iteration 7594, loss = 0.00292718\n",
      "Iteration 7595, loss = 0.00292635\n",
      "Iteration 7596, loss = 0.00292571\n",
      "Iteration 7597, loss = 0.00292511\n",
      "Iteration 7598, loss = 0.00292466\n",
      "Iteration 7599, loss = 0.00292393\n",
      "Iteration 7600, loss = 0.00292344\n",
      "Iteration 7601, loss = 0.00292280\n",
      "Iteration 7602, loss = 0.00292225\n",
      "Iteration 7603, loss = 0.00292165\n",
      "Iteration 7604, loss = 0.00292138\n",
      "Iteration 7605, loss = 0.00292055\n",
      "Iteration 7606, loss = 0.00291991\n",
      "Iteration 7607, loss = 0.00291930\n",
      "Iteration 7608, loss = 0.00291900\n",
      "Iteration 7609, loss = 0.00291821\n",
      "Iteration 7610, loss = 0.00291761\n",
      "Iteration 7611, loss = 0.00291756\n",
      "Iteration 7612, loss = 0.00291661\n",
      "Iteration 7613, loss = 0.00291603\n",
      "Iteration 7614, loss = 0.00291547\n",
      "Iteration 7615, loss = 0.00291491\n",
      "Iteration 7616, loss = 0.00291435\n",
      "Iteration 7617, loss = 0.00291381\n",
      "Iteration 7618, loss = 0.00291317\n",
      "Iteration 7619, loss = 0.00291264\n",
      "Iteration 7620, loss = 0.00291250\n",
      "Iteration 7621, loss = 0.00291171\n",
      "Iteration 7622, loss = 0.00291115\n",
      "Iteration 7623, loss = 0.00291054\n",
      "Iteration 7624, loss = 0.00291009\n",
      "Iteration 7625, loss = 0.00290958\n",
      "Iteration 7626, loss = 0.00290899\n",
      "Iteration 7627, loss = 0.00290844\n",
      "Iteration 7628, loss = 0.00290786\n",
      "Iteration 7629, loss = 0.00290731\n",
      "Iteration 7630, loss = 0.00290679\n",
      "Iteration 7631, loss = 0.00290629\n",
      "Iteration 7632, loss = 0.00290578\n",
      "Iteration 7633, loss = 0.00290509\n",
      "Iteration 7634, loss = 0.00290457\n",
      "Iteration 7635, loss = 0.00290416\n",
      "Iteration 7636, loss = 0.00290356\n",
      "Iteration 7637, loss = 0.00290299\n",
      "Iteration 7638, loss = 0.00290250\n",
      "Iteration 7639, loss = 0.00290193\n",
      "Iteration 7640, loss = 0.00290154\n",
      "Iteration 7641, loss = 0.00290094\n",
      "Iteration 7642, loss = 0.00290037\n",
      "Iteration 7643, loss = 0.00289987\n",
      "Iteration 7644, loss = 0.00289935\n",
      "Iteration 7645, loss = 0.00289886\n",
      "Iteration 7646, loss = 0.00289836\n",
      "Iteration 7647, loss = 0.00289832\n",
      "Iteration 7648, loss = 0.00289733\n",
      "Iteration 7649, loss = 0.00289692\n",
      "Iteration 7650, loss = 0.00289614\n",
      "Iteration 7651, loss = 0.00289564\n",
      "Iteration 7652, loss = 0.00289506\n",
      "Iteration 7653, loss = 0.00289452\n",
      "Iteration 7654, loss = 0.00289393\n",
      "Iteration 7655, loss = 0.00289332\n",
      "Iteration 7656, loss = 0.00289276\n",
      "Iteration 7657, loss = 0.00289224\n",
      "Iteration 7658, loss = 0.00289165\n",
      "Iteration 7659, loss = 0.00289127\n",
      "Iteration 7660, loss = 0.00289075\n",
      "Iteration 7661, loss = 0.00289020\n",
      "Iteration 7662, loss = 0.00288971\n",
      "Iteration 7663, loss = 0.00288914\n",
      "Iteration 7664, loss = 0.00288875\n",
      "Iteration 7665, loss = 0.00288819\n",
      "Iteration 7666, loss = 0.00288773\n",
      "Iteration 7667, loss = 0.00288725\n",
      "Iteration 7668, loss = 0.00288681\n",
      "Iteration 7669, loss = 0.00288636\n",
      "Iteration 7670, loss = 0.00288603\n",
      "Iteration 7671, loss = 0.00288548\n",
      "Iteration 7672, loss = 0.00288492\n",
      "Iteration 7673, loss = 0.00288454\n",
      "Iteration 7674, loss = 0.00288412\n",
      "Iteration 7675, loss = 0.00288342\n",
      "Iteration 7676, loss = 0.00288292\n",
      "Iteration 7677, loss = 0.00288227\n",
      "Iteration 7678, loss = 0.00288174\n",
      "Iteration 7679, loss = 0.00288121\n",
      "Iteration 7680, loss = 0.00288067\n",
      "Iteration 7681, loss = 0.00288009\n",
      "Iteration 7682, loss = 0.00287967\n",
      "Iteration 7683, loss = 0.00287911\n",
      "Iteration 7684, loss = 0.00287853\n",
      "Iteration 7685, loss = 0.00287812\n",
      "Iteration 7686, loss = 0.00287765\n",
      "Iteration 7687, loss = 0.00287692\n",
      "Iteration 7688, loss = 0.00287641\n",
      "Iteration 7689, loss = 0.00287588\n",
      "Iteration 7690, loss = 0.00287519\n",
      "Iteration 7691, loss = 0.00287465\n",
      "Iteration 7692, loss = 0.00287408\n",
      "Iteration 7693, loss = 0.00287359\n",
      "Iteration 7694, loss = 0.00287299\n",
      "Iteration 7695, loss = 0.00287247\n",
      "Iteration 7696, loss = 0.00287193\n",
      "Iteration 7697, loss = 0.00287140\n",
      "Iteration 7698, loss = 0.00287135\n",
      "Iteration 7699, loss = 0.00287054\n",
      "Iteration 7700, loss = 0.00286994\n",
      "Iteration 7701, loss = 0.00286943\n",
      "Iteration 7702, loss = 0.00286883\n",
      "Iteration 7703, loss = 0.00286836\n",
      "Iteration 7704, loss = 0.00286776\n",
      "Iteration 7705, loss = 0.00286735\n",
      "Iteration 7706, loss = 0.00286676\n",
      "Iteration 7707, loss = 0.00286623\n",
      "Iteration 7708, loss = 0.00286562\n",
      "Iteration 7709, loss = 0.00286508\n",
      "Iteration 7710, loss = 0.00286456\n",
      "Iteration 7711, loss = 0.00286415\n",
      "Iteration 7712, loss = 0.00286371\n",
      "Iteration 7713, loss = 0.00286314\n",
      "Iteration 7714, loss = 0.00286255\n",
      "Iteration 7715, loss = 0.00286216\n",
      "Iteration 7716, loss = 0.00286168\n",
      "Iteration 7717, loss = 0.00286117\n",
      "Iteration 7718, loss = 0.00286060\n",
      "Iteration 7719, loss = 0.00285997\n",
      "Iteration 7720, loss = 0.00285935\n",
      "Iteration 7721, loss = 0.00285879\n",
      "Iteration 7722, loss = 0.00285838\n",
      "Iteration 7723, loss = 0.00285782\n",
      "Iteration 7724, loss = 0.00285742\n",
      "Iteration 7725, loss = 0.00285690\n",
      "Iteration 7726, loss = 0.00285634\n",
      "Iteration 7727, loss = 0.00285590\n",
      "Iteration 7728, loss = 0.00285531\n",
      "Iteration 7729, loss = 0.00285455\n",
      "Iteration 7730, loss = 0.00285400\n",
      "Iteration 7731, loss = 0.00285352\n",
      "Iteration 7732, loss = 0.00285298\n",
      "Iteration 7733, loss = 0.00285234\n",
      "Iteration 7734, loss = 0.00285187\n",
      "Iteration 7735, loss = 0.00285136\n",
      "Iteration 7736, loss = 0.00285075\n",
      "Iteration 7737, loss = 0.00285029\n",
      "Iteration 7738, loss = 0.00284963\n",
      "Iteration 7739, loss = 0.00284910\n",
      "Iteration 7740, loss = 0.00284879\n",
      "Iteration 7741, loss = 0.00284807\n",
      "Iteration 7742, loss = 0.00284751\n",
      "Iteration 7743, loss = 0.00284694\n",
      "Iteration 7744, loss = 0.00284629\n",
      "Iteration 7745, loss = 0.00284624\n",
      "Iteration 7746, loss = 0.00284527\n",
      "Iteration 7747, loss = 0.00284476\n",
      "Iteration 7748, loss = 0.00284430\n",
      "Iteration 7749, loss = 0.00284360\n",
      "Iteration 7750, loss = 0.00284306\n",
      "Iteration 7751, loss = 0.00284250\n",
      "Iteration 7752, loss = 0.00284201\n",
      "Iteration 7753, loss = 0.00284146\n",
      "Iteration 7754, loss = 0.00284107\n",
      "Iteration 7755, loss = 0.00284050\n",
      "Iteration 7756, loss = 0.00284001\n",
      "Iteration 7757, loss = 0.00283954\n",
      "Iteration 7758, loss = 0.00283909\n",
      "Iteration 7759, loss = 0.00283858\n",
      "Iteration 7760, loss = 0.00283795\n",
      "Iteration 7761, loss = 0.00283743\n",
      "Iteration 7762, loss = 0.00283691\n",
      "Iteration 7763, loss = 0.00283631\n",
      "Iteration 7764, loss = 0.00283576\n",
      "Iteration 7765, loss = 0.00283510\n",
      "Iteration 7766, loss = 0.00283462\n",
      "Iteration 7767, loss = 0.00283398\n",
      "Iteration 7768, loss = 0.00283352\n",
      "Iteration 7769, loss = 0.00283300\n",
      "Iteration 7770, loss = 0.00283249\n",
      "Iteration 7771, loss = 0.00283184\n",
      "Iteration 7772, loss = 0.00283127\n",
      "Iteration 7773, loss = 0.00283064\n",
      "Iteration 7774, loss = 0.00283018\n",
      "Iteration 7775, loss = 0.00282971\n",
      "Iteration 7776, loss = 0.00282918\n",
      "Iteration 7777, loss = 0.00282857\n",
      "Iteration 7778, loss = 0.00282806\n",
      "Iteration 7779, loss = 0.00282757\n",
      "Iteration 7780, loss = 0.00282694\n",
      "Iteration 7781, loss = 0.00282649\n",
      "Iteration 7782, loss = 0.00282585\n",
      "Iteration 7783, loss = 0.00282533\n",
      "Iteration 7784, loss = 0.00282469\n",
      "Iteration 7785, loss = 0.00282489\n",
      "Iteration 7786, loss = 0.00282382\n",
      "Iteration 7787, loss = 0.00282342\n",
      "Iteration 7788, loss = 0.00282293\n",
      "Iteration 7789, loss = 0.00282241\n",
      "Iteration 7790, loss = 0.00282191\n",
      "Iteration 7791, loss = 0.00282136\n",
      "Iteration 7792, loss = 0.00282110\n",
      "Iteration 7793, loss = 0.00282056\n",
      "Iteration 7794, loss = 0.00282005\n",
      "Iteration 7795, loss = 0.00281956\n",
      "Iteration 7796, loss = 0.00281910\n",
      "Iteration 7797, loss = 0.00281862\n",
      "Iteration 7798, loss = 0.00281804\n",
      "Iteration 7799, loss = 0.00281759\n",
      "Iteration 7800, loss = 0.00281715\n",
      "Iteration 7801, loss = 0.00281658\n",
      "Iteration 7802, loss = 0.00281619\n",
      "Iteration 7803, loss = 0.00281555\n",
      "Iteration 7804, loss = 0.00281502\n",
      "Iteration 7805, loss = 0.00281451\n",
      "Iteration 7806, loss = 0.00281406\n",
      "Iteration 7807, loss = 0.00281366\n",
      "Iteration 7808, loss = 0.00281315\n",
      "Iteration 7809, loss = 0.00281270\n",
      "Iteration 7810, loss = 0.00281216\n",
      "Iteration 7811, loss = 0.00281171\n",
      "Iteration 7812, loss = 0.00281139\n",
      "Iteration 7813, loss = 0.00281073\n",
      "Iteration 7814, loss = 0.00281019\n",
      "Iteration 7815, loss = 0.00280959\n",
      "Iteration 7816, loss = 0.00280921\n",
      "Iteration 7817, loss = 0.00280868\n",
      "Iteration 7818, loss = 0.00280814\n",
      "Iteration 7819, loss = 0.00280760\n",
      "Iteration 7820, loss = 0.00280716\n",
      "Iteration 7821, loss = 0.00280660\n",
      "Iteration 7822, loss = 0.00280606\n",
      "Iteration 7823, loss = 0.00280556\n",
      "Iteration 7824, loss = 0.00280533\n",
      "Iteration 7825, loss = 0.00280468\n",
      "Iteration 7826, loss = 0.00280402\n",
      "Iteration 7827, loss = 0.00280352\n",
      "Iteration 7828, loss = 0.00280305\n",
      "Iteration 7829, loss = 0.00280251\n",
      "Iteration 7830, loss = 0.00280249\n",
      "Iteration 7831, loss = 0.00280166\n",
      "Iteration 7832, loss = 0.00280104\n",
      "Iteration 7833, loss = 0.00280057\n",
      "Iteration 7834, loss = 0.00280003\n",
      "Iteration 7835, loss = 0.00279957\n",
      "Iteration 7836, loss = 0.00279919\n",
      "Iteration 7837, loss = 0.00279868\n",
      "Iteration 7838, loss = 0.00279803\n",
      "Iteration 7839, loss = 0.00279765\n",
      "Iteration 7840, loss = 0.00279695\n",
      "Iteration 7841, loss = 0.00279645\n",
      "Iteration 7842, loss = 0.00279596\n",
      "Iteration 7843, loss = 0.00279540\n",
      "Iteration 7844, loss = 0.00279504\n",
      "Iteration 7845, loss = 0.00279434\n",
      "Iteration 7846, loss = 0.00279386\n",
      "Iteration 7847, loss = 0.00279333\n",
      "Iteration 7848, loss = 0.00279286\n",
      "Iteration 7849, loss = 0.00279245\n",
      "Iteration 7850, loss = 0.00279202\n",
      "Iteration 7851, loss = 0.00279132\n",
      "Iteration 7852, loss = 0.00279085\n",
      "Iteration 7853, loss = 0.00279038\n",
      "Iteration 7854, loss = 0.00278992\n",
      "Iteration 7855, loss = 0.00278944\n",
      "Iteration 7856, loss = 0.00278902\n",
      "Iteration 7857, loss = 0.00278850\n",
      "Iteration 7858, loss = 0.00278804\n",
      "Iteration 7859, loss = 0.00278755\n",
      "Iteration 7860, loss = 0.00278717\n",
      "Iteration 7861, loss = 0.00278674\n",
      "Iteration 7862, loss = 0.00278617\n",
      "Iteration 7863, loss = 0.00278569\n",
      "Iteration 7864, loss = 0.00278526\n",
      "Iteration 7865, loss = 0.00278469\n",
      "Iteration 7866, loss = 0.00278424\n",
      "Iteration 7867, loss = 0.00278377\n",
      "Iteration 7868, loss = 0.00278333\n",
      "Iteration 7869, loss = 0.00278296\n",
      "Iteration 7870, loss = 0.00278238\n",
      "Iteration 7871, loss = 0.00278203\n",
      "Iteration 7872, loss = 0.00278152\n",
      "Iteration 7873, loss = 0.00278101\n",
      "Iteration 7874, loss = 0.00278072\n",
      "Iteration 7875, loss = 0.00278014\n",
      "Iteration 7876, loss = 0.00277969\n",
      "Iteration 7877, loss = 0.00277920\n",
      "Iteration 7878, loss = 0.00277904\n",
      "Iteration 7879, loss = 0.00277836\n",
      "Iteration 7880, loss = 0.00277784\n",
      "Iteration 7881, loss = 0.00277745\n",
      "Iteration 7882, loss = 0.00277687\n",
      "Iteration 7883, loss = 0.00277654\n",
      "Iteration 7884, loss = 0.00277602\n",
      "Iteration 7885, loss = 0.00277543\n",
      "Iteration 7886, loss = 0.00277495\n",
      "Iteration 7887, loss = 0.00277444\n",
      "Iteration 7888, loss = 0.00277427\n",
      "Iteration 7889, loss = 0.00277360\n",
      "Iteration 7890, loss = 0.00277315\n",
      "Iteration 7891, loss = 0.00277262\n",
      "Iteration 7892, loss = 0.00277221\n",
      "Iteration 7893, loss = 0.00277169\n",
      "Iteration 7894, loss = 0.00277120\n",
      "Iteration 7895, loss = 0.00277077\n",
      "Iteration 7896, loss = 0.00277029\n",
      "Iteration 7897, loss = 0.00276994\n",
      "Iteration 7898, loss = 0.00276955\n",
      "Iteration 7899, loss = 0.00276900\n",
      "Iteration 7900, loss = 0.00276848\n",
      "Iteration 7901, loss = 0.00276804\n",
      "Iteration 7902, loss = 0.00276750\n",
      "Iteration 7903, loss = 0.00276727\n",
      "Iteration 7904, loss = 0.00276662\n",
      "Iteration 7905, loss = 0.00276618\n",
      "Iteration 7906, loss = 0.00276571\n",
      "Iteration 7907, loss = 0.00276508\n",
      "Iteration 7908, loss = 0.00276466\n",
      "Iteration 7909, loss = 0.00276416\n",
      "Iteration 7910, loss = 0.00276380\n",
      "Iteration 7911, loss = 0.00276326\n",
      "Iteration 7912, loss = 0.00276294\n",
      "Iteration 7913, loss = 0.00276219\n",
      "Iteration 7914, loss = 0.00276203\n",
      "Iteration 7915, loss = 0.00276125\n",
      "Iteration 7916, loss = 0.00276099\n",
      "Iteration 7917, loss = 0.00276036\n",
      "Iteration 7918, loss = 0.00275980\n",
      "Iteration 7919, loss = 0.00275926\n",
      "Iteration 7920, loss = 0.00275888\n",
      "Iteration 7921, loss = 0.00275833\n",
      "Iteration 7922, loss = 0.00275789\n",
      "Iteration 7923, loss = 0.00275744\n",
      "Iteration 7924, loss = 0.00275702\n",
      "Iteration 7925, loss = 0.00275665\n",
      "Iteration 7926, loss = 0.00275614\n",
      "Iteration 7927, loss = 0.00275549\n",
      "Iteration 7928, loss = 0.00275527\n",
      "Iteration 7929, loss = 0.00275464\n",
      "Iteration 7930, loss = 0.00275411\n",
      "Iteration 7931, loss = 0.00275364\n",
      "Iteration 7932, loss = 0.00275323\n",
      "Iteration 7933, loss = 0.00275277\n",
      "Iteration 7934, loss = 0.00275233\n",
      "Iteration 7935, loss = 0.00275192\n",
      "Iteration 7936, loss = 0.00275155\n",
      "Iteration 7937, loss = 0.00275098\n",
      "Iteration 7938, loss = 0.00275059\n",
      "Iteration 7939, loss = 0.00275022\n",
      "Iteration 7940, loss = 0.00274978\n",
      "Iteration 7941, loss = 0.00274935\n",
      "Iteration 7942, loss = 0.00274883\n",
      "Iteration 7943, loss = 0.00274846\n",
      "Iteration 7944, loss = 0.00274777\n",
      "Iteration 7945, loss = 0.00274712\n",
      "Iteration 7946, loss = 0.00274694\n",
      "Iteration 7947, loss = 0.00274616\n",
      "Iteration 7948, loss = 0.00274567\n",
      "Iteration 7949, loss = 0.00274505\n",
      "Iteration 7950, loss = 0.00274499\n",
      "Iteration 7951, loss = 0.00274420\n",
      "Iteration 7952, loss = 0.00274370\n",
      "Iteration 7953, loss = 0.00274318\n",
      "Iteration 7954, loss = 0.00274272\n",
      "Iteration 7955, loss = 0.00274223\n",
      "Iteration 7956, loss = 0.00274187\n",
      "Iteration 7957, loss = 0.00274127\n",
      "Iteration 7958, loss = 0.00274092\n",
      "Iteration 7959, loss = 0.00274030\n",
      "Iteration 7960, loss = 0.00273982\n",
      "Iteration 7961, loss = 0.00273940\n",
      "Iteration 7962, loss = 0.00273901\n",
      "Iteration 7963, loss = 0.00273827\n",
      "Iteration 7964, loss = 0.00273778\n",
      "Iteration 7965, loss = 0.00273746\n",
      "Iteration 7966, loss = 0.00273685\n",
      "Iteration 7967, loss = 0.00273634\n",
      "Iteration 7968, loss = 0.00273583\n",
      "Iteration 7969, loss = 0.00273545\n",
      "Iteration 7970, loss = 0.00273493\n",
      "Iteration 7971, loss = 0.00273434\n",
      "Iteration 7972, loss = 0.00273388\n",
      "Iteration 7973, loss = 0.00273341\n",
      "Iteration 7974, loss = 0.00273287\n",
      "Iteration 7975, loss = 0.00273239\n",
      "Iteration 7976, loss = 0.00273189\n",
      "Iteration 7977, loss = 0.00273123\n",
      "Iteration 7978, loss = 0.00273080\n",
      "Iteration 7979, loss = 0.00273020\n",
      "Iteration 7980, loss = 0.00272965\n",
      "Iteration 7981, loss = 0.00272916\n",
      "Iteration 7982, loss = 0.00272872\n",
      "Iteration 7983, loss = 0.00272812\n",
      "Iteration 7984, loss = 0.00272776\n",
      "Iteration 7985, loss = 0.00272723\n",
      "Iteration 7986, loss = 0.00272675\n",
      "Iteration 7987, loss = 0.00272635\n",
      "Iteration 7988, loss = 0.00272590\n",
      "Iteration 7989, loss = 0.00272543\n",
      "Iteration 7990, loss = 0.00272497\n",
      "Iteration 7991, loss = 0.00272446\n",
      "Iteration 7992, loss = 0.00272402\n",
      "Iteration 7993, loss = 0.00272354\n",
      "Iteration 7994, loss = 0.00272305\n",
      "Iteration 7995, loss = 0.00272265\n",
      "Iteration 7996, loss = 0.00272211\n",
      "Iteration 7997, loss = 0.00272168\n",
      "Iteration 7998, loss = 0.00272119\n",
      "Iteration 7999, loss = 0.00272074\n",
      "Iteration 8000, loss = 0.00272022\n",
      "Iteration 1, loss = 1.04533777\n",
      "Iteration 2, loss = 1.04197988\n",
      "Iteration 3, loss = 1.03672599\n",
      "Iteration 4, loss = 1.03014017\n",
      "Iteration 5, loss = 1.02223377\n",
      "Iteration 6, loss = 1.01389917\n",
      "Iteration 7, loss = 1.00474357\n",
      "Iteration 8, loss = 0.99526246\n",
      "Iteration 9, loss = 0.98554390\n",
      "Iteration 10, loss = 0.97556625\n",
      "Iteration 11, loss = 0.96554581\n",
      "Iteration 12, loss = 0.95541138\n",
      "Iteration 13, loss = 0.94545463\n",
      "Iteration 14, loss = 0.93537389\n",
      "Iteration 15, loss = 0.92562783\n",
      "Iteration 16, loss = 0.91595671\n",
      "Iteration 17, loss = 0.90654725\n",
      "Iteration 18, loss = 0.89760892\n",
      "Iteration 19, loss = 0.88862650\n",
      "Iteration 20, loss = 0.88020056\n",
      "Iteration 21, loss = 0.87177416\n",
      "Iteration 22, loss = 0.86383072\n",
      "Iteration 23, loss = 0.85599932\n",
      "Iteration 24, loss = 0.84808456\n",
      "Iteration 25, loss = 0.84077675\n",
      "Iteration 26, loss = 0.83327340\n",
      "Iteration 27, loss = 0.82626859\n",
      "Iteration 28, loss = 0.81908021\n",
      "Iteration 29, loss = 0.81263345\n",
      "Iteration 30, loss = 0.80627099\n",
      "Iteration 31, loss = 0.79981006\n",
      "Iteration 32, loss = 0.79407199\n",
      "Iteration 33, loss = 0.78820908\n",
      "Iteration 34, loss = 0.78250189\n",
      "Iteration 35, loss = 0.77696534\n",
      "Iteration 36, loss = 0.77174100\n",
      "Iteration 37, loss = 0.76651579\n",
      "Iteration 38, loss = 0.76158159\n",
      "Iteration 39, loss = 0.75669047\n",
      "Iteration 40, loss = 0.75200854\n",
      "Iteration 41, loss = 0.74732348\n",
      "Iteration 42, loss = 0.74298072\n",
      "Iteration 43, loss = 0.73846953\n",
      "Iteration 44, loss = 0.73412705\n",
      "Iteration 45, loss = 0.72999926\n",
      "Iteration 46, loss = 0.72580554\n",
      "Iteration 47, loss = 0.72186305\n",
      "Iteration 48, loss = 0.71797971\n",
      "Iteration 49, loss = 0.71415697\n",
      "Iteration 50, loss = 0.71047110\n",
      "Iteration 51, loss = 0.70682267\n",
      "Iteration 52, loss = 0.70329583\n",
      "Iteration 53, loss = 0.69985456\n",
      "Iteration 54, loss = 0.69648640\n",
      "Iteration 55, loss = 0.69304056\n",
      "Iteration 56, loss = 0.68974461\n",
      "Iteration 57, loss = 0.68666158\n",
      "Iteration 58, loss = 0.68329602\n",
      "Iteration 59, loss = 0.68030677\n",
      "Iteration 60, loss = 0.67723692\n",
      "Iteration 61, loss = 0.67430879\n",
      "Iteration 62, loss = 0.67143142\n",
      "Iteration 63, loss = 0.66857475\n",
      "Iteration 64, loss = 0.66575753\n",
      "Iteration 65, loss = 0.66309150\n",
      "Iteration 66, loss = 0.66033774\n",
      "Iteration 67, loss = 0.65764418\n",
      "Iteration 68, loss = 0.65494135\n",
      "Iteration 69, loss = 0.65228927\n",
      "Iteration 70, loss = 0.64968823\n",
      "Iteration 71, loss = 0.64697935\n",
      "Iteration 72, loss = 0.64440231\n",
      "Iteration 73, loss = 0.64180102\n",
      "Iteration 74, loss = 0.63920993\n",
      "Iteration 75, loss = 0.63659168\n",
      "Iteration 76, loss = 0.63403229\n",
      "Iteration 77, loss = 0.63149562\n",
      "Iteration 78, loss = 0.62887533\n",
      "Iteration 79, loss = 0.62631596\n",
      "Iteration 80, loss = 0.62381059\n",
      "Iteration 81, loss = 0.62126474\n",
      "Iteration 82, loss = 0.61876245\n",
      "Iteration 83, loss = 0.61628056\n",
      "Iteration 84, loss = 0.61376837\n",
      "Iteration 85, loss = 0.61124511\n",
      "Iteration 86, loss = 0.60883975\n",
      "Iteration 87, loss = 0.60625140\n",
      "Iteration 88, loss = 0.60381184\n",
      "Iteration 89, loss = 0.60133259\n",
      "Iteration 90, loss = 0.59882031\n",
      "Iteration 91, loss = 0.59640363\n",
      "Iteration 92, loss = 0.59393214\n",
      "Iteration 93, loss = 0.59146374\n",
      "Iteration 94, loss = 0.58903075\n",
      "Iteration 95, loss = 0.58660935\n",
      "Iteration 96, loss = 0.58419309\n",
      "Iteration 97, loss = 0.58178278\n",
      "Iteration 98, loss = 0.57934034\n",
      "Iteration 99, loss = 0.57698279\n",
      "Iteration 100, loss = 0.57460073\n",
      "Iteration 101, loss = 0.57213735\n",
      "Iteration 102, loss = 0.56976020\n",
      "Iteration 103, loss = 0.56733488\n",
      "Iteration 104, loss = 0.56496831\n",
      "Iteration 105, loss = 0.56256520\n",
      "Iteration 106, loss = 0.56022535\n",
      "Iteration 107, loss = 0.55780774\n",
      "Iteration 108, loss = 0.55551813\n",
      "Iteration 109, loss = 0.55316246\n",
      "Iteration 110, loss = 0.55082834\n",
      "Iteration 111, loss = 0.54851314\n",
      "Iteration 112, loss = 0.54618706\n",
      "Iteration 113, loss = 0.54390374\n",
      "Iteration 114, loss = 0.54157557\n",
      "Iteration 115, loss = 0.53926576\n",
      "Iteration 116, loss = 0.53698791\n",
      "Iteration 117, loss = 0.53469017\n",
      "Iteration 118, loss = 0.53239473\n",
      "Iteration 119, loss = 0.53006936\n",
      "Iteration 120, loss = 0.52778652\n",
      "Iteration 121, loss = 0.52548268\n",
      "Iteration 122, loss = 0.52320993\n",
      "Iteration 123, loss = 0.52089119\n",
      "Iteration 124, loss = 0.51862408\n",
      "Iteration 125, loss = 0.51637146\n",
      "Iteration 126, loss = 0.51410980\n",
      "Iteration 127, loss = 0.51183987\n",
      "Iteration 128, loss = 0.50961220\n",
      "Iteration 129, loss = 0.50736292\n",
      "Iteration 130, loss = 0.50511882\n",
      "Iteration 131, loss = 0.50288535\n",
      "Iteration 132, loss = 0.50064922\n",
      "Iteration 133, loss = 0.49844581\n",
      "Iteration 134, loss = 0.49628004\n",
      "Iteration 135, loss = 0.49408994\n",
      "Iteration 136, loss = 0.49190703\n",
      "Iteration 137, loss = 0.48976161\n",
      "Iteration 138, loss = 0.48759299\n",
      "Iteration 139, loss = 0.48545464\n",
      "Iteration 140, loss = 0.48335941\n",
      "Iteration 141, loss = 0.48122433\n",
      "Iteration 142, loss = 0.47912044\n",
      "Iteration 143, loss = 0.47700825\n",
      "Iteration 144, loss = 0.47491437\n",
      "Iteration 145, loss = 0.47279813\n",
      "Iteration 146, loss = 0.47071004\n",
      "Iteration 147, loss = 0.46859083\n",
      "Iteration 148, loss = 0.46654767\n",
      "Iteration 149, loss = 0.46440276\n",
      "Iteration 150, loss = 0.46232900\n",
      "Iteration 151, loss = 0.46024468\n",
      "Iteration 152, loss = 0.45812639\n",
      "Iteration 153, loss = 0.45602343\n",
      "Iteration 154, loss = 0.45392001\n",
      "Iteration 155, loss = 0.45182505\n",
      "Iteration 156, loss = 0.44976944\n",
      "Iteration 157, loss = 0.44764982\n",
      "Iteration 158, loss = 0.44559379\n",
      "Iteration 159, loss = 0.44354011\n",
      "Iteration 160, loss = 0.44148578\n",
      "Iteration 161, loss = 0.43943547\n",
      "Iteration 162, loss = 0.43737854\n",
      "Iteration 163, loss = 0.43531309\n",
      "Iteration 164, loss = 0.43325577\n",
      "Iteration 165, loss = 0.43117178\n",
      "Iteration 166, loss = 0.42908412\n",
      "Iteration 167, loss = 0.42699960\n",
      "Iteration 168, loss = 0.42491502\n",
      "Iteration 169, loss = 0.42280711\n",
      "Iteration 170, loss = 0.42070734\n",
      "Iteration 171, loss = 0.41863541\n",
      "Iteration 172, loss = 0.41654918\n",
      "Iteration 173, loss = 0.41444923\n",
      "Iteration 174, loss = 0.41239454\n",
      "Iteration 175, loss = 0.41032507\n",
      "Iteration 176, loss = 0.40823843\n",
      "Iteration 177, loss = 0.40618314\n",
      "Iteration 178, loss = 0.40409952\n",
      "Iteration 179, loss = 0.40204726\n",
      "Iteration 180, loss = 0.39997350\n",
      "Iteration 181, loss = 0.39793861\n",
      "Iteration 182, loss = 0.39586642\n",
      "Iteration 183, loss = 0.39382274\n",
      "Iteration 184, loss = 0.39176264\n",
      "Iteration 185, loss = 0.38976212\n",
      "Iteration 186, loss = 0.38769682\n",
      "Iteration 187, loss = 0.38565259\n",
      "Iteration 188, loss = 0.38362723\n",
      "Iteration 189, loss = 0.38162080\n",
      "Iteration 190, loss = 0.37958373\n",
      "Iteration 191, loss = 0.37757050\n",
      "Iteration 192, loss = 0.37556722\n",
      "Iteration 193, loss = 0.37357762\n",
      "Iteration 194, loss = 0.37154910\n",
      "Iteration 195, loss = 0.36957282\n",
      "Iteration 196, loss = 0.36754896\n",
      "Iteration 197, loss = 0.36556621\n",
      "Iteration 198, loss = 0.36356522\n",
      "Iteration 199, loss = 0.36157158\n",
      "Iteration 200, loss = 0.35957636\n",
      "Iteration 201, loss = 0.35759488\n",
      "Iteration 202, loss = 0.35561266\n",
      "Iteration 203, loss = 0.35362860\n",
      "Iteration 204, loss = 0.35166325\n",
      "Iteration 205, loss = 0.34969779\n",
      "Iteration 206, loss = 0.34775670\n",
      "Iteration 207, loss = 0.34581535\n",
      "Iteration 208, loss = 0.34385554\n",
      "Iteration 209, loss = 0.34191510\n",
      "Iteration 210, loss = 0.33998870\n",
      "Iteration 211, loss = 0.33804088\n",
      "Iteration 212, loss = 0.33611351\n",
      "Iteration 213, loss = 0.33420178\n",
      "Iteration 214, loss = 0.33225961\n",
      "Iteration 215, loss = 0.33035739\n",
      "Iteration 216, loss = 0.32842593\n",
      "Iteration 217, loss = 0.32653036\n",
      "Iteration 218, loss = 0.32460831\n",
      "Iteration 219, loss = 0.32271409\n",
      "Iteration 220, loss = 0.32081254\n",
      "Iteration 221, loss = 0.31893015\n",
      "Iteration 222, loss = 0.31705595\n",
      "Iteration 223, loss = 0.31519335\n",
      "Iteration 224, loss = 0.31332180\n",
      "Iteration 225, loss = 0.31146929\n",
      "Iteration 226, loss = 0.30963221\n",
      "Iteration 227, loss = 0.30776918\n",
      "Iteration 228, loss = 0.30592646\n",
      "Iteration 229, loss = 0.30408044\n",
      "Iteration 230, loss = 0.30225955\n",
      "Iteration 231, loss = 0.30041997\n",
      "Iteration 232, loss = 0.29860592\n",
      "Iteration 233, loss = 0.29679088\n",
      "Iteration 234, loss = 0.29501181\n",
      "Iteration 235, loss = 0.29320777\n",
      "Iteration 236, loss = 0.29144504\n",
      "Iteration 237, loss = 0.28968817\n",
      "Iteration 238, loss = 0.28792962\n",
      "Iteration 239, loss = 0.28618437\n",
      "Iteration 240, loss = 0.28445278\n",
      "Iteration 241, loss = 0.28272931\n",
      "Iteration 242, loss = 0.28101397\n",
      "Iteration 243, loss = 0.27931649\n",
      "Iteration 244, loss = 0.27762157\n",
      "Iteration 245, loss = 0.27595261\n",
      "Iteration 246, loss = 0.27428335\n",
      "Iteration 247, loss = 0.27261746\n",
      "Iteration 248, loss = 0.27095401\n",
      "Iteration 249, loss = 0.26927899\n",
      "Iteration 250, loss = 0.26765415\n",
      "Iteration 251, loss = 0.26598009\n",
      "Iteration 252, loss = 0.26435005\n",
      "Iteration 253, loss = 0.26273116\n",
      "Iteration 254, loss = 0.26111485\n",
      "Iteration 255, loss = 0.25951445\n",
      "Iteration 256, loss = 0.25792980\n",
      "Iteration 257, loss = 0.25636912\n",
      "Iteration 258, loss = 0.25481027\n",
      "Iteration 259, loss = 0.25323283\n",
      "Iteration 260, loss = 0.25167202\n",
      "Iteration 261, loss = 0.25012734\n",
      "Iteration 262, loss = 0.24859457\n",
      "Iteration 263, loss = 0.24706072\n",
      "Iteration 264, loss = 0.24553567\n",
      "Iteration 265, loss = 0.24404446\n",
      "Iteration 266, loss = 0.24253787\n",
      "Iteration 267, loss = 0.24105158\n",
      "Iteration 268, loss = 0.23958249\n",
      "Iteration 269, loss = 0.23812869\n",
      "Iteration 270, loss = 0.23666253\n",
      "Iteration 271, loss = 0.23524018\n",
      "Iteration 272, loss = 0.23382426\n",
      "Iteration 273, loss = 0.23240184\n",
      "Iteration 274, loss = 0.23101640\n",
      "Iteration 275, loss = 0.22961616\n",
      "Iteration 276, loss = 0.22823304\n",
      "Iteration 277, loss = 0.22686304\n",
      "Iteration 278, loss = 0.22552158\n",
      "Iteration 279, loss = 0.22414145\n",
      "Iteration 280, loss = 0.22281770\n",
      "Iteration 281, loss = 0.22148900\n",
      "Iteration 282, loss = 0.22017380\n",
      "Iteration 283, loss = 0.21885517\n",
      "Iteration 284, loss = 0.21754344\n",
      "Iteration 285, loss = 0.21624562\n",
      "Iteration 286, loss = 0.21496134\n",
      "Iteration 287, loss = 0.21367501\n",
      "Iteration 288, loss = 0.21239573\n",
      "Iteration 289, loss = 0.21113941\n",
      "Iteration 290, loss = 0.20989609\n",
      "Iteration 291, loss = 0.20865125\n",
      "Iteration 292, loss = 0.20742712\n",
      "Iteration 293, loss = 0.20620823\n",
      "Iteration 294, loss = 0.20499466\n",
      "Iteration 295, loss = 0.20379707\n",
      "Iteration 296, loss = 0.20260684\n",
      "Iteration 297, loss = 0.20142977\n",
      "Iteration 298, loss = 0.20025516\n",
      "Iteration 299, loss = 0.19910010\n",
      "Iteration 300, loss = 0.19796264\n",
      "Iteration 301, loss = 0.19682623\n",
      "Iteration 302, loss = 0.19569708\n",
      "Iteration 303, loss = 0.19458779\n",
      "Iteration 304, loss = 0.19348662\n",
      "Iteration 305, loss = 0.19238416\n",
      "Iteration 306, loss = 0.19129840\n",
      "Iteration 307, loss = 0.19021060\n",
      "Iteration 308, loss = 0.18913719\n",
      "Iteration 309, loss = 0.18806666\n",
      "Iteration 310, loss = 0.18701041\n",
      "Iteration 311, loss = 0.18596451\n",
      "Iteration 312, loss = 0.18491772\n",
      "Iteration 313, loss = 0.18388903\n",
      "Iteration 314, loss = 0.18286227\n",
      "Iteration 315, loss = 0.18183945\n",
      "Iteration 316, loss = 0.18083253\n",
      "Iteration 317, loss = 0.17982006\n",
      "Iteration 318, loss = 0.17883127\n",
      "Iteration 319, loss = 0.17783667\n",
      "Iteration 320, loss = 0.17685605\n",
      "Iteration 321, loss = 0.17588318\n",
      "Iteration 322, loss = 0.17491365\n",
      "Iteration 323, loss = 0.17395510\n",
      "Iteration 324, loss = 0.17300928\n",
      "Iteration 325, loss = 0.17206300\n",
      "Iteration 326, loss = 0.17113259\n",
      "Iteration 327, loss = 0.17020037\n",
      "Iteration 328, loss = 0.16927659\n",
      "Iteration 329, loss = 0.16837125\n",
      "Iteration 330, loss = 0.16747907\n",
      "Iteration 331, loss = 0.16657932\n",
      "Iteration 332, loss = 0.16569246\n",
      "Iteration 333, loss = 0.16482690\n",
      "Iteration 334, loss = 0.16396148\n",
      "Iteration 335, loss = 0.16310518\n",
      "Iteration 336, loss = 0.16225803\n",
      "Iteration 337, loss = 0.16142842\n",
      "Iteration 338, loss = 0.16058958\n",
      "Iteration 339, loss = 0.15977236\n",
      "Iteration 340, loss = 0.15894603\n",
      "Iteration 341, loss = 0.15813079\n",
      "Iteration 342, loss = 0.15731929\n",
      "Iteration 343, loss = 0.15652295\n",
      "Iteration 344, loss = 0.15572414\n",
      "Iteration 345, loss = 0.15492624\n",
      "Iteration 346, loss = 0.15414377\n",
      "Iteration 347, loss = 0.15337022\n",
      "Iteration 348, loss = 0.15259619\n",
      "Iteration 349, loss = 0.15183804\n",
      "Iteration 350, loss = 0.15108144\n",
      "Iteration 351, loss = 0.15032614\n",
      "Iteration 352, loss = 0.14957259\n",
      "Iteration 353, loss = 0.14882663\n",
      "Iteration 354, loss = 0.14807552\n",
      "Iteration 355, loss = 0.14733115\n",
      "Iteration 356, loss = 0.14659190\n",
      "Iteration 357, loss = 0.14586302\n",
      "Iteration 358, loss = 0.14513187\n",
      "Iteration 359, loss = 0.14442373\n",
      "Iteration 360, loss = 0.14370946\n",
      "Iteration 361, loss = 0.14301413\n",
      "Iteration 362, loss = 0.14231372\n",
      "Iteration 363, loss = 0.14162814\n",
      "Iteration 364, loss = 0.14094666\n",
      "Iteration 365, loss = 0.14027383\n",
      "Iteration 366, loss = 0.13959433\n",
      "Iteration 367, loss = 0.13893328\n",
      "Iteration 368, loss = 0.13827587\n",
      "Iteration 369, loss = 0.13762308\n",
      "Iteration 370, loss = 0.13697919\n",
      "Iteration 371, loss = 0.13633794\n",
      "Iteration 372, loss = 0.13570550\n",
      "Iteration 373, loss = 0.13508274\n",
      "Iteration 374, loss = 0.13446523\n",
      "Iteration 375, loss = 0.13384739\n",
      "Iteration 376, loss = 0.13324042\n",
      "Iteration 377, loss = 0.13263895\n",
      "Iteration 378, loss = 0.13204230\n",
      "Iteration 379, loss = 0.13144661\n",
      "Iteration 380, loss = 0.13085379\n",
      "Iteration 381, loss = 0.13026754\n",
      "Iteration 382, loss = 0.12968432\n",
      "Iteration 383, loss = 0.12910510\n",
      "Iteration 384, loss = 0.12853700\n",
      "Iteration 385, loss = 0.12796742\n",
      "Iteration 386, loss = 0.12740056\n",
      "Iteration 387, loss = 0.12684513\n",
      "Iteration 388, loss = 0.12628934\n",
      "Iteration 389, loss = 0.12574029\n",
      "Iteration 390, loss = 0.12519407\n",
      "Iteration 391, loss = 0.12465122\n",
      "Iteration 392, loss = 0.12412380\n",
      "Iteration 393, loss = 0.12358843\n",
      "Iteration 394, loss = 0.12306442\n",
      "Iteration 395, loss = 0.12254439\n",
      "Iteration 396, loss = 0.12202870\n",
      "Iteration 397, loss = 0.12151795\n",
      "Iteration 398, loss = 0.12100410\n",
      "Iteration 399, loss = 0.12049970\n",
      "Iteration 400, loss = 0.11999367\n",
      "Iteration 401, loss = 0.11950040\n",
      "Iteration 402, loss = 0.11899940\n",
      "Iteration 403, loss = 0.11851434\n",
      "Iteration 404, loss = 0.11802343\n",
      "Iteration 405, loss = 0.11754761\n",
      "Iteration 406, loss = 0.11705789\n",
      "Iteration 407, loss = 0.11658494\n",
      "Iteration 408, loss = 0.11611250\n",
      "Iteration 409, loss = 0.11564486\n",
      "Iteration 410, loss = 0.11517949\n",
      "Iteration 411, loss = 0.11472133\n",
      "Iteration 412, loss = 0.11426039\n",
      "Iteration 413, loss = 0.11380778\n",
      "Iteration 414, loss = 0.11335367\n",
      "Iteration 415, loss = 0.11289857\n",
      "Iteration 416, loss = 0.11245659\n",
      "Iteration 417, loss = 0.11201453\n",
      "Iteration 418, loss = 0.11157333\n",
      "Iteration 419, loss = 0.11114249\n",
      "Iteration 420, loss = 0.11071270\n",
      "Iteration 421, loss = 0.11028485\n",
      "Iteration 422, loss = 0.10986666\n",
      "Iteration 423, loss = 0.10944007\n",
      "Iteration 424, loss = 0.10901938\n",
      "Iteration 425, loss = 0.10859805\n",
      "Iteration 426, loss = 0.10818211\n",
      "Iteration 427, loss = 0.10776363\n",
      "Iteration 428, loss = 0.10734654\n",
      "Iteration 429, loss = 0.10694218\n",
      "Iteration 430, loss = 0.10653476\n",
      "Iteration 431, loss = 0.10612633\n",
      "Iteration 432, loss = 0.10572007\n",
      "Iteration 433, loss = 0.10532726\n",
      "Iteration 434, loss = 0.10492786\n",
      "Iteration 435, loss = 0.10454083\n",
      "Iteration 436, loss = 0.10415225\n",
      "Iteration 437, loss = 0.10376818\n",
      "Iteration 438, loss = 0.10338718\n",
      "Iteration 439, loss = 0.10301015\n",
      "Iteration 440, loss = 0.10263521\n",
      "Iteration 441, loss = 0.10226249\n",
      "Iteration 442, loss = 0.10189575\n",
      "Iteration 443, loss = 0.10152805\n",
      "Iteration 444, loss = 0.10116309\n",
      "Iteration 445, loss = 0.10080226\n",
      "Iteration 446, loss = 0.10044093\n",
      "Iteration 447, loss = 0.10008361\n",
      "Iteration 448, loss = 0.09972678\n",
      "Iteration 449, loss = 0.09937582\n",
      "Iteration 450, loss = 0.09902943\n",
      "Iteration 451, loss = 0.09868318\n",
      "Iteration 452, loss = 0.09833537\n",
      "Iteration 453, loss = 0.09799713\n",
      "Iteration 454, loss = 0.09765389\n",
      "Iteration 455, loss = 0.09732262\n",
      "Iteration 456, loss = 0.09698800\n",
      "Iteration 457, loss = 0.09665764\n",
      "Iteration 458, loss = 0.09633031\n",
      "Iteration 459, loss = 0.09600210\n",
      "Iteration 460, loss = 0.09567131\n",
      "Iteration 461, loss = 0.09534738\n",
      "Iteration 462, loss = 0.09502331\n",
      "Iteration 463, loss = 0.09470269\n",
      "Iteration 464, loss = 0.09437829\n",
      "Iteration 465, loss = 0.09405193\n",
      "Iteration 466, loss = 0.09373747\n",
      "Iteration 467, loss = 0.09342042\n",
      "Iteration 468, loss = 0.09311173\n",
      "Iteration 469, loss = 0.09280333\n",
      "Iteration 470, loss = 0.09249810\n",
      "Iteration 471, loss = 0.09219906\n",
      "Iteration 472, loss = 0.09189894\n",
      "Iteration 473, loss = 0.09159673\n",
      "Iteration 474, loss = 0.09130115\n",
      "Iteration 475, loss = 0.09100631\n",
      "Iteration 476, loss = 0.09071226\n",
      "Iteration 477, loss = 0.09042628\n",
      "Iteration 478, loss = 0.09014428\n",
      "Iteration 479, loss = 0.08986051\n",
      "Iteration 480, loss = 0.08957535\n",
      "Iteration 481, loss = 0.08929835\n",
      "Iteration 482, loss = 0.08900973\n",
      "Iteration 483, loss = 0.08873065\n",
      "Iteration 484, loss = 0.08844475\n",
      "Iteration 485, loss = 0.08816849\n",
      "Iteration 486, loss = 0.08789446\n",
      "Iteration 487, loss = 0.08761105\n",
      "Iteration 488, loss = 0.08734006\n",
      "Iteration 489, loss = 0.08706511\n",
      "Iteration 490, loss = 0.08679398\n",
      "Iteration 491, loss = 0.08652231\n",
      "Iteration 492, loss = 0.08626259\n",
      "Iteration 493, loss = 0.08598762\n",
      "Iteration 494, loss = 0.08572692\n",
      "Iteration 495, loss = 0.08546910\n",
      "Iteration 496, loss = 0.08520868\n",
      "Iteration 497, loss = 0.08496106\n",
      "Iteration 498, loss = 0.08470912\n",
      "Iteration 499, loss = 0.08446150\n",
      "Iteration 500, loss = 0.08422402\n",
      "Iteration 501, loss = 0.08397640\n",
      "Iteration 502, loss = 0.08373343\n",
      "Iteration 503, loss = 0.08349572\n",
      "Iteration 504, loss = 0.08325848\n",
      "Iteration 505, loss = 0.08302296\n",
      "Iteration 506, loss = 0.08279482\n",
      "Iteration 507, loss = 0.08256179\n",
      "Iteration 508, loss = 0.08233354\n",
      "Iteration 509, loss = 0.08210381\n",
      "Iteration 510, loss = 0.08187319\n",
      "Iteration 511, loss = 0.08164799\n",
      "Iteration 512, loss = 0.08142176\n",
      "Iteration 513, loss = 0.08119523\n",
      "Iteration 514, loss = 0.08097003\n",
      "Iteration 515, loss = 0.08074062\n",
      "Iteration 516, loss = 0.08051924\n",
      "Iteration 517, loss = 0.08028897\n",
      "Iteration 518, loss = 0.08007198\n",
      "Iteration 519, loss = 0.07984225\n",
      "Iteration 520, loss = 0.07962241\n",
      "Iteration 521, loss = 0.07940730\n",
      "Iteration 522, loss = 0.07918652\n",
      "Iteration 523, loss = 0.07897256\n",
      "Iteration 524, loss = 0.07875598\n",
      "Iteration 525, loss = 0.07854922\n",
      "Iteration 526, loss = 0.07833557\n",
      "Iteration 527, loss = 0.07812898\n",
      "Iteration 528, loss = 0.07792959\n",
      "Iteration 529, loss = 0.07771652\n",
      "Iteration 530, loss = 0.07751534\n",
      "Iteration 531, loss = 0.07730965\n",
      "Iteration 532, loss = 0.07710541\n",
      "Iteration 533, loss = 0.07690724\n",
      "Iteration 534, loss = 0.07670783\n",
      "Iteration 535, loss = 0.07650950\n",
      "Iteration 536, loss = 0.07630684\n",
      "Iteration 537, loss = 0.07610342\n",
      "Iteration 538, loss = 0.07590330\n",
      "Iteration 539, loss = 0.07570219\n",
      "Iteration 540, loss = 0.07550331\n",
      "Iteration 541, loss = 0.07530755\n",
      "Iteration 542, loss = 0.07511380\n",
      "Iteration 543, loss = 0.07492079\n",
      "Iteration 544, loss = 0.07472728\n",
      "Iteration 545, loss = 0.07453532\n",
      "Iteration 546, loss = 0.07434316\n",
      "Iteration 547, loss = 0.07415460\n",
      "Iteration 548, loss = 0.07396305\n",
      "Iteration 549, loss = 0.07377968\n",
      "Iteration 550, loss = 0.07359499\n",
      "Iteration 551, loss = 0.07340814\n",
      "Iteration 552, loss = 0.07322633\n",
      "Iteration 553, loss = 0.07304038\n",
      "Iteration 554, loss = 0.07286542\n",
      "Iteration 555, loss = 0.07268836\n",
      "Iteration 556, loss = 0.07251047\n",
      "Iteration 557, loss = 0.07233082\n",
      "Iteration 558, loss = 0.07216149\n",
      "Iteration 559, loss = 0.07198878\n",
      "Iteration 560, loss = 0.07181986\n",
      "Iteration 561, loss = 0.07164989\n",
      "Iteration 562, loss = 0.07148277\n",
      "Iteration 563, loss = 0.07132253\n",
      "Iteration 564, loss = 0.07115119\n",
      "Iteration 565, loss = 0.07099495\n",
      "Iteration 566, loss = 0.07082577\n",
      "Iteration 567, loss = 0.07065594\n",
      "Iteration 568, loss = 0.07048930\n",
      "Iteration 569, loss = 0.07032889\n",
      "Iteration 570, loss = 0.07015517\n",
      "Iteration 571, loss = 0.06998881\n",
      "Iteration 572, loss = 0.06981831\n",
      "Iteration 573, loss = 0.06965539\n",
      "Iteration 574, loss = 0.06949874\n",
      "Iteration 575, loss = 0.06932614\n",
      "Iteration 576, loss = 0.06916517\n",
      "Iteration 577, loss = 0.06900978\n",
      "Iteration 578, loss = 0.06884365\n",
      "Iteration 579, loss = 0.06868382\n",
      "Iteration 580, loss = 0.06852477\n",
      "Iteration 581, loss = 0.06836534\n",
      "Iteration 582, loss = 0.06820148\n",
      "Iteration 583, loss = 0.06804436\n",
      "Iteration 584, loss = 0.06788969\n",
      "Iteration 585, loss = 0.06773587\n",
      "Iteration 586, loss = 0.06758365\n",
      "Iteration 587, loss = 0.06742998\n",
      "Iteration 588, loss = 0.06727967\n",
      "Iteration 589, loss = 0.06712651\n",
      "Iteration 590, loss = 0.06697674\n",
      "Iteration 591, loss = 0.06682846\n",
      "Iteration 592, loss = 0.06667928\n",
      "Iteration 593, loss = 0.06653155\n",
      "Iteration 594, loss = 0.06638861\n",
      "Iteration 595, loss = 0.06623606\n",
      "Iteration 596, loss = 0.06608710\n",
      "Iteration 597, loss = 0.06594231\n",
      "Iteration 598, loss = 0.06579747\n",
      "Iteration 599, loss = 0.06564353\n",
      "Iteration 600, loss = 0.06550568\n",
      "Iteration 601, loss = 0.06535411\n",
      "Iteration 602, loss = 0.06521679\n",
      "Iteration 603, loss = 0.06507443\n",
      "Iteration 604, loss = 0.06493655\n",
      "Iteration 605, loss = 0.06479410\n",
      "Iteration 606, loss = 0.06465979\n",
      "Iteration 607, loss = 0.06452119\n",
      "Iteration 608, loss = 0.06438722\n",
      "Iteration 609, loss = 0.06425832\n",
      "Iteration 610, loss = 0.06412037\n",
      "Iteration 611, loss = 0.06398543\n",
      "Iteration 612, loss = 0.06385134\n",
      "Iteration 613, loss = 0.06371979\n",
      "Iteration 614, loss = 0.06358938\n",
      "Iteration 615, loss = 0.06345295\n",
      "Iteration 616, loss = 0.06332338\n",
      "Iteration 617, loss = 0.06319684\n",
      "Iteration 618, loss = 0.06306741\n",
      "Iteration 619, loss = 0.06293793\n",
      "Iteration 620, loss = 0.06281271\n",
      "Iteration 621, loss = 0.06268701\n",
      "Iteration 622, loss = 0.06256418\n",
      "Iteration 623, loss = 0.06243821\n",
      "Iteration 624, loss = 0.06231753\n",
      "Iteration 625, loss = 0.06219316\n",
      "Iteration 626, loss = 0.06207098\n",
      "Iteration 627, loss = 0.06194755\n",
      "Iteration 628, loss = 0.06182479\n",
      "Iteration 629, loss = 0.06170527\n",
      "Iteration 630, loss = 0.06157994\n",
      "Iteration 631, loss = 0.06145433\n",
      "Iteration 632, loss = 0.06133241\n",
      "Iteration 633, loss = 0.06120610\n",
      "Iteration 634, loss = 0.06108756\n",
      "Iteration 635, loss = 0.06096140\n",
      "Iteration 636, loss = 0.06084062\n",
      "Iteration 637, loss = 0.06071685\n",
      "Iteration 638, loss = 0.06060331\n",
      "Iteration 639, loss = 0.06047942\n",
      "Iteration 640, loss = 0.06035986\n",
      "Iteration 641, loss = 0.06024275\n",
      "Iteration 642, loss = 0.06012386\n",
      "Iteration 643, loss = 0.06001410\n",
      "Iteration 644, loss = 0.05989433\n",
      "Iteration 645, loss = 0.05978512\n",
      "Iteration 646, loss = 0.05967153\n",
      "Iteration 647, loss = 0.05956143\n",
      "Iteration 648, loss = 0.05944394\n",
      "Iteration 649, loss = 0.05933336\n",
      "Iteration 650, loss = 0.05922210\n",
      "Iteration 651, loss = 0.05910978\n",
      "Iteration 652, loss = 0.05899726\n",
      "Iteration 653, loss = 0.05888741\n",
      "Iteration 654, loss = 0.05877360\n",
      "Iteration 655, loss = 0.05866752\n",
      "Iteration 656, loss = 0.05855154\n",
      "Iteration 657, loss = 0.05844185\n",
      "Iteration 658, loss = 0.05833349\n",
      "Iteration 659, loss = 0.05822432\n",
      "Iteration 660, loss = 0.05811775\n",
      "Iteration 661, loss = 0.05801070\n",
      "Iteration 662, loss = 0.05789672\n",
      "Iteration 663, loss = 0.05779107\n",
      "Iteration 664, loss = 0.05767950\n",
      "Iteration 665, loss = 0.05756821\n",
      "Iteration 666, loss = 0.05746318\n",
      "Iteration 667, loss = 0.05735057\n",
      "Iteration 668, loss = 0.05724418\n",
      "Iteration 669, loss = 0.05713765\n",
      "Iteration 670, loss = 0.05702719\n",
      "Iteration 671, loss = 0.05692282\n",
      "Iteration 672, loss = 0.05681813\n",
      "Iteration 673, loss = 0.05671207\n",
      "Iteration 674, loss = 0.05661237\n",
      "Iteration 675, loss = 0.05650981\n",
      "Iteration 676, loss = 0.05640614\n",
      "Iteration 677, loss = 0.05630521\n",
      "Iteration 678, loss = 0.05620183\n",
      "Iteration 679, loss = 0.05609885\n",
      "Iteration 680, loss = 0.05600128\n",
      "Iteration 681, loss = 0.05589744\n",
      "Iteration 682, loss = 0.05580252\n",
      "Iteration 683, loss = 0.05570199\n",
      "Iteration 684, loss = 0.05559876\n",
      "Iteration 685, loss = 0.05550261\n",
      "Iteration 686, loss = 0.05540200\n",
      "Iteration 687, loss = 0.05530464\n",
      "Iteration 688, loss = 0.05520414\n",
      "Iteration 689, loss = 0.05511052\n",
      "Iteration 690, loss = 0.05500932\n",
      "Iteration 691, loss = 0.05491512\n",
      "Iteration 692, loss = 0.05481754\n",
      "Iteration 693, loss = 0.05472106\n",
      "Iteration 694, loss = 0.05462952\n",
      "Iteration 695, loss = 0.05453065\n",
      "Iteration 696, loss = 0.05443471\n",
      "Iteration 697, loss = 0.05434028\n",
      "Iteration 698, loss = 0.05424474\n",
      "Iteration 699, loss = 0.05415304\n",
      "Iteration 700, loss = 0.05405578\n",
      "Iteration 701, loss = 0.05396533\n",
      "Iteration 702, loss = 0.05387274\n",
      "Iteration 703, loss = 0.05378212\n",
      "Iteration 704, loss = 0.05369488\n",
      "Iteration 705, loss = 0.05360017\n",
      "Iteration 706, loss = 0.05350793\n",
      "Iteration 707, loss = 0.05341418\n",
      "Iteration 708, loss = 0.05331921\n",
      "Iteration 709, loss = 0.05322794\n",
      "Iteration 710, loss = 0.05313518\n",
      "Iteration 711, loss = 0.05304275\n",
      "Iteration 712, loss = 0.05295499\n",
      "Iteration 713, loss = 0.05286485\n",
      "Iteration 714, loss = 0.05277987\n",
      "Iteration 715, loss = 0.05269112\n",
      "Iteration 716, loss = 0.05260567\n",
      "Iteration 717, loss = 0.05251850\n",
      "Iteration 718, loss = 0.05243237\n",
      "Iteration 719, loss = 0.05234610\n",
      "Iteration 720, loss = 0.05226082\n",
      "Iteration 721, loss = 0.05217501\n",
      "Iteration 722, loss = 0.05209036\n",
      "Iteration 723, loss = 0.05200341\n",
      "Iteration 724, loss = 0.05191989\n",
      "Iteration 725, loss = 0.05183439\n",
      "Iteration 726, loss = 0.05174903\n",
      "Iteration 727, loss = 0.05166540\n",
      "Iteration 728, loss = 0.05158282\n",
      "Iteration 729, loss = 0.05150101\n",
      "Iteration 730, loss = 0.05141522\n",
      "Iteration 731, loss = 0.05133061\n",
      "Iteration 732, loss = 0.05124540\n",
      "Iteration 733, loss = 0.05115663\n",
      "Iteration 734, loss = 0.05106750\n",
      "Iteration 735, loss = 0.05098216\n",
      "Iteration 736, loss = 0.05089695\n",
      "Iteration 737, loss = 0.05081214\n",
      "Iteration 738, loss = 0.05073067\n",
      "Iteration 739, loss = 0.05064846\n",
      "Iteration 740, loss = 0.05056827\n",
      "Iteration 741, loss = 0.05049048\n",
      "Iteration 742, loss = 0.05041071\n",
      "Iteration 743, loss = 0.05033041\n",
      "Iteration 744, loss = 0.05025181\n",
      "Iteration 745, loss = 0.05017217\n",
      "Iteration 746, loss = 0.05009485\n",
      "Iteration 747, loss = 0.05001382\n",
      "Iteration 748, loss = 0.04993465\n",
      "Iteration 749, loss = 0.04985630\n",
      "Iteration 750, loss = 0.04977363\n",
      "Iteration 751, loss = 0.04969398\n",
      "Iteration 752, loss = 0.04961448\n",
      "Iteration 753, loss = 0.04953772\n",
      "Iteration 754, loss = 0.04945983\n",
      "Iteration 755, loss = 0.04938453\n",
      "Iteration 756, loss = 0.04930965\n",
      "Iteration 757, loss = 0.04923060\n",
      "Iteration 758, loss = 0.04915744\n",
      "Iteration 759, loss = 0.04908124\n",
      "Iteration 760, loss = 0.04900494\n",
      "Iteration 761, loss = 0.04892868\n",
      "Iteration 762, loss = 0.04885320\n",
      "Iteration 763, loss = 0.04877892\n",
      "Iteration 764, loss = 0.04869536\n",
      "Iteration 765, loss = 0.04862085\n",
      "Iteration 766, loss = 0.04854380\n",
      "Iteration 767, loss = 0.04847207\n",
      "Iteration 768, loss = 0.04839159\n",
      "Iteration 769, loss = 0.04831905\n",
      "Iteration 770, loss = 0.04824301\n",
      "Iteration 771, loss = 0.04816784\n",
      "Iteration 772, loss = 0.04809952\n",
      "Iteration 773, loss = 0.04802115\n",
      "Iteration 774, loss = 0.04794524\n",
      "Iteration 775, loss = 0.04787263\n",
      "Iteration 776, loss = 0.04779697\n",
      "Iteration 777, loss = 0.04772369\n",
      "Iteration 778, loss = 0.04765208\n",
      "Iteration 779, loss = 0.04757668\n",
      "Iteration 780, loss = 0.04750118\n",
      "Iteration 781, loss = 0.04742676\n",
      "Iteration 782, loss = 0.04735416\n",
      "Iteration 783, loss = 0.04728017\n",
      "Iteration 784, loss = 0.04720844\n",
      "Iteration 785, loss = 0.04714216\n",
      "Iteration 786, loss = 0.04707043\n",
      "Iteration 787, loss = 0.04700081\n",
      "Iteration 788, loss = 0.04692866\n",
      "Iteration 789, loss = 0.04685892\n",
      "Iteration 790, loss = 0.04678803\n",
      "Iteration 791, loss = 0.04672037\n",
      "Iteration 792, loss = 0.04664871\n",
      "Iteration 793, loss = 0.04657929\n",
      "Iteration 794, loss = 0.04650853\n",
      "Iteration 795, loss = 0.04643680\n",
      "Iteration 796, loss = 0.04636820\n",
      "Iteration 797, loss = 0.04630349\n",
      "Iteration 798, loss = 0.04622468\n",
      "Iteration 799, loss = 0.04616112\n",
      "Iteration 800, loss = 0.04608872\n",
      "Iteration 801, loss = 0.04602025\n",
      "Iteration 802, loss = 0.04595198\n",
      "Iteration 803, loss = 0.04588702\n",
      "Iteration 804, loss = 0.04581937\n",
      "Iteration 805, loss = 0.04575326\n",
      "Iteration 806, loss = 0.04568865\n",
      "Iteration 807, loss = 0.04562073\n",
      "Iteration 808, loss = 0.04555511\n",
      "Iteration 809, loss = 0.04549217\n",
      "Iteration 810, loss = 0.04542618\n",
      "Iteration 811, loss = 0.04536390\n",
      "Iteration 812, loss = 0.04530054\n",
      "Iteration 813, loss = 0.04523884\n",
      "Iteration 814, loss = 0.04517516\n",
      "Iteration 815, loss = 0.04511446\n",
      "Iteration 816, loss = 0.04504888\n",
      "Iteration 817, loss = 0.04498628\n",
      "Iteration 818, loss = 0.04492260\n",
      "Iteration 819, loss = 0.04485592\n",
      "Iteration 820, loss = 0.04479403\n",
      "Iteration 821, loss = 0.04472718\n",
      "Iteration 822, loss = 0.04466136\n",
      "Iteration 823, loss = 0.04459248\n",
      "Iteration 824, loss = 0.04452696\n",
      "Iteration 825, loss = 0.04446304\n",
      "Iteration 826, loss = 0.04439525\n",
      "Iteration 827, loss = 0.04433268\n",
      "Iteration 828, loss = 0.04426864\n",
      "Iteration 829, loss = 0.04420568\n",
      "Iteration 830, loss = 0.04414498\n",
      "Iteration 831, loss = 0.04408188\n",
      "Iteration 832, loss = 0.04401694\n",
      "Iteration 833, loss = 0.04395158\n",
      "Iteration 834, loss = 0.04389261\n",
      "Iteration 835, loss = 0.04383098\n",
      "Iteration 836, loss = 0.04376494\n",
      "Iteration 837, loss = 0.04369961\n",
      "Iteration 838, loss = 0.04363926\n",
      "Iteration 839, loss = 0.04357596\n",
      "Iteration 840, loss = 0.04351389\n",
      "Iteration 841, loss = 0.04345417\n",
      "Iteration 842, loss = 0.04339462\n",
      "Iteration 843, loss = 0.04333565\n",
      "Iteration 844, loss = 0.04327748\n",
      "Iteration 845, loss = 0.04322262\n",
      "Iteration 846, loss = 0.04316172\n",
      "Iteration 847, loss = 0.04310306\n",
      "Iteration 848, loss = 0.04304299\n",
      "Iteration 849, loss = 0.04298563\n",
      "Iteration 850, loss = 0.04292866\n",
      "Iteration 851, loss = 0.04286863\n",
      "Iteration 852, loss = 0.04280934\n",
      "Iteration 853, loss = 0.04274663\n",
      "Iteration 854, loss = 0.04268932\n",
      "Iteration 855, loss = 0.04263122\n",
      "Iteration 856, loss = 0.04257216\n",
      "Iteration 857, loss = 0.04251540\n",
      "Iteration 858, loss = 0.04245262\n",
      "Iteration 859, loss = 0.04239112\n",
      "Iteration 860, loss = 0.04233418\n",
      "Iteration 861, loss = 0.04227436\n",
      "Iteration 862, loss = 0.04221485\n",
      "Iteration 863, loss = 0.04215415\n",
      "Iteration 864, loss = 0.04209813\n",
      "Iteration 865, loss = 0.04203728\n",
      "Iteration 866, loss = 0.04198082\n",
      "Iteration 867, loss = 0.04192330\n",
      "Iteration 868, loss = 0.04187268\n",
      "Iteration 869, loss = 0.04181197\n",
      "Iteration 870, loss = 0.04175853\n",
      "Iteration 871, loss = 0.04170873\n",
      "Iteration 872, loss = 0.04164930\n",
      "Iteration 873, loss = 0.04159612\n",
      "Iteration 874, loss = 0.04154046\n",
      "Iteration 875, loss = 0.04149062\n",
      "Iteration 876, loss = 0.04143799\n",
      "Iteration 877, loss = 0.04138545\n",
      "Iteration 878, loss = 0.04133358\n",
      "Iteration 879, loss = 0.04128489\n",
      "Iteration 880, loss = 0.04122879\n",
      "Iteration 881, loss = 0.04117694\n",
      "Iteration 882, loss = 0.04112656\n",
      "Iteration 883, loss = 0.04107683\n",
      "Iteration 884, loss = 0.04102734\n",
      "Iteration 885, loss = 0.04098136\n",
      "Iteration 886, loss = 0.04092595\n",
      "Iteration 887, loss = 0.04087629\n",
      "Iteration 888, loss = 0.04082459\n",
      "Iteration 889, loss = 0.04077413\n",
      "Iteration 890, loss = 0.04072412\n",
      "Iteration 891, loss = 0.04067415\n",
      "Iteration 892, loss = 0.04062647\n",
      "Iteration 893, loss = 0.04057417\n",
      "Iteration 894, loss = 0.04052633\n",
      "Iteration 895, loss = 0.04047359\n",
      "Iteration 896, loss = 0.04042767\n",
      "Iteration 897, loss = 0.04037535\n",
      "Iteration 898, loss = 0.04032376\n",
      "Iteration 899, loss = 0.04027330\n",
      "Iteration 900, loss = 0.04022399\n",
      "Iteration 901, loss = 0.04017330\n",
      "Iteration 902, loss = 0.04012072\n",
      "Iteration 903, loss = 0.04007152\n",
      "Iteration 904, loss = 0.04002219\n",
      "Iteration 905, loss = 0.03997149\n",
      "Iteration 906, loss = 0.03991798\n",
      "Iteration 907, loss = 0.03986814\n",
      "Iteration 908, loss = 0.03981761\n",
      "Iteration 909, loss = 0.03976701\n",
      "Iteration 910, loss = 0.03971642\n",
      "Iteration 911, loss = 0.03967212\n",
      "Iteration 912, loss = 0.03962045\n",
      "Iteration 913, loss = 0.03957855\n",
      "Iteration 914, loss = 0.03952450\n",
      "Iteration 915, loss = 0.03947931\n",
      "Iteration 916, loss = 0.03943128\n",
      "Iteration 917, loss = 0.03938701\n",
      "Iteration 918, loss = 0.03933741\n",
      "Iteration 919, loss = 0.03929145\n",
      "Iteration 920, loss = 0.03924640\n",
      "Iteration 921, loss = 0.03919833\n",
      "Iteration 922, loss = 0.03915369\n",
      "Iteration 923, loss = 0.03910741\n",
      "Iteration 924, loss = 0.03906161\n",
      "Iteration 925, loss = 0.03901625\n",
      "Iteration 926, loss = 0.03897167\n",
      "Iteration 927, loss = 0.03892587\n",
      "Iteration 928, loss = 0.03887912\n",
      "Iteration 929, loss = 0.03883713\n",
      "Iteration 930, loss = 0.03878884\n",
      "Iteration 931, loss = 0.03874559\n",
      "Iteration 932, loss = 0.03869791\n",
      "Iteration 933, loss = 0.03865071\n",
      "Iteration 934, loss = 0.03860586\n",
      "Iteration 935, loss = 0.03855992\n",
      "Iteration 936, loss = 0.03851521\n",
      "Iteration 937, loss = 0.03847224\n",
      "Iteration 938, loss = 0.03842609\n",
      "Iteration 939, loss = 0.03838221\n",
      "Iteration 940, loss = 0.03833599\n",
      "Iteration 941, loss = 0.03829109\n",
      "Iteration 942, loss = 0.03824329\n",
      "Iteration 943, loss = 0.03819707\n",
      "Iteration 944, loss = 0.03815176\n",
      "Iteration 945, loss = 0.03810258\n",
      "Iteration 946, loss = 0.03806031\n",
      "Iteration 947, loss = 0.03801219\n",
      "Iteration 948, loss = 0.03796615\n",
      "Iteration 949, loss = 0.03792335\n",
      "Iteration 950, loss = 0.03787734\n",
      "Iteration 951, loss = 0.03783437\n",
      "Iteration 952, loss = 0.03778754\n",
      "Iteration 953, loss = 0.03774914\n",
      "Iteration 954, loss = 0.03770176\n",
      "Iteration 955, loss = 0.03765760\n",
      "Iteration 956, loss = 0.03761328\n",
      "Iteration 957, loss = 0.03756835\n",
      "Iteration 958, loss = 0.03752643\n",
      "Iteration 959, loss = 0.03748305\n",
      "Iteration 960, loss = 0.03744037\n",
      "Iteration 961, loss = 0.03739651\n",
      "Iteration 962, loss = 0.03735350\n",
      "Iteration 963, loss = 0.03731084\n",
      "Iteration 964, loss = 0.03726748\n",
      "Iteration 965, loss = 0.03722534\n",
      "Iteration 966, loss = 0.03718376\n",
      "Iteration 967, loss = 0.03714142\n",
      "Iteration 968, loss = 0.03710046\n",
      "Iteration 969, loss = 0.03705935\n",
      "Iteration 970, loss = 0.03701744\n",
      "Iteration 971, loss = 0.03697742\n",
      "Iteration 972, loss = 0.03693680\n",
      "Iteration 973, loss = 0.03689478\n",
      "Iteration 974, loss = 0.03685228\n",
      "Iteration 975, loss = 0.03681022\n",
      "Iteration 976, loss = 0.03676822\n",
      "Iteration 977, loss = 0.03673024\n",
      "Iteration 978, loss = 0.03668844\n",
      "Iteration 979, loss = 0.03664789\n",
      "Iteration 980, loss = 0.03660735\n",
      "Iteration 981, loss = 0.03656660\n",
      "Iteration 982, loss = 0.03652910\n",
      "Iteration 983, loss = 0.03648985\n",
      "Iteration 984, loss = 0.03645331\n",
      "Iteration 985, loss = 0.03641413\n",
      "Iteration 986, loss = 0.03637128\n",
      "Iteration 987, loss = 0.03633114\n",
      "Iteration 988, loss = 0.03629238\n",
      "Iteration 989, loss = 0.03625751\n",
      "Iteration 990, loss = 0.03621422\n",
      "Iteration 991, loss = 0.03617368\n",
      "Iteration 992, loss = 0.03613380\n",
      "Iteration 993, loss = 0.03609200\n",
      "Iteration 994, loss = 0.03605166\n",
      "Iteration 995, loss = 0.03600932\n",
      "Iteration 996, loss = 0.03597445\n",
      "Iteration 997, loss = 0.03593641\n",
      "Iteration 998, loss = 0.03589386\n",
      "Iteration 999, loss = 0.03585511\n",
      "Iteration 1000, loss = 0.03581637\n",
      "Iteration 1001, loss = 0.03577891\n",
      "Iteration 1002, loss = 0.03573984\n",
      "Iteration 1003, loss = 0.03569844\n",
      "Iteration 1004, loss = 0.03566116\n",
      "Iteration 1005, loss = 0.03562404\n",
      "Iteration 1006, loss = 0.03558469\n",
      "Iteration 1007, loss = 0.03554267\n",
      "Iteration 1008, loss = 0.03550676\n",
      "Iteration 1009, loss = 0.03546312\n",
      "Iteration 1010, loss = 0.03542471\n",
      "Iteration 1011, loss = 0.03538313\n",
      "Iteration 1012, loss = 0.03534403\n",
      "Iteration 1013, loss = 0.03530634\n",
      "Iteration 1014, loss = 0.03526459\n",
      "Iteration 1015, loss = 0.03522665\n",
      "Iteration 1016, loss = 0.03518903\n",
      "Iteration 1017, loss = 0.03514881\n",
      "Iteration 1018, loss = 0.03511054\n",
      "Iteration 1019, loss = 0.03507011\n",
      "Iteration 1020, loss = 0.03503000\n",
      "Iteration 1021, loss = 0.03499208\n",
      "Iteration 1022, loss = 0.03495166\n",
      "Iteration 1023, loss = 0.03491044\n",
      "Iteration 1024, loss = 0.03487553\n",
      "Iteration 1025, loss = 0.03483218\n",
      "Iteration 1026, loss = 0.03479372\n",
      "Iteration 1027, loss = 0.03475343\n",
      "Iteration 1028, loss = 0.03471986\n",
      "Iteration 1029, loss = 0.03467883\n",
      "Iteration 1030, loss = 0.03464063\n",
      "Iteration 1031, loss = 0.03460448\n",
      "Iteration 1032, loss = 0.03456787\n",
      "Iteration 1033, loss = 0.03452952\n",
      "Iteration 1034, loss = 0.03449463\n",
      "Iteration 1035, loss = 0.03445854\n",
      "Iteration 1036, loss = 0.03442069\n",
      "Iteration 1037, loss = 0.03438694\n",
      "Iteration 1038, loss = 0.03434826\n",
      "Iteration 1039, loss = 0.03431215\n",
      "Iteration 1040, loss = 0.03427444\n",
      "Iteration 1041, loss = 0.03423792\n",
      "Iteration 1042, loss = 0.03419976\n",
      "Iteration 1043, loss = 0.03416561\n",
      "Iteration 1044, loss = 0.03412767\n",
      "Iteration 1045, loss = 0.03409217\n",
      "Iteration 1046, loss = 0.03405723\n",
      "Iteration 1047, loss = 0.03402104\n",
      "Iteration 1048, loss = 0.03398706\n",
      "Iteration 1049, loss = 0.03395030\n",
      "Iteration 1050, loss = 0.03391517\n",
      "Iteration 1051, loss = 0.03388039\n",
      "Iteration 1052, loss = 0.03384560\n",
      "Iteration 1053, loss = 0.03381292\n",
      "Iteration 1054, loss = 0.03377597\n",
      "Iteration 1055, loss = 0.03374147\n",
      "Iteration 1056, loss = 0.03370950\n",
      "Iteration 1057, loss = 0.03367190\n",
      "Iteration 1058, loss = 0.03363633\n",
      "Iteration 1059, loss = 0.03360191\n",
      "Iteration 1060, loss = 0.03356871\n",
      "Iteration 1061, loss = 0.03353268\n",
      "Iteration 1062, loss = 0.03349645\n",
      "Iteration 1063, loss = 0.03346311\n",
      "Iteration 1064, loss = 0.03342654\n",
      "Iteration 1065, loss = 0.03339272\n",
      "Iteration 1066, loss = 0.03335762\n",
      "Iteration 1067, loss = 0.03332396\n",
      "Iteration 1068, loss = 0.03328942\n",
      "Iteration 1069, loss = 0.03325581\n",
      "Iteration 1070, loss = 0.03322030\n",
      "Iteration 1071, loss = 0.03318680\n",
      "Iteration 1072, loss = 0.03314509\n",
      "Iteration 1073, loss = 0.03311082\n",
      "Iteration 1074, loss = 0.03307476\n",
      "Iteration 1075, loss = 0.03303934\n",
      "Iteration 1076, loss = 0.03301102\n",
      "Iteration 1077, loss = 0.03297443\n",
      "Iteration 1078, loss = 0.03293918\n",
      "Iteration 1079, loss = 0.03290735\n",
      "Iteration 1080, loss = 0.03287100\n",
      "Iteration 1081, loss = 0.03284092\n",
      "Iteration 1082, loss = 0.03280613\n",
      "Iteration 1083, loss = 0.03277114\n",
      "Iteration 1084, loss = 0.03273799\n",
      "Iteration 1085, loss = 0.03270422\n",
      "Iteration 1086, loss = 0.03266881\n",
      "Iteration 1087, loss = 0.03263464\n",
      "Iteration 1088, loss = 0.03260370\n",
      "Iteration 1089, loss = 0.03256912\n",
      "Iteration 1090, loss = 0.03253539\n",
      "Iteration 1091, loss = 0.03250160\n",
      "Iteration 1092, loss = 0.03247024\n",
      "Iteration 1093, loss = 0.03243490\n",
      "Iteration 1094, loss = 0.03240467\n",
      "Iteration 1095, loss = 0.03237146\n",
      "Iteration 1096, loss = 0.03233852\n",
      "Iteration 1097, loss = 0.03230416\n",
      "Iteration 1098, loss = 0.03227203\n",
      "Iteration 1099, loss = 0.03223915\n",
      "Iteration 1100, loss = 0.03220609\n",
      "Iteration 1101, loss = 0.03217030\n",
      "Iteration 1102, loss = 0.03213555\n",
      "Iteration 1103, loss = 0.03210247\n",
      "Iteration 1104, loss = 0.03206907\n",
      "Iteration 1105, loss = 0.03203704\n",
      "Iteration 1106, loss = 0.03200255\n",
      "Iteration 1107, loss = 0.03196930\n",
      "Iteration 1108, loss = 0.03193786\n",
      "Iteration 1109, loss = 0.03190490\n",
      "Iteration 1110, loss = 0.03187502\n",
      "Iteration 1111, loss = 0.03184161\n",
      "Iteration 1112, loss = 0.03180814\n",
      "Iteration 1113, loss = 0.03177702\n",
      "Iteration 1114, loss = 0.03174549\n",
      "Iteration 1115, loss = 0.03171293\n",
      "Iteration 1116, loss = 0.03168216\n",
      "Iteration 1117, loss = 0.03164984\n",
      "Iteration 1118, loss = 0.03161880\n",
      "Iteration 1119, loss = 0.03158875\n",
      "Iteration 1120, loss = 0.03155757\n",
      "Iteration 1121, loss = 0.03152579\n",
      "Iteration 1122, loss = 0.03149480\n",
      "Iteration 1123, loss = 0.03146265\n",
      "Iteration 1124, loss = 0.03143166\n",
      "Iteration 1125, loss = 0.03140054\n",
      "Iteration 1126, loss = 0.03136948\n",
      "Iteration 1127, loss = 0.03133795\n",
      "Iteration 1128, loss = 0.03130714\n",
      "Iteration 1129, loss = 0.03127949\n",
      "Iteration 1130, loss = 0.03124543\n",
      "Iteration 1131, loss = 0.03121460\n",
      "Iteration 1132, loss = 0.03118127\n",
      "Iteration 1133, loss = 0.03115019\n",
      "Iteration 1134, loss = 0.03112809\n",
      "Iteration 1135, loss = 0.03109239\n",
      "Iteration 1136, loss = 0.03105885\n",
      "Iteration 1137, loss = 0.03102968\n",
      "Iteration 1138, loss = 0.03099763\n",
      "Iteration 1139, loss = 0.03096577\n",
      "Iteration 1140, loss = 0.03093504\n",
      "Iteration 1141, loss = 0.03090517\n",
      "Iteration 1142, loss = 0.03087463\n",
      "Iteration 1143, loss = 0.03084389\n",
      "Iteration 1144, loss = 0.03081502\n",
      "Iteration 1145, loss = 0.03078414\n",
      "Iteration 1146, loss = 0.03075613\n",
      "Iteration 1147, loss = 0.03072549\n",
      "Iteration 1148, loss = 0.03069450\n",
      "Iteration 1149, loss = 0.03066502\n",
      "Iteration 1150, loss = 0.03063435\n",
      "Iteration 1151, loss = 0.03060435\n",
      "Iteration 1152, loss = 0.03057807\n",
      "Iteration 1153, loss = 0.03055029\n",
      "Iteration 1154, loss = 0.03052133\n",
      "Iteration 1155, loss = 0.03049266\n",
      "Iteration 1156, loss = 0.03046158\n",
      "Iteration 1157, loss = 0.03043511\n",
      "Iteration 1158, loss = 0.03040530\n",
      "Iteration 1159, loss = 0.03037587\n",
      "Iteration 1160, loss = 0.03034684\n",
      "Iteration 1161, loss = 0.03031664\n",
      "Iteration 1162, loss = 0.03028776\n",
      "Iteration 1163, loss = 0.03025874\n",
      "Iteration 1164, loss = 0.03022945\n",
      "Iteration 1165, loss = 0.03020420\n",
      "Iteration 1166, loss = 0.03017645\n",
      "Iteration 1167, loss = 0.03014907\n",
      "Iteration 1168, loss = 0.03012204\n",
      "Iteration 1169, loss = 0.03009564\n",
      "Iteration 1170, loss = 0.03006499\n",
      "Iteration 1171, loss = 0.03003942\n",
      "Iteration 1172, loss = 0.03000869\n",
      "Iteration 1173, loss = 0.02998064\n",
      "Iteration 1174, loss = 0.02995573\n",
      "Iteration 1175, loss = 0.02992871\n",
      "Iteration 1176, loss = 0.02990186\n",
      "Iteration 1177, loss = 0.02987628\n",
      "Iteration 1178, loss = 0.02985383\n",
      "Iteration 1179, loss = 0.02982644\n",
      "Iteration 1180, loss = 0.02980080\n",
      "Iteration 1181, loss = 0.02977241\n",
      "Iteration 1182, loss = 0.02974522\n",
      "Iteration 1183, loss = 0.02971529\n",
      "Iteration 1184, loss = 0.02968777\n",
      "Iteration 1185, loss = 0.02966103\n",
      "Iteration 1186, loss = 0.02963278\n",
      "Iteration 1187, loss = 0.02960588\n",
      "Iteration 1188, loss = 0.02957890\n",
      "Iteration 1189, loss = 0.02955349\n",
      "Iteration 1190, loss = 0.02952683\n",
      "Iteration 1191, loss = 0.02950112\n",
      "Iteration 1192, loss = 0.02947425\n",
      "Iteration 1193, loss = 0.02944726\n",
      "Iteration 1194, loss = 0.02941869\n",
      "Iteration 1195, loss = 0.02939345\n",
      "Iteration 1196, loss = 0.02936490\n",
      "Iteration 1197, loss = 0.02934072\n",
      "Iteration 1198, loss = 0.02930968\n",
      "Iteration 1199, loss = 0.02928439\n",
      "Iteration 1200, loss = 0.02925661\n",
      "Iteration 1201, loss = 0.02922981\n",
      "Iteration 1202, loss = 0.02920321\n",
      "Iteration 1203, loss = 0.02917773\n",
      "Iteration 1204, loss = 0.02915026\n",
      "Iteration 1205, loss = 0.02912482\n",
      "Iteration 1206, loss = 0.02909974\n",
      "Iteration 1207, loss = 0.02907418\n",
      "Iteration 1208, loss = 0.02904967\n",
      "Iteration 1209, loss = 0.02902379\n",
      "Iteration 1210, loss = 0.02899947\n",
      "Iteration 1211, loss = 0.02897606\n",
      "Iteration 1212, loss = 0.02895183\n",
      "Iteration 1213, loss = 0.02892580\n",
      "Iteration 1214, loss = 0.02890211\n",
      "Iteration 1215, loss = 0.02887739\n",
      "Iteration 1216, loss = 0.02885324\n",
      "Iteration 1217, loss = 0.02882747\n",
      "Iteration 1218, loss = 0.02880265\n",
      "Iteration 1219, loss = 0.02877582\n",
      "Iteration 1220, loss = 0.02874826\n",
      "Iteration 1221, loss = 0.02872580\n",
      "Iteration 1222, loss = 0.02869674\n",
      "Iteration 1223, loss = 0.02866961\n",
      "Iteration 1224, loss = 0.02864320\n",
      "Iteration 1225, loss = 0.02862280\n",
      "Iteration 1226, loss = 0.02859547\n",
      "Iteration 1227, loss = 0.02856723\n",
      "Iteration 1228, loss = 0.02854119\n",
      "Iteration 1229, loss = 0.02851482\n",
      "Iteration 1230, loss = 0.02848944\n",
      "Iteration 1231, loss = 0.02846223\n",
      "Iteration 1232, loss = 0.02843398\n",
      "Iteration 1233, loss = 0.02840860\n",
      "Iteration 1234, loss = 0.02838599\n",
      "Iteration 1235, loss = 0.02835748\n",
      "Iteration 1236, loss = 0.02833277\n",
      "Iteration 1237, loss = 0.02830799\n",
      "Iteration 1238, loss = 0.02828074\n",
      "Iteration 1239, loss = 0.02825380\n",
      "Iteration 1240, loss = 0.02823175\n",
      "Iteration 1241, loss = 0.02820370\n",
      "Iteration 1242, loss = 0.02818028\n",
      "Iteration 1243, loss = 0.02815689\n",
      "Iteration 1244, loss = 0.02813106\n",
      "Iteration 1245, loss = 0.02810644\n",
      "Iteration 1246, loss = 0.02807913\n",
      "Iteration 1247, loss = 0.02805473\n",
      "Iteration 1248, loss = 0.02802949\n",
      "Iteration 1249, loss = 0.02800625\n",
      "Iteration 1250, loss = 0.02798173\n",
      "Iteration 1251, loss = 0.02795580\n",
      "Iteration 1252, loss = 0.02792862\n",
      "Iteration 1253, loss = 0.02790383\n",
      "Iteration 1254, loss = 0.02787908\n",
      "Iteration 1255, loss = 0.02785119\n",
      "Iteration 1256, loss = 0.02782620\n",
      "Iteration 1257, loss = 0.02779815\n",
      "Iteration 1258, loss = 0.02777399\n",
      "Iteration 1259, loss = 0.02774749\n",
      "Iteration 1260, loss = 0.02772209\n",
      "Iteration 1261, loss = 0.02769691\n",
      "Iteration 1262, loss = 0.02766962\n",
      "Iteration 1263, loss = 0.02764502\n",
      "Iteration 1264, loss = 0.02762067\n",
      "Iteration 1265, loss = 0.02759512\n",
      "Iteration 1266, loss = 0.02757057\n",
      "Iteration 1267, loss = 0.02754591\n",
      "Iteration 1268, loss = 0.02752283\n",
      "Iteration 1269, loss = 0.02749933\n",
      "Iteration 1270, loss = 0.02747309\n",
      "Iteration 1271, loss = 0.02744960\n",
      "Iteration 1272, loss = 0.02742554\n",
      "Iteration 1273, loss = 0.02740002\n",
      "Iteration 1274, loss = 0.02737641\n",
      "Iteration 1275, loss = 0.02735060\n",
      "Iteration 1276, loss = 0.02732833\n",
      "Iteration 1277, loss = 0.02730187\n",
      "Iteration 1278, loss = 0.02727772\n",
      "Iteration 1279, loss = 0.02725273\n",
      "Iteration 1280, loss = 0.02722692\n",
      "Iteration 1281, loss = 0.02720472\n",
      "Iteration 1282, loss = 0.02718232\n",
      "Iteration 1283, loss = 0.02715715\n",
      "Iteration 1284, loss = 0.02713470\n",
      "Iteration 1285, loss = 0.02711176\n",
      "Iteration 1286, loss = 0.02708871\n",
      "Iteration 1287, loss = 0.02706698\n",
      "Iteration 1288, loss = 0.02704460\n",
      "Iteration 1289, loss = 0.02702031\n",
      "Iteration 1290, loss = 0.02699851\n",
      "Iteration 1291, loss = 0.02697474\n",
      "Iteration 1292, loss = 0.02695084\n",
      "Iteration 1293, loss = 0.02692811\n",
      "Iteration 1294, loss = 0.02690545\n",
      "Iteration 1295, loss = 0.02688078\n",
      "Iteration 1296, loss = 0.02685854\n",
      "Iteration 1297, loss = 0.02683676\n",
      "Iteration 1298, loss = 0.02681237\n",
      "Iteration 1299, loss = 0.02678923\n",
      "Iteration 1300, loss = 0.02676489\n",
      "Iteration 1301, loss = 0.02674212\n",
      "Iteration 1302, loss = 0.02671959\n",
      "Iteration 1303, loss = 0.02669716\n",
      "Iteration 1304, loss = 0.02667275\n",
      "Iteration 1305, loss = 0.02665252\n",
      "Iteration 1306, loss = 0.02662727\n",
      "Iteration 1307, loss = 0.02660386\n",
      "Iteration 1308, loss = 0.02658101\n",
      "Iteration 1309, loss = 0.02655772\n",
      "Iteration 1310, loss = 0.02653374\n",
      "Iteration 1311, loss = 0.02650689\n",
      "Iteration 1312, loss = 0.02648295\n",
      "Iteration 1313, loss = 0.02645892\n",
      "Iteration 1314, loss = 0.02643634\n",
      "Iteration 1315, loss = 0.02641365\n",
      "Iteration 1316, loss = 0.02638870\n",
      "Iteration 1317, loss = 0.02636590\n",
      "Iteration 1318, loss = 0.02634475\n",
      "Iteration 1319, loss = 0.02632050\n",
      "Iteration 1320, loss = 0.02629720\n",
      "Iteration 1321, loss = 0.02627497\n",
      "Iteration 1322, loss = 0.02625518\n",
      "Iteration 1323, loss = 0.02623172\n",
      "Iteration 1324, loss = 0.02621057\n",
      "Iteration 1325, loss = 0.02618803\n",
      "Iteration 1326, loss = 0.02616623\n",
      "Iteration 1327, loss = 0.02614510\n",
      "Iteration 1328, loss = 0.02612332\n",
      "Iteration 1329, loss = 0.02610191\n",
      "Iteration 1330, loss = 0.02608362\n",
      "Iteration 1331, loss = 0.02606004\n",
      "Iteration 1332, loss = 0.02603730\n",
      "Iteration 1333, loss = 0.02601410\n",
      "Iteration 1334, loss = 0.02599658\n",
      "Iteration 1335, loss = 0.02597265\n",
      "Iteration 1336, loss = 0.02595322\n",
      "Iteration 1337, loss = 0.02593092\n",
      "Iteration 1338, loss = 0.02590924\n",
      "Iteration 1339, loss = 0.02588958\n",
      "Iteration 1340, loss = 0.02586683\n",
      "Iteration 1341, loss = 0.02584548\n",
      "Iteration 1342, loss = 0.02582379\n",
      "Iteration 1343, loss = 0.02580243\n",
      "Iteration 1344, loss = 0.02578152\n",
      "Iteration 1345, loss = 0.02576277\n",
      "Iteration 1346, loss = 0.02574037\n",
      "Iteration 1347, loss = 0.02571939\n",
      "Iteration 1348, loss = 0.02569860\n",
      "Iteration 1349, loss = 0.02567878\n",
      "Iteration 1350, loss = 0.02565848\n",
      "Iteration 1351, loss = 0.02563640\n",
      "Iteration 1352, loss = 0.02561531\n",
      "Iteration 1353, loss = 0.02559441\n",
      "Iteration 1354, loss = 0.02557196\n",
      "Iteration 1355, loss = 0.02554856\n",
      "Iteration 1356, loss = 0.02552647\n",
      "Iteration 1357, loss = 0.02550811\n",
      "Iteration 1358, loss = 0.02548344\n",
      "Iteration 1359, loss = 0.02546248\n",
      "Iteration 1360, loss = 0.02543997\n",
      "Iteration 1361, loss = 0.02541968\n",
      "Iteration 1362, loss = 0.02539886\n",
      "Iteration 1363, loss = 0.02537797\n",
      "Iteration 1364, loss = 0.02535706\n",
      "Iteration 1365, loss = 0.02533707\n",
      "Iteration 1366, loss = 0.02531722\n",
      "Iteration 1367, loss = 0.02529764\n",
      "Iteration 1368, loss = 0.02527798\n",
      "Iteration 1369, loss = 0.02525977\n",
      "Iteration 1370, loss = 0.02523981\n",
      "Iteration 1371, loss = 0.02522121\n",
      "Iteration 1372, loss = 0.02520150\n",
      "Iteration 1373, loss = 0.02518305\n",
      "Iteration 1374, loss = 0.02516423\n",
      "Iteration 1375, loss = 0.02514484\n",
      "Iteration 1376, loss = 0.02512636\n",
      "Iteration 1377, loss = 0.02510823\n",
      "Iteration 1378, loss = 0.02508607\n",
      "Iteration 1379, loss = 0.02506567\n",
      "Iteration 1380, loss = 0.02504688\n",
      "Iteration 1381, loss = 0.02502718\n",
      "Iteration 1382, loss = 0.02500746\n",
      "Iteration 1383, loss = 0.02498746\n",
      "Iteration 1384, loss = 0.02496853\n",
      "Iteration 1385, loss = 0.02494765\n",
      "Iteration 1386, loss = 0.02493001\n",
      "Iteration 1387, loss = 0.02491106\n",
      "Iteration 1388, loss = 0.02489278\n",
      "Iteration 1389, loss = 0.02487036\n",
      "Iteration 1390, loss = 0.02485031\n",
      "Iteration 1391, loss = 0.02482993\n",
      "Iteration 1392, loss = 0.02481013\n",
      "Iteration 1393, loss = 0.02479201\n",
      "Iteration 1394, loss = 0.02477029\n",
      "Iteration 1395, loss = 0.02475256\n",
      "Iteration 1396, loss = 0.02473131\n",
      "Iteration 1397, loss = 0.02471059\n",
      "Iteration 1398, loss = 0.02469321\n",
      "Iteration 1399, loss = 0.02467084\n",
      "Iteration 1400, loss = 0.02465409\n",
      "Iteration 1401, loss = 0.02463253\n",
      "Iteration 1402, loss = 0.02461348\n",
      "Iteration 1403, loss = 0.02459381\n",
      "Iteration 1404, loss = 0.02457486\n",
      "Iteration 1405, loss = 0.02455580\n",
      "Iteration 1406, loss = 0.02453635\n",
      "Iteration 1407, loss = 0.02451746\n",
      "Iteration 1408, loss = 0.02449634\n",
      "Iteration 1409, loss = 0.02447662\n",
      "Iteration 1410, loss = 0.02445320\n",
      "Iteration 1411, loss = 0.02443592\n",
      "Iteration 1412, loss = 0.02441286\n",
      "Iteration 1413, loss = 0.02439571\n",
      "Iteration 1414, loss = 0.02437484\n",
      "Iteration 1415, loss = 0.02435512\n",
      "Iteration 1416, loss = 0.02433647\n",
      "Iteration 1417, loss = 0.02431760\n",
      "Iteration 1418, loss = 0.02429939\n",
      "Iteration 1419, loss = 0.02428044\n",
      "Iteration 1420, loss = 0.02425865\n",
      "Iteration 1421, loss = 0.02424074\n",
      "Iteration 1422, loss = 0.02422030\n",
      "Iteration 1423, loss = 0.02419971\n",
      "Iteration 1424, loss = 0.02417931\n",
      "Iteration 1425, loss = 0.02416132\n",
      "Iteration 1426, loss = 0.02414339\n",
      "Iteration 1427, loss = 0.02412299\n",
      "Iteration 1428, loss = 0.02410466\n",
      "Iteration 1429, loss = 0.02408593\n",
      "Iteration 1430, loss = 0.02406639\n",
      "Iteration 1431, loss = 0.02404871\n",
      "Iteration 1432, loss = 0.02403059\n",
      "Iteration 1433, loss = 0.02401187\n",
      "Iteration 1434, loss = 0.02399435\n",
      "Iteration 1435, loss = 0.02397419\n",
      "Iteration 1436, loss = 0.02395498\n",
      "Iteration 1437, loss = 0.02393684\n",
      "Iteration 1438, loss = 0.02391693\n",
      "Iteration 1439, loss = 0.02389997\n",
      "Iteration 1440, loss = 0.02387923\n",
      "Iteration 1441, loss = 0.02385860\n",
      "Iteration 1442, loss = 0.02384085\n",
      "Iteration 1443, loss = 0.02382236\n",
      "Iteration 1444, loss = 0.02380365\n",
      "Iteration 1445, loss = 0.02378620\n",
      "Iteration 1446, loss = 0.02376712\n",
      "Iteration 1447, loss = 0.02374739\n",
      "Iteration 1448, loss = 0.02372893\n",
      "Iteration 1449, loss = 0.02371162\n",
      "Iteration 1450, loss = 0.02369265\n",
      "Iteration 1451, loss = 0.02367565\n",
      "Iteration 1452, loss = 0.02365811\n",
      "Iteration 1453, loss = 0.02364023\n",
      "Iteration 1454, loss = 0.02361993\n",
      "Iteration 1455, loss = 0.02360171\n",
      "Iteration 1456, loss = 0.02358410\n",
      "Iteration 1457, loss = 0.02356563\n",
      "Iteration 1458, loss = 0.02354613\n",
      "Iteration 1459, loss = 0.02353142\n",
      "Iteration 1460, loss = 0.02351090\n",
      "Iteration 1461, loss = 0.02349160\n",
      "Iteration 1462, loss = 0.02347272\n",
      "Iteration 1463, loss = 0.02345509\n",
      "Iteration 1464, loss = 0.02343725\n",
      "Iteration 1465, loss = 0.02341824\n",
      "Iteration 1466, loss = 0.02340070\n",
      "Iteration 1467, loss = 0.02338495\n",
      "Iteration 1468, loss = 0.02336672\n",
      "Iteration 1469, loss = 0.02334950\n",
      "Iteration 1470, loss = 0.02333116\n",
      "Iteration 1471, loss = 0.02331358\n",
      "Iteration 1472, loss = 0.02329677\n",
      "Iteration 1473, loss = 0.02327866\n",
      "Iteration 1474, loss = 0.02326150\n",
      "Iteration 1475, loss = 0.02324388\n",
      "Iteration 1476, loss = 0.02322655\n",
      "Iteration 1477, loss = 0.02320768\n",
      "Iteration 1478, loss = 0.02318825\n",
      "Iteration 1479, loss = 0.02317005\n",
      "Iteration 1480, loss = 0.02315324\n",
      "Iteration 1481, loss = 0.02313367\n",
      "Iteration 1482, loss = 0.02311741\n",
      "Iteration 1483, loss = 0.02309850\n",
      "Iteration 1484, loss = 0.02308298\n",
      "Iteration 1485, loss = 0.02306530\n",
      "Iteration 1486, loss = 0.02304785\n",
      "Iteration 1487, loss = 0.02303186\n",
      "Iteration 1488, loss = 0.02301454\n",
      "Iteration 1489, loss = 0.02299707\n",
      "Iteration 1490, loss = 0.02298159\n",
      "Iteration 1491, loss = 0.02296239\n",
      "Iteration 1492, loss = 0.02294438\n",
      "Iteration 1493, loss = 0.02292558\n",
      "Iteration 1494, loss = 0.02290581\n",
      "Iteration 1495, loss = 0.02288821\n",
      "Iteration 1496, loss = 0.02286921\n",
      "Iteration 1497, loss = 0.02285031\n",
      "Iteration 1498, loss = 0.02283137\n",
      "Iteration 1499, loss = 0.02281464\n",
      "Iteration 1500, loss = 0.02279558\n",
      "Iteration 1501, loss = 0.02277883\n",
      "Iteration 1502, loss = 0.02276121\n",
      "Iteration 1503, loss = 0.02274465\n",
      "Iteration 1504, loss = 0.02272804\n",
      "Iteration 1505, loss = 0.02271109\n",
      "Iteration 1506, loss = 0.02269518\n",
      "Iteration 1507, loss = 0.02267770\n",
      "Iteration 1508, loss = 0.02266149\n",
      "Iteration 1509, loss = 0.02264505\n",
      "Iteration 1510, loss = 0.02263040\n",
      "Iteration 1511, loss = 0.02261245\n",
      "Iteration 1512, loss = 0.02259561\n",
      "Iteration 1513, loss = 0.02257851\n",
      "Iteration 1514, loss = 0.02256194\n",
      "Iteration 1515, loss = 0.02254612\n",
      "Iteration 1516, loss = 0.02252840\n",
      "Iteration 1517, loss = 0.02251053\n",
      "Iteration 1518, loss = 0.02249388\n",
      "Iteration 1519, loss = 0.02247660\n",
      "Iteration 1520, loss = 0.02246033\n",
      "Iteration 1521, loss = 0.02244611\n",
      "Iteration 1522, loss = 0.02242990\n",
      "Iteration 1523, loss = 0.02241629\n",
      "Iteration 1524, loss = 0.02239815\n",
      "Iteration 1525, loss = 0.02238219\n",
      "Iteration 1526, loss = 0.02236717\n",
      "Iteration 1527, loss = 0.02234897\n",
      "Iteration 1528, loss = 0.02233357\n",
      "Iteration 1529, loss = 0.02231547\n",
      "Iteration 1530, loss = 0.02229898\n",
      "Iteration 1531, loss = 0.02228146\n",
      "Iteration 1532, loss = 0.02226485\n",
      "Iteration 1533, loss = 0.02224838\n",
      "Iteration 1534, loss = 0.02223221\n",
      "Iteration 1535, loss = 0.02221441\n",
      "Iteration 1536, loss = 0.02219713\n",
      "Iteration 1537, loss = 0.02217989\n",
      "Iteration 1538, loss = 0.02216466\n",
      "Iteration 1539, loss = 0.02214658\n",
      "Iteration 1540, loss = 0.02212888\n",
      "Iteration 1541, loss = 0.02211165\n",
      "Iteration 1542, loss = 0.02209483\n",
      "Iteration 1543, loss = 0.02207716\n",
      "Iteration 1544, loss = 0.02206408\n",
      "Iteration 1545, loss = 0.02204571\n",
      "Iteration 1546, loss = 0.02202780\n",
      "Iteration 1547, loss = 0.02201088\n",
      "Iteration 1548, loss = 0.02199572\n",
      "Iteration 1549, loss = 0.02197570\n",
      "Iteration 1550, loss = 0.02196150\n",
      "Iteration 1551, loss = 0.02194374\n",
      "Iteration 1552, loss = 0.02192678\n",
      "Iteration 1553, loss = 0.02191012\n",
      "Iteration 1554, loss = 0.02189279\n",
      "Iteration 1555, loss = 0.02187939\n",
      "Iteration 1556, loss = 0.02186112\n",
      "Iteration 1557, loss = 0.02184367\n",
      "Iteration 1558, loss = 0.02182793\n",
      "Iteration 1559, loss = 0.02181250\n",
      "Iteration 1560, loss = 0.02179620\n",
      "Iteration 1561, loss = 0.02178119\n",
      "Iteration 1562, loss = 0.02176453\n",
      "Iteration 1563, loss = 0.02174846\n",
      "Iteration 1564, loss = 0.02173221\n",
      "Iteration 1565, loss = 0.02171500\n",
      "Iteration 1566, loss = 0.02170053\n",
      "Iteration 1567, loss = 0.02168292\n",
      "Iteration 1568, loss = 0.02166648\n",
      "Iteration 1569, loss = 0.02165179\n",
      "Iteration 1570, loss = 0.02163361\n",
      "Iteration 1571, loss = 0.02161766\n",
      "Iteration 1572, loss = 0.02160073\n",
      "Iteration 1573, loss = 0.02158539\n",
      "Iteration 1574, loss = 0.02156850\n",
      "Iteration 1575, loss = 0.02155244\n",
      "Iteration 1576, loss = 0.02153570\n",
      "Iteration 1577, loss = 0.02151885\n",
      "Iteration 1578, loss = 0.02150279\n",
      "Iteration 1579, loss = 0.02148623\n",
      "Iteration 1580, loss = 0.02147011\n",
      "Iteration 1581, loss = 0.02145493\n",
      "Iteration 1582, loss = 0.02143956\n",
      "Iteration 1583, loss = 0.02142635\n",
      "Iteration 1584, loss = 0.02141184\n",
      "Iteration 1585, loss = 0.02139709\n",
      "Iteration 1586, loss = 0.02138048\n",
      "Iteration 1587, loss = 0.02136417\n",
      "Iteration 1588, loss = 0.02134921\n",
      "Iteration 1589, loss = 0.02133319\n",
      "Iteration 1590, loss = 0.02131810\n",
      "Iteration 1591, loss = 0.02130116\n",
      "Iteration 1592, loss = 0.02128658\n",
      "Iteration 1593, loss = 0.02127294\n",
      "Iteration 1594, loss = 0.02125609\n",
      "Iteration 1595, loss = 0.02124020\n",
      "Iteration 1596, loss = 0.02122345\n",
      "Iteration 1597, loss = 0.02120877\n",
      "Iteration 1598, loss = 0.02119248\n",
      "Iteration 1599, loss = 0.02117689\n",
      "Iteration 1600, loss = 0.02116107\n",
      "Iteration 1601, loss = 0.02114517\n",
      "Iteration 1602, loss = 0.02112990\n",
      "Iteration 1603, loss = 0.02111476\n",
      "Iteration 1604, loss = 0.02109889\n",
      "Iteration 1605, loss = 0.02108360\n",
      "Iteration 1606, loss = 0.02106816\n",
      "Iteration 1607, loss = 0.02105233\n",
      "Iteration 1608, loss = 0.02103675\n",
      "Iteration 1609, loss = 0.02102277\n",
      "Iteration 1610, loss = 0.02100781\n",
      "Iteration 1611, loss = 0.02099085\n",
      "Iteration 1612, loss = 0.02097839\n",
      "Iteration 1613, loss = 0.02096046\n",
      "Iteration 1614, loss = 0.02094580\n",
      "Iteration 1615, loss = 0.02092944\n",
      "Iteration 1616, loss = 0.02091387\n",
      "Iteration 1617, loss = 0.02089889\n",
      "Iteration 1618, loss = 0.02088374\n",
      "Iteration 1619, loss = 0.02086807\n",
      "Iteration 1620, loss = 0.02085441\n",
      "Iteration 1621, loss = 0.02083634\n",
      "Iteration 1622, loss = 0.02082148\n",
      "Iteration 1623, loss = 0.02080569\n",
      "Iteration 1624, loss = 0.02078972\n",
      "Iteration 1625, loss = 0.02077437\n",
      "Iteration 1626, loss = 0.02076042\n",
      "Iteration 1627, loss = 0.02074493\n",
      "Iteration 1628, loss = 0.02073067\n",
      "Iteration 1629, loss = 0.02071536\n",
      "Iteration 1630, loss = 0.02070085\n",
      "Iteration 1631, loss = 0.02068591\n",
      "Iteration 1632, loss = 0.02067236\n",
      "Iteration 1633, loss = 0.02065961\n",
      "Iteration 1634, loss = 0.02064243\n",
      "Iteration 1635, loss = 0.02062678\n",
      "Iteration 1636, loss = 0.02061227\n",
      "Iteration 1637, loss = 0.02059694\n",
      "Iteration 1638, loss = 0.02058084\n",
      "Iteration 1639, loss = 0.02056567\n",
      "Iteration 1640, loss = 0.02055513\n",
      "Iteration 1641, loss = 0.02053646\n",
      "Iteration 1642, loss = 0.02052522\n",
      "Iteration 1643, loss = 0.02050936\n",
      "Iteration 1644, loss = 0.02049409\n",
      "Iteration 1645, loss = 0.02048105\n",
      "Iteration 1646, loss = 0.02046527\n",
      "Iteration 1647, loss = 0.02045041\n",
      "Iteration 1648, loss = 0.02043664\n",
      "Iteration 1649, loss = 0.02042095\n",
      "Iteration 1650, loss = 0.02040780\n",
      "Iteration 1651, loss = 0.02039350\n",
      "Iteration 1652, loss = 0.02037930\n",
      "Iteration 1653, loss = 0.02036596\n",
      "Iteration 1654, loss = 0.02035126\n",
      "Iteration 1655, loss = 0.02033759\n",
      "Iteration 1656, loss = 0.02032665\n",
      "Iteration 1657, loss = 0.02031084\n",
      "Iteration 1658, loss = 0.02029764\n",
      "Iteration 1659, loss = 0.02028354\n",
      "Iteration 1660, loss = 0.02026727\n",
      "Iteration 1661, loss = 0.02025327\n",
      "Iteration 1662, loss = 0.02024004\n",
      "Iteration 1663, loss = 0.02022458\n",
      "Iteration 1664, loss = 0.02020914\n",
      "Iteration 1665, loss = 0.02019516\n",
      "Iteration 1666, loss = 0.02018043\n",
      "Iteration 1667, loss = 0.02016559\n",
      "Iteration 1668, loss = 0.02015152\n",
      "Iteration 1669, loss = 0.02013767\n",
      "Iteration 1670, loss = 0.02012330\n",
      "Iteration 1671, loss = 0.02011139\n",
      "Iteration 1672, loss = 0.02009475\n",
      "Iteration 1673, loss = 0.02008132\n",
      "Iteration 1674, loss = 0.02006735\n",
      "Iteration 1675, loss = 0.02005437\n",
      "Iteration 1676, loss = 0.02003874\n",
      "Iteration 1677, loss = 0.02002427\n",
      "Iteration 1678, loss = 0.02001100\n",
      "Iteration 1679, loss = 0.01999745\n",
      "Iteration 1680, loss = 0.01998751\n",
      "Iteration 1681, loss = 0.01997213\n",
      "Iteration 1682, loss = 0.01995834\n",
      "Iteration 1683, loss = 0.01994503\n",
      "Iteration 1684, loss = 0.01993095\n",
      "Iteration 1685, loss = 0.01991954\n",
      "Iteration 1686, loss = 0.01990488\n",
      "Iteration 1687, loss = 0.01989091\n",
      "Iteration 1688, loss = 0.01987763\n",
      "Iteration 1689, loss = 0.01986396\n",
      "Iteration 1690, loss = 0.01984979\n",
      "Iteration 1691, loss = 0.01983729\n",
      "Iteration 1692, loss = 0.01982406\n",
      "Iteration 1693, loss = 0.01981013\n",
      "Iteration 1694, loss = 0.01979598\n",
      "Iteration 1695, loss = 0.01978463\n",
      "Iteration 1696, loss = 0.01977008\n",
      "Iteration 1697, loss = 0.01975810\n",
      "Iteration 1698, loss = 0.01974339\n",
      "Iteration 1699, loss = 0.01972914\n",
      "Iteration 1700, loss = 0.01971532\n",
      "Iteration 1701, loss = 0.01970189\n",
      "Iteration 1702, loss = 0.01968778\n",
      "Iteration 1703, loss = 0.01967451\n",
      "Iteration 1704, loss = 0.01966252\n",
      "Iteration 1705, loss = 0.01964749\n",
      "Iteration 1706, loss = 0.01963558\n",
      "Iteration 1707, loss = 0.01962070\n",
      "Iteration 1708, loss = 0.01960787\n",
      "Iteration 1709, loss = 0.01959341\n",
      "Iteration 1710, loss = 0.01957949\n",
      "Iteration 1711, loss = 0.01956607\n",
      "Iteration 1712, loss = 0.01955417\n",
      "Iteration 1713, loss = 0.01953896\n",
      "Iteration 1714, loss = 0.01952497\n",
      "Iteration 1715, loss = 0.01951086\n",
      "Iteration 1716, loss = 0.01949744\n",
      "Iteration 1717, loss = 0.01948791\n",
      "Iteration 1718, loss = 0.01947136\n",
      "Iteration 1719, loss = 0.01945633\n",
      "Iteration 1720, loss = 0.01944266\n",
      "Iteration 1721, loss = 0.01942911\n",
      "Iteration 1722, loss = 0.01941555\n",
      "Iteration 1723, loss = 0.01940278\n",
      "Iteration 1724, loss = 0.01938840\n",
      "Iteration 1725, loss = 0.01937567\n",
      "Iteration 1726, loss = 0.01936257\n",
      "Iteration 1727, loss = 0.01934993\n",
      "Iteration 1728, loss = 0.01933594\n",
      "Iteration 1729, loss = 0.01932291\n",
      "Iteration 1730, loss = 0.01930969\n",
      "Iteration 1731, loss = 0.01929733\n",
      "Iteration 1732, loss = 0.01928512\n",
      "Iteration 1733, loss = 0.01927142\n",
      "Iteration 1734, loss = 0.01925830\n",
      "Iteration 1735, loss = 0.01924416\n",
      "Iteration 1736, loss = 0.01923335\n",
      "Iteration 1737, loss = 0.01922052\n",
      "Iteration 1738, loss = 0.01920867\n",
      "Iteration 1739, loss = 0.01919450\n",
      "Iteration 1740, loss = 0.01918177\n",
      "Iteration 1741, loss = 0.01916970\n",
      "Iteration 1742, loss = 0.01915521\n",
      "Iteration 1743, loss = 0.01914271\n",
      "Iteration 1744, loss = 0.01912974\n",
      "Iteration 1745, loss = 0.01911937\n",
      "Iteration 1746, loss = 0.01910609\n",
      "Iteration 1747, loss = 0.01909270\n",
      "Iteration 1748, loss = 0.01907916\n",
      "Iteration 1749, loss = 0.01906668\n",
      "Iteration 1750, loss = 0.01905398\n",
      "Iteration 1751, loss = 0.01904021\n",
      "Iteration 1752, loss = 0.01903137\n",
      "Iteration 1753, loss = 0.01901592\n",
      "Iteration 1754, loss = 0.01900341\n",
      "Iteration 1755, loss = 0.01899120\n",
      "Iteration 1756, loss = 0.01897829\n",
      "Iteration 1757, loss = 0.01896597\n",
      "Iteration 1758, loss = 0.01895201\n",
      "Iteration 1759, loss = 0.01893932\n",
      "Iteration 1760, loss = 0.01892612\n",
      "Iteration 1761, loss = 0.01891311\n",
      "Iteration 1762, loss = 0.01889979\n",
      "Iteration 1763, loss = 0.01888780\n",
      "Iteration 1764, loss = 0.01887496\n",
      "Iteration 1765, loss = 0.01886189\n",
      "Iteration 1766, loss = 0.01884943\n",
      "Iteration 1767, loss = 0.01883596\n",
      "Iteration 1768, loss = 0.01882311\n",
      "Iteration 1769, loss = 0.01881262\n",
      "Iteration 1770, loss = 0.01879800\n",
      "Iteration 1771, loss = 0.01878612\n",
      "Iteration 1772, loss = 0.01877327\n",
      "Iteration 1773, loss = 0.01876071\n",
      "Iteration 1774, loss = 0.01874773\n",
      "Iteration 1775, loss = 0.01873736\n",
      "Iteration 1776, loss = 0.01872632\n",
      "Iteration 1777, loss = 0.01871033\n",
      "Iteration 1778, loss = 0.01869768\n",
      "Iteration 1779, loss = 0.01868409\n",
      "Iteration 1780, loss = 0.01867000\n",
      "Iteration 1781, loss = 0.01865714\n",
      "Iteration 1782, loss = 0.01864532\n",
      "Iteration 1783, loss = 0.01863108\n",
      "Iteration 1784, loss = 0.01861820\n",
      "Iteration 1785, loss = 0.01860558\n",
      "Iteration 1786, loss = 0.01859229\n",
      "Iteration 1787, loss = 0.01858005\n",
      "Iteration 1788, loss = 0.01856647\n",
      "Iteration 1789, loss = 0.01855509\n",
      "Iteration 1790, loss = 0.01853934\n",
      "Iteration 1791, loss = 0.01852589\n",
      "Iteration 1792, loss = 0.01851225\n",
      "Iteration 1793, loss = 0.01849870\n",
      "Iteration 1794, loss = 0.01848544\n",
      "Iteration 1795, loss = 0.01847258\n",
      "Iteration 1796, loss = 0.01846001\n",
      "Iteration 1797, loss = 0.01844711\n",
      "Iteration 1798, loss = 0.01843454\n",
      "Iteration 1799, loss = 0.01842245\n",
      "Iteration 1800, loss = 0.01840932\n",
      "Iteration 1801, loss = 0.01839909\n",
      "Iteration 1802, loss = 0.01838416\n",
      "Iteration 1803, loss = 0.01837189\n",
      "Iteration 1804, loss = 0.01835940\n",
      "Iteration 1805, loss = 0.01835060\n",
      "Iteration 1806, loss = 0.01833500\n",
      "Iteration 1807, loss = 0.01832397\n",
      "Iteration 1808, loss = 0.01831018\n",
      "Iteration 1809, loss = 0.01829855\n",
      "Iteration 1810, loss = 0.01828589\n",
      "Iteration 1811, loss = 0.01827274\n",
      "Iteration 1812, loss = 0.01825981\n",
      "Iteration 1813, loss = 0.01825119\n",
      "Iteration 1814, loss = 0.01823751\n",
      "Iteration 1815, loss = 0.01822527\n",
      "Iteration 1816, loss = 0.01821301\n",
      "Iteration 1817, loss = 0.01820222\n",
      "Iteration 1818, loss = 0.01819260\n",
      "Iteration 1819, loss = 0.01817834\n",
      "Iteration 1820, loss = 0.01816636\n",
      "Iteration 1821, loss = 0.01815425\n",
      "Iteration 1822, loss = 0.01814256\n",
      "Iteration 1823, loss = 0.01813007\n",
      "Iteration 1824, loss = 0.01811744\n",
      "Iteration 1825, loss = 0.01810550\n",
      "Iteration 1826, loss = 0.01809578\n",
      "Iteration 1827, loss = 0.01808161\n",
      "Iteration 1828, loss = 0.01806994\n",
      "Iteration 1829, loss = 0.01805791\n",
      "Iteration 1830, loss = 0.01804703\n",
      "Iteration 1831, loss = 0.01803487\n",
      "Iteration 1832, loss = 0.01802375\n",
      "Iteration 1833, loss = 0.01801209\n",
      "Iteration 1834, loss = 0.01800035\n",
      "Iteration 1835, loss = 0.01799001\n",
      "Iteration 1836, loss = 0.01797798\n",
      "Iteration 1837, loss = 0.01796540\n",
      "Iteration 1838, loss = 0.01795398\n",
      "Iteration 1839, loss = 0.01794214\n",
      "Iteration 1840, loss = 0.01792939\n",
      "Iteration 1841, loss = 0.01791868\n",
      "Iteration 1842, loss = 0.01790605\n",
      "Iteration 1843, loss = 0.01789335\n",
      "Iteration 1844, loss = 0.01788202\n",
      "Iteration 1845, loss = 0.01787141\n",
      "Iteration 1846, loss = 0.01785969\n",
      "Iteration 1847, loss = 0.01784799\n",
      "Iteration 1848, loss = 0.01783550\n",
      "Iteration 1849, loss = 0.01782458\n",
      "Iteration 1850, loss = 0.01781331\n",
      "Iteration 1851, loss = 0.01780238\n",
      "Iteration 1852, loss = 0.01778974\n",
      "Iteration 1853, loss = 0.01777772\n",
      "Iteration 1854, loss = 0.01776579\n",
      "Iteration 1855, loss = 0.01775691\n",
      "Iteration 1856, loss = 0.01774375\n",
      "Iteration 1857, loss = 0.01773153\n",
      "Iteration 1858, loss = 0.01772049\n",
      "Iteration 1859, loss = 0.01770788\n",
      "Iteration 1860, loss = 0.01769555\n",
      "Iteration 1861, loss = 0.01768518\n",
      "Iteration 1862, loss = 0.01767269\n",
      "Iteration 1863, loss = 0.01766115\n",
      "Iteration 1864, loss = 0.01765086\n",
      "Iteration 1865, loss = 0.01763903\n",
      "Iteration 1866, loss = 0.01762788\n",
      "Iteration 1867, loss = 0.01761622\n",
      "Iteration 1868, loss = 0.01760616\n",
      "Iteration 1869, loss = 0.01759497\n",
      "Iteration 1870, loss = 0.01758387\n",
      "Iteration 1871, loss = 0.01757322\n",
      "Iteration 1872, loss = 0.01756214\n",
      "Iteration 1873, loss = 0.01755105\n",
      "Iteration 1874, loss = 0.01754027\n",
      "Iteration 1875, loss = 0.01752964\n",
      "Iteration 1876, loss = 0.01751844\n",
      "Iteration 1877, loss = 0.01750654\n",
      "Iteration 1878, loss = 0.01749534\n",
      "Iteration 1879, loss = 0.01748503\n",
      "Iteration 1880, loss = 0.01747618\n",
      "Iteration 1881, loss = 0.01746366\n",
      "Iteration 1882, loss = 0.01745185\n",
      "Iteration 1883, loss = 0.01743853\n",
      "Iteration 1884, loss = 0.01742880\n",
      "Iteration 1885, loss = 0.01741458\n",
      "Iteration 1886, loss = 0.01740371\n",
      "Iteration 1887, loss = 0.01739179\n",
      "Iteration 1888, loss = 0.01737968\n",
      "Iteration 1889, loss = 0.01736850\n",
      "Iteration 1890, loss = 0.01735852\n",
      "Iteration 1891, loss = 0.01734684\n",
      "Iteration 1892, loss = 0.01733411\n",
      "Iteration 1893, loss = 0.01732399\n",
      "Iteration 1894, loss = 0.01731362\n",
      "Iteration 1895, loss = 0.01730197\n",
      "Iteration 1896, loss = 0.01728970\n",
      "Iteration 1897, loss = 0.01727944\n",
      "Iteration 1898, loss = 0.01726779\n",
      "Iteration 1899, loss = 0.01725842\n",
      "Iteration 1900, loss = 0.01724498\n",
      "Iteration 1901, loss = 0.01723356\n",
      "Iteration 1902, loss = 0.01722273\n",
      "Iteration 1903, loss = 0.01721006\n",
      "Iteration 1904, loss = 0.01720039\n",
      "Iteration 1905, loss = 0.01718821\n",
      "Iteration 1906, loss = 0.01717781\n",
      "Iteration 1907, loss = 0.01716619\n",
      "Iteration 1908, loss = 0.01715472\n",
      "Iteration 1909, loss = 0.01714478\n",
      "Iteration 1910, loss = 0.01713342\n",
      "Iteration 1911, loss = 0.01712345\n",
      "Iteration 1912, loss = 0.01711139\n",
      "Iteration 1913, loss = 0.01710108\n",
      "Iteration 1914, loss = 0.01709031\n",
      "Iteration 1915, loss = 0.01707984\n",
      "Iteration 1916, loss = 0.01706880\n",
      "Iteration 1917, loss = 0.01705876\n",
      "Iteration 1918, loss = 0.01704745\n",
      "Iteration 1919, loss = 0.01703718\n",
      "Iteration 1920, loss = 0.01702728\n",
      "Iteration 1921, loss = 0.01701654\n",
      "Iteration 1922, loss = 0.01700641\n",
      "Iteration 1923, loss = 0.01699655\n",
      "Iteration 1924, loss = 0.01698607\n",
      "Iteration 1925, loss = 0.01697658\n",
      "Iteration 1926, loss = 0.01696571\n",
      "Iteration 1927, loss = 0.01695475\n",
      "Iteration 1928, loss = 0.01694443\n",
      "Iteration 1929, loss = 0.01693404\n",
      "Iteration 1930, loss = 0.01692385\n",
      "Iteration 1931, loss = 0.01691445\n",
      "Iteration 1932, loss = 0.01690559\n",
      "Iteration 1933, loss = 0.01689576\n",
      "Iteration 1934, loss = 0.01688610\n",
      "Iteration 1935, loss = 0.01687688\n",
      "Iteration 1936, loss = 0.01686709\n",
      "Iteration 1937, loss = 0.01685625\n",
      "Iteration 1938, loss = 0.01684588\n",
      "Iteration 1939, loss = 0.01683528\n",
      "Iteration 1940, loss = 0.01682531\n",
      "Iteration 1941, loss = 0.01681261\n",
      "Iteration 1942, loss = 0.01680132\n",
      "Iteration 1943, loss = 0.01679417\n",
      "Iteration 1944, loss = 0.01678103\n",
      "Iteration 1945, loss = 0.01676992\n",
      "Iteration 1946, loss = 0.01675778\n",
      "Iteration 1947, loss = 0.01674710\n",
      "Iteration 1948, loss = 0.01673708\n",
      "Iteration 1949, loss = 0.01672490\n",
      "Iteration 1950, loss = 0.01671415\n",
      "Iteration 1951, loss = 0.01670391\n",
      "Iteration 1952, loss = 0.01669328\n",
      "Iteration 1953, loss = 0.01668353\n",
      "Iteration 1954, loss = 0.01667325\n",
      "Iteration 1955, loss = 0.01666333\n",
      "Iteration 1956, loss = 0.01665369\n",
      "Iteration 1957, loss = 0.01664374\n",
      "Iteration 1958, loss = 0.01663356\n",
      "Iteration 1959, loss = 0.01662417\n",
      "Iteration 1960, loss = 0.01661520\n",
      "Iteration 1961, loss = 0.01660589\n",
      "Iteration 1962, loss = 0.01659598\n",
      "Iteration 1963, loss = 0.01658737\n",
      "Iteration 1964, loss = 0.01657872\n",
      "Iteration 1965, loss = 0.01656773\n",
      "Iteration 1966, loss = 0.01655830\n",
      "Iteration 1967, loss = 0.01654906\n",
      "Iteration 1968, loss = 0.01653824\n",
      "Iteration 1969, loss = 0.01652864\n",
      "Iteration 1970, loss = 0.01651777\n",
      "Iteration 1971, loss = 0.01650722\n",
      "Iteration 1972, loss = 0.01649758\n",
      "Iteration 1973, loss = 0.01648978\n",
      "Iteration 1974, loss = 0.01647827\n",
      "Iteration 1975, loss = 0.01646811\n",
      "Iteration 1976, loss = 0.01645967\n",
      "Iteration 1977, loss = 0.01644978\n",
      "Iteration 1978, loss = 0.01643949\n",
      "Iteration 1979, loss = 0.01643072\n",
      "Iteration 1980, loss = 0.01642109\n",
      "Iteration 1981, loss = 0.01641037\n",
      "Iteration 1982, loss = 0.01640095\n",
      "Iteration 1983, loss = 0.01639040\n",
      "Iteration 1984, loss = 0.01637932\n",
      "Iteration 1985, loss = 0.01637033\n",
      "Iteration 1986, loss = 0.01635922\n",
      "Iteration 1987, loss = 0.01635002\n",
      "Iteration 1988, loss = 0.01634036\n",
      "Iteration 1989, loss = 0.01633404\n",
      "Iteration 1990, loss = 0.01632104\n",
      "Iteration 1991, loss = 0.01631113\n",
      "Iteration 1992, loss = 0.01630168\n",
      "Iteration 1993, loss = 0.01629153\n",
      "Iteration 1994, loss = 0.01628283\n",
      "Iteration 1995, loss = 0.01627214\n",
      "Iteration 1996, loss = 0.01626209\n",
      "Iteration 1997, loss = 0.01625318\n",
      "Iteration 1998, loss = 0.01624357\n",
      "Iteration 1999, loss = 0.01623331\n",
      "Iteration 2000, loss = 0.01622349\n",
      "Iteration 2001, loss = 0.01621553\n",
      "Iteration 2002, loss = 0.01620530\n",
      "Iteration 2003, loss = 0.01619544\n",
      "Iteration 2004, loss = 0.01618572\n",
      "Iteration 2005, loss = 0.01617610\n",
      "Iteration 2006, loss = 0.01616696\n",
      "Iteration 2007, loss = 0.01615736\n",
      "Iteration 2008, loss = 0.01614734\n",
      "Iteration 2009, loss = 0.01613800\n",
      "Iteration 2010, loss = 0.01612873\n",
      "Iteration 2011, loss = 0.01611944\n",
      "Iteration 2012, loss = 0.01611005\n",
      "Iteration 2013, loss = 0.01610161\n",
      "Iteration 2014, loss = 0.01609271\n",
      "Iteration 2015, loss = 0.01608421\n",
      "Iteration 2016, loss = 0.01607576\n",
      "Iteration 2017, loss = 0.01606437\n",
      "Iteration 2018, loss = 0.01605419\n",
      "Iteration 2019, loss = 0.01604406\n",
      "Iteration 2020, loss = 0.01603398\n",
      "Iteration 2021, loss = 0.01602275\n",
      "Iteration 2022, loss = 0.01601392\n",
      "Iteration 2023, loss = 0.01600519\n",
      "Iteration 2024, loss = 0.01599599\n",
      "Iteration 2025, loss = 0.01598536\n",
      "Iteration 2026, loss = 0.01597631\n",
      "Iteration 2027, loss = 0.01596758\n",
      "Iteration 2028, loss = 0.01595887\n",
      "Iteration 2029, loss = 0.01595029\n",
      "Iteration 2030, loss = 0.01593965\n",
      "Iteration 2031, loss = 0.01593267\n",
      "Iteration 2032, loss = 0.01592188\n",
      "Iteration 2033, loss = 0.01591227\n",
      "Iteration 2034, loss = 0.01590347\n",
      "Iteration 2035, loss = 0.01589402\n",
      "Iteration 2036, loss = 0.01588531\n",
      "Iteration 2037, loss = 0.01587603\n",
      "Iteration 2038, loss = 0.01586741\n",
      "Iteration 2039, loss = 0.01585958\n",
      "Iteration 2040, loss = 0.01584959\n",
      "Iteration 2041, loss = 0.01583974\n",
      "Iteration 2042, loss = 0.01583065\n",
      "Iteration 2043, loss = 0.01581951\n",
      "Iteration 2044, loss = 0.01580898\n",
      "Iteration 2045, loss = 0.01579957\n",
      "Iteration 2046, loss = 0.01578808\n",
      "Iteration 2047, loss = 0.01577951\n",
      "Iteration 2048, loss = 0.01576833\n",
      "Iteration 2049, loss = 0.01575886\n",
      "Iteration 2050, loss = 0.01574802\n",
      "Iteration 2051, loss = 0.01573757\n",
      "Iteration 2052, loss = 0.01573096\n",
      "Iteration 2053, loss = 0.01571936\n",
      "Iteration 2054, loss = 0.01571114\n",
      "Iteration 2055, loss = 0.01570055\n",
      "Iteration 2056, loss = 0.01569224\n",
      "Iteration 2057, loss = 0.01568215\n",
      "Iteration 2058, loss = 0.01567302\n",
      "Iteration 2059, loss = 0.01566369\n",
      "Iteration 2060, loss = 0.01565459\n",
      "Iteration 2061, loss = 0.01564522\n",
      "Iteration 2062, loss = 0.01563619\n",
      "Iteration 2063, loss = 0.01562666\n",
      "Iteration 2064, loss = 0.01561699\n",
      "Iteration 2065, loss = 0.01560784\n",
      "Iteration 2066, loss = 0.01559759\n",
      "Iteration 2067, loss = 0.01558826\n",
      "Iteration 2068, loss = 0.01557860\n",
      "Iteration 2069, loss = 0.01556911\n",
      "Iteration 2070, loss = 0.01555995\n",
      "Iteration 2071, loss = 0.01555097\n",
      "Iteration 2072, loss = 0.01554229\n",
      "Iteration 2073, loss = 0.01553446\n",
      "Iteration 2074, loss = 0.01552281\n",
      "Iteration 2075, loss = 0.01551372\n",
      "Iteration 2076, loss = 0.01550298\n",
      "Iteration 2077, loss = 0.01549362\n",
      "Iteration 2078, loss = 0.01548358\n",
      "Iteration 2079, loss = 0.01547407\n",
      "Iteration 2080, loss = 0.01546405\n",
      "Iteration 2081, loss = 0.01545422\n",
      "Iteration 2082, loss = 0.01544521\n",
      "Iteration 2083, loss = 0.01543545\n",
      "Iteration 2084, loss = 0.01542594\n",
      "Iteration 2085, loss = 0.01541589\n",
      "Iteration 2086, loss = 0.01540693\n",
      "Iteration 2087, loss = 0.01539829\n",
      "Iteration 2088, loss = 0.01538870\n",
      "Iteration 2089, loss = 0.01538193\n",
      "Iteration 2090, loss = 0.01537079\n",
      "Iteration 2091, loss = 0.01536307\n",
      "Iteration 2092, loss = 0.01535350\n",
      "Iteration 2093, loss = 0.01534489\n",
      "Iteration 2094, loss = 0.01533600\n",
      "Iteration 2095, loss = 0.01532762\n",
      "Iteration 2096, loss = 0.01531921\n",
      "Iteration 2097, loss = 0.01530988\n",
      "Iteration 2098, loss = 0.01530192\n",
      "Iteration 2099, loss = 0.01529177\n",
      "Iteration 2100, loss = 0.01528345\n",
      "Iteration 2101, loss = 0.01527415\n",
      "Iteration 2102, loss = 0.01526471\n",
      "Iteration 2103, loss = 0.01525614\n",
      "Iteration 2104, loss = 0.01524779\n",
      "Iteration 2105, loss = 0.01523963\n",
      "Iteration 2106, loss = 0.01523047\n",
      "Iteration 2107, loss = 0.01522132\n",
      "Iteration 2108, loss = 0.01521338\n",
      "Iteration 2109, loss = 0.01520457\n",
      "Iteration 2110, loss = 0.01519545\n",
      "Iteration 2111, loss = 0.01518740\n",
      "Iteration 2112, loss = 0.01517818\n",
      "Iteration 2113, loss = 0.01516981\n",
      "Iteration 2114, loss = 0.01516162\n",
      "Iteration 2115, loss = 0.01515393\n",
      "Iteration 2116, loss = 0.01514760\n",
      "Iteration 2117, loss = 0.01513752\n",
      "Iteration 2118, loss = 0.01512855\n",
      "Iteration 2119, loss = 0.01512041\n",
      "Iteration 2120, loss = 0.01511142\n",
      "Iteration 2121, loss = 0.01510276\n",
      "Iteration 2122, loss = 0.01509389\n",
      "Iteration 2123, loss = 0.01508468\n",
      "Iteration 2124, loss = 0.01507813\n",
      "Iteration 2125, loss = 0.01506936\n",
      "Iteration 2126, loss = 0.01506251\n",
      "Iteration 2127, loss = 0.01505017\n",
      "Iteration 2128, loss = 0.01504029\n",
      "Iteration 2129, loss = 0.01502968\n",
      "Iteration 2130, loss = 0.01502216\n",
      "Iteration 2131, loss = 0.01501248\n",
      "Iteration 2132, loss = 0.01500388\n",
      "Iteration 2133, loss = 0.01499517\n",
      "Iteration 2134, loss = 0.01498425\n",
      "Iteration 2135, loss = 0.01497786\n",
      "Iteration 2136, loss = 0.01496797\n",
      "Iteration 2137, loss = 0.01495871\n",
      "Iteration 2138, loss = 0.01494977\n",
      "Iteration 2139, loss = 0.01494163\n",
      "Iteration 2140, loss = 0.01493239\n",
      "Iteration 2141, loss = 0.01492493\n",
      "Iteration 2142, loss = 0.01491397\n",
      "Iteration 2143, loss = 0.01490655\n",
      "Iteration 2144, loss = 0.01489595\n",
      "Iteration 2145, loss = 0.01488812\n",
      "Iteration 2146, loss = 0.01487846\n",
      "Iteration 2147, loss = 0.01487020\n",
      "Iteration 2148, loss = 0.01486158\n",
      "Iteration 2149, loss = 0.01485290\n",
      "Iteration 2150, loss = 0.01484431\n",
      "Iteration 2151, loss = 0.01483647\n",
      "Iteration 2152, loss = 0.01482824\n",
      "Iteration 2153, loss = 0.01481937\n",
      "Iteration 2154, loss = 0.01481123\n",
      "Iteration 2155, loss = 0.01480202\n",
      "Iteration 2156, loss = 0.01479298\n",
      "Iteration 2157, loss = 0.01478372\n",
      "Iteration 2158, loss = 0.01477450\n",
      "Iteration 2159, loss = 0.01476645\n",
      "Iteration 2160, loss = 0.01475755\n",
      "Iteration 2161, loss = 0.01474757\n",
      "Iteration 2162, loss = 0.01474116\n",
      "Iteration 2163, loss = 0.01473092\n",
      "Iteration 2164, loss = 0.01472265\n",
      "Iteration 2165, loss = 0.01471265\n",
      "Iteration 2166, loss = 0.01470412\n",
      "Iteration 2167, loss = 0.01469552\n",
      "Iteration 2168, loss = 0.01468740\n",
      "Iteration 2169, loss = 0.01467848\n",
      "Iteration 2170, loss = 0.01467010\n",
      "Iteration 2171, loss = 0.01466239\n",
      "Iteration 2172, loss = 0.01465435\n",
      "Iteration 2173, loss = 0.01464584\n",
      "Iteration 2174, loss = 0.01463722\n",
      "Iteration 2175, loss = 0.01463045\n",
      "Iteration 2176, loss = 0.01462003\n",
      "Iteration 2177, loss = 0.01461196\n",
      "Iteration 2178, loss = 0.01460265\n",
      "Iteration 2179, loss = 0.01459475\n",
      "Iteration 2180, loss = 0.01458663\n",
      "Iteration 2181, loss = 0.01457794\n",
      "Iteration 2182, loss = 0.01456915\n",
      "Iteration 2183, loss = 0.01455990\n",
      "Iteration 2184, loss = 0.01455198\n",
      "Iteration 2185, loss = 0.01454322\n",
      "Iteration 2186, loss = 0.01453524\n",
      "Iteration 2187, loss = 0.01452738\n",
      "Iteration 2188, loss = 0.01451838\n",
      "Iteration 2189, loss = 0.01451045\n",
      "Iteration 2190, loss = 0.01450233\n",
      "Iteration 2191, loss = 0.01449433\n",
      "Iteration 2192, loss = 0.01448680\n",
      "Iteration 2193, loss = 0.01447758\n",
      "Iteration 2194, loss = 0.01446942\n",
      "Iteration 2195, loss = 0.01446056\n",
      "Iteration 2196, loss = 0.01445259\n",
      "Iteration 2197, loss = 0.01444334\n",
      "Iteration 2198, loss = 0.01443435\n",
      "Iteration 2199, loss = 0.01442546\n",
      "Iteration 2200, loss = 0.01441785\n",
      "Iteration 2201, loss = 0.01440993\n",
      "Iteration 2202, loss = 0.01440292\n",
      "Iteration 2203, loss = 0.01439479\n",
      "Iteration 2204, loss = 0.01438764\n",
      "Iteration 2205, loss = 0.01438044\n",
      "Iteration 2206, loss = 0.01437337\n",
      "Iteration 2207, loss = 0.01436699\n",
      "Iteration 2208, loss = 0.01435905\n",
      "Iteration 2209, loss = 0.01435149\n",
      "Iteration 2210, loss = 0.01434316\n",
      "Iteration 2211, loss = 0.01433579\n",
      "Iteration 2212, loss = 0.01432925\n",
      "Iteration 2213, loss = 0.01432014\n",
      "Iteration 2214, loss = 0.01431235\n",
      "Iteration 2215, loss = 0.01430350\n",
      "Iteration 2216, loss = 0.01429524\n",
      "Iteration 2217, loss = 0.01428718\n",
      "Iteration 2218, loss = 0.01427967\n",
      "Iteration 2219, loss = 0.01427189\n",
      "Iteration 2220, loss = 0.01426286\n",
      "Iteration 2221, loss = 0.01425672\n",
      "Iteration 2222, loss = 0.01424645\n",
      "Iteration 2223, loss = 0.01423892\n",
      "Iteration 2224, loss = 0.01423103\n",
      "Iteration 2225, loss = 0.01422177\n",
      "Iteration 2226, loss = 0.01421374\n",
      "Iteration 2227, loss = 0.01420643\n",
      "Iteration 2228, loss = 0.01419864\n",
      "Iteration 2229, loss = 0.01419066\n",
      "Iteration 2230, loss = 0.01418293\n",
      "Iteration 2231, loss = 0.01417553\n",
      "Iteration 2232, loss = 0.01416782\n",
      "Iteration 2233, loss = 0.01416005\n",
      "Iteration 2234, loss = 0.01415367\n",
      "Iteration 2235, loss = 0.01414591\n",
      "Iteration 2236, loss = 0.01413895\n",
      "Iteration 2237, loss = 0.01413240\n",
      "Iteration 2238, loss = 0.01412459\n",
      "Iteration 2239, loss = 0.01411577\n",
      "Iteration 2240, loss = 0.01410749\n",
      "Iteration 2241, loss = 0.01409975\n",
      "Iteration 2242, loss = 0.01409020\n",
      "Iteration 2243, loss = 0.01408064\n",
      "Iteration 2244, loss = 0.01407344\n",
      "Iteration 2245, loss = 0.01406615\n",
      "Iteration 2246, loss = 0.01405687\n",
      "Iteration 2247, loss = 0.01404809\n",
      "Iteration 2248, loss = 0.01404120\n",
      "Iteration 2249, loss = 0.01403324\n",
      "Iteration 2250, loss = 0.01402453\n",
      "Iteration 2251, loss = 0.01401931\n",
      "Iteration 2252, loss = 0.01401095\n",
      "Iteration 2253, loss = 0.01400351\n",
      "Iteration 2254, loss = 0.01399430\n",
      "Iteration 2255, loss = 0.01398696\n",
      "Iteration 2256, loss = 0.01397859\n",
      "Iteration 2257, loss = 0.01397138\n",
      "Iteration 2258, loss = 0.01396312\n",
      "Iteration 2259, loss = 0.01395520\n",
      "Iteration 2260, loss = 0.01394761\n",
      "Iteration 2261, loss = 0.01394017\n",
      "Iteration 2262, loss = 0.01393250\n",
      "Iteration 2263, loss = 0.01392346\n",
      "Iteration 2264, loss = 0.01391600\n",
      "Iteration 2265, loss = 0.01390753\n",
      "Iteration 2266, loss = 0.01390023\n",
      "Iteration 2267, loss = 0.01389261\n",
      "Iteration 2268, loss = 0.01388593\n",
      "Iteration 2269, loss = 0.01387880\n",
      "Iteration 2270, loss = 0.01387112\n",
      "Iteration 2271, loss = 0.01386406\n",
      "Iteration 2272, loss = 0.01385667\n",
      "Iteration 2273, loss = 0.01384987\n",
      "Iteration 2274, loss = 0.01384166\n",
      "Iteration 2275, loss = 0.01383341\n",
      "Iteration 2276, loss = 0.01382637\n",
      "Iteration 2277, loss = 0.01381845\n",
      "Iteration 2278, loss = 0.01381026\n",
      "Iteration 2279, loss = 0.01380161\n",
      "Iteration 2280, loss = 0.01379307\n",
      "Iteration 2281, loss = 0.01378719\n",
      "Iteration 2282, loss = 0.01377864\n",
      "Iteration 2283, loss = 0.01377100\n",
      "Iteration 2284, loss = 0.01376285\n",
      "Iteration 2285, loss = 0.01375482\n",
      "Iteration 2286, loss = 0.01374786\n",
      "Iteration 2287, loss = 0.01374004\n",
      "Iteration 2288, loss = 0.01373179\n",
      "Iteration 2289, loss = 0.01372483\n",
      "Iteration 2290, loss = 0.01371697\n",
      "Iteration 2291, loss = 0.01370839\n",
      "Iteration 2292, loss = 0.01370092\n",
      "Iteration 2293, loss = 0.01369325\n",
      "Iteration 2294, loss = 0.01368566\n",
      "Iteration 2295, loss = 0.01367841\n",
      "Iteration 2296, loss = 0.01367159\n",
      "Iteration 2297, loss = 0.01366432\n",
      "Iteration 2298, loss = 0.01365889\n",
      "Iteration 2299, loss = 0.01365095\n",
      "Iteration 2300, loss = 0.01364428\n",
      "Iteration 2301, loss = 0.01363742\n",
      "Iteration 2302, loss = 0.01362967\n",
      "Iteration 2303, loss = 0.01362121\n",
      "Iteration 2304, loss = 0.01361265\n",
      "Iteration 2305, loss = 0.01360570\n",
      "Iteration 2306, loss = 0.01359670\n",
      "Iteration 2307, loss = 0.01359144\n",
      "Iteration 2308, loss = 0.01358284\n",
      "Iteration 2309, loss = 0.01357431\n",
      "Iteration 2310, loss = 0.01356690\n",
      "Iteration 2311, loss = 0.01356025\n",
      "Iteration 2312, loss = 0.01355317\n",
      "Iteration 2313, loss = 0.01354512\n",
      "Iteration 2314, loss = 0.01353808\n",
      "Iteration 2315, loss = 0.01353052\n",
      "Iteration 2316, loss = 0.01352397\n",
      "Iteration 2317, loss = 0.01351649\n",
      "Iteration 2318, loss = 0.01350973\n",
      "Iteration 2319, loss = 0.01350295\n",
      "Iteration 2320, loss = 0.01349759\n",
      "Iteration 2321, loss = 0.01349032\n",
      "Iteration 2322, loss = 0.01348270\n",
      "Iteration 2323, loss = 0.01347558\n",
      "Iteration 2324, loss = 0.01346881\n",
      "Iteration 2325, loss = 0.01346100\n",
      "Iteration 2326, loss = 0.01345425\n",
      "Iteration 2327, loss = 0.01344635\n",
      "Iteration 2328, loss = 0.01343804\n",
      "Iteration 2329, loss = 0.01342903\n",
      "Iteration 2330, loss = 0.01342218\n",
      "Iteration 2331, loss = 0.01341405\n",
      "Iteration 2332, loss = 0.01340481\n",
      "Iteration 2333, loss = 0.01339699\n",
      "Iteration 2334, loss = 0.01339068\n",
      "Iteration 2335, loss = 0.01338149\n",
      "Iteration 2336, loss = 0.01337539\n",
      "Iteration 2337, loss = 0.01336607\n",
      "Iteration 2338, loss = 0.01335862\n",
      "Iteration 2339, loss = 0.01335128\n",
      "Iteration 2340, loss = 0.01334331\n",
      "Iteration 2341, loss = 0.01333595\n",
      "Iteration 2342, loss = 0.01332792\n",
      "Iteration 2343, loss = 0.01332105\n",
      "Iteration 2344, loss = 0.01331316\n",
      "Iteration 2345, loss = 0.01330539\n",
      "Iteration 2346, loss = 0.01329829\n",
      "Iteration 2347, loss = 0.01329176\n",
      "Iteration 2348, loss = 0.01328215\n",
      "Iteration 2349, loss = 0.01327543\n",
      "Iteration 2350, loss = 0.01326790\n",
      "Iteration 2351, loss = 0.01326113\n",
      "Iteration 2352, loss = 0.01325326\n",
      "Iteration 2353, loss = 0.01324664\n",
      "Iteration 2354, loss = 0.01324026\n",
      "Iteration 2355, loss = 0.01323206\n",
      "Iteration 2356, loss = 0.01322700\n",
      "Iteration 2357, loss = 0.01321772\n",
      "Iteration 2358, loss = 0.01321038\n",
      "Iteration 2359, loss = 0.01320398\n",
      "Iteration 2360, loss = 0.01319572\n",
      "Iteration 2361, loss = 0.01318945\n",
      "Iteration 2362, loss = 0.01318116\n",
      "Iteration 2363, loss = 0.01317403\n",
      "Iteration 2364, loss = 0.01316673\n",
      "Iteration 2365, loss = 0.01315916\n",
      "Iteration 2366, loss = 0.01315192\n",
      "Iteration 2367, loss = 0.01314506\n",
      "Iteration 2368, loss = 0.01313719\n",
      "Iteration 2369, loss = 0.01312901\n",
      "Iteration 2370, loss = 0.01312281\n",
      "Iteration 2371, loss = 0.01311556\n",
      "Iteration 2372, loss = 0.01310978\n",
      "Iteration 2373, loss = 0.01310053\n",
      "Iteration 2374, loss = 0.01309339\n",
      "Iteration 2375, loss = 0.01308629\n",
      "Iteration 2376, loss = 0.01307947\n",
      "Iteration 2377, loss = 0.01307126\n",
      "Iteration 2378, loss = 0.01306480\n",
      "Iteration 2379, loss = 0.01305741\n",
      "Iteration 2380, loss = 0.01304981\n",
      "Iteration 2381, loss = 0.01304231\n",
      "Iteration 2382, loss = 0.01303569\n",
      "Iteration 2383, loss = 0.01302956\n",
      "Iteration 2384, loss = 0.01302213\n",
      "Iteration 2385, loss = 0.01301641\n",
      "Iteration 2386, loss = 0.01300876\n",
      "Iteration 2387, loss = 0.01300336\n",
      "Iteration 2388, loss = 0.01299629\n",
      "Iteration 2389, loss = 0.01299113\n",
      "Iteration 2390, loss = 0.01298197\n",
      "Iteration 2391, loss = 0.01297484\n",
      "Iteration 2392, loss = 0.01296774\n",
      "Iteration 2393, loss = 0.01296036\n",
      "Iteration 2394, loss = 0.01295388\n",
      "Iteration 2395, loss = 0.01294678\n",
      "Iteration 2396, loss = 0.01293902\n",
      "Iteration 2397, loss = 0.01293207\n",
      "Iteration 2398, loss = 0.01292547\n",
      "Iteration 2399, loss = 0.01291750\n",
      "Iteration 2400, loss = 0.01291103\n",
      "Iteration 2401, loss = 0.01290449\n",
      "Iteration 2402, loss = 0.01289627\n",
      "Iteration 2403, loss = 0.01288966\n",
      "Iteration 2404, loss = 0.01288195\n",
      "Iteration 2405, loss = 0.01287690\n",
      "Iteration 2406, loss = 0.01286844\n",
      "Iteration 2407, loss = 0.01286142\n",
      "Iteration 2408, loss = 0.01285461\n",
      "Iteration 2409, loss = 0.01284792\n",
      "Iteration 2410, loss = 0.01284077\n",
      "Iteration 2411, loss = 0.01283384\n",
      "Iteration 2412, loss = 0.01282759\n",
      "Iteration 2413, loss = 0.01281960\n",
      "Iteration 2414, loss = 0.01281246\n",
      "Iteration 2415, loss = 0.01280450\n",
      "Iteration 2416, loss = 0.01279811\n",
      "Iteration 2417, loss = 0.01278992\n",
      "Iteration 2418, loss = 0.01278409\n",
      "Iteration 2419, loss = 0.01277639\n",
      "Iteration 2420, loss = 0.01276945\n",
      "Iteration 2421, loss = 0.01276289\n",
      "Iteration 2422, loss = 0.01275633\n",
      "Iteration 2423, loss = 0.01274904\n",
      "Iteration 2424, loss = 0.01274286\n",
      "Iteration 2425, loss = 0.01273604\n",
      "Iteration 2426, loss = 0.01272899\n",
      "Iteration 2427, loss = 0.01272272\n",
      "Iteration 2428, loss = 0.01271628\n",
      "Iteration 2429, loss = 0.01271011\n",
      "Iteration 2430, loss = 0.01270376\n",
      "Iteration 2431, loss = 0.01269698\n",
      "Iteration 2432, loss = 0.01269079\n",
      "Iteration 2433, loss = 0.01268616\n",
      "Iteration 2434, loss = 0.01267881\n",
      "Iteration 2435, loss = 0.01267271\n",
      "Iteration 2436, loss = 0.01266758\n",
      "Iteration 2437, loss = 0.01266107\n",
      "Iteration 2438, loss = 0.01265535\n",
      "Iteration 2439, loss = 0.01264888\n",
      "Iteration 2440, loss = 0.01264154\n",
      "Iteration 2441, loss = 0.01263567\n",
      "Iteration 2442, loss = 0.01262846\n",
      "Iteration 2443, loss = 0.01262147\n",
      "Iteration 2444, loss = 0.01261487\n",
      "Iteration 2445, loss = 0.01260750\n",
      "Iteration 2446, loss = 0.01260069\n",
      "Iteration 2447, loss = 0.01259405\n",
      "Iteration 2448, loss = 0.01258638\n",
      "Iteration 2449, loss = 0.01258024\n",
      "Iteration 2450, loss = 0.01257266\n",
      "Iteration 2451, loss = 0.01256704\n",
      "Iteration 2452, loss = 0.01255958\n",
      "Iteration 2453, loss = 0.01255363\n",
      "Iteration 2454, loss = 0.01254737\n",
      "Iteration 2455, loss = 0.01254138\n",
      "Iteration 2456, loss = 0.01253501\n",
      "Iteration 2457, loss = 0.01252863\n",
      "Iteration 2458, loss = 0.01252232\n",
      "Iteration 2459, loss = 0.01251673\n",
      "Iteration 2460, loss = 0.01250950\n",
      "Iteration 2461, loss = 0.01250302\n",
      "Iteration 2462, loss = 0.01249648\n",
      "Iteration 2463, loss = 0.01249038\n",
      "Iteration 2464, loss = 0.01248360\n",
      "Iteration 2465, loss = 0.01247547\n",
      "Iteration 2466, loss = 0.01246992\n",
      "Iteration 2467, loss = 0.01246160\n",
      "Iteration 2468, loss = 0.01245569\n",
      "Iteration 2469, loss = 0.01244876\n",
      "Iteration 2470, loss = 0.01244193\n",
      "Iteration 2471, loss = 0.01243579\n",
      "Iteration 2472, loss = 0.01242847\n",
      "Iteration 2473, loss = 0.01242288\n",
      "Iteration 2474, loss = 0.01241583\n",
      "Iteration 2475, loss = 0.01240926\n",
      "Iteration 2476, loss = 0.01240270\n",
      "Iteration 2477, loss = 0.01239627\n",
      "Iteration 2478, loss = 0.01239007\n",
      "Iteration 2479, loss = 0.01238361\n",
      "Iteration 2480, loss = 0.01237709\n",
      "Iteration 2481, loss = 0.01237118\n",
      "Iteration 2482, loss = 0.01236498\n",
      "Iteration 2483, loss = 0.01235908\n",
      "Iteration 2484, loss = 0.01235329\n",
      "Iteration 2485, loss = 0.01234752\n",
      "Iteration 2486, loss = 0.01234167\n",
      "Iteration 2487, loss = 0.01233626\n",
      "Iteration 2488, loss = 0.01233042\n",
      "Iteration 2489, loss = 0.01232463\n",
      "Iteration 2490, loss = 0.01231946\n",
      "Iteration 2491, loss = 0.01231425\n",
      "Iteration 2492, loss = 0.01230848\n",
      "Iteration 2493, loss = 0.01230386\n",
      "Iteration 2494, loss = 0.01229774\n",
      "Iteration 2495, loss = 0.01229205\n",
      "Iteration 2496, loss = 0.01228597\n",
      "Iteration 2497, loss = 0.01227975\n",
      "Iteration 2498, loss = 0.01227533\n",
      "Iteration 2499, loss = 0.01226931\n",
      "Iteration 2500, loss = 0.01226444\n",
      "Iteration 2501, loss = 0.01225806\n",
      "Iteration 2502, loss = 0.01225193\n",
      "Iteration 2503, loss = 0.01224565\n",
      "Iteration 2504, loss = 0.01224045\n",
      "Iteration 2505, loss = 0.01223333\n",
      "Iteration 2506, loss = 0.01222712\n",
      "Iteration 2507, loss = 0.01222078\n",
      "Iteration 2508, loss = 0.01221374\n",
      "Iteration 2509, loss = 0.01220722\n",
      "Iteration 2510, loss = 0.01220089\n",
      "Iteration 2511, loss = 0.01219466\n",
      "Iteration 2512, loss = 0.01218858\n",
      "Iteration 2513, loss = 0.01218288\n",
      "Iteration 2514, loss = 0.01217710\n",
      "Iteration 2515, loss = 0.01217159\n",
      "Iteration 2516, loss = 0.01216597\n",
      "Iteration 2517, loss = 0.01216047\n",
      "Iteration 2518, loss = 0.01215631\n",
      "Iteration 2519, loss = 0.01214913\n",
      "Iteration 2520, loss = 0.01214357\n",
      "Iteration 2521, loss = 0.01213705\n",
      "Iteration 2522, loss = 0.01213109\n",
      "Iteration 2523, loss = 0.01212542\n",
      "Iteration 2524, loss = 0.01211937\n",
      "Iteration 2525, loss = 0.01211303\n",
      "Iteration 2526, loss = 0.01210655\n",
      "Iteration 2527, loss = 0.01210004\n",
      "Iteration 2528, loss = 0.01209442\n",
      "Iteration 2529, loss = 0.01208808\n",
      "Iteration 2530, loss = 0.01208391\n",
      "Iteration 2531, loss = 0.01207643\n",
      "Iteration 2532, loss = 0.01207023\n",
      "Iteration 2533, loss = 0.01206463\n",
      "Iteration 2534, loss = 0.01205884\n",
      "Iteration 2535, loss = 0.01205248\n",
      "Iteration 2536, loss = 0.01204699\n",
      "Iteration 2537, loss = 0.01203967\n",
      "Iteration 2538, loss = 0.01203496\n",
      "Iteration 2539, loss = 0.01202715\n",
      "Iteration 2540, loss = 0.01202104\n",
      "Iteration 2541, loss = 0.01201373\n",
      "Iteration 2542, loss = 0.01200892\n",
      "Iteration 2543, loss = 0.01200122\n",
      "Iteration 2544, loss = 0.01199517\n",
      "Iteration 2545, loss = 0.01198945\n",
      "Iteration 2546, loss = 0.01198251\n",
      "Iteration 2547, loss = 0.01197519\n",
      "Iteration 2548, loss = 0.01196873\n",
      "Iteration 2549, loss = 0.01196110\n",
      "Iteration 2550, loss = 0.01195451\n",
      "Iteration 2551, loss = 0.01194769\n",
      "Iteration 2552, loss = 0.01194042\n",
      "Iteration 2553, loss = 0.01193434\n",
      "Iteration 2554, loss = 0.01192774\n",
      "Iteration 2555, loss = 0.01192154\n",
      "Iteration 2556, loss = 0.01191501\n",
      "Iteration 2557, loss = 0.01190890\n",
      "Iteration 2558, loss = 0.01190409\n",
      "Iteration 2559, loss = 0.01189690\n",
      "Iteration 2560, loss = 0.01189178\n",
      "Iteration 2561, loss = 0.01188635\n",
      "Iteration 2562, loss = 0.01187964\n",
      "Iteration 2563, loss = 0.01187322\n",
      "Iteration 2564, loss = 0.01186683\n",
      "Iteration 2565, loss = 0.01186012\n",
      "Iteration 2566, loss = 0.01185426\n",
      "Iteration 2567, loss = 0.01184725\n",
      "Iteration 2568, loss = 0.01184089\n",
      "Iteration 2569, loss = 0.01183387\n",
      "Iteration 2570, loss = 0.01182760\n",
      "Iteration 2571, loss = 0.01182230\n",
      "Iteration 2572, loss = 0.01181470\n",
      "Iteration 2573, loss = 0.01180890\n",
      "Iteration 2574, loss = 0.01180305\n",
      "Iteration 2575, loss = 0.01179642\n",
      "Iteration 2576, loss = 0.01179151\n",
      "Iteration 2577, loss = 0.01178418\n",
      "Iteration 2578, loss = 0.01177845\n",
      "Iteration 2579, loss = 0.01177091\n",
      "Iteration 2580, loss = 0.01176577\n",
      "Iteration 2581, loss = 0.01175914\n",
      "Iteration 2582, loss = 0.01175236\n",
      "Iteration 2583, loss = 0.01174701\n",
      "Iteration 2584, loss = 0.01174073\n",
      "Iteration 2585, loss = 0.01173401\n",
      "Iteration 2586, loss = 0.01172773\n",
      "Iteration 2587, loss = 0.01172266\n",
      "Iteration 2588, loss = 0.01171586\n",
      "Iteration 2589, loss = 0.01170987\n",
      "Iteration 2590, loss = 0.01170401\n",
      "Iteration 2591, loss = 0.01169820\n",
      "Iteration 2592, loss = 0.01169229\n",
      "Iteration 2593, loss = 0.01168754\n",
      "Iteration 2594, loss = 0.01168158\n",
      "Iteration 2595, loss = 0.01167623\n",
      "Iteration 2596, loss = 0.01167222\n",
      "Iteration 2597, loss = 0.01166570\n",
      "Iteration 2598, loss = 0.01166050\n",
      "Iteration 2599, loss = 0.01165498\n",
      "Iteration 2600, loss = 0.01164982\n",
      "Iteration 2601, loss = 0.01164388\n",
      "Iteration 2602, loss = 0.01163851\n",
      "Iteration 2603, loss = 0.01163137\n",
      "Iteration 2604, loss = 0.01162620\n",
      "Iteration 2605, loss = 0.01162061\n",
      "Iteration 2606, loss = 0.01161446\n",
      "Iteration 2607, loss = 0.01160944\n",
      "Iteration 2608, loss = 0.01160430\n",
      "Iteration 2609, loss = 0.01159802\n",
      "Iteration 2610, loss = 0.01159154\n",
      "Iteration 2611, loss = 0.01158608\n",
      "Iteration 2612, loss = 0.01158072\n",
      "Iteration 2613, loss = 0.01157501\n",
      "Iteration 2614, loss = 0.01156888\n",
      "Iteration 2615, loss = 0.01156278\n",
      "Iteration 2616, loss = 0.01155812\n",
      "Iteration 2617, loss = 0.01155248\n",
      "Iteration 2618, loss = 0.01154744\n",
      "Iteration 2619, loss = 0.01154170\n",
      "Iteration 2620, loss = 0.01153637\n",
      "Iteration 2621, loss = 0.01153191\n",
      "Iteration 2622, loss = 0.01152682\n",
      "Iteration 2623, loss = 0.01152281\n",
      "Iteration 2624, loss = 0.01151860\n",
      "Iteration 2625, loss = 0.01151369\n",
      "Iteration 2626, loss = 0.01150893\n",
      "Iteration 2627, loss = 0.01150460\n",
      "Iteration 2628, loss = 0.01149942\n",
      "Iteration 2629, loss = 0.01149484\n",
      "Iteration 2630, loss = 0.01148893\n",
      "Iteration 2631, loss = 0.01148378\n",
      "Iteration 2632, loss = 0.01147795\n",
      "Iteration 2633, loss = 0.01147267\n",
      "Iteration 2634, loss = 0.01146714\n",
      "Iteration 2635, loss = 0.01146162\n",
      "Iteration 2636, loss = 0.01145613\n",
      "Iteration 2637, loss = 0.01144943\n",
      "Iteration 2638, loss = 0.01144440\n",
      "Iteration 2639, loss = 0.01143691\n",
      "Iteration 2640, loss = 0.01143153\n",
      "Iteration 2641, loss = 0.01142641\n",
      "Iteration 2642, loss = 0.01142003\n",
      "Iteration 2643, loss = 0.01141422\n",
      "Iteration 2644, loss = 0.01140878\n",
      "Iteration 2645, loss = 0.01140276\n",
      "Iteration 2646, loss = 0.01139922\n",
      "Iteration 2647, loss = 0.01139297\n",
      "Iteration 2648, loss = 0.01138682\n",
      "Iteration 2649, loss = 0.01138184\n",
      "Iteration 2650, loss = 0.01137682\n",
      "Iteration 2651, loss = 0.01137213\n",
      "Iteration 2652, loss = 0.01136612\n",
      "Iteration 2653, loss = 0.01136129\n",
      "Iteration 2654, loss = 0.01135586\n",
      "Iteration 2655, loss = 0.01135090\n",
      "Iteration 2656, loss = 0.01134551\n",
      "Iteration 2657, loss = 0.01134048\n",
      "Iteration 2658, loss = 0.01133548\n",
      "Iteration 2659, loss = 0.01132936\n",
      "Iteration 2660, loss = 0.01132321\n",
      "Iteration 2661, loss = 0.01131755\n",
      "Iteration 2662, loss = 0.01131193\n",
      "Iteration 2663, loss = 0.01130638\n",
      "Iteration 2664, loss = 0.01130077\n",
      "Iteration 2665, loss = 0.01129587\n",
      "Iteration 2666, loss = 0.01128993\n",
      "Iteration 2667, loss = 0.01128442\n",
      "Iteration 2668, loss = 0.01127985\n",
      "Iteration 2669, loss = 0.01127405\n",
      "Iteration 2670, loss = 0.01126859\n",
      "Iteration 2671, loss = 0.01126387\n",
      "Iteration 2672, loss = 0.01125655\n",
      "Iteration 2673, loss = 0.01125005\n",
      "Iteration 2674, loss = 0.01124395\n",
      "Iteration 2675, loss = 0.01123749\n",
      "Iteration 2676, loss = 0.01123317\n",
      "Iteration 2677, loss = 0.01122535\n",
      "Iteration 2678, loss = 0.01121998\n",
      "Iteration 2679, loss = 0.01121411\n",
      "Iteration 2680, loss = 0.01120775\n",
      "Iteration 2681, loss = 0.01120347\n",
      "Iteration 2682, loss = 0.01119579\n",
      "Iteration 2683, loss = 0.01118980\n",
      "Iteration 2684, loss = 0.01118427\n",
      "Iteration 2685, loss = 0.01117759\n",
      "Iteration 2686, loss = 0.01117184\n",
      "Iteration 2687, loss = 0.01116510\n",
      "Iteration 2688, loss = 0.01116204\n",
      "Iteration 2689, loss = 0.01115455\n",
      "Iteration 2690, loss = 0.01114959\n",
      "Iteration 2691, loss = 0.01114337\n",
      "Iteration 2692, loss = 0.01113782\n",
      "Iteration 2693, loss = 0.01113192\n",
      "Iteration 2694, loss = 0.01112734\n",
      "Iteration 2695, loss = 0.01112151\n",
      "Iteration 2696, loss = 0.01111522\n",
      "Iteration 2697, loss = 0.01110943\n",
      "Iteration 2698, loss = 0.01110304\n",
      "Iteration 2699, loss = 0.01109698\n",
      "Iteration 2700, loss = 0.01109038\n",
      "Iteration 2701, loss = 0.01108743\n",
      "Iteration 2702, loss = 0.01107925\n",
      "Iteration 2703, loss = 0.01107624\n",
      "Iteration 2704, loss = 0.01107128\n",
      "Iteration 2705, loss = 0.01106483\n",
      "Iteration 2706, loss = 0.01105953\n",
      "Iteration 2707, loss = 0.01105409\n",
      "Iteration 2708, loss = 0.01104876\n",
      "Iteration 2709, loss = 0.01104325\n",
      "Iteration 2710, loss = 0.01103775\n",
      "Iteration 2711, loss = 0.01103206\n",
      "Iteration 2712, loss = 0.01102762\n",
      "Iteration 2713, loss = 0.01102200\n",
      "Iteration 2714, loss = 0.01101632\n",
      "Iteration 2715, loss = 0.01101052\n",
      "Iteration 2716, loss = 0.01100602\n",
      "Iteration 2717, loss = 0.01100005\n",
      "Iteration 2718, loss = 0.01099479\n",
      "Iteration 2719, loss = 0.01099016\n",
      "Iteration 2720, loss = 0.01098430\n",
      "Iteration 2721, loss = 0.01097904\n",
      "Iteration 2722, loss = 0.01097382\n",
      "Iteration 2723, loss = 0.01096895\n",
      "Iteration 2724, loss = 0.01096286\n",
      "Iteration 2725, loss = 0.01095757\n",
      "Iteration 2726, loss = 0.01095216\n",
      "Iteration 2727, loss = 0.01094682\n",
      "Iteration 2728, loss = 0.01094162\n",
      "Iteration 2729, loss = 0.01093583\n",
      "Iteration 2730, loss = 0.01093012\n",
      "Iteration 2731, loss = 0.01092483\n",
      "Iteration 2732, loss = 0.01091990\n",
      "Iteration 2733, loss = 0.01091443\n",
      "Iteration 2734, loss = 0.01090830\n",
      "Iteration 2735, loss = 0.01090270\n",
      "Iteration 2736, loss = 0.01089845\n",
      "Iteration 2737, loss = 0.01089250\n",
      "Iteration 2738, loss = 0.01088652\n",
      "Iteration 2739, loss = 0.01088099\n",
      "Iteration 2740, loss = 0.01087642\n",
      "Iteration 2741, loss = 0.01087051\n",
      "Iteration 2742, loss = 0.01086547\n",
      "Iteration 2743, loss = 0.01086231\n",
      "Iteration 2744, loss = 0.01085547\n",
      "Iteration 2745, loss = 0.01084992\n",
      "Iteration 2746, loss = 0.01084595\n",
      "Iteration 2747, loss = 0.01083901\n",
      "Iteration 2748, loss = 0.01083257\n",
      "Iteration 2749, loss = 0.01082679\n",
      "Iteration 2750, loss = 0.01082193\n",
      "Iteration 2751, loss = 0.01081595\n",
      "Iteration 2752, loss = 0.01081013\n",
      "Iteration 2753, loss = 0.01080490\n",
      "Iteration 2754, loss = 0.01079954\n",
      "Iteration 2755, loss = 0.01079453\n",
      "Iteration 2756, loss = 0.01078831\n",
      "Iteration 2757, loss = 0.01078355\n",
      "Iteration 2758, loss = 0.01077744\n",
      "Iteration 2759, loss = 0.01077195\n",
      "Iteration 2760, loss = 0.01076664\n",
      "Iteration 2761, loss = 0.01076146\n",
      "Iteration 2762, loss = 0.01075551\n",
      "Iteration 2763, loss = 0.01074994\n",
      "Iteration 2764, loss = 0.01074497\n",
      "Iteration 2765, loss = 0.01073927\n",
      "Iteration 2766, loss = 0.01073399\n",
      "Iteration 2767, loss = 0.01073025\n",
      "Iteration 2768, loss = 0.01072381\n",
      "Iteration 2769, loss = 0.01071894\n",
      "Iteration 2770, loss = 0.01071464\n",
      "Iteration 2771, loss = 0.01070909\n",
      "Iteration 2772, loss = 0.01070477\n",
      "Iteration 2773, loss = 0.01069864\n",
      "Iteration 2774, loss = 0.01069396\n",
      "Iteration 2775, loss = 0.01068885\n",
      "Iteration 2776, loss = 0.01068352\n",
      "Iteration 2777, loss = 0.01067896\n",
      "Iteration 2778, loss = 0.01067363\n",
      "Iteration 2779, loss = 0.01066828\n",
      "Iteration 2780, loss = 0.01066296\n",
      "Iteration 2781, loss = 0.01065992\n",
      "Iteration 2782, loss = 0.01065342\n",
      "Iteration 2783, loss = 0.01064663\n",
      "Iteration 2784, loss = 0.01064223\n",
      "Iteration 2785, loss = 0.01063691\n",
      "Iteration 2786, loss = 0.01063199\n",
      "Iteration 2787, loss = 0.01062605\n",
      "Iteration 2788, loss = 0.01062074\n",
      "Iteration 2789, loss = 0.01061529\n",
      "Iteration 2790, loss = 0.01061188\n",
      "Iteration 2791, loss = 0.01060550\n",
      "Iteration 2792, loss = 0.01060050\n",
      "Iteration 2793, loss = 0.01059576\n",
      "Iteration 2794, loss = 0.01059044\n",
      "Iteration 2795, loss = 0.01058579\n",
      "Iteration 2796, loss = 0.01058073\n",
      "Iteration 2797, loss = 0.01057558\n",
      "Iteration 2798, loss = 0.01057032\n",
      "Iteration 2799, loss = 0.01056588\n",
      "Iteration 2800, loss = 0.01055981\n",
      "Iteration 2801, loss = 0.01055500\n",
      "Iteration 2802, loss = 0.01054966\n",
      "Iteration 2803, loss = 0.01054429\n",
      "Iteration 2804, loss = 0.01054014\n",
      "Iteration 2805, loss = 0.01053499\n",
      "Iteration 2806, loss = 0.01052939\n",
      "Iteration 2807, loss = 0.01052428\n",
      "Iteration 2808, loss = 0.01051924\n",
      "Iteration 2809, loss = 0.01051422\n",
      "Iteration 2810, loss = 0.01050956\n",
      "Iteration 2811, loss = 0.01050461\n",
      "Iteration 2812, loss = 0.01050020\n",
      "Iteration 2813, loss = 0.01049535\n",
      "Iteration 2814, loss = 0.01049102\n",
      "Iteration 2815, loss = 0.01048559\n",
      "Iteration 2816, loss = 0.01048077\n",
      "Iteration 2817, loss = 0.01047487\n",
      "Iteration 2818, loss = 0.01047024\n",
      "Iteration 2819, loss = 0.01046478\n",
      "Iteration 2820, loss = 0.01045934\n",
      "Iteration 2821, loss = 0.01045477\n",
      "Iteration 2822, loss = 0.01044935\n",
      "Iteration 2823, loss = 0.01044426\n",
      "Iteration 2824, loss = 0.01043888\n",
      "Iteration 2825, loss = 0.01043478\n",
      "Iteration 2826, loss = 0.01042865\n",
      "Iteration 2827, loss = 0.01042458\n",
      "Iteration 2828, loss = 0.01041894\n",
      "Iteration 2829, loss = 0.01041461\n",
      "Iteration 2830, loss = 0.01040941\n",
      "Iteration 2831, loss = 0.01040513\n",
      "Iteration 2832, loss = 0.01039923\n",
      "Iteration 2833, loss = 0.01039430\n",
      "Iteration 2834, loss = 0.01038928\n",
      "Iteration 2835, loss = 0.01038438\n",
      "Iteration 2836, loss = 0.01038057\n",
      "Iteration 2837, loss = 0.01037456\n",
      "Iteration 2838, loss = 0.01036990\n",
      "Iteration 2839, loss = 0.01036488\n",
      "Iteration 2840, loss = 0.01035965\n",
      "Iteration 2841, loss = 0.01035455\n",
      "Iteration 2842, loss = 0.01034944\n",
      "Iteration 2843, loss = 0.01034407\n",
      "Iteration 2844, loss = 0.01033784\n",
      "Iteration 2845, loss = 0.01033291\n",
      "Iteration 2846, loss = 0.01032712\n",
      "Iteration 2847, loss = 0.01032172\n",
      "Iteration 2848, loss = 0.01031570\n",
      "Iteration 2849, loss = 0.01031142\n",
      "Iteration 2850, loss = 0.01030676\n",
      "Iteration 2851, loss = 0.01030053\n",
      "Iteration 2852, loss = 0.01029527\n",
      "Iteration 2853, loss = 0.01029030\n",
      "Iteration 2854, loss = 0.01028548\n",
      "Iteration 2855, loss = 0.01028144\n",
      "Iteration 2856, loss = 0.01027507\n",
      "Iteration 2857, loss = 0.01026972\n",
      "Iteration 2858, loss = 0.01026552\n",
      "Iteration 2859, loss = 0.01026005\n",
      "Iteration 2860, loss = 0.01025462\n",
      "Iteration 2861, loss = 0.01024934\n",
      "Iteration 2862, loss = 0.01024415\n",
      "Iteration 2863, loss = 0.01023922\n",
      "Iteration 2864, loss = 0.01023395\n",
      "Iteration 2865, loss = 0.01022867\n",
      "Iteration 2866, loss = 0.01022320\n",
      "Iteration 2867, loss = 0.01021834\n",
      "Iteration 2868, loss = 0.01021339\n",
      "Iteration 2869, loss = 0.01020772\n",
      "Iteration 2870, loss = 0.01020252\n",
      "Iteration 2871, loss = 0.01019768\n",
      "Iteration 2872, loss = 0.01019239\n",
      "Iteration 2873, loss = 0.01018845\n",
      "Iteration 2874, loss = 0.01018275\n",
      "Iteration 2875, loss = 0.01017806\n",
      "Iteration 2876, loss = 0.01017352\n",
      "Iteration 2877, loss = 0.01016947\n",
      "Iteration 2878, loss = 0.01016415\n",
      "Iteration 2879, loss = 0.01015966\n",
      "Iteration 2880, loss = 0.01015598\n",
      "Iteration 2881, loss = 0.01015003\n",
      "Iteration 2882, loss = 0.01014528\n",
      "Iteration 2883, loss = 0.01014074\n",
      "Iteration 2884, loss = 0.01013591\n",
      "Iteration 2885, loss = 0.01013096\n",
      "Iteration 2886, loss = 0.01012644\n",
      "Iteration 2887, loss = 0.01012135\n",
      "Iteration 2888, loss = 0.01011689\n",
      "Iteration 2889, loss = 0.01011192\n",
      "Iteration 2890, loss = 0.01010748\n",
      "Iteration 2891, loss = 0.01010250\n",
      "Iteration 2892, loss = 0.01009871\n",
      "Iteration 2893, loss = 0.01009268\n",
      "Iteration 2894, loss = 0.01008755\n",
      "Iteration 2895, loss = 0.01008297\n",
      "Iteration 2896, loss = 0.01007751\n",
      "Iteration 2897, loss = 0.01007285\n",
      "Iteration 2898, loss = 0.01006762\n",
      "Iteration 2899, loss = 0.01006301\n",
      "Iteration 2900, loss = 0.01005756\n",
      "Iteration 2901, loss = 0.01005262\n",
      "Iteration 2902, loss = 0.01004756\n",
      "Iteration 2903, loss = 0.01004253\n",
      "Iteration 2904, loss = 0.01003958\n",
      "Iteration 2905, loss = 0.01003363\n",
      "Iteration 2906, loss = 0.01002841\n",
      "Iteration 2907, loss = 0.01002360\n",
      "Iteration 2908, loss = 0.01001921\n",
      "Iteration 2909, loss = 0.01001425\n",
      "Iteration 2910, loss = 0.01000939\n",
      "Iteration 2911, loss = 0.01000494\n",
      "Iteration 2912, loss = 0.01000015\n",
      "Iteration 2913, loss = 0.00999477\n",
      "Iteration 2914, loss = 0.00999014\n",
      "Iteration 2915, loss = 0.00998539\n",
      "Iteration 2916, loss = 0.00998064\n",
      "Iteration 2917, loss = 0.00997638\n",
      "Iteration 2918, loss = 0.00997117\n",
      "Iteration 2919, loss = 0.00996640\n",
      "Iteration 2920, loss = 0.00996183\n",
      "Iteration 2921, loss = 0.00995686\n",
      "Iteration 2922, loss = 0.00995221\n",
      "Iteration 2923, loss = 0.00994720\n",
      "Iteration 2924, loss = 0.00994338\n",
      "Iteration 2925, loss = 0.00993833\n",
      "Iteration 2926, loss = 0.00993390\n",
      "Iteration 2927, loss = 0.00992947\n",
      "Iteration 2928, loss = 0.00992455\n",
      "Iteration 2929, loss = 0.00992001\n",
      "Iteration 2930, loss = 0.00991590\n",
      "Iteration 2931, loss = 0.00991139\n",
      "Iteration 2932, loss = 0.00990683\n",
      "Iteration 2933, loss = 0.00990288\n",
      "Iteration 2934, loss = 0.00989848\n",
      "Iteration 2935, loss = 0.00989311\n",
      "Iteration 2936, loss = 0.00988966\n",
      "Iteration 2937, loss = 0.00988506\n",
      "Iteration 2938, loss = 0.00988117\n",
      "Iteration 2939, loss = 0.00987598\n",
      "Iteration 2940, loss = 0.00987267\n",
      "Iteration 2941, loss = 0.00986677\n",
      "Iteration 2942, loss = 0.00986269\n",
      "Iteration 2943, loss = 0.00985759\n",
      "Iteration 2944, loss = 0.00985299\n",
      "Iteration 2945, loss = 0.00984785\n",
      "Iteration 2946, loss = 0.00984284\n",
      "Iteration 2947, loss = 0.00983854\n",
      "Iteration 2948, loss = 0.00983333\n",
      "Iteration 2949, loss = 0.00982831\n",
      "Iteration 2950, loss = 0.00982347\n",
      "Iteration 2951, loss = 0.00981858\n",
      "Iteration 2952, loss = 0.00981477\n",
      "Iteration 2953, loss = 0.00981011\n",
      "Iteration 2954, loss = 0.00980548\n",
      "Iteration 2955, loss = 0.00980079\n",
      "Iteration 2956, loss = 0.00979631\n",
      "Iteration 2957, loss = 0.00979273\n",
      "Iteration 2958, loss = 0.00978775\n",
      "Iteration 2959, loss = 0.00978341\n",
      "Iteration 2960, loss = 0.00977906\n",
      "Iteration 2961, loss = 0.00977469\n",
      "Iteration 2962, loss = 0.00977085\n",
      "Iteration 2963, loss = 0.00976638\n",
      "Iteration 2964, loss = 0.00976218\n",
      "Iteration 2965, loss = 0.00975768\n",
      "Iteration 2966, loss = 0.00975326\n",
      "Iteration 2967, loss = 0.00974866\n",
      "Iteration 2968, loss = 0.00974400\n",
      "Iteration 2969, loss = 0.00973963\n",
      "Iteration 2970, loss = 0.00973470\n",
      "Iteration 2971, loss = 0.00972959\n",
      "Iteration 2972, loss = 0.00972516\n",
      "Iteration 2973, loss = 0.00972031\n",
      "Iteration 2974, loss = 0.00971569\n",
      "Iteration 2975, loss = 0.00971104\n",
      "Iteration 2976, loss = 0.00970695\n",
      "Iteration 2977, loss = 0.00970187\n",
      "Iteration 2978, loss = 0.00969759\n",
      "Iteration 2979, loss = 0.00969346\n",
      "Iteration 2980, loss = 0.00968900\n",
      "Iteration 2981, loss = 0.00968449\n",
      "Iteration 2982, loss = 0.00968002\n",
      "Iteration 2983, loss = 0.00967546\n",
      "Iteration 2984, loss = 0.00967100\n",
      "Iteration 2985, loss = 0.00966642\n",
      "Iteration 2986, loss = 0.00966206\n",
      "Iteration 2987, loss = 0.00965865\n",
      "Iteration 2988, loss = 0.00965401\n",
      "Iteration 2989, loss = 0.00965042\n",
      "Iteration 2990, loss = 0.00964653\n",
      "Iteration 2991, loss = 0.00964199\n",
      "Iteration 2992, loss = 0.00963845\n",
      "Iteration 2993, loss = 0.00963424\n",
      "Iteration 2994, loss = 0.00963013\n",
      "Iteration 2995, loss = 0.00962612\n",
      "Iteration 2996, loss = 0.00962304\n",
      "Iteration 2997, loss = 0.00961861\n",
      "Iteration 2998, loss = 0.00961540\n",
      "Iteration 2999, loss = 0.00961011\n",
      "Iteration 3000, loss = 0.00960626\n",
      "Iteration 3001, loss = 0.00960226\n",
      "Iteration 3002, loss = 0.00959821\n",
      "Iteration 3003, loss = 0.00959353\n",
      "Iteration 3004, loss = 0.00958925\n",
      "Iteration 3005, loss = 0.00958525\n",
      "Iteration 3006, loss = 0.00958061\n",
      "Iteration 3007, loss = 0.00957799\n",
      "Iteration 3008, loss = 0.00957310\n",
      "Iteration 3009, loss = 0.00957015\n",
      "Iteration 3010, loss = 0.00956649\n",
      "Iteration 3011, loss = 0.00956162\n",
      "Iteration 3012, loss = 0.00955753\n",
      "Iteration 3013, loss = 0.00955317\n",
      "Iteration 3014, loss = 0.00954963\n",
      "Iteration 3015, loss = 0.00954539\n",
      "Iteration 3016, loss = 0.00954112\n",
      "Iteration 3017, loss = 0.00953678\n",
      "Iteration 3018, loss = 0.00953218\n",
      "Iteration 3019, loss = 0.00952705\n",
      "Iteration 3020, loss = 0.00952264\n",
      "Iteration 3021, loss = 0.00951926\n",
      "Iteration 3022, loss = 0.00951314\n",
      "Iteration 3023, loss = 0.00950883\n",
      "Iteration 3024, loss = 0.00950447\n",
      "Iteration 3025, loss = 0.00950006\n",
      "Iteration 3026, loss = 0.00949596\n",
      "Iteration 3027, loss = 0.00949243\n",
      "Iteration 3028, loss = 0.00948879\n",
      "Iteration 3029, loss = 0.00948402\n",
      "Iteration 3030, loss = 0.00948008\n",
      "Iteration 3031, loss = 0.00947601\n",
      "Iteration 3032, loss = 0.00947219\n",
      "Iteration 3033, loss = 0.00946803\n",
      "Iteration 3034, loss = 0.00946395\n",
      "Iteration 3035, loss = 0.00946005\n",
      "Iteration 3036, loss = 0.00945668\n",
      "Iteration 3037, loss = 0.00945189\n",
      "Iteration 3038, loss = 0.00944876\n",
      "Iteration 3039, loss = 0.00944376\n",
      "Iteration 3040, loss = 0.00943996\n",
      "Iteration 3041, loss = 0.00943590\n",
      "Iteration 3042, loss = 0.00943222\n",
      "Iteration 3043, loss = 0.00942816\n",
      "Iteration 3044, loss = 0.00942435\n",
      "Iteration 3045, loss = 0.00942059\n",
      "Iteration 3046, loss = 0.00941625\n",
      "Iteration 3047, loss = 0.00941318\n",
      "Iteration 3048, loss = 0.00940853\n",
      "Iteration 3049, loss = 0.00940491\n",
      "Iteration 3050, loss = 0.00939968\n",
      "Iteration 3051, loss = 0.00939478\n",
      "Iteration 3052, loss = 0.00938988\n",
      "Iteration 3053, loss = 0.00938436\n",
      "Iteration 3054, loss = 0.00938000\n",
      "Iteration 3055, loss = 0.00937670\n",
      "Iteration 3056, loss = 0.00937094\n",
      "Iteration 3057, loss = 0.00936819\n",
      "Iteration 3058, loss = 0.00936233\n",
      "Iteration 3059, loss = 0.00935762\n",
      "Iteration 3060, loss = 0.00935429\n",
      "Iteration 3061, loss = 0.00934950\n",
      "Iteration 3062, loss = 0.00934565\n",
      "Iteration 3063, loss = 0.00934136\n",
      "Iteration 3064, loss = 0.00933744\n",
      "Iteration 3065, loss = 0.00933346\n",
      "Iteration 3066, loss = 0.00932952\n",
      "Iteration 3067, loss = 0.00932495\n",
      "Iteration 3068, loss = 0.00932066\n",
      "Iteration 3069, loss = 0.00931722\n",
      "Iteration 3070, loss = 0.00931247\n",
      "Iteration 3071, loss = 0.00930870\n",
      "Iteration 3072, loss = 0.00930437\n",
      "Iteration 3073, loss = 0.00929944\n",
      "Iteration 3074, loss = 0.00929497\n",
      "Iteration 3075, loss = 0.00929048\n",
      "Iteration 3076, loss = 0.00928653\n",
      "Iteration 3077, loss = 0.00928201\n",
      "Iteration 3078, loss = 0.00927779\n",
      "Iteration 3079, loss = 0.00927419\n",
      "Iteration 3080, loss = 0.00926971\n",
      "Iteration 3081, loss = 0.00926593\n",
      "Iteration 3082, loss = 0.00926204\n",
      "Iteration 3083, loss = 0.00925793\n",
      "Iteration 3084, loss = 0.00925414\n",
      "Iteration 3085, loss = 0.00925098\n",
      "Iteration 3086, loss = 0.00924616\n",
      "Iteration 3087, loss = 0.00924238\n",
      "Iteration 3088, loss = 0.00923933\n",
      "Iteration 3089, loss = 0.00923531\n",
      "Iteration 3090, loss = 0.00923157\n",
      "Iteration 3091, loss = 0.00922785\n",
      "Iteration 3092, loss = 0.00922401\n",
      "Iteration 3093, loss = 0.00922078\n",
      "Iteration 3094, loss = 0.00921701\n",
      "Iteration 3095, loss = 0.00921348\n",
      "Iteration 3096, loss = 0.00920961\n",
      "Iteration 3097, loss = 0.00920536\n",
      "Iteration 3098, loss = 0.00920124\n",
      "Iteration 3099, loss = 0.00919700\n",
      "Iteration 3100, loss = 0.00919269\n",
      "Iteration 3101, loss = 0.00918903\n",
      "Iteration 3102, loss = 0.00918540\n",
      "Iteration 3103, loss = 0.00918152\n",
      "Iteration 3104, loss = 0.00917780\n",
      "Iteration 3105, loss = 0.00917366\n",
      "Iteration 3106, loss = 0.00916953\n",
      "Iteration 3107, loss = 0.00916569\n",
      "Iteration 3108, loss = 0.00916190\n",
      "Iteration 3109, loss = 0.00915780\n",
      "Iteration 3110, loss = 0.00915445\n",
      "Iteration 3111, loss = 0.00915037\n",
      "Iteration 3112, loss = 0.00914614\n",
      "Iteration 3113, loss = 0.00914244\n",
      "Iteration 3114, loss = 0.00913994\n",
      "Iteration 3115, loss = 0.00913496\n",
      "Iteration 3116, loss = 0.00913136\n",
      "Iteration 3117, loss = 0.00912710\n",
      "Iteration 3118, loss = 0.00912293\n",
      "Iteration 3119, loss = 0.00911926\n",
      "Iteration 3120, loss = 0.00911556\n",
      "Iteration 3121, loss = 0.00911187\n",
      "Iteration 3122, loss = 0.00910801\n",
      "Iteration 3123, loss = 0.00910437\n",
      "Iteration 3124, loss = 0.00910100\n",
      "Iteration 3125, loss = 0.00909656\n",
      "Iteration 3126, loss = 0.00909293\n",
      "Iteration 3127, loss = 0.00908905\n",
      "Iteration 3128, loss = 0.00908546\n",
      "Iteration 3129, loss = 0.00908146\n",
      "Iteration 3130, loss = 0.00907768\n",
      "Iteration 3131, loss = 0.00907412\n",
      "Iteration 3132, loss = 0.00906968\n",
      "Iteration 3133, loss = 0.00906621\n",
      "Iteration 3134, loss = 0.00906149\n",
      "Iteration 3135, loss = 0.00905798\n",
      "Iteration 3136, loss = 0.00905358\n",
      "Iteration 3137, loss = 0.00905033\n",
      "Iteration 3138, loss = 0.00904635\n",
      "Iteration 3139, loss = 0.00904259\n",
      "Iteration 3140, loss = 0.00903909\n",
      "Iteration 3141, loss = 0.00903590\n",
      "Iteration 3142, loss = 0.00903227\n",
      "Iteration 3143, loss = 0.00902910\n",
      "Iteration 3144, loss = 0.00902610\n",
      "Iteration 3145, loss = 0.00902234\n",
      "Iteration 3146, loss = 0.00902004\n",
      "Iteration 3147, loss = 0.00901557\n",
      "Iteration 3148, loss = 0.00901167\n",
      "Iteration 3149, loss = 0.00900771\n",
      "Iteration 3150, loss = 0.00900447\n",
      "Iteration 3151, loss = 0.00900048\n",
      "Iteration 3152, loss = 0.00899701\n",
      "Iteration 3153, loss = 0.00899358\n",
      "Iteration 3154, loss = 0.00898985\n",
      "Iteration 3155, loss = 0.00898633\n",
      "Iteration 3156, loss = 0.00898260\n",
      "Iteration 3157, loss = 0.00897841\n",
      "Iteration 3158, loss = 0.00897353\n",
      "Iteration 3159, loss = 0.00896996\n",
      "Iteration 3160, loss = 0.00896516\n",
      "Iteration 3161, loss = 0.00896104\n",
      "Iteration 3162, loss = 0.00895682\n",
      "Iteration 3163, loss = 0.00895269\n",
      "Iteration 3164, loss = 0.00894878\n",
      "Iteration 3165, loss = 0.00894494\n",
      "Iteration 3166, loss = 0.00894085\n",
      "Iteration 3167, loss = 0.00893715\n",
      "Iteration 3168, loss = 0.00893207\n",
      "Iteration 3169, loss = 0.00892789\n",
      "Iteration 3170, loss = 0.00892375\n",
      "Iteration 3171, loss = 0.00892000\n",
      "Iteration 3172, loss = 0.00891578\n",
      "Iteration 3173, loss = 0.00891200\n",
      "Iteration 3174, loss = 0.00890828\n",
      "Iteration 3175, loss = 0.00890428\n",
      "Iteration 3176, loss = 0.00890075\n",
      "Iteration 3177, loss = 0.00889692\n",
      "Iteration 3178, loss = 0.00889368\n",
      "Iteration 3179, loss = 0.00889021\n",
      "Iteration 3180, loss = 0.00888689\n",
      "Iteration 3181, loss = 0.00888299\n",
      "Iteration 3182, loss = 0.00887966\n",
      "Iteration 3183, loss = 0.00887529\n",
      "Iteration 3184, loss = 0.00887297\n",
      "Iteration 3185, loss = 0.00886786\n",
      "Iteration 3186, loss = 0.00886418\n",
      "Iteration 3187, loss = 0.00886021\n",
      "Iteration 3188, loss = 0.00885659\n",
      "Iteration 3189, loss = 0.00885297\n",
      "Iteration 3190, loss = 0.00884920\n",
      "Iteration 3191, loss = 0.00884547\n",
      "Iteration 3192, loss = 0.00884183\n",
      "Iteration 3193, loss = 0.00883739\n",
      "Iteration 3194, loss = 0.00883355\n",
      "Iteration 3195, loss = 0.00882994\n",
      "Iteration 3196, loss = 0.00882587\n",
      "Iteration 3197, loss = 0.00882239\n",
      "Iteration 3198, loss = 0.00881860\n",
      "Iteration 3199, loss = 0.00881503\n",
      "Iteration 3200, loss = 0.00881153\n",
      "Iteration 3201, loss = 0.00880769\n",
      "Iteration 3202, loss = 0.00880388\n",
      "Iteration 3203, loss = 0.00880054\n",
      "Iteration 3204, loss = 0.00879803\n",
      "Iteration 3205, loss = 0.00879364\n",
      "Iteration 3206, loss = 0.00878958\n",
      "Iteration 3207, loss = 0.00878593\n",
      "Iteration 3208, loss = 0.00878175\n",
      "Iteration 3209, loss = 0.00877765\n",
      "Iteration 3210, loss = 0.00877377\n",
      "Iteration 3211, loss = 0.00877008\n",
      "Iteration 3212, loss = 0.00876572\n",
      "Iteration 3213, loss = 0.00876272\n",
      "Iteration 3214, loss = 0.00875791\n",
      "Iteration 3215, loss = 0.00875439\n",
      "Iteration 3216, loss = 0.00875041\n",
      "Iteration 3217, loss = 0.00874682\n",
      "Iteration 3218, loss = 0.00874275\n",
      "Iteration 3219, loss = 0.00873855\n",
      "Iteration 3220, loss = 0.00873480\n",
      "Iteration 3221, loss = 0.00873170\n",
      "Iteration 3222, loss = 0.00872790\n",
      "Iteration 3223, loss = 0.00872478\n",
      "Iteration 3224, loss = 0.00872162\n",
      "Iteration 3225, loss = 0.00871830\n",
      "Iteration 3226, loss = 0.00871471\n",
      "Iteration 3227, loss = 0.00871149\n",
      "Iteration 3228, loss = 0.00870789\n",
      "Iteration 3229, loss = 0.00870502\n",
      "Iteration 3230, loss = 0.00870191\n",
      "Iteration 3231, loss = 0.00869836\n",
      "Iteration 3232, loss = 0.00869468\n",
      "Iteration 3233, loss = 0.00869239\n",
      "Iteration 3234, loss = 0.00868786\n",
      "Iteration 3235, loss = 0.00868472\n",
      "Iteration 3236, loss = 0.00868083\n",
      "Iteration 3237, loss = 0.00867727\n",
      "Iteration 3238, loss = 0.00867415\n",
      "Iteration 3239, loss = 0.00867072\n",
      "Iteration 3240, loss = 0.00866767\n",
      "Iteration 3241, loss = 0.00866465\n",
      "Iteration 3242, loss = 0.00866195\n",
      "Iteration 3243, loss = 0.00865899\n",
      "Iteration 3244, loss = 0.00865570\n",
      "Iteration 3245, loss = 0.00865168\n",
      "Iteration 3246, loss = 0.00864799\n",
      "Iteration 3247, loss = 0.00864390\n",
      "Iteration 3248, loss = 0.00864095\n",
      "Iteration 3249, loss = 0.00863696\n",
      "Iteration 3250, loss = 0.00863281\n",
      "Iteration 3251, loss = 0.00863007\n",
      "Iteration 3252, loss = 0.00862512\n",
      "Iteration 3253, loss = 0.00862045\n",
      "Iteration 3254, loss = 0.00861702\n",
      "Iteration 3255, loss = 0.00861221\n",
      "Iteration 3256, loss = 0.00860852\n",
      "Iteration 3257, loss = 0.00860503\n",
      "Iteration 3258, loss = 0.00860056\n",
      "Iteration 3259, loss = 0.00859718\n",
      "Iteration 3260, loss = 0.00859342\n",
      "Iteration 3261, loss = 0.00859002\n",
      "Iteration 3262, loss = 0.00858621\n",
      "Iteration 3263, loss = 0.00858266\n",
      "Iteration 3264, loss = 0.00857913\n",
      "Iteration 3265, loss = 0.00857546\n",
      "Iteration 3266, loss = 0.00857218\n",
      "Iteration 3267, loss = 0.00856899\n",
      "Iteration 3268, loss = 0.00856545\n",
      "Iteration 3269, loss = 0.00856190\n",
      "Iteration 3270, loss = 0.00855845\n",
      "Iteration 3271, loss = 0.00855568\n",
      "Iteration 3272, loss = 0.00855200\n",
      "Iteration 3273, loss = 0.00854882\n",
      "Iteration 3274, loss = 0.00854538\n",
      "Iteration 3275, loss = 0.00854242\n",
      "Iteration 3276, loss = 0.00853880\n",
      "Iteration 3277, loss = 0.00853565\n",
      "Iteration 3278, loss = 0.00853231\n",
      "Iteration 3279, loss = 0.00852885\n",
      "Iteration 3280, loss = 0.00852532\n",
      "Iteration 3281, loss = 0.00852196\n",
      "Iteration 3282, loss = 0.00851844\n",
      "Iteration 3283, loss = 0.00851476\n",
      "Iteration 3284, loss = 0.00851160\n",
      "Iteration 3285, loss = 0.00850751\n",
      "Iteration 3286, loss = 0.00850466\n",
      "Iteration 3287, loss = 0.00850031\n",
      "Iteration 3288, loss = 0.00849675\n",
      "Iteration 3289, loss = 0.00849321\n",
      "Iteration 3290, loss = 0.00848982\n",
      "Iteration 3291, loss = 0.00848633\n",
      "Iteration 3292, loss = 0.00848303\n",
      "Iteration 3293, loss = 0.00847903\n",
      "Iteration 3294, loss = 0.00847583\n",
      "Iteration 3295, loss = 0.00847171\n",
      "Iteration 3296, loss = 0.00846819\n",
      "Iteration 3297, loss = 0.00846443\n",
      "Iteration 3298, loss = 0.00846063\n",
      "Iteration 3299, loss = 0.00845776\n",
      "Iteration 3300, loss = 0.00845378\n",
      "Iteration 3301, loss = 0.00844899\n",
      "Iteration 3302, loss = 0.00844538\n",
      "Iteration 3303, loss = 0.00844115\n",
      "Iteration 3304, loss = 0.00843780\n",
      "Iteration 3305, loss = 0.00843391\n",
      "Iteration 3306, loss = 0.00842981\n",
      "Iteration 3307, loss = 0.00842645\n",
      "Iteration 3308, loss = 0.00842213\n",
      "Iteration 3309, loss = 0.00841867\n",
      "Iteration 3310, loss = 0.00841477\n",
      "Iteration 3311, loss = 0.00841129\n",
      "Iteration 3312, loss = 0.00840802\n",
      "Iteration 3313, loss = 0.00840427\n",
      "Iteration 3314, loss = 0.00840075\n",
      "Iteration 3315, loss = 0.00839715\n",
      "Iteration 3316, loss = 0.00839361\n",
      "Iteration 3317, loss = 0.00839001\n",
      "Iteration 3318, loss = 0.00838637\n",
      "Iteration 3319, loss = 0.00838312\n",
      "Iteration 3320, loss = 0.00837959\n",
      "Iteration 3321, loss = 0.00837712\n",
      "Iteration 3322, loss = 0.00837567\n",
      "Iteration 3323, loss = 0.00837086\n",
      "Iteration 3324, loss = 0.00836751\n",
      "Iteration 3325, loss = 0.00836431\n",
      "Iteration 3326, loss = 0.00836102\n",
      "Iteration 3327, loss = 0.00835776\n",
      "Iteration 3328, loss = 0.00835457\n",
      "Iteration 3329, loss = 0.00835120\n",
      "Iteration 3330, loss = 0.00834725\n",
      "Iteration 3331, loss = 0.00834407\n",
      "Iteration 3332, loss = 0.00834065\n",
      "Iteration 3333, loss = 0.00833722\n",
      "Iteration 3334, loss = 0.00833411\n",
      "Iteration 3335, loss = 0.00833012\n",
      "Iteration 3336, loss = 0.00832662\n",
      "Iteration 3337, loss = 0.00832301\n",
      "Iteration 3338, loss = 0.00831906\n",
      "Iteration 3339, loss = 0.00831587\n",
      "Iteration 3340, loss = 0.00831193\n",
      "Iteration 3341, loss = 0.00830853\n",
      "Iteration 3342, loss = 0.00830560\n",
      "Iteration 3343, loss = 0.00830214\n",
      "Iteration 3344, loss = 0.00829913\n",
      "Iteration 3345, loss = 0.00829576\n",
      "Iteration 3346, loss = 0.00829226\n",
      "Iteration 3347, loss = 0.00828874\n",
      "Iteration 3348, loss = 0.00828511\n",
      "Iteration 3349, loss = 0.00828185\n",
      "Iteration 3350, loss = 0.00827890\n",
      "Iteration 3351, loss = 0.00827557\n",
      "Iteration 3352, loss = 0.00827187\n",
      "Iteration 3353, loss = 0.00826869\n",
      "Iteration 3354, loss = 0.00826551\n",
      "Iteration 3355, loss = 0.00826163\n",
      "Iteration 3356, loss = 0.00825803\n",
      "Iteration 3357, loss = 0.00825469\n",
      "Iteration 3358, loss = 0.00825108\n",
      "Iteration 3359, loss = 0.00824776\n",
      "Iteration 3360, loss = 0.00824475\n",
      "Iteration 3361, loss = 0.00824125\n",
      "Iteration 3362, loss = 0.00823889\n",
      "Iteration 3363, loss = 0.00823383\n",
      "Iteration 3364, loss = 0.00823015\n",
      "Iteration 3365, loss = 0.00822611\n",
      "Iteration 3366, loss = 0.00822318\n",
      "Iteration 3367, loss = 0.00822071\n",
      "Iteration 3368, loss = 0.00821556\n",
      "Iteration 3369, loss = 0.00821205\n",
      "Iteration 3370, loss = 0.00820889\n",
      "Iteration 3371, loss = 0.00820530\n",
      "Iteration 3372, loss = 0.00820178\n",
      "Iteration 3373, loss = 0.00819886\n",
      "Iteration 3374, loss = 0.00819566\n",
      "Iteration 3375, loss = 0.00819180\n",
      "Iteration 3376, loss = 0.00818798\n",
      "Iteration 3377, loss = 0.00818410\n",
      "Iteration 3378, loss = 0.00818081\n",
      "Iteration 3379, loss = 0.00817773\n",
      "Iteration 3380, loss = 0.00817283\n",
      "Iteration 3381, loss = 0.00816976\n",
      "Iteration 3382, loss = 0.00816631\n",
      "Iteration 3383, loss = 0.00816233\n",
      "Iteration 3384, loss = 0.00815801\n",
      "Iteration 3385, loss = 0.00815529\n",
      "Iteration 3386, loss = 0.00815157\n",
      "Iteration 3387, loss = 0.00814725\n",
      "Iteration 3388, loss = 0.00814400\n",
      "Iteration 3389, loss = 0.00814022\n",
      "Iteration 3390, loss = 0.00813685\n",
      "Iteration 3391, loss = 0.00813332\n",
      "Iteration 3392, loss = 0.00813046\n",
      "Iteration 3393, loss = 0.00812691\n",
      "Iteration 3394, loss = 0.00812290\n",
      "Iteration 3395, loss = 0.00811944\n",
      "Iteration 3396, loss = 0.00811635\n",
      "Iteration 3397, loss = 0.00811286\n",
      "Iteration 3398, loss = 0.00810962\n",
      "Iteration 3399, loss = 0.00810610\n",
      "Iteration 3400, loss = 0.00810349\n",
      "Iteration 3401, loss = 0.00809951\n",
      "Iteration 3402, loss = 0.00809699\n",
      "Iteration 3403, loss = 0.00809268\n",
      "Iteration 3404, loss = 0.00808929\n",
      "Iteration 3405, loss = 0.00808653\n",
      "Iteration 3406, loss = 0.00808291\n",
      "Iteration 3407, loss = 0.00807939\n",
      "Iteration 3408, loss = 0.00807620\n",
      "Iteration 3409, loss = 0.00807279\n",
      "Iteration 3410, loss = 0.00806992\n",
      "Iteration 3411, loss = 0.00806632\n",
      "Iteration 3412, loss = 0.00806307\n",
      "Iteration 3413, loss = 0.00805996\n",
      "Iteration 3414, loss = 0.00805724\n",
      "Iteration 3415, loss = 0.00805400\n",
      "Iteration 3416, loss = 0.00805091\n",
      "Iteration 3417, loss = 0.00804763\n",
      "Iteration 3418, loss = 0.00804433\n",
      "Iteration 3419, loss = 0.00804113\n",
      "Iteration 3420, loss = 0.00803780\n",
      "Iteration 3421, loss = 0.00803492\n",
      "Iteration 3422, loss = 0.00803183\n",
      "Iteration 3423, loss = 0.00802871\n",
      "Iteration 3424, loss = 0.00802550\n",
      "Iteration 3425, loss = 0.00802267\n",
      "Iteration 3426, loss = 0.00801921\n",
      "Iteration 3427, loss = 0.00801644\n",
      "Iteration 3428, loss = 0.00801232\n",
      "Iteration 3429, loss = 0.00800932\n",
      "Iteration 3430, loss = 0.00800555\n",
      "Iteration 3431, loss = 0.00800219\n",
      "Iteration 3432, loss = 0.00799930\n",
      "Iteration 3433, loss = 0.00799606\n",
      "Iteration 3434, loss = 0.00799239\n",
      "Iteration 3435, loss = 0.00798937\n",
      "Iteration 3436, loss = 0.00798631\n",
      "Iteration 3437, loss = 0.00798375\n",
      "Iteration 3438, loss = 0.00797983\n",
      "Iteration 3439, loss = 0.00797662\n",
      "Iteration 3440, loss = 0.00797364\n",
      "Iteration 3441, loss = 0.00797068\n",
      "Iteration 3442, loss = 0.00796768\n",
      "Iteration 3443, loss = 0.00796470\n",
      "Iteration 3444, loss = 0.00796187\n",
      "Iteration 3445, loss = 0.00795876\n",
      "Iteration 3446, loss = 0.00795560\n",
      "Iteration 3447, loss = 0.00795261\n",
      "Iteration 3448, loss = 0.00794941\n",
      "Iteration 3449, loss = 0.00794648\n",
      "Iteration 3450, loss = 0.00794349\n",
      "Iteration 3451, loss = 0.00794184\n",
      "Iteration 3452, loss = 0.00793724\n",
      "Iteration 3453, loss = 0.00793330\n",
      "Iteration 3454, loss = 0.00793128\n",
      "Iteration 3455, loss = 0.00792747\n",
      "Iteration 3456, loss = 0.00792459\n",
      "Iteration 3457, loss = 0.00792093\n",
      "Iteration 3458, loss = 0.00791787\n",
      "Iteration 3459, loss = 0.00791463\n",
      "Iteration 3460, loss = 0.00791152\n",
      "Iteration 3461, loss = 0.00790855\n",
      "Iteration 3462, loss = 0.00790586\n",
      "Iteration 3463, loss = 0.00790274\n",
      "Iteration 3464, loss = 0.00789955\n",
      "Iteration 3465, loss = 0.00789705\n",
      "Iteration 3466, loss = 0.00789345\n",
      "Iteration 3467, loss = 0.00789061\n",
      "Iteration 3468, loss = 0.00788774\n",
      "Iteration 3469, loss = 0.00788510\n",
      "Iteration 3470, loss = 0.00788315\n",
      "Iteration 3471, loss = 0.00787951\n",
      "Iteration 3472, loss = 0.00787605\n",
      "Iteration 3473, loss = 0.00787287\n",
      "Iteration 3474, loss = 0.00786924\n",
      "Iteration 3475, loss = 0.00786590\n",
      "Iteration 3476, loss = 0.00786216\n",
      "Iteration 3477, loss = 0.00785952\n",
      "Iteration 3478, loss = 0.00785625\n",
      "Iteration 3479, loss = 0.00785234\n",
      "Iteration 3480, loss = 0.00784935\n",
      "Iteration 3481, loss = 0.00784594\n",
      "Iteration 3482, loss = 0.00784343\n",
      "Iteration 3483, loss = 0.00784001\n",
      "Iteration 3484, loss = 0.00783722\n",
      "Iteration 3485, loss = 0.00783415\n",
      "Iteration 3486, loss = 0.00783111\n",
      "Iteration 3487, loss = 0.00782843\n",
      "Iteration 3488, loss = 0.00782490\n",
      "Iteration 3489, loss = 0.00782264\n",
      "Iteration 3490, loss = 0.00781882\n",
      "Iteration 3491, loss = 0.00781570\n",
      "Iteration 3492, loss = 0.00781305\n",
      "Iteration 3493, loss = 0.00780932\n",
      "Iteration 3494, loss = 0.00780629\n",
      "Iteration 3495, loss = 0.00780352\n",
      "Iteration 3496, loss = 0.00780004\n",
      "Iteration 3497, loss = 0.00779704\n",
      "Iteration 3498, loss = 0.00779436\n",
      "Iteration 3499, loss = 0.00779108\n",
      "Iteration 3500, loss = 0.00778816\n",
      "Iteration 3501, loss = 0.00778474\n",
      "Iteration 3502, loss = 0.00778175\n",
      "Iteration 3503, loss = 0.00777858\n",
      "Iteration 3504, loss = 0.00777577\n",
      "Iteration 3505, loss = 0.00777260\n",
      "Iteration 3506, loss = 0.00776942\n",
      "Iteration 3507, loss = 0.00776763\n",
      "Iteration 3508, loss = 0.00776370\n",
      "Iteration 3509, loss = 0.00776064\n",
      "Iteration 3510, loss = 0.00775773\n",
      "Iteration 3511, loss = 0.00775407\n",
      "Iteration 3512, loss = 0.00775143\n",
      "Iteration 3513, loss = 0.00774813\n",
      "Iteration 3514, loss = 0.00774558\n",
      "Iteration 3515, loss = 0.00774221\n",
      "Iteration 3516, loss = 0.00773906\n",
      "Iteration 3517, loss = 0.00773600\n",
      "Iteration 3518, loss = 0.00773268\n",
      "Iteration 3519, loss = 0.00772953\n",
      "Iteration 3520, loss = 0.00772653\n",
      "Iteration 3521, loss = 0.00772318\n",
      "Iteration 3522, loss = 0.00772042\n",
      "Iteration 3523, loss = 0.00771704\n",
      "Iteration 3524, loss = 0.00771356\n",
      "Iteration 3525, loss = 0.00771030\n",
      "Iteration 3526, loss = 0.00770824\n",
      "Iteration 3527, loss = 0.00770458\n",
      "Iteration 3528, loss = 0.00770117\n",
      "Iteration 3529, loss = 0.00769771\n",
      "Iteration 3530, loss = 0.00769445\n",
      "Iteration 3531, loss = 0.00769161\n",
      "Iteration 3532, loss = 0.00768732\n",
      "Iteration 3533, loss = 0.00768461\n",
      "Iteration 3534, loss = 0.00768063\n",
      "Iteration 3535, loss = 0.00767748\n",
      "Iteration 3536, loss = 0.00767387\n",
      "Iteration 3537, loss = 0.00767060\n",
      "Iteration 3538, loss = 0.00766739\n",
      "Iteration 3539, loss = 0.00766538\n",
      "Iteration 3540, loss = 0.00766135\n",
      "Iteration 3541, loss = 0.00765858\n",
      "Iteration 3542, loss = 0.00765548\n",
      "Iteration 3543, loss = 0.00765290\n",
      "Iteration 3544, loss = 0.00764972\n",
      "Iteration 3545, loss = 0.00764669\n",
      "Iteration 3546, loss = 0.00764405\n",
      "Iteration 3547, loss = 0.00764105\n",
      "Iteration 3548, loss = 0.00763808\n",
      "Iteration 3549, loss = 0.00763499\n",
      "Iteration 3550, loss = 0.00763213\n",
      "Iteration 3551, loss = 0.00762887\n",
      "Iteration 3552, loss = 0.00762597\n",
      "Iteration 3553, loss = 0.00762286\n",
      "Iteration 3554, loss = 0.00761995\n",
      "Iteration 3555, loss = 0.00761671\n",
      "Iteration 3556, loss = 0.00761435\n",
      "Iteration 3557, loss = 0.00761073\n",
      "Iteration 3558, loss = 0.00760744\n",
      "Iteration 3559, loss = 0.00760480\n",
      "Iteration 3560, loss = 0.00760164\n",
      "Iteration 3561, loss = 0.00759886\n",
      "Iteration 3562, loss = 0.00759549\n",
      "Iteration 3563, loss = 0.00759263\n",
      "Iteration 3564, loss = 0.00759023\n",
      "Iteration 3565, loss = 0.00758717\n",
      "Iteration 3566, loss = 0.00758423\n",
      "Iteration 3567, loss = 0.00758165\n",
      "Iteration 3568, loss = 0.00757861\n",
      "Iteration 3569, loss = 0.00757668\n",
      "Iteration 3570, loss = 0.00757221\n",
      "Iteration 3571, loss = 0.00756976\n",
      "Iteration 3572, loss = 0.00756576\n",
      "Iteration 3573, loss = 0.00756261\n",
      "Iteration 3574, loss = 0.00755985\n",
      "Iteration 3575, loss = 0.00755631\n",
      "Iteration 3576, loss = 0.00755275\n",
      "Iteration 3577, loss = 0.00754935\n",
      "Iteration 3578, loss = 0.00754643\n",
      "Iteration 3579, loss = 0.00754320\n",
      "Iteration 3580, loss = 0.00754041\n",
      "Iteration 3581, loss = 0.00753722\n",
      "Iteration 3582, loss = 0.00753439\n",
      "Iteration 3583, loss = 0.00753148\n",
      "Iteration 3584, loss = 0.00752834\n",
      "Iteration 3585, loss = 0.00752537\n",
      "Iteration 3586, loss = 0.00752242\n",
      "Iteration 3587, loss = 0.00751950\n",
      "Iteration 3588, loss = 0.00751690\n",
      "Iteration 3589, loss = 0.00751397\n",
      "Iteration 3590, loss = 0.00751075\n",
      "Iteration 3591, loss = 0.00750822\n",
      "Iteration 3592, loss = 0.00750515\n",
      "Iteration 3593, loss = 0.00750233\n",
      "Iteration 3594, loss = 0.00749934\n",
      "Iteration 3595, loss = 0.00749621\n",
      "Iteration 3596, loss = 0.00749309\n",
      "Iteration 3597, loss = 0.00749083\n",
      "Iteration 3598, loss = 0.00748738\n",
      "Iteration 3599, loss = 0.00748478\n",
      "Iteration 3600, loss = 0.00748163\n",
      "Iteration 3601, loss = 0.00747883\n",
      "Iteration 3602, loss = 0.00747606\n",
      "Iteration 3603, loss = 0.00747281\n",
      "Iteration 3604, loss = 0.00747088\n",
      "Iteration 3605, loss = 0.00746776\n",
      "Iteration 3606, loss = 0.00746476\n",
      "Iteration 3607, loss = 0.00746216\n",
      "Iteration 3608, loss = 0.00745912\n",
      "Iteration 3609, loss = 0.00745603\n",
      "Iteration 3610, loss = 0.00745329\n",
      "Iteration 3611, loss = 0.00745087\n",
      "Iteration 3612, loss = 0.00744857\n",
      "Iteration 3613, loss = 0.00744581\n",
      "Iteration 3614, loss = 0.00744328\n",
      "Iteration 3615, loss = 0.00744096\n",
      "Iteration 3616, loss = 0.00743853\n",
      "Iteration 3617, loss = 0.00743609\n",
      "Iteration 3618, loss = 0.00743404\n",
      "Iteration 3619, loss = 0.00743112\n",
      "Iteration 3620, loss = 0.00742856\n",
      "Iteration 3621, loss = 0.00742624\n",
      "Iteration 3622, loss = 0.00742352\n",
      "Iteration 3623, loss = 0.00742101\n",
      "Iteration 3624, loss = 0.00741786\n",
      "Iteration 3625, loss = 0.00741556\n",
      "Iteration 3626, loss = 0.00741206\n",
      "Iteration 3627, loss = 0.00740989\n",
      "Iteration 3628, loss = 0.00740696\n",
      "Iteration 3629, loss = 0.00740440\n",
      "Iteration 3630, loss = 0.00740145\n",
      "Iteration 3631, loss = 0.00739865\n",
      "Iteration 3632, loss = 0.00739599\n",
      "Iteration 3633, loss = 0.00739336\n",
      "Iteration 3634, loss = 0.00739063\n",
      "Iteration 3635, loss = 0.00738826\n",
      "Iteration 3636, loss = 0.00738658\n",
      "Iteration 3637, loss = 0.00738335\n",
      "Iteration 3638, loss = 0.00738058\n",
      "Iteration 3639, loss = 0.00737853\n",
      "Iteration 3640, loss = 0.00737500\n",
      "Iteration 3641, loss = 0.00737175\n",
      "Iteration 3642, loss = 0.00736853\n",
      "Iteration 3643, loss = 0.00736546\n",
      "Iteration 3644, loss = 0.00736234\n",
      "Iteration 3645, loss = 0.00735913\n",
      "Iteration 3646, loss = 0.00735652\n",
      "Iteration 3647, loss = 0.00735323\n",
      "Iteration 3648, loss = 0.00735053\n",
      "Iteration 3649, loss = 0.00734791\n",
      "Iteration 3650, loss = 0.00734483\n",
      "Iteration 3651, loss = 0.00734236\n",
      "Iteration 3652, loss = 0.00733892\n",
      "Iteration 3653, loss = 0.00733585\n",
      "Iteration 3654, loss = 0.00733303\n",
      "Iteration 3655, loss = 0.00733009\n",
      "Iteration 3656, loss = 0.00732736\n",
      "Iteration 3657, loss = 0.00732491\n",
      "Iteration 3658, loss = 0.00732175\n",
      "Iteration 3659, loss = 0.00731892\n",
      "Iteration 3660, loss = 0.00731635\n",
      "Iteration 3661, loss = 0.00731325\n",
      "Iteration 3662, loss = 0.00730946\n",
      "Iteration 3663, loss = 0.00730713\n",
      "Iteration 3664, loss = 0.00730377\n",
      "Iteration 3665, loss = 0.00730094\n",
      "Iteration 3666, loss = 0.00729812\n",
      "Iteration 3667, loss = 0.00729511\n",
      "Iteration 3668, loss = 0.00729233\n",
      "Iteration 3669, loss = 0.00728961\n",
      "Iteration 3670, loss = 0.00728723\n",
      "Iteration 3671, loss = 0.00728435\n",
      "Iteration 3672, loss = 0.00728172\n",
      "Iteration 3673, loss = 0.00727950\n",
      "Iteration 3674, loss = 0.00727668\n",
      "Iteration 3675, loss = 0.00727416\n",
      "Iteration 3676, loss = 0.00727132\n",
      "Iteration 3677, loss = 0.00726863\n",
      "Iteration 3678, loss = 0.00726598\n",
      "Iteration 3679, loss = 0.00726365\n",
      "Iteration 3680, loss = 0.00726127\n",
      "Iteration 3681, loss = 0.00725859\n",
      "Iteration 3682, loss = 0.00725640\n",
      "Iteration 3683, loss = 0.00725515\n",
      "Iteration 3684, loss = 0.00725148\n",
      "Iteration 3685, loss = 0.00724864\n",
      "Iteration 3686, loss = 0.00724580\n",
      "Iteration 3687, loss = 0.00724313\n",
      "Iteration 3688, loss = 0.00724042\n",
      "Iteration 3689, loss = 0.00723793\n",
      "Iteration 3690, loss = 0.00723538\n",
      "Iteration 3691, loss = 0.00723281\n",
      "Iteration 3692, loss = 0.00723018\n",
      "Iteration 3693, loss = 0.00722815\n",
      "Iteration 3694, loss = 0.00722580\n",
      "Iteration 3695, loss = 0.00722363\n",
      "Iteration 3696, loss = 0.00722124\n",
      "Iteration 3697, loss = 0.00721876\n",
      "Iteration 3698, loss = 0.00721694\n",
      "Iteration 3699, loss = 0.00721379\n",
      "Iteration 3700, loss = 0.00721100\n",
      "Iteration 3701, loss = 0.00720861\n",
      "Iteration 3702, loss = 0.00720538\n",
      "Iteration 3703, loss = 0.00720235\n",
      "Iteration 3704, loss = 0.00719965\n",
      "Iteration 3705, loss = 0.00719647\n",
      "Iteration 3706, loss = 0.00719371\n",
      "Iteration 3707, loss = 0.00719074\n",
      "Iteration 3708, loss = 0.00718829\n",
      "Iteration 3709, loss = 0.00718548\n",
      "Iteration 3710, loss = 0.00718315\n",
      "Iteration 3711, loss = 0.00718051\n",
      "Iteration 3712, loss = 0.00717766\n",
      "Iteration 3713, loss = 0.00717562\n",
      "Iteration 3714, loss = 0.00717286\n",
      "Iteration 3715, loss = 0.00717057\n",
      "Iteration 3716, loss = 0.00716819\n",
      "Iteration 3717, loss = 0.00716625\n",
      "Iteration 3718, loss = 0.00716373\n",
      "Iteration 3719, loss = 0.00716096\n",
      "Iteration 3720, loss = 0.00715800\n",
      "Iteration 3721, loss = 0.00715504\n",
      "Iteration 3722, loss = 0.00715299\n",
      "Iteration 3723, loss = 0.00714983\n",
      "Iteration 3724, loss = 0.00714706\n",
      "Iteration 3725, loss = 0.00714458\n",
      "Iteration 3726, loss = 0.00714183\n",
      "Iteration 3727, loss = 0.00713940\n",
      "Iteration 3728, loss = 0.00713684\n",
      "Iteration 3729, loss = 0.00713510\n",
      "Iteration 3730, loss = 0.00713166\n",
      "Iteration 3731, loss = 0.00712828\n",
      "Iteration 3732, loss = 0.00712545\n",
      "Iteration 3733, loss = 0.00712244\n",
      "Iteration 3734, loss = 0.00711993\n",
      "Iteration 3735, loss = 0.00711658\n",
      "Iteration 3736, loss = 0.00711404\n",
      "Iteration 3737, loss = 0.00711057\n",
      "Iteration 3738, loss = 0.00710774\n",
      "Iteration 3739, loss = 0.00710418\n",
      "Iteration 3740, loss = 0.00710109\n",
      "Iteration 3741, loss = 0.00709863\n",
      "Iteration 3742, loss = 0.00709508\n",
      "Iteration 3743, loss = 0.00709259\n",
      "Iteration 3744, loss = 0.00708993\n",
      "Iteration 3745, loss = 0.00708660\n",
      "Iteration 3746, loss = 0.00708440\n",
      "Iteration 3747, loss = 0.00708152\n",
      "Iteration 3748, loss = 0.00707889\n",
      "Iteration 3749, loss = 0.00707686\n",
      "Iteration 3750, loss = 0.00707417\n",
      "Iteration 3751, loss = 0.00707219\n",
      "Iteration 3752, loss = 0.00706977\n",
      "Iteration 3753, loss = 0.00706833\n",
      "Iteration 3754, loss = 0.00706489\n",
      "Iteration 3755, loss = 0.00706206\n",
      "Iteration 3756, loss = 0.00705957\n",
      "Iteration 3757, loss = 0.00705649\n",
      "Iteration 3758, loss = 0.00705442\n",
      "Iteration 3759, loss = 0.00705142\n",
      "Iteration 3760, loss = 0.00704814\n",
      "Iteration 3761, loss = 0.00704520\n",
      "Iteration 3762, loss = 0.00704199\n",
      "Iteration 3763, loss = 0.00703947\n",
      "Iteration 3764, loss = 0.00703625\n",
      "Iteration 3765, loss = 0.00703336\n",
      "Iteration 3766, loss = 0.00703071\n",
      "Iteration 3767, loss = 0.00702791\n",
      "Iteration 3768, loss = 0.00702526\n",
      "Iteration 3769, loss = 0.00702257\n",
      "Iteration 3770, loss = 0.00701990\n",
      "Iteration 3771, loss = 0.00701749\n",
      "Iteration 3772, loss = 0.00701495\n",
      "Iteration 3773, loss = 0.00701244\n",
      "Iteration 3774, loss = 0.00700949\n",
      "Iteration 3775, loss = 0.00700693\n",
      "Iteration 3776, loss = 0.00700477\n",
      "Iteration 3777, loss = 0.00700225\n",
      "Iteration 3778, loss = 0.00699907\n",
      "Iteration 3779, loss = 0.00699660\n",
      "Iteration 3780, loss = 0.00699421\n",
      "Iteration 3781, loss = 0.00699139\n",
      "Iteration 3782, loss = 0.00698905\n",
      "Iteration 3783, loss = 0.00698642\n",
      "Iteration 3784, loss = 0.00698397\n",
      "Iteration 3785, loss = 0.00698156\n",
      "Iteration 3786, loss = 0.00697861\n",
      "Iteration 3787, loss = 0.00697643\n",
      "Iteration 3788, loss = 0.00697471\n",
      "Iteration 3789, loss = 0.00697281\n",
      "Iteration 3790, loss = 0.00696952\n",
      "Iteration 3791, loss = 0.00696709\n",
      "Iteration 3792, loss = 0.00696455\n",
      "Iteration 3793, loss = 0.00696224\n",
      "Iteration 3794, loss = 0.00695984\n",
      "Iteration 3795, loss = 0.00695769\n",
      "Iteration 3796, loss = 0.00695553\n",
      "Iteration 3797, loss = 0.00695329\n",
      "Iteration 3798, loss = 0.00695112\n",
      "Iteration 3799, loss = 0.00694888\n",
      "Iteration 3800, loss = 0.00694636\n",
      "Iteration 3801, loss = 0.00694362\n",
      "Iteration 3802, loss = 0.00694139\n",
      "Iteration 3803, loss = 0.00693872\n",
      "Iteration 3804, loss = 0.00693635\n",
      "Iteration 3805, loss = 0.00693359\n",
      "Iteration 3806, loss = 0.00693071\n",
      "Iteration 3807, loss = 0.00692841\n",
      "Iteration 3808, loss = 0.00692657\n",
      "Iteration 3809, loss = 0.00692329\n",
      "Iteration 3810, loss = 0.00692111\n",
      "Iteration 3811, loss = 0.00691834\n",
      "Iteration 3812, loss = 0.00691614\n",
      "Iteration 3813, loss = 0.00691343\n",
      "Iteration 3814, loss = 0.00691078\n",
      "Iteration 3815, loss = 0.00690823\n",
      "Iteration 3816, loss = 0.00690589\n",
      "Iteration 3817, loss = 0.00690385\n",
      "Iteration 3818, loss = 0.00690109\n",
      "Iteration 3819, loss = 0.00689878\n",
      "Iteration 3820, loss = 0.00689637\n",
      "Iteration 3821, loss = 0.00689413\n",
      "Iteration 3822, loss = 0.00689185\n",
      "Iteration 3823, loss = 0.00688979\n",
      "Iteration 3824, loss = 0.00688713\n",
      "Iteration 3825, loss = 0.00688514\n",
      "Iteration 3826, loss = 0.00688310\n",
      "Iteration 3827, loss = 0.00688103\n",
      "Iteration 3828, loss = 0.00687881\n",
      "Iteration 3829, loss = 0.00687680\n",
      "Iteration 3830, loss = 0.00687548\n",
      "Iteration 3831, loss = 0.00687346\n",
      "Iteration 3832, loss = 0.00687166\n",
      "Iteration 3833, loss = 0.00686906\n",
      "Iteration 3834, loss = 0.00686707\n",
      "Iteration 3835, loss = 0.00686450\n",
      "Iteration 3836, loss = 0.00686154\n",
      "Iteration 3837, loss = 0.00685865\n",
      "Iteration 3838, loss = 0.00685567\n",
      "Iteration 3839, loss = 0.00685383\n",
      "Iteration 3840, loss = 0.00685017\n",
      "Iteration 3841, loss = 0.00684770\n",
      "Iteration 3842, loss = 0.00684528\n",
      "Iteration 3843, loss = 0.00684243\n",
      "Iteration 3844, loss = 0.00684027\n",
      "Iteration 3845, loss = 0.00683756\n",
      "Iteration 3846, loss = 0.00683480\n",
      "Iteration 3847, loss = 0.00683236\n",
      "Iteration 3848, loss = 0.00682951\n",
      "Iteration 3849, loss = 0.00682721\n",
      "Iteration 3850, loss = 0.00682453\n",
      "Iteration 3851, loss = 0.00682253\n",
      "Iteration 3852, loss = 0.00681991\n",
      "Iteration 3853, loss = 0.00681739\n",
      "Iteration 3854, loss = 0.00681511\n",
      "Iteration 3855, loss = 0.00681251\n",
      "Iteration 3856, loss = 0.00681059\n",
      "Iteration 3857, loss = 0.00680805\n",
      "Iteration 3858, loss = 0.00680507\n",
      "Iteration 3859, loss = 0.00680312\n",
      "Iteration 3860, loss = 0.00680037\n",
      "Iteration 3861, loss = 0.00679795\n",
      "Iteration 3862, loss = 0.00679598\n",
      "Iteration 3863, loss = 0.00679356\n",
      "Iteration 3864, loss = 0.00679119\n",
      "Iteration 3865, loss = 0.00679004\n",
      "Iteration 3866, loss = 0.00678663\n",
      "Iteration 3867, loss = 0.00678402\n",
      "Iteration 3868, loss = 0.00678177\n",
      "Iteration 3869, loss = 0.00677912\n",
      "Iteration 3870, loss = 0.00677694\n",
      "Iteration 3871, loss = 0.00677499\n",
      "Iteration 3872, loss = 0.00677307\n",
      "Iteration 3873, loss = 0.00677044\n",
      "Iteration 3874, loss = 0.00676810\n",
      "Iteration 3875, loss = 0.00676571\n",
      "Iteration 3876, loss = 0.00676339\n",
      "Iteration 3877, loss = 0.00676074\n",
      "Iteration 3878, loss = 0.00675878\n",
      "Iteration 3879, loss = 0.00675614\n",
      "Iteration 3880, loss = 0.00675389\n",
      "Iteration 3881, loss = 0.00675123\n",
      "Iteration 3882, loss = 0.00674902\n",
      "Iteration 3883, loss = 0.00674636\n",
      "Iteration 3884, loss = 0.00674376\n",
      "Iteration 3885, loss = 0.00674104\n",
      "Iteration 3886, loss = 0.00673868\n",
      "Iteration 3887, loss = 0.00673593\n",
      "Iteration 3888, loss = 0.00673381\n",
      "Iteration 3889, loss = 0.00673131\n",
      "Iteration 3890, loss = 0.00672934\n",
      "Iteration 3891, loss = 0.00672687\n",
      "Iteration 3892, loss = 0.00672458\n",
      "Iteration 3893, loss = 0.00672243\n",
      "Iteration 3894, loss = 0.00672001\n",
      "Iteration 3895, loss = 0.00671774\n",
      "Iteration 3896, loss = 0.00671563\n",
      "Iteration 3897, loss = 0.00671293\n",
      "Iteration 3898, loss = 0.00671014\n",
      "Iteration 3899, loss = 0.00670753\n",
      "Iteration 3900, loss = 0.00670548\n",
      "Iteration 3901, loss = 0.00670264\n",
      "Iteration 3902, loss = 0.00670032\n",
      "Iteration 3903, loss = 0.00669864\n",
      "Iteration 3904, loss = 0.00669606\n",
      "Iteration 3905, loss = 0.00669382\n",
      "Iteration 3906, loss = 0.00669144\n",
      "Iteration 3907, loss = 0.00668942\n",
      "Iteration 3908, loss = 0.00668732\n",
      "Iteration 3909, loss = 0.00668523\n",
      "Iteration 3910, loss = 0.00668293\n",
      "Iteration 3911, loss = 0.00668051\n",
      "Iteration 3912, loss = 0.00667875\n",
      "Iteration 3913, loss = 0.00667588\n",
      "Iteration 3914, loss = 0.00667337\n",
      "Iteration 3915, loss = 0.00667065\n",
      "Iteration 3916, loss = 0.00666837\n",
      "Iteration 3917, loss = 0.00666454\n",
      "Iteration 3918, loss = 0.00666215\n",
      "Iteration 3919, loss = 0.00665914\n",
      "Iteration 3920, loss = 0.00665629\n",
      "Iteration 3921, loss = 0.00665360\n",
      "Iteration 3922, loss = 0.00665249\n",
      "Iteration 3923, loss = 0.00664897\n",
      "Iteration 3924, loss = 0.00664646\n",
      "Iteration 3925, loss = 0.00664345\n",
      "Iteration 3926, loss = 0.00664047\n",
      "Iteration 3927, loss = 0.00663725\n",
      "Iteration 3928, loss = 0.00663476\n",
      "Iteration 3929, loss = 0.00663180\n",
      "Iteration 3930, loss = 0.00662853\n",
      "Iteration 3931, loss = 0.00662523\n",
      "Iteration 3932, loss = 0.00662282\n",
      "Iteration 3933, loss = 0.00662202\n",
      "Iteration 3934, loss = 0.00661881\n",
      "Iteration 3935, loss = 0.00661560\n",
      "Iteration 3936, loss = 0.00661300\n",
      "Iteration 3937, loss = 0.00661045\n",
      "Iteration 3938, loss = 0.00660754\n",
      "Iteration 3939, loss = 0.00660487\n",
      "Iteration 3940, loss = 0.00660303\n",
      "Iteration 3941, loss = 0.00660003\n",
      "Iteration 3942, loss = 0.00659756\n",
      "Iteration 3943, loss = 0.00659453\n",
      "Iteration 3944, loss = 0.00659236\n",
      "Iteration 3945, loss = 0.00659012\n",
      "Iteration 3946, loss = 0.00658742\n",
      "Iteration 3947, loss = 0.00658511\n",
      "Iteration 3948, loss = 0.00658277\n",
      "Iteration 3949, loss = 0.00658039\n",
      "Iteration 3950, loss = 0.00657850\n",
      "Iteration 3951, loss = 0.00657578\n",
      "Iteration 3952, loss = 0.00657359\n",
      "Iteration 3953, loss = 0.00657120\n",
      "Iteration 3954, loss = 0.00656899\n",
      "Iteration 3955, loss = 0.00656660\n",
      "Iteration 3956, loss = 0.00656444\n",
      "Iteration 3957, loss = 0.00656232\n",
      "Iteration 3958, loss = 0.00656003\n",
      "Iteration 3959, loss = 0.00655768\n",
      "Iteration 3960, loss = 0.00655591\n",
      "Iteration 3961, loss = 0.00655352\n",
      "Iteration 3962, loss = 0.00655128\n",
      "Iteration 3963, loss = 0.00654894\n",
      "Iteration 3964, loss = 0.00654633\n",
      "Iteration 3965, loss = 0.00654416\n",
      "Iteration 3966, loss = 0.00654231\n",
      "Iteration 3967, loss = 0.00654018\n",
      "Iteration 3968, loss = 0.00653724\n",
      "Iteration 3969, loss = 0.00653499\n",
      "Iteration 3970, loss = 0.00653245\n",
      "Iteration 3971, loss = 0.00653004\n",
      "Iteration 3972, loss = 0.00652776\n",
      "Iteration 3973, loss = 0.00652509\n",
      "Iteration 3974, loss = 0.00652261\n",
      "Iteration 3975, loss = 0.00652047\n",
      "Iteration 3976, loss = 0.00651880\n",
      "Iteration 3977, loss = 0.00651559\n",
      "Iteration 3978, loss = 0.00651306\n",
      "Iteration 3979, loss = 0.00651125\n",
      "Iteration 3980, loss = 0.00650855\n",
      "Iteration 3981, loss = 0.00650651\n",
      "Iteration 3982, loss = 0.00650418\n",
      "Iteration 3983, loss = 0.00650238\n",
      "Iteration 3984, loss = 0.00649970\n",
      "Iteration 3985, loss = 0.00649727\n",
      "Iteration 3986, loss = 0.00649501\n",
      "Iteration 3987, loss = 0.00649253\n",
      "Iteration 3988, loss = 0.00649014\n",
      "Iteration 3989, loss = 0.00648781\n",
      "Iteration 3990, loss = 0.00648545\n",
      "Iteration 3991, loss = 0.00648285\n",
      "Iteration 3992, loss = 0.00648072\n",
      "Iteration 3993, loss = 0.00647800\n",
      "Iteration 3994, loss = 0.00647537\n",
      "Iteration 3995, loss = 0.00647392\n",
      "Iteration 3996, loss = 0.00647093\n",
      "Iteration 3997, loss = 0.00646865\n",
      "Iteration 3998, loss = 0.00646615\n",
      "Iteration 3999, loss = 0.00646393\n",
      "Iteration 4000, loss = 0.00646251\n",
      "Iteration 4001, loss = 0.00645935\n",
      "Iteration 4002, loss = 0.00645754\n",
      "Iteration 4003, loss = 0.00645493\n",
      "Iteration 4004, loss = 0.00645258\n",
      "Iteration 4005, loss = 0.00645024\n",
      "Iteration 4006, loss = 0.00644792\n",
      "Iteration 4007, loss = 0.00644545\n",
      "Iteration 4008, loss = 0.00644331\n",
      "Iteration 4009, loss = 0.00644039\n",
      "Iteration 4010, loss = 0.00643801\n",
      "Iteration 4011, loss = 0.00643548\n",
      "Iteration 4012, loss = 0.00643294\n",
      "Iteration 4013, loss = 0.00643053\n",
      "Iteration 4014, loss = 0.00642788\n",
      "Iteration 4015, loss = 0.00642561\n",
      "Iteration 4016, loss = 0.00642313\n",
      "Iteration 4017, loss = 0.00642070\n",
      "Iteration 4018, loss = 0.00641846\n",
      "Iteration 4019, loss = 0.00641611\n",
      "Iteration 4020, loss = 0.00641377\n",
      "Iteration 4021, loss = 0.00641160\n",
      "Iteration 4022, loss = 0.00640921\n",
      "Iteration 4023, loss = 0.00640763\n",
      "Iteration 4024, loss = 0.00640506\n",
      "Iteration 4025, loss = 0.00640294\n",
      "Iteration 4026, loss = 0.00640132\n",
      "Iteration 4027, loss = 0.00639884\n",
      "Iteration 4028, loss = 0.00639660\n",
      "Iteration 4029, loss = 0.00639438\n",
      "Iteration 4030, loss = 0.00639225\n",
      "Iteration 4031, loss = 0.00639011\n",
      "Iteration 4032, loss = 0.00638802\n",
      "Iteration 4033, loss = 0.00638618\n",
      "Iteration 4034, loss = 0.00638405\n",
      "Iteration 4035, loss = 0.00638175\n",
      "Iteration 4036, loss = 0.00637927\n",
      "Iteration 4037, loss = 0.00637676\n",
      "Iteration 4038, loss = 0.00637449\n",
      "Iteration 4039, loss = 0.00637216\n",
      "Iteration 4040, loss = 0.00636972\n",
      "Iteration 4041, loss = 0.00636737\n",
      "Iteration 4042, loss = 0.00636563\n",
      "Iteration 4043, loss = 0.00636317\n",
      "Iteration 4044, loss = 0.00636079\n",
      "Iteration 4045, loss = 0.00635828\n",
      "Iteration 4046, loss = 0.00635640\n",
      "Iteration 4047, loss = 0.00635428\n",
      "Iteration 4048, loss = 0.00635228\n",
      "Iteration 4049, loss = 0.00635011\n",
      "Iteration 4050, loss = 0.00634765\n",
      "Iteration 4051, loss = 0.00634553\n",
      "Iteration 4052, loss = 0.00634325\n",
      "Iteration 4053, loss = 0.00634106\n",
      "Iteration 4054, loss = 0.00633898\n",
      "Iteration 4055, loss = 0.00633687\n",
      "Iteration 4056, loss = 0.00633458\n",
      "Iteration 4057, loss = 0.00633254\n",
      "Iteration 4058, loss = 0.00633026\n",
      "Iteration 4059, loss = 0.00632841\n",
      "Iteration 4060, loss = 0.00632586\n",
      "Iteration 4061, loss = 0.00632374\n",
      "Iteration 4062, loss = 0.00632194\n",
      "Iteration 4063, loss = 0.00631952\n",
      "Iteration 4064, loss = 0.00631705\n",
      "Iteration 4065, loss = 0.00631446\n",
      "Iteration 4066, loss = 0.00631191\n",
      "Iteration 4067, loss = 0.00631050\n",
      "Iteration 4068, loss = 0.00630737\n",
      "Iteration 4069, loss = 0.00630527\n",
      "Iteration 4070, loss = 0.00630329\n",
      "Iteration 4071, loss = 0.00630110\n",
      "Iteration 4072, loss = 0.00629891\n",
      "Iteration 4073, loss = 0.00629658\n",
      "Iteration 4074, loss = 0.00629454\n",
      "Iteration 4075, loss = 0.00629214\n",
      "Iteration 4076, loss = 0.00628988\n",
      "Iteration 4077, loss = 0.00628788\n",
      "Iteration 4078, loss = 0.00628520\n",
      "Iteration 4079, loss = 0.00628316\n",
      "Iteration 4080, loss = 0.00628094\n",
      "Iteration 4081, loss = 0.00627866\n",
      "Iteration 4082, loss = 0.00627655\n",
      "Iteration 4083, loss = 0.00627464\n",
      "Iteration 4084, loss = 0.00627253\n",
      "Iteration 4085, loss = 0.00627033\n",
      "Iteration 4086, loss = 0.00626850\n",
      "Iteration 4087, loss = 0.00626613\n",
      "Iteration 4088, loss = 0.00626360\n",
      "Iteration 4089, loss = 0.00626156\n",
      "Iteration 4090, loss = 0.00625933\n",
      "Iteration 4091, loss = 0.00625720\n",
      "Iteration 4092, loss = 0.00625491\n",
      "Iteration 4093, loss = 0.00625280\n",
      "Iteration 4094, loss = 0.00625093\n",
      "Iteration 4095, loss = 0.00624874\n",
      "Iteration 4096, loss = 0.00624713\n",
      "Iteration 4097, loss = 0.00624582\n",
      "Iteration 4098, loss = 0.00624324\n",
      "Iteration 4099, loss = 0.00624124\n",
      "Iteration 4100, loss = 0.00623983\n",
      "Iteration 4101, loss = 0.00623751\n",
      "Iteration 4102, loss = 0.00623551\n",
      "Iteration 4103, loss = 0.00623343\n",
      "Iteration 4104, loss = 0.00623157\n",
      "Iteration 4105, loss = 0.00622980\n",
      "Iteration 4106, loss = 0.00622782\n",
      "Iteration 4107, loss = 0.00622608\n",
      "Iteration 4108, loss = 0.00622415\n",
      "Iteration 4109, loss = 0.00622222\n",
      "Iteration 4110, loss = 0.00622041\n",
      "Iteration 4111, loss = 0.00621858\n",
      "Iteration 4112, loss = 0.00621667\n",
      "Iteration 4113, loss = 0.00621455\n",
      "Iteration 4114, loss = 0.00621277\n",
      "Iteration 4115, loss = 0.00621119\n",
      "Iteration 4116, loss = 0.00620864\n",
      "Iteration 4117, loss = 0.00620651\n",
      "Iteration 4118, loss = 0.00620438\n",
      "Iteration 4119, loss = 0.00620220\n",
      "Iteration 4120, loss = 0.00619995\n",
      "Iteration 4121, loss = 0.00619787\n",
      "Iteration 4122, loss = 0.00619580\n",
      "Iteration 4123, loss = 0.00619359\n",
      "Iteration 4124, loss = 0.00619139\n",
      "Iteration 4125, loss = 0.00618951\n",
      "Iteration 4126, loss = 0.00618720\n",
      "Iteration 4127, loss = 0.00618518\n",
      "Iteration 4128, loss = 0.00618319\n",
      "Iteration 4129, loss = 0.00618132\n",
      "Iteration 4130, loss = 0.00617918\n",
      "Iteration 4131, loss = 0.00617716\n",
      "Iteration 4132, loss = 0.00617530\n",
      "Iteration 4133, loss = 0.00617346\n",
      "Iteration 4134, loss = 0.00617141\n",
      "Iteration 4135, loss = 0.00616921\n",
      "Iteration 4136, loss = 0.00616717\n",
      "Iteration 4137, loss = 0.00616516\n",
      "Iteration 4138, loss = 0.00616307\n",
      "Iteration 4139, loss = 0.00616143\n",
      "Iteration 4140, loss = 0.00615935\n",
      "Iteration 4141, loss = 0.00615784\n",
      "Iteration 4142, loss = 0.00615544\n",
      "Iteration 4143, loss = 0.00615401\n",
      "Iteration 4144, loss = 0.00615256\n",
      "Iteration 4145, loss = 0.00615029\n",
      "Iteration 4146, loss = 0.00614794\n",
      "Iteration 4147, loss = 0.00614546\n",
      "Iteration 4148, loss = 0.00614325\n",
      "Iteration 4149, loss = 0.00614114\n",
      "Iteration 4150, loss = 0.00613755\n",
      "Iteration 4151, loss = 0.00613509\n",
      "Iteration 4152, loss = 0.00613222\n",
      "Iteration 4153, loss = 0.00612899\n",
      "Iteration 4154, loss = 0.00612716\n",
      "Iteration 4155, loss = 0.00612393\n",
      "Iteration 4156, loss = 0.00612181\n",
      "Iteration 4157, loss = 0.00611942\n",
      "Iteration 4158, loss = 0.00611662\n",
      "Iteration 4159, loss = 0.00611428\n",
      "Iteration 4160, loss = 0.00611161\n",
      "Iteration 4161, loss = 0.00610978\n",
      "Iteration 4162, loss = 0.00610665\n",
      "Iteration 4163, loss = 0.00610411\n",
      "Iteration 4164, loss = 0.00610207\n",
      "Iteration 4165, loss = 0.00609968\n",
      "Iteration 4166, loss = 0.00609733\n",
      "Iteration 4167, loss = 0.00609538\n",
      "Iteration 4168, loss = 0.00609307\n",
      "Iteration 4169, loss = 0.00609050\n",
      "Iteration 4170, loss = 0.00608798\n",
      "Iteration 4171, loss = 0.00608636\n",
      "Iteration 4172, loss = 0.00608362\n",
      "Iteration 4173, loss = 0.00608182\n",
      "Iteration 4174, loss = 0.00607932\n",
      "Iteration 4175, loss = 0.00607709\n",
      "Iteration 4176, loss = 0.00607492\n",
      "Iteration 4177, loss = 0.00607266\n",
      "Iteration 4178, loss = 0.00607061\n",
      "Iteration 4179, loss = 0.00606826\n",
      "Iteration 4180, loss = 0.00606652\n",
      "Iteration 4181, loss = 0.00606406\n",
      "Iteration 4182, loss = 0.00606185\n",
      "Iteration 4183, loss = 0.00605958\n",
      "Iteration 4184, loss = 0.00605757\n",
      "Iteration 4185, loss = 0.00605604\n",
      "Iteration 4186, loss = 0.00605337\n",
      "Iteration 4187, loss = 0.00605098\n",
      "Iteration 4188, loss = 0.00604932\n",
      "Iteration 4189, loss = 0.00604729\n",
      "Iteration 4190, loss = 0.00604515\n",
      "Iteration 4191, loss = 0.00604324\n",
      "Iteration 4192, loss = 0.00604126\n",
      "Iteration 4193, loss = 0.00603921\n",
      "Iteration 4194, loss = 0.00603692\n",
      "Iteration 4195, loss = 0.00603504\n",
      "Iteration 4196, loss = 0.00603288\n",
      "Iteration 4197, loss = 0.00603061\n",
      "Iteration 4198, loss = 0.00602887\n",
      "Iteration 4199, loss = 0.00602649\n",
      "Iteration 4200, loss = 0.00602401\n",
      "Iteration 4201, loss = 0.00602229\n",
      "Iteration 4202, loss = 0.00601987\n",
      "Iteration 4203, loss = 0.00601798\n",
      "Iteration 4204, loss = 0.00601585\n",
      "Iteration 4205, loss = 0.00601370\n",
      "Iteration 4206, loss = 0.00601171\n",
      "Iteration 4207, loss = 0.00601000\n",
      "Iteration 4208, loss = 0.00600749\n",
      "Iteration 4209, loss = 0.00600539\n",
      "Iteration 4210, loss = 0.00600319\n",
      "Iteration 4211, loss = 0.00600125\n",
      "Iteration 4212, loss = 0.00599906\n",
      "Iteration 4213, loss = 0.00599717\n",
      "Iteration 4214, loss = 0.00599498\n",
      "Iteration 4215, loss = 0.00599325\n",
      "Iteration 4216, loss = 0.00599105\n",
      "Iteration 4217, loss = 0.00598894\n",
      "Iteration 4218, loss = 0.00598717\n",
      "Iteration 4219, loss = 0.00598538\n",
      "Iteration 4220, loss = 0.00598300\n",
      "Iteration 4221, loss = 0.00598092\n",
      "Iteration 4222, loss = 0.00597889\n",
      "Iteration 4223, loss = 0.00597753\n",
      "Iteration 4224, loss = 0.00597523\n",
      "Iteration 4225, loss = 0.00597312\n",
      "Iteration 4226, loss = 0.00597111\n",
      "Iteration 4227, loss = 0.00596912\n",
      "Iteration 4228, loss = 0.00596712\n",
      "Iteration 4229, loss = 0.00596517\n",
      "Iteration 4230, loss = 0.00596315\n",
      "Iteration 4231, loss = 0.00596099\n",
      "Iteration 4232, loss = 0.00595897\n",
      "Iteration 4233, loss = 0.00595742\n",
      "Iteration 4234, loss = 0.00595469\n",
      "Iteration 4235, loss = 0.00595294\n",
      "Iteration 4236, loss = 0.00595078\n",
      "Iteration 4237, loss = 0.00594848\n",
      "Iteration 4238, loss = 0.00594647\n",
      "Iteration 4239, loss = 0.00594446\n",
      "Iteration 4240, loss = 0.00594222\n",
      "Iteration 4241, loss = 0.00594024\n",
      "Iteration 4242, loss = 0.00593817\n",
      "Iteration 4243, loss = 0.00593600\n",
      "Iteration 4244, loss = 0.00593410\n",
      "Iteration 4245, loss = 0.00593211\n",
      "Iteration 4246, loss = 0.00593012\n",
      "Iteration 4247, loss = 0.00592809\n",
      "Iteration 4248, loss = 0.00592618\n",
      "Iteration 4249, loss = 0.00592448\n",
      "Iteration 4250, loss = 0.00592262\n",
      "Iteration 4251, loss = 0.00592068\n",
      "Iteration 4252, loss = 0.00591887\n",
      "Iteration 4253, loss = 0.00591705\n",
      "Iteration 4254, loss = 0.00591515\n",
      "Iteration 4255, loss = 0.00591430\n",
      "Iteration 4256, loss = 0.00591149\n",
      "Iteration 4257, loss = 0.00590967\n",
      "Iteration 4258, loss = 0.00590769\n",
      "Iteration 4259, loss = 0.00590567\n",
      "Iteration 4260, loss = 0.00590351\n",
      "Iteration 4261, loss = 0.00590152\n",
      "Iteration 4262, loss = 0.00589979\n",
      "Iteration 4263, loss = 0.00589778\n",
      "Iteration 4264, loss = 0.00589578\n",
      "Iteration 4265, loss = 0.00589384\n",
      "Iteration 4266, loss = 0.00589173\n",
      "Iteration 4267, loss = 0.00588997\n",
      "Iteration 4268, loss = 0.00588871\n",
      "Iteration 4269, loss = 0.00588614\n",
      "Iteration 4270, loss = 0.00588408\n",
      "Iteration 4271, loss = 0.00588219\n",
      "Iteration 4272, loss = 0.00587999\n",
      "Iteration 4273, loss = 0.00587822\n",
      "Iteration 4274, loss = 0.00587630\n",
      "Iteration 4275, loss = 0.00587382\n",
      "Iteration 4276, loss = 0.00587219\n",
      "Iteration 4277, loss = 0.00586986\n",
      "Iteration 4278, loss = 0.00586750\n",
      "Iteration 4279, loss = 0.00586500\n",
      "Iteration 4280, loss = 0.00586316\n",
      "Iteration 4281, loss = 0.00586099\n",
      "Iteration 4282, loss = 0.00585909\n",
      "Iteration 4283, loss = 0.00585672\n",
      "Iteration 4284, loss = 0.00585449\n",
      "Iteration 4285, loss = 0.00585243\n",
      "Iteration 4286, loss = 0.00585059\n",
      "Iteration 4287, loss = 0.00584880\n",
      "Iteration 4288, loss = 0.00584651\n",
      "Iteration 4289, loss = 0.00584477\n",
      "Iteration 4290, loss = 0.00584294\n",
      "Iteration 4291, loss = 0.00584091\n",
      "Iteration 4292, loss = 0.00583914\n",
      "Iteration 4293, loss = 0.00583751\n",
      "Iteration 4294, loss = 0.00583515\n",
      "Iteration 4295, loss = 0.00583346\n",
      "Iteration 4296, loss = 0.00583118\n",
      "Iteration 4297, loss = 0.00582957\n",
      "Iteration 4298, loss = 0.00582762\n",
      "Iteration 4299, loss = 0.00582554\n",
      "Iteration 4300, loss = 0.00582353\n",
      "Iteration 4301, loss = 0.00582168\n",
      "Iteration 4302, loss = 0.00581946\n",
      "Iteration 4303, loss = 0.00581753\n",
      "Iteration 4304, loss = 0.00581562\n",
      "Iteration 4305, loss = 0.00581368\n",
      "Iteration 4306, loss = 0.00581166\n",
      "Iteration 4307, loss = 0.00580990\n",
      "Iteration 4308, loss = 0.00580768\n",
      "Iteration 4309, loss = 0.00580591\n",
      "Iteration 4310, loss = 0.00580398\n",
      "Iteration 4311, loss = 0.00580226\n",
      "Iteration 4312, loss = 0.00580028\n",
      "Iteration 4313, loss = 0.00579808\n",
      "Iteration 4314, loss = 0.00579632\n",
      "Iteration 4315, loss = 0.00579441\n",
      "Iteration 4316, loss = 0.00579253\n",
      "Iteration 4317, loss = 0.00579071\n",
      "Iteration 4318, loss = 0.00578844\n",
      "Iteration 4319, loss = 0.00578650\n",
      "Iteration 4320, loss = 0.00578448\n",
      "Iteration 4321, loss = 0.00578287\n",
      "Iteration 4322, loss = 0.00578067\n",
      "Iteration 4323, loss = 0.00577903\n",
      "Iteration 4324, loss = 0.00577673\n",
      "Iteration 4325, loss = 0.00577462\n",
      "Iteration 4326, loss = 0.00577246\n",
      "Iteration 4327, loss = 0.00577010\n",
      "Iteration 4328, loss = 0.00576818\n",
      "Iteration 4329, loss = 0.00576588\n",
      "Iteration 4330, loss = 0.00576370\n",
      "Iteration 4331, loss = 0.00576245\n",
      "Iteration 4332, loss = 0.00576002\n",
      "Iteration 4333, loss = 0.00575775\n",
      "Iteration 4334, loss = 0.00575586\n",
      "Iteration 4335, loss = 0.00575395\n",
      "Iteration 4336, loss = 0.00575314\n",
      "Iteration 4337, loss = 0.00575046\n",
      "Iteration 4338, loss = 0.00574846\n",
      "Iteration 4339, loss = 0.00574584\n",
      "Iteration 4340, loss = 0.00574351\n",
      "Iteration 4341, loss = 0.00574146\n",
      "Iteration 4342, loss = 0.00574064\n",
      "Iteration 4343, loss = 0.00573760\n",
      "Iteration 4344, loss = 0.00573572\n",
      "Iteration 4345, loss = 0.00573396\n",
      "Iteration 4346, loss = 0.00573219\n",
      "Iteration 4347, loss = 0.00573030\n",
      "Iteration 4348, loss = 0.00572830\n",
      "Iteration 4349, loss = 0.00572638\n",
      "Iteration 4350, loss = 0.00572442\n",
      "Iteration 4351, loss = 0.00572271\n",
      "Iteration 4352, loss = 0.00572147\n",
      "Iteration 4353, loss = 0.00571937\n",
      "Iteration 4354, loss = 0.00571740\n",
      "Iteration 4355, loss = 0.00571548\n",
      "Iteration 4356, loss = 0.00571409\n",
      "Iteration 4357, loss = 0.00571244\n",
      "Iteration 4358, loss = 0.00571060\n",
      "Iteration 4359, loss = 0.00570908\n",
      "Iteration 4360, loss = 0.00570684\n",
      "Iteration 4361, loss = 0.00570518\n",
      "Iteration 4362, loss = 0.00570336\n",
      "Iteration 4363, loss = 0.00570139\n",
      "Iteration 4364, loss = 0.00569929\n",
      "Iteration 4365, loss = 0.00569743\n",
      "Iteration 4366, loss = 0.00569539\n",
      "Iteration 4367, loss = 0.00569357\n",
      "Iteration 4368, loss = 0.00569162\n",
      "Iteration 4369, loss = 0.00568981\n",
      "Iteration 4370, loss = 0.00568774\n",
      "Iteration 4371, loss = 0.00568599\n",
      "Iteration 4372, loss = 0.00568443\n",
      "Iteration 4373, loss = 0.00568224\n",
      "Iteration 4374, loss = 0.00568033\n",
      "Iteration 4375, loss = 0.00567851\n",
      "Iteration 4376, loss = 0.00567678\n",
      "Iteration 4377, loss = 0.00567517\n",
      "Iteration 4378, loss = 0.00567308\n",
      "Iteration 4379, loss = 0.00567177\n",
      "Iteration 4380, loss = 0.00566941\n",
      "Iteration 4381, loss = 0.00566759\n",
      "Iteration 4382, loss = 0.00566567\n",
      "Iteration 4383, loss = 0.00566388\n",
      "Iteration 4384, loss = 0.00566203\n",
      "Iteration 4385, loss = 0.00566012\n",
      "Iteration 4386, loss = 0.00565845\n",
      "Iteration 4387, loss = 0.00565635\n",
      "Iteration 4388, loss = 0.00565469\n",
      "Iteration 4389, loss = 0.00565273\n",
      "Iteration 4390, loss = 0.00565097\n",
      "Iteration 4391, loss = 0.00564904\n",
      "Iteration 4392, loss = 0.00564722\n",
      "Iteration 4393, loss = 0.00564535\n",
      "Iteration 4394, loss = 0.00564346\n",
      "Iteration 4395, loss = 0.00564248\n",
      "Iteration 4396, loss = 0.00563971\n",
      "Iteration 4397, loss = 0.00563791\n",
      "Iteration 4398, loss = 0.00563605\n",
      "Iteration 4399, loss = 0.00563400\n",
      "Iteration 4400, loss = 0.00563216\n",
      "Iteration 4401, loss = 0.00563040\n",
      "Iteration 4402, loss = 0.00562903\n",
      "Iteration 4403, loss = 0.00562696\n",
      "Iteration 4404, loss = 0.00562522\n",
      "Iteration 4405, loss = 0.00562321\n",
      "Iteration 4406, loss = 0.00562129\n",
      "Iteration 4407, loss = 0.00561929\n",
      "Iteration 4408, loss = 0.00561753\n",
      "Iteration 4409, loss = 0.00561560\n",
      "Iteration 4410, loss = 0.00561414\n",
      "Iteration 4411, loss = 0.00561211\n",
      "Iteration 4412, loss = 0.00561038\n",
      "Iteration 4413, loss = 0.00560876\n",
      "Iteration 4414, loss = 0.00560699\n",
      "Iteration 4415, loss = 0.00560547\n",
      "Iteration 4416, loss = 0.00560355\n",
      "Iteration 4417, loss = 0.00560190\n",
      "Iteration 4418, loss = 0.00560012\n",
      "Iteration 4419, loss = 0.00559828\n",
      "Iteration 4420, loss = 0.00559667\n",
      "Iteration 4421, loss = 0.00559467\n",
      "Iteration 4422, loss = 0.00559266\n",
      "Iteration 4423, loss = 0.00559130\n",
      "Iteration 4424, loss = 0.00558938\n",
      "Iteration 4425, loss = 0.00558758\n",
      "Iteration 4426, loss = 0.00558588\n",
      "Iteration 4427, loss = 0.00558416\n",
      "Iteration 4428, loss = 0.00558252\n",
      "Iteration 4429, loss = 0.00558085\n",
      "Iteration 4430, loss = 0.00557948\n",
      "Iteration 4431, loss = 0.00557783\n",
      "Iteration 4432, loss = 0.00557620\n",
      "Iteration 4433, loss = 0.00557467\n",
      "Iteration 4434, loss = 0.00557335\n",
      "Iteration 4435, loss = 0.00557118\n",
      "Iteration 4436, loss = 0.00556950\n",
      "Iteration 4437, loss = 0.00556821\n",
      "Iteration 4438, loss = 0.00556640\n",
      "Iteration 4439, loss = 0.00556467\n",
      "Iteration 4440, loss = 0.00556306\n",
      "Iteration 4441, loss = 0.00556135\n",
      "Iteration 4442, loss = 0.00555923\n",
      "Iteration 4443, loss = 0.00555806\n",
      "Iteration 4444, loss = 0.00555583\n",
      "Iteration 4445, loss = 0.00555386\n",
      "Iteration 4446, loss = 0.00555205\n",
      "Iteration 4447, loss = 0.00555048\n",
      "Iteration 4448, loss = 0.00554843\n",
      "Iteration 4449, loss = 0.00554667\n",
      "Iteration 4450, loss = 0.00554480\n",
      "Iteration 4451, loss = 0.00554289\n",
      "Iteration 4452, loss = 0.00554092\n",
      "Iteration 4453, loss = 0.00553909\n",
      "Iteration 4454, loss = 0.00553741\n",
      "Iteration 4455, loss = 0.00553566\n",
      "Iteration 4456, loss = 0.00553376\n",
      "Iteration 4457, loss = 0.00553245\n",
      "Iteration 4458, loss = 0.00553033\n",
      "Iteration 4459, loss = 0.00552912\n",
      "Iteration 4460, loss = 0.00552697\n",
      "Iteration 4461, loss = 0.00552512\n",
      "Iteration 4462, loss = 0.00552347\n",
      "Iteration 4463, loss = 0.00552160\n",
      "Iteration 4464, loss = 0.00551986\n",
      "Iteration 4465, loss = 0.00551829\n",
      "Iteration 4466, loss = 0.00551644\n",
      "Iteration 4467, loss = 0.00551487\n",
      "Iteration 4468, loss = 0.00551317\n",
      "Iteration 4469, loss = 0.00551187\n",
      "Iteration 4470, loss = 0.00550986\n",
      "Iteration 4471, loss = 0.00550853\n",
      "Iteration 4472, loss = 0.00550666\n",
      "Iteration 4473, loss = 0.00550469\n",
      "Iteration 4474, loss = 0.00550326\n",
      "Iteration 4475, loss = 0.00550125\n",
      "Iteration 4476, loss = 0.00549934\n",
      "Iteration 4477, loss = 0.00549756\n",
      "Iteration 4478, loss = 0.00549561\n",
      "Iteration 4479, loss = 0.00549449\n",
      "Iteration 4480, loss = 0.00549236\n",
      "Iteration 4481, loss = 0.00549085\n",
      "Iteration 4482, loss = 0.00548892\n",
      "Iteration 4483, loss = 0.00548737\n",
      "Iteration 4484, loss = 0.00548566\n",
      "Iteration 4485, loss = 0.00548402\n",
      "Iteration 4486, loss = 0.00548215\n",
      "Iteration 4487, loss = 0.00548055\n",
      "Iteration 4488, loss = 0.00547883\n",
      "Iteration 4489, loss = 0.00547717\n",
      "Iteration 4490, loss = 0.00547542\n",
      "Iteration 4491, loss = 0.00547388\n",
      "Iteration 4492, loss = 0.00547154\n",
      "Iteration 4493, loss = 0.00546974\n",
      "Iteration 4494, loss = 0.00546795\n",
      "Iteration 4495, loss = 0.00546607\n",
      "Iteration 4496, loss = 0.00546431\n",
      "Iteration 4497, loss = 0.00546214\n",
      "Iteration 4498, loss = 0.00546037\n",
      "Iteration 4499, loss = 0.00545843\n",
      "Iteration 4500, loss = 0.00545730\n",
      "Iteration 4501, loss = 0.00545502\n",
      "Iteration 4502, loss = 0.00545325\n",
      "Iteration 4503, loss = 0.00545150\n",
      "Iteration 4504, loss = 0.00544996\n",
      "Iteration 4505, loss = 0.00544814\n",
      "Iteration 4506, loss = 0.00544679\n",
      "Iteration 4507, loss = 0.00544464\n",
      "Iteration 4508, loss = 0.00544286\n",
      "Iteration 4509, loss = 0.00544130\n",
      "Iteration 4510, loss = 0.00543930\n",
      "Iteration 4511, loss = 0.00543744\n",
      "Iteration 4512, loss = 0.00543592\n",
      "Iteration 4513, loss = 0.00543405\n",
      "Iteration 4514, loss = 0.00543232\n",
      "Iteration 4515, loss = 0.00543027\n",
      "Iteration 4516, loss = 0.00542830\n",
      "Iteration 4517, loss = 0.00542691\n",
      "Iteration 4518, loss = 0.00542495\n",
      "Iteration 4519, loss = 0.00542296\n",
      "Iteration 4520, loss = 0.00542260\n",
      "Iteration 4521, loss = 0.00542021\n",
      "Iteration 4522, loss = 0.00541812\n",
      "Iteration 4523, loss = 0.00541627\n",
      "Iteration 4524, loss = 0.00541445\n",
      "Iteration 4525, loss = 0.00541263\n",
      "Iteration 4526, loss = 0.00541113\n",
      "Iteration 4527, loss = 0.00540923\n",
      "Iteration 4528, loss = 0.00540746\n",
      "Iteration 4529, loss = 0.00540584\n",
      "Iteration 4530, loss = 0.00540385\n",
      "Iteration 4531, loss = 0.00540210\n",
      "Iteration 4532, loss = 0.00540033\n",
      "Iteration 4533, loss = 0.00539859\n",
      "Iteration 4534, loss = 0.00539699\n",
      "Iteration 4535, loss = 0.00539568\n",
      "Iteration 4536, loss = 0.00539365\n",
      "Iteration 4537, loss = 0.00539159\n",
      "Iteration 4538, loss = 0.00538996\n",
      "Iteration 4539, loss = 0.00538832\n",
      "Iteration 4540, loss = 0.00538663\n",
      "Iteration 4541, loss = 0.00538480\n",
      "Iteration 4542, loss = 0.00538327\n",
      "Iteration 4543, loss = 0.00538203\n",
      "Iteration 4544, loss = 0.00537977\n",
      "Iteration 4545, loss = 0.00537814\n",
      "Iteration 4546, loss = 0.00537639\n",
      "Iteration 4547, loss = 0.00537492\n",
      "Iteration 4548, loss = 0.00537293\n",
      "Iteration 4549, loss = 0.00537145\n",
      "Iteration 4550, loss = 0.00536938\n",
      "Iteration 4551, loss = 0.00536777\n",
      "Iteration 4552, loss = 0.00536586\n",
      "Iteration 4553, loss = 0.00536401\n",
      "Iteration 4554, loss = 0.00536208\n",
      "Iteration 4555, loss = 0.00536044\n",
      "Iteration 4556, loss = 0.00535859\n",
      "Iteration 4557, loss = 0.00535683\n",
      "Iteration 4558, loss = 0.00535484\n",
      "Iteration 4559, loss = 0.00535445\n",
      "Iteration 4560, loss = 0.00535178\n",
      "Iteration 4561, loss = 0.00535001\n",
      "Iteration 4562, loss = 0.00534834\n",
      "Iteration 4563, loss = 0.00534667\n",
      "Iteration 4564, loss = 0.00534465\n",
      "Iteration 4565, loss = 0.00534289\n",
      "Iteration 4566, loss = 0.00534143\n",
      "Iteration 4567, loss = 0.00533987\n",
      "Iteration 4568, loss = 0.00533776\n",
      "Iteration 4569, loss = 0.00533622\n",
      "Iteration 4570, loss = 0.00533413\n",
      "Iteration 4571, loss = 0.00533261\n",
      "Iteration 4572, loss = 0.00533053\n",
      "Iteration 4573, loss = 0.00532898\n",
      "Iteration 4574, loss = 0.00532687\n",
      "Iteration 4575, loss = 0.00532513\n",
      "Iteration 4576, loss = 0.00532341\n",
      "Iteration 4577, loss = 0.00532204\n",
      "Iteration 4578, loss = 0.00532030\n",
      "Iteration 4579, loss = 0.00531902\n",
      "Iteration 4580, loss = 0.00531635\n",
      "Iteration 4581, loss = 0.00531540\n",
      "Iteration 4582, loss = 0.00531305\n",
      "Iteration 4583, loss = 0.00531139\n",
      "Iteration 4584, loss = 0.00530947\n",
      "Iteration 4585, loss = 0.00530791\n",
      "Iteration 4586, loss = 0.00530608\n",
      "Iteration 4587, loss = 0.00530457\n",
      "Iteration 4588, loss = 0.00530280\n",
      "Iteration 4589, loss = 0.00530131\n",
      "Iteration 4590, loss = 0.00529931\n",
      "Iteration 4591, loss = 0.00529757\n",
      "Iteration 4592, loss = 0.00529579\n",
      "Iteration 4593, loss = 0.00529432\n",
      "Iteration 4594, loss = 0.00529243\n",
      "Iteration 4595, loss = 0.00529103\n",
      "Iteration 4596, loss = 0.00528911\n",
      "Iteration 4597, loss = 0.00528720\n",
      "Iteration 4598, loss = 0.00528513\n",
      "Iteration 4599, loss = 0.00528344\n",
      "Iteration 4600, loss = 0.00528140\n",
      "Iteration 4601, loss = 0.00527989\n",
      "Iteration 4602, loss = 0.00527794\n",
      "Iteration 4603, loss = 0.00527617\n",
      "Iteration 4604, loss = 0.00527447\n",
      "Iteration 4605, loss = 0.00527283\n",
      "Iteration 4606, loss = 0.00527087\n",
      "Iteration 4607, loss = 0.00526926\n",
      "Iteration 4608, loss = 0.00526801\n",
      "Iteration 4609, loss = 0.00526597\n",
      "Iteration 4610, loss = 0.00526427\n",
      "Iteration 4611, loss = 0.00526269\n",
      "Iteration 4612, loss = 0.00526066\n",
      "Iteration 4613, loss = 0.00525956\n",
      "Iteration 4614, loss = 0.00525795\n",
      "Iteration 4615, loss = 0.00525598\n",
      "Iteration 4616, loss = 0.00525420\n",
      "Iteration 4617, loss = 0.00525267\n",
      "Iteration 4618, loss = 0.00525079\n",
      "Iteration 4619, loss = 0.00524897\n",
      "Iteration 4620, loss = 0.00524725\n",
      "Iteration 4621, loss = 0.00524572\n",
      "Iteration 4622, loss = 0.00524398\n",
      "Iteration 4623, loss = 0.00524227\n",
      "Iteration 4624, loss = 0.00524062\n",
      "Iteration 4625, loss = 0.00523899\n",
      "Iteration 4626, loss = 0.00523741\n",
      "Iteration 4627, loss = 0.00523579\n",
      "Iteration 4628, loss = 0.00523433\n",
      "Iteration 4629, loss = 0.00523279\n",
      "Iteration 4630, loss = 0.00523142\n",
      "Iteration 4631, loss = 0.00522926\n",
      "Iteration 4632, loss = 0.00522778\n",
      "Iteration 4633, loss = 0.00522590\n",
      "Iteration 4634, loss = 0.00522434\n",
      "Iteration 4635, loss = 0.00522277\n",
      "Iteration 4636, loss = 0.00522089\n",
      "Iteration 4637, loss = 0.00521954\n",
      "Iteration 4638, loss = 0.00521777\n",
      "Iteration 4639, loss = 0.00521629\n",
      "Iteration 4640, loss = 0.00521464\n",
      "Iteration 4641, loss = 0.00521321\n",
      "Iteration 4642, loss = 0.00521138\n",
      "Iteration 4643, loss = 0.00520971\n",
      "Iteration 4644, loss = 0.00520809\n",
      "Iteration 4645, loss = 0.00520688\n",
      "Iteration 4646, loss = 0.00520476\n",
      "Iteration 4647, loss = 0.00520270\n",
      "Iteration 4648, loss = 0.00520098\n",
      "Iteration 4649, loss = 0.00519919\n",
      "Iteration 4650, loss = 0.00519763\n",
      "Iteration 4651, loss = 0.00519579\n",
      "Iteration 4652, loss = 0.00519415\n",
      "Iteration 4653, loss = 0.00519232\n",
      "Iteration 4654, loss = 0.00519064\n",
      "Iteration 4655, loss = 0.00518889\n",
      "Iteration 4656, loss = 0.00518723\n",
      "Iteration 4657, loss = 0.00518547\n",
      "Iteration 4658, loss = 0.00518389\n",
      "Iteration 4659, loss = 0.00518211\n",
      "Iteration 4660, loss = 0.00518044\n",
      "Iteration 4661, loss = 0.00517882\n",
      "Iteration 4662, loss = 0.00517749\n",
      "Iteration 4663, loss = 0.00517555\n",
      "Iteration 4664, loss = 0.00517418\n",
      "Iteration 4665, loss = 0.00517244\n",
      "Iteration 4666, loss = 0.00517081\n",
      "Iteration 4667, loss = 0.00516926\n",
      "Iteration 4668, loss = 0.00516773\n",
      "Iteration 4669, loss = 0.00516623\n",
      "Iteration 4670, loss = 0.00516461\n",
      "Iteration 4671, loss = 0.00516320\n",
      "Iteration 4672, loss = 0.00516155\n",
      "Iteration 4673, loss = 0.00516018\n",
      "Iteration 4674, loss = 0.00515825\n",
      "Iteration 4675, loss = 0.00515663\n",
      "Iteration 4676, loss = 0.00515504\n",
      "Iteration 4677, loss = 0.00515362\n",
      "Iteration 4678, loss = 0.00515203\n",
      "Iteration 4679, loss = 0.00515035\n",
      "Iteration 4680, loss = 0.00514866\n",
      "Iteration 4681, loss = 0.00514697\n",
      "Iteration 4682, loss = 0.00514547\n",
      "Iteration 4683, loss = 0.00514404\n",
      "Iteration 4684, loss = 0.00514246\n",
      "Iteration 4685, loss = 0.00514090\n",
      "Iteration 4686, loss = 0.00513926\n",
      "Iteration 4687, loss = 0.00513766\n",
      "Iteration 4688, loss = 0.00513609\n",
      "Iteration 4689, loss = 0.00513468\n",
      "Iteration 4690, loss = 0.00513304\n",
      "Iteration 4691, loss = 0.00513143\n",
      "Iteration 4692, loss = 0.00512990\n",
      "Iteration 4693, loss = 0.00512853\n",
      "Iteration 4694, loss = 0.00512678\n",
      "Iteration 4695, loss = 0.00512526\n",
      "Iteration 4696, loss = 0.00512386\n",
      "Iteration 4697, loss = 0.00512236\n",
      "Iteration 4698, loss = 0.00512086\n",
      "Iteration 4699, loss = 0.00511974\n",
      "Iteration 4700, loss = 0.00511771\n",
      "Iteration 4701, loss = 0.00511599\n",
      "Iteration 4702, loss = 0.00511441\n",
      "Iteration 4703, loss = 0.00511311\n",
      "Iteration 4704, loss = 0.00511111\n",
      "Iteration 4705, loss = 0.00510955\n",
      "Iteration 4706, loss = 0.00510807\n",
      "Iteration 4707, loss = 0.00510666\n",
      "Iteration 4708, loss = 0.00510506\n",
      "Iteration 4709, loss = 0.00510336\n",
      "Iteration 4710, loss = 0.00510181\n",
      "Iteration 4711, loss = 0.00510036\n",
      "Iteration 4712, loss = 0.00509889\n",
      "Iteration 4713, loss = 0.00509739\n",
      "Iteration 4714, loss = 0.00509616\n",
      "Iteration 4715, loss = 0.00509465\n",
      "Iteration 4716, loss = 0.00509319\n",
      "Iteration 4717, loss = 0.00509223\n",
      "Iteration 4718, loss = 0.00509053\n",
      "Iteration 4719, loss = 0.00508873\n",
      "Iteration 4720, loss = 0.00508731\n",
      "Iteration 4721, loss = 0.00508576\n",
      "Iteration 4722, loss = 0.00508406\n",
      "Iteration 4723, loss = 0.00508278\n",
      "Iteration 4724, loss = 0.00508090\n",
      "Iteration 4725, loss = 0.00507931\n",
      "Iteration 4726, loss = 0.00507765\n",
      "Iteration 4727, loss = 0.00507615\n",
      "Iteration 4728, loss = 0.00507496\n",
      "Iteration 4729, loss = 0.00507324\n",
      "Iteration 4730, loss = 0.00507184\n",
      "Iteration 4731, loss = 0.00507062\n",
      "Iteration 4732, loss = 0.00506917\n",
      "Iteration 4733, loss = 0.00506772\n",
      "Iteration 4734, loss = 0.00506638\n",
      "Iteration 4735, loss = 0.00506505\n",
      "Iteration 4736, loss = 0.00506371\n",
      "Iteration 4737, loss = 0.00506228\n",
      "Iteration 4738, loss = 0.00506070\n",
      "Iteration 4739, loss = 0.00505994\n",
      "Iteration 4740, loss = 0.00505807\n",
      "Iteration 4741, loss = 0.00505666\n",
      "Iteration 4742, loss = 0.00505503\n",
      "Iteration 4743, loss = 0.00505361\n",
      "Iteration 4744, loss = 0.00505218\n",
      "Iteration 4745, loss = 0.00505074\n",
      "Iteration 4746, loss = 0.00504934\n",
      "Iteration 4747, loss = 0.00504803\n",
      "Iteration 4748, loss = 0.00504672\n",
      "Iteration 4749, loss = 0.00504553\n",
      "Iteration 4750, loss = 0.00504386\n",
      "Iteration 4751, loss = 0.00504248\n",
      "Iteration 4752, loss = 0.00504094\n",
      "Iteration 4753, loss = 0.00503898\n",
      "Iteration 4754, loss = 0.00503765\n",
      "Iteration 4755, loss = 0.00503577\n",
      "Iteration 4756, loss = 0.00503401\n",
      "Iteration 4757, loss = 0.00503246\n",
      "Iteration 4758, loss = 0.00503152\n",
      "Iteration 4759, loss = 0.00502951\n",
      "Iteration 4760, loss = 0.00502816\n",
      "Iteration 4761, loss = 0.00502693\n",
      "Iteration 4762, loss = 0.00502512\n",
      "Iteration 4763, loss = 0.00502359\n",
      "Iteration 4764, loss = 0.00502215\n",
      "Iteration 4765, loss = 0.00502043\n",
      "Iteration 4766, loss = 0.00501875\n",
      "Iteration 4767, loss = 0.00501731\n",
      "Iteration 4768, loss = 0.00501565\n",
      "Iteration 4769, loss = 0.00501413\n",
      "Iteration 4770, loss = 0.00501257\n",
      "Iteration 4771, loss = 0.00501105\n",
      "Iteration 4772, loss = 0.00500943\n",
      "Iteration 4773, loss = 0.00500790\n",
      "Iteration 4774, loss = 0.00500643\n",
      "Iteration 4775, loss = 0.00500484\n",
      "Iteration 4776, loss = 0.00500371\n",
      "Iteration 4777, loss = 0.00500200\n",
      "Iteration 4778, loss = 0.00500043\n",
      "Iteration 4779, loss = 0.00499937\n",
      "Iteration 4780, loss = 0.00499776\n",
      "Iteration 4781, loss = 0.00499617\n",
      "Iteration 4782, loss = 0.00499466\n",
      "Iteration 4783, loss = 0.00499335\n",
      "Iteration 4784, loss = 0.00499201\n",
      "Iteration 4785, loss = 0.00499018\n",
      "Iteration 4786, loss = 0.00498916\n",
      "Iteration 4787, loss = 0.00498748\n",
      "Iteration 4788, loss = 0.00498552\n",
      "Iteration 4789, loss = 0.00498400\n",
      "Iteration 4790, loss = 0.00498247\n",
      "Iteration 4791, loss = 0.00498073\n",
      "Iteration 4792, loss = 0.00497910\n",
      "Iteration 4793, loss = 0.00497759\n",
      "Iteration 4794, loss = 0.00497596\n",
      "Iteration 4795, loss = 0.00497441\n",
      "Iteration 4796, loss = 0.00497303\n",
      "Iteration 4797, loss = 0.00497134\n",
      "Iteration 4798, loss = 0.00497022\n",
      "Iteration 4799, loss = 0.00496848\n",
      "Iteration 4800, loss = 0.00496697\n",
      "Iteration 4801, loss = 0.00496556\n",
      "Iteration 4802, loss = 0.00496414\n",
      "Iteration 4803, loss = 0.00496353\n",
      "Iteration 4804, loss = 0.00496129\n",
      "Iteration 4805, loss = 0.00495988\n",
      "Iteration 4806, loss = 0.00495864\n",
      "Iteration 4807, loss = 0.00495672\n",
      "Iteration 4808, loss = 0.00495534\n",
      "Iteration 4809, loss = 0.00495397\n",
      "Iteration 4810, loss = 0.00495226\n",
      "Iteration 4811, loss = 0.00495074\n",
      "Iteration 4812, loss = 0.00494914\n",
      "Iteration 4813, loss = 0.00494769\n",
      "Iteration 4814, loss = 0.00494643\n",
      "Iteration 4815, loss = 0.00494493\n",
      "Iteration 4816, loss = 0.00494319\n",
      "Iteration 4817, loss = 0.00494154\n",
      "Iteration 4818, loss = 0.00493994\n",
      "Iteration 4819, loss = 0.00493815\n",
      "Iteration 4820, loss = 0.00493712\n",
      "Iteration 4821, loss = 0.00493525\n",
      "Iteration 4822, loss = 0.00493355\n",
      "Iteration 4823, loss = 0.00493204\n",
      "Iteration 4824, loss = 0.00493058\n",
      "Iteration 4825, loss = 0.00492925\n",
      "Iteration 4826, loss = 0.00492792\n",
      "Iteration 4827, loss = 0.00492620\n",
      "Iteration 4828, loss = 0.00492461\n",
      "Iteration 4829, loss = 0.00492278\n",
      "Iteration 4830, loss = 0.00492104\n",
      "Iteration 4831, loss = 0.00491993\n",
      "Iteration 4832, loss = 0.00491813\n",
      "Iteration 4833, loss = 0.00491623\n",
      "Iteration 4834, loss = 0.00491565\n",
      "Iteration 4835, loss = 0.00491324\n",
      "Iteration 4836, loss = 0.00491271\n",
      "Iteration 4837, loss = 0.00491021\n",
      "Iteration 4838, loss = 0.00490867\n",
      "Iteration 4839, loss = 0.00490722\n",
      "Iteration 4840, loss = 0.00490604\n",
      "Iteration 4841, loss = 0.00490421\n",
      "Iteration 4842, loss = 0.00490314\n",
      "Iteration 4843, loss = 0.00490141\n",
      "Iteration 4844, loss = 0.00490007\n",
      "Iteration 4845, loss = 0.00489857\n",
      "Iteration 4846, loss = 0.00489726\n",
      "Iteration 4847, loss = 0.00489542\n",
      "Iteration 4848, loss = 0.00489392\n",
      "Iteration 4849, loss = 0.00489252\n",
      "Iteration 4850, loss = 0.00489126\n",
      "Iteration 4851, loss = 0.00488996\n",
      "Iteration 4852, loss = 0.00488828\n",
      "Iteration 4853, loss = 0.00488682\n",
      "Iteration 4854, loss = 0.00488578\n",
      "Iteration 4855, loss = 0.00488401\n",
      "Iteration 4856, loss = 0.00488258\n",
      "Iteration 4857, loss = 0.00488090\n",
      "Iteration 4858, loss = 0.00487958\n",
      "Iteration 4859, loss = 0.00487781\n",
      "Iteration 4860, loss = 0.00487649\n",
      "Iteration 4861, loss = 0.00487498\n",
      "Iteration 4862, loss = 0.00487350\n",
      "Iteration 4863, loss = 0.00487213\n",
      "Iteration 4864, loss = 0.00487056\n",
      "Iteration 4865, loss = 0.00486913\n",
      "Iteration 4866, loss = 0.00486762\n",
      "Iteration 4867, loss = 0.00486607\n",
      "Iteration 4868, loss = 0.00486469\n",
      "Iteration 4869, loss = 0.00486352\n",
      "Iteration 4870, loss = 0.00486271\n",
      "Iteration 4871, loss = 0.00486094\n",
      "Iteration 4872, loss = 0.00486030\n",
      "Iteration 4873, loss = 0.00485853\n",
      "Iteration 4874, loss = 0.00485703\n",
      "Iteration 4875, loss = 0.00485572\n",
      "Iteration 4876, loss = 0.00485454\n",
      "Iteration 4877, loss = 0.00485275\n",
      "Iteration 4878, loss = 0.00485116\n",
      "Iteration 4879, loss = 0.00484963\n",
      "Iteration 4880, loss = 0.00484860\n",
      "Iteration 4881, loss = 0.00484690\n",
      "Iteration 4882, loss = 0.00484553\n",
      "Iteration 4883, loss = 0.00484385\n",
      "Iteration 4884, loss = 0.00484236\n",
      "Iteration 4885, loss = 0.00484086\n",
      "Iteration 4886, loss = 0.00483947\n",
      "Iteration 4887, loss = 0.00483764\n",
      "Iteration 4888, loss = 0.00483601\n",
      "Iteration 4889, loss = 0.00483486\n",
      "Iteration 4890, loss = 0.00483292\n",
      "Iteration 4891, loss = 0.00483146\n",
      "Iteration 4892, loss = 0.00482977\n",
      "Iteration 4893, loss = 0.00482838\n",
      "Iteration 4894, loss = 0.00482689\n",
      "Iteration 4895, loss = 0.00482553\n",
      "Iteration 4896, loss = 0.00482376\n",
      "Iteration 4897, loss = 0.00482267\n",
      "Iteration 4898, loss = 0.00482084\n",
      "Iteration 4899, loss = 0.00481955\n",
      "Iteration 4900, loss = 0.00481816\n",
      "Iteration 4901, loss = 0.00481656\n",
      "Iteration 4902, loss = 0.00481510\n",
      "Iteration 4903, loss = 0.00481374\n",
      "Iteration 4904, loss = 0.00481222\n",
      "Iteration 4905, loss = 0.00481088\n",
      "Iteration 4906, loss = 0.00480956\n",
      "Iteration 4907, loss = 0.00480795\n",
      "Iteration 4908, loss = 0.00480654\n",
      "Iteration 4909, loss = 0.00480515\n",
      "Iteration 4910, loss = 0.00480351\n",
      "Iteration 4911, loss = 0.00480217\n",
      "Iteration 4912, loss = 0.00480039\n",
      "Iteration 4913, loss = 0.00479901\n",
      "Iteration 4914, loss = 0.00479798\n",
      "Iteration 4915, loss = 0.00479634\n",
      "Iteration 4916, loss = 0.00479449\n",
      "Iteration 4917, loss = 0.00479303\n",
      "Iteration 4918, loss = 0.00479172\n",
      "Iteration 4919, loss = 0.00479040\n",
      "Iteration 4920, loss = 0.00478848\n",
      "Iteration 4921, loss = 0.00478701\n",
      "Iteration 4922, loss = 0.00478538\n",
      "Iteration 4923, loss = 0.00478391\n",
      "Iteration 4924, loss = 0.00478250\n",
      "Iteration 4925, loss = 0.00478106\n",
      "Iteration 4926, loss = 0.00477974\n",
      "Iteration 4927, loss = 0.00477823\n",
      "Iteration 4928, loss = 0.00477680\n",
      "Iteration 4929, loss = 0.00477533\n",
      "Iteration 4930, loss = 0.00477420\n",
      "Iteration 4931, loss = 0.00477254\n",
      "Iteration 4932, loss = 0.00477116\n",
      "Iteration 4933, loss = 0.00476979\n",
      "Iteration 4934, loss = 0.00476826\n",
      "Iteration 4935, loss = 0.00476697\n",
      "Iteration 4936, loss = 0.00476545\n",
      "Iteration 4937, loss = 0.00476415\n",
      "Iteration 4938, loss = 0.00476266\n",
      "Iteration 4939, loss = 0.00476113\n",
      "Iteration 4940, loss = 0.00475941\n",
      "Iteration 4941, loss = 0.00475795\n",
      "Iteration 4942, loss = 0.00475695\n",
      "Iteration 4943, loss = 0.00475539\n",
      "Iteration 4944, loss = 0.00475375\n",
      "Iteration 4945, loss = 0.00475224\n",
      "Iteration 4946, loss = 0.00475111\n",
      "Iteration 4947, loss = 0.00474930\n",
      "Iteration 4948, loss = 0.00474791\n",
      "Iteration 4949, loss = 0.00474645\n",
      "Iteration 4950, loss = 0.00474513\n",
      "Iteration 4951, loss = 0.00474370\n",
      "Iteration 4952, loss = 0.00474237\n",
      "Iteration 4953, loss = 0.00474109\n",
      "Iteration 4954, loss = 0.00473983\n",
      "Iteration 4955, loss = 0.00473827\n",
      "Iteration 4956, loss = 0.00473695\n",
      "Iteration 4957, loss = 0.00473546\n",
      "Iteration 4958, loss = 0.00473430\n",
      "Iteration 4959, loss = 0.00473315\n",
      "Iteration 4960, loss = 0.00473176\n",
      "Iteration 4961, loss = 0.00473047\n",
      "Iteration 4962, loss = 0.00472907\n",
      "Iteration 4963, loss = 0.00472774\n",
      "Iteration 4964, loss = 0.00472625\n",
      "Iteration 4965, loss = 0.00472489\n",
      "Iteration 4966, loss = 0.00472341\n",
      "Iteration 4967, loss = 0.00472220\n",
      "Iteration 4968, loss = 0.00472071\n",
      "Iteration 4969, loss = 0.00471912\n",
      "Iteration 4970, loss = 0.00471774\n",
      "Iteration 4971, loss = 0.00471649\n",
      "Iteration 4972, loss = 0.00471485\n",
      "Iteration 4973, loss = 0.00471346\n",
      "Iteration 4974, loss = 0.00471216\n",
      "Iteration 4975, loss = 0.00471110\n",
      "Iteration 4976, loss = 0.00470930\n",
      "Iteration 4977, loss = 0.00470790\n",
      "Iteration 4978, loss = 0.00470662\n",
      "Iteration 4979, loss = 0.00470541\n",
      "Iteration 4980, loss = 0.00470390\n",
      "Iteration 4981, loss = 0.00470266\n",
      "Iteration 4982, loss = 0.00470133\n",
      "Iteration 4983, loss = 0.00470001\n",
      "Iteration 4984, loss = 0.00469868\n",
      "Iteration 4985, loss = 0.00469782\n",
      "Iteration 4986, loss = 0.00469612\n",
      "Iteration 4987, loss = 0.00469481\n",
      "Iteration 4988, loss = 0.00469361\n",
      "Iteration 4989, loss = 0.00469196\n",
      "Iteration 4990, loss = 0.00469021\n",
      "Iteration 4991, loss = 0.00468908\n",
      "Iteration 4992, loss = 0.00468753\n",
      "Iteration 4993, loss = 0.00468609\n",
      "Iteration 4994, loss = 0.00468462\n",
      "Iteration 4995, loss = 0.00468328\n",
      "Iteration 4996, loss = 0.00468190\n",
      "Iteration 4997, loss = 0.00468071\n",
      "Iteration 4998, loss = 0.00467928\n",
      "Iteration 4999, loss = 0.00467824\n",
      "Iteration 5000, loss = 0.00467661\n",
      "Iteration 5001, loss = 0.00467523\n",
      "Iteration 5002, loss = 0.00467391\n",
      "Iteration 5003, loss = 0.00467266\n",
      "Iteration 5004, loss = 0.00467144\n",
      "Iteration 5005, loss = 0.00467035\n",
      "Iteration 5006, loss = 0.00466893\n",
      "Iteration 5007, loss = 0.00466771\n",
      "Iteration 5008, loss = 0.00466650\n",
      "Iteration 5009, loss = 0.00466518\n",
      "Iteration 5010, loss = 0.00466401\n",
      "Iteration 5011, loss = 0.00466268\n",
      "Iteration 5012, loss = 0.00466143\n",
      "Iteration 5013, loss = 0.00466074\n",
      "Iteration 5014, loss = 0.00465892\n",
      "Iteration 5015, loss = 0.00465753\n",
      "Iteration 5016, loss = 0.00465642\n",
      "Iteration 5017, loss = 0.00465504\n",
      "Iteration 5018, loss = 0.00465365\n",
      "Iteration 5019, loss = 0.00465245\n",
      "Iteration 5020, loss = 0.00465098\n",
      "Iteration 5021, loss = 0.00464982\n",
      "Iteration 5022, loss = 0.00464852\n",
      "Iteration 5023, loss = 0.00464736\n",
      "Iteration 5024, loss = 0.00464611\n",
      "Iteration 5025, loss = 0.00464488\n",
      "Iteration 5026, loss = 0.00464365\n",
      "Iteration 5027, loss = 0.00464244\n",
      "Iteration 5028, loss = 0.00464179\n",
      "Iteration 5029, loss = 0.00464060\n",
      "Iteration 5030, loss = 0.00463905\n",
      "Iteration 5031, loss = 0.00463774\n",
      "Iteration 5032, loss = 0.00463665\n",
      "Iteration 5033, loss = 0.00463525\n",
      "Iteration 5034, loss = 0.00463423\n",
      "Iteration 5035, loss = 0.00463282\n",
      "Iteration 5036, loss = 0.00463137\n",
      "Iteration 5037, loss = 0.00463037\n",
      "Iteration 5038, loss = 0.00462892\n",
      "Iteration 5039, loss = 0.00462765\n",
      "Iteration 5040, loss = 0.00462639\n",
      "Iteration 5041, loss = 0.00462524\n",
      "Iteration 5042, loss = 0.00462391\n",
      "Iteration 5043, loss = 0.00462283\n",
      "Iteration 5044, loss = 0.00462168\n",
      "Iteration 5045, loss = 0.00462030\n",
      "Iteration 5046, loss = 0.00461905\n",
      "Iteration 5047, loss = 0.00461778\n",
      "Iteration 5048, loss = 0.00461655\n",
      "Iteration 5049, loss = 0.00461530\n",
      "Iteration 5050, loss = 0.00461387\n",
      "Iteration 5051, loss = 0.00461303\n",
      "Iteration 5052, loss = 0.00461161\n",
      "Iteration 5053, loss = 0.00461021\n",
      "Iteration 5054, loss = 0.00460891\n",
      "Iteration 5055, loss = 0.00460774\n",
      "Iteration 5056, loss = 0.00460656\n",
      "Iteration 5057, loss = 0.00460527\n",
      "Iteration 5058, loss = 0.00460409\n",
      "Iteration 5059, loss = 0.00460302\n",
      "Iteration 5060, loss = 0.00460147\n",
      "Iteration 5061, loss = 0.00460033\n",
      "Iteration 5062, loss = 0.00459893\n",
      "Iteration 5063, loss = 0.00459777\n",
      "Iteration 5064, loss = 0.00459657\n",
      "Iteration 5065, loss = 0.00459541\n",
      "Iteration 5066, loss = 0.00459418\n",
      "Iteration 5067, loss = 0.00459302\n",
      "Iteration 5068, loss = 0.00459209\n",
      "Iteration 5069, loss = 0.00459052\n",
      "Iteration 5070, loss = 0.00458948\n",
      "Iteration 5071, loss = 0.00458797\n",
      "Iteration 5072, loss = 0.00458675\n",
      "Iteration 5073, loss = 0.00458543\n",
      "Iteration 5074, loss = 0.00458411\n",
      "Iteration 5075, loss = 0.00458289\n",
      "Iteration 5076, loss = 0.00458179\n",
      "Iteration 5077, loss = 0.00458048\n",
      "Iteration 5078, loss = 0.00458002\n",
      "Iteration 5079, loss = 0.00457770\n",
      "Iteration 5080, loss = 0.00457600\n",
      "Iteration 5081, loss = 0.00457446\n",
      "Iteration 5082, loss = 0.00457367\n",
      "Iteration 5083, loss = 0.00457186\n",
      "Iteration 5084, loss = 0.00457036\n",
      "Iteration 5085, loss = 0.00456881\n",
      "Iteration 5086, loss = 0.00456740\n",
      "Iteration 5087, loss = 0.00456635\n",
      "Iteration 5088, loss = 0.00456470\n",
      "Iteration 5089, loss = 0.00456329\n",
      "Iteration 5090, loss = 0.00456176\n",
      "Iteration 5091, loss = 0.00456102\n",
      "Iteration 5092, loss = 0.00455907\n",
      "Iteration 5093, loss = 0.00455763\n",
      "Iteration 5094, loss = 0.00455657\n",
      "Iteration 5095, loss = 0.00455483\n",
      "Iteration 5096, loss = 0.00455392\n",
      "Iteration 5097, loss = 0.00455249\n",
      "Iteration 5098, loss = 0.00455108\n",
      "Iteration 5099, loss = 0.00454998\n",
      "Iteration 5100, loss = 0.00454877\n",
      "Iteration 5101, loss = 0.00454737\n",
      "Iteration 5102, loss = 0.00454611\n",
      "Iteration 5103, loss = 0.00454509\n",
      "Iteration 5104, loss = 0.00454375\n",
      "Iteration 5105, loss = 0.00454230\n",
      "Iteration 5106, loss = 0.00454104\n",
      "Iteration 5107, loss = 0.00453990\n",
      "Iteration 5108, loss = 0.00453866\n",
      "Iteration 5109, loss = 0.00453726\n",
      "Iteration 5110, loss = 0.00453620\n",
      "Iteration 5111, loss = 0.00453497\n",
      "Iteration 5112, loss = 0.00453349\n",
      "Iteration 5113, loss = 0.00453248\n",
      "Iteration 5114, loss = 0.00453075\n",
      "Iteration 5115, loss = 0.00452934\n",
      "Iteration 5116, loss = 0.00452812\n",
      "Iteration 5117, loss = 0.00452708\n",
      "Iteration 5118, loss = 0.00452553\n",
      "Iteration 5119, loss = 0.00452429\n",
      "Iteration 5120, loss = 0.00452285\n",
      "Iteration 5121, loss = 0.00452166\n",
      "Iteration 5122, loss = 0.00452032\n",
      "Iteration 5123, loss = 0.00451963\n",
      "Iteration 5124, loss = 0.00451760\n",
      "Iteration 5125, loss = 0.00451627\n",
      "Iteration 5126, loss = 0.00451495\n",
      "Iteration 5127, loss = 0.00451366\n",
      "Iteration 5128, loss = 0.00451241\n",
      "Iteration 5129, loss = 0.00451124\n",
      "Iteration 5130, loss = 0.00451004\n",
      "Iteration 5131, loss = 0.00450841\n",
      "Iteration 5132, loss = 0.00450740\n",
      "Iteration 5133, loss = 0.00450585\n",
      "Iteration 5134, loss = 0.00450459\n",
      "Iteration 5135, loss = 0.00450302\n",
      "Iteration 5136, loss = 0.00450162\n",
      "Iteration 5137, loss = 0.00450040\n",
      "Iteration 5138, loss = 0.00449902\n",
      "Iteration 5139, loss = 0.00449766\n",
      "Iteration 5140, loss = 0.00449648\n",
      "Iteration 5141, loss = 0.00449502\n",
      "Iteration 5142, loss = 0.00449363\n",
      "Iteration 5143, loss = 0.00449240\n",
      "Iteration 5144, loss = 0.00449103\n",
      "Iteration 5145, loss = 0.00448968\n",
      "Iteration 5146, loss = 0.00448812\n",
      "Iteration 5147, loss = 0.00448683\n",
      "Iteration 5148, loss = 0.00448534\n",
      "Iteration 5149, loss = 0.00448423\n",
      "Iteration 5150, loss = 0.00448272\n",
      "Iteration 5151, loss = 0.00448187\n",
      "Iteration 5152, loss = 0.00448032\n",
      "Iteration 5153, loss = 0.00447920\n",
      "Iteration 5154, loss = 0.00447800\n",
      "Iteration 5155, loss = 0.00447668\n",
      "Iteration 5156, loss = 0.00447543\n",
      "Iteration 5157, loss = 0.00447424\n",
      "Iteration 5158, loss = 0.00447300\n",
      "Iteration 5159, loss = 0.00447203\n",
      "Iteration 5160, loss = 0.00447074\n",
      "Iteration 5161, loss = 0.00446945\n",
      "Iteration 5162, loss = 0.00446826\n",
      "Iteration 5163, loss = 0.00446696\n",
      "Iteration 5164, loss = 0.00446572\n",
      "Iteration 5165, loss = 0.00446460\n",
      "Iteration 5166, loss = 0.00446325\n",
      "Iteration 5167, loss = 0.00446213\n",
      "Iteration 5168, loss = 0.00446098\n",
      "Iteration 5169, loss = 0.00445991\n",
      "Iteration 5170, loss = 0.00445877\n",
      "Iteration 5171, loss = 0.00445860\n",
      "Iteration 5172, loss = 0.00445639\n",
      "Iteration 5173, loss = 0.00445516\n",
      "Iteration 5174, loss = 0.00445401\n",
      "Iteration 5175, loss = 0.00445259\n",
      "Iteration 5176, loss = 0.00445160\n",
      "Iteration 5177, loss = 0.00445019\n",
      "Iteration 5178, loss = 0.00444880\n",
      "Iteration 5179, loss = 0.00444751\n",
      "Iteration 5180, loss = 0.00444624\n",
      "Iteration 5181, loss = 0.00444544\n",
      "Iteration 5182, loss = 0.00444378\n",
      "Iteration 5183, loss = 0.00444278\n",
      "Iteration 5184, loss = 0.00444126\n",
      "Iteration 5185, loss = 0.00443990\n",
      "Iteration 5186, loss = 0.00443872\n",
      "Iteration 5187, loss = 0.00443736\n",
      "Iteration 5188, loss = 0.00443594\n",
      "Iteration 5189, loss = 0.00443458\n",
      "Iteration 5190, loss = 0.00443323\n",
      "Iteration 5191, loss = 0.00443198\n",
      "Iteration 5192, loss = 0.00443069\n",
      "Iteration 5193, loss = 0.00442962\n",
      "Iteration 5194, loss = 0.00442815\n",
      "Iteration 5195, loss = 0.00442702\n",
      "Iteration 5196, loss = 0.00442573\n",
      "Iteration 5197, loss = 0.00442465\n",
      "Iteration 5198, loss = 0.00442343\n",
      "Iteration 5199, loss = 0.00442231\n",
      "Iteration 5200, loss = 0.00442123\n",
      "Iteration 5201, loss = 0.00442001\n",
      "Iteration 5202, loss = 0.00441865\n",
      "Iteration 5203, loss = 0.00441754\n",
      "Iteration 5204, loss = 0.00441645\n",
      "Iteration 5205, loss = 0.00441519\n",
      "Iteration 5206, loss = 0.00441375\n",
      "Iteration 5207, loss = 0.00441267\n",
      "Iteration 5208, loss = 0.00441139\n",
      "Iteration 5209, loss = 0.00441024\n",
      "Iteration 5210, loss = 0.00440890\n",
      "Iteration 5211, loss = 0.00440763\n",
      "Iteration 5212, loss = 0.00440658\n",
      "Iteration 5213, loss = 0.00440523\n",
      "Iteration 5214, loss = 0.00440420\n",
      "Iteration 5215, loss = 0.00440306\n",
      "Iteration 5216, loss = 0.00440193\n",
      "Iteration 5217, loss = 0.00440075\n",
      "Iteration 5218, loss = 0.00439957\n",
      "Iteration 5219, loss = 0.00439835\n",
      "Iteration 5220, loss = 0.00439720\n",
      "Iteration 5221, loss = 0.00439571\n",
      "Iteration 5222, loss = 0.00439455\n",
      "Iteration 5223, loss = 0.00439318\n",
      "Iteration 5224, loss = 0.00439194\n",
      "Iteration 5225, loss = 0.00439074\n",
      "Iteration 5226, loss = 0.00438956\n",
      "Iteration 5227, loss = 0.00438839\n",
      "Iteration 5228, loss = 0.00438725\n",
      "Iteration 5229, loss = 0.00438606\n",
      "Iteration 5230, loss = 0.00438509\n",
      "Iteration 5231, loss = 0.00438381\n",
      "Iteration 5232, loss = 0.00438271\n",
      "Iteration 5233, loss = 0.00438158\n",
      "Iteration 5234, loss = 0.00438044\n",
      "Iteration 5235, loss = 0.00437936\n",
      "Iteration 5236, loss = 0.00437810\n",
      "Iteration 5237, loss = 0.00437700\n",
      "Iteration 5238, loss = 0.00437548\n",
      "Iteration 5239, loss = 0.00437411\n",
      "Iteration 5240, loss = 0.00437293\n",
      "Iteration 5241, loss = 0.00437137\n",
      "Iteration 5242, loss = 0.00437070\n",
      "Iteration 5243, loss = 0.00436895\n",
      "Iteration 5244, loss = 0.00436841\n",
      "Iteration 5245, loss = 0.00436724\n",
      "Iteration 5246, loss = 0.00436569\n",
      "Iteration 5247, loss = 0.00436465\n",
      "Iteration 5248, loss = 0.00436336\n",
      "Iteration 5249, loss = 0.00436214\n",
      "Iteration 5250, loss = 0.00436131\n",
      "Iteration 5251, loss = 0.00435985\n",
      "Iteration 5252, loss = 0.00435855\n",
      "Iteration 5253, loss = 0.00435736\n",
      "Iteration 5254, loss = 0.00435615\n",
      "Iteration 5255, loss = 0.00435480\n",
      "Iteration 5256, loss = 0.00435337\n",
      "Iteration 5257, loss = 0.00435206\n",
      "Iteration 5258, loss = 0.00435079\n",
      "Iteration 5259, loss = 0.00434975\n",
      "Iteration 5260, loss = 0.00434848\n",
      "Iteration 5261, loss = 0.00434726\n",
      "Iteration 5262, loss = 0.00434591\n",
      "Iteration 5263, loss = 0.00434457\n",
      "Iteration 5264, loss = 0.00434349\n",
      "Iteration 5265, loss = 0.00434210\n",
      "Iteration 5266, loss = 0.00434136\n",
      "Iteration 5267, loss = 0.00433986\n",
      "Iteration 5268, loss = 0.00433862\n",
      "Iteration 5269, loss = 0.00433732\n",
      "Iteration 5270, loss = 0.00433606\n",
      "Iteration 5271, loss = 0.00433506\n",
      "Iteration 5272, loss = 0.00433381\n",
      "Iteration 5273, loss = 0.00433271\n",
      "Iteration 5274, loss = 0.00433151\n",
      "Iteration 5275, loss = 0.00433031\n",
      "Iteration 5276, loss = 0.00432965\n",
      "Iteration 5277, loss = 0.00432814\n",
      "Iteration 5278, loss = 0.00432699\n",
      "Iteration 5279, loss = 0.00432585\n",
      "Iteration 5280, loss = 0.00432481\n",
      "Iteration 5281, loss = 0.00432378\n",
      "Iteration 5282, loss = 0.00432264\n",
      "Iteration 5283, loss = 0.00432160\n",
      "Iteration 5284, loss = 0.00432039\n",
      "Iteration 5285, loss = 0.00431917\n",
      "Iteration 5286, loss = 0.00431835\n",
      "Iteration 5287, loss = 0.00431706\n",
      "Iteration 5288, loss = 0.00431568\n",
      "Iteration 5289, loss = 0.00431443\n",
      "Iteration 5290, loss = 0.00431327\n",
      "Iteration 5291, loss = 0.00431238\n",
      "Iteration 5292, loss = 0.00431098\n",
      "Iteration 5293, loss = 0.00430983\n",
      "Iteration 5294, loss = 0.00430881\n",
      "Iteration 5295, loss = 0.00430758\n",
      "Iteration 5296, loss = 0.00430641\n",
      "Iteration 5297, loss = 0.00430521\n",
      "Iteration 5298, loss = 0.00430421\n",
      "Iteration 5299, loss = 0.00430289\n",
      "Iteration 5300, loss = 0.00430185\n",
      "Iteration 5301, loss = 0.00430070\n",
      "Iteration 5302, loss = 0.00430002\n",
      "Iteration 5303, loss = 0.00429856\n",
      "Iteration 5304, loss = 0.00429725\n",
      "Iteration 5305, loss = 0.00429606\n",
      "Iteration 5306, loss = 0.00429478\n",
      "Iteration 5307, loss = 0.00429365\n",
      "Iteration 5308, loss = 0.00429255\n",
      "Iteration 5309, loss = 0.00429126\n",
      "Iteration 5310, loss = 0.00429011\n",
      "Iteration 5311, loss = 0.00428868\n",
      "Iteration 5312, loss = 0.00428749\n",
      "Iteration 5313, loss = 0.00428655\n",
      "Iteration 5314, loss = 0.00428529\n",
      "Iteration 5315, loss = 0.00428422\n",
      "Iteration 5316, loss = 0.00428309\n",
      "Iteration 5317, loss = 0.00428224\n",
      "Iteration 5318, loss = 0.00428066\n",
      "Iteration 5319, loss = 0.00427927\n",
      "Iteration 5320, loss = 0.00427832\n",
      "Iteration 5321, loss = 0.00427687\n",
      "Iteration 5322, loss = 0.00427552\n",
      "Iteration 5323, loss = 0.00427450\n",
      "Iteration 5324, loss = 0.00427313\n",
      "Iteration 5325, loss = 0.00427168\n",
      "Iteration 5326, loss = 0.00427058\n",
      "Iteration 5327, loss = 0.00426926\n",
      "Iteration 5328, loss = 0.00426812\n",
      "Iteration 5329, loss = 0.00426708\n",
      "Iteration 5330, loss = 0.00426578\n",
      "Iteration 5331, loss = 0.00426459\n",
      "Iteration 5332, loss = 0.00426322\n",
      "Iteration 5333, loss = 0.00426216\n",
      "Iteration 5334, loss = 0.00426085\n",
      "Iteration 5335, loss = 0.00425956\n",
      "Iteration 5336, loss = 0.00425840\n",
      "Iteration 5337, loss = 0.00425760\n",
      "Iteration 5338, loss = 0.00425592\n",
      "Iteration 5339, loss = 0.00425485\n",
      "Iteration 5340, loss = 0.00425363\n",
      "Iteration 5341, loss = 0.00425250\n",
      "Iteration 5342, loss = 0.00425145\n",
      "Iteration 5343, loss = 0.00425006\n",
      "Iteration 5344, loss = 0.00424919\n",
      "Iteration 5345, loss = 0.00424793\n",
      "Iteration 5346, loss = 0.00424679\n",
      "Iteration 5347, loss = 0.00424581\n",
      "Iteration 5348, loss = 0.00424452\n",
      "Iteration 5349, loss = 0.00424343\n",
      "Iteration 5350, loss = 0.00424228\n",
      "Iteration 5351, loss = 0.00424134\n",
      "Iteration 5352, loss = 0.00423994\n",
      "Iteration 5353, loss = 0.00423891\n",
      "Iteration 5354, loss = 0.00423769\n",
      "Iteration 5355, loss = 0.00423657\n",
      "Iteration 5356, loss = 0.00423527\n",
      "Iteration 5357, loss = 0.00423391\n",
      "Iteration 5358, loss = 0.00423297\n",
      "Iteration 5359, loss = 0.00423184\n",
      "Iteration 5360, loss = 0.00423047\n",
      "Iteration 5361, loss = 0.00422928\n",
      "Iteration 5362, loss = 0.00422823\n",
      "Iteration 5363, loss = 0.00422694\n",
      "Iteration 5364, loss = 0.00422588\n",
      "Iteration 5365, loss = 0.00422473\n",
      "Iteration 5366, loss = 0.00422396\n",
      "Iteration 5367, loss = 0.00422230\n",
      "Iteration 5368, loss = 0.00422125\n",
      "Iteration 5369, loss = 0.00422027\n",
      "Iteration 5370, loss = 0.00421900\n",
      "Iteration 5371, loss = 0.00421797\n",
      "Iteration 5372, loss = 0.00421675\n",
      "Iteration 5373, loss = 0.00421575\n",
      "Iteration 5374, loss = 0.00421461\n",
      "Iteration 5375, loss = 0.00421366\n",
      "Iteration 5376, loss = 0.00421249\n",
      "Iteration 5377, loss = 0.00421131\n",
      "Iteration 5378, loss = 0.00421043\n",
      "Iteration 5379, loss = 0.00420867\n",
      "Iteration 5380, loss = 0.00420781\n",
      "Iteration 5381, loss = 0.00420666\n",
      "Iteration 5382, loss = 0.00420543\n",
      "Iteration 5383, loss = 0.00420420\n",
      "Iteration 5384, loss = 0.00420356\n",
      "Iteration 5385, loss = 0.00420232\n",
      "Iteration 5386, loss = 0.00420141\n",
      "Iteration 5387, loss = 0.00420027\n",
      "Iteration 5388, loss = 0.00419900\n",
      "Iteration 5389, loss = 0.00419803\n",
      "Iteration 5390, loss = 0.00419680\n",
      "Iteration 5391, loss = 0.00419558\n",
      "Iteration 5392, loss = 0.00419441\n",
      "Iteration 5393, loss = 0.00419326\n",
      "Iteration 5394, loss = 0.00419217\n",
      "Iteration 5395, loss = 0.00419103\n",
      "Iteration 5396, loss = 0.00419049\n",
      "Iteration 5397, loss = 0.00418900\n",
      "Iteration 5398, loss = 0.00418772\n",
      "Iteration 5399, loss = 0.00418682\n",
      "Iteration 5400, loss = 0.00418561\n",
      "Iteration 5401, loss = 0.00418440\n",
      "Iteration 5402, loss = 0.00418330\n",
      "Iteration 5403, loss = 0.00418206\n",
      "Iteration 5404, loss = 0.00418106\n",
      "Iteration 5405, loss = 0.00417969\n",
      "Iteration 5406, loss = 0.00417850\n",
      "Iteration 5407, loss = 0.00417731\n",
      "Iteration 5408, loss = 0.00417603\n",
      "Iteration 5409, loss = 0.00417484\n",
      "Iteration 5410, loss = 0.00417355\n",
      "Iteration 5411, loss = 0.00417254\n",
      "Iteration 5412, loss = 0.00417144\n",
      "Iteration 5413, loss = 0.00417097\n",
      "Iteration 5414, loss = 0.00416950\n",
      "Iteration 5415, loss = 0.00416788\n",
      "Iteration 5416, loss = 0.00416680\n",
      "Iteration 5417, loss = 0.00416570\n",
      "Iteration 5418, loss = 0.00416480\n",
      "Iteration 5419, loss = 0.00416351\n",
      "Iteration 5420, loss = 0.00416230\n",
      "Iteration 5421, loss = 0.00416130\n",
      "Iteration 5422, loss = 0.00416007\n",
      "Iteration 5423, loss = 0.00415884\n",
      "Iteration 5424, loss = 0.00415767\n",
      "Iteration 5425, loss = 0.00415652\n",
      "Iteration 5426, loss = 0.00415524\n",
      "Iteration 5427, loss = 0.00415403\n",
      "Iteration 5428, loss = 0.00415294\n",
      "Iteration 5429, loss = 0.00415194\n",
      "Iteration 5430, loss = 0.00415058\n",
      "Iteration 5431, loss = 0.00414945\n",
      "Iteration 5432, loss = 0.00414817\n",
      "Iteration 5433, loss = 0.00414708\n",
      "Iteration 5434, loss = 0.00414578\n",
      "Iteration 5435, loss = 0.00414460\n",
      "Iteration 5436, loss = 0.00414344\n",
      "Iteration 5437, loss = 0.00414252\n",
      "Iteration 5438, loss = 0.00414125\n",
      "Iteration 5439, loss = 0.00414004\n",
      "Iteration 5440, loss = 0.00413902\n",
      "Iteration 5441, loss = 0.00413786\n",
      "Iteration 5442, loss = 0.00413677\n",
      "Iteration 5443, loss = 0.00413553\n",
      "Iteration 5444, loss = 0.00413453\n",
      "Iteration 5445, loss = 0.00413338\n",
      "Iteration 5446, loss = 0.00413223\n",
      "Iteration 5447, loss = 0.00413093\n",
      "Iteration 5448, loss = 0.00412996\n",
      "Iteration 5449, loss = 0.00412864\n",
      "Iteration 5450, loss = 0.00412753\n",
      "Iteration 5451, loss = 0.00412633\n",
      "Iteration 5452, loss = 0.00412523\n",
      "Iteration 5453, loss = 0.00412405\n",
      "Iteration 5454, loss = 0.00412319\n",
      "Iteration 5455, loss = 0.00412189\n",
      "Iteration 5456, loss = 0.00412074\n",
      "Iteration 5457, loss = 0.00411968\n",
      "Iteration 5458, loss = 0.00411848\n",
      "Iteration 5459, loss = 0.00411753\n",
      "Iteration 5460, loss = 0.00411702\n",
      "Iteration 5461, loss = 0.00411561\n",
      "Iteration 5462, loss = 0.00411456\n",
      "Iteration 5463, loss = 0.00411333\n",
      "Iteration 5464, loss = 0.00411237\n",
      "Iteration 5465, loss = 0.00411149\n",
      "Iteration 5466, loss = 0.00411036\n",
      "Iteration 5467, loss = 0.00410931\n",
      "Iteration 5468, loss = 0.00410826\n",
      "Iteration 5469, loss = 0.00410728\n",
      "Iteration 5470, loss = 0.00410622\n",
      "Iteration 5471, loss = 0.00410526\n",
      "Iteration 5472, loss = 0.00410402\n",
      "Iteration 5473, loss = 0.00410296\n",
      "Iteration 5474, loss = 0.00410186\n",
      "Iteration 5475, loss = 0.00410111\n",
      "Iteration 5476, loss = 0.00409982\n",
      "Iteration 5477, loss = 0.00409881\n",
      "Iteration 5478, loss = 0.00409764\n",
      "Iteration 5479, loss = 0.00409657\n",
      "Iteration 5480, loss = 0.00409565\n",
      "Iteration 5481, loss = 0.00409443\n",
      "Iteration 5482, loss = 0.00409347\n",
      "Iteration 5483, loss = 0.00409267\n",
      "Iteration 5484, loss = 0.00409153\n",
      "Iteration 5485, loss = 0.00409040\n",
      "Iteration 5486, loss = 0.00408954\n",
      "Iteration 5487, loss = 0.00408838\n",
      "Iteration 5488, loss = 0.00408732\n",
      "Iteration 5489, loss = 0.00408631\n",
      "Iteration 5490, loss = 0.00408505\n",
      "Iteration 5491, loss = 0.00408414\n",
      "Iteration 5492, loss = 0.00408319\n",
      "Iteration 5493, loss = 0.00408205\n",
      "Iteration 5494, loss = 0.00408120\n",
      "Iteration 5495, loss = 0.00408008\n",
      "Iteration 5496, loss = 0.00407892\n",
      "Iteration 5497, loss = 0.00407793\n",
      "Iteration 5498, loss = 0.00407663\n",
      "Iteration 5499, loss = 0.00407551\n",
      "Iteration 5500, loss = 0.00407421\n",
      "Iteration 5501, loss = 0.00407344\n",
      "Iteration 5502, loss = 0.00407240\n",
      "Iteration 5503, loss = 0.00407135\n",
      "Iteration 5504, loss = 0.00406998\n",
      "Iteration 5505, loss = 0.00406906\n",
      "Iteration 5506, loss = 0.00406794\n",
      "Iteration 5507, loss = 0.00406687\n",
      "Iteration 5508, loss = 0.00406584\n",
      "Iteration 5509, loss = 0.00406477\n",
      "Iteration 5510, loss = 0.00406380\n",
      "Iteration 5511, loss = 0.00406283\n",
      "Iteration 5512, loss = 0.00406172\n",
      "Iteration 5513, loss = 0.00406075\n",
      "Iteration 5514, loss = 0.00405990\n",
      "Iteration 5515, loss = 0.00405875\n",
      "Iteration 5516, loss = 0.00405779\n",
      "Iteration 5517, loss = 0.00405666\n",
      "Iteration 5518, loss = 0.00405583\n",
      "Iteration 5519, loss = 0.00405460\n",
      "Iteration 5520, loss = 0.00405388\n",
      "Iteration 5521, loss = 0.00405294\n",
      "Iteration 5522, loss = 0.00405173\n",
      "Iteration 5523, loss = 0.00405072\n",
      "Iteration 5524, loss = 0.00404955\n",
      "Iteration 5525, loss = 0.00404858\n",
      "Iteration 5526, loss = 0.00404747\n",
      "Iteration 5527, loss = 0.00404662\n",
      "Iteration 5528, loss = 0.00404534\n",
      "Iteration 5529, loss = 0.00404444\n",
      "Iteration 5530, loss = 0.00404307\n",
      "Iteration 5531, loss = 0.00404186\n",
      "Iteration 5532, loss = 0.00404114\n",
      "Iteration 5533, loss = 0.00403950\n",
      "Iteration 5534, loss = 0.00403876\n",
      "Iteration 5535, loss = 0.00403749\n",
      "Iteration 5536, loss = 0.00403621\n",
      "Iteration 5537, loss = 0.00403584\n",
      "Iteration 5538, loss = 0.00403420\n",
      "Iteration 5539, loss = 0.00403347\n",
      "Iteration 5540, loss = 0.00403201\n",
      "Iteration 5541, loss = 0.00403079\n",
      "Iteration 5542, loss = 0.00402995\n",
      "Iteration 5543, loss = 0.00402892\n",
      "Iteration 5544, loss = 0.00402749\n",
      "Iteration 5545, loss = 0.00402641\n",
      "Iteration 5546, loss = 0.00402529\n",
      "Iteration 5547, loss = 0.00402418\n",
      "Iteration 5548, loss = 0.00402309\n",
      "Iteration 5549, loss = 0.00402194\n",
      "Iteration 5550, loss = 0.00402086\n",
      "Iteration 5551, loss = 0.00401963\n",
      "Iteration 5552, loss = 0.00401858\n",
      "Iteration 5553, loss = 0.00401746\n",
      "Iteration 5554, loss = 0.00401641\n",
      "Iteration 5555, loss = 0.00401515\n",
      "Iteration 5556, loss = 0.00401420\n",
      "Iteration 5557, loss = 0.00401296\n",
      "Iteration 5558, loss = 0.00401189\n",
      "Iteration 5559, loss = 0.00401080\n",
      "Iteration 5560, loss = 0.00400969\n",
      "Iteration 5561, loss = 0.00400870\n",
      "Iteration 5562, loss = 0.00400780\n",
      "Iteration 5563, loss = 0.00400664\n",
      "Iteration 5564, loss = 0.00400552\n",
      "Iteration 5565, loss = 0.00400457\n",
      "Iteration 5566, loss = 0.00400332\n",
      "Iteration 5567, loss = 0.00400232\n",
      "Iteration 5568, loss = 0.00400112\n",
      "Iteration 5569, loss = 0.00400007\n",
      "Iteration 5570, loss = 0.00399895\n",
      "Iteration 5571, loss = 0.00399798\n",
      "Iteration 5572, loss = 0.00399710\n",
      "Iteration 5573, loss = 0.00399589\n",
      "Iteration 5574, loss = 0.00399511\n",
      "Iteration 5575, loss = 0.00399381\n",
      "Iteration 5576, loss = 0.00399271\n",
      "Iteration 5577, loss = 0.00399157\n",
      "Iteration 5578, loss = 0.00399039\n",
      "Iteration 5579, loss = 0.00398958\n",
      "Iteration 5580, loss = 0.00398830\n",
      "Iteration 5581, loss = 0.00398708\n",
      "Iteration 5582, loss = 0.00398607\n",
      "Iteration 5583, loss = 0.00398491\n",
      "Iteration 5584, loss = 0.00398394\n",
      "Iteration 5585, loss = 0.00398304\n",
      "Iteration 5586, loss = 0.00398211\n",
      "Iteration 5587, loss = 0.00398133\n",
      "Iteration 5588, loss = 0.00398030\n",
      "Iteration 5589, loss = 0.00397935\n",
      "Iteration 5590, loss = 0.00397831\n",
      "Iteration 5591, loss = 0.00397746\n",
      "Iteration 5592, loss = 0.00397638\n",
      "Iteration 5593, loss = 0.00397538\n",
      "Iteration 5594, loss = 0.00397444\n",
      "Iteration 5595, loss = 0.00397354\n",
      "Iteration 5596, loss = 0.00397253\n",
      "Iteration 5597, loss = 0.00397166\n",
      "Iteration 5598, loss = 0.00397079\n",
      "Iteration 5599, loss = 0.00396996\n",
      "Iteration 5600, loss = 0.00396834\n",
      "Iteration 5601, loss = 0.00396771\n",
      "Iteration 5602, loss = 0.00396639\n",
      "Iteration 5603, loss = 0.00396541\n",
      "Iteration 5604, loss = 0.00396443\n",
      "Iteration 5605, loss = 0.00396352\n",
      "Iteration 5606, loss = 0.00396250\n",
      "Iteration 5607, loss = 0.00396146\n",
      "Iteration 5608, loss = 0.00396042\n",
      "Iteration 5609, loss = 0.00395952\n",
      "Iteration 5610, loss = 0.00395827\n",
      "Iteration 5611, loss = 0.00395708\n",
      "Iteration 5612, loss = 0.00395611\n",
      "Iteration 5613, loss = 0.00395482\n",
      "Iteration 5614, loss = 0.00395395\n",
      "Iteration 5615, loss = 0.00395258\n",
      "Iteration 5616, loss = 0.00395148\n",
      "Iteration 5617, loss = 0.00395012\n",
      "Iteration 5618, loss = 0.00394925\n",
      "Iteration 5619, loss = 0.00394807\n",
      "Iteration 5620, loss = 0.00394677\n",
      "Iteration 5621, loss = 0.00394560\n",
      "Iteration 5622, loss = 0.00394456\n",
      "Iteration 5623, loss = 0.00394328\n",
      "Iteration 5624, loss = 0.00394254\n",
      "Iteration 5625, loss = 0.00394130\n",
      "Iteration 5626, loss = 0.00394035\n",
      "Iteration 5627, loss = 0.00393909\n",
      "Iteration 5628, loss = 0.00393808\n",
      "Iteration 5629, loss = 0.00393712\n",
      "Iteration 5630, loss = 0.00393610\n",
      "Iteration 5631, loss = 0.00393511\n",
      "Iteration 5632, loss = 0.00393432\n",
      "Iteration 5633, loss = 0.00393300\n",
      "Iteration 5634, loss = 0.00393197\n",
      "Iteration 5635, loss = 0.00393079\n",
      "Iteration 5636, loss = 0.00392971\n",
      "Iteration 5637, loss = 0.00392870\n",
      "Iteration 5638, loss = 0.00392748\n",
      "Iteration 5639, loss = 0.00392645\n",
      "Iteration 5640, loss = 0.00392537\n",
      "Iteration 5641, loss = 0.00392448\n",
      "Iteration 5642, loss = 0.00392337\n",
      "Iteration 5643, loss = 0.00392257\n",
      "Iteration 5644, loss = 0.00392103\n",
      "Iteration 5645, loss = 0.00391998\n",
      "Iteration 5646, loss = 0.00391888\n",
      "Iteration 5647, loss = 0.00391779\n",
      "Iteration 5648, loss = 0.00391682\n",
      "Iteration 5649, loss = 0.00391575\n",
      "Iteration 5650, loss = 0.00391473\n",
      "Iteration 5651, loss = 0.00391374\n",
      "Iteration 5652, loss = 0.00391279\n",
      "Iteration 5653, loss = 0.00391187\n",
      "Iteration 5654, loss = 0.00391085\n",
      "Iteration 5655, loss = 0.00391037\n",
      "Iteration 5656, loss = 0.00390895\n",
      "Iteration 5657, loss = 0.00390803\n",
      "Iteration 5658, loss = 0.00390692\n",
      "Iteration 5659, loss = 0.00390612\n",
      "Iteration 5660, loss = 0.00390509\n",
      "Iteration 5661, loss = 0.00390407\n",
      "Iteration 5662, loss = 0.00390318\n",
      "Iteration 5663, loss = 0.00390208\n",
      "Iteration 5664, loss = 0.00390108\n",
      "Iteration 5665, loss = 0.00390038\n",
      "Iteration 5666, loss = 0.00389936\n",
      "Iteration 5667, loss = 0.00389827\n",
      "Iteration 5668, loss = 0.00389737\n",
      "Iteration 5669, loss = 0.00389637\n",
      "Iteration 5670, loss = 0.00389537\n",
      "Iteration 5671, loss = 0.00389444\n",
      "Iteration 5672, loss = 0.00389345\n",
      "Iteration 5673, loss = 0.00389259\n",
      "Iteration 5674, loss = 0.00389142\n",
      "Iteration 5675, loss = 0.00389043\n",
      "Iteration 5676, loss = 0.00388955\n",
      "Iteration 5677, loss = 0.00388843\n",
      "Iteration 5678, loss = 0.00388738\n",
      "Iteration 5679, loss = 0.00388649\n",
      "Iteration 5680, loss = 0.00388542\n",
      "Iteration 5681, loss = 0.00388450\n",
      "Iteration 5682, loss = 0.00388342\n",
      "Iteration 5683, loss = 0.00388243\n",
      "Iteration 5684, loss = 0.00388171\n",
      "Iteration 5685, loss = 0.00388061\n",
      "Iteration 5686, loss = 0.00387966\n",
      "Iteration 5687, loss = 0.00387877\n",
      "Iteration 5688, loss = 0.00387778\n",
      "Iteration 5689, loss = 0.00387695\n",
      "Iteration 5690, loss = 0.00387605\n",
      "Iteration 5691, loss = 0.00387523\n",
      "Iteration 5692, loss = 0.00387435\n",
      "Iteration 5693, loss = 0.00387328\n",
      "Iteration 5694, loss = 0.00387243\n",
      "Iteration 5695, loss = 0.00387122\n",
      "Iteration 5696, loss = 0.00387024\n",
      "Iteration 5697, loss = 0.00386928\n",
      "Iteration 5698, loss = 0.00386819\n",
      "Iteration 5699, loss = 0.00386762\n",
      "Iteration 5700, loss = 0.00386632\n",
      "Iteration 5701, loss = 0.00386526\n",
      "Iteration 5702, loss = 0.00386435\n",
      "Iteration 5703, loss = 0.00386337\n",
      "Iteration 5704, loss = 0.00386238\n",
      "Iteration 5705, loss = 0.00386163\n",
      "Iteration 5706, loss = 0.00386044\n",
      "Iteration 5707, loss = 0.00385950\n",
      "Iteration 5708, loss = 0.00385867\n",
      "Iteration 5709, loss = 0.00385769\n",
      "Iteration 5710, loss = 0.00385712\n",
      "Iteration 5711, loss = 0.00385585\n",
      "Iteration 5712, loss = 0.00385516\n",
      "Iteration 5713, loss = 0.00385408\n",
      "Iteration 5714, loss = 0.00385288\n",
      "Iteration 5715, loss = 0.00385190\n",
      "Iteration 5716, loss = 0.00385086\n",
      "Iteration 5717, loss = 0.00385006\n",
      "Iteration 5718, loss = 0.00384900\n",
      "Iteration 5719, loss = 0.00384836\n",
      "Iteration 5720, loss = 0.00384709\n",
      "Iteration 5721, loss = 0.00384618\n",
      "Iteration 5722, loss = 0.00384517\n",
      "Iteration 5723, loss = 0.00384423\n",
      "Iteration 5724, loss = 0.00384324\n",
      "Iteration 5725, loss = 0.00384220\n",
      "Iteration 5726, loss = 0.00384121\n",
      "Iteration 5727, loss = 0.00384039\n",
      "Iteration 5728, loss = 0.00383953\n",
      "Iteration 5729, loss = 0.00383841\n",
      "Iteration 5730, loss = 0.00383788\n",
      "Iteration 5731, loss = 0.00383662\n",
      "Iteration 5732, loss = 0.00383571\n",
      "Iteration 5733, loss = 0.00383453\n",
      "Iteration 5734, loss = 0.00383357\n",
      "Iteration 5735, loss = 0.00383263\n",
      "Iteration 5736, loss = 0.00383152\n",
      "Iteration 5737, loss = 0.00383068\n",
      "Iteration 5738, loss = 0.00382964\n",
      "Iteration 5739, loss = 0.00382868\n",
      "Iteration 5740, loss = 0.00382782\n",
      "Iteration 5741, loss = 0.00382699\n",
      "Iteration 5742, loss = 0.00382599\n",
      "Iteration 5743, loss = 0.00382511\n",
      "Iteration 5744, loss = 0.00382426\n",
      "Iteration 5745, loss = 0.00382334\n",
      "Iteration 5746, loss = 0.00382323\n",
      "Iteration 5747, loss = 0.00382163\n",
      "Iteration 5748, loss = 0.00382054\n",
      "Iteration 5749, loss = 0.00381972\n",
      "Iteration 5750, loss = 0.00381871\n",
      "Iteration 5751, loss = 0.00381789\n",
      "Iteration 5752, loss = 0.00381691\n",
      "Iteration 5753, loss = 0.00381605\n",
      "Iteration 5754, loss = 0.00381525\n",
      "Iteration 5755, loss = 0.00381427\n",
      "Iteration 5756, loss = 0.00381332\n",
      "Iteration 5757, loss = 0.00381240\n",
      "Iteration 5758, loss = 0.00381142\n",
      "Iteration 5759, loss = 0.00381057\n",
      "Iteration 5760, loss = 0.00380949\n",
      "Iteration 5761, loss = 0.00380834\n",
      "Iteration 5762, loss = 0.00380718\n",
      "Iteration 5763, loss = 0.00380610\n",
      "Iteration 5764, loss = 0.00380504\n",
      "Iteration 5765, loss = 0.00380395\n",
      "Iteration 5766, loss = 0.00380301\n",
      "Iteration 5767, loss = 0.00380203\n",
      "Iteration 5768, loss = 0.00380108\n",
      "Iteration 5769, loss = 0.00379994\n",
      "Iteration 5770, loss = 0.00379914\n",
      "Iteration 5771, loss = 0.00379803\n",
      "Iteration 5772, loss = 0.00379697\n",
      "Iteration 5773, loss = 0.00379602\n",
      "Iteration 5774, loss = 0.00379505\n",
      "Iteration 5775, loss = 0.00379428\n",
      "Iteration 5776, loss = 0.00379315\n",
      "Iteration 5777, loss = 0.00379222\n",
      "Iteration 5778, loss = 0.00379124\n",
      "Iteration 5779, loss = 0.00379021\n",
      "Iteration 5780, loss = 0.00378938\n",
      "Iteration 5781, loss = 0.00378837\n",
      "Iteration 5782, loss = 0.00378740\n",
      "Iteration 5783, loss = 0.00378650\n",
      "Iteration 5784, loss = 0.00378536\n",
      "Iteration 5785, loss = 0.00378436\n",
      "Iteration 5786, loss = 0.00378334\n",
      "Iteration 5787, loss = 0.00378225\n",
      "Iteration 5788, loss = 0.00378124\n",
      "Iteration 5789, loss = 0.00378025\n",
      "Iteration 5790, loss = 0.00377922\n",
      "Iteration 5791, loss = 0.00377828\n",
      "Iteration 5792, loss = 0.00377733\n",
      "Iteration 5793, loss = 0.00377645\n",
      "Iteration 5794, loss = 0.00377546\n",
      "Iteration 5795, loss = 0.00377451\n",
      "Iteration 5796, loss = 0.00377359\n",
      "Iteration 5797, loss = 0.00377264\n",
      "Iteration 5798, loss = 0.00377182\n",
      "Iteration 5799, loss = 0.00377125\n",
      "Iteration 5800, loss = 0.00377010\n",
      "Iteration 5801, loss = 0.00376892\n",
      "Iteration 5802, loss = 0.00376805\n",
      "Iteration 5803, loss = 0.00376701\n",
      "Iteration 5804, loss = 0.00376611\n",
      "Iteration 5805, loss = 0.00376498\n",
      "Iteration 5806, loss = 0.00376394\n",
      "Iteration 5807, loss = 0.00376307\n",
      "Iteration 5808, loss = 0.00376203\n",
      "Iteration 5809, loss = 0.00376107\n",
      "Iteration 5810, loss = 0.00376038\n",
      "Iteration 5811, loss = 0.00375938\n",
      "Iteration 5812, loss = 0.00375834\n",
      "Iteration 5813, loss = 0.00375753\n",
      "Iteration 5814, loss = 0.00375651\n",
      "Iteration 5815, loss = 0.00375567\n",
      "Iteration 5816, loss = 0.00375477\n",
      "Iteration 5817, loss = 0.00375385\n",
      "Iteration 5818, loss = 0.00375288\n",
      "Iteration 5819, loss = 0.00375195\n",
      "Iteration 5820, loss = 0.00375142\n",
      "Iteration 5821, loss = 0.00375030\n",
      "Iteration 5822, loss = 0.00374944\n",
      "Iteration 5823, loss = 0.00374843\n",
      "Iteration 5824, loss = 0.00374777\n",
      "Iteration 5825, loss = 0.00374655\n",
      "Iteration 5826, loss = 0.00374578\n",
      "Iteration 5827, loss = 0.00374480\n",
      "Iteration 5828, loss = 0.00374384\n",
      "Iteration 5829, loss = 0.00374297\n",
      "Iteration 5830, loss = 0.00374212\n",
      "Iteration 5831, loss = 0.00374112\n",
      "Iteration 5832, loss = 0.00374021\n",
      "Iteration 5833, loss = 0.00373943\n",
      "Iteration 5834, loss = 0.00373858\n",
      "Iteration 5835, loss = 0.00373787\n",
      "Iteration 5836, loss = 0.00373695\n",
      "Iteration 5837, loss = 0.00373592\n",
      "Iteration 5838, loss = 0.00373511\n",
      "Iteration 5839, loss = 0.00373416\n",
      "Iteration 5840, loss = 0.00373305\n",
      "Iteration 5841, loss = 0.00373225\n",
      "Iteration 5842, loss = 0.00373118\n",
      "Iteration 5843, loss = 0.00373010\n",
      "Iteration 5844, loss = 0.00372902\n",
      "Iteration 5845, loss = 0.00372797\n",
      "Iteration 5846, loss = 0.00372731\n",
      "Iteration 5847, loss = 0.00372628\n",
      "Iteration 5848, loss = 0.00372521\n",
      "Iteration 5849, loss = 0.00372428\n",
      "Iteration 5850, loss = 0.00372332\n",
      "Iteration 5851, loss = 0.00372258\n",
      "Iteration 5852, loss = 0.00372143\n",
      "Iteration 5853, loss = 0.00372032\n",
      "Iteration 5854, loss = 0.00371939\n",
      "Iteration 5855, loss = 0.00371838\n",
      "Iteration 5856, loss = 0.00371749\n",
      "Iteration 5857, loss = 0.00371644\n",
      "Iteration 5858, loss = 0.00371531\n",
      "Iteration 5859, loss = 0.00371424\n",
      "Iteration 5860, loss = 0.00371340\n",
      "Iteration 5861, loss = 0.00371236\n",
      "Iteration 5862, loss = 0.00371150\n",
      "Iteration 5863, loss = 0.00371062\n",
      "Iteration 5864, loss = 0.00370963\n",
      "Iteration 5865, loss = 0.00370867\n",
      "Iteration 5866, loss = 0.00370769\n",
      "Iteration 5867, loss = 0.00370680\n",
      "Iteration 5868, loss = 0.00370595\n",
      "Iteration 5869, loss = 0.00370500\n",
      "Iteration 5870, loss = 0.00370414\n",
      "Iteration 5871, loss = 0.00370323\n",
      "Iteration 5872, loss = 0.00370230\n",
      "Iteration 5873, loss = 0.00370123\n",
      "Iteration 5874, loss = 0.00370032\n",
      "Iteration 5875, loss = 0.00369935\n",
      "Iteration 5876, loss = 0.00369847\n",
      "Iteration 5877, loss = 0.00369734\n",
      "Iteration 5878, loss = 0.00369634\n",
      "Iteration 5879, loss = 0.00369543\n",
      "Iteration 5880, loss = 0.00369436\n",
      "Iteration 5881, loss = 0.00369360\n",
      "Iteration 5882, loss = 0.00369257\n",
      "Iteration 5883, loss = 0.00369168\n",
      "Iteration 5884, loss = 0.00369072\n",
      "Iteration 5885, loss = 0.00368981\n",
      "Iteration 5886, loss = 0.00368894\n",
      "Iteration 5887, loss = 0.00368791\n",
      "Iteration 5888, loss = 0.00368709\n",
      "Iteration 5889, loss = 0.00368618\n",
      "Iteration 5890, loss = 0.00368517\n",
      "Iteration 5891, loss = 0.00368427\n",
      "Iteration 5892, loss = 0.00368337\n",
      "Iteration 5893, loss = 0.00368247\n",
      "Iteration 5894, loss = 0.00368149\n",
      "Iteration 5895, loss = 0.00368053\n",
      "Iteration 5896, loss = 0.00367956\n",
      "Iteration 5897, loss = 0.00367859\n",
      "Iteration 5898, loss = 0.00367785\n",
      "Iteration 5899, loss = 0.00367676\n",
      "Iteration 5900, loss = 0.00367610\n",
      "Iteration 5901, loss = 0.00367524\n",
      "Iteration 5902, loss = 0.00367419\n",
      "Iteration 5903, loss = 0.00367332\n",
      "Iteration 5904, loss = 0.00367219\n",
      "Iteration 5905, loss = 0.00367108\n",
      "Iteration 5906, loss = 0.00367019\n",
      "Iteration 5907, loss = 0.00366925\n",
      "Iteration 5908, loss = 0.00366823\n",
      "Iteration 5909, loss = 0.00366752\n",
      "Iteration 5910, loss = 0.00366640\n",
      "Iteration 5911, loss = 0.00366564\n",
      "Iteration 5912, loss = 0.00366453\n",
      "Iteration 5913, loss = 0.00366365\n",
      "Iteration 5914, loss = 0.00366285\n",
      "Iteration 5915, loss = 0.00366171\n",
      "Iteration 5916, loss = 0.00366086\n",
      "Iteration 5917, loss = 0.00365986\n",
      "Iteration 5918, loss = 0.00365899\n",
      "Iteration 5919, loss = 0.00365794\n",
      "Iteration 5920, loss = 0.00365707\n",
      "Iteration 5921, loss = 0.00365613\n",
      "Iteration 5922, loss = 0.00365518\n",
      "Iteration 5923, loss = 0.00365441\n",
      "Iteration 5924, loss = 0.00365343\n",
      "Iteration 5925, loss = 0.00365273\n",
      "Iteration 5926, loss = 0.00365182\n",
      "Iteration 5927, loss = 0.00365087\n",
      "Iteration 5928, loss = 0.00365003\n",
      "Iteration 5929, loss = 0.00364924\n",
      "Iteration 5930, loss = 0.00364875\n",
      "Iteration 5931, loss = 0.00364772\n",
      "Iteration 5932, loss = 0.00364697\n",
      "Iteration 5933, loss = 0.00364622\n",
      "Iteration 5934, loss = 0.00364533\n",
      "Iteration 5935, loss = 0.00364445\n",
      "Iteration 5936, loss = 0.00364376\n",
      "Iteration 5937, loss = 0.00364283\n",
      "Iteration 5938, loss = 0.00364181\n",
      "Iteration 5939, loss = 0.00364093\n",
      "Iteration 5940, loss = 0.00363990\n",
      "Iteration 5941, loss = 0.00363889\n",
      "Iteration 5942, loss = 0.00363839\n",
      "Iteration 5943, loss = 0.00363711\n",
      "Iteration 5944, loss = 0.00363614\n",
      "Iteration 5945, loss = 0.00363543\n",
      "Iteration 5946, loss = 0.00363443\n",
      "Iteration 5947, loss = 0.00363343\n",
      "Iteration 5948, loss = 0.00363251\n",
      "Iteration 5949, loss = 0.00363148\n",
      "Iteration 5950, loss = 0.00363076\n",
      "Iteration 5951, loss = 0.00362969\n",
      "Iteration 5952, loss = 0.00362878\n",
      "Iteration 5953, loss = 0.00362775\n",
      "Iteration 5954, loss = 0.00362707\n",
      "Iteration 5955, loss = 0.00362597\n",
      "Iteration 5956, loss = 0.00362500\n",
      "Iteration 5957, loss = 0.00362453\n",
      "Iteration 5958, loss = 0.00362379\n",
      "Iteration 5959, loss = 0.00362243\n",
      "Iteration 5960, loss = 0.00362144\n",
      "Iteration 5961, loss = 0.00362042\n",
      "Iteration 5962, loss = 0.00361943\n",
      "Iteration 5963, loss = 0.00361849\n",
      "Iteration 5964, loss = 0.00361749\n",
      "Iteration 5965, loss = 0.00361659\n",
      "Iteration 5966, loss = 0.00361566\n",
      "Iteration 5967, loss = 0.00361474\n",
      "Iteration 5968, loss = 0.00361383\n",
      "Iteration 5969, loss = 0.00361287\n",
      "Iteration 5970, loss = 0.00361206\n",
      "Iteration 5971, loss = 0.00361118\n",
      "Iteration 5972, loss = 0.00361035\n",
      "Iteration 5973, loss = 0.00360954\n",
      "Iteration 5974, loss = 0.00360863\n",
      "Iteration 5975, loss = 0.00360783\n",
      "Iteration 5976, loss = 0.00360709\n",
      "Iteration 5977, loss = 0.00360636\n",
      "Iteration 5978, loss = 0.00360508\n",
      "Iteration 5979, loss = 0.00360422\n",
      "Iteration 5980, loss = 0.00360337\n",
      "Iteration 5981, loss = 0.00360240\n",
      "Iteration 5982, loss = 0.00360145\n",
      "Iteration 5983, loss = 0.00360088\n",
      "Iteration 5984, loss = 0.00359965\n",
      "Iteration 5985, loss = 0.00359878\n",
      "Iteration 5986, loss = 0.00359785\n",
      "Iteration 5987, loss = 0.00359693\n",
      "Iteration 5988, loss = 0.00359609\n",
      "Iteration 5989, loss = 0.00359517\n",
      "Iteration 5990, loss = 0.00359427\n",
      "Iteration 5991, loss = 0.00359341\n",
      "Iteration 5992, loss = 0.00359238\n",
      "Iteration 5993, loss = 0.00359181\n",
      "Iteration 5994, loss = 0.00359060\n",
      "Iteration 5995, loss = 0.00359004\n",
      "Iteration 5996, loss = 0.00358878\n",
      "Iteration 5997, loss = 0.00358787\n",
      "Iteration 5998, loss = 0.00358704\n",
      "Iteration 5999, loss = 0.00358607\n",
      "Iteration 6000, loss = 0.00358514\n",
      "Iteration 6001, loss = 0.00358434\n",
      "Iteration 6002, loss = 0.00358351\n",
      "Iteration 6003, loss = 0.00358255\n",
      "Iteration 6004, loss = 0.00358183\n",
      "Iteration 6005, loss = 0.00358089\n",
      "Iteration 6006, loss = 0.00358001\n",
      "Iteration 6007, loss = 0.00357904\n",
      "Iteration 6008, loss = 0.00357813\n",
      "Iteration 6009, loss = 0.00357730\n",
      "Iteration 6010, loss = 0.00357641\n",
      "Iteration 6011, loss = 0.00357554\n",
      "Iteration 6012, loss = 0.00357466\n",
      "Iteration 6013, loss = 0.00357381\n",
      "Iteration 6014, loss = 0.00357290\n",
      "Iteration 6015, loss = 0.00357205\n",
      "Iteration 6016, loss = 0.00357141\n",
      "Iteration 6017, loss = 0.00357037\n",
      "Iteration 6018, loss = 0.00356941\n",
      "Iteration 6019, loss = 0.00356848\n",
      "Iteration 6020, loss = 0.00356768\n",
      "Iteration 6021, loss = 0.00356680\n",
      "Iteration 6022, loss = 0.00356575\n",
      "Iteration 6023, loss = 0.00356500\n",
      "Iteration 6024, loss = 0.00356404\n",
      "Iteration 6025, loss = 0.00356312\n",
      "Iteration 6026, loss = 0.00356228\n",
      "Iteration 6027, loss = 0.00356134\n",
      "Iteration 6028, loss = 0.00356058\n",
      "Iteration 6029, loss = 0.00355982\n",
      "Iteration 6030, loss = 0.00355895\n",
      "Iteration 6031, loss = 0.00355791\n",
      "Iteration 6032, loss = 0.00355742\n",
      "Iteration 6033, loss = 0.00355629\n",
      "Iteration 6034, loss = 0.00355563\n",
      "Iteration 6035, loss = 0.00355472\n",
      "Iteration 6036, loss = 0.00355370\n",
      "Iteration 6037, loss = 0.00355285\n",
      "Iteration 6038, loss = 0.00355210\n",
      "Iteration 6039, loss = 0.00355123\n",
      "Iteration 6040, loss = 0.00355036\n",
      "Iteration 6041, loss = 0.00354958\n",
      "Iteration 6042, loss = 0.00354879\n",
      "Iteration 6043, loss = 0.00354793\n",
      "Iteration 6044, loss = 0.00354711\n",
      "Iteration 6045, loss = 0.00354631\n",
      "Iteration 6046, loss = 0.00354538\n",
      "Iteration 6047, loss = 0.00354464\n",
      "Iteration 6048, loss = 0.00354373\n",
      "Iteration 6049, loss = 0.00354287\n",
      "Iteration 6050, loss = 0.00354194\n",
      "Iteration 6051, loss = 0.00354142\n",
      "Iteration 6052, loss = 0.00354040\n",
      "Iteration 6053, loss = 0.00353957\n",
      "Iteration 6054, loss = 0.00353872\n",
      "Iteration 6055, loss = 0.00353793\n",
      "Iteration 6056, loss = 0.00353713\n",
      "Iteration 6057, loss = 0.00353628\n",
      "Iteration 6058, loss = 0.00353549\n",
      "Iteration 6059, loss = 0.00353468\n",
      "Iteration 6060, loss = 0.00353387\n",
      "Iteration 6061, loss = 0.00353320\n",
      "Iteration 6062, loss = 0.00353232\n",
      "Iteration 6063, loss = 0.00353158\n",
      "Iteration 6064, loss = 0.00353070\n",
      "Iteration 6065, loss = 0.00352990\n",
      "Iteration 6066, loss = 0.00352913\n",
      "Iteration 6067, loss = 0.00352827\n",
      "Iteration 6068, loss = 0.00352742\n",
      "Iteration 6069, loss = 0.00352661\n",
      "Iteration 6070, loss = 0.00352581\n",
      "Iteration 6071, loss = 0.00352489\n",
      "Iteration 6072, loss = 0.00352415\n",
      "Iteration 6073, loss = 0.00352332\n",
      "Iteration 6074, loss = 0.00352252\n",
      "Iteration 6075, loss = 0.00352170\n",
      "Iteration 6076, loss = 0.00352072\n",
      "Iteration 6077, loss = 0.00351993\n",
      "Iteration 6078, loss = 0.00351905\n",
      "Iteration 6079, loss = 0.00351824\n",
      "Iteration 6080, loss = 0.00351737\n",
      "Iteration 6081, loss = 0.00351658\n",
      "Iteration 6082, loss = 0.00351575\n",
      "Iteration 6083, loss = 0.00351488\n",
      "Iteration 6084, loss = 0.00351400\n",
      "Iteration 6085, loss = 0.00351336\n",
      "Iteration 6086, loss = 0.00351231\n",
      "Iteration 6087, loss = 0.00351166\n",
      "Iteration 6088, loss = 0.00351071\n",
      "Iteration 6089, loss = 0.00351003\n",
      "Iteration 6090, loss = 0.00350938\n",
      "Iteration 6091, loss = 0.00350834\n",
      "Iteration 6092, loss = 0.00350766\n",
      "Iteration 6093, loss = 0.00350658\n",
      "Iteration 6094, loss = 0.00350578\n",
      "Iteration 6095, loss = 0.00350495\n",
      "Iteration 6096, loss = 0.00350410\n",
      "Iteration 6097, loss = 0.00350330\n",
      "Iteration 6098, loss = 0.00350246\n",
      "Iteration 6099, loss = 0.00350160\n",
      "Iteration 6100, loss = 0.00350092\n",
      "Iteration 6101, loss = 0.00349988\n",
      "Iteration 6102, loss = 0.00349897\n",
      "Iteration 6103, loss = 0.00349805\n",
      "Iteration 6104, loss = 0.00349721\n",
      "Iteration 6105, loss = 0.00349661\n",
      "Iteration 6106, loss = 0.00349576\n",
      "Iteration 6107, loss = 0.00349488\n",
      "Iteration 6108, loss = 0.00349462\n",
      "Iteration 6109, loss = 0.00349330\n",
      "Iteration 6110, loss = 0.00349243\n",
      "Iteration 6111, loss = 0.00349158\n",
      "Iteration 6112, loss = 0.00349084\n",
      "Iteration 6113, loss = 0.00348988\n",
      "Iteration 6114, loss = 0.00348902\n",
      "Iteration 6115, loss = 0.00348846\n",
      "Iteration 6116, loss = 0.00348739\n",
      "Iteration 6117, loss = 0.00348648\n",
      "Iteration 6118, loss = 0.00348572\n",
      "Iteration 6119, loss = 0.00348496\n",
      "Iteration 6120, loss = 0.00348430\n",
      "Iteration 6121, loss = 0.00348362\n",
      "Iteration 6122, loss = 0.00348269\n",
      "Iteration 6123, loss = 0.00348189\n",
      "Iteration 6124, loss = 0.00348107\n",
      "Iteration 6125, loss = 0.00348029\n",
      "Iteration 6126, loss = 0.00347952\n",
      "Iteration 6127, loss = 0.00347850\n",
      "Iteration 6128, loss = 0.00347755\n",
      "Iteration 6129, loss = 0.00347670\n",
      "Iteration 6130, loss = 0.00347587\n",
      "Iteration 6131, loss = 0.00347472\n",
      "Iteration 6132, loss = 0.00347385\n",
      "Iteration 6133, loss = 0.00347294\n",
      "Iteration 6134, loss = 0.00347229\n",
      "Iteration 6135, loss = 0.00347111\n",
      "Iteration 6136, loss = 0.00347066\n",
      "Iteration 6137, loss = 0.00346963\n",
      "Iteration 6138, loss = 0.00346890\n",
      "Iteration 6139, loss = 0.00346808\n",
      "Iteration 6140, loss = 0.00346734\n",
      "Iteration 6141, loss = 0.00346655\n",
      "Iteration 6142, loss = 0.00346596\n",
      "Iteration 6143, loss = 0.00346511\n",
      "Iteration 6144, loss = 0.00346467\n",
      "Iteration 6145, loss = 0.00346373\n",
      "Iteration 6146, loss = 0.00346254\n",
      "Iteration 6147, loss = 0.00346197\n",
      "Iteration 6148, loss = 0.00346090\n",
      "Iteration 6149, loss = 0.00346023\n",
      "Iteration 6150, loss = 0.00345914\n",
      "Iteration 6151, loss = 0.00345835\n",
      "Iteration 6152, loss = 0.00345758\n",
      "Iteration 6153, loss = 0.00345652\n",
      "Iteration 6154, loss = 0.00345561\n",
      "Iteration 6155, loss = 0.00345481\n",
      "Iteration 6156, loss = 0.00345393\n",
      "Iteration 6157, loss = 0.00345319\n",
      "Iteration 6158, loss = 0.00345221\n",
      "Iteration 6159, loss = 0.00345129\n",
      "Iteration 6160, loss = 0.00345052\n",
      "Iteration 6161, loss = 0.00344966\n",
      "Iteration 6162, loss = 0.00344893\n",
      "Iteration 6163, loss = 0.00344797\n",
      "Iteration 6164, loss = 0.00344739\n",
      "Iteration 6165, loss = 0.00344625\n",
      "Iteration 6166, loss = 0.00344538\n",
      "Iteration 6167, loss = 0.00344456\n",
      "Iteration 6168, loss = 0.00344365\n",
      "Iteration 6169, loss = 0.00344279\n",
      "Iteration 6170, loss = 0.00344193\n",
      "Iteration 6171, loss = 0.00344111\n",
      "Iteration 6172, loss = 0.00344063\n",
      "Iteration 6173, loss = 0.00343934\n",
      "Iteration 6174, loss = 0.00343861\n",
      "Iteration 6175, loss = 0.00343770\n",
      "Iteration 6176, loss = 0.00343687\n",
      "Iteration 6177, loss = 0.00343601\n",
      "Iteration 6178, loss = 0.00343501\n",
      "Iteration 6179, loss = 0.00343412\n",
      "Iteration 6180, loss = 0.00343373\n",
      "Iteration 6181, loss = 0.00343271\n",
      "Iteration 6182, loss = 0.00343186\n",
      "Iteration 6183, loss = 0.00343107\n",
      "Iteration 6184, loss = 0.00343025\n",
      "Iteration 6185, loss = 0.00342949\n",
      "Iteration 6186, loss = 0.00342864\n",
      "Iteration 6187, loss = 0.00342779\n",
      "Iteration 6188, loss = 0.00342694\n",
      "Iteration 6189, loss = 0.00342602\n",
      "Iteration 6190, loss = 0.00342531\n",
      "Iteration 6191, loss = 0.00342450\n",
      "Iteration 6192, loss = 0.00342364\n",
      "Iteration 6193, loss = 0.00342287\n",
      "Iteration 6194, loss = 0.00342192\n",
      "Iteration 6195, loss = 0.00342120\n",
      "Iteration 6196, loss = 0.00342020\n",
      "Iteration 6197, loss = 0.00341944\n",
      "Iteration 6198, loss = 0.00341852\n",
      "Iteration 6199, loss = 0.00341772\n",
      "Iteration 6200, loss = 0.00341699\n",
      "Iteration 6201, loss = 0.00341605\n",
      "Iteration 6202, loss = 0.00341524\n",
      "Iteration 6203, loss = 0.00341450\n",
      "Iteration 6204, loss = 0.00341369\n",
      "Iteration 6205, loss = 0.00341278\n",
      "Iteration 6206, loss = 0.00341198\n",
      "Iteration 6207, loss = 0.00341108\n",
      "Iteration 6208, loss = 0.00341032\n",
      "Iteration 6209, loss = 0.00340966\n",
      "Iteration 6210, loss = 0.00340870\n",
      "Iteration 6211, loss = 0.00340779\n",
      "Iteration 6212, loss = 0.00340694\n",
      "Iteration 6213, loss = 0.00340617\n",
      "Iteration 6214, loss = 0.00340533\n",
      "Iteration 6215, loss = 0.00340448\n",
      "Iteration 6216, loss = 0.00340365\n",
      "Iteration 6217, loss = 0.00340295\n",
      "Iteration 6218, loss = 0.00340201\n",
      "Iteration 6219, loss = 0.00340128\n",
      "Iteration 6220, loss = 0.00340053\n",
      "Iteration 6221, loss = 0.00339964\n",
      "Iteration 6222, loss = 0.00339889\n",
      "Iteration 6223, loss = 0.00339811\n",
      "Iteration 6224, loss = 0.00339729\n",
      "Iteration 6225, loss = 0.00339642\n",
      "Iteration 6226, loss = 0.00339559\n",
      "Iteration 6227, loss = 0.00339465\n",
      "Iteration 6228, loss = 0.00339380\n",
      "Iteration 6229, loss = 0.00339315\n",
      "Iteration 6230, loss = 0.00339235\n",
      "Iteration 6231, loss = 0.00339178\n",
      "Iteration 6232, loss = 0.00339068\n",
      "Iteration 6233, loss = 0.00338990\n",
      "Iteration 6234, loss = 0.00338919\n",
      "Iteration 6235, loss = 0.00338831\n",
      "Iteration 6236, loss = 0.00338748\n",
      "Iteration 6237, loss = 0.00338667\n",
      "Iteration 6238, loss = 0.00338585\n",
      "Iteration 6239, loss = 0.00338546\n",
      "Iteration 6240, loss = 0.00338443\n",
      "Iteration 6241, loss = 0.00338361\n",
      "Iteration 6242, loss = 0.00338290\n",
      "Iteration 6243, loss = 0.00338215\n",
      "Iteration 6244, loss = 0.00338170\n",
      "Iteration 6245, loss = 0.00338068\n",
      "Iteration 6246, loss = 0.00337987\n",
      "Iteration 6247, loss = 0.00337916\n",
      "Iteration 6248, loss = 0.00337837\n",
      "Iteration 6249, loss = 0.00337736\n",
      "Iteration 6250, loss = 0.00337649\n",
      "Iteration 6251, loss = 0.00337583\n",
      "Iteration 6252, loss = 0.00337506\n",
      "Iteration 6253, loss = 0.00337433\n",
      "Iteration 6254, loss = 0.00337343\n",
      "Iteration 6255, loss = 0.00337263\n",
      "Iteration 6256, loss = 0.00337182\n",
      "Iteration 6257, loss = 0.00337132\n",
      "Iteration 6258, loss = 0.00337035\n",
      "Iteration 6259, loss = 0.00336957\n",
      "Iteration 6260, loss = 0.00336863\n",
      "Iteration 6261, loss = 0.00336788\n",
      "Iteration 6262, loss = 0.00336711\n",
      "Iteration 6263, loss = 0.00336649\n",
      "Iteration 6264, loss = 0.00336568\n",
      "Iteration 6265, loss = 0.00336521\n",
      "Iteration 6266, loss = 0.00336436\n",
      "Iteration 6267, loss = 0.00336367\n",
      "Iteration 6268, loss = 0.00336295\n",
      "Iteration 6269, loss = 0.00336230\n",
      "Iteration 6270, loss = 0.00336170\n",
      "Iteration 6271, loss = 0.00336091\n",
      "Iteration 6272, loss = 0.00336023\n",
      "Iteration 6273, loss = 0.00335943\n",
      "Iteration 6274, loss = 0.00335864\n",
      "Iteration 6275, loss = 0.00335794\n",
      "Iteration 6276, loss = 0.00335716\n",
      "Iteration 6277, loss = 0.00335650\n",
      "Iteration 6278, loss = 0.00335571\n",
      "Iteration 6279, loss = 0.00335494\n",
      "Iteration 6280, loss = 0.00335428\n",
      "Iteration 6281, loss = 0.00335346\n",
      "Iteration 6282, loss = 0.00335264\n",
      "Iteration 6283, loss = 0.00335193\n",
      "Iteration 6284, loss = 0.00335116\n",
      "Iteration 6285, loss = 0.00335050\n",
      "Iteration 6286, loss = 0.00334967\n",
      "Iteration 6287, loss = 0.00334898\n",
      "Iteration 6288, loss = 0.00334824\n",
      "Iteration 6289, loss = 0.00334749\n",
      "Iteration 6290, loss = 0.00334677\n",
      "Iteration 6291, loss = 0.00334603\n",
      "Iteration 6292, loss = 0.00334533\n",
      "Iteration 6293, loss = 0.00334507\n",
      "Iteration 6294, loss = 0.00334382\n",
      "Iteration 6295, loss = 0.00334318\n",
      "Iteration 6296, loss = 0.00334223\n",
      "Iteration 6297, loss = 0.00334154\n",
      "Iteration 6298, loss = 0.00334071\n",
      "Iteration 6299, loss = 0.00334006\n",
      "Iteration 6300, loss = 0.00333939\n",
      "Iteration 6301, loss = 0.00333863\n",
      "Iteration 6302, loss = 0.00333807\n",
      "Iteration 6303, loss = 0.00333738\n",
      "Iteration 6304, loss = 0.00333677\n",
      "Iteration 6305, loss = 0.00333605\n",
      "Iteration 6306, loss = 0.00333522\n",
      "Iteration 6307, loss = 0.00333456\n",
      "Iteration 6308, loss = 0.00333383\n",
      "Iteration 6309, loss = 0.00333317\n",
      "Iteration 6310, loss = 0.00333247\n",
      "Iteration 6311, loss = 0.00333178\n",
      "Iteration 6312, loss = 0.00333112\n",
      "Iteration 6313, loss = 0.00333041\n",
      "Iteration 6314, loss = 0.00332982\n",
      "Iteration 6315, loss = 0.00332903\n",
      "Iteration 6316, loss = 0.00332836\n",
      "Iteration 6317, loss = 0.00332755\n",
      "Iteration 6318, loss = 0.00332685\n",
      "Iteration 6319, loss = 0.00332610\n",
      "Iteration 6320, loss = 0.00332542\n",
      "Iteration 6321, loss = 0.00332463\n",
      "Iteration 6322, loss = 0.00332405\n",
      "Iteration 6323, loss = 0.00332363\n",
      "Iteration 6324, loss = 0.00332274\n",
      "Iteration 6325, loss = 0.00332197\n",
      "Iteration 6326, loss = 0.00332135\n",
      "Iteration 6327, loss = 0.00332113\n",
      "Iteration 6328, loss = 0.00332026\n",
      "Iteration 6329, loss = 0.00331976\n",
      "Iteration 6330, loss = 0.00331889\n",
      "Iteration 6331, loss = 0.00331828\n",
      "Iteration 6332, loss = 0.00331748\n",
      "Iteration 6333, loss = 0.00331672\n",
      "Iteration 6334, loss = 0.00331594\n",
      "Iteration 6335, loss = 0.00331514\n",
      "Iteration 6336, loss = 0.00331441\n",
      "Iteration 6337, loss = 0.00331371\n",
      "Iteration 6338, loss = 0.00331302\n",
      "Iteration 6339, loss = 0.00331228\n",
      "Iteration 6340, loss = 0.00331174\n",
      "Iteration 6341, loss = 0.00331141\n",
      "Iteration 6342, loss = 0.00331059\n",
      "Iteration 6343, loss = 0.00331008\n",
      "Iteration 6344, loss = 0.00330927\n",
      "Iteration 6345, loss = 0.00330856\n",
      "Iteration 6346, loss = 0.00330785\n",
      "Iteration 6347, loss = 0.00330717\n",
      "Iteration 6348, loss = 0.00330655\n",
      "Iteration 6349, loss = 0.00330599\n",
      "Iteration 6350, loss = 0.00330511\n",
      "Iteration 6351, loss = 0.00330436\n",
      "Iteration 6352, loss = 0.00330314\n",
      "Iteration 6353, loss = 0.00330227\n",
      "Iteration 6354, loss = 0.00330123\n",
      "Iteration 6355, loss = 0.00330067\n",
      "Iteration 6356, loss = 0.00329947\n",
      "Iteration 6357, loss = 0.00329854\n",
      "Iteration 6358, loss = 0.00329782\n",
      "Iteration 6359, loss = 0.00329677\n",
      "Iteration 6360, loss = 0.00329589\n",
      "Iteration 6361, loss = 0.00329492\n",
      "Iteration 6362, loss = 0.00329422\n",
      "Iteration 6363, loss = 0.00329319\n",
      "Iteration 6364, loss = 0.00329235\n",
      "Iteration 6365, loss = 0.00329158\n",
      "Iteration 6366, loss = 0.00329071\n",
      "Iteration 6367, loss = 0.00328985\n",
      "Iteration 6368, loss = 0.00328913\n",
      "Iteration 6369, loss = 0.00328842\n",
      "Iteration 6370, loss = 0.00328774\n",
      "Iteration 6371, loss = 0.00328701\n",
      "Iteration 6372, loss = 0.00328641\n",
      "Iteration 6373, loss = 0.00328578\n",
      "Iteration 6374, loss = 0.00328498\n",
      "Iteration 6375, loss = 0.00328433\n",
      "Iteration 6376, loss = 0.00328363\n",
      "Iteration 6377, loss = 0.00328295\n",
      "Iteration 6378, loss = 0.00328224\n",
      "Iteration 6379, loss = 0.00328153\n",
      "Iteration 6380, loss = 0.00328083\n",
      "Iteration 6381, loss = 0.00328018\n",
      "Iteration 6382, loss = 0.00327939\n",
      "Iteration 6383, loss = 0.00327857\n",
      "Iteration 6384, loss = 0.00327791\n",
      "Iteration 6385, loss = 0.00327693\n",
      "Iteration 6386, loss = 0.00327621\n",
      "Iteration 6387, loss = 0.00327546\n",
      "Iteration 6388, loss = 0.00327469\n",
      "Iteration 6389, loss = 0.00327398\n",
      "Iteration 6390, loss = 0.00327330\n",
      "Iteration 6391, loss = 0.00327260\n",
      "Iteration 6392, loss = 0.00327173\n",
      "Iteration 6393, loss = 0.00327110\n",
      "Iteration 6394, loss = 0.00327012\n",
      "Iteration 6395, loss = 0.00326951\n",
      "Iteration 6396, loss = 0.00326864\n",
      "Iteration 6397, loss = 0.00326777\n",
      "Iteration 6398, loss = 0.00326699\n",
      "Iteration 6399, loss = 0.00326637\n",
      "Iteration 6400, loss = 0.00326529\n",
      "Iteration 6401, loss = 0.00326438\n",
      "Iteration 6402, loss = 0.00326375\n",
      "Iteration 6403, loss = 0.00326260\n",
      "Iteration 6404, loss = 0.00326171\n",
      "Iteration 6405, loss = 0.00326084\n",
      "Iteration 6406, loss = 0.00326004\n",
      "Iteration 6407, loss = 0.00325926\n",
      "Iteration 6408, loss = 0.00325832\n",
      "Iteration 6409, loss = 0.00325763\n",
      "Iteration 6410, loss = 0.00325689\n",
      "Iteration 6411, loss = 0.00325613\n",
      "Iteration 6412, loss = 0.00325539\n",
      "Iteration 6413, loss = 0.00325468\n",
      "Iteration 6414, loss = 0.00325386\n",
      "Iteration 6415, loss = 0.00325301\n",
      "Iteration 6416, loss = 0.00325214\n",
      "Iteration 6417, loss = 0.00325130\n",
      "Iteration 6418, loss = 0.00325045\n",
      "Iteration 6419, loss = 0.00324960\n",
      "Iteration 6420, loss = 0.00324865\n",
      "Iteration 6421, loss = 0.00324818\n",
      "Iteration 6422, loss = 0.00324717\n",
      "Iteration 6423, loss = 0.00324657\n",
      "Iteration 6424, loss = 0.00324560\n",
      "Iteration 6425, loss = 0.00324491\n",
      "Iteration 6426, loss = 0.00324420\n",
      "Iteration 6427, loss = 0.00324343\n",
      "Iteration 6428, loss = 0.00324274\n",
      "Iteration 6429, loss = 0.00324207\n",
      "Iteration 6430, loss = 0.00324136\n",
      "Iteration 6431, loss = 0.00324066\n",
      "Iteration 6432, loss = 0.00323993\n",
      "Iteration 6433, loss = 0.00323928\n",
      "Iteration 6434, loss = 0.00323850\n",
      "Iteration 6435, loss = 0.00323768\n",
      "Iteration 6436, loss = 0.00323697\n",
      "Iteration 6437, loss = 0.00323618\n",
      "Iteration 6438, loss = 0.00323546\n",
      "Iteration 6439, loss = 0.00323464\n",
      "Iteration 6440, loss = 0.00323389\n",
      "Iteration 6441, loss = 0.00323322\n",
      "Iteration 6442, loss = 0.00323254\n",
      "Iteration 6443, loss = 0.00323190\n",
      "Iteration 6444, loss = 0.00323129\n",
      "Iteration 6445, loss = 0.00323065\n",
      "Iteration 6446, loss = 0.00323000\n",
      "Iteration 6447, loss = 0.00322959\n",
      "Iteration 6448, loss = 0.00322847\n",
      "Iteration 6449, loss = 0.00322761\n",
      "Iteration 6450, loss = 0.00322686\n",
      "Iteration 6451, loss = 0.00322596\n",
      "Iteration 6452, loss = 0.00322514\n",
      "Iteration 6453, loss = 0.00322429\n",
      "Iteration 6454, loss = 0.00322355\n",
      "Iteration 6455, loss = 0.00322278\n",
      "Iteration 6456, loss = 0.00322187\n",
      "Iteration 6457, loss = 0.00322110\n",
      "Iteration 6458, loss = 0.00322041\n",
      "Iteration 6459, loss = 0.00321970\n",
      "Iteration 6460, loss = 0.00321905\n",
      "Iteration 6461, loss = 0.00321827\n",
      "Iteration 6462, loss = 0.00321761\n",
      "Iteration 6463, loss = 0.00321679\n",
      "Iteration 6464, loss = 0.00321612\n",
      "Iteration 6465, loss = 0.00321545\n",
      "Iteration 6466, loss = 0.00321464\n",
      "Iteration 6467, loss = 0.00321384\n",
      "Iteration 6468, loss = 0.00321312\n",
      "Iteration 6469, loss = 0.00321231\n",
      "Iteration 6470, loss = 0.00321156\n",
      "Iteration 6471, loss = 0.00321077\n",
      "Iteration 6472, loss = 0.00320989\n",
      "Iteration 6473, loss = 0.00320909\n",
      "Iteration 6474, loss = 0.00320820\n",
      "Iteration 6475, loss = 0.00320785\n",
      "Iteration 6476, loss = 0.00320696\n",
      "Iteration 6477, loss = 0.00320607\n",
      "Iteration 6478, loss = 0.00320533\n",
      "Iteration 6479, loss = 0.00320458\n",
      "Iteration 6480, loss = 0.00320387\n",
      "Iteration 6481, loss = 0.00320315\n",
      "Iteration 6482, loss = 0.00320255\n",
      "Iteration 6483, loss = 0.00320170\n",
      "Iteration 6484, loss = 0.00320106\n",
      "Iteration 6485, loss = 0.00320036\n",
      "Iteration 6486, loss = 0.00319966\n",
      "Iteration 6487, loss = 0.00319897\n",
      "Iteration 6488, loss = 0.00319836\n",
      "Iteration 6489, loss = 0.00319761\n",
      "Iteration 6490, loss = 0.00319682\n",
      "Iteration 6491, loss = 0.00319602\n",
      "Iteration 6492, loss = 0.00319560\n",
      "Iteration 6493, loss = 0.00319493\n",
      "Iteration 6494, loss = 0.00319391\n",
      "Iteration 6495, loss = 0.00319304\n",
      "Iteration 6496, loss = 0.00319251\n",
      "Iteration 6497, loss = 0.00319169\n",
      "Iteration 6498, loss = 0.00319083\n",
      "Iteration 6499, loss = 0.00319015\n",
      "Iteration 6500, loss = 0.00318938\n",
      "Iteration 6501, loss = 0.00318866\n",
      "Iteration 6502, loss = 0.00318798\n",
      "Iteration 6503, loss = 0.00318746\n",
      "Iteration 6504, loss = 0.00318654\n",
      "Iteration 6505, loss = 0.00318580\n",
      "Iteration 6506, loss = 0.00318504\n",
      "Iteration 6507, loss = 0.00318438\n",
      "Iteration 6508, loss = 0.00318372\n",
      "Iteration 6509, loss = 0.00318285\n",
      "Iteration 6510, loss = 0.00318215\n",
      "Iteration 6511, loss = 0.00318140\n",
      "Iteration 6512, loss = 0.00318081\n",
      "Iteration 6513, loss = 0.00318008\n",
      "Iteration 6514, loss = 0.00317938\n",
      "Iteration 6515, loss = 0.00317870\n",
      "Iteration 6516, loss = 0.00317809\n",
      "Iteration 6517, loss = 0.00317736\n",
      "Iteration 6518, loss = 0.00317659\n",
      "Iteration 6519, loss = 0.00317592\n",
      "Iteration 6520, loss = 0.00317545\n",
      "Iteration 6521, loss = 0.00317453\n",
      "Iteration 6522, loss = 0.00317385\n",
      "Iteration 6523, loss = 0.00317319\n",
      "Iteration 6524, loss = 0.00317231\n",
      "Iteration 6525, loss = 0.00317165\n",
      "Iteration 6526, loss = 0.00317091\n",
      "Iteration 6527, loss = 0.00317027\n",
      "Iteration 6528, loss = 0.00316943\n",
      "Iteration 6529, loss = 0.00316869\n",
      "Iteration 6530, loss = 0.00316796\n",
      "Iteration 6531, loss = 0.00316715\n",
      "Iteration 6532, loss = 0.00316644\n",
      "Iteration 6533, loss = 0.00316576\n",
      "Iteration 6534, loss = 0.00316503\n",
      "Iteration 6535, loss = 0.00316434\n",
      "Iteration 6536, loss = 0.00316364\n",
      "Iteration 6537, loss = 0.00316292\n",
      "Iteration 6538, loss = 0.00316221\n",
      "Iteration 6539, loss = 0.00316149\n",
      "Iteration 6540, loss = 0.00316081\n",
      "Iteration 6541, loss = 0.00316028\n",
      "Iteration 6542, loss = 0.00315957\n",
      "Iteration 6543, loss = 0.00315884\n",
      "Iteration 6544, loss = 0.00315824\n",
      "Iteration 6545, loss = 0.00315753\n",
      "Iteration 6546, loss = 0.00315695\n",
      "Iteration 6547, loss = 0.00315619\n",
      "Iteration 6548, loss = 0.00315558\n",
      "Iteration 6549, loss = 0.00315477\n",
      "Iteration 6550, loss = 0.00315425\n",
      "Iteration 6551, loss = 0.00315340\n",
      "Iteration 6552, loss = 0.00315270\n",
      "Iteration 6553, loss = 0.00315198\n",
      "Iteration 6554, loss = 0.00315129\n",
      "Iteration 6555, loss = 0.00315056\n",
      "Iteration 6556, loss = 0.00314979\n",
      "Iteration 6557, loss = 0.00314918\n",
      "Iteration 6558, loss = 0.00314841\n",
      "Iteration 6559, loss = 0.00314769\n",
      "Iteration 6560, loss = 0.00314713\n",
      "Iteration 6561, loss = 0.00314621\n",
      "Iteration 6562, loss = 0.00314555\n",
      "Iteration 6563, loss = 0.00314468\n",
      "Iteration 6564, loss = 0.00314395\n",
      "Iteration 6565, loss = 0.00314321\n",
      "Iteration 6566, loss = 0.00314250\n",
      "Iteration 6567, loss = 0.00314179\n",
      "Iteration 6568, loss = 0.00314106\n",
      "Iteration 6569, loss = 0.00314022\n",
      "Iteration 6570, loss = 0.00313947\n",
      "Iteration 6571, loss = 0.00313878\n",
      "Iteration 6572, loss = 0.00313804\n",
      "Iteration 6573, loss = 0.00313734\n",
      "Iteration 6574, loss = 0.00313665\n",
      "Iteration 6575, loss = 0.00313595\n",
      "Iteration 6576, loss = 0.00313511\n",
      "Iteration 6577, loss = 0.00313449\n",
      "Iteration 6578, loss = 0.00313395\n",
      "Iteration 6579, loss = 0.00313304\n",
      "Iteration 6580, loss = 0.00313233\n",
      "Iteration 6581, loss = 0.00313177\n",
      "Iteration 6582, loss = 0.00313091\n",
      "Iteration 6583, loss = 0.00313013\n",
      "Iteration 6584, loss = 0.00312939\n",
      "Iteration 6585, loss = 0.00312870\n",
      "Iteration 6586, loss = 0.00312794\n",
      "Iteration 6587, loss = 0.00312717\n",
      "Iteration 6588, loss = 0.00312657\n",
      "Iteration 6589, loss = 0.00312577\n",
      "Iteration 6590, loss = 0.00312501\n",
      "Iteration 6591, loss = 0.00312432\n",
      "Iteration 6592, loss = 0.00312353\n",
      "Iteration 6593, loss = 0.00312282\n",
      "Iteration 6594, loss = 0.00312212\n",
      "Iteration 6595, loss = 0.00312142\n",
      "Iteration 6596, loss = 0.00312091\n",
      "Iteration 6597, loss = 0.00312004\n",
      "Iteration 6598, loss = 0.00311933\n",
      "Iteration 6599, loss = 0.00311860\n",
      "Iteration 6600, loss = 0.00311785\n",
      "Iteration 6601, loss = 0.00311717\n",
      "Iteration 6602, loss = 0.00311657\n",
      "Iteration 6603, loss = 0.00311590\n",
      "Iteration 6604, loss = 0.00311514\n",
      "Iteration 6605, loss = 0.00311441\n",
      "Iteration 6606, loss = 0.00311373\n",
      "Iteration 6607, loss = 0.00311327\n",
      "Iteration 6608, loss = 0.00311240\n",
      "Iteration 6609, loss = 0.00311171\n",
      "Iteration 6610, loss = 0.00311102\n",
      "Iteration 6611, loss = 0.00311038\n",
      "Iteration 6612, loss = 0.00310976\n",
      "Iteration 6613, loss = 0.00310910\n",
      "Iteration 6614, loss = 0.00310851\n",
      "Iteration 6615, loss = 0.00310779\n",
      "Iteration 6616, loss = 0.00310721\n",
      "Iteration 6617, loss = 0.00310658\n",
      "Iteration 6618, loss = 0.00310588\n",
      "Iteration 6619, loss = 0.00310522\n",
      "Iteration 6620, loss = 0.00310493\n",
      "Iteration 6621, loss = 0.00310411\n",
      "Iteration 6622, loss = 0.00310336\n",
      "Iteration 6623, loss = 0.00310269\n",
      "Iteration 6624, loss = 0.00310230\n",
      "Iteration 6625, loss = 0.00310145\n",
      "Iteration 6626, loss = 0.00310084\n",
      "Iteration 6627, loss = 0.00310013\n",
      "Iteration 6628, loss = 0.00309946\n",
      "Iteration 6629, loss = 0.00309880\n",
      "Iteration 6630, loss = 0.00309814\n",
      "Iteration 6631, loss = 0.00309735\n",
      "Iteration 6632, loss = 0.00309660\n",
      "Iteration 6633, loss = 0.00309580\n",
      "Iteration 6634, loss = 0.00309521\n",
      "Iteration 6635, loss = 0.00309457\n",
      "Iteration 6636, loss = 0.00309375\n",
      "Iteration 6637, loss = 0.00309303\n",
      "Iteration 6638, loss = 0.00309235\n",
      "Iteration 6639, loss = 0.00309163\n",
      "Iteration 6640, loss = 0.00309093\n",
      "Iteration 6641, loss = 0.00309048\n",
      "Iteration 6642, loss = 0.00308964\n",
      "Iteration 6643, loss = 0.00308892\n",
      "Iteration 6644, loss = 0.00308819\n",
      "Iteration 6645, loss = 0.00308742\n",
      "Iteration 6646, loss = 0.00308674\n",
      "Iteration 6647, loss = 0.00308617\n",
      "Iteration 6648, loss = 0.00308557\n",
      "Iteration 6649, loss = 0.00308490\n",
      "Iteration 6650, loss = 0.00308405\n",
      "Iteration 6651, loss = 0.00308333\n",
      "Iteration 6652, loss = 0.00308279\n",
      "Iteration 6653, loss = 0.00308203\n",
      "Iteration 6654, loss = 0.00308135\n",
      "Iteration 6655, loss = 0.00308069\n",
      "Iteration 6656, loss = 0.00308001\n",
      "Iteration 6657, loss = 0.00307936\n",
      "Iteration 6658, loss = 0.00307878\n",
      "Iteration 6659, loss = 0.00307806\n",
      "Iteration 6660, loss = 0.00307747\n",
      "Iteration 6661, loss = 0.00307680\n",
      "Iteration 6662, loss = 0.00307613\n",
      "Iteration 6663, loss = 0.00307561\n",
      "Iteration 6664, loss = 0.00307487\n",
      "Iteration 6665, loss = 0.00307416\n",
      "Iteration 6666, loss = 0.00307396\n",
      "Iteration 6667, loss = 0.00307284\n",
      "Iteration 6668, loss = 0.00307230\n",
      "Iteration 6669, loss = 0.00307159\n",
      "Iteration 6670, loss = 0.00307094\n",
      "Iteration 6671, loss = 0.00307033\n",
      "Iteration 6672, loss = 0.00306965\n",
      "Iteration 6673, loss = 0.00306912\n",
      "Iteration 6674, loss = 0.00306840\n",
      "Iteration 6675, loss = 0.00306789\n",
      "Iteration 6676, loss = 0.00306715\n",
      "Iteration 6677, loss = 0.00306645\n",
      "Iteration 6678, loss = 0.00306570\n",
      "Iteration 6679, loss = 0.00306502\n",
      "Iteration 6680, loss = 0.00306423\n",
      "Iteration 6681, loss = 0.00306354\n",
      "Iteration 6682, loss = 0.00306286\n",
      "Iteration 6683, loss = 0.00306226\n",
      "Iteration 6684, loss = 0.00306158\n",
      "Iteration 6685, loss = 0.00306089\n",
      "Iteration 6686, loss = 0.00306027\n",
      "Iteration 6687, loss = 0.00305947\n",
      "Iteration 6688, loss = 0.00305895\n",
      "Iteration 6689, loss = 0.00305819\n",
      "Iteration 6690, loss = 0.00305757\n",
      "Iteration 6691, loss = 0.00305690\n",
      "Iteration 6692, loss = 0.00305629\n",
      "Iteration 6693, loss = 0.00305556\n",
      "Iteration 6694, loss = 0.00305493\n",
      "Iteration 6695, loss = 0.00305426\n",
      "Iteration 6696, loss = 0.00305365\n",
      "Iteration 6697, loss = 0.00305309\n",
      "Iteration 6698, loss = 0.00305238\n",
      "Iteration 6699, loss = 0.00305202\n",
      "Iteration 6700, loss = 0.00305116\n",
      "Iteration 6701, loss = 0.00305054\n",
      "Iteration 6702, loss = 0.00304969\n",
      "Iteration 6703, loss = 0.00304910\n",
      "Iteration 6704, loss = 0.00304828\n",
      "Iteration 6705, loss = 0.00304749\n",
      "Iteration 6706, loss = 0.00304681\n",
      "Iteration 6707, loss = 0.00304607\n",
      "Iteration 6708, loss = 0.00304530\n",
      "Iteration 6709, loss = 0.00304461\n",
      "Iteration 6710, loss = 0.00304406\n",
      "Iteration 6711, loss = 0.00304312\n",
      "Iteration 6712, loss = 0.00304237\n",
      "Iteration 6713, loss = 0.00304161\n",
      "Iteration 6714, loss = 0.00304124\n",
      "Iteration 6715, loss = 0.00304022\n",
      "Iteration 6716, loss = 0.00303964\n",
      "Iteration 6717, loss = 0.00303893\n",
      "Iteration 6718, loss = 0.00303806\n",
      "Iteration 6719, loss = 0.00303731\n",
      "Iteration 6720, loss = 0.00303672\n",
      "Iteration 6721, loss = 0.00303590\n",
      "Iteration 6722, loss = 0.00303528\n",
      "Iteration 6723, loss = 0.00303452\n",
      "Iteration 6724, loss = 0.00303382\n",
      "Iteration 6725, loss = 0.00303320\n",
      "Iteration 6726, loss = 0.00303261\n",
      "Iteration 6727, loss = 0.00303166\n",
      "Iteration 6728, loss = 0.00303113\n",
      "Iteration 6729, loss = 0.00303026\n",
      "Iteration 6730, loss = 0.00302962\n",
      "Iteration 6731, loss = 0.00302884\n",
      "Iteration 6732, loss = 0.00302821\n",
      "Iteration 6733, loss = 0.00302757\n",
      "Iteration 6734, loss = 0.00302678\n",
      "Iteration 6735, loss = 0.00302609\n",
      "Iteration 6736, loss = 0.00302540\n",
      "Iteration 6737, loss = 0.00302489\n",
      "Iteration 6738, loss = 0.00302411\n",
      "Iteration 6739, loss = 0.00302348\n",
      "Iteration 6740, loss = 0.00302286\n",
      "Iteration 6741, loss = 0.00302230\n",
      "Iteration 6742, loss = 0.00302166\n",
      "Iteration 6743, loss = 0.00302108\n",
      "Iteration 6744, loss = 0.00302050\n",
      "Iteration 6745, loss = 0.00302004\n",
      "Iteration 6746, loss = 0.00301933\n",
      "Iteration 6747, loss = 0.00301875\n",
      "Iteration 6748, loss = 0.00301816\n",
      "Iteration 6749, loss = 0.00301754\n",
      "Iteration 6750, loss = 0.00301706\n",
      "Iteration 6751, loss = 0.00301634\n",
      "Iteration 6752, loss = 0.00301569\n",
      "Iteration 6753, loss = 0.00301500\n",
      "Iteration 6754, loss = 0.00301439\n",
      "Iteration 6755, loss = 0.00301374\n",
      "Iteration 6756, loss = 0.00301318\n",
      "Iteration 6757, loss = 0.00301251\n",
      "Iteration 6758, loss = 0.00301193\n",
      "Iteration 6759, loss = 0.00301132\n",
      "Iteration 6760, loss = 0.00301079\n",
      "Iteration 6761, loss = 0.00301000\n",
      "Iteration 6762, loss = 0.00300932\n",
      "Iteration 6763, loss = 0.00300856\n",
      "Iteration 6764, loss = 0.00300803\n",
      "Iteration 6765, loss = 0.00300739\n",
      "Iteration 6766, loss = 0.00300673\n",
      "Iteration 6767, loss = 0.00300605\n",
      "Iteration 6768, loss = 0.00300556\n",
      "Iteration 6769, loss = 0.00300493\n",
      "Iteration 6770, loss = 0.00300428\n",
      "Iteration 6771, loss = 0.00300364\n",
      "Iteration 6772, loss = 0.00300294\n",
      "Iteration 6773, loss = 0.00300230\n",
      "Iteration 6774, loss = 0.00300155\n",
      "Iteration 6775, loss = 0.00300086\n",
      "Iteration 6776, loss = 0.00300011\n",
      "Iteration 6777, loss = 0.00299950\n",
      "Iteration 6778, loss = 0.00299902\n",
      "Iteration 6779, loss = 0.00299803\n",
      "Iteration 6780, loss = 0.00299740\n",
      "Iteration 6781, loss = 0.00299681\n",
      "Iteration 6782, loss = 0.00299608\n",
      "Iteration 6783, loss = 0.00299539\n",
      "Iteration 6784, loss = 0.00299475\n",
      "Iteration 6785, loss = 0.00299410\n",
      "Iteration 6786, loss = 0.00299341\n",
      "Iteration 6787, loss = 0.00299277\n",
      "Iteration 6788, loss = 0.00299209\n",
      "Iteration 6789, loss = 0.00299138\n",
      "Iteration 6790, loss = 0.00299070\n",
      "Iteration 6791, loss = 0.00299002\n",
      "Iteration 6792, loss = 0.00298941\n",
      "Iteration 6793, loss = 0.00298871\n",
      "Iteration 6794, loss = 0.00298814\n",
      "Iteration 6795, loss = 0.00298753\n",
      "Iteration 6796, loss = 0.00298704\n",
      "Iteration 6797, loss = 0.00298622\n",
      "Iteration 6798, loss = 0.00298556\n",
      "Iteration 6799, loss = 0.00298493\n",
      "Iteration 6800, loss = 0.00298434\n",
      "Iteration 6801, loss = 0.00298370\n",
      "Iteration 6802, loss = 0.00298314\n",
      "Iteration 6803, loss = 0.00298251\n",
      "Iteration 6804, loss = 0.00298195\n",
      "Iteration 6805, loss = 0.00298140\n",
      "Iteration 6806, loss = 0.00298083\n",
      "Iteration 6807, loss = 0.00298025\n",
      "Iteration 6808, loss = 0.00297976\n",
      "Iteration 6809, loss = 0.00297900\n",
      "Iteration 6810, loss = 0.00297831\n",
      "Iteration 6811, loss = 0.00297775\n",
      "Iteration 6812, loss = 0.00297714\n",
      "Iteration 6813, loss = 0.00297679\n",
      "Iteration 6814, loss = 0.00297597\n",
      "Iteration 6815, loss = 0.00297541\n",
      "Iteration 6816, loss = 0.00297496\n",
      "Iteration 6817, loss = 0.00297413\n",
      "Iteration 6818, loss = 0.00297350\n",
      "Iteration 6819, loss = 0.00297285\n",
      "Iteration 6820, loss = 0.00297217\n",
      "Iteration 6821, loss = 0.00297156\n",
      "Iteration 6822, loss = 0.00297094\n",
      "Iteration 6823, loss = 0.00297045\n",
      "Iteration 6824, loss = 0.00296973\n",
      "Iteration 6825, loss = 0.00296909\n",
      "Iteration 6826, loss = 0.00296832\n",
      "Iteration 6827, loss = 0.00296782\n",
      "Iteration 6828, loss = 0.00296709\n",
      "Iteration 6829, loss = 0.00296645\n",
      "Iteration 6830, loss = 0.00296574\n",
      "Iteration 6831, loss = 0.00296507\n",
      "Iteration 6832, loss = 0.00296456\n",
      "Iteration 6833, loss = 0.00296391\n",
      "Iteration 6834, loss = 0.00296329\n",
      "Iteration 6835, loss = 0.00296253\n",
      "Iteration 6836, loss = 0.00296185\n",
      "Iteration 6837, loss = 0.00296115\n",
      "Iteration 6838, loss = 0.00296057\n",
      "Iteration 6839, loss = 0.00295988\n",
      "Iteration 6840, loss = 0.00295917\n",
      "Iteration 6841, loss = 0.00295861\n",
      "Iteration 6842, loss = 0.00295778\n",
      "Iteration 6843, loss = 0.00295723\n",
      "Iteration 6844, loss = 0.00295663\n",
      "Iteration 6845, loss = 0.00295586\n",
      "Iteration 6846, loss = 0.00295515\n",
      "Iteration 6847, loss = 0.00295444\n",
      "Iteration 6848, loss = 0.00295389\n",
      "Iteration 6849, loss = 0.00295315\n",
      "Iteration 6850, loss = 0.00295255\n",
      "Iteration 6851, loss = 0.00295189\n",
      "Iteration 6852, loss = 0.00295124\n",
      "Iteration 6853, loss = 0.00295074\n",
      "Iteration 6854, loss = 0.00295000\n",
      "Iteration 6855, loss = 0.00294939\n",
      "Iteration 6856, loss = 0.00294874\n",
      "Iteration 6857, loss = 0.00294830\n",
      "Iteration 6858, loss = 0.00294749\n",
      "Iteration 6859, loss = 0.00294688\n",
      "Iteration 6860, loss = 0.00294623\n",
      "Iteration 6861, loss = 0.00294566\n",
      "Iteration 6862, loss = 0.00294506\n",
      "Iteration 6863, loss = 0.00294447\n",
      "Iteration 6864, loss = 0.00294374\n",
      "Iteration 6865, loss = 0.00294313\n",
      "Iteration 6866, loss = 0.00294251\n",
      "Iteration 6867, loss = 0.00294183\n",
      "Iteration 6868, loss = 0.00294130\n",
      "Iteration 6869, loss = 0.00294066\n",
      "Iteration 6870, loss = 0.00294013\n",
      "Iteration 6871, loss = 0.00293955\n",
      "Iteration 6872, loss = 0.00293897\n",
      "Iteration 6873, loss = 0.00293845\n",
      "Iteration 6874, loss = 0.00293774\n",
      "Iteration 6875, loss = 0.00293739\n",
      "Iteration 6876, loss = 0.00293657\n",
      "Iteration 6877, loss = 0.00293605\n",
      "Iteration 6878, loss = 0.00293550\n",
      "Iteration 6879, loss = 0.00293488\n",
      "Iteration 6880, loss = 0.00293421\n",
      "Iteration 6881, loss = 0.00293369\n",
      "Iteration 6882, loss = 0.00293320\n",
      "Iteration 6883, loss = 0.00293240\n",
      "Iteration 6884, loss = 0.00293180\n",
      "Iteration 6885, loss = 0.00293114\n",
      "Iteration 6886, loss = 0.00293050\n",
      "Iteration 6887, loss = 0.00292995\n",
      "Iteration 6888, loss = 0.00292926\n",
      "Iteration 6889, loss = 0.00292877\n",
      "Iteration 6890, loss = 0.00292806\n",
      "Iteration 6891, loss = 0.00292751\n",
      "Iteration 6892, loss = 0.00292687\n",
      "Iteration 6893, loss = 0.00292631\n",
      "Iteration 6894, loss = 0.00292576\n",
      "Iteration 6895, loss = 0.00292517\n",
      "Iteration 6896, loss = 0.00292449\n",
      "Iteration 6897, loss = 0.00292384\n",
      "Iteration 6898, loss = 0.00292324\n",
      "Iteration 6899, loss = 0.00292267\n",
      "Iteration 6900, loss = 0.00292202\n",
      "Iteration 6901, loss = 0.00292137\n",
      "Iteration 6902, loss = 0.00292077\n",
      "Iteration 6903, loss = 0.00292010\n",
      "Iteration 6904, loss = 0.00291948\n",
      "Iteration 6905, loss = 0.00291884\n",
      "Iteration 6906, loss = 0.00291823\n",
      "Iteration 6907, loss = 0.00291765\n",
      "Iteration 6908, loss = 0.00291691\n",
      "Iteration 6909, loss = 0.00291625\n",
      "Iteration 6910, loss = 0.00291565\n",
      "Iteration 6911, loss = 0.00291497\n",
      "Iteration 6912, loss = 0.00291435\n",
      "Iteration 6913, loss = 0.00291370\n",
      "Iteration 6914, loss = 0.00291291\n",
      "Iteration 6915, loss = 0.00291221\n",
      "Iteration 6916, loss = 0.00291148\n",
      "Iteration 6917, loss = 0.00291088\n",
      "Iteration 6918, loss = 0.00291021\n",
      "Iteration 6919, loss = 0.00290954\n",
      "Iteration 6920, loss = 0.00290881\n",
      "Iteration 6921, loss = 0.00290814\n",
      "Iteration 6922, loss = 0.00290792\n",
      "Iteration 6923, loss = 0.00290687\n",
      "Iteration 6924, loss = 0.00290637\n",
      "Iteration 6925, loss = 0.00290557\n",
      "Iteration 6926, loss = 0.00290504\n",
      "Iteration 6927, loss = 0.00290437\n",
      "Iteration 6928, loss = 0.00290368\n",
      "Iteration 6929, loss = 0.00290305\n",
      "Iteration 6930, loss = 0.00290242\n",
      "Iteration 6931, loss = 0.00290190\n",
      "Iteration 6932, loss = 0.00290121\n",
      "Iteration 6933, loss = 0.00290058\n",
      "Iteration 6934, loss = 0.00289992\n",
      "Iteration 6935, loss = 0.00289936\n",
      "Iteration 6936, loss = 0.00289871\n",
      "Iteration 6937, loss = 0.00289808\n",
      "Iteration 6938, loss = 0.00289754\n",
      "Iteration 6939, loss = 0.00289691\n",
      "Iteration 6940, loss = 0.00289635\n",
      "Iteration 6941, loss = 0.00289563\n",
      "Iteration 6942, loss = 0.00289510\n",
      "Iteration 6943, loss = 0.00289437\n",
      "Iteration 6944, loss = 0.00289368\n",
      "Iteration 6945, loss = 0.00289314\n",
      "Iteration 6946, loss = 0.00289255\n",
      "Iteration 6947, loss = 0.00289184\n",
      "Iteration 6948, loss = 0.00289122\n",
      "Iteration 6949, loss = 0.00289060\n",
      "Iteration 6950, loss = 0.00288982\n",
      "Iteration 6951, loss = 0.00288939\n",
      "Iteration 6952, loss = 0.00288881\n",
      "Iteration 6953, loss = 0.00288803\n",
      "Iteration 6954, loss = 0.00288745\n",
      "Iteration 6955, loss = 0.00288686\n",
      "Iteration 6956, loss = 0.00288620\n",
      "Iteration 6957, loss = 0.00288573\n",
      "Iteration 6958, loss = 0.00288483\n",
      "Iteration 6959, loss = 0.00288424\n",
      "Iteration 6960, loss = 0.00288358\n",
      "Iteration 6961, loss = 0.00288299\n",
      "Iteration 6962, loss = 0.00288233\n",
      "Iteration 6963, loss = 0.00288157\n",
      "Iteration 6964, loss = 0.00288136\n",
      "Iteration 6965, loss = 0.00288035\n",
      "Iteration 6966, loss = 0.00287977\n",
      "Iteration 6967, loss = 0.00287912\n",
      "Iteration 6968, loss = 0.00287861\n",
      "Iteration 6969, loss = 0.00287788\n",
      "Iteration 6970, loss = 0.00287726\n",
      "Iteration 6971, loss = 0.00287670\n",
      "Iteration 6972, loss = 0.00287608\n",
      "Iteration 6973, loss = 0.00287547\n",
      "Iteration 6974, loss = 0.00287501\n",
      "Iteration 6975, loss = 0.00287421\n",
      "Iteration 6976, loss = 0.00287350\n",
      "Iteration 6977, loss = 0.00287304\n",
      "Iteration 6978, loss = 0.00287243\n",
      "Iteration 6979, loss = 0.00287168\n",
      "Iteration 6980, loss = 0.00287103\n",
      "Iteration 6981, loss = 0.00287047\n",
      "Iteration 6982, loss = 0.00286978\n",
      "Iteration 6983, loss = 0.00286921\n",
      "Iteration 6984, loss = 0.00286862\n",
      "Iteration 6985, loss = 0.00286798\n",
      "Iteration 6986, loss = 0.00286734\n",
      "Iteration 6987, loss = 0.00286667\n",
      "Iteration 6988, loss = 0.00286599\n",
      "Iteration 6989, loss = 0.00286530\n",
      "Iteration 6990, loss = 0.00286479\n",
      "Iteration 6991, loss = 0.00286415\n",
      "Iteration 6992, loss = 0.00286352\n",
      "Iteration 6993, loss = 0.00286300\n",
      "Iteration 6994, loss = 0.00286248\n",
      "Iteration 6995, loss = 0.00286210\n",
      "Iteration 6996, loss = 0.00286128\n",
      "Iteration 6997, loss = 0.00286081\n",
      "Iteration 6998, loss = 0.00286012\n",
      "Iteration 6999, loss = 0.00285958\n",
      "Iteration 7000, loss = 0.00285895\n",
      "Iteration 7001, loss = 0.00285842\n",
      "Iteration 7002, loss = 0.00285773\n",
      "Iteration 7003, loss = 0.00285707\n",
      "Iteration 7004, loss = 0.00285654\n",
      "Iteration 7005, loss = 0.00285590\n",
      "Iteration 7006, loss = 0.00285527\n",
      "Iteration 7007, loss = 0.00285471\n",
      "Iteration 7008, loss = 0.00285420\n",
      "Iteration 7009, loss = 0.00285342\n",
      "Iteration 7010, loss = 0.00285269\n",
      "Iteration 7011, loss = 0.00285271\n",
      "Iteration 7012, loss = 0.00285157\n",
      "Iteration 7013, loss = 0.00285088\n",
      "Iteration 7014, loss = 0.00285039\n",
      "Iteration 7015, loss = 0.00284960\n",
      "Iteration 7016, loss = 0.00284907\n",
      "Iteration 7017, loss = 0.00284826\n",
      "Iteration 7018, loss = 0.00284750\n",
      "Iteration 7019, loss = 0.00284703\n",
      "Iteration 7020, loss = 0.00284629\n",
      "Iteration 7021, loss = 0.00284557\n",
      "Iteration 7022, loss = 0.00284499\n",
      "Iteration 7023, loss = 0.00284430\n",
      "Iteration 7024, loss = 0.00284364\n",
      "Iteration 7025, loss = 0.00284299\n",
      "Iteration 7026, loss = 0.00284242\n",
      "Iteration 7027, loss = 0.00284181\n",
      "Iteration 7028, loss = 0.00284129\n",
      "Iteration 7029, loss = 0.00284065\n",
      "Iteration 7030, loss = 0.00283995\n",
      "Iteration 7031, loss = 0.00283944\n",
      "Iteration 7032, loss = 0.00283874\n",
      "Iteration 7033, loss = 0.00283817\n",
      "Iteration 7034, loss = 0.00283761\n",
      "Iteration 7035, loss = 0.00283697\n",
      "Iteration 7036, loss = 0.00283656\n",
      "Iteration 7037, loss = 0.00283584\n",
      "Iteration 7038, loss = 0.00283528\n",
      "Iteration 7039, loss = 0.00283472\n",
      "Iteration 7040, loss = 0.00283412\n",
      "Iteration 7041, loss = 0.00283368\n",
      "Iteration 7042, loss = 0.00283300\n",
      "Iteration 7043, loss = 0.00283238\n",
      "Iteration 7044, loss = 0.00283187\n",
      "Iteration 7045, loss = 0.00283132\n",
      "Iteration 7046, loss = 0.00283049\n",
      "Iteration 7047, loss = 0.00282993\n",
      "Iteration 7048, loss = 0.00282930\n",
      "Iteration 7049, loss = 0.00282870\n",
      "Iteration 7050, loss = 0.00282798\n",
      "Iteration 7051, loss = 0.00282740\n",
      "Iteration 7052, loss = 0.00282711\n",
      "Iteration 7053, loss = 0.00282648\n",
      "Iteration 7054, loss = 0.00282538\n",
      "Iteration 7055, loss = 0.00282496\n",
      "Iteration 7056, loss = 0.00282426\n",
      "Iteration 7057, loss = 0.00282369\n",
      "Iteration 7058, loss = 0.00282313\n",
      "Iteration 7059, loss = 0.00282254\n",
      "Iteration 7060, loss = 0.00282193\n",
      "Iteration 7061, loss = 0.00282138\n",
      "Iteration 7062, loss = 0.00282079\n",
      "Iteration 7063, loss = 0.00282025\n",
      "Iteration 7064, loss = 0.00281969\n",
      "Iteration 7065, loss = 0.00281911\n",
      "Iteration 7066, loss = 0.00281848\n",
      "Iteration 7067, loss = 0.00281790\n",
      "Iteration 7068, loss = 0.00281735\n",
      "Iteration 7069, loss = 0.00281675\n",
      "Iteration 7070, loss = 0.00281611\n",
      "Iteration 7071, loss = 0.00281560\n",
      "Iteration 7072, loss = 0.00281484\n",
      "Iteration 7073, loss = 0.00281421\n",
      "Iteration 7074, loss = 0.00281378\n",
      "Iteration 7075, loss = 0.00281304\n",
      "Iteration 7076, loss = 0.00281231\n",
      "Iteration 7077, loss = 0.00281175\n",
      "Iteration 7078, loss = 0.00281114\n",
      "Iteration 7079, loss = 0.00281048\n",
      "Iteration 7080, loss = 0.00280990\n",
      "Iteration 7081, loss = 0.00280940\n",
      "Iteration 7082, loss = 0.00280884\n",
      "Iteration 7083, loss = 0.00280817\n",
      "Iteration 7084, loss = 0.00280761\n",
      "Iteration 7085, loss = 0.00280698\n",
      "Iteration 7086, loss = 0.00280645\n",
      "Iteration 7087, loss = 0.00280610\n",
      "Iteration 7088, loss = 0.00280528\n",
      "Iteration 7089, loss = 0.00280475\n",
      "Iteration 7090, loss = 0.00280429\n",
      "Iteration 7091, loss = 0.00280360\n",
      "Iteration 7092, loss = 0.00280305\n",
      "Iteration 7093, loss = 0.00280249\n",
      "Iteration 7094, loss = 0.00280184\n",
      "Iteration 7095, loss = 0.00280132\n",
      "Iteration 7096, loss = 0.00280096\n",
      "Iteration 7097, loss = 0.00280026\n",
      "Iteration 7098, loss = 0.00279981\n",
      "Iteration 7099, loss = 0.00279925\n",
      "Iteration 7100, loss = 0.00279857\n",
      "Iteration 7101, loss = 0.00279800\n",
      "Iteration 7102, loss = 0.00279745\n",
      "Iteration 7103, loss = 0.00279689\n",
      "Iteration 7104, loss = 0.00279636\n",
      "Iteration 7105, loss = 0.00279585\n",
      "Iteration 7106, loss = 0.00279527\n",
      "Iteration 7107, loss = 0.00279473\n",
      "Iteration 7108, loss = 0.00279420\n",
      "Iteration 7109, loss = 0.00279371\n",
      "Iteration 7110, loss = 0.00279318\n",
      "Iteration 7111, loss = 0.00279255\n",
      "Iteration 7112, loss = 0.00279206\n",
      "Iteration 7113, loss = 0.00279150\n",
      "Iteration 7114, loss = 0.00279094\n",
      "Iteration 7115, loss = 0.00279037\n",
      "Iteration 7116, loss = 0.00278980\n",
      "Iteration 7117, loss = 0.00278941\n",
      "Iteration 7118, loss = 0.00278880\n",
      "Iteration 7119, loss = 0.00278814\n",
      "Iteration 7120, loss = 0.00278759\n",
      "Iteration 7121, loss = 0.00278705\n",
      "Iteration 7122, loss = 0.00278642\n",
      "Iteration 7123, loss = 0.00278596\n",
      "Iteration 7124, loss = 0.00278545\n",
      "Iteration 7125, loss = 0.00278485\n",
      "Iteration 7126, loss = 0.00278430\n",
      "Iteration 7127, loss = 0.00278387\n",
      "Iteration 7128, loss = 0.00278329\n",
      "Iteration 7129, loss = 0.00278264\n",
      "Iteration 7130, loss = 0.00278208\n",
      "Iteration 7131, loss = 0.00278156\n",
      "Iteration 7132, loss = 0.00278106\n",
      "Iteration 7133, loss = 0.00278038\n",
      "Iteration 7134, loss = 0.00277970\n",
      "Iteration 7135, loss = 0.00277906\n",
      "Iteration 7136, loss = 0.00277842\n",
      "Iteration 7137, loss = 0.00277796\n",
      "Iteration 7138, loss = 0.00277734\n",
      "Iteration 7139, loss = 0.00277674\n",
      "Iteration 7140, loss = 0.00277616\n",
      "Iteration 7141, loss = 0.00277565\n",
      "Iteration 7142, loss = 0.00277517\n",
      "Iteration 7143, loss = 0.00277471\n",
      "Iteration 7144, loss = 0.00277397\n",
      "Iteration 7145, loss = 0.00277340\n",
      "Iteration 7146, loss = 0.00277283\n",
      "Iteration 7147, loss = 0.00277225\n",
      "Iteration 7148, loss = 0.00277170\n",
      "Iteration 7149, loss = 0.00277124\n",
      "Iteration 7150, loss = 0.00277063\n",
      "Iteration 7151, loss = 0.00277011\n",
      "Iteration 7152, loss = 0.00276951\n",
      "Iteration 7153, loss = 0.00276902\n",
      "Iteration 7154, loss = 0.00276834\n",
      "Iteration 7155, loss = 0.00276775\n",
      "Iteration 7156, loss = 0.00276720\n",
      "Iteration 7157, loss = 0.00276675\n",
      "Iteration 7158, loss = 0.00276608\n",
      "Iteration 7159, loss = 0.00276552\n",
      "Iteration 7160, loss = 0.00276495\n",
      "Iteration 7161, loss = 0.00276444\n",
      "Iteration 7162, loss = 0.00276374\n",
      "Iteration 7163, loss = 0.00276310\n",
      "Iteration 7164, loss = 0.00276271\n",
      "Iteration 7165, loss = 0.00276198\n",
      "Iteration 7166, loss = 0.00276143\n",
      "Iteration 7167, loss = 0.00276083\n",
      "Iteration 7168, loss = 0.00276048\n",
      "Iteration 7169, loss = 0.00275972\n",
      "Iteration 7170, loss = 0.00275946\n",
      "Iteration 7171, loss = 0.00275861\n",
      "Iteration 7172, loss = 0.00275810\n",
      "Iteration 7173, loss = 0.00275756\n",
      "Iteration 7174, loss = 0.00275698\n",
      "Iteration 7175, loss = 0.00275647\n",
      "Iteration 7176, loss = 0.00275585\n",
      "Iteration 7177, loss = 0.00275567\n",
      "Iteration 7178, loss = 0.00275481\n",
      "Iteration 7179, loss = 0.00275440\n",
      "Iteration 7180, loss = 0.00275386\n",
      "Iteration 7181, loss = 0.00275316\n",
      "Iteration 7182, loss = 0.00275252\n",
      "Iteration 7183, loss = 0.00275204\n",
      "Iteration 7184, loss = 0.00275142\n",
      "Iteration 7185, loss = 0.00275086\n",
      "Iteration 7186, loss = 0.00275032\n",
      "Iteration 7187, loss = 0.00274974\n",
      "Iteration 7188, loss = 0.00274922\n",
      "Iteration 7189, loss = 0.00274863\n",
      "Iteration 7190, loss = 0.00274809\n",
      "Iteration 7191, loss = 0.00274759\n",
      "Iteration 7192, loss = 0.00274705\n",
      "Iteration 7193, loss = 0.00274634\n",
      "Iteration 7194, loss = 0.00274581\n",
      "Iteration 7195, loss = 0.00274529\n",
      "Iteration 7196, loss = 0.00274472\n",
      "Iteration 7197, loss = 0.00274417\n",
      "Iteration 7198, loss = 0.00274366\n",
      "Iteration 7199, loss = 0.00274310\n",
      "Iteration 7200, loss = 0.00274258\n",
      "Iteration 7201, loss = 0.00274209\n",
      "Iteration 7202, loss = 0.00274160\n",
      "Iteration 7203, loss = 0.00274107\n",
      "Iteration 7204, loss = 0.00274048\n",
      "Iteration 7205, loss = 0.00273992\n",
      "Iteration 7206, loss = 0.00273934\n",
      "Iteration 7207, loss = 0.00273903\n",
      "Iteration 7208, loss = 0.00273837\n",
      "Iteration 7209, loss = 0.00273789\n",
      "Iteration 7210, loss = 0.00273731\n",
      "Iteration 7211, loss = 0.00273694\n",
      "Iteration 7212, loss = 0.00273626\n",
      "Iteration 7213, loss = 0.00273584\n",
      "Iteration 7214, loss = 0.00273515\n",
      "Iteration 7215, loss = 0.00273456\n",
      "Iteration 7216, loss = 0.00273406\n",
      "Iteration 7217, loss = 0.00273339\n",
      "Iteration 7218, loss = 0.00273277\n",
      "Iteration 7219, loss = 0.00273230\n",
      "Iteration 7220, loss = 0.00273164\n",
      "Iteration 7221, loss = 0.00273114\n",
      "Iteration 7222, loss = 0.00273067\n",
      "Iteration 7223, loss = 0.00273006\n",
      "Iteration 7224, loss = 0.00272946\n",
      "Iteration 7225, loss = 0.00272894\n",
      "Iteration 7226, loss = 0.00272850\n",
      "Iteration 7227, loss = 0.00272786\n",
      "Iteration 7228, loss = 0.00272735\n",
      "Iteration 7229, loss = 0.00272683\n",
      "Iteration 7230, loss = 0.00272636\n",
      "Iteration 7231, loss = 0.00272580\n",
      "Iteration 7232, loss = 0.00272525\n",
      "Iteration 7233, loss = 0.00272466\n",
      "Iteration 7234, loss = 0.00272410\n",
      "Iteration 7235, loss = 0.00272356\n",
      "Iteration 7236, loss = 0.00272302\n",
      "Iteration 7237, loss = 0.00272248\n",
      "Iteration 7238, loss = 0.00272206\n",
      "Iteration 7239, loss = 0.00272142\n",
      "Iteration 7240, loss = 0.00272093\n",
      "Iteration 7241, loss = 0.00272036\n",
      "Iteration 7242, loss = 0.00271986\n",
      "Iteration 7243, loss = 0.00271933\n",
      "Iteration 7244, loss = 0.00271876\n",
      "Iteration 7245, loss = 0.00271821\n",
      "Iteration 7246, loss = 0.00271767\n",
      "Iteration 7247, loss = 0.00271708\n",
      "Iteration 7248, loss = 0.00271645\n",
      "Iteration 7249, loss = 0.00271616\n",
      "Iteration 7250, loss = 0.00271533\n",
      "Iteration 7251, loss = 0.00271487\n",
      "Iteration 7252, loss = 0.00271436\n",
      "Iteration 7253, loss = 0.00271377\n",
      "Iteration 7254, loss = 0.00271337\n",
      "Iteration 7255, loss = 0.00271275\n",
      "Iteration 7256, loss = 0.00271222\n",
      "Iteration 7257, loss = 0.00271174\n",
      "Iteration 7258, loss = 0.00271120\n",
      "Iteration 7259, loss = 0.00271069\n",
      "Iteration 7260, loss = 0.00271021\n",
      "Iteration 7261, loss = 0.00270966\n",
      "Iteration 7262, loss = 0.00270923\n",
      "Iteration 7263, loss = 0.00270866\n",
      "Iteration 7264, loss = 0.00270810\n",
      "Iteration 7265, loss = 0.00270760\n",
      "Iteration 7266, loss = 0.00270712\n",
      "Iteration 7267, loss = 0.00270659\n",
      "Iteration 7268, loss = 0.00270613\n",
      "Iteration 7269, loss = 0.00270557\n",
      "Iteration 7270, loss = 0.00270507\n",
      "Iteration 7271, loss = 0.00270457\n",
      "Iteration 7272, loss = 0.00270397\n",
      "Iteration 7273, loss = 0.00270353\n",
      "Iteration 7274, loss = 0.00270298\n",
      "Iteration 7275, loss = 0.00270244\n",
      "Iteration 7276, loss = 0.00270191\n",
      "Iteration 7277, loss = 0.00270135\n",
      "Iteration 7278, loss = 0.00270084\n",
      "Iteration 7279, loss = 0.00270038\n",
      "Iteration 7280, loss = 0.00269978\n",
      "Iteration 7281, loss = 0.00269921\n",
      "Iteration 7282, loss = 0.00269863\n",
      "Iteration 7283, loss = 0.00269805\n",
      "Iteration 7284, loss = 0.00269749\n",
      "Iteration 7285, loss = 0.00269691\n",
      "Iteration 7286, loss = 0.00269635\n",
      "Iteration 7287, loss = 0.00269578\n",
      "Iteration 7288, loss = 0.00269514\n",
      "Iteration 7289, loss = 0.00269461\n",
      "Iteration 7290, loss = 0.00269416\n",
      "Iteration 7291, loss = 0.00269366\n",
      "Iteration 7292, loss = 0.00269292\n",
      "Iteration 7293, loss = 0.00269230\n",
      "Iteration 7294, loss = 0.00269190\n",
      "Iteration 7295, loss = 0.00269120\n",
      "Iteration 7296, loss = 0.00269058\n",
      "Iteration 7297, loss = 0.00269010\n",
      "Iteration 7298, loss = 0.00268949\n",
      "Iteration 7299, loss = 0.00268896\n",
      "Iteration 7300, loss = 0.00268849\n",
      "Iteration 7301, loss = 0.00268790\n",
      "Iteration 7302, loss = 0.00268744\n",
      "Iteration 7303, loss = 0.00268689\n",
      "Iteration 7304, loss = 0.00268643\n",
      "Iteration 7305, loss = 0.00268586\n",
      "Iteration 7306, loss = 0.00268534\n",
      "Iteration 7307, loss = 0.00268483\n",
      "Iteration 7308, loss = 0.00268426\n",
      "Iteration 7309, loss = 0.00268370\n",
      "Iteration 7310, loss = 0.00268311\n",
      "Iteration 7311, loss = 0.00268254\n",
      "Iteration 7312, loss = 0.00268211\n",
      "Iteration 7313, loss = 0.00268142\n",
      "Iteration 7314, loss = 0.00268099\n",
      "Iteration 7315, loss = 0.00268020\n",
      "Iteration 7316, loss = 0.00267959\n",
      "Iteration 7317, loss = 0.00267918\n",
      "Iteration 7318, loss = 0.00267849\n",
      "Iteration 7319, loss = 0.00267795\n",
      "Iteration 7320, loss = 0.00267748\n",
      "Iteration 7321, loss = 0.00267682\n",
      "Iteration 7322, loss = 0.00267628\n",
      "Iteration 7323, loss = 0.00267565\n",
      "Iteration 7324, loss = 0.00267510\n",
      "Iteration 7325, loss = 0.00267455\n",
      "Iteration 7326, loss = 0.00267404\n",
      "Iteration 7327, loss = 0.00267352\n",
      "Iteration 7328, loss = 0.00267307\n",
      "Iteration 7329, loss = 0.00267248\n",
      "Iteration 7330, loss = 0.00267195\n",
      "Iteration 7331, loss = 0.00267137\n",
      "Iteration 7332, loss = 0.00267079\n",
      "Iteration 7333, loss = 0.00267019\n",
      "Iteration 7334, loss = 0.00266958\n",
      "Iteration 7335, loss = 0.00266906\n",
      "Iteration 7336, loss = 0.00266856\n",
      "Iteration 7337, loss = 0.00266797\n",
      "Iteration 7338, loss = 0.00266745\n",
      "Iteration 7339, loss = 0.00266687\n",
      "Iteration 7340, loss = 0.00266636\n",
      "Iteration 7341, loss = 0.00266587\n",
      "Iteration 7342, loss = 0.00266543\n",
      "Iteration 7343, loss = 0.00266490\n",
      "Iteration 7344, loss = 0.00266435\n",
      "Iteration 7345, loss = 0.00266395\n",
      "Iteration 7346, loss = 0.00266338\n",
      "Iteration 7347, loss = 0.00266296\n",
      "Iteration 7348, loss = 0.00266240\n",
      "Iteration 7349, loss = 0.00266190\n",
      "Iteration 7350, loss = 0.00266130\n",
      "Iteration 7351, loss = 0.00266086\n",
      "Iteration 7352, loss = 0.00266028\n",
      "Iteration 7353, loss = 0.00265974\n",
      "Iteration 7354, loss = 0.00265926\n",
      "Iteration 7355, loss = 0.00265871\n",
      "Iteration 7356, loss = 0.00265829\n",
      "Iteration 7357, loss = 0.00265777\n",
      "Iteration 7358, loss = 0.00265725\n",
      "Iteration 7359, loss = 0.00265679\n",
      "Iteration 7360, loss = 0.00265640\n",
      "Iteration 7361, loss = 0.00265578\n",
      "Iteration 7362, loss = 0.00265535\n",
      "Iteration 7363, loss = 0.00265471\n",
      "Iteration 7364, loss = 0.00265411\n",
      "Iteration 7365, loss = 0.00265347\n",
      "Iteration 7366, loss = 0.00265295\n",
      "Iteration 7367, loss = 0.00265227\n",
      "Iteration 7368, loss = 0.00265188\n",
      "Iteration 7369, loss = 0.00265135\n",
      "Iteration 7370, loss = 0.00265075\n",
      "Iteration 7371, loss = 0.00265022\n",
      "Iteration 7372, loss = 0.00264962\n",
      "Iteration 7373, loss = 0.00264919\n",
      "Iteration 7374, loss = 0.00264849\n",
      "Iteration 7375, loss = 0.00264798\n",
      "Iteration 7376, loss = 0.00264742\n",
      "Iteration 7377, loss = 0.00264690\n",
      "Iteration 7378, loss = 0.00264665\n",
      "Iteration 7379, loss = 0.00264578\n",
      "Iteration 7380, loss = 0.00264519\n",
      "Iteration 7381, loss = 0.00264465\n",
      "Iteration 7382, loss = 0.00264410\n",
      "Iteration 7383, loss = 0.00264333\n",
      "Iteration 7384, loss = 0.00264282\n",
      "Iteration 7385, loss = 0.00264224\n",
      "Iteration 7386, loss = 0.00264166\n",
      "Iteration 7387, loss = 0.00264114\n",
      "Iteration 7388, loss = 0.00264055\n",
      "Iteration 7389, loss = 0.00264004\n",
      "Iteration 7390, loss = 0.00263947\n",
      "Iteration 7391, loss = 0.00263901\n",
      "Iteration 7392, loss = 0.00263846\n",
      "Iteration 7393, loss = 0.00263779\n",
      "Iteration 7394, loss = 0.00263731\n",
      "Iteration 7395, loss = 0.00263665\n",
      "Iteration 7396, loss = 0.00263623\n",
      "Iteration 7397, loss = 0.00263562\n",
      "Iteration 7398, loss = 0.00263530\n",
      "Iteration 7399, loss = 0.00263455\n",
      "Iteration 7400, loss = 0.00263388\n",
      "Iteration 7401, loss = 0.00263344\n",
      "Iteration 7402, loss = 0.00263292\n",
      "Iteration 7403, loss = 0.00263250\n",
      "Iteration 7404, loss = 0.00263188\n",
      "Iteration 7405, loss = 0.00263128\n",
      "Iteration 7406, loss = 0.00263077\n",
      "Iteration 7407, loss = 0.00263031\n",
      "Iteration 7408, loss = 0.00262983\n",
      "Iteration 7409, loss = 0.00262941\n",
      "Iteration 7410, loss = 0.00262899\n",
      "Iteration 7411, loss = 0.00262846\n",
      "Iteration 7412, loss = 0.00262794\n",
      "Iteration 7413, loss = 0.00262743\n",
      "Iteration 7414, loss = 0.00262695\n",
      "Iteration 7415, loss = 0.00262645\n",
      "Iteration 7416, loss = 0.00262595\n",
      "Iteration 7417, loss = 0.00262554\n",
      "Iteration 7418, loss = 0.00262500\n",
      "Iteration 7419, loss = 0.00262458\n",
      "Iteration 7420, loss = 0.00262425\n",
      "Iteration 7421, loss = 0.00262365\n",
      "Iteration 7422, loss = 0.00262322\n",
      "Iteration 7423, loss = 0.00262277\n",
      "Iteration 7424, loss = 0.00262221\n",
      "Iteration 7425, loss = 0.00262169\n",
      "Iteration 7426, loss = 0.00262123\n",
      "Iteration 7427, loss = 0.00262068\n",
      "Iteration 7428, loss = 0.00262022\n",
      "Iteration 7429, loss = 0.00261969\n",
      "Iteration 7430, loss = 0.00261926\n",
      "Iteration 7431, loss = 0.00261883\n",
      "Iteration 7432, loss = 0.00261832\n",
      "Iteration 7433, loss = 0.00261779\n",
      "Iteration 7434, loss = 0.00261714\n",
      "Iteration 7435, loss = 0.00261670\n",
      "Iteration 7436, loss = 0.00261611\n",
      "Iteration 7437, loss = 0.00261554\n",
      "Iteration 7438, loss = 0.00261507\n",
      "Iteration 7439, loss = 0.00261446\n",
      "Iteration 7440, loss = 0.00261394\n",
      "Iteration 7441, loss = 0.00261343\n",
      "Iteration 7442, loss = 0.00261287\n",
      "Iteration 7443, loss = 0.00261232\n",
      "Iteration 7444, loss = 0.00261183\n",
      "Iteration 7445, loss = 0.00261134\n",
      "Iteration 7446, loss = 0.00261080\n",
      "Iteration 7447, loss = 0.00261028\n",
      "Iteration 7448, loss = 0.00260986\n",
      "Iteration 7449, loss = 0.00260933\n",
      "Iteration 7450, loss = 0.00260882\n",
      "Iteration 7451, loss = 0.00260835\n",
      "Iteration 7452, loss = 0.00260787\n",
      "Iteration 7453, loss = 0.00260741\n",
      "Iteration 7454, loss = 0.00260703\n",
      "Iteration 7455, loss = 0.00260647\n",
      "Iteration 7456, loss = 0.00260603\n",
      "Iteration 7457, loss = 0.00260586\n",
      "Iteration 7458, loss = 0.00260508\n",
      "Iteration 7459, loss = 0.00260452\n",
      "Iteration 7460, loss = 0.00260394\n",
      "Iteration 7461, loss = 0.00260348\n",
      "Iteration 7462, loss = 0.00260296\n",
      "Iteration 7463, loss = 0.00260245\n",
      "Iteration 7464, loss = 0.00260196\n",
      "Iteration 7465, loss = 0.00260142\n",
      "Iteration 7466, loss = 0.00260090\n",
      "Iteration 7467, loss = 0.00260045\n",
      "Iteration 7468, loss = 0.00259997\n",
      "Iteration 7469, loss = 0.00259941\n",
      "Iteration 7470, loss = 0.00259900\n",
      "Iteration 7471, loss = 0.00259839\n",
      "Iteration 7472, loss = 0.00259787\n",
      "Iteration 7473, loss = 0.00259746\n",
      "Iteration 7474, loss = 0.00259691\n",
      "Iteration 7475, loss = 0.00259639\n",
      "Iteration 7476, loss = 0.00259592\n",
      "Iteration 7477, loss = 0.00259541\n",
      "Iteration 7478, loss = 0.00259492\n",
      "Iteration 7479, loss = 0.00259454\n",
      "Iteration 7480, loss = 0.00259395\n",
      "Iteration 7481, loss = 0.00259346\n",
      "Iteration 7482, loss = 0.00259292\n",
      "Iteration 7483, loss = 0.00259237\n",
      "Iteration 7484, loss = 0.00259186\n",
      "Iteration 7485, loss = 0.00259138\n",
      "Iteration 7486, loss = 0.00259083\n",
      "Iteration 7487, loss = 0.00259030\n",
      "Iteration 7488, loss = 0.00258979\n",
      "Iteration 7489, loss = 0.00258936\n",
      "Iteration 7490, loss = 0.00258888\n",
      "Iteration 7491, loss = 0.00258835\n",
      "Iteration 7492, loss = 0.00258795\n",
      "Iteration 7493, loss = 0.00258735\n",
      "Iteration 7494, loss = 0.00258689\n",
      "Iteration 7495, loss = 0.00258634\n",
      "Iteration 7496, loss = 0.00258588\n",
      "Iteration 7497, loss = 0.00258533\n",
      "Iteration 7498, loss = 0.00258474\n",
      "Iteration 7499, loss = 0.00258446\n",
      "Iteration 7500, loss = 0.00258372\n",
      "Iteration 7501, loss = 0.00258310\n",
      "Iteration 7502, loss = 0.00258262\n",
      "Iteration 7503, loss = 0.00258207\n",
      "Iteration 7504, loss = 0.00258149\n",
      "Iteration 7505, loss = 0.00258095\n",
      "Iteration 7506, loss = 0.00258040\n",
      "Iteration 7507, loss = 0.00258005\n",
      "Iteration 7508, loss = 0.00257937\n",
      "Iteration 7509, loss = 0.00257896\n",
      "Iteration 7510, loss = 0.00257855\n",
      "Iteration 7511, loss = 0.00257777\n",
      "Iteration 7512, loss = 0.00257724\n",
      "Iteration 7513, loss = 0.00257660\n",
      "Iteration 7514, loss = 0.00257604\n",
      "Iteration 7515, loss = 0.00257555\n",
      "Iteration 7516, loss = 0.00257502\n",
      "Iteration 7517, loss = 0.00257450\n",
      "Iteration 7518, loss = 0.00257393\n",
      "Iteration 7519, loss = 0.00257342\n",
      "Iteration 7520, loss = 0.00257323\n",
      "Iteration 7521, loss = 0.00257246\n",
      "Iteration 7522, loss = 0.00257194\n",
      "Iteration 7523, loss = 0.00257148\n",
      "Iteration 7524, loss = 0.00257094\n",
      "Iteration 7525, loss = 0.00257043\n",
      "Iteration 7526, loss = 0.00256988\n",
      "Iteration 7527, loss = 0.00256944\n",
      "Iteration 7528, loss = 0.00256893\n",
      "Iteration 7529, loss = 0.00256854\n",
      "Iteration 7530, loss = 0.00256797\n",
      "Iteration 7531, loss = 0.00256746\n",
      "Iteration 7532, loss = 0.00256698\n",
      "Iteration 7533, loss = 0.00256654\n",
      "Iteration 7534, loss = 0.00256601\n",
      "Iteration 7535, loss = 0.00256550\n",
      "Iteration 7536, loss = 0.00256515\n",
      "Iteration 7537, loss = 0.00256466\n",
      "Iteration 7538, loss = 0.00256406\n",
      "Iteration 7539, loss = 0.00256362\n",
      "Iteration 7540, loss = 0.00256316\n",
      "Iteration 7541, loss = 0.00256271\n",
      "Iteration 7542, loss = 0.00256220\n",
      "Iteration 7543, loss = 0.00256174\n",
      "Iteration 7544, loss = 0.00256121\n",
      "Iteration 7545, loss = 0.00256071\n",
      "Iteration 7546, loss = 0.00256019\n",
      "Iteration 7547, loss = 0.00255979\n",
      "Iteration 7548, loss = 0.00255920\n",
      "Iteration 7549, loss = 0.00255874\n",
      "Iteration 7550, loss = 0.00255816\n",
      "Iteration 7551, loss = 0.00255774\n",
      "Iteration 7552, loss = 0.00255720\n",
      "Iteration 7553, loss = 0.00255672\n",
      "Iteration 7554, loss = 0.00255626\n",
      "Iteration 7555, loss = 0.00255569\n",
      "Iteration 7556, loss = 0.00255521\n",
      "Iteration 7557, loss = 0.00255469\n",
      "Iteration 7558, loss = 0.00255429\n",
      "Iteration 7559, loss = 0.00255376\n",
      "Iteration 7560, loss = 0.00255342\n",
      "Iteration 7561, loss = 0.00255281\n",
      "Iteration 7562, loss = 0.00255233\n",
      "Iteration 7563, loss = 0.00255181\n",
      "Iteration 7564, loss = 0.00255134\n",
      "Iteration 7565, loss = 0.00255082\n",
      "Iteration 7566, loss = 0.00255043\n",
      "Iteration 7567, loss = 0.00254987\n",
      "Iteration 7568, loss = 0.00254934\n",
      "Iteration 7569, loss = 0.00254882\n",
      "Iteration 7570, loss = 0.00254829\n",
      "Iteration 7571, loss = 0.00254788\n",
      "Iteration 7572, loss = 0.00254737\n",
      "Iteration 7573, loss = 0.00254689\n",
      "Iteration 7574, loss = 0.00254640\n",
      "Iteration 7575, loss = 0.00254591\n",
      "Iteration 7576, loss = 0.00254556\n",
      "Iteration 7577, loss = 0.00254504\n",
      "Iteration 7578, loss = 0.00254450\n",
      "Iteration 7579, loss = 0.00254403\n",
      "Iteration 7580, loss = 0.00254351\n",
      "Iteration 7581, loss = 0.00254304\n",
      "Iteration 7582, loss = 0.00254243\n",
      "Iteration 7583, loss = 0.00254199\n",
      "Iteration 7584, loss = 0.00254139\n",
      "Iteration 7585, loss = 0.00254081\n",
      "Iteration 7586, loss = 0.00254030\n",
      "Iteration 7587, loss = 0.00253984\n",
      "Iteration 7588, loss = 0.00253927\n",
      "Iteration 7589, loss = 0.00253877\n",
      "Iteration 7590, loss = 0.00253825\n",
      "Iteration 7591, loss = 0.00253771\n",
      "Iteration 7592, loss = 0.00253728\n",
      "Iteration 7593, loss = 0.00253676\n",
      "Iteration 7594, loss = 0.00253630\n",
      "Iteration 7595, loss = 0.00253576\n",
      "Iteration 7596, loss = 0.00253524\n",
      "Iteration 7597, loss = 0.00253473\n",
      "Iteration 7598, loss = 0.00253428\n",
      "Iteration 7599, loss = 0.00253385\n",
      "Iteration 7600, loss = 0.00253330\n",
      "Iteration 7601, loss = 0.00253280\n",
      "Iteration 7602, loss = 0.00253236\n",
      "Iteration 7603, loss = 0.00253182\n",
      "Iteration 7604, loss = 0.00253144\n",
      "Iteration 7605, loss = 0.00253094\n",
      "Iteration 7606, loss = 0.00253044\n",
      "Iteration 7607, loss = 0.00252999\n",
      "Iteration 7608, loss = 0.00252956\n",
      "Iteration 7609, loss = 0.00252911\n",
      "Iteration 7610, loss = 0.00252852\n",
      "Iteration 7611, loss = 0.00252802\n",
      "Iteration 7612, loss = 0.00252755\n",
      "Iteration 7613, loss = 0.00252719\n",
      "Iteration 7614, loss = 0.00252663\n",
      "Iteration 7615, loss = 0.00252610\n",
      "Iteration 7616, loss = 0.00252560\n",
      "Iteration 7617, loss = 0.00252523\n",
      "Iteration 7618, loss = 0.00252467\n",
      "Iteration 7619, loss = 0.00252419\n",
      "Iteration 7620, loss = 0.00252369\n",
      "Iteration 7621, loss = 0.00252321\n",
      "Iteration 7622, loss = 0.00252278\n",
      "Iteration 7623, loss = 0.00252220\n",
      "Iteration 7624, loss = 0.00252166\n",
      "Iteration 7625, loss = 0.00252126\n",
      "Iteration 7626, loss = 0.00252082\n",
      "Iteration 7627, loss = 0.00252032\n",
      "Iteration 7628, loss = 0.00251974\n",
      "Iteration 7629, loss = 0.00251940\n",
      "Iteration 7630, loss = 0.00251883\n",
      "Iteration 7631, loss = 0.00251827\n",
      "Iteration 7632, loss = 0.00251782\n",
      "Iteration 7633, loss = 0.00251723\n",
      "Iteration 7634, loss = 0.00251673\n",
      "Iteration 7635, loss = 0.00251619\n",
      "Iteration 7636, loss = 0.00251573\n",
      "Iteration 7637, loss = 0.00251521\n",
      "Iteration 7638, loss = 0.00251477\n",
      "Iteration 7639, loss = 0.00251425\n",
      "Iteration 7640, loss = 0.00251380\n",
      "Iteration 7641, loss = 0.00251332\n",
      "Iteration 7642, loss = 0.00251287\n",
      "Iteration 7643, loss = 0.00251241\n",
      "Iteration 7644, loss = 0.00251197\n",
      "Iteration 7645, loss = 0.00251152\n",
      "Iteration 7646, loss = 0.00251115\n",
      "Iteration 7647, loss = 0.00251074\n",
      "Iteration 7648, loss = 0.00251019\n",
      "Iteration 7649, loss = 0.00250969\n",
      "Iteration 7650, loss = 0.00250912\n",
      "Iteration 7651, loss = 0.00250871\n",
      "Iteration 7652, loss = 0.00250810\n",
      "Iteration 7653, loss = 0.00250769\n",
      "Iteration 7654, loss = 0.00250710\n",
      "Iteration 7655, loss = 0.00250658\n",
      "Iteration 7656, loss = 0.00250611\n",
      "Iteration 7657, loss = 0.00250572\n",
      "Iteration 7658, loss = 0.00250516\n",
      "Iteration 7659, loss = 0.00250470\n",
      "Iteration 7660, loss = 0.00250425\n",
      "Iteration 7661, loss = 0.00250375\n",
      "Iteration 7662, loss = 0.00250334\n",
      "Iteration 7663, loss = 0.00250283\n",
      "Iteration 7664, loss = 0.00250240\n",
      "Iteration 7665, loss = 0.00250194\n",
      "Iteration 7666, loss = 0.00250155\n",
      "Iteration 7667, loss = 0.00250109\n",
      "Iteration 7668, loss = 0.00250079\n",
      "Iteration 7669, loss = 0.00250032\n",
      "Iteration 7670, loss = 0.00249989\n",
      "Iteration 7671, loss = 0.00249947\n",
      "Iteration 7672, loss = 0.00249900\n",
      "Iteration 7673, loss = 0.00249865\n",
      "Iteration 7674, loss = 0.00249813\n",
      "Iteration 7675, loss = 0.00249772\n",
      "Iteration 7676, loss = 0.00249724\n",
      "Iteration 7677, loss = 0.00249667\n",
      "Iteration 7678, loss = 0.00249617\n",
      "Iteration 7679, loss = 0.00249570\n",
      "Iteration 7680, loss = 0.00249518\n",
      "Iteration 7681, loss = 0.00249471\n",
      "Iteration 7682, loss = 0.00249440\n",
      "Iteration 7683, loss = 0.00249374\n",
      "Iteration 7684, loss = 0.00249334\n",
      "Iteration 7685, loss = 0.00249281\n",
      "Iteration 7686, loss = 0.00249227\n",
      "Iteration 7687, loss = 0.00249188\n",
      "Iteration 7688, loss = 0.00249116\n",
      "Iteration 7689, loss = 0.00249053\n",
      "Iteration 7690, loss = 0.00249013\n",
      "Iteration 7691, loss = 0.00248955\n",
      "Iteration 7692, loss = 0.00248916\n",
      "Iteration 7693, loss = 0.00248851\n",
      "Iteration 7694, loss = 0.00248804\n",
      "Iteration 7695, loss = 0.00248755\n",
      "Iteration 7696, loss = 0.00248705\n",
      "Iteration 7697, loss = 0.00248657\n",
      "Iteration 7698, loss = 0.00248610\n",
      "Iteration 7699, loss = 0.00248568\n",
      "Iteration 7700, loss = 0.00248518\n",
      "Iteration 7701, loss = 0.00248463\n",
      "Iteration 7702, loss = 0.00248438\n",
      "Iteration 7703, loss = 0.00248373\n",
      "Iteration 7704, loss = 0.00248327\n",
      "Iteration 7705, loss = 0.00248271\n",
      "Iteration 7706, loss = 0.00248223\n",
      "Iteration 7707, loss = 0.00248184\n",
      "Iteration 7708, loss = 0.00248125\n",
      "Iteration 7709, loss = 0.00248076\n",
      "Iteration 7710, loss = 0.00248030\n",
      "Iteration 7711, loss = 0.00247982\n",
      "Iteration 7712, loss = 0.00247933\n",
      "Iteration 7713, loss = 0.00247898\n",
      "Iteration 7714, loss = 0.00247841\n",
      "Iteration 7715, loss = 0.00247803\n",
      "Iteration 7716, loss = 0.00247744\n",
      "Iteration 7717, loss = 0.00247708\n",
      "Iteration 7718, loss = 0.00247649\n",
      "Iteration 7719, loss = 0.00247603\n",
      "Iteration 7720, loss = 0.00247547\n",
      "Iteration 7721, loss = 0.00247496\n",
      "Iteration 7722, loss = 0.00247455\n",
      "Iteration 7723, loss = 0.00247402\n",
      "Iteration 7724, loss = 0.00247351\n",
      "Iteration 7725, loss = 0.00247302\n",
      "Iteration 7726, loss = 0.00247267\n",
      "Iteration 7727, loss = 0.00247205\n",
      "Iteration 7728, loss = 0.00247163\n",
      "Iteration 7729, loss = 0.00247100\n",
      "Iteration 7730, loss = 0.00247043\n",
      "Iteration 7731, loss = 0.00247008\n",
      "Iteration 7732, loss = 0.00246944\n",
      "Iteration 7733, loss = 0.00246892\n",
      "Iteration 7734, loss = 0.00246851\n",
      "Iteration 7735, loss = 0.00246796\n",
      "Iteration 7736, loss = 0.00246742\n",
      "Iteration 7737, loss = 0.00246693\n",
      "Iteration 7738, loss = 0.00246646\n",
      "Iteration 7739, loss = 0.00246592\n",
      "Iteration 7740, loss = 0.00246543\n",
      "Iteration 7741, loss = 0.00246496\n",
      "Iteration 7742, loss = 0.00246452\n",
      "Iteration 7743, loss = 0.00246400\n",
      "Iteration 7744, loss = 0.00246350\n",
      "Iteration 7745, loss = 0.00246314\n",
      "Iteration 7746, loss = 0.00246268\n",
      "Iteration 7747, loss = 0.00246212\n",
      "Iteration 7748, loss = 0.00246175\n",
      "Iteration 7749, loss = 0.00246118\n",
      "Iteration 7750, loss = 0.00246067\n",
      "Iteration 7751, loss = 0.00246021\n",
      "Iteration 7752, loss = 0.00245978\n",
      "Iteration 7753, loss = 0.00245925\n",
      "Iteration 7754, loss = 0.00245884\n",
      "Iteration 7755, loss = 0.00245832\n",
      "Iteration 7756, loss = 0.00245788\n",
      "Iteration 7757, loss = 0.00245748\n",
      "Iteration 7758, loss = 0.00245704\n",
      "Iteration 7759, loss = 0.00245652\n",
      "Iteration 7760, loss = 0.00245605\n",
      "Iteration 7761, loss = 0.00245565\n",
      "Iteration 7762, loss = 0.00245517\n",
      "Iteration 7763, loss = 0.00245450\n",
      "Iteration 7764, loss = 0.00245399\n",
      "Iteration 7765, loss = 0.00245355\n",
      "Iteration 7766, loss = 0.00245307\n",
      "Iteration 7767, loss = 0.00245251\n",
      "Iteration 7768, loss = 0.00245201\n",
      "Iteration 7769, loss = 0.00245148\n",
      "Iteration 7770, loss = 0.00245134\n",
      "Iteration 7771, loss = 0.00245053\n",
      "Iteration 7772, loss = 0.00245008\n",
      "Iteration 7773, loss = 0.00244951\n",
      "Iteration 7774, loss = 0.00244901\n",
      "Iteration 7775, loss = 0.00244850\n",
      "Iteration 7776, loss = 0.00244801\n",
      "Iteration 7777, loss = 0.00244753\n",
      "Iteration 7778, loss = 0.00244708\n",
      "Iteration 7779, loss = 0.00244661\n",
      "Iteration 7780, loss = 0.00244610\n",
      "Iteration 7781, loss = 0.00244568\n",
      "Iteration 7782, loss = 0.00244515\n",
      "Iteration 7783, loss = 0.00244469\n",
      "Iteration 7784, loss = 0.00244417\n",
      "Iteration 7785, loss = 0.00244369\n",
      "Iteration 7786, loss = 0.00244321\n",
      "Iteration 7787, loss = 0.00244275\n",
      "Iteration 7788, loss = 0.00244240\n",
      "Iteration 7789, loss = 0.00244180\n",
      "Iteration 7790, loss = 0.00244142\n",
      "Iteration 7791, loss = 0.00244091\n",
      "Iteration 7792, loss = 0.00244045\n",
      "Iteration 7793, loss = 0.00244001\n",
      "Iteration 7794, loss = 0.00243956\n",
      "Iteration 7795, loss = 0.00243914\n",
      "Iteration 7796, loss = 0.00243869\n",
      "Iteration 7797, loss = 0.00243827\n",
      "Iteration 7798, loss = 0.00243778\n",
      "Iteration 7799, loss = 0.00243727\n",
      "Iteration 7800, loss = 0.00243693\n",
      "Iteration 7801, loss = 0.00243643\n",
      "Iteration 7802, loss = 0.00243602\n",
      "Iteration 7803, loss = 0.00243546\n",
      "Iteration 7804, loss = 0.00243498\n",
      "Iteration 7805, loss = 0.00243452\n",
      "Iteration 7806, loss = 0.00243411\n",
      "Iteration 7807, loss = 0.00243369\n",
      "Iteration 7808, loss = 0.00243327\n",
      "Iteration 7809, loss = 0.00243287\n",
      "Iteration 7810, loss = 0.00243235\n",
      "Iteration 7811, loss = 0.00243189\n",
      "Iteration 7812, loss = 0.00243155\n",
      "Iteration 7813, loss = 0.00243102\n",
      "Iteration 7814, loss = 0.00243056\n",
      "Iteration 7815, loss = 0.00243017\n",
      "Iteration 7816, loss = 0.00242964\n",
      "Iteration 7817, loss = 0.00242913\n",
      "Iteration 7818, loss = 0.00242870\n",
      "Iteration 7819, loss = 0.00242829\n",
      "Iteration 7820, loss = 0.00242776\n",
      "Iteration 7821, loss = 0.00242730\n",
      "Iteration 7822, loss = 0.00242679\n",
      "Iteration 7823, loss = 0.00242632\n",
      "Iteration 7824, loss = 0.00242586\n",
      "Iteration 7825, loss = 0.00242536\n",
      "Iteration 7826, loss = 0.00242490\n",
      "Iteration 7827, loss = 0.00242440\n",
      "Iteration 7828, loss = 0.00242396\n",
      "Iteration 7829, loss = 0.00242357\n",
      "Iteration 7830, loss = 0.00242320\n",
      "Iteration 7831, loss = 0.00242274\n",
      "Iteration 7832, loss = 0.00242212\n",
      "Iteration 7833, loss = 0.00242163\n",
      "Iteration 7834, loss = 0.00242111\n",
      "Iteration 7835, loss = 0.00242059\n",
      "Iteration 7836, loss = 0.00242025\n",
      "Iteration 7837, loss = 0.00241969\n",
      "Iteration 7838, loss = 0.00241924\n",
      "Iteration 7839, loss = 0.00241872\n",
      "Iteration 7840, loss = 0.00241825\n",
      "Iteration 7841, loss = 0.00241777\n",
      "Iteration 7842, loss = 0.00241734\n",
      "Iteration 7843, loss = 0.00241685\n",
      "Iteration 7844, loss = 0.00241643\n",
      "Iteration 7845, loss = 0.00241598\n",
      "Iteration 7846, loss = 0.00241551\n",
      "Iteration 7847, loss = 0.00241512\n",
      "Iteration 7848, loss = 0.00241466\n",
      "Iteration 7849, loss = 0.00241416\n",
      "Iteration 7850, loss = 0.00241371\n",
      "Iteration 7851, loss = 0.00241324\n",
      "Iteration 7852, loss = 0.00241279\n",
      "Iteration 7853, loss = 0.00241233\n",
      "Iteration 7854, loss = 0.00241187\n",
      "Iteration 7855, loss = 0.00241152\n",
      "Iteration 7856, loss = 0.00241109\n",
      "Iteration 7857, loss = 0.00241064\n",
      "Iteration 7858, loss = 0.00241020\n",
      "Iteration 7859, loss = 0.00240976\n",
      "Iteration 7860, loss = 0.00240934\n",
      "Iteration 7861, loss = 0.00240907\n",
      "Iteration 7862, loss = 0.00240854\n",
      "Iteration 7863, loss = 0.00240811\n",
      "Iteration 7864, loss = 0.00240766\n",
      "Iteration 7865, loss = 0.00240724\n",
      "Iteration 7866, loss = 0.00240675\n",
      "Iteration 7867, loss = 0.00240631\n",
      "Iteration 7868, loss = 0.00240592\n",
      "Iteration 7869, loss = 0.00240545\n",
      "Iteration 7870, loss = 0.00240505\n",
      "Iteration 7871, loss = 0.00240463\n",
      "Iteration 7872, loss = 0.00240418\n",
      "Iteration 7873, loss = 0.00240367\n",
      "Iteration 7874, loss = 0.00240321\n",
      "Iteration 7875, loss = 0.00240278\n",
      "Iteration 7876, loss = 0.00240228\n",
      "Iteration 7877, loss = 0.00240175\n",
      "Iteration 7878, loss = 0.00240153\n",
      "Iteration 7879, loss = 0.00240097\n",
      "Iteration 7880, loss = 0.00240046\n",
      "Iteration 7881, loss = 0.00240022\n",
      "Iteration 7882, loss = 0.00239973\n",
      "Iteration 7883, loss = 0.00239925\n",
      "Iteration 7884, loss = 0.00239875\n",
      "Iteration 7885, loss = 0.00239834\n",
      "Iteration 7886, loss = 0.00239784\n",
      "Iteration 7887, loss = 0.00239755\n",
      "Iteration 7888, loss = 0.00239701\n",
      "Iteration 7889, loss = 0.00239650\n",
      "Iteration 7890, loss = 0.00239605\n",
      "Iteration 7891, loss = 0.00239570\n",
      "Iteration 7892, loss = 0.00239525\n",
      "Iteration 7893, loss = 0.00239476\n",
      "Iteration 7894, loss = 0.00239438\n",
      "Iteration 7895, loss = 0.00239390\n",
      "Iteration 7896, loss = 0.00239345\n",
      "Iteration 7897, loss = 0.00239306\n",
      "Iteration 7898, loss = 0.00239284\n",
      "Iteration 7899, loss = 0.00239215\n",
      "Iteration 7900, loss = 0.00239171\n",
      "Iteration 7901, loss = 0.00239125\n",
      "Iteration 7902, loss = 0.00239081\n",
      "Iteration 7903, loss = 0.00239040\n",
      "Iteration 7904, loss = 0.00238995\n",
      "Iteration 7905, loss = 0.00238952\n",
      "Iteration 7906, loss = 0.00238907\n",
      "Iteration 7907, loss = 0.00238865\n",
      "Iteration 7908, loss = 0.00238840\n",
      "Iteration 7909, loss = 0.00238798\n",
      "Iteration 7910, loss = 0.00238779\n",
      "Iteration 7911, loss = 0.00238718\n",
      "Iteration 7912, loss = 0.00238678\n",
      "Iteration 7913, loss = 0.00238632\n",
      "Iteration 7914, loss = 0.00238587\n",
      "Iteration 7915, loss = 0.00238545\n",
      "Iteration 7916, loss = 0.00238504\n",
      "Iteration 7917, loss = 0.00238471\n",
      "Iteration 7918, loss = 0.00238420\n",
      "Iteration 7919, loss = 0.00238373\n",
      "Iteration 7920, loss = 0.00238345\n",
      "Iteration 7921, loss = 0.00238289\n",
      "Iteration 7922, loss = 0.00238252\n",
      "Iteration 7923, loss = 0.00238212\n",
      "Iteration 7924, loss = 0.00238169\n",
      "Iteration 7925, loss = 0.00238128\n",
      "Iteration 7926, loss = 0.00238072\n",
      "Iteration 7927, loss = 0.00238032\n",
      "Iteration 7928, loss = 0.00238002\n",
      "Iteration 7929, loss = 0.00237946\n",
      "Iteration 7930, loss = 0.00237894\n",
      "Iteration 7931, loss = 0.00237850\n",
      "Iteration 7932, loss = 0.00237808\n",
      "Iteration 7933, loss = 0.00237759\n",
      "Iteration 7934, loss = 0.00237715\n",
      "Iteration 7935, loss = 0.00237673\n",
      "Iteration 7936, loss = 0.00237631\n",
      "Iteration 7937, loss = 0.00237589\n",
      "Iteration 7938, loss = 0.00237544\n",
      "Iteration 7939, loss = 0.00237507\n",
      "Iteration 7940, loss = 0.00237460\n",
      "Iteration 7941, loss = 0.00237440\n",
      "Iteration 7942, loss = 0.00237377\n",
      "Iteration 7943, loss = 0.00237334\n",
      "Iteration 7944, loss = 0.00237289\n",
      "Iteration 7945, loss = 0.00237237\n",
      "Iteration 7946, loss = 0.00237202\n",
      "Iteration 7947, loss = 0.00237146\n",
      "Iteration 7948, loss = 0.00237102\n",
      "Iteration 7949, loss = 0.00237059\n",
      "Iteration 7950, loss = 0.00237021\n",
      "Iteration 7951, loss = 0.00236965\n",
      "Iteration 7952, loss = 0.00236925\n",
      "Iteration 7953, loss = 0.00236880\n",
      "Iteration 7954, loss = 0.00236852\n",
      "Iteration 7955, loss = 0.00236795\n",
      "Iteration 7956, loss = 0.00236750\n",
      "Iteration 7957, loss = 0.00236704\n",
      "Iteration 7958, loss = 0.00236661\n",
      "Iteration 7959, loss = 0.00236625\n",
      "Iteration 7960, loss = 0.00236575\n",
      "Iteration 7961, loss = 0.00236527\n",
      "Iteration 7962, loss = 0.00236512\n",
      "Iteration 7963, loss = 0.00236442\n",
      "Iteration 7964, loss = 0.00236397\n",
      "Iteration 7965, loss = 0.00236367\n",
      "Iteration 7966, loss = 0.00236310\n",
      "Iteration 7967, loss = 0.00236258\n",
      "Iteration 7968, loss = 0.00236223\n",
      "Iteration 7969, loss = 0.00236173\n",
      "Iteration 7970, loss = 0.00236124\n",
      "Iteration 7971, loss = 0.00236076\n",
      "Iteration 7972, loss = 0.00236028\n",
      "Iteration 7973, loss = 0.00235975\n",
      "Iteration 7974, loss = 0.00235935\n",
      "Iteration 7975, loss = 0.00235888\n",
      "Iteration 7976, loss = 0.00235849\n",
      "Iteration 7977, loss = 0.00235796\n",
      "Iteration 7978, loss = 0.00235760\n",
      "Iteration 7979, loss = 0.00235708\n",
      "Iteration 7980, loss = 0.00235650\n",
      "Iteration 7981, loss = 0.00235609\n",
      "Iteration 7982, loss = 0.00235561\n",
      "Iteration 7983, loss = 0.00235529\n",
      "Iteration 7984, loss = 0.00235480\n",
      "Iteration 7985, loss = 0.00235434\n",
      "Iteration 7986, loss = 0.00235392\n",
      "Iteration 7987, loss = 0.00235354\n",
      "Iteration 7988, loss = 0.00235308\n",
      "Iteration 7989, loss = 0.00235267\n",
      "Iteration 7990, loss = 0.00235219\n",
      "Iteration 7991, loss = 0.00235174\n",
      "Iteration 7992, loss = 0.00235131\n",
      "Iteration 7993, loss = 0.00235084\n",
      "Iteration 7994, loss = 0.00235036\n",
      "Iteration 7995, loss = 0.00234994\n",
      "Iteration 7996, loss = 0.00234939\n",
      "Iteration 7997, loss = 0.00234908\n",
      "Iteration 7998, loss = 0.00234852\n",
      "Iteration 7999, loss = 0.00234819\n",
      "Iteration 8000, loss = 0.00234776\n",
      "Iteration 1, loss = 1.02924602\n",
      "Iteration 2, loss = 1.02603546\n",
      "Iteration 3, loss = 1.02105733\n",
      "Iteration 4, loss = 1.01483506\n",
      "Iteration 5, loss = 1.00742757\n",
      "Iteration 6, loss = 0.99962128\n",
      "Iteration 7, loss = 0.99108443\n",
      "Iteration 8, loss = 0.98219828\n",
      "Iteration 9, loss = 0.97309884\n",
      "Iteration 10, loss = 0.96388227\n",
      "Iteration 11, loss = 0.95452481\n",
      "Iteration 12, loss = 0.94526268\n",
      "Iteration 13, loss = 0.93599634\n",
      "Iteration 14, loss = 0.92684828\n",
      "Iteration 15, loss = 0.91785871\n",
      "Iteration 16, loss = 0.90903557\n",
      "Iteration 17, loss = 0.90042755\n",
      "Iteration 18, loss = 0.89225408\n",
      "Iteration 19, loss = 0.88395934\n",
      "Iteration 20, loss = 0.87615366\n",
      "Iteration 21, loss = 0.86838927\n",
      "Iteration 22, loss = 0.86096845\n",
      "Iteration 23, loss = 0.85377428\n",
      "Iteration 24, loss = 0.84633931\n",
      "Iteration 25, loss = 0.83952342\n",
      "Iteration 26, loss = 0.83248898\n",
      "Iteration 27, loss = 0.82602981\n",
      "Iteration 28, loss = 0.81924763\n",
      "Iteration 29, loss = 0.81315270\n",
      "Iteration 30, loss = 0.80715108\n",
      "Iteration 31, loss = 0.80106190\n",
      "Iteration 32, loss = 0.79553018\n",
      "Iteration 33, loss = 0.78995926\n",
      "Iteration 34, loss = 0.78455907\n",
      "Iteration 35, loss = 0.77934658\n",
      "Iteration 36, loss = 0.77447143\n",
      "Iteration 37, loss = 0.76944722\n",
      "Iteration 38, loss = 0.76489379\n",
      "Iteration 39, loss = 0.76018095\n",
      "Iteration 40, loss = 0.75574900\n",
      "Iteration 41, loss = 0.75131218\n",
      "Iteration 42, loss = 0.74710791\n",
      "Iteration 43, loss = 0.74280644\n",
      "Iteration 44, loss = 0.73873723\n",
      "Iteration 45, loss = 0.73475250\n",
      "Iteration 46, loss = 0.73086877\n",
      "Iteration 47, loss = 0.72698467\n",
      "Iteration 48, loss = 0.72338309\n",
      "Iteration 49, loss = 0.71966340\n",
      "Iteration 50, loss = 0.71612645\n",
      "Iteration 51, loss = 0.71266253\n",
      "Iteration 52, loss = 0.70920878\n",
      "Iteration 53, loss = 0.70595190\n",
      "Iteration 54, loss = 0.70270387\n",
      "Iteration 55, loss = 0.69943385\n",
      "Iteration 56, loss = 0.69631865\n",
      "Iteration 57, loss = 0.69331139\n",
      "Iteration 58, loss = 0.69009054\n",
      "Iteration 59, loss = 0.68719258\n",
      "Iteration 60, loss = 0.68424958\n",
      "Iteration 61, loss = 0.68138899\n",
      "Iteration 62, loss = 0.67860111\n",
      "Iteration 63, loss = 0.67578011\n",
      "Iteration 64, loss = 0.67308598\n",
      "Iteration 65, loss = 0.67045977\n",
      "Iteration 66, loss = 0.66778765\n",
      "Iteration 67, loss = 0.66512930\n",
      "Iteration 68, loss = 0.66249015\n",
      "Iteration 69, loss = 0.65988812\n",
      "Iteration 70, loss = 0.65736972\n",
      "Iteration 71, loss = 0.65469456\n",
      "Iteration 72, loss = 0.65219536\n",
      "Iteration 73, loss = 0.64960319\n",
      "Iteration 74, loss = 0.64705161\n",
      "Iteration 75, loss = 0.64440332\n",
      "Iteration 76, loss = 0.64187148\n",
      "Iteration 77, loss = 0.63928682\n",
      "Iteration 78, loss = 0.63670427\n",
      "Iteration 79, loss = 0.63410211\n",
      "Iteration 80, loss = 0.63161845\n",
      "Iteration 81, loss = 0.62906962\n",
      "Iteration 82, loss = 0.62656255\n",
      "Iteration 83, loss = 0.62407469\n",
      "Iteration 84, loss = 0.62156008\n",
      "Iteration 85, loss = 0.61908128\n",
      "Iteration 86, loss = 0.61665382\n",
      "Iteration 87, loss = 0.61411858\n",
      "Iteration 88, loss = 0.61168684\n",
      "Iteration 89, loss = 0.60921949\n",
      "Iteration 90, loss = 0.60671258\n",
      "Iteration 91, loss = 0.60431214\n",
      "Iteration 92, loss = 0.60185581\n",
      "Iteration 93, loss = 0.59940666\n",
      "Iteration 94, loss = 0.59698626\n",
      "Iteration 95, loss = 0.59458103\n",
      "Iteration 96, loss = 0.59217660\n",
      "Iteration 97, loss = 0.58977010\n",
      "Iteration 98, loss = 0.58734829\n",
      "Iteration 99, loss = 0.58500078\n",
      "Iteration 100, loss = 0.58262236\n",
      "Iteration 101, loss = 0.58017293\n",
      "Iteration 102, loss = 0.57781746\n",
      "Iteration 103, loss = 0.57542895\n",
      "Iteration 104, loss = 0.57314227\n",
      "Iteration 105, loss = 0.57076749\n",
      "Iteration 106, loss = 0.56849826\n",
      "Iteration 107, loss = 0.56615903\n",
      "Iteration 108, loss = 0.56392450\n",
      "Iteration 109, loss = 0.56164704\n",
      "Iteration 110, loss = 0.55941008\n",
      "Iteration 111, loss = 0.55719311\n",
      "Iteration 112, loss = 0.55494160\n",
      "Iteration 113, loss = 0.55276953\n",
      "Iteration 114, loss = 0.55053829\n",
      "Iteration 115, loss = 0.54833783\n",
      "Iteration 116, loss = 0.54614691\n",
      "Iteration 117, loss = 0.54395414\n",
      "Iteration 118, loss = 0.54177558\n",
      "Iteration 119, loss = 0.53954130\n",
      "Iteration 120, loss = 0.53735566\n",
      "Iteration 121, loss = 0.53515370\n",
      "Iteration 122, loss = 0.53296517\n",
      "Iteration 123, loss = 0.53072684\n",
      "Iteration 124, loss = 0.52854243\n",
      "Iteration 125, loss = 0.52635891\n",
      "Iteration 126, loss = 0.52420246\n",
      "Iteration 127, loss = 0.52204443\n",
      "Iteration 128, loss = 0.51993817\n",
      "Iteration 129, loss = 0.51780842\n",
      "Iteration 130, loss = 0.51570171\n",
      "Iteration 131, loss = 0.51360608\n",
      "Iteration 132, loss = 0.51149977\n",
      "Iteration 133, loss = 0.50941025\n",
      "Iteration 134, loss = 0.50735225\n",
      "Iteration 135, loss = 0.50534412\n",
      "Iteration 136, loss = 0.50327052\n",
      "Iteration 137, loss = 0.50128588\n",
      "Iteration 138, loss = 0.49925054\n",
      "Iteration 139, loss = 0.49720713\n",
      "Iteration 140, loss = 0.49519920\n",
      "Iteration 141, loss = 0.49316535\n",
      "Iteration 142, loss = 0.49113195\n",
      "Iteration 143, loss = 0.48908202\n",
      "Iteration 144, loss = 0.48707068\n",
      "Iteration 145, loss = 0.48502283\n",
      "Iteration 146, loss = 0.48301353\n",
      "Iteration 147, loss = 0.48096521\n",
      "Iteration 148, loss = 0.47899061\n",
      "Iteration 149, loss = 0.47692410\n",
      "Iteration 150, loss = 0.47491734\n",
      "Iteration 151, loss = 0.47289591\n",
      "Iteration 152, loss = 0.47084326\n",
      "Iteration 153, loss = 0.46881112\n",
      "Iteration 154, loss = 0.46677407\n",
      "Iteration 155, loss = 0.46474389\n",
      "Iteration 156, loss = 0.46274724\n",
      "Iteration 157, loss = 0.46070250\n",
      "Iteration 158, loss = 0.45870887\n",
      "Iteration 159, loss = 0.45672828\n",
      "Iteration 160, loss = 0.45473843\n",
      "Iteration 161, loss = 0.45277439\n",
      "Iteration 162, loss = 0.45077487\n",
      "Iteration 163, loss = 0.44878563\n",
      "Iteration 164, loss = 0.44679976\n",
      "Iteration 165, loss = 0.44478924\n",
      "Iteration 166, loss = 0.44277280\n",
      "Iteration 167, loss = 0.44075524\n",
      "Iteration 168, loss = 0.43871821\n",
      "Iteration 169, loss = 0.43667311\n",
      "Iteration 170, loss = 0.43466095\n",
      "Iteration 171, loss = 0.43264896\n",
      "Iteration 172, loss = 0.43062170\n",
      "Iteration 173, loss = 0.42861561\n",
      "Iteration 174, loss = 0.42663590\n",
      "Iteration 175, loss = 0.42465066\n",
      "Iteration 176, loss = 0.42265289\n",
      "Iteration 177, loss = 0.42066712\n",
      "Iteration 178, loss = 0.41866203\n",
      "Iteration 179, loss = 0.41667322\n",
      "Iteration 180, loss = 0.41465665\n",
      "Iteration 181, loss = 0.41270262\n",
      "Iteration 182, loss = 0.41069065\n",
      "Iteration 183, loss = 0.40869818\n",
      "Iteration 184, loss = 0.40669532\n",
      "Iteration 185, loss = 0.40471763\n",
      "Iteration 186, loss = 0.40269160\n",
      "Iteration 187, loss = 0.40068973\n",
      "Iteration 188, loss = 0.39871020\n",
      "Iteration 189, loss = 0.39671682\n",
      "Iteration 190, loss = 0.39472239\n",
      "Iteration 191, loss = 0.39274426\n",
      "Iteration 192, loss = 0.39077957\n",
      "Iteration 193, loss = 0.38882104\n",
      "Iteration 194, loss = 0.38684197\n",
      "Iteration 195, loss = 0.38489387\n",
      "Iteration 196, loss = 0.38290493\n",
      "Iteration 197, loss = 0.38096548\n",
      "Iteration 198, loss = 0.37899056\n",
      "Iteration 199, loss = 0.37703116\n",
      "Iteration 200, loss = 0.37506953\n",
      "Iteration 201, loss = 0.37313178\n",
      "Iteration 202, loss = 0.37117795\n",
      "Iteration 203, loss = 0.36922441\n",
      "Iteration 204, loss = 0.36729257\n",
      "Iteration 205, loss = 0.36534681\n",
      "Iteration 206, loss = 0.36342134\n",
      "Iteration 207, loss = 0.36149502\n",
      "Iteration 208, loss = 0.35954903\n",
      "Iteration 209, loss = 0.35760907\n",
      "Iteration 210, loss = 0.35568083\n",
      "Iteration 211, loss = 0.35373932\n",
      "Iteration 212, loss = 0.35180325\n",
      "Iteration 213, loss = 0.34988277\n",
      "Iteration 214, loss = 0.34794520\n",
      "Iteration 215, loss = 0.34604789\n",
      "Iteration 216, loss = 0.34411153\n",
      "Iteration 217, loss = 0.34222069\n",
      "Iteration 218, loss = 0.34030006\n",
      "Iteration 219, loss = 0.33841150\n",
      "Iteration 220, loss = 0.33651514\n",
      "Iteration 221, loss = 0.33462666\n",
      "Iteration 222, loss = 0.33274681\n",
      "Iteration 223, loss = 0.33088673\n",
      "Iteration 224, loss = 0.32900635\n",
      "Iteration 225, loss = 0.32715567\n",
      "Iteration 226, loss = 0.32531085\n",
      "Iteration 227, loss = 0.32344605\n",
      "Iteration 228, loss = 0.32159611\n",
      "Iteration 229, loss = 0.31973413\n",
      "Iteration 230, loss = 0.31790861\n",
      "Iteration 231, loss = 0.31603995\n",
      "Iteration 232, loss = 0.31421882\n",
      "Iteration 233, loss = 0.31237157\n",
      "Iteration 234, loss = 0.31056578\n",
      "Iteration 235, loss = 0.30873843\n",
      "Iteration 236, loss = 0.30693946\n",
      "Iteration 237, loss = 0.30516459\n",
      "Iteration 238, loss = 0.30336425\n",
      "Iteration 239, loss = 0.30158247\n",
      "Iteration 240, loss = 0.29982116\n",
      "Iteration 241, loss = 0.29804938\n",
      "Iteration 242, loss = 0.29631688\n",
      "Iteration 243, loss = 0.29456208\n",
      "Iteration 244, loss = 0.29284208\n",
      "Iteration 245, loss = 0.29113682\n",
      "Iteration 246, loss = 0.28942884\n",
      "Iteration 247, loss = 0.28774231\n",
      "Iteration 248, loss = 0.28603346\n",
      "Iteration 249, loss = 0.28432956\n",
      "Iteration 250, loss = 0.28266819\n",
      "Iteration 251, loss = 0.28096579\n",
      "Iteration 252, loss = 0.27930589\n",
      "Iteration 253, loss = 0.27765279\n",
      "Iteration 254, loss = 0.27600775\n",
      "Iteration 255, loss = 0.27437185\n",
      "Iteration 256, loss = 0.27275860\n",
      "Iteration 257, loss = 0.27115837\n",
      "Iteration 258, loss = 0.26956320\n",
      "Iteration 259, loss = 0.26795471\n",
      "Iteration 260, loss = 0.26636446\n",
      "Iteration 261, loss = 0.26478702\n",
      "Iteration 262, loss = 0.26321724\n",
      "Iteration 263, loss = 0.26164282\n",
      "Iteration 264, loss = 0.26007192\n",
      "Iteration 265, loss = 0.25852905\n",
      "Iteration 266, loss = 0.25697096\n",
      "Iteration 267, loss = 0.25541713\n",
      "Iteration 268, loss = 0.25388783\n",
      "Iteration 269, loss = 0.25237025\n",
      "Iteration 270, loss = 0.25082961\n",
      "Iteration 271, loss = 0.24933923\n",
      "Iteration 272, loss = 0.24786124\n",
      "Iteration 273, loss = 0.24637547\n",
      "Iteration 274, loss = 0.24492379\n",
      "Iteration 275, loss = 0.24345511\n",
      "Iteration 276, loss = 0.24201145\n",
      "Iteration 277, loss = 0.24057646\n",
      "Iteration 278, loss = 0.23916280\n",
      "Iteration 279, loss = 0.23772565\n",
      "Iteration 280, loss = 0.23633787\n",
      "Iteration 281, loss = 0.23495405\n",
      "Iteration 282, loss = 0.23357922\n",
      "Iteration 283, loss = 0.23220610\n",
      "Iteration 284, loss = 0.23084772\n",
      "Iteration 285, loss = 0.22950058\n",
      "Iteration 286, loss = 0.22816489\n",
      "Iteration 287, loss = 0.22682556\n",
      "Iteration 288, loss = 0.22550811\n",
      "Iteration 289, loss = 0.22418907\n",
      "Iteration 290, loss = 0.22289384\n",
      "Iteration 291, loss = 0.22159602\n",
      "Iteration 292, loss = 0.22031019\n",
      "Iteration 293, loss = 0.21904436\n",
      "Iteration 294, loss = 0.21776983\n",
      "Iteration 295, loss = 0.21651019\n",
      "Iteration 296, loss = 0.21526756\n",
      "Iteration 297, loss = 0.21402523\n",
      "Iteration 298, loss = 0.21279084\n",
      "Iteration 299, loss = 0.21156524\n",
      "Iteration 300, loss = 0.21036874\n",
      "Iteration 301, loss = 0.20916407\n",
      "Iteration 302, loss = 0.20796614\n",
      "Iteration 303, loss = 0.20679637\n",
      "Iteration 304, loss = 0.20561984\n",
      "Iteration 305, loss = 0.20445149\n",
      "Iteration 306, loss = 0.20330330\n",
      "Iteration 307, loss = 0.20215457\n",
      "Iteration 308, loss = 0.20101614\n",
      "Iteration 309, loss = 0.19988303\n",
      "Iteration 310, loss = 0.19876384\n",
      "Iteration 311, loss = 0.19765760\n",
      "Iteration 312, loss = 0.19654948\n",
      "Iteration 313, loss = 0.19545722\n",
      "Iteration 314, loss = 0.19437479\n",
      "Iteration 315, loss = 0.19328107\n",
      "Iteration 316, loss = 0.19220726\n",
      "Iteration 317, loss = 0.19112978\n",
      "Iteration 318, loss = 0.19007224\n",
      "Iteration 319, loss = 0.18901460\n",
      "Iteration 320, loss = 0.18796264\n",
      "Iteration 321, loss = 0.18692718\n",
      "Iteration 322, loss = 0.18589328\n",
      "Iteration 323, loss = 0.18486635\n",
      "Iteration 324, loss = 0.18385734\n",
      "Iteration 325, loss = 0.18285011\n",
      "Iteration 326, loss = 0.18185724\n",
      "Iteration 327, loss = 0.18086137\n",
      "Iteration 328, loss = 0.17987375\n",
      "Iteration 329, loss = 0.17890750\n",
      "Iteration 330, loss = 0.17794440\n",
      "Iteration 331, loss = 0.17697913\n",
      "Iteration 332, loss = 0.17602643\n",
      "Iteration 333, loss = 0.17509916\n",
      "Iteration 334, loss = 0.17416546\n",
      "Iteration 335, loss = 0.17324501\n",
      "Iteration 336, loss = 0.17233478\n",
      "Iteration 337, loss = 0.17143193\n",
      "Iteration 338, loss = 0.17052948\n",
      "Iteration 339, loss = 0.16963939\n",
      "Iteration 340, loss = 0.16874972\n",
      "Iteration 341, loss = 0.16787027\n",
      "Iteration 342, loss = 0.16698927\n",
      "Iteration 343, loss = 0.16612287\n",
      "Iteration 344, loss = 0.16526084\n",
      "Iteration 345, loss = 0.16439470\n",
      "Iteration 346, loss = 0.16354445\n",
      "Iteration 347, loss = 0.16270045\n",
      "Iteration 348, loss = 0.16186072\n",
      "Iteration 349, loss = 0.16102969\n",
      "Iteration 350, loss = 0.16020778\n",
      "Iteration 351, loss = 0.15938586\n",
      "Iteration 352, loss = 0.15856686\n",
      "Iteration 353, loss = 0.15775241\n",
      "Iteration 354, loss = 0.15694320\n",
      "Iteration 355, loss = 0.15613410\n",
      "Iteration 356, loss = 0.15533129\n",
      "Iteration 357, loss = 0.15453758\n",
      "Iteration 358, loss = 0.15374954\n",
      "Iteration 359, loss = 0.15296978\n",
      "Iteration 360, loss = 0.15219740\n",
      "Iteration 361, loss = 0.15143417\n",
      "Iteration 362, loss = 0.15065915\n",
      "Iteration 363, loss = 0.14990561\n",
      "Iteration 364, loss = 0.14916137\n",
      "Iteration 365, loss = 0.14842298\n",
      "Iteration 366, loss = 0.14767302\n",
      "Iteration 367, loss = 0.14694517\n",
      "Iteration 368, loss = 0.14622487\n",
      "Iteration 369, loss = 0.14550991\n",
      "Iteration 370, loss = 0.14480204\n",
      "Iteration 371, loss = 0.14410428\n",
      "Iteration 372, loss = 0.14340990\n",
      "Iteration 373, loss = 0.14272620\n",
      "Iteration 374, loss = 0.14205129\n",
      "Iteration 375, loss = 0.14137245\n",
      "Iteration 376, loss = 0.14070591\n",
      "Iteration 377, loss = 0.14004966\n",
      "Iteration 378, loss = 0.13939514\n",
      "Iteration 379, loss = 0.13874085\n",
      "Iteration 380, loss = 0.13808974\n",
      "Iteration 381, loss = 0.13744648\n",
      "Iteration 382, loss = 0.13680282\n",
      "Iteration 383, loss = 0.13616311\n",
      "Iteration 384, loss = 0.13553743\n",
      "Iteration 385, loss = 0.13490845\n",
      "Iteration 386, loss = 0.13428355\n",
      "Iteration 387, loss = 0.13367115\n",
      "Iteration 388, loss = 0.13305746\n",
      "Iteration 389, loss = 0.13245578\n",
      "Iteration 390, loss = 0.13185517\n",
      "Iteration 391, loss = 0.13125530\n",
      "Iteration 392, loss = 0.13067401\n",
      "Iteration 393, loss = 0.13008602\n",
      "Iteration 394, loss = 0.12950769\n",
      "Iteration 395, loss = 0.12893473\n",
      "Iteration 396, loss = 0.12836706\n",
      "Iteration 397, loss = 0.12780429\n",
      "Iteration 398, loss = 0.12724223\n",
      "Iteration 399, loss = 0.12668648\n",
      "Iteration 400, loss = 0.12613283\n",
      "Iteration 401, loss = 0.12559175\n",
      "Iteration 402, loss = 0.12504451\n",
      "Iteration 403, loss = 0.12451278\n",
      "Iteration 404, loss = 0.12397731\n",
      "Iteration 405, loss = 0.12345182\n",
      "Iteration 406, loss = 0.12292284\n",
      "Iteration 407, loss = 0.12240750\n",
      "Iteration 408, loss = 0.12188772\n",
      "Iteration 409, loss = 0.12137565\n",
      "Iteration 410, loss = 0.12086586\n",
      "Iteration 411, loss = 0.12036634\n",
      "Iteration 412, loss = 0.11986602\n",
      "Iteration 413, loss = 0.11936929\n",
      "Iteration 414, loss = 0.11887600\n",
      "Iteration 415, loss = 0.11837819\n",
      "Iteration 416, loss = 0.11789344\n",
      "Iteration 417, loss = 0.11741049\n",
      "Iteration 418, loss = 0.11693493\n",
      "Iteration 419, loss = 0.11646266\n",
      "Iteration 420, loss = 0.11599939\n",
      "Iteration 421, loss = 0.11553834\n",
      "Iteration 422, loss = 0.11506985\n",
      "Iteration 423, loss = 0.11460741\n",
      "Iteration 424, loss = 0.11415603\n",
      "Iteration 425, loss = 0.11367885\n",
      "Iteration 426, loss = 0.11322584\n",
      "Iteration 427, loss = 0.11277249\n",
      "Iteration 428, loss = 0.11231074\n",
      "Iteration 429, loss = 0.11187360\n",
      "Iteration 430, loss = 0.11143025\n",
      "Iteration 431, loss = 0.11098465\n",
      "Iteration 432, loss = 0.11054912\n",
      "Iteration 433, loss = 0.11011909\n",
      "Iteration 434, loss = 0.10968908\n",
      "Iteration 435, loss = 0.10926581\n",
      "Iteration 436, loss = 0.10884739\n",
      "Iteration 437, loss = 0.10843071\n",
      "Iteration 438, loss = 0.10801787\n",
      "Iteration 439, loss = 0.10760880\n",
      "Iteration 440, loss = 0.10719954\n",
      "Iteration 441, loss = 0.10679799\n",
      "Iteration 442, loss = 0.10639834\n",
      "Iteration 443, loss = 0.10599963\n",
      "Iteration 444, loss = 0.10560472\n",
      "Iteration 445, loss = 0.10520960\n",
      "Iteration 446, loss = 0.10482045\n",
      "Iteration 447, loss = 0.10443112\n",
      "Iteration 448, loss = 0.10404754\n",
      "Iteration 449, loss = 0.10366733\n",
      "Iteration 450, loss = 0.10328783\n",
      "Iteration 451, loss = 0.10290995\n",
      "Iteration 452, loss = 0.10253512\n",
      "Iteration 453, loss = 0.10216436\n",
      "Iteration 454, loss = 0.10179646\n",
      "Iteration 455, loss = 0.10143199\n",
      "Iteration 456, loss = 0.10107005\n",
      "Iteration 457, loss = 0.10071285\n",
      "Iteration 458, loss = 0.10034938\n",
      "Iteration 459, loss = 0.09999305\n",
      "Iteration 460, loss = 0.09962636\n",
      "Iteration 461, loss = 0.09926585\n",
      "Iteration 462, loss = 0.09891871\n",
      "Iteration 463, loss = 0.09856182\n",
      "Iteration 464, loss = 0.09820512\n",
      "Iteration 465, loss = 0.09785349\n",
      "Iteration 466, loss = 0.09751065\n",
      "Iteration 467, loss = 0.09716691\n",
      "Iteration 468, loss = 0.09682545\n",
      "Iteration 469, loss = 0.09649023\n",
      "Iteration 470, loss = 0.09615861\n",
      "Iteration 471, loss = 0.09582515\n",
      "Iteration 472, loss = 0.09550044\n",
      "Iteration 473, loss = 0.09517294\n",
      "Iteration 474, loss = 0.09485392\n",
      "Iteration 475, loss = 0.09452947\n",
      "Iteration 476, loss = 0.09421402\n",
      "Iteration 477, loss = 0.09390619\n",
      "Iteration 478, loss = 0.09359449\n",
      "Iteration 479, loss = 0.09328712\n",
      "Iteration 480, loss = 0.09297668\n",
      "Iteration 481, loss = 0.09267530\n",
      "Iteration 482, loss = 0.09236265\n",
      "Iteration 483, loss = 0.09205586\n",
      "Iteration 484, loss = 0.09175222\n",
      "Iteration 485, loss = 0.09144827\n",
      "Iteration 486, loss = 0.09114477\n",
      "Iteration 487, loss = 0.09083978\n",
      "Iteration 488, loss = 0.09053944\n",
      "Iteration 489, loss = 0.09023793\n",
      "Iteration 490, loss = 0.08994338\n",
      "Iteration 491, loss = 0.08964620\n",
      "Iteration 492, loss = 0.08936313\n",
      "Iteration 493, loss = 0.08906741\n",
      "Iteration 494, loss = 0.08878510\n",
      "Iteration 495, loss = 0.08850630\n",
      "Iteration 496, loss = 0.08822437\n",
      "Iteration 497, loss = 0.08795587\n",
      "Iteration 498, loss = 0.08768108\n",
      "Iteration 499, loss = 0.08741482\n",
      "Iteration 500, loss = 0.08716119\n",
      "Iteration 501, loss = 0.08689239\n",
      "Iteration 502, loss = 0.08662142\n",
      "Iteration 503, loss = 0.08636815\n",
      "Iteration 504, loss = 0.08611049\n",
      "Iteration 505, loss = 0.08584762\n",
      "Iteration 506, loss = 0.08561218\n",
      "Iteration 507, loss = 0.08535618\n",
      "Iteration 508, loss = 0.08510540\n",
      "Iteration 509, loss = 0.08486030\n",
      "Iteration 510, loss = 0.08461278\n",
      "Iteration 511, loss = 0.08436799\n",
      "Iteration 512, loss = 0.08412304\n",
      "Iteration 513, loss = 0.08387881\n",
      "Iteration 514, loss = 0.08363910\n",
      "Iteration 515, loss = 0.08339378\n",
      "Iteration 516, loss = 0.08315094\n",
      "Iteration 517, loss = 0.08290511\n",
      "Iteration 518, loss = 0.08266700\n",
      "Iteration 519, loss = 0.08242305\n",
      "Iteration 520, loss = 0.08218888\n",
      "Iteration 521, loss = 0.08195768\n",
      "Iteration 522, loss = 0.08172155\n",
      "Iteration 523, loss = 0.08149107\n",
      "Iteration 524, loss = 0.08126441\n",
      "Iteration 525, loss = 0.08104130\n",
      "Iteration 526, loss = 0.08080876\n",
      "Iteration 527, loss = 0.08058936\n",
      "Iteration 528, loss = 0.08037517\n",
      "Iteration 529, loss = 0.08014633\n",
      "Iteration 530, loss = 0.07993836\n",
      "Iteration 531, loss = 0.07971347\n",
      "Iteration 532, loss = 0.07949816\n",
      "Iteration 533, loss = 0.07928717\n",
      "Iteration 534, loss = 0.07907283\n",
      "Iteration 535, loss = 0.07886243\n",
      "Iteration 536, loss = 0.07864520\n",
      "Iteration 537, loss = 0.07843284\n",
      "Iteration 538, loss = 0.07821795\n",
      "Iteration 539, loss = 0.07800412\n",
      "Iteration 540, loss = 0.07779708\n",
      "Iteration 541, loss = 0.07758704\n",
      "Iteration 542, loss = 0.07738282\n",
      "Iteration 543, loss = 0.07717469\n",
      "Iteration 544, loss = 0.07696939\n",
      "Iteration 545, loss = 0.07676371\n",
      "Iteration 546, loss = 0.07656096\n",
      "Iteration 547, loss = 0.07636042\n",
      "Iteration 548, loss = 0.07615771\n",
      "Iteration 549, loss = 0.07596036\n",
      "Iteration 550, loss = 0.07576394\n",
      "Iteration 551, loss = 0.07556854\n",
      "Iteration 552, loss = 0.07537215\n",
      "Iteration 553, loss = 0.07517502\n",
      "Iteration 554, loss = 0.07499105\n",
      "Iteration 555, loss = 0.07479508\n",
      "Iteration 556, loss = 0.07460744\n",
      "Iteration 557, loss = 0.07441452\n",
      "Iteration 558, loss = 0.07423459\n",
      "Iteration 559, loss = 0.07404848\n",
      "Iteration 560, loss = 0.07386734\n",
      "Iteration 561, loss = 0.07368149\n",
      "Iteration 562, loss = 0.07350129\n",
      "Iteration 563, loss = 0.07332326\n",
      "Iteration 564, loss = 0.07313996\n",
      "Iteration 565, loss = 0.07296935\n",
      "Iteration 566, loss = 0.07279086\n",
      "Iteration 567, loss = 0.07260857\n",
      "Iteration 568, loss = 0.07243141\n",
      "Iteration 569, loss = 0.07227112\n",
      "Iteration 570, loss = 0.07208277\n",
      "Iteration 571, loss = 0.07190848\n",
      "Iteration 572, loss = 0.07173252\n",
      "Iteration 573, loss = 0.07156084\n",
      "Iteration 574, loss = 0.07139391\n",
      "Iteration 575, loss = 0.07121905\n",
      "Iteration 576, loss = 0.07105055\n",
      "Iteration 577, loss = 0.07088532\n",
      "Iteration 578, loss = 0.07071459\n",
      "Iteration 579, loss = 0.07055226\n",
      "Iteration 580, loss = 0.07038387\n",
      "Iteration 581, loss = 0.07022022\n",
      "Iteration 582, loss = 0.07005267\n",
      "Iteration 583, loss = 0.06988803\n",
      "Iteration 584, loss = 0.06972443\n",
      "Iteration 585, loss = 0.06956451\n",
      "Iteration 586, loss = 0.06940674\n",
      "Iteration 587, loss = 0.06924419\n",
      "Iteration 588, loss = 0.06908534\n",
      "Iteration 589, loss = 0.06892452\n",
      "Iteration 590, loss = 0.06876700\n",
      "Iteration 591, loss = 0.06860830\n",
      "Iteration 592, loss = 0.06844953\n",
      "Iteration 593, loss = 0.06829610\n",
      "Iteration 594, loss = 0.06814847\n",
      "Iteration 595, loss = 0.06798990\n",
      "Iteration 596, loss = 0.06783271\n",
      "Iteration 597, loss = 0.06768024\n",
      "Iteration 598, loss = 0.06753050\n",
      "Iteration 599, loss = 0.06736991\n",
      "Iteration 600, loss = 0.06722613\n",
      "Iteration 601, loss = 0.06707353\n",
      "Iteration 602, loss = 0.06692413\n",
      "Iteration 603, loss = 0.06677845\n",
      "Iteration 604, loss = 0.06663053\n",
      "Iteration 605, loss = 0.06648560\n",
      "Iteration 606, loss = 0.06634145\n",
      "Iteration 607, loss = 0.06619752\n",
      "Iteration 608, loss = 0.06605378\n",
      "Iteration 609, loss = 0.06592558\n",
      "Iteration 610, loss = 0.06577653\n",
      "Iteration 611, loss = 0.06563186\n",
      "Iteration 612, loss = 0.06548936\n",
      "Iteration 613, loss = 0.06535361\n",
      "Iteration 614, loss = 0.06521711\n",
      "Iteration 615, loss = 0.06507286\n",
      "Iteration 616, loss = 0.06493267\n",
      "Iteration 617, loss = 0.06480039\n",
      "Iteration 618, loss = 0.06466100\n",
      "Iteration 619, loss = 0.06452567\n",
      "Iteration 620, loss = 0.06439223\n",
      "Iteration 621, loss = 0.06426000\n",
      "Iteration 622, loss = 0.06412891\n",
      "Iteration 623, loss = 0.06399628\n",
      "Iteration 624, loss = 0.06386812\n",
      "Iteration 625, loss = 0.06373750\n",
      "Iteration 626, loss = 0.06361231\n",
      "Iteration 627, loss = 0.06347953\n",
      "Iteration 628, loss = 0.06335200\n",
      "Iteration 629, loss = 0.06322853\n",
      "Iteration 630, loss = 0.06309671\n",
      "Iteration 631, loss = 0.06296745\n",
      "Iteration 632, loss = 0.06284237\n",
      "Iteration 633, loss = 0.06271261\n",
      "Iteration 634, loss = 0.06258647\n",
      "Iteration 635, loss = 0.06245890\n",
      "Iteration 636, loss = 0.06233403\n",
      "Iteration 637, loss = 0.06220434\n",
      "Iteration 638, loss = 0.06208600\n",
      "Iteration 639, loss = 0.06195880\n",
      "Iteration 640, loss = 0.06183607\n",
      "Iteration 641, loss = 0.06171818\n",
      "Iteration 642, loss = 0.06159348\n",
      "Iteration 643, loss = 0.06147662\n",
      "Iteration 644, loss = 0.06135710\n",
      "Iteration 645, loss = 0.06124397\n",
      "Iteration 646, loss = 0.06112670\n",
      "Iteration 647, loss = 0.06101690\n",
      "Iteration 648, loss = 0.06089500\n",
      "Iteration 649, loss = 0.06078161\n",
      "Iteration 650, loss = 0.06066889\n",
      "Iteration 651, loss = 0.06055296\n",
      "Iteration 652, loss = 0.06043700\n",
      "Iteration 653, loss = 0.06032479\n",
      "Iteration 654, loss = 0.06020896\n",
      "Iteration 655, loss = 0.06009664\n",
      "Iteration 656, loss = 0.05997910\n",
      "Iteration 657, loss = 0.05986614\n",
      "Iteration 658, loss = 0.05975506\n",
      "Iteration 659, loss = 0.05964386\n",
      "Iteration 660, loss = 0.05953129\n",
      "Iteration 661, loss = 0.05942191\n",
      "Iteration 662, loss = 0.05930717\n",
      "Iteration 663, loss = 0.05919484\n",
      "Iteration 664, loss = 0.05908159\n",
      "Iteration 665, loss = 0.05896770\n",
      "Iteration 666, loss = 0.05885520\n",
      "Iteration 667, loss = 0.05874077\n",
      "Iteration 668, loss = 0.05863242\n",
      "Iteration 669, loss = 0.05852129\n",
      "Iteration 670, loss = 0.05840746\n",
      "Iteration 671, loss = 0.05830014\n",
      "Iteration 672, loss = 0.05819092\n",
      "Iteration 673, loss = 0.05808207\n",
      "Iteration 674, loss = 0.05798067\n",
      "Iteration 675, loss = 0.05787388\n",
      "Iteration 676, loss = 0.05776801\n",
      "Iteration 677, loss = 0.05766739\n",
      "Iteration 678, loss = 0.05756398\n",
      "Iteration 679, loss = 0.05745647\n",
      "Iteration 680, loss = 0.05735641\n",
      "Iteration 681, loss = 0.05725207\n",
      "Iteration 682, loss = 0.05715339\n",
      "Iteration 683, loss = 0.05705154\n",
      "Iteration 684, loss = 0.05694924\n",
      "Iteration 685, loss = 0.05685281\n",
      "Iteration 686, loss = 0.05675084\n",
      "Iteration 687, loss = 0.05665309\n",
      "Iteration 688, loss = 0.05655040\n",
      "Iteration 689, loss = 0.05645422\n",
      "Iteration 690, loss = 0.05635339\n",
      "Iteration 691, loss = 0.05625460\n",
      "Iteration 692, loss = 0.05615499\n",
      "Iteration 693, loss = 0.05606271\n",
      "Iteration 694, loss = 0.05596275\n",
      "Iteration 695, loss = 0.05586683\n",
      "Iteration 696, loss = 0.05576808\n",
      "Iteration 697, loss = 0.05567223\n",
      "Iteration 698, loss = 0.05557482\n",
      "Iteration 699, loss = 0.05548369\n",
      "Iteration 700, loss = 0.05538549\n",
      "Iteration 701, loss = 0.05529124\n",
      "Iteration 702, loss = 0.05519952\n",
      "Iteration 703, loss = 0.05510736\n",
      "Iteration 704, loss = 0.05501877\n",
      "Iteration 705, loss = 0.05492274\n",
      "Iteration 706, loss = 0.05482892\n",
      "Iteration 707, loss = 0.05473420\n",
      "Iteration 708, loss = 0.05463974\n",
      "Iteration 709, loss = 0.05454867\n",
      "Iteration 710, loss = 0.05445525\n",
      "Iteration 711, loss = 0.05436302\n",
      "Iteration 712, loss = 0.05427532\n",
      "Iteration 713, loss = 0.05418756\n",
      "Iteration 714, loss = 0.05409771\n",
      "Iteration 715, loss = 0.05400804\n",
      "Iteration 716, loss = 0.05392127\n",
      "Iteration 717, loss = 0.05383148\n",
      "Iteration 718, loss = 0.05374549\n",
      "Iteration 719, loss = 0.05365842\n",
      "Iteration 720, loss = 0.05356962\n",
      "Iteration 721, loss = 0.05348433\n",
      "Iteration 722, loss = 0.05339757\n",
      "Iteration 723, loss = 0.05330858\n",
      "Iteration 724, loss = 0.05322014\n",
      "Iteration 725, loss = 0.05313986\n",
      "Iteration 726, loss = 0.05304796\n",
      "Iteration 727, loss = 0.05295955\n",
      "Iteration 728, loss = 0.05287667\n",
      "Iteration 729, loss = 0.05278774\n",
      "Iteration 730, loss = 0.05270118\n",
      "Iteration 731, loss = 0.05261382\n",
      "Iteration 732, loss = 0.05252400\n",
      "Iteration 733, loss = 0.05243344\n",
      "Iteration 734, loss = 0.05234567\n",
      "Iteration 735, loss = 0.05226345\n",
      "Iteration 736, loss = 0.05217433\n",
      "Iteration 737, loss = 0.05209057\n",
      "Iteration 738, loss = 0.05200723\n",
      "Iteration 739, loss = 0.05192452\n",
      "Iteration 740, loss = 0.05184335\n",
      "Iteration 741, loss = 0.05176434\n",
      "Iteration 742, loss = 0.05168304\n",
      "Iteration 743, loss = 0.05160445\n",
      "Iteration 744, loss = 0.05152620\n",
      "Iteration 745, loss = 0.05144569\n",
      "Iteration 746, loss = 0.05136753\n",
      "Iteration 747, loss = 0.05128458\n",
      "Iteration 748, loss = 0.05120284\n",
      "Iteration 749, loss = 0.05112335\n",
      "Iteration 750, loss = 0.05103931\n",
      "Iteration 751, loss = 0.05095885\n",
      "Iteration 752, loss = 0.05087830\n",
      "Iteration 753, loss = 0.05080240\n",
      "Iteration 754, loss = 0.05072325\n",
      "Iteration 755, loss = 0.05064571\n",
      "Iteration 756, loss = 0.05057005\n",
      "Iteration 757, loss = 0.05049213\n",
      "Iteration 758, loss = 0.05041739\n",
      "Iteration 759, loss = 0.05034211\n",
      "Iteration 760, loss = 0.05026734\n",
      "Iteration 761, loss = 0.05018660\n",
      "Iteration 762, loss = 0.05011261\n",
      "Iteration 763, loss = 0.05003571\n",
      "Iteration 764, loss = 0.04995260\n",
      "Iteration 765, loss = 0.04987831\n",
      "Iteration 766, loss = 0.04980198\n",
      "Iteration 767, loss = 0.04972610\n",
      "Iteration 768, loss = 0.04964891\n",
      "Iteration 769, loss = 0.04957533\n",
      "Iteration 770, loss = 0.04949756\n",
      "Iteration 771, loss = 0.04942139\n",
      "Iteration 772, loss = 0.04934926\n",
      "Iteration 773, loss = 0.04927306\n",
      "Iteration 774, loss = 0.04919810\n",
      "Iteration 775, loss = 0.04912551\n",
      "Iteration 776, loss = 0.04904971\n",
      "Iteration 777, loss = 0.04897572\n",
      "Iteration 778, loss = 0.04890452\n",
      "Iteration 779, loss = 0.04882882\n",
      "Iteration 780, loss = 0.04875412\n",
      "Iteration 781, loss = 0.04867799\n",
      "Iteration 782, loss = 0.04860629\n",
      "Iteration 783, loss = 0.04853332\n",
      "Iteration 784, loss = 0.04846616\n",
      "Iteration 785, loss = 0.04839843\n",
      "Iteration 786, loss = 0.04832511\n",
      "Iteration 787, loss = 0.04825993\n",
      "Iteration 788, loss = 0.04818777\n",
      "Iteration 789, loss = 0.04811938\n",
      "Iteration 790, loss = 0.04804953\n",
      "Iteration 791, loss = 0.04797941\n",
      "Iteration 792, loss = 0.04790999\n",
      "Iteration 793, loss = 0.04783773\n",
      "Iteration 794, loss = 0.04776787\n",
      "Iteration 795, loss = 0.04769685\n",
      "Iteration 796, loss = 0.04762687\n",
      "Iteration 797, loss = 0.04756410\n",
      "Iteration 798, loss = 0.04748818\n",
      "Iteration 799, loss = 0.04742283\n",
      "Iteration 800, loss = 0.04735869\n",
      "Iteration 801, loss = 0.04728342\n",
      "Iteration 802, loss = 0.04721783\n",
      "Iteration 803, loss = 0.04715243\n",
      "Iteration 804, loss = 0.04708528\n",
      "Iteration 805, loss = 0.04701687\n",
      "Iteration 806, loss = 0.04695269\n",
      "Iteration 807, loss = 0.04688249\n",
      "Iteration 808, loss = 0.04681983\n",
      "Iteration 809, loss = 0.04675452\n",
      "Iteration 810, loss = 0.04668958\n",
      "Iteration 811, loss = 0.04662661\n",
      "Iteration 812, loss = 0.04656461\n",
      "Iteration 813, loss = 0.04650121\n",
      "Iteration 814, loss = 0.04644186\n",
      "Iteration 815, loss = 0.04638072\n",
      "Iteration 816, loss = 0.04631566\n",
      "Iteration 817, loss = 0.04625464\n",
      "Iteration 818, loss = 0.04618827\n",
      "Iteration 819, loss = 0.04612272\n",
      "Iteration 820, loss = 0.04605914\n",
      "Iteration 821, loss = 0.04599502\n",
      "Iteration 822, loss = 0.04593329\n",
      "Iteration 823, loss = 0.04586590\n",
      "Iteration 824, loss = 0.04580368\n",
      "Iteration 825, loss = 0.04574018\n",
      "Iteration 826, loss = 0.04567418\n",
      "Iteration 827, loss = 0.04561186\n",
      "Iteration 828, loss = 0.04554743\n",
      "Iteration 829, loss = 0.04548496\n",
      "Iteration 830, loss = 0.04542746\n",
      "Iteration 831, loss = 0.04536155\n",
      "Iteration 832, loss = 0.04529899\n",
      "Iteration 833, loss = 0.04523499\n",
      "Iteration 834, loss = 0.04517920\n",
      "Iteration 835, loss = 0.04511420\n",
      "Iteration 836, loss = 0.04505395\n",
      "Iteration 837, loss = 0.04498976\n",
      "Iteration 838, loss = 0.04493045\n",
      "Iteration 839, loss = 0.04486953\n",
      "Iteration 840, loss = 0.04481056\n",
      "Iteration 841, loss = 0.04475030\n",
      "Iteration 842, loss = 0.04469234\n",
      "Iteration 843, loss = 0.04463358\n",
      "Iteration 844, loss = 0.04457611\n",
      "Iteration 845, loss = 0.04451880\n",
      "Iteration 846, loss = 0.04445938\n",
      "Iteration 847, loss = 0.04440031\n",
      "Iteration 848, loss = 0.04434181\n",
      "Iteration 849, loss = 0.04428535\n",
      "Iteration 850, loss = 0.04422264\n",
      "Iteration 851, loss = 0.04416611\n",
      "Iteration 852, loss = 0.04410632\n",
      "Iteration 853, loss = 0.04404829\n",
      "Iteration 854, loss = 0.04398986\n",
      "Iteration 855, loss = 0.04393241\n",
      "Iteration 856, loss = 0.04387556\n",
      "Iteration 857, loss = 0.04382551\n",
      "Iteration 858, loss = 0.04376233\n",
      "Iteration 859, loss = 0.04370594\n",
      "Iteration 860, loss = 0.04364760\n",
      "Iteration 861, loss = 0.04359069\n",
      "Iteration 862, loss = 0.04353124\n",
      "Iteration 863, loss = 0.04347441\n",
      "Iteration 864, loss = 0.04341771\n",
      "Iteration 865, loss = 0.04335637\n",
      "Iteration 866, loss = 0.04329986\n",
      "Iteration 867, loss = 0.04324318\n",
      "Iteration 868, loss = 0.04319225\n",
      "Iteration 869, loss = 0.04312941\n",
      "Iteration 870, loss = 0.04307438\n",
      "Iteration 871, loss = 0.04301900\n",
      "Iteration 872, loss = 0.04296009\n",
      "Iteration 873, loss = 0.04290451\n",
      "Iteration 874, loss = 0.04284878\n",
      "Iteration 875, loss = 0.04279810\n",
      "Iteration 876, loss = 0.04274306\n",
      "Iteration 877, loss = 0.04268882\n",
      "Iteration 878, loss = 0.04263607\n",
      "Iteration 879, loss = 0.04258636\n",
      "Iteration 880, loss = 0.04252733\n",
      "Iteration 881, loss = 0.04247313\n",
      "Iteration 882, loss = 0.04242214\n",
      "Iteration 883, loss = 0.04237011\n",
      "Iteration 884, loss = 0.04231843\n",
      "Iteration 885, loss = 0.04227087\n",
      "Iteration 886, loss = 0.04221438\n",
      "Iteration 887, loss = 0.04216119\n",
      "Iteration 888, loss = 0.04210905\n",
      "Iteration 889, loss = 0.04205764\n",
      "Iteration 890, loss = 0.04200593\n",
      "Iteration 891, loss = 0.04195674\n",
      "Iteration 892, loss = 0.04190790\n",
      "Iteration 893, loss = 0.04185735\n",
      "Iteration 894, loss = 0.04180803\n",
      "Iteration 895, loss = 0.04175785\n",
      "Iteration 896, loss = 0.04171181\n",
      "Iteration 897, loss = 0.04165785\n",
      "Iteration 898, loss = 0.04160705\n",
      "Iteration 899, loss = 0.04155606\n",
      "Iteration 900, loss = 0.04150755\n",
      "Iteration 901, loss = 0.04145458\n",
      "Iteration 902, loss = 0.04140595\n",
      "Iteration 903, loss = 0.04135414\n",
      "Iteration 904, loss = 0.04130497\n",
      "Iteration 905, loss = 0.04125422\n",
      "Iteration 906, loss = 0.04120176\n",
      "Iteration 907, loss = 0.04115058\n",
      "Iteration 908, loss = 0.04109797\n",
      "Iteration 909, loss = 0.04104687\n",
      "Iteration 910, loss = 0.04099605\n",
      "Iteration 911, loss = 0.04094861\n",
      "Iteration 912, loss = 0.04089675\n",
      "Iteration 913, loss = 0.04085506\n",
      "Iteration 914, loss = 0.04079744\n",
      "Iteration 915, loss = 0.04075057\n",
      "Iteration 916, loss = 0.04070133\n",
      "Iteration 917, loss = 0.04065606\n",
      "Iteration 918, loss = 0.04060660\n",
      "Iteration 919, loss = 0.04055914\n",
      "Iteration 920, loss = 0.04051153\n",
      "Iteration 921, loss = 0.04046176\n",
      "Iteration 922, loss = 0.04041559\n",
      "Iteration 923, loss = 0.04036777\n",
      "Iteration 924, loss = 0.04032013\n",
      "Iteration 925, loss = 0.04027280\n",
      "Iteration 926, loss = 0.04022764\n",
      "Iteration 927, loss = 0.04018051\n",
      "Iteration 928, loss = 0.04013271\n",
      "Iteration 929, loss = 0.04008703\n",
      "Iteration 930, loss = 0.04004011\n",
      "Iteration 931, loss = 0.03999649\n",
      "Iteration 932, loss = 0.03994693\n",
      "Iteration 933, loss = 0.03989834\n",
      "Iteration 934, loss = 0.03985124\n",
      "Iteration 935, loss = 0.03980644\n",
      "Iteration 936, loss = 0.03976190\n",
      "Iteration 937, loss = 0.03971513\n",
      "Iteration 938, loss = 0.03967067\n",
      "Iteration 939, loss = 0.03962419\n",
      "Iteration 940, loss = 0.03957764\n",
      "Iteration 941, loss = 0.03953082\n",
      "Iteration 942, loss = 0.03948236\n",
      "Iteration 943, loss = 0.03943553\n",
      "Iteration 944, loss = 0.03938847\n",
      "Iteration 945, loss = 0.03933917\n",
      "Iteration 946, loss = 0.03929532\n",
      "Iteration 947, loss = 0.03924863\n",
      "Iteration 948, loss = 0.03919895\n",
      "Iteration 949, loss = 0.03915480\n",
      "Iteration 950, loss = 0.03911051\n",
      "Iteration 951, loss = 0.03906366\n",
      "Iteration 952, loss = 0.03901587\n",
      "Iteration 953, loss = 0.03897811\n",
      "Iteration 954, loss = 0.03892769\n",
      "Iteration 955, loss = 0.03888156\n",
      "Iteration 956, loss = 0.03883693\n",
      "Iteration 957, loss = 0.03879034\n",
      "Iteration 958, loss = 0.03874687\n",
      "Iteration 959, loss = 0.03870054\n",
      "Iteration 960, loss = 0.03865688\n",
      "Iteration 961, loss = 0.03861336\n",
      "Iteration 962, loss = 0.03856629\n",
      "Iteration 963, loss = 0.03852385\n",
      "Iteration 964, loss = 0.03847801\n",
      "Iteration 965, loss = 0.03843365\n",
      "Iteration 966, loss = 0.03838869\n",
      "Iteration 967, loss = 0.03834570\n",
      "Iteration 968, loss = 0.03830146\n",
      "Iteration 969, loss = 0.03825824\n",
      "Iteration 970, loss = 0.03821542\n",
      "Iteration 971, loss = 0.03817383\n",
      "Iteration 972, loss = 0.03813358\n",
      "Iteration 973, loss = 0.03808886\n",
      "Iteration 974, loss = 0.03804624\n",
      "Iteration 975, loss = 0.03800415\n",
      "Iteration 976, loss = 0.03796002\n",
      "Iteration 977, loss = 0.03792182\n",
      "Iteration 978, loss = 0.03787908\n",
      "Iteration 979, loss = 0.03783909\n",
      "Iteration 980, loss = 0.03779855\n",
      "Iteration 981, loss = 0.03775933\n",
      "Iteration 982, loss = 0.03772073\n",
      "Iteration 983, loss = 0.03768127\n",
      "Iteration 984, loss = 0.03764364\n",
      "Iteration 985, loss = 0.03760584\n",
      "Iteration 986, loss = 0.03756108\n",
      "Iteration 987, loss = 0.03751935\n",
      "Iteration 988, loss = 0.03747802\n",
      "Iteration 989, loss = 0.03744011\n",
      "Iteration 990, loss = 0.03739749\n",
      "Iteration 991, loss = 0.03735610\n",
      "Iteration 992, loss = 0.03731470\n",
      "Iteration 993, loss = 0.03727192\n",
      "Iteration 994, loss = 0.03723293\n",
      "Iteration 995, loss = 0.03718992\n",
      "Iteration 996, loss = 0.03715011\n",
      "Iteration 997, loss = 0.03711076\n",
      "Iteration 998, loss = 0.03706686\n",
      "Iteration 999, loss = 0.03702748\n",
      "Iteration 1000, loss = 0.03698918\n",
      "Iteration 1001, loss = 0.03694713\n",
      "Iteration 1002, loss = 0.03690855\n",
      "Iteration 1003, loss = 0.03686809\n",
      "Iteration 1004, loss = 0.03682477\n",
      "Iteration 1005, loss = 0.03678809\n",
      "Iteration 1006, loss = 0.03674816\n",
      "Iteration 1007, loss = 0.03670318\n",
      "Iteration 1008, loss = 0.03666914\n",
      "Iteration 1009, loss = 0.03662197\n",
      "Iteration 1010, loss = 0.03658508\n",
      "Iteration 1011, loss = 0.03654032\n",
      "Iteration 1012, loss = 0.03650019\n",
      "Iteration 1013, loss = 0.03646037\n",
      "Iteration 1014, loss = 0.03641982\n",
      "Iteration 1015, loss = 0.03638025\n",
      "Iteration 1016, loss = 0.03634116\n",
      "Iteration 1017, loss = 0.03630104\n",
      "Iteration 1018, loss = 0.03626404\n",
      "Iteration 1019, loss = 0.03622141\n",
      "Iteration 1020, loss = 0.03618031\n",
      "Iteration 1021, loss = 0.03614053\n",
      "Iteration 1022, loss = 0.03610010\n",
      "Iteration 1023, loss = 0.03605599\n",
      "Iteration 1024, loss = 0.03601885\n",
      "Iteration 1025, loss = 0.03597778\n",
      "Iteration 1026, loss = 0.03593553\n",
      "Iteration 1027, loss = 0.03589783\n",
      "Iteration 1028, loss = 0.03585810\n",
      "Iteration 1029, loss = 0.03581542\n",
      "Iteration 1030, loss = 0.03577663\n",
      "Iteration 1031, loss = 0.03573940\n",
      "Iteration 1032, loss = 0.03570148\n",
      "Iteration 1033, loss = 0.03566161\n",
      "Iteration 1034, loss = 0.03562462\n",
      "Iteration 1035, loss = 0.03558790\n",
      "Iteration 1036, loss = 0.03555008\n",
      "Iteration 1037, loss = 0.03551703\n",
      "Iteration 1038, loss = 0.03547589\n",
      "Iteration 1039, loss = 0.03543853\n",
      "Iteration 1040, loss = 0.03539962\n",
      "Iteration 1041, loss = 0.03536285\n",
      "Iteration 1042, loss = 0.03532377\n",
      "Iteration 1043, loss = 0.03528569\n",
      "Iteration 1044, loss = 0.03524901\n",
      "Iteration 1045, loss = 0.03521266\n",
      "Iteration 1046, loss = 0.03517943\n",
      "Iteration 1047, loss = 0.03514062\n",
      "Iteration 1048, loss = 0.03510542\n",
      "Iteration 1049, loss = 0.03506773\n",
      "Iteration 1050, loss = 0.03503291\n",
      "Iteration 1051, loss = 0.03499734\n",
      "Iteration 1052, loss = 0.03495961\n",
      "Iteration 1053, loss = 0.03492496\n",
      "Iteration 1054, loss = 0.03488736\n",
      "Iteration 1055, loss = 0.03485242\n",
      "Iteration 1056, loss = 0.03481566\n",
      "Iteration 1057, loss = 0.03478183\n",
      "Iteration 1058, loss = 0.03474478\n",
      "Iteration 1059, loss = 0.03471115\n",
      "Iteration 1060, loss = 0.03467545\n",
      "Iteration 1061, loss = 0.03464054\n",
      "Iteration 1062, loss = 0.03460290\n",
      "Iteration 1063, loss = 0.03457013\n",
      "Iteration 1064, loss = 0.03453343\n",
      "Iteration 1065, loss = 0.03449995\n",
      "Iteration 1066, loss = 0.03446608\n",
      "Iteration 1067, loss = 0.03443271\n",
      "Iteration 1068, loss = 0.03440300\n",
      "Iteration 1069, loss = 0.03436494\n",
      "Iteration 1070, loss = 0.03432931\n",
      "Iteration 1071, loss = 0.03429731\n",
      "Iteration 1072, loss = 0.03425141\n",
      "Iteration 1073, loss = 0.03421582\n",
      "Iteration 1074, loss = 0.03417872\n",
      "Iteration 1075, loss = 0.03413903\n",
      "Iteration 1076, loss = 0.03410758\n",
      "Iteration 1077, loss = 0.03406944\n",
      "Iteration 1078, loss = 0.03403021\n",
      "Iteration 1079, loss = 0.03399774\n",
      "Iteration 1080, loss = 0.03395829\n",
      "Iteration 1081, loss = 0.03392623\n",
      "Iteration 1082, loss = 0.03388918\n",
      "Iteration 1083, loss = 0.03385494\n",
      "Iteration 1084, loss = 0.03381845\n",
      "Iteration 1085, loss = 0.03378350\n",
      "Iteration 1086, loss = 0.03374610\n",
      "Iteration 1087, loss = 0.03371066\n",
      "Iteration 1088, loss = 0.03367728\n",
      "Iteration 1089, loss = 0.03364485\n",
      "Iteration 1090, loss = 0.03360795\n",
      "Iteration 1091, loss = 0.03357368\n",
      "Iteration 1092, loss = 0.03354192\n",
      "Iteration 1093, loss = 0.03350607\n",
      "Iteration 1094, loss = 0.03347616\n",
      "Iteration 1095, loss = 0.03344088\n",
      "Iteration 1096, loss = 0.03340926\n",
      "Iteration 1097, loss = 0.03337273\n",
      "Iteration 1098, loss = 0.03333904\n",
      "Iteration 1099, loss = 0.03330452\n",
      "Iteration 1100, loss = 0.03327263\n",
      "Iteration 1101, loss = 0.03323764\n",
      "Iteration 1102, loss = 0.03320050\n",
      "Iteration 1103, loss = 0.03316572\n",
      "Iteration 1104, loss = 0.03313192\n",
      "Iteration 1105, loss = 0.03309677\n",
      "Iteration 1106, loss = 0.03306326\n",
      "Iteration 1107, loss = 0.03302787\n",
      "Iteration 1108, loss = 0.03299504\n",
      "Iteration 1109, loss = 0.03296159\n",
      "Iteration 1110, loss = 0.03293087\n",
      "Iteration 1111, loss = 0.03289537\n",
      "Iteration 1112, loss = 0.03286124\n",
      "Iteration 1113, loss = 0.03282948\n",
      "Iteration 1114, loss = 0.03279614\n",
      "Iteration 1115, loss = 0.03276210\n",
      "Iteration 1116, loss = 0.03272760\n",
      "Iteration 1117, loss = 0.03269421\n",
      "Iteration 1118, loss = 0.03266201\n",
      "Iteration 1119, loss = 0.03262853\n",
      "Iteration 1120, loss = 0.03259711\n",
      "Iteration 1121, loss = 0.03256141\n",
      "Iteration 1122, loss = 0.03253426\n",
      "Iteration 1123, loss = 0.03250225\n",
      "Iteration 1124, loss = 0.03246795\n",
      "Iteration 1125, loss = 0.03243540\n",
      "Iteration 1126, loss = 0.03240402\n",
      "Iteration 1127, loss = 0.03237173\n",
      "Iteration 1128, loss = 0.03234027\n",
      "Iteration 1129, loss = 0.03231192\n",
      "Iteration 1130, loss = 0.03227985\n",
      "Iteration 1131, loss = 0.03224482\n",
      "Iteration 1132, loss = 0.03220930\n",
      "Iteration 1133, loss = 0.03217538\n",
      "Iteration 1134, loss = 0.03214696\n",
      "Iteration 1135, loss = 0.03211240\n",
      "Iteration 1136, loss = 0.03207560\n",
      "Iteration 1137, loss = 0.03204280\n",
      "Iteration 1138, loss = 0.03200922\n",
      "Iteration 1139, loss = 0.03197517\n",
      "Iteration 1140, loss = 0.03194471\n",
      "Iteration 1141, loss = 0.03191223\n",
      "Iteration 1142, loss = 0.03187995\n",
      "Iteration 1143, loss = 0.03185160\n",
      "Iteration 1144, loss = 0.03181827\n",
      "Iteration 1145, loss = 0.03178763\n",
      "Iteration 1146, loss = 0.03175489\n",
      "Iteration 1147, loss = 0.03172378\n",
      "Iteration 1148, loss = 0.03169257\n",
      "Iteration 1149, loss = 0.03166276\n",
      "Iteration 1150, loss = 0.03163101\n",
      "Iteration 1151, loss = 0.03160129\n",
      "Iteration 1152, loss = 0.03157414\n",
      "Iteration 1153, loss = 0.03154510\n",
      "Iteration 1154, loss = 0.03151563\n",
      "Iteration 1155, loss = 0.03148647\n",
      "Iteration 1156, loss = 0.03145572\n",
      "Iteration 1157, loss = 0.03142654\n",
      "Iteration 1158, loss = 0.03139540\n",
      "Iteration 1159, loss = 0.03136551\n",
      "Iteration 1160, loss = 0.03133460\n",
      "Iteration 1161, loss = 0.03130522\n",
      "Iteration 1162, loss = 0.03127440\n",
      "Iteration 1163, loss = 0.03124545\n",
      "Iteration 1164, loss = 0.03121850\n",
      "Iteration 1165, loss = 0.03119149\n",
      "Iteration 1166, loss = 0.03116556\n",
      "Iteration 1167, loss = 0.03113630\n",
      "Iteration 1168, loss = 0.03110846\n",
      "Iteration 1169, loss = 0.03107845\n",
      "Iteration 1170, loss = 0.03104902\n",
      "Iteration 1171, loss = 0.03102351\n",
      "Iteration 1172, loss = 0.03099159\n",
      "Iteration 1173, loss = 0.03096283\n",
      "Iteration 1174, loss = 0.03093812\n",
      "Iteration 1175, loss = 0.03090894\n",
      "Iteration 1176, loss = 0.03088073\n",
      "Iteration 1177, loss = 0.03085511\n",
      "Iteration 1178, loss = 0.03083306\n",
      "Iteration 1179, loss = 0.03080315\n",
      "Iteration 1180, loss = 0.03077868\n",
      "Iteration 1181, loss = 0.03074628\n",
      "Iteration 1182, loss = 0.03071682\n",
      "Iteration 1183, loss = 0.03068450\n",
      "Iteration 1184, loss = 0.03065762\n",
      "Iteration 1185, loss = 0.03062681\n",
      "Iteration 1186, loss = 0.03059616\n",
      "Iteration 1187, loss = 0.03056795\n",
      "Iteration 1188, loss = 0.03053934\n",
      "Iteration 1189, loss = 0.03051289\n",
      "Iteration 1190, loss = 0.03048367\n",
      "Iteration 1191, loss = 0.03045620\n",
      "Iteration 1192, loss = 0.03042686\n",
      "Iteration 1193, loss = 0.03039748\n",
      "Iteration 1194, loss = 0.03036723\n",
      "Iteration 1195, loss = 0.03034122\n",
      "Iteration 1196, loss = 0.03030872\n",
      "Iteration 1197, loss = 0.03028104\n",
      "Iteration 1198, loss = 0.03024970\n",
      "Iteration 1199, loss = 0.03022269\n",
      "Iteration 1200, loss = 0.03019339\n",
      "Iteration 1201, loss = 0.03016549\n",
      "Iteration 1202, loss = 0.03013868\n",
      "Iteration 1203, loss = 0.03011093\n",
      "Iteration 1204, loss = 0.03008348\n",
      "Iteration 1205, loss = 0.03005680\n",
      "Iteration 1206, loss = 0.03003056\n",
      "Iteration 1207, loss = 0.03000392\n",
      "Iteration 1208, loss = 0.02997777\n",
      "Iteration 1209, loss = 0.02995315\n",
      "Iteration 1210, loss = 0.02992770\n",
      "Iteration 1211, loss = 0.02990318\n",
      "Iteration 1212, loss = 0.02987757\n",
      "Iteration 1213, loss = 0.02985094\n",
      "Iteration 1214, loss = 0.02982583\n",
      "Iteration 1215, loss = 0.02980077\n",
      "Iteration 1216, loss = 0.02977507\n",
      "Iteration 1217, loss = 0.02974899\n",
      "Iteration 1218, loss = 0.02972210\n",
      "Iteration 1219, loss = 0.02969533\n",
      "Iteration 1220, loss = 0.02966733\n",
      "Iteration 1221, loss = 0.02964369\n",
      "Iteration 1222, loss = 0.02961235\n",
      "Iteration 1223, loss = 0.02958352\n",
      "Iteration 1224, loss = 0.02955957\n",
      "Iteration 1225, loss = 0.02953651\n",
      "Iteration 1226, loss = 0.02950656\n",
      "Iteration 1227, loss = 0.02947742\n",
      "Iteration 1228, loss = 0.02945185\n",
      "Iteration 1229, loss = 0.02942333\n",
      "Iteration 1230, loss = 0.02939537\n",
      "Iteration 1231, loss = 0.02936607\n",
      "Iteration 1232, loss = 0.02933547\n",
      "Iteration 1233, loss = 0.02930732\n",
      "Iteration 1234, loss = 0.02928357\n",
      "Iteration 1235, loss = 0.02925237\n",
      "Iteration 1236, loss = 0.02922551\n",
      "Iteration 1237, loss = 0.02919853\n",
      "Iteration 1238, loss = 0.02917202\n",
      "Iteration 1239, loss = 0.02914193\n",
      "Iteration 1240, loss = 0.02911997\n",
      "Iteration 1241, loss = 0.02908914\n",
      "Iteration 1242, loss = 0.02906463\n",
      "Iteration 1243, loss = 0.02903970\n",
      "Iteration 1244, loss = 0.02901434\n",
      "Iteration 1245, loss = 0.02898516\n",
      "Iteration 1246, loss = 0.02895912\n",
      "Iteration 1247, loss = 0.02893248\n",
      "Iteration 1248, loss = 0.02890772\n",
      "Iteration 1249, loss = 0.02888188\n",
      "Iteration 1250, loss = 0.02885608\n",
      "Iteration 1251, loss = 0.02882895\n",
      "Iteration 1252, loss = 0.02880240\n",
      "Iteration 1253, loss = 0.02877641\n",
      "Iteration 1254, loss = 0.02875068\n",
      "Iteration 1255, loss = 0.02872166\n",
      "Iteration 1256, loss = 0.02869577\n",
      "Iteration 1257, loss = 0.02866677\n",
      "Iteration 1258, loss = 0.02864001\n",
      "Iteration 1259, loss = 0.02861255\n",
      "Iteration 1260, loss = 0.02858751\n",
      "Iteration 1261, loss = 0.02856044\n",
      "Iteration 1262, loss = 0.02853247\n",
      "Iteration 1263, loss = 0.02850581\n",
      "Iteration 1264, loss = 0.02848330\n",
      "Iteration 1265, loss = 0.02845501\n",
      "Iteration 1266, loss = 0.02842973\n",
      "Iteration 1267, loss = 0.02840547\n",
      "Iteration 1268, loss = 0.02838144\n",
      "Iteration 1269, loss = 0.02835781\n",
      "Iteration 1270, loss = 0.02832894\n",
      "Iteration 1271, loss = 0.02830406\n",
      "Iteration 1272, loss = 0.02827796\n",
      "Iteration 1273, loss = 0.02825020\n",
      "Iteration 1274, loss = 0.02822841\n",
      "Iteration 1275, loss = 0.02819884\n",
      "Iteration 1276, loss = 0.02817424\n",
      "Iteration 1277, loss = 0.02814675\n",
      "Iteration 1278, loss = 0.02812101\n",
      "Iteration 1279, loss = 0.02809418\n",
      "Iteration 1280, loss = 0.02806940\n",
      "Iteration 1281, loss = 0.02804232\n",
      "Iteration 1282, loss = 0.02801987\n",
      "Iteration 1283, loss = 0.02799304\n",
      "Iteration 1284, loss = 0.02796774\n",
      "Iteration 1285, loss = 0.02794376\n",
      "Iteration 1286, loss = 0.02792002\n",
      "Iteration 1287, loss = 0.02789634\n",
      "Iteration 1288, loss = 0.02787348\n",
      "Iteration 1289, loss = 0.02784782\n",
      "Iteration 1290, loss = 0.02782536\n",
      "Iteration 1291, loss = 0.02780039\n",
      "Iteration 1292, loss = 0.02777533\n",
      "Iteration 1293, loss = 0.02775168\n",
      "Iteration 1294, loss = 0.02772864\n",
      "Iteration 1295, loss = 0.02770314\n",
      "Iteration 1296, loss = 0.02767983\n",
      "Iteration 1297, loss = 0.02765562\n",
      "Iteration 1298, loss = 0.02763175\n",
      "Iteration 1299, loss = 0.02760823\n",
      "Iteration 1300, loss = 0.02758314\n",
      "Iteration 1301, loss = 0.02756069\n",
      "Iteration 1302, loss = 0.02753665\n",
      "Iteration 1303, loss = 0.02751329\n",
      "Iteration 1304, loss = 0.02748817\n",
      "Iteration 1305, loss = 0.02746889\n",
      "Iteration 1306, loss = 0.02744318\n",
      "Iteration 1307, loss = 0.02742044\n",
      "Iteration 1308, loss = 0.02739693\n",
      "Iteration 1309, loss = 0.02737146\n",
      "Iteration 1310, loss = 0.02734763\n",
      "Iteration 1311, loss = 0.02731874\n",
      "Iteration 1312, loss = 0.02729457\n",
      "Iteration 1313, loss = 0.02726770\n",
      "Iteration 1314, loss = 0.02724365\n",
      "Iteration 1315, loss = 0.02722034\n",
      "Iteration 1316, loss = 0.02719360\n",
      "Iteration 1317, loss = 0.02716920\n",
      "Iteration 1318, loss = 0.02714957\n",
      "Iteration 1319, loss = 0.02712131\n",
      "Iteration 1320, loss = 0.02709807\n",
      "Iteration 1321, loss = 0.02707477\n",
      "Iteration 1322, loss = 0.02705176\n",
      "Iteration 1323, loss = 0.02702696\n",
      "Iteration 1324, loss = 0.02700713\n",
      "Iteration 1325, loss = 0.02698230\n",
      "Iteration 1326, loss = 0.02695960\n",
      "Iteration 1327, loss = 0.02693739\n",
      "Iteration 1328, loss = 0.02691512\n",
      "Iteration 1329, loss = 0.02689277\n",
      "Iteration 1330, loss = 0.02687401\n",
      "Iteration 1331, loss = 0.02684809\n",
      "Iteration 1332, loss = 0.02682562\n",
      "Iteration 1333, loss = 0.02680223\n",
      "Iteration 1334, loss = 0.02678152\n",
      "Iteration 1335, loss = 0.02675784\n",
      "Iteration 1336, loss = 0.02673702\n",
      "Iteration 1337, loss = 0.02671488\n",
      "Iteration 1338, loss = 0.02669238\n",
      "Iteration 1339, loss = 0.02667231\n",
      "Iteration 1340, loss = 0.02664869\n",
      "Iteration 1341, loss = 0.02662703\n",
      "Iteration 1342, loss = 0.02660356\n",
      "Iteration 1343, loss = 0.02658228\n",
      "Iteration 1344, loss = 0.02655983\n",
      "Iteration 1345, loss = 0.02653924\n",
      "Iteration 1346, loss = 0.02651879\n",
      "Iteration 1347, loss = 0.02649583\n",
      "Iteration 1348, loss = 0.02647325\n",
      "Iteration 1349, loss = 0.02645134\n",
      "Iteration 1350, loss = 0.02642954\n",
      "Iteration 1351, loss = 0.02640979\n",
      "Iteration 1352, loss = 0.02638391\n",
      "Iteration 1353, loss = 0.02635931\n",
      "Iteration 1354, loss = 0.02633474\n",
      "Iteration 1355, loss = 0.02631440\n",
      "Iteration 1356, loss = 0.02629224\n",
      "Iteration 1357, loss = 0.02627581\n",
      "Iteration 1358, loss = 0.02625068\n",
      "Iteration 1359, loss = 0.02622860\n",
      "Iteration 1360, loss = 0.02620678\n",
      "Iteration 1361, loss = 0.02618656\n",
      "Iteration 1362, loss = 0.02616619\n",
      "Iteration 1363, loss = 0.02614481\n",
      "Iteration 1364, loss = 0.02612611\n",
      "Iteration 1365, loss = 0.02610374\n",
      "Iteration 1366, loss = 0.02608327\n",
      "Iteration 1367, loss = 0.02606344\n",
      "Iteration 1368, loss = 0.02604357\n",
      "Iteration 1369, loss = 0.02602551\n",
      "Iteration 1370, loss = 0.02600541\n",
      "Iteration 1371, loss = 0.02598836\n",
      "Iteration 1372, loss = 0.02596766\n",
      "Iteration 1373, loss = 0.02594961\n",
      "Iteration 1374, loss = 0.02593221\n",
      "Iteration 1375, loss = 0.02591209\n",
      "Iteration 1376, loss = 0.02589323\n",
      "Iteration 1377, loss = 0.02587704\n",
      "Iteration 1378, loss = 0.02585415\n",
      "Iteration 1379, loss = 0.02583370\n",
      "Iteration 1380, loss = 0.02581559\n",
      "Iteration 1381, loss = 0.02579520\n",
      "Iteration 1382, loss = 0.02577497\n",
      "Iteration 1383, loss = 0.02575535\n",
      "Iteration 1384, loss = 0.02573683\n",
      "Iteration 1385, loss = 0.02571585\n",
      "Iteration 1386, loss = 0.02569655\n",
      "Iteration 1387, loss = 0.02567733\n",
      "Iteration 1388, loss = 0.02565951\n",
      "Iteration 1389, loss = 0.02563433\n",
      "Iteration 1390, loss = 0.02561630\n",
      "Iteration 1391, loss = 0.02559382\n",
      "Iteration 1392, loss = 0.02557359\n",
      "Iteration 1393, loss = 0.02555473\n",
      "Iteration 1394, loss = 0.02553396\n",
      "Iteration 1395, loss = 0.02551776\n",
      "Iteration 1396, loss = 0.02549706\n",
      "Iteration 1397, loss = 0.02547712\n",
      "Iteration 1398, loss = 0.02545815\n",
      "Iteration 1399, loss = 0.02543683\n",
      "Iteration 1400, loss = 0.02541905\n",
      "Iteration 1401, loss = 0.02539774\n",
      "Iteration 1402, loss = 0.02537818\n",
      "Iteration 1403, loss = 0.02535849\n",
      "Iteration 1404, loss = 0.02533936\n",
      "Iteration 1405, loss = 0.02532009\n",
      "Iteration 1406, loss = 0.02530063\n",
      "Iteration 1407, loss = 0.02528320\n",
      "Iteration 1408, loss = 0.02525962\n",
      "Iteration 1409, loss = 0.02524062\n",
      "Iteration 1410, loss = 0.02521643\n",
      "Iteration 1411, loss = 0.02519907\n",
      "Iteration 1412, loss = 0.02517778\n",
      "Iteration 1413, loss = 0.02515775\n",
      "Iteration 1414, loss = 0.02513790\n",
      "Iteration 1415, loss = 0.02511813\n",
      "Iteration 1416, loss = 0.02509919\n",
      "Iteration 1417, loss = 0.02508253\n",
      "Iteration 1418, loss = 0.02506282\n",
      "Iteration 1419, loss = 0.02504394\n",
      "Iteration 1420, loss = 0.02502176\n",
      "Iteration 1421, loss = 0.02500380\n",
      "Iteration 1422, loss = 0.02498319\n",
      "Iteration 1423, loss = 0.02496222\n",
      "Iteration 1424, loss = 0.02494095\n",
      "Iteration 1425, loss = 0.02492216\n",
      "Iteration 1426, loss = 0.02490402\n",
      "Iteration 1427, loss = 0.02488265\n",
      "Iteration 1428, loss = 0.02486486\n",
      "Iteration 1429, loss = 0.02484463\n",
      "Iteration 1430, loss = 0.02482446\n",
      "Iteration 1431, loss = 0.02480539\n",
      "Iteration 1432, loss = 0.02478777\n",
      "Iteration 1433, loss = 0.02476875\n",
      "Iteration 1434, loss = 0.02474880\n",
      "Iteration 1435, loss = 0.02472952\n",
      "Iteration 1436, loss = 0.02471053\n",
      "Iteration 1437, loss = 0.02469221\n",
      "Iteration 1438, loss = 0.02467192\n",
      "Iteration 1439, loss = 0.02465497\n",
      "Iteration 1440, loss = 0.02463347\n",
      "Iteration 1441, loss = 0.02461374\n",
      "Iteration 1442, loss = 0.02459491\n",
      "Iteration 1443, loss = 0.02457691\n",
      "Iteration 1444, loss = 0.02455718\n",
      "Iteration 1445, loss = 0.02453854\n",
      "Iteration 1446, loss = 0.02452052\n",
      "Iteration 1447, loss = 0.02450250\n",
      "Iteration 1448, loss = 0.02448346\n",
      "Iteration 1449, loss = 0.02446794\n",
      "Iteration 1450, loss = 0.02444904\n",
      "Iteration 1451, loss = 0.02443133\n",
      "Iteration 1452, loss = 0.02441438\n",
      "Iteration 1453, loss = 0.02439736\n",
      "Iteration 1454, loss = 0.02437754\n",
      "Iteration 1455, loss = 0.02435774\n",
      "Iteration 1456, loss = 0.02434097\n",
      "Iteration 1457, loss = 0.02432259\n",
      "Iteration 1458, loss = 0.02430295\n",
      "Iteration 1459, loss = 0.02429142\n",
      "Iteration 1460, loss = 0.02426870\n",
      "Iteration 1461, loss = 0.02424963\n",
      "Iteration 1462, loss = 0.02423066\n",
      "Iteration 1463, loss = 0.02421293\n",
      "Iteration 1464, loss = 0.02419489\n",
      "Iteration 1465, loss = 0.02417594\n",
      "Iteration 1466, loss = 0.02415893\n",
      "Iteration 1467, loss = 0.02414357\n",
      "Iteration 1468, loss = 0.02412459\n",
      "Iteration 1469, loss = 0.02410756\n",
      "Iteration 1470, loss = 0.02408817\n",
      "Iteration 1471, loss = 0.02407054\n",
      "Iteration 1472, loss = 0.02405288\n",
      "Iteration 1473, loss = 0.02403446\n",
      "Iteration 1474, loss = 0.02401723\n",
      "Iteration 1475, loss = 0.02399789\n",
      "Iteration 1476, loss = 0.02398056\n",
      "Iteration 1477, loss = 0.02396160\n",
      "Iteration 1478, loss = 0.02394326\n",
      "Iteration 1479, loss = 0.02392340\n",
      "Iteration 1480, loss = 0.02390690\n",
      "Iteration 1481, loss = 0.02388684\n",
      "Iteration 1482, loss = 0.02387090\n",
      "Iteration 1483, loss = 0.02385237\n",
      "Iteration 1484, loss = 0.02383494\n",
      "Iteration 1485, loss = 0.02381690\n",
      "Iteration 1486, loss = 0.02379847\n",
      "Iteration 1487, loss = 0.02378120\n",
      "Iteration 1488, loss = 0.02376302\n",
      "Iteration 1489, loss = 0.02374489\n",
      "Iteration 1490, loss = 0.02372961\n",
      "Iteration 1491, loss = 0.02370954\n",
      "Iteration 1492, loss = 0.02369004\n",
      "Iteration 1493, loss = 0.02367192\n",
      "Iteration 1494, loss = 0.02365281\n",
      "Iteration 1495, loss = 0.02363556\n",
      "Iteration 1496, loss = 0.02361444\n",
      "Iteration 1497, loss = 0.02359631\n",
      "Iteration 1498, loss = 0.02357910\n",
      "Iteration 1499, loss = 0.02356040\n",
      "Iteration 1500, loss = 0.02354193\n",
      "Iteration 1501, loss = 0.02352516\n",
      "Iteration 1502, loss = 0.02350736\n",
      "Iteration 1503, loss = 0.02349086\n",
      "Iteration 1504, loss = 0.02347363\n",
      "Iteration 1505, loss = 0.02345726\n",
      "Iteration 1506, loss = 0.02344108\n",
      "Iteration 1507, loss = 0.02342397\n",
      "Iteration 1508, loss = 0.02340681\n",
      "Iteration 1509, loss = 0.02339009\n",
      "Iteration 1510, loss = 0.02337603\n",
      "Iteration 1511, loss = 0.02335707\n",
      "Iteration 1512, loss = 0.02334102\n",
      "Iteration 1513, loss = 0.02332368\n",
      "Iteration 1514, loss = 0.02330711\n",
      "Iteration 1515, loss = 0.02329058\n",
      "Iteration 1516, loss = 0.02327239\n",
      "Iteration 1517, loss = 0.02325420\n",
      "Iteration 1518, loss = 0.02323614\n",
      "Iteration 1519, loss = 0.02321964\n",
      "Iteration 1520, loss = 0.02320246\n",
      "Iteration 1521, loss = 0.02318798\n",
      "Iteration 1522, loss = 0.02317033\n",
      "Iteration 1523, loss = 0.02315703\n",
      "Iteration 1524, loss = 0.02313865\n",
      "Iteration 1525, loss = 0.02312193\n",
      "Iteration 1526, loss = 0.02310638\n",
      "Iteration 1527, loss = 0.02308768\n",
      "Iteration 1528, loss = 0.02307185\n",
      "Iteration 1529, loss = 0.02305450\n",
      "Iteration 1530, loss = 0.02303757\n",
      "Iteration 1531, loss = 0.02301931\n",
      "Iteration 1532, loss = 0.02300327\n",
      "Iteration 1533, loss = 0.02298654\n",
      "Iteration 1534, loss = 0.02296911\n",
      "Iteration 1535, loss = 0.02295151\n",
      "Iteration 1536, loss = 0.02293424\n",
      "Iteration 1537, loss = 0.02291688\n",
      "Iteration 1538, loss = 0.02290241\n",
      "Iteration 1539, loss = 0.02288391\n",
      "Iteration 1540, loss = 0.02286672\n",
      "Iteration 1541, loss = 0.02284846\n",
      "Iteration 1542, loss = 0.02283183\n",
      "Iteration 1543, loss = 0.02281734\n",
      "Iteration 1544, loss = 0.02280134\n",
      "Iteration 1545, loss = 0.02278344\n",
      "Iteration 1546, loss = 0.02276575\n",
      "Iteration 1547, loss = 0.02274892\n",
      "Iteration 1548, loss = 0.02273298\n",
      "Iteration 1549, loss = 0.02271477\n",
      "Iteration 1550, loss = 0.02269859\n",
      "Iteration 1551, loss = 0.02268123\n",
      "Iteration 1552, loss = 0.02266320\n",
      "Iteration 1553, loss = 0.02264789\n",
      "Iteration 1554, loss = 0.02262942\n",
      "Iteration 1555, loss = 0.02261364\n",
      "Iteration 1556, loss = 0.02259698\n",
      "Iteration 1557, loss = 0.02257975\n",
      "Iteration 1558, loss = 0.02256415\n",
      "Iteration 1559, loss = 0.02254768\n",
      "Iteration 1560, loss = 0.02253213\n",
      "Iteration 1561, loss = 0.02251537\n",
      "Iteration 1562, loss = 0.02249810\n",
      "Iteration 1563, loss = 0.02248200\n",
      "Iteration 1564, loss = 0.02246507\n",
      "Iteration 1565, loss = 0.02244715\n",
      "Iteration 1566, loss = 0.02243461\n",
      "Iteration 1567, loss = 0.02241501\n",
      "Iteration 1568, loss = 0.02239898\n",
      "Iteration 1569, loss = 0.02238452\n",
      "Iteration 1570, loss = 0.02236685\n",
      "Iteration 1571, loss = 0.02235140\n",
      "Iteration 1572, loss = 0.02233342\n",
      "Iteration 1573, loss = 0.02231688\n",
      "Iteration 1574, loss = 0.02229968\n",
      "Iteration 1575, loss = 0.02228431\n",
      "Iteration 1576, loss = 0.02226706\n",
      "Iteration 1577, loss = 0.02224910\n",
      "Iteration 1578, loss = 0.02223270\n",
      "Iteration 1579, loss = 0.02221612\n",
      "Iteration 1580, loss = 0.02219971\n",
      "Iteration 1581, loss = 0.02218422\n",
      "Iteration 1582, loss = 0.02216867\n",
      "Iteration 1583, loss = 0.02215534\n",
      "Iteration 1584, loss = 0.02213901\n",
      "Iteration 1585, loss = 0.02212442\n",
      "Iteration 1586, loss = 0.02210914\n",
      "Iteration 1587, loss = 0.02208982\n",
      "Iteration 1588, loss = 0.02207753\n",
      "Iteration 1589, loss = 0.02205902\n",
      "Iteration 1590, loss = 0.02204253\n",
      "Iteration 1591, loss = 0.02202624\n",
      "Iteration 1592, loss = 0.02201231\n",
      "Iteration 1593, loss = 0.02199818\n",
      "Iteration 1594, loss = 0.02198012\n",
      "Iteration 1595, loss = 0.02196367\n",
      "Iteration 1596, loss = 0.02194736\n",
      "Iteration 1597, loss = 0.02193309\n",
      "Iteration 1598, loss = 0.02191558\n",
      "Iteration 1599, loss = 0.02189920\n",
      "Iteration 1600, loss = 0.02188374\n",
      "Iteration 1601, loss = 0.02186620\n",
      "Iteration 1602, loss = 0.02185029\n",
      "Iteration 1603, loss = 0.02183493\n",
      "Iteration 1604, loss = 0.02181804\n",
      "Iteration 1605, loss = 0.02180298\n",
      "Iteration 1606, loss = 0.02178607\n",
      "Iteration 1607, loss = 0.02177011\n",
      "Iteration 1608, loss = 0.02175334\n",
      "Iteration 1609, loss = 0.02174288\n",
      "Iteration 1610, loss = 0.02172462\n",
      "Iteration 1611, loss = 0.02170767\n",
      "Iteration 1612, loss = 0.02169386\n",
      "Iteration 1613, loss = 0.02167711\n",
      "Iteration 1614, loss = 0.02166228\n",
      "Iteration 1615, loss = 0.02164652\n",
      "Iteration 1616, loss = 0.02163010\n",
      "Iteration 1617, loss = 0.02161451\n",
      "Iteration 1618, loss = 0.02159955\n",
      "Iteration 1619, loss = 0.02158402\n",
      "Iteration 1620, loss = 0.02156916\n",
      "Iteration 1621, loss = 0.02155155\n",
      "Iteration 1622, loss = 0.02153826\n",
      "Iteration 1623, loss = 0.02152117\n",
      "Iteration 1624, loss = 0.02150558\n",
      "Iteration 1625, loss = 0.02148951\n",
      "Iteration 1626, loss = 0.02147461\n",
      "Iteration 1627, loss = 0.02145989\n",
      "Iteration 1628, loss = 0.02144477\n",
      "Iteration 1629, loss = 0.02143002\n",
      "Iteration 1630, loss = 0.02141503\n",
      "Iteration 1631, loss = 0.02139967\n",
      "Iteration 1632, loss = 0.02138662\n",
      "Iteration 1633, loss = 0.02137351\n",
      "Iteration 1634, loss = 0.02135680\n",
      "Iteration 1635, loss = 0.02134053\n",
      "Iteration 1636, loss = 0.02132610\n",
      "Iteration 1637, loss = 0.02131188\n",
      "Iteration 1638, loss = 0.02129436\n",
      "Iteration 1639, loss = 0.02127938\n",
      "Iteration 1640, loss = 0.02126837\n",
      "Iteration 1641, loss = 0.02125026\n",
      "Iteration 1642, loss = 0.02123932\n",
      "Iteration 1643, loss = 0.02122256\n",
      "Iteration 1644, loss = 0.02120689\n",
      "Iteration 1645, loss = 0.02119302\n",
      "Iteration 1646, loss = 0.02117711\n",
      "Iteration 1647, loss = 0.02116170\n",
      "Iteration 1648, loss = 0.02114769\n",
      "Iteration 1649, loss = 0.02113183\n",
      "Iteration 1650, loss = 0.02111816\n",
      "Iteration 1651, loss = 0.02110434\n",
      "Iteration 1652, loss = 0.02108944\n",
      "Iteration 1653, loss = 0.02107597\n",
      "Iteration 1654, loss = 0.02106097\n",
      "Iteration 1655, loss = 0.02104684\n",
      "Iteration 1656, loss = 0.02103487\n",
      "Iteration 1657, loss = 0.02101977\n",
      "Iteration 1658, loss = 0.02100702\n",
      "Iteration 1659, loss = 0.02099274\n",
      "Iteration 1660, loss = 0.02097747\n",
      "Iteration 1661, loss = 0.02096259\n",
      "Iteration 1662, loss = 0.02094764\n",
      "Iteration 1663, loss = 0.02093346\n",
      "Iteration 1664, loss = 0.02091825\n",
      "Iteration 1665, loss = 0.02090395\n",
      "Iteration 1666, loss = 0.02089010\n",
      "Iteration 1667, loss = 0.02087458\n",
      "Iteration 1668, loss = 0.02086101\n",
      "Iteration 1669, loss = 0.02084758\n",
      "Iteration 1670, loss = 0.02083227\n",
      "Iteration 1671, loss = 0.02081985\n",
      "Iteration 1672, loss = 0.02080430\n",
      "Iteration 1673, loss = 0.02079072\n",
      "Iteration 1674, loss = 0.02077809\n",
      "Iteration 1675, loss = 0.02076273\n",
      "Iteration 1676, loss = 0.02074766\n",
      "Iteration 1677, loss = 0.02073274\n",
      "Iteration 1678, loss = 0.02071929\n",
      "Iteration 1679, loss = 0.02070537\n",
      "Iteration 1680, loss = 0.02069602\n",
      "Iteration 1681, loss = 0.02067963\n",
      "Iteration 1682, loss = 0.02066668\n",
      "Iteration 1683, loss = 0.02065212\n",
      "Iteration 1684, loss = 0.02063842\n",
      "Iteration 1685, loss = 0.02062658\n",
      "Iteration 1686, loss = 0.02061196\n",
      "Iteration 1687, loss = 0.02059796\n",
      "Iteration 1688, loss = 0.02058440\n",
      "Iteration 1689, loss = 0.02057108\n",
      "Iteration 1690, loss = 0.02055628\n",
      "Iteration 1691, loss = 0.02054445\n",
      "Iteration 1692, loss = 0.02053103\n",
      "Iteration 1693, loss = 0.02051582\n",
      "Iteration 1694, loss = 0.02050136\n",
      "Iteration 1695, loss = 0.02048819\n",
      "Iteration 1696, loss = 0.02047871\n",
      "Iteration 1697, loss = 0.02046290\n",
      "Iteration 1698, loss = 0.02044866\n",
      "Iteration 1699, loss = 0.02043456\n",
      "Iteration 1700, loss = 0.02041991\n",
      "Iteration 1701, loss = 0.02040692\n",
      "Iteration 1702, loss = 0.02039347\n",
      "Iteration 1703, loss = 0.02038096\n",
      "Iteration 1704, loss = 0.02036804\n",
      "Iteration 1705, loss = 0.02035308\n",
      "Iteration 1706, loss = 0.02034104\n",
      "Iteration 1707, loss = 0.02032716\n",
      "Iteration 1708, loss = 0.02031204\n",
      "Iteration 1709, loss = 0.02029894\n",
      "Iteration 1710, loss = 0.02028439\n",
      "Iteration 1711, loss = 0.02027190\n",
      "Iteration 1712, loss = 0.02025993\n",
      "Iteration 1713, loss = 0.02024438\n",
      "Iteration 1714, loss = 0.02023061\n",
      "Iteration 1715, loss = 0.02021592\n",
      "Iteration 1716, loss = 0.02020244\n",
      "Iteration 1717, loss = 0.02019244\n",
      "Iteration 1718, loss = 0.02017598\n",
      "Iteration 1719, loss = 0.02016101\n",
      "Iteration 1720, loss = 0.02014616\n",
      "Iteration 1721, loss = 0.02013237\n",
      "Iteration 1722, loss = 0.02011790\n",
      "Iteration 1723, loss = 0.02010850\n",
      "Iteration 1724, loss = 0.02009153\n",
      "Iteration 1725, loss = 0.02007820\n",
      "Iteration 1726, loss = 0.02006500\n",
      "Iteration 1727, loss = 0.02005229\n",
      "Iteration 1728, loss = 0.02003938\n",
      "Iteration 1729, loss = 0.02002584\n",
      "Iteration 1730, loss = 0.02001158\n",
      "Iteration 1731, loss = 0.02000168\n",
      "Iteration 1732, loss = 0.01998683\n",
      "Iteration 1733, loss = 0.01997301\n",
      "Iteration 1734, loss = 0.01995931\n",
      "Iteration 1735, loss = 0.01994547\n",
      "Iteration 1736, loss = 0.01993341\n",
      "Iteration 1737, loss = 0.01991985\n",
      "Iteration 1738, loss = 0.01990725\n",
      "Iteration 1739, loss = 0.01989309\n",
      "Iteration 1740, loss = 0.01987968\n",
      "Iteration 1741, loss = 0.01986734\n",
      "Iteration 1742, loss = 0.01985271\n",
      "Iteration 1743, loss = 0.01983937\n",
      "Iteration 1744, loss = 0.01982634\n",
      "Iteration 1745, loss = 0.01981659\n",
      "Iteration 1746, loss = 0.01980145\n",
      "Iteration 1747, loss = 0.01978811\n",
      "Iteration 1748, loss = 0.01977398\n",
      "Iteration 1749, loss = 0.01976099\n",
      "Iteration 1750, loss = 0.01974798\n",
      "Iteration 1751, loss = 0.01973339\n",
      "Iteration 1752, loss = 0.01972378\n",
      "Iteration 1753, loss = 0.01970807\n",
      "Iteration 1754, loss = 0.01969583\n",
      "Iteration 1755, loss = 0.01968323\n",
      "Iteration 1756, loss = 0.01967052\n",
      "Iteration 1757, loss = 0.01965770\n",
      "Iteration 1758, loss = 0.01964403\n",
      "Iteration 1759, loss = 0.01963083\n",
      "Iteration 1760, loss = 0.01961793\n",
      "Iteration 1761, loss = 0.01960382\n",
      "Iteration 1762, loss = 0.01959001\n",
      "Iteration 1763, loss = 0.01957758\n",
      "Iteration 1764, loss = 0.01956391\n",
      "Iteration 1765, loss = 0.01955352\n",
      "Iteration 1766, loss = 0.01954012\n",
      "Iteration 1767, loss = 0.01952763\n",
      "Iteration 1768, loss = 0.01951752\n",
      "Iteration 1769, loss = 0.01950497\n",
      "Iteration 1770, loss = 0.01949317\n",
      "Iteration 1771, loss = 0.01948186\n",
      "Iteration 1772, loss = 0.01946928\n",
      "Iteration 1773, loss = 0.01945894\n",
      "Iteration 1774, loss = 0.01944390\n",
      "Iteration 1775, loss = 0.01943274\n",
      "Iteration 1776, loss = 0.01942352\n",
      "Iteration 1777, loss = 0.01940686\n",
      "Iteration 1778, loss = 0.01939348\n",
      "Iteration 1779, loss = 0.01938043\n",
      "Iteration 1780, loss = 0.01936644\n",
      "Iteration 1781, loss = 0.01935359\n",
      "Iteration 1782, loss = 0.01934168\n",
      "Iteration 1783, loss = 0.01932686\n",
      "Iteration 1784, loss = 0.01931428\n",
      "Iteration 1785, loss = 0.01930182\n",
      "Iteration 1786, loss = 0.01928793\n",
      "Iteration 1787, loss = 0.01927494\n",
      "Iteration 1788, loss = 0.01926126\n",
      "Iteration 1789, loss = 0.01924873\n",
      "Iteration 1790, loss = 0.01923102\n",
      "Iteration 1791, loss = 0.01921723\n",
      "Iteration 1792, loss = 0.01920310\n",
      "Iteration 1793, loss = 0.01918810\n",
      "Iteration 1794, loss = 0.01917462\n",
      "Iteration 1795, loss = 0.01916108\n",
      "Iteration 1796, loss = 0.01914922\n",
      "Iteration 1797, loss = 0.01913661\n",
      "Iteration 1798, loss = 0.01912340\n",
      "Iteration 1799, loss = 0.01911132\n",
      "Iteration 1800, loss = 0.01909838\n",
      "Iteration 1801, loss = 0.01908682\n",
      "Iteration 1802, loss = 0.01907484\n",
      "Iteration 1803, loss = 0.01906160\n",
      "Iteration 1804, loss = 0.01904914\n",
      "Iteration 1805, loss = 0.01904001\n",
      "Iteration 1806, loss = 0.01902340\n",
      "Iteration 1807, loss = 0.01901153\n",
      "Iteration 1808, loss = 0.01899749\n",
      "Iteration 1809, loss = 0.01898530\n",
      "Iteration 1810, loss = 0.01897572\n",
      "Iteration 1811, loss = 0.01895902\n",
      "Iteration 1812, loss = 0.01894752\n",
      "Iteration 1813, loss = 0.01893724\n",
      "Iteration 1814, loss = 0.01892350\n",
      "Iteration 1815, loss = 0.01891141\n",
      "Iteration 1816, loss = 0.01889853\n",
      "Iteration 1817, loss = 0.01888748\n",
      "Iteration 1818, loss = 0.01887661\n",
      "Iteration 1819, loss = 0.01886232\n",
      "Iteration 1820, loss = 0.01884944\n",
      "Iteration 1821, loss = 0.01883708\n",
      "Iteration 1822, loss = 0.01882486\n",
      "Iteration 1823, loss = 0.01881213\n",
      "Iteration 1824, loss = 0.01879924\n",
      "Iteration 1825, loss = 0.01878733\n",
      "Iteration 1826, loss = 0.01877658\n",
      "Iteration 1827, loss = 0.01876415\n",
      "Iteration 1828, loss = 0.01875114\n",
      "Iteration 1829, loss = 0.01874018\n",
      "Iteration 1830, loss = 0.01872755\n",
      "Iteration 1831, loss = 0.01871577\n",
      "Iteration 1832, loss = 0.01870414\n",
      "Iteration 1833, loss = 0.01869184\n",
      "Iteration 1834, loss = 0.01867930\n",
      "Iteration 1835, loss = 0.01866933\n",
      "Iteration 1836, loss = 0.01865843\n",
      "Iteration 1837, loss = 0.01864521\n",
      "Iteration 1838, loss = 0.01863408\n",
      "Iteration 1839, loss = 0.01862192\n",
      "Iteration 1840, loss = 0.01860969\n",
      "Iteration 1841, loss = 0.01859909\n",
      "Iteration 1842, loss = 0.01858646\n",
      "Iteration 1843, loss = 0.01857451\n",
      "Iteration 1844, loss = 0.01856246\n",
      "Iteration 1845, loss = 0.01855299\n",
      "Iteration 1846, loss = 0.01854147\n",
      "Iteration 1847, loss = 0.01852931\n",
      "Iteration 1848, loss = 0.01851752\n",
      "Iteration 1849, loss = 0.01850685\n",
      "Iteration 1850, loss = 0.01849703\n",
      "Iteration 1851, loss = 0.01848464\n",
      "Iteration 1852, loss = 0.01847198\n",
      "Iteration 1853, loss = 0.01845994\n",
      "Iteration 1854, loss = 0.01844879\n",
      "Iteration 1855, loss = 0.01844005\n",
      "Iteration 1856, loss = 0.01842619\n",
      "Iteration 1857, loss = 0.01841477\n",
      "Iteration 1858, loss = 0.01840307\n",
      "Iteration 1859, loss = 0.01839085\n",
      "Iteration 1860, loss = 0.01837881\n",
      "Iteration 1861, loss = 0.01836754\n",
      "Iteration 1862, loss = 0.01835429\n",
      "Iteration 1863, loss = 0.01834307\n",
      "Iteration 1864, loss = 0.01833264\n",
      "Iteration 1865, loss = 0.01831971\n",
      "Iteration 1866, loss = 0.01830843\n",
      "Iteration 1867, loss = 0.01829620\n",
      "Iteration 1868, loss = 0.01828813\n",
      "Iteration 1869, loss = 0.01827453\n",
      "Iteration 1870, loss = 0.01826289\n",
      "Iteration 1871, loss = 0.01825203\n",
      "Iteration 1872, loss = 0.01824078\n",
      "Iteration 1873, loss = 0.01822924\n",
      "Iteration 1874, loss = 0.01821832\n",
      "Iteration 1875, loss = 0.01820710\n",
      "Iteration 1876, loss = 0.01819551\n",
      "Iteration 1877, loss = 0.01818377\n",
      "Iteration 1878, loss = 0.01817264\n",
      "Iteration 1879, loss = 0.01816407\n",
      "Iteration 1880, loss = 0.01815462\n",
      "Iteration 1881, loss = 0.01814072\n",
      "Iteration 1882, loss = 0.01812864\n",
      "Iteration 1883, loss = 0.01811490\n",
      "Iteration 1884, loss = 0.01810572\n",
      "Iteration 1885, loss = 0.01809013\n",
      "Iteration 1886, loss = 0.01807921\n",
      "Iteration 1887, loss = 0.01806782\n",
      "Iteration 1888, loss = 0.01805532\n",
      "Iteration 1889, loss = 0.01804411\n",
      "Iteration 1890, loss = 0.01803391\n",
      "Iteration 1891, loss = 0.01802246\n",
      "Iteration 1892, loss = 0.01800997\n",
      "Iteration 1893, loss = 0.01799949\n",
      "Iteration 1894, loss = 0.01798884\n",
      "Iteration 1895, loss = 0.01797624\n",
      "Iteration 1896, loss = 0.01796517\n",
      "Iteration 1897, loss = 0.01795460\n",
      "Iteration 1898, loss = 0.01794325\n",
      "Iteration 1899, loss = 0.01793322\n",
      "Iteration 1900, loss = 0.01791980\n",
      "Iteration 1901, loss = 0.01790805\n",
      "Iteration 1902, loss = 0.01789681\n",
      "Iteration 1903, loss = 0.01788358\n",
      "Iteration 1904, loss = 0.01787379\n",
      "Iteration 1905, loss = 0.01786155\n",
      "Iteration 1906, loss = 0.01784993\n",
      "Iteration 1907, loss = 0.01783892\n",
      "Iteration 1908, loss = 0.01782736\n",
      "Iteration 1909, loss = 0.01781846\n",
      "Iteration 1910, loss = 0.01780623\n",
      "Iteration 1911, loss = 0.01779509\n",
      "Iteration 1912, loss = 0.01778338\n",
      "Iteration 1913, loss = 0.01777294\n",
      "Iteration 1914, loss = 0.01776227\n",
      "Iteration 1915, loss = 0.01775180\n",
      "Iteration 1916, loss = 0.01774066\n",
      "Iteration 1917, loss = 0.01773033\n",
      "Iteration 1918, loss = 0.01771949\n",
      "Iteration 1919, loss = 0.01770914\n",
      "Iteration 1920, loss = 0.01769925\n",
      "Iteration 1921, loss = 0.01768833\n",
      "Iteration 1922, loss = 0.01767759\n",
      "Iteration 1923, loss = 0.01766743\n",
      "Iteration 1924, loss = 0.01765722\n",
      "Iteration 1925, loss = 0.01764774\n",
      "Iteration 1926, loss = 0.01763675\n",
      "Iteration 1927, loss = 0.01762529\n",
      "Iteration 1928, loss = 0.01761536\n",
      "Iteration 1929, loss = 0.01760479\n",
      "Iteration 1930, loss = 0.01759485\n",
      "Iteration 1931, loss = 0.01758459\n",
      "Iteration 1932, loss = 0.01757617\n",
      "Iteration 1933, loss = 0.01756723\n",
      "Iteration 1934, loss = 0.01755683\n",
      "Iteration 1935, loss = 0.01754704\n",
      "Iteration 1936, loss = 0.01753813\n",
      "Iteration 1937, loss = 0.01752730\n",
      "Iteration 1938, loss = 0.01751670\n",
      "Iteration 1939, loss = 0.01750523\n",
      "Iteration 1940, loss = 0.01749573\n",
      "Iteration 1941, loss = 0.01748316\n",
      "Iteration 1942, loss = 0.01747287\n",
      "Iteration 1943, loss = 0.01746328\n",
      "Iteration 1944, loss = 0.01745103\n",
      "Iteration 1945, loss = 0.01743982\n",
      "Iteration 1946, loss = 0.01742767\n",
      "Iteration 1947, loss = 0.01741664\n",
      "Iteration 1948, loss = 0.01740644\n",
      "Iteration 1949, loss = 0.01739410\n",
      "Iteration 1950, loss = 0.01738343\n",
      "Iteration 1951, loss = 0.01737272\n",
      "Iteration 1952, loss = 0.01736196\n",
      "Iteration 1953, loss = 0.01735165\n",
      "Iteration 1954, loss = 0.01734130\n",
      "Iteration 1955, loss = 0.01733094\n",
      "Iteration 1956, loss = 0.01732150\n",
      "Iteration 1957, loss = 0.01731140\n",
      "Iteration 1958, loss = 0.01730061\n",
      "Iteration 1959, loss = 0.01729104\n",
      "Iteration 1960, loss = 0.01728158\n",
      "Iteration 1961, loss = 0.01727188\n",
      "Iteration 1962, loss = 0.01726212\n",
      "Iteration 1963, loss = 0.01725315\n",
      "Iteration 1964, loss = 0.01724404\n",
      "Iteration 1965, loss = 0.01723235\n",
      "Iteration 1966, loss = 0.01722303\n",
      "Iteration 1967, loss = 0.01721290\n",
      "Iteration 1968, loss = 0.01720151\n",
      "Iteration 1969, loss = 0.01719316\n",
      "Iteration 1970, loss = 0.01718039\n",
      "Iteration 1971, loss = 0.01716984\n",
      "Iteration 1972, loss = 0.01716010\n",
      "Iteration 1973, loss = 0.01715263\n",
      "Iteration 1974, loss = 0.01714046\n",
      "Iteration 1975, loss = 0.01712985\n",
      "Iteration 1976, loss = 0.01712149\n",
      "Iteration 1977, loss = 0.01711152\n",
      "Iteration 1978, loss = 0.01710131\n",
      "Iteration 1979, loss = 0.01709193\n",
      "Iteration 1980, loss = 0.01708334\n",
      "Iteration 1981, loss = 0.01707144\n",
      "Iteration 1982, loss = 0.01706299\n",
      "Iteration 1983, loss = 0.01705260\n",
      "Iteration 1984, loss = 0.01704164\n",
      "Iteration 1985, loss = 0.01703163\n",
      "Iteration 1986, loss = 0.01702301\n",
      "Iteration 1987, loss = 0.01701269\n",
      "Iteration 1988, loss = 0.01700289\n",
      "Iteration 1989, loss = 0.01699644\n",
      "Iteration 1990, loss = 0.01698357\n",
      "Iteration 1991, loss = 0.01697347\n",
      "Iteration 1992, loss = 0.01696374\n",
      "Iteration 1993, loss = 0.01695456\n",
      "Iteration 1994, loss = 0.01694518\n",
      "Iteration 1995, loss = 0.01693468\n",
      "Iteration 1996, loss = 0.01692505\n",
      "Iteration 1997, loss = 0.01691618\n",
      "Iteration 1998, loss = 0.01690660\n",
      "Iteration 1999, loss = 0.01689769\n",
      "Iteration 2000, loss = 0.01688762\n",
      "Iteration 2001, loss = 0.01687966\n",
      "Iteration 2002, loss = 0.01687355\n",
      "Iteration 2003, loss = 0.01686115\n",
      "Iteration 2004, loss = 0.01685229\n",
      "Iteration 2005, loss = 0.01684259\n",
      "Iteration 2006, loss = 0.01683274\n",
      "Iteration 2007, loss = 0.01682298\n",
      "Iteration 2008, loss = 0.01681247\n",
      "Iteration 2009, loss = 0.01680295\n",
      "Iteration 2010, loss = 0.01679352\n",
      "Iteration 2011, loss = 0.01678387\n",
      "Iteration 2012, loss = 0.01677392\n",
      "Iteration 2013, loss = 0.01676549\n",
      "Iteration 2014, loss = 0.01675604\n",
      "Iteration 2015, loss = 0.01674723\n",
      "Iteration 2016, loss = 0.01673975\n",
      "Iteration 2017, loss = 0.01672816\n",
      "Iteration 2018, loss = 0.01671665\n",
      "Iteration 2019, loss = 0.01670618\n",
      "Iteration 2020, loss = 0.01669561\n",
      "Iteration 2021, loss = 0.01668417\n",
      "Iteration 2022, loss = 0.01667561\n",
      "Iteration 2023, loss = 0.01666703\n",
      "Iteration 2024, loss = 0.01665711\n",
      "Iteration 2025, loss = 0.01664655\n",
      "Iteration 2026, loss = 0.01663931\n",
      "Iteration 2027, loss = 0.01663041\n",
      "Iteration 2028, loss = 0.01662104\n",
      "Iteration 2029, loss = 0.01661138\n",
      "Iteration 2030, loss = 0.01660128\n",
      "Iteration 2031, loss = 0.01659302\n",
      "Iteration 2032, loss = 0.01658222\n",
      "Iteration 2033, loss = 0.01657170\n",
      "Iteration 2034, loss = 0.01656280\n",
      "Iteration 2035, loss = 0.01655290\n",
      "Iteration 2036, loss = 0.01654280\n",
      "Iteration 2037, loss = 0.01653281\n",
      "Iteration 2038, loss = 0.01652385\n",
      "Iteration 2039, loss = 0.01651575\n",
      "Iteration 2040, loss = 0.01650510\n",
      "Iteration 2041, loss = 0.01649523\n",
      "Iteration 2042, loss = 0.01648462\n",
      "Iteration 2043, loss = 0.01647467\n",
      "Iteration 2044, loss = 0.01646327\n",
      "Iteration 2045, loss = 0.01645342\n",
      "Iteration 2046, loss = 0.01644162\n",
      "Iteration 2047, loss = 0.01643291\n",
      "Iteration 2048, loss = 0.01642111\n",
      "Iteration 2049, loss = 0.01641196\n",
      "Iteration 2050, loss = 0.01640074\n",
      "Iteration 2051, loss = 0.01638997\n",
      "Iteration 2052, loss = 0.01638383\n",
      "Iteration 2053, loss = 0.01637135\n",
      "Iteration 2054, loss = 0.01636285\n",
      "Iteration 2055, loss = 0.01635211\n",
      "Iteration 2056, loss = 0.01634404\n",
      "Iteration 2057, loss = 0.01633292\n",
      "Iteration 2058, loss = 0.01632476\n",
      "Iteration 2059, loss = 0.01631439\n",
      "Iteration 2060, loss = 0.01630456\n",
      "Iteration 2061, loss = 0.01629450\n",
      "Iteration 2062, loss = 0.01628555\n",
      "Iteration 2063, loss = 0.01627490\n",
      "Iteration 2064, loss = 0.01626513\n",
      "Iteration 2065, loss = 0.01625429\n",
      "Iteration 2066, loss = 0.01624443\n",
      "Iteration 2067, loss = 0.01623399\n",
      "Iteration 2068, loss = 0.01622455\n",
      "Iteration 2069, loss = 0.01621528\n",
      "Iteration 2070, loss = 0.01620544\n",
      "Iteration 2071, loss = 0.01619670\n",
      "Iteration 2072, loss = 0.01618817\n",
      "Iteration 2073, loss = 0.01618017\n",
      "Iteration 2074, loss = 0.01616900\n",
      "Iteration 2075, loss = 0.01616106\n",
      "Iteration 2076, loss = 0.01614995\n",
      "Iteration 2077, loss = 0.01614088\n",
      "Iteration 2078, loss = 0.01613125\n",
      "Iteration 2079, loss = 0.01612122\n",
      "Iteration 2080, loss = 0.01611262\n",
      "Iteration 2081, loss = 0.01610488\n",
      "Iteration 2082, loss = 0.01609481\n",
      "Iteration 2083, loss = 0.01608674\n",
      "Iteration 2084, loss = 0.01607607\n",
      "Iteration 2085, loss = 0.01606584\n",
      "Iteration 2086, loss = 0.01605712\n",
      "Iteration 2087, loss = 0.01604790\n",
      "Iteration 2088, loss = 0.01603810\n",
      "Iteration 2089, loss = 0.01603069\n",
      "Iteration 2090, loss = 0.01601966\n",
      "Iteration 2091, loss = 0.01601254\n",
      "Iteration 2092, loss = 0.01600248\n",
      "Iteration 2093, loss = 0.01599389\n",
      "Iteration 2094, loss = 0.01598474\n",
      "Iteration 2095, loss = 0.01597656\n",
      "Iteration 2096, loss = 0.01596816\n",
      "Iteration 2097, loss = 0.01595813\n",
      "Iteration 2098, loss = 0.01594966\n",
      "Iteration 2099, loss = 0.01593921\n",
      "Iteration 2100, loss = 0.01593168\n",
      "Iteration 2101, loss = 0.01592125\n",
      "Iteration 2102, loss = 0.01591109\n",
      "Iteration 2103, loss = 0.01590258\n",
      "Iteration 2104, loss = 0.01589372\n",
      "Iteration 2105, loss = 0.01588580\n",
      "Iteration 2106, loss = 0.01587712\n",
      "Iteration 2107, loss = 0.01586743\n",
      "Iteration 2108, loss = 0.01585934\n",
      "Iteration 2109, loss = 0.01585061\n",
      "Iteration 2110, loss = 0.01584073\n",
      "Iteration 2111, loss = 0.01583196\n",
      "Iteration 2112, loss = 0.01582254\n",
      "Iteration 2113, loss = 0.01581397\n",
      "Iteration 2114, loss = 0.01580504\n",
      "Iteration 2115, loss = 0.01579646\n",
      "Iteration 2116, loss = 0.01579208\n",
      "Iteration 2117, loss = 0.01578036\n",
      "Iteration 2118, loss = 0.01577123\n",
      "Iteration 2119, loss = 0.01576273\n",
      "Iteration 2120, loss = 0.01575285\n",
      "Iteration 2121, loss = 0.01574486\n",
      "Iteration 2122, loss = 0.01573534\n",
      "Iteration 2123, loss = 0.01572563\n",
      "Iteration 2124, loss = 0.01571899\n",
      "Iteration 2125, loss = 0.01570987\n",
      "Iteration 2126, loss = 0.01570288\n",
      "Iteration 2127, loss = 0.01568924\n",
      "Iteration 2128, loss = 0.01567885\n",
      "Iteration 2129, loss = 0.01566755\n",
      "Iteration 2130, loss = 0.01566038\n",
      "Iteration 2131, loss = 0.01564956\n",
      "Iteration 2132, loss = 0.01564050\n",
      "Iteration 2133, loss = 0.01563120\n",
      "Iteration 2134, loss = 0.01562043\n",
      "Iteration 2135, loss = 0.01561484\n",
      "Iteration 2136, loss = 0.01560402\n",
      "Iteration 2137, loss = 0.01559453\n",
      "Iteration 2138, loss = 0.01558576\n",
      "Iteration 2139, loss = 0.01557690\n",
      "Iteration 2140, loss = 0.01556698\n",
      "Iteration 2141, loss = 0.01555771\n",
      "Iteration 2142, loss = 0.01554700\n",
      "Iteration 2143, loss = 0.01553989\n",
      "Iteration 2144, loss = 0.01552852\n",
      "Iteration 2145, loss = 0.01552025\n",
      "Iteration 2146, loss = 0.01551037\n",
      "Iteration 2147, loss = 0.01550299\n",
      "Iteration 2148, loss = 0.01549345\n",
      "Iteration 2149, loss = 0.01548454\n",
      "Iteration 2150, loss = 0.01547671\n",
      "Iteration 2151, loss = 0.01546918\n",
      "Iteration 2152, loss = 0.01546059\n",
      "Iteration 2153, loss = 0.01545266\n",
      "Iteration 2154, loss = 0.01544323\n",
      "Iteration 2155, loss = 0.01543397\n",
      "Iteration 2156, loss = 0.01542514\n",
      "Iteration 2157, loss = 0.01541480\n",
      "Iteration 2158, loss = 0.01540633\n",
      "Iteration 2159, loss = 0.01539613\n",
      "Iteration 2160, loss = 0.01538773\n",
      "Iteration 2161, loss = 0.01537745\n",
      "Iteration 2162, loss = 0.01537161\n",
      "Iteration 2163, loss = 0.01536063\n",
      "Iteration 2164, loss = 0.01535135\n",
      "Iteration 2165, loss = 0.01534138\n",
      "Iteration 2166, loss = 0.01533306\n",
      "Iteration 2167, loss = 0.01532410\n",
      "Iteration 2168, loss = 0.01531431\n",
      "Iteration 2169, loss = 0.01530722\n",
      "Iteration 2170, loss = 0.01529797\n",
      "Iteration 2171, loss = 0.01529027\n",
      "Iteration 2172, loss = 0.01528140\n",
      "Iteration 2173, loss = 0.01527298\n",
      "Iteration 2174, loss = 0.01526425\n",
      "Iteration 2175, loss = 0.01525715\n",
      "Iteration 2176, loss = 0.01524677\n",
      "Iteration 2177, loss = 0.01523899\n",
      "Iteration 2178, loss = 0.01522883\n",
      "Iteration 2179, loss = 0.01522116\n",
      "Iteration 2180, loss = 0.01521476\n",
      "Iteration 2181, loss = 0.01520498\n",
      "Iteration 2182, loss = 0.01519673\n",
      "Iteration 2183, loss = 0.01518747\n",
      "Iteration 2184, loss = 0.01517942\n",
      "Iteration 2185, loss = 0.01517078\n",
      "Iteration 2186, loss = 0.01516399\n",
      "Iteration 2187, loss = 0.01515619\n",
      "Iteration 2188, loss = 0.01514775\n",
      "Iteration 2189, loss = 0.01513912\n",
      "Iteration 2190, loss = 0.01513071\n",
      "Iteration 2191, loss = 0.01512294\n",
      "Iteration 2192, loss = 0.01511432\n",
      "Iteration 2193, loss = 0.01510475\n",
      "Iteration 2194, loss = 0.01509636\n",
      "Iteration 2195, loss = 0.01508636\n",
      "Iteration 2196, loss = 0.01507807\n",
      "Iteration 2197, loss = 0.01507002\n",
      "Iteration 2198, loss = 0.01506109\n",
      "Iteration 2199, loss = 0.01505133\n",
      "Iteration 2200, loss = 0.01504444\n",
      "Iteration 2201, loss = 0.01503632\n",
      "Iteration 2202, loss = 0.01502974\n",
      "Iteration 2203, loss = 0.01502071\n",
      "Iteration 2204, loss = 0.01501373\n",
      "Iteration 2205, loss = 0.01500520\n",
      "Iteration 2206, loss = 0.01499829\n",
      "Iteration 2207, loss = 0.01499143\n",
      "Iteration 2208, loss = 0.01498341\n",
      "Iteration 2209, loss = 0.01497522\n",
      "Iteration 2210, loss = 0.01496622\n",
      "Iteration 2211, loss = 0.01495894\n",
      "Iteration 2212, loss = 0.01495347\n",
      "Iteration 2213, loss = 0.01494174\n",
      "Iteration 2214, loss = 0.01493517\n",
      "Iteration 2215, loss = 0.01492476\n",
      "Iteration 2216, loss = 0.01491649\n",
      "Iteration 2217, loss = 0.01490766\n",
      "Iteration 2218, loss = 0.01490021\n",
      "Iteration 2219, loss = 0.01489321\n",
      "Iteration 2220, loss = 0.01488350\n",
      "Iteration 2221, loss = 0.01487789\n",
      "Iteration 2222, loss = 0.01486805\n",
      "Iteration 2223, loss = 0.01486214\n",
      "Iteration 2224, loss = 0.01485252\n",
      "Iteration 2225, loss = 0.01484372\n",
      "Iteration 2226, loss = 0.01483544\n",
      "Iteration 2227, loss = 0.01482817\n",
      "Iteration 2228, loss = 0.01482060\n",
      "Iteration 2229, loss = 0.01481226\n",
      "Iteration 2230, loss = 0.01480447\n",
      "Iteration 2231, loss = 0.01479728\n",
      "Iteration 2232, loss = 0.01478940\n",
      "Iteration 2233, loss = 0.01478091\n",
      "Iteration 2234, loss = 0.01477456\n",
      "Iteration 2235, loss = 0.01476594\n",
      "Iteration 2236, loss = 0.01475813\n",
      "Iteration 2237, loss = 0.01475129\n",
      "Iteration 2238, loss = 0.01474258\n",
      "Iteration 2239, loss = 0.01473432\n",
      "Iteration 2240, loss = 0.01472621\n",
      "Iteration 2241, loss = 0.01471773\n",
      "Iteration 2242, loss = 0.01470849\n",
      "Iteration 2243, loss = 0.01469903\n",
      "Iteration 2244, loss = 0.01469128\n",
      "Iteration 2245, loss = 0.01468431\n",
      "Iteration 2246, loss = 0.01467515\n",
      "Iteration 2247, loss = 0.01466612\n",
      "Iteration 2248, loss = 0.01465882\n",
      "Iteration 2249, loss = 0.01465201\n",
      "Iteration 2250, loss = 0.01464356\n",
      "Iteration 2251, loss = 0.01463799\n",
      "Iteration 2252, loss = 0.01462976\n",
      "Iteration 2253, loss = 0.01462273\n",
      "Iteration 2254, loss = 0.01461306\n",
      "Iteration 2255, loss = 0.01460565\n",
      "Iteration 2256, loss = 0.01459717\n",
      "Iteration 2257, loss = 0.01458950\n",
      "Iteration 2258, loss = 0.01458092\n",
      "Iteration 2259, loss = 0.01457302\n",
      "Iteration 2260, loss = 0.01456540\n",
      "Iteration 2261, loss = 0.01455728\n",
      "Iteration 2262, loss = 0.01454806\n",
      "Iteration 2263, loss = 0.01454004\n",
      "Iteration 2264, loss = 0.01453228\n",
      "Iteration 2265, loss = 0.01452388\n",
      "Iteration 2266, loss = 0.01451691\n",
      "Iteration 2267, loss = 0.01450920\n",
      "Iteration 2268, loss = 0.01450222\n",
      "Iteration 2269, loss = 0.01449510\n",
      "Iteration 2270, loss = 0.01448802\n",
      "Iteration 2271, loss = 0.01448015\n",
      "Iteration 2272, loss = 0.01447259\n",
      "Iteration 2273, loss = 0.01446530\n",
      "Iteration 2274, loss = 0.01445688\n",
      "Iteration 2275, loss = 0.01444875\n",
      "Iteration 2276, loss = 0.01444114\n",
      "Iteration 2277, loss = 0.01443398\n",
      "Iteration 2278, loss = 0.01442591\n",
      "Iteration 2279, loss = 0.01441650\n",
      "Iteration 2280, loss = 0.01440841\n",
      "Iteration 2281, loss = 0.01440134\n",
      "Iteration 2282, loss = 0.01439313\n",
      "Iteration 2283, loss = 0.01438486\n",
      "Iteration 2284, loss = 0.01437673\n",
      "Iteration 2285, loss = 0.01436900\n",
      "Iteration 2286, loss = 0.01436124\n",
      "Iteration 2287, loss = 0.01435297\n",
      "Iteration 2288, loss = 0.01434501\n",
      "Iteration 2289, loss = 0.01433706\n",
      "Iteration 2290, loss = 0.01432926\n",
      "Iteration 2291, loss = 0.01432025\n",
      "Iteration 2292, loss = 0.01431343\n",
      "Iteration 2293, loss = 0.01430515\n",
      "Iteration 2294, loss = 0.01429770\n",
      "Iteration 2295, loss = 0.01429165\n",
      "Iteration 2296, loss = 0.01428381\n",
      "Iteration 2297, loss = 0.01427680\n",
      "Iteration 2298, loss = 0.01427228\n",
      "Iteration 2299, loss = 0.01426329\n",
      "Iteration 2300, loss = 0.01425705\n",
      "Iteration 2301, loss = 0.01425213\n",
      "Iteration 2302, loss = 0.01424298\n",
      "Iteration 2303, loss = 0.01423485\n",
      "Iteration 2304, loss = 0.01422617\n",
      "Iteration 2305, loss = 0.01421944\n",
      "Iteration 2306, loss = 0.01421092\n",
      "Iteration 2307, loss = 0.01420544\n",
      "Iteration 2308, loss = 0.01419784\n",
      "Iteration 2309, loss = 0.01418891\n",
      "Iteration 2310, loss = 0.01418183\n",
      "Iteration 2311, loss = 0.01417418\n",
      "Iteration 2312, loss = 0.01416694\n",
      "Iteration 2313, loss = 0.01415933\n",
      "Iteration 2314, loss = 0.01415208\n",
      "Iteration 2315, loss = 0.01414455\n",
      "Iteration 2316, loss = 0.01413793\n",
      "Iteration 2317, loss = 0.01413017\n",
      "Iteration 2318, loss = 0.01412388\n",
      "Iteration 2319, loss = 0.01411647\n",
      "Iteration 2320, loss = 0.01411030\n",
      "Iteration 2321, loss = 0.01410280\n",
      "Iteration 2322, loss = 0.01409563\n",
      "Iteration 2323, loss = 0.01408852\n",
      "Iteration 2324, loss = 0.01408165\n",
      "Iteration 2325, loss = 0.01407348\n",
      "Iteration 2326, loss = 0.01406651\n",
      "Iteration 2327, loss = 0.01405789\n",
      "Iteration 2328, loss = 0.01404966\n",
      "Iteration 2329, loss = 0.01404066\n",
      "Iteration 2330, loss = 0.01403295\n",
      "Iteration 2331, loss = 0.01402581\n",
      "Iteration 2332, loss = 0.01401590\n",
      "Iteration 2333, loss = 0.01400778\n",
      "Iteration 2334, loss = 0.01400203\n",
      "Iteration 2335, loss = 0.01399300\n",
      "Iteration 2336, loss = 0.01398675\n",
      "Iteration 2337, loss = 0.01397675\n",
      "Iteration 2338, loss = 0.01396909\n",
      "Iteration 2339, loss = 0.01396143\n",
      "Iteration 2340, loss = 0.01395323\n",
      "Iteration 2341, loss = 0.01394656\n",
      "Iteration 2342, loss = 0.01393724\n",
      "Iteration 2343, loss = 0.01393037\n",
      "Iteration 2344, loss = 0.01392231\n",
      "Iteration 2345, loss = 0.01391415\n",
      "Iteration 2346, loss = 0.01390797\n",
      "Iteration 2347, loss = 0.01390056\n",
      "Iteration 2348, loss = 0.01389079\n",
      "Iteration 2349, loss = 0.01388379\n",
      "Iteration 2350, loss = 0.01387568\n",
      "Iteration 2351, loss = 0.01386788\n",
      "Iteration 2352, loss = 0.01385996\n",
      "Iteration 2353, loss = 0.01385270\n",
      "Iteration 2354, loss = 0.01384756\n",
      "Iteration 2355, loss = 0.01383782\n",
      "Iteration 2356, loss = 0.01383101\n",
      "Iteration 2357, loss = 0.01382252\n",
      "Iteration 2358, loss = 0.01381496\n",
      "Iteration 2359, loss = 0.01380766\n",
      "Iteration 2360, loss = 0.01379977\n",
      "Iteration 2361, loss = 0.01379285\n",
      "Iteration 2362, loss = 0.01378504\n",
      "Iteration 2363, loss = 0.01377738\n",
      "Iteration 2364, loss = 0.01377059\n",
      "Iteration 2365, loss = 0.01376255\n",
      "Iteration 2366, loss = 0.01375570\n",
      "Iteration 2367, loss = 0.01374916\n",
      "Iteration 2368, loss = 0.01374122\n",
      "Iteration 2369, loss = 0.01373250\n",
      "Iteration 2370, loss = 0.01372638\n",
      "Iteration 2371, loss = 0.01371929\n",
      "Iteration 2372, loss = 0.01371306\n",
      "Iteration 2373, loss = 0.01370423\n",
      "Iteration 2374, loss = 0.01369704\n",
      "Iteration 2375, loss = 0.01369057\n",
      "Iteration 2376, loss = 0.01368316\n",
      "Iteration 2377, loss = 0.01367561\n",
      "Iteration 2378, loss = 0.01366903\n",
      "Iteration 2379, loss = 0.01366197\n",
      "Iteration 2380, loss = 0.01365381\n",
      "Iteration 2381, loss = 0.01364645\n",
      "Iteration 2382, loss = 0.01364013\n",
      "Iteration 2383, loss = 0.01363411\n",
      "Iteration 2384, loss = 0.01362641\n",
      "Iteration 2385, loss = 0.01362016\n",
      "Iteration 2386, loss = 0.01361336\n",
      "Iteration 2387, loss = 0.01360688\n",
      "Iteration 2388, loss = 0.01359968\n",
      "Iteration 2389, loss = 0.01359468\n",
      "Iteration 2390, loss = 0.01358754\n",
      "Iteration 2391, loss = 0.01357989\n",
      "Iteration 2392, loss = 0.01357197\n",
      "Iteration 2393, loss = 0.01356422\n",
      "Iteration 2394, loss = 0.01355782\n",
      "Iteration 2395, loss = 0.01354960\n",
      "Iteration 2396, loss = 0.01354248\n",
      "Iteration 2397, loss = 0.01353486\n",
      "Iteration 2398, loss = 0.01352906\n",
      "Iteration 2399, loss = 0.01352037\n",
      "Iteration 2400, loss = 0.01351342\n",
      "Iteration 2401, loss = 0.01350665\n",
      "Iteration 2402, loss = 0.01349877\n",
      "Iteration 2403, loss = 0.01349159\n",
      "Iteration 2404, loss = 0.01348430\n",
      "Iteration 2405, loss = 0.01347816\n",
      "Iteration 2406, loss = 0.01347068\n",
      "Iteration 2407, loss = 0.01346323\n",
      "Iteration 2408, loss = 0.01345640\n",
      "Iteration 2409, loss = 0.01345152\n",
      "Iteration 2410, loss = 0.01344332\n",
      "Iteration 2411, loss = 0.01343627\n",
      "Iteration 2412, loss = 0.01343050\n",
      "Iteration 2413, loss = 0.01342090\n",
      "Iteration 2414, loss = 0.01341356\n",
      "Iteration 2415, loss = 0.01340627\n",
      "Iteration 2416, loss = 0.01339956\n",
      "Iteration 2417, loss = 0.01339081\n",
      "Iteration 2418, loss = 0.01338556\n",
      "Iteration 2419, loss = 0.01337725\n",
      "Iteration 2420, loss = 0.01336975\n",
      "Iteration 2421, loss = 0.01336271\n",
      "Iteration 2422, loss = 0.01335565\n",
      "Iteration 2423, loss = 0.01334853\n",
      "Iteration 2424, loss = 0.01334156\n",
      "Iteration 2425, loss = 0.01333506\n",
      "Iteration 2426, loss = 0.01332761\n",
      "Iteration 2427, loss = 0.01332161\n",
      "Iteration 2428, loss = 0.01331469\n",
      "Iteration 2429, loss = 0.01330839\n",
      "Iteration 2430, loss = 0.01330205\n",
      "Iteration 2431, loss = 0.01329570\n",
      "Iteration 2432, loss = 0.01328941\n",
      "Iteration 2433, loss = 0.01328467\n",
      "Iteration 2434, loss = 0.01327749\n",
      "Iteration 2435, loss = 0.01327180\n",
      "Iteration 2436, loss = 0.01326646\n",
      "Iteration 2437, loss = 0.01325920\n",
      "Iteration 2438, loss = 0.01325376\n",
      "Iteration 2439, loss = 0.01324773\n",
      "Iteration 2440, loss = 0.01323993\n",
      "Iteration 2441, loss = 0.01323380\n",
      "Iteration 2442, loss = 0.01322596\n",
      "Iteration 2443, loss = 0.01321937\n",
      "Iteration 2444, loss = 0.01321226\n",
      "Iteration 2445, loss = 0.01320481\n",
      "Iteration 2446, loss = 0.01319770\n",
      "Iteration 2447, loss = 0.01319086\n",
      "Iteration 2448, loss = 0.01318281\n",
      "Iteration 2449, loss = 0.01317707\n",
      "Iteration 2450, loss = 0.01316922\n",
      "Iteration 2451, loss = 0.01316378\n",
      "Iteration 2452, loss = 0.01315560\n",
      "Iteration 2453, loss = 0.01314976\n",
      "Iteration 2454, loss = 0.01314355\n",
      "Iteration 2455, loss = 0.01313738\n",
      "Iteration 2456, loss = 0.01313091\n",
      "Iteration 2457, loss = 0.01312425\n",
      "Iteration 2458, loss = 0.01311774\n",
      "Iteration 2459, loss = 0.01311196\n",
      "Iteration 2460, loss = 0.01310471\n",
      "Iteration 2461, loss = 0.01309782\n",
      "Iteration 2462, loss = 0.01309124\n",
      "Iteration 2463, loss = 0.01308558\n",
      "Iteration 2464, loss = 0.01307865\n",
      "Iteration 2465, loss = 0.01306986\n",
      "Iteration 2466, loss = 0.01306438\n",
      "Iteration 2467, loss = 0.01305575\n",
      "Iteration 2468, loss = 0.01304910\n",
      "Iteration 2469, loss = 0.01304247\n",
      "Iteration 2470, loss = 0.01303553\n",
      "Iteration 2471, loss = 0.01302926\n",
      "Iteration 2472, loss = 0.01302180\n",
      "Iteration 2473, loss = 0.01301705\n",
      "Iteration 2474, loss = 0.01300940\n",
      "Iteration 2475, loss = 0.01300311\n",
      "Iteration 2476, loss = 0.01299586\n",
      "Iteration 2477, loss = 0.01299042\n",
      "Iteration 2478, loss = 0.01298336\n",
      "Iteration 2479, loss = 0.01297668\n",
      "Iteration 2480, loss = 0.01297020\n",
      "Iteration 2481, loss = 0.01296403\n",
      "Iteration 2482, loss = 0.01295776\n",
      "Iteration 2483, loss = 0.01295197\n",
      "Iteration 2484, loss = 0.01294696\n",
      "Iteration 2485, loss = 0.01294016\n",
      "Iteration 2486, loss = 0.01293438\n",
      "Iteration 2487, loss = 0.01292845\n",
      "Iteration 2488, loss = 0.01292278\n",
      "Iteration 2489, loss = 0.01291681\n",
      "Iteration 2490, loss = 0.01291238\n",
      "Iteration 2491, loss = 0.01290653\n",
      "Iteration 2492, loss = 0.01290122\n",
      "Iteration 2493, loss = 0.01289715\n",
      "Iteration 2494, loss = 0.01289063\n",
      "Iteration 2495, loss = 0.01288513\n",
      "Iteration 2496, loss = 0.01287917\n",
      "Iteration 2497, loss = 0.01287330\n",
      "Iteration 2498, loss = 0.01286891\n",
      "Iteration 2499, loss = 0.01286326\n",
      "Iteration 2500, loss = 0.01285842\n",
      "Iteration 2501, loss = 0.01285149\n",
      "Iteration 2502, loss = 0.01284553\n",
      "Iteration 2503, loss = 0.01283885\n",
      "Iteration 2504, loss = 0.01283324\n",
      "Iteration 2505, loss = 0.01282643\n",
      "Iteration 2506, loss = 0.01282010\n",
      "Iteration 2507, loss = 0.01281396\n",
      "Iteration 2508, loss = 0.01280662\n",
      "Iteration 2509, loss = 0.01279969\n",
      "Iteration 2510, loss = 0.01279318\n",
      "Iteration 2511, loss = 0.01278765\n",
      "Iteration 2512, loss = 0.01278143\n",
      "Iteration 2513, loss = 0.01277565\n",
      "Iteration 2514, loss = 0.01276982\n",
      "Iteration 2515, loss = 0.01276448\n",
      "Iteration 2516, loss = 0.01275886\n",
      "Iteration 2517, loss = 0.01275323\n",
      "Iteration 2518, loss = 0.01274934\n",
      "Iteration 2519, loss = 0.01274169\n",
      "Iteration 2520, loss = 0.01273580\n",
      "Iteration 2521, loss = 0.01272886\n",
      "Iteration 2522, loss = 0.01272235\n",
      "Iteration 2523, loss = 0.01271650\n",
      "Iteration 2524, loss = 0.01270967\n",
      "Iteration 2525, loss = 0.01270255\n",
      "Iteration 2526, loss = 0.01269569\n",
      "Iteration 2527, loss = 0.01268847\n",
      "Iteration 2528, loss = 0.01268305\n",
      "Iteration 2529, loss = 0.01267650\n",
      "Iteration 2530, loss = 0.01267015\n",
      "Iteration 2531, loss = 0.01266315\n",
      "Iteration 2532, loss = 0.01265696\n",
      "Iteration 2533, loss = 0.01265107\n",
      "Iteration 2534, loss = 0.01264502\n",
      "Iteration 2535, loss = 0.01263887\n",
      "Iteration 2536, loss = 0.01263323\n",
      "Iteration 2537, loss = 0.01262552\n",
      "Iteration 2538, loss = 0.01262138\n",
      "Iteration 2539, loss = 0.01261271\n",
      "Iteration 2540, loss = 0.01260616\n",
      "Iteration 2541, loss = 0.01259918\n",
      "Iteration 2542, loss = 0.01259452\n",
      "Iteration 2543, loss = 0.01258687\n",
      "Iteration 2544, loss = 0.01258094\n",
      "Iteration 2545, loss = 0.01257497\n",
      "Iteration 2546, loss = 0.01256788\n",
      "Iteration 2547, loss = 0.01256106\n",
      "Iteration 2548, loss = 0.01255424\n",
      "Iteration 2549, loss = 0.01254664\n",
      "Iteration 2550, loss = 0.01253953\n",
      "Iteration 2551, loss = 0.01253277\n",
      "Iteration 2552, loss = 0.01252496\n",
      "Iteration 2553, loss = 0.01251888\n",
      "Iteration 2554, loss = 0.01251228\n",
      "Iteration 2555, loss = 0.01250573\n",
      "Iteration 2556, loss = 0.01249893\n",
      "Iteration 2557, loss = 0.01249221\n",
      "Iteration 2558, loss = 0.01248842\n",
      "Iteration 2559, loss = 0.01248020\n",
      "Iteration 2560, loss = 0.01247461\n",
      "Iteration 2561, loss = 0.01247033\n",
      "Iteration 2562, loss = 0.01246212\n",
      "Iteration 2563, loss = 0.01245539\n",
      "Iteration 2564, loss = 0.01244920\n",
      "Iteration 2565, loss = 0.01244199\n",
      "Iteration 2566, loss = 0.01243741\n",
      "Iteration 2567, loss = 0.01242940\n",
      "Iteration 2568, loss = 0.01242284\n",
      "Iteration 2569, loss = 0.01241584\n",
      "Iteration 2570, loss = 0.01240924\n",
      "Iteration 2571, loss = 0.01240352\n",
      "Iteration 2572, loss = 0.01239556\n",
      "Iteration 2573, loss = 0.01238934\n",
      "Iteration 2574, loss = 0.01238385\n",
      "Iteration 2575, loss = 0.01237703\n",
      "Iteration 2576, loss = 0.01237048\n",
      "Iteration 2577, loss = 0.01236286\n",
      "Iteration 2578, loss = 0.01235600\n",
      "Iteration 2579, loss = 0.01234852\n",
      "Iteration 2580, loss = 0.01234412\n",
      "Iteration 2581, loss = 0.01233670\n",
      "Iteration 2582, loss = 0.01232951\n",
      "Iteration 2583, loss = 0.01232531\n",
      "Iteration 2584, loss = 0.01231764\n",
      "Iteration 2585, loss = 0.01231101\n",
      "Iteration 2586, loss = 0.01230467\n",
      "Iteration 2587, loss = 0.01229945\n",
      "Iteration 2588, loss = 0.01229242\n",
      "Iteration 2589, loss = 0.01228680\n",
      "Iteration 2590, loss = 0.01228039\n",
      "Iteration 2591, loss = 0.01227448\n",
      "Iteration 2592, loss = 0.01226852\n",
      "Iteration 2593, loss = 0.01226445\n",
      "Iteration 2594, loss = 0.01225744\n",
      "Iteration 2595, loss = 0.01225257\n",
      "Iteration 2596, loss = 0.01224807\n",
      "Iteration 2597, loss = 0.01224160\n",
      "Iteration 2598, loss = 0.01223600\n",
      "Iteration 2599, loss = 0.01223047\n",
      "Iteration 2600, loss = 0.01222481\n",
      "Iteration 2601, loss = 0.01221904\n",
      "Iteration 2602, loss = 0.01221434\n",
      "Iteration 2603, loss = 0.01220680\n",
      "Iteration 2604, loss = 0.01220135\n",
      "Iteration 2605, loss = 0.01219519\n",
      "Iteration 2606, loss = 0.01218937\n",
      "Iteration 2607, loss = 0.01218416\n",
      "Iteration 2608, loss = 0.01217825\n",
      "Iteration 2609, loss = 0.01217288\n",
      "Iteration 2610, loss = 0.01216613\n",
      "Iteration 2611, loss = 0.01216083\n",
      "Iteration 2612, loss = 0.01215491\n",
      "Iteration 2613, loss = 0.01214928\n",
      "Iteration 2614, loss = 0.01214343\n",
      "Iteration 2615, loss = 0.01213692\n",
      "Iteration 2616, loss = 0.01213309\n",
      "Iteration 2617, loss = 0.01212603\n",
      "Iteration 2618, loss = 0.01212084\n",
      "Iteration 2619, loss = 0.01211506\n",
      "Iteration 2620, loss = 0.01210950\n",
      "Iteration 2621, loss = 0.01210459\n",
      "Iteration 2622, loss = 0.01209944\n",
      "Iteration 2623, loss = 0.01209473\n",
      "Iteration 2624, loss = 0.01209145\n",
      "Iteration 2625, loss = 0.01208538\n",
      "Iteration 2626, loss = 0.01208096\n",
      "Iteration 2627, loss = 0.01207699\n",
      "Iteration 2628, loss = 0.01207191\n",
      "Iteration 2629, loss = 0.01206662\n",
      "Iteration 2630, loss = 0.01206096\n",
      "Iteration 2631, loss = 0.01205589\n",
      "Iteration 2632, loss = 0.01205002\n",
      "Iteration 2633, loss = 0.01204479\n",
      "Iteration 2634, loss = 0.01203925\n",
      "Iteration 2635, loss = 0.01203395\n",
      "Iteration 2636, loss = 0.01202861\n",
      "Iteration 2637, loss = 0.01202224\n",
      "Iteration 2638, loss = 0.01201629\n",
      "Iteration 2639, loss = 0.01200915\n",
      "Iteration 2640, loss = 0.01200348\n",
      "Iteration 2641, loss = 0.01199821\n",
      "Iteration 2642, loss = 0.01199150\n",
      "Iteration 2643, loss = 0.01198515\n",
      "Iteration 2644, loss = 0.01198045\n",
      "Iteration 2645, loss = 0.01197360\n",
      "Iteration 2646, loss = 0.01197000\n",
      "Iteration 2647, loss = 0.01196352\n",
      "Iteration 2648, loss = 0.01195724\n",
      "Iteration 2649, loss = 0.01195207\n",
      "Iteration 2650, loss = 0.01194679\n",
      "Iteration 2651, loss = 0.01194132\n",
      "Iteration 2652, loss = 0.01193514\n",
      "Iteration 2653, loss = 0.01193050\n",
      "Iteration 2654, loss = 0.01192431\n",
      "Iteration 2655, loss = 0.01191941\n",
      "Iteration 2656, loss = 0.01191391\n",
      "Iteration 2657, loss = 0.01190892\n",
      "Iteration 2658, loss = 0.01190296\n",
      "Iteration 2659, loss = 0.01189643\n",
      "Iteration 2660, loss = 0.01189002\n",
      "Iteration 2661, loss = 0.01188408\n",
      "Iteration 2662, loss = 0.01187822\n",
      "Iteration 2663, loss = 0.01187389\n",
      "Iteration 2664, loss = 0.01186700\n",
      "Iteration 2665, loss = 0.01186308\n",
      "Iteration 2666, loss = 0.01185577\n",
      "Iteration 2667, loss = 0.01185011\n",
      "Iteration 2668, loss = 0.01184503\n",
      "Iteration 2669, loss = 0.01183880\n",
      "Iteration 2670, loss = 0.01183300\n",
      "Iteration 2671, loss = 0.01182856\n",
      "Iteration 2672, loss = 0.01182036\n",
      "Iteration 2673, loss = 0.01181379\n",
      "Iteration 2674, loss = 0.01180780\n",
      "Iteration 2675, loss = 0.01180122\n",
      "Iteration 2676, loss = 0.01179620\n",
      "Iteration 2677, loss = 0.01178895\n",
      "Iteration 2678, loss = 0.01178317\n",
      "Iteration 2679, loss = 0.01177701\n",
      "Iteration 2680, loss = 0.01177069\n",
      "Iteration 2681, loss = 0.01176658\n",
      "Iteration 2682, loss = 0.01175847\n",
      "Iteration 2683, loss = 0.01175280\n",
      "Iteration 2684, loss = 0.01174688\n",
      "Iteration 2685, loss = 0.01174044\n",
      "Iteration 2686, loss = 0.01173456\n",
      "Iteration 2687, loss = 0.01172765\n",
      "Iteration 2688, loss = 0.01172381\n",
      "Iteration 2689, loss = 0.01171642\n",
      "Iteration 2690, loss = 0.01171231\n",
      "Iteration 2691, loss = 0.01170568\n",
      "Iteration 2692, loss = 0.01169985\n",
      "Iteration 2693, loss = 0.01169414\n",
      "Iteration 2694, loss = 0.01168894\n",
      "Iteration 2695, loss = 0.01168403\n",
      "Iteration 2696, loss = 0.01167811\n",
      "Iteration 2697, loss = 0.01167253\n",
      "Iteration 2698, loss = 0.01166644\n",
      "Iteration 2699, loss = 0.01166111\n",
      "Iteration 2700, loss = 0.01165432\n",
      "Iteration 2701, loss = 0.01165122\n",
      "Iteration 2702, loss = 0.01164354\n",
      "Iteration 2703, loss = 0.01164097\n",
      "Iteration 2704, loss = 0.01163578\n",
      "Iteration 2705, loss = 0.01163032\n",
      "Iteration 2706, loss = 0.01162483\n",
      "Iteration 2707, loss = 0.01161949\n",
      "Iteration 2708, loss = 0.01161463\n",
      "Iteration 2709, loss = 0.01160898\n",
      "Iteration 2710, loss = 0.01160361\n",
      "Iteration 2711, loss = 0.01159790\n",
      "Iteration 2712, loss = 0.01159346\n",
      "Iteration 2713, loss = 0.01158798\n",
      "Iteration 2714, loss = 0.01158242\n",
      "Iteration 2715, loss = 0.01157665\n",
      "Iteration 2716, loss = 0.01157308\n",
      "Iteration 2717, loss = 0.01156641\n",
      "Iteration 2718, loss = 0.01156082\n",
      "Iteration 2719, loss = 0.01155682\n",
      "Iteration 2720, loss = 0.01155058\n",
      "Iteration 2721, loss = 0.01154519\n",
      "Iteration 2722, loss = 0.01153964\n",
      "Iteration 2723, loss = 0.01153458\n",
      "Iteration 2724, loss = 0.01152902\n",
      "Iteration 2725, loss = 0.01152366\n",
      "Iteration 2726, loss = 0.01151816\n",
      "Iteration 2727, loss = 0.01151296\n",
      "Iteration 2728, loss = 0.01150774\n",
      "Iteration 2729, loss = 0.01150245\n",
      "Iteration 2730, loss = 0.01149661\n",
      "Iteration 2731, loss = 0.01149076\n",
      "Iteration 2732, loss = 0.01148661\n",
      "Iteration 2733, loss = 0.01148038\n",
      "Iteration 2734, loss = 0.01147464\n",
      "Iteration 2735, loss = 0.01146864\n",
      "Iteration 2736, loss = 0.01146444\n",
      "Iteration 2737, loss = 0.01145774\n",
      "Iteration 2738, loss = 0.01145199\n",
      "Iteration 2739, loss = 0.01144609\n",
      "Iteration 2740, loss = 0.01144066\n",
      "Iteration 2741, loss = 0.01143569\n",
      "Iteration 2742, loss = 0.01143029\n",
      "Iteration 2743, loss = 0.01142643\n",
      "Iteration 2744, loss = 0.01141983\n",
      "Iteration 2745, loss = 0.01141417\n",
      "Iteration 2746, loss = 0.01141048\n",
      "Iteration 2747, loss = 0.01140395\n",
      "Iteration 2748, loss = 0.01139692\n",
      "Iteration 2749, loss = 0.01139090\n",
      "Iteration 2750, loss = 0.01138587\n",
      "Iteration 2751, loss = 0.01138023\n",
      "Iteration 2752, loss = 0.01137506\n",
      "Iteration 2753, loss = 0.01136933\n",
      "Iteration 2754, loss = 0.01136443\n",
      "Iteration 2755, loss = 0.01135903\n",
      "Iteration 2756, loss = 0.01135321\n",
      "Iteration 2757, loss = 0.01134862\n",
      "Iteration 2758, loss = 0.01134190\n",
      "Iteration 2759, loss = 0.01133643\n",
      "Iteration 2760, loss = 0.01133130\n",
      "Iteration 2761, loss = 0.01132574\n",
      "Iteration 2762, loss = 0.01131926\n",
      "Iteration 2763, loss = 0.01131394\n",
      "Iteration 2764, loss = 0.01130870\n",
      "Iteration 2765, loss = 0.01130267\n",
      "Iteration 2766, loss = 0.01129735\n",
      "Iteration 2767, loss = 0.01129324\n",
      "Iteration 2768, loss = 0.01128670\n",
      "Iteration 2769, loss = 0.01128154\n",
      "Iteration 2770, loss = 0.01127812\n",
      "Iteration 2771, loss = 0.01127179\n",
      "Iteration 2772, loss = 0.01126691\n",
      "Iteration 2773, loss = 0.01126076\n",
      "Iteration 2774, loss = 0.01125606\n",
      "Iteration 2775, loss = 0.01125060\n",
      "Iteration 2776, loss = 0.01124595\n",
      "Iteration 2777, loss = 0.01124085\n",
      "Iteration 2778, loss = 0.01123451\n",
      "Iteration 2779, loss = 0.01122999\n",
      "Iteration 2780, loss = 0.01122365\n",
      "Iteration 2781, loss = 0.01122053\n",
      "Iteration 2782, loss = 0.01121372\n",
      "Iteration 2783, loss = 0.01120723\n",
      "Iteration 2784, loss = 0.01120318\n",
      "Iteration 2785, loss = 0.01119806\n",
      "Iteration 2786, loss = 0.01119244\n",
      "Iteration 2787, loss = 0.01118663\n",
      "Iteration 2788, loss = 0.01118135\n",
      "Iteration 2789, loss = 0.01117601\n",
      "Iteration 2790, loss = 0.01117421\n",
      "Iteration 2791, loss = 0.01116709\n",
      "Iteration 2792, loss = 0.01116209\n",
      "Iteration 2793, loss = 0.01115714\n",
      "Iteration 2794, loss = 0.01115181\n",
      "Iteration 2795, loss = 0.01114726\n",
      "Iteration 2796, loss = 0.01114229\n",
      "Iteration 2797, loss = 0.01113700\n",
      "Iteration 2798, loss = 0.01113211\n",
      "Iteration 2799, loss = 0.01112781\n",
      "Iteration 2800, loss = 0.01112157\n",
      "Iteration 2801, loss = 0.01111674\n",
      "Iteration 2802, loss = 0.01111176\n",
      "Iteration 2803, loss = 0.01110705\n",
      "Iteration 2804, loss = 0.01110342\n",
      "Iteration 2805, loss = 0.01109872\n",
      "Iteration 2806, loss = 0.01109409\n",
      "Iteration 2807, loss = 0.01108868\n",
      "Iteration 2808, loss = 0.01108354\n",
      "Iteration 2809, loss = 0.01107809\n",
      "Iteration 2810, loss = 0.01107333\n",
      "Iteration 2811, loss = 0.01106833\n",
      "Iteration 2812, loss = 0.01106372\n",
      "Iteration 2813, loss = 0.01105841\n",
      "Iteration 2814, loss = 0.01105466\n",
      "Iteration 2815, loss = 0.01104899\n",
      "Iteration 2816, loss = 0.01104345\n",
      "Iteration 2817, loss = 0.01103734\n",
      "Iteration 2818, loss = 0.01103246\n",
      "Iteration 2819, loss = 0.01102680\n",
      "Iteration 2820, loss = 0.01102081\n",
      "Iteration 2821, loss = 0.01101639\n",
      "Iteration 2822, loss = 0.01101033\n",
      "Iteration 2823, loss = 0.01100498\n",
      "Iteration 2824, loss = 0.01099953\n",
      "Iteration 2825, loss = 0.01099390\n",
      "Iteration 2826, loss = 0.01098942\n",
      "Iteration 2827, loss = 0.01098321\n",
      "Iteration 2828, loss = 0.01097743\n",
      "Iteration 2829, loss = 0.01097288\n",
      "Iteration 2830, loss = 0.01096726\n",
      "Iteration 2831, loss = 0.01096262\n",
      "Iteration 2832, loss = 0.01095654\n",
      "Iteration 2833, loss = 0.01095121\n",
      "Iteration 2834, loss = 0.01094575\n",
      "Iteration 2835, loss = 0.01094039\n",
      "Iteration 2836, loss = 0.01093654\n",
      "Iteration 2837, loss = 0.01093063\n",
      "Iteration 2838, loss = 0.01092587\n",
      "Iteration 2839, loss = 0.01092000\n",
      "Iteration 2840, loss = 0.01091524\n",
      "Iteration 2841, loss = 0.01090932\n",
      "Iteration 2842, loss = 0.01090395\n",
      "Iteration 2843, loss = 0.01089853\n",
      "Iteration 2844, loss = 0.01089207\n",
      "Iteration 2845, loss = 0.01088737\n",
      "Iteration 2846, loss = 0.01088056\n",
      "Iteration 2847, loss = 0.01087530\n",
      "Iteration 2848, loss = 0.01086902\n",
      "Iteration 2849, loss = 0.01086442\n",
      "Iteration 2850, loss = 0.01086059\n",
      "Iteration 2851, loss = 0.01085374\n",
      "Iteration 2852, loss = 0.01084810\n",
      "Iteration 2853, loss = 0.01084323\n",
      "Iteration 2854, loss = 0.01083835\n",
      "Iteration 2855, loss = 0.01083463\n",
      "Iteration 2856, loss = 0.01082805\n",
      "Iteration 2857, loss = 0.01082262\n",
      "Iteration 2858, loss = 0.01081872\n",
      "Iteration 2859, loss = 0.01081270\n",
      "Iteration 2860, loss = 0.01080702\n",
      "Iteration 2861, loss = 0.01080174\n",
      "Iteration 2862, loss = 0.01079653\n",
      "Iteration 2863, loss = 0.01079119\n",
      "Iteration 2864, loss = 0.01078588\n",
      "Iteration 2865, loss = 0.01078069\n",
      "Iteration 2866, loss = 0.01077543\n",
      "Iteration 2867, loss = 0.01077018\n",
      "Iteration 2868, loss = 0.01076464\n",
      "Iteration 2869, loss = 0.01075923\n",
      "Iteration 2870, loss = 0.01075319\n",
      "Iteration 2871, loss = 0.01074812\n",
      "Iteration 2872, loss = 0.01074286\n",
      "Iteration 2873, loss = 0.01073849\n",
      "Iteration 2874, loss = 0.01073315\n",
      "Iteration 2875, loss = 0.01072800\n",
      "Iteration 2876, loss = 0.01072344\n",
      "Iteration 2877, loss = 0.01071895\n",
      "Iteration 2878, loss = 0.01071365\n",
      "Iteration 2879, loss = 0.01070900\n",
      "Iteration 2880, loss = 0.01070571\n",
      "Iteration 2881, loss = 0.01069904\n",
      "Iteration 2882, loss = 0.01069436\n",
      "Iteration 2883, loss = 0.01068962\n",
      "Iteration 2884, loss = 0.01068479\n",
      "Iteration 2885, loss = 0.01067965\n",
      "Iteration 2886, loss = 0.01067499\n",
      "Iteration 2887, loss = 0.01067017\n",
      "Iteration 2888, loss = 0.01066547\n",
      "Iteration 2889, loss = 0.01066064\n",
      "Iteration 2890, loss = 0.01065621\n",
      "Iteration 2891, loss = 0.01065123\n",
      "Iteration 2892, loss = 0.01064661\n",
      "Iteration 2893, loss = 0.01064064\n",
      "Iteration 2894, loss = 0.01063549\n",
      "Iteration 2895, loss = 0.01063088\n",
      "Iteration 2896, loss = 0.01062550\n",
      "Iteration 2897, loss = 0.01062215\n",
      "Iteration 2898, loss = 0.01061504\n",
      "Iteration 2899, loss = 0.01060978\n",
      "Iteration 2900, loss = 0.01060453\n",
      "Iteration 2901, loss = 0.01059950\n",
      "Iteration 2902, loss = 0.01059404\n",
      "Iteration 2903, loss = 0.01058949\n",
      "Iteration 2904, loss = 0.01058703\n",
      "Iteration 2905, loss = 0.01058077\n",
      "Iteration 2906, loss = 0.01057499\n",
      "Iteration 2907, loss = 0.01057000\n",
      "Iteration 2908, loss = 0.01056547\n",
      "Iteration 2909, loss = 0.01056050\n",
      "Iteration 2910, loss = 0.01055515\n",
      "Iteration 2911, loss = 0.01055097\n",
      "Iteration 2912, loss = 0.01054541\n",
      "Iteration 2913, loss = 0.01054055\n",
      "Iteration 2914, loss = 0.01053531\n",
      "Iteration 2915, loss = 0.01053001\n",
      "Iteration 2916, loss = 0.01052506\n",
      "Iteration 2917, loss = 0.01052106\n",
      "Iteration 2918, loss = 0.01051527\n",
      "Iteration 2919, loss = 0.01051074\n",
      "Iteration 2920, loss = 0.01050590\n",
      "Iteration 2921, loss = 0.01050086\n",
      "Iteration 2922, loss = 0.01049633\n",
      "Iteration 2923, loss = 0.01049155\n",
      "Iteration 2924, loss = 0.01048687\n",
      "Iteration 2925, loss = 0.01048218\n",
      "Iteration 2926, loss = 0.01047752\n",
      "Iteration 2927, loss = 0.01047293\n",
      "Iteration 2928, loss = 0.01046835\n",
      "Iteration 2929, loss = 0.01046302\n",
      "Iteration 2930, loss = 0.01045847\n",
      "Iteration 2931, loss = 0.01045409\n",
      "Iteration 2932, loss = 0.01044913\n",
      "Iteration 2933, loss = 0.01044522\n",
      "Iteration 2934, loss = 0.01044033\n",
      "Iteration 2935, loss = 0.01043512\n",
      "Iteration 2936, loss = 0.01043212\n",
      "Iteration 2937, loss = 0.01042591\n",
      "Iteration 2938, loss = 0.01042164\n",
      "Iteration 2939, loss = 0.01041672\n",
      "Iteration 2940, loss = 0.01041315\n",
      "Iteration 2941, loss = 0.01040674\n",
      "Iteration 2942, loss = 0.01040318\n",
      "Iteration 2943, loss = 0.01039705\n",
      "Iteration 2944, loss = 0.01039415\n",
      "Iteration 2945, loss = 0.01038746\n",
      "Iteration 2946, loss = 0.01038174\n",
      "Iteration 2947, loss = 0.01037840\n",
      "Iteration 2948, loss = 0.01037193\n",
      "Iteration 2949, loss = 0.01036645\n",
      "Iteration 2950, loss = 0.01036117\n",
      "Iteration 2951, loss = 0.01035583\n",
      "Iteration 2952, loss = 0.01035200\n",
      "Iteration 2953, loss = 0.01034695\n",
      "Iteration 2954, loss = 0.01034215\n",
      "Iteration 2955, loss = 0.01033774\n",
      "Iteration 2956, loss = 0.01033308\n",
      "Iteration 2957, loss = 0.01032919\n",
      "Iteration 2958, loss = 0.01032423\n",
      "Iteration 2959, loss = 0.01032011\n",
      "Iteration 2960, loss = 0.01031563\n",
      "Iteration 2961, loss = 0.01031146\n",
      "Iteration 2962, loss = 0.01030748\n",
      "Iteration 2963, loss = 0.01030302\n",
      "Iteration 2964, loss = 0.01029905\n",
      "Iteration 2965, loss = 0.01029411\n",
      "Iteration 2966, loss = 0.01028979\n",
      "Iteration 2967, loss = 0.01028473\n",
      "Iteration 2968, loss = 0.01028047\n",
      "Iteration 2969, loss = 0.01027556\n",
      "Iteration 2970, loss = 0.01027074\n",
      "Iteration 2971, loss = 0.01026572\n",
      "Iteration 2972, loss = 0.01026090\n",
      "Iteration 2973, loss = 0.01025589\n",
      "Iteration 2974, loss = 0.01025145\n",
      "Iteration 2975, loss = 0.01024654\n",
      "Iteration 2976, loss = 0.01024193\n",
      "Iteration 2977, loss = 0.01023654\n",
      "Iteration 2978, loss = 0.01023171\n",
      "Iteration 2979, loss = 0.01022678\n",
      "Iteration 2980, loss = 0.01022205\n",
      "Iteration 2981, loss = 0.01021880\n",
      "Iteration 2982, loss = 0.01021276\n",
      "Iteration 2983, loss = 0.01020830\n",
      "Iteration 2984, loss = 0.01020336\n",
      "Iteration 2985, loss = 0.01019854\n",
      "Iteration 2986, loss = 0.01019371\n",
      "Iteration 2987, loss = 0.01019082\n",
      "Iteration 2988, loss = 0.01018598\n",
      "Iteration 2989, loss = 0.01018200\n",
      "Iteration 2990, loss = 0.01017780\n",
      "Iteration 2991, loss = 0.01017307\n",
      "Iteration 2992, loss = 0.01016882\n",
      "Iteration 2993, loss = 0.01016453\n",
      "Iteration 2994, loss = 0.01015953\n",
      "Iteration 2995, loss = 0.01015474\n",
      "Iteration 2996, loss = 0.01015186\n",
      "Iteration 2997, loss = 0.01014662\n",
      "Iteration 2998, loss = 0.01014318\n",
      "Iteration 2999, loss = 0.01013762\n",
      "Iteration 3000, loss = 0.01013462\n",
      "Iteration 3001, loss = 0.01013001\n",
      "Iteration 3002, loss = 0.01012551\n",
      "Iteration 3003, loss = 0.01012078\n",
      "Iteration 3004, loss = 0.01011640\n",
      "Iteration 3005, loss = 0.01011215\n",
      "Iteration 3006, loss = 0.01010774\n",
      "Iteration 3007, loss = 0.01010449\n",
      "Iteration 3008, loss = 0.01009971\n",
      "Iteration 3009, loss = 0.01009567\n",
      "Iteration 3010, loss = 0.01009278\n",
      "Iteration 3011, loss = 0.01008771\n",
      "Iteration 3012, loss = 0.01008298\n",
      "Iteration 3013, loss = 0.01007830\n",
      "Iteration 3014, loss = 0.01007452\n",
      "Iteration 3015, loss = 0.01007013\n",
      "Iteration 3016, loss = 0.01006556\n",
      "Iteration 3017, loss = 0.01006101\n",
      "Iteration 3018, loss = 0.01005625\n",
      "Iteration 3019, loss = 0.01005109\n",
      "Iteration 3020, loss = 0.01004623\n",
      "Iteration 3021, loss = 0.01004353\n",
      "Iteration 3022, loss = 0.01003736\n",
      "Iteration 3023, loss = 0.01003280\n",
      "Iteration 3024, loss = 0.01002835\n",
      "Iteration 3025, loss = 0.01002428\n",
      "Iteration 3026, loss = 0.01002000\n",
      "Iteration 3027, loss = 0.01001619\n",
      "Iteration 3028, loss = 0.01001245\n",
      "Iteration 3029, loss = 0.01000773\n",
      "Iteration 3030, loss = 0.01000377\n",
      "Iteration 3031, loss = 0.00999918\n",
      "Iteration 3032, loss = 0.00999522\n",
      "Iteration 3033, loss = 0.00999165\n",
      "Iteration 3034, loss = 0.00998665\n",
      "Iteration 3035, loss = 0.00998250\n",
      "Iteration 3036, loss = 0.00997883\n",
      "Iteration 3037, loss = 0.00997433\n",
      "Iteration 3038, loss = 0.00997032\n",
      "Iteration 3039, loss = 0.00996559\n",
      "Iteration 3040, loss = 0.00996119\n",
      "Iteration 3041, loss = 0.00995709\n",
      "Iteration 3042, loss = 0.00995378\n",
      "Iteration 3043, loss = 0.00994916\n",
      "Iteration 3044, loss = 0.00994487\n",
      "Iteration 3045, loss = 0.00994204\n",
      "Iteration 3046, loss = 0.00993777\n",
      "Iteration 3047, loss = 0.00993385\n",
      "Iteration 3048, loss = 0.00992912\n",
      "Iteration 3049, loss = 0.00992543\n",
      "Iteration 3050, loss = 0.00991993\n",
      "Iteration 3051, loss = 0.00991468\n",
      "Iteration 3052, loss = 0.00990986\n",
      "Iteration 3053, loss = 0.00990508\n",
      "Iteration 3054, loss = 0.00989938\n",
      "Iteration 3055, loss = 0.00989654\n",
      "Iteration 3056, loss = 0.00989077\n",
      "Iteration 3057, loss = 0.00988789\n",
      "Iteration 3058, loss = 0.00988203\n",
      "Iteration 3059, loss = 0.00987745\n",
      "Iteration 3060, loss = 0.00987425\n",
      "Iteration 3061, loss = 0.00986931\n",
      "Iteration 3062, loss = 0.00986547\n",
      "Iteration 3063, loss = 0.00986121\n",
      "Iteration 3064, loss = 0.00985740\n",
      "Iteration 3065, loss = 0.00985312\n",
      "Iteration 3066, loss = 0.00984940\n",
      "Iteration 3067, loss = 0.00984464\n",
      "Iteration 3068, loss = 0.00984041\n",
      "Iteration 3069, loss = 0.00983740\n",
      "Iteration 3070, loss = 0.00983190\n",
      "Iteration 3071, loss = 0.00982787\n",
      "Iteration 3072, loss = 0.00982329\n",
      "Iteration 3073, loss = 0.00981834\n",
      "Iteration 3074, loss = 0.00981371\n",
      "Iteration 3075, loss = 0.00980893\n",
      "Iteration 3076, loss = 0.00980493\n",
      "Iteration 3077, loss = 0.00980047\n",
      "Iteration 3078, loss = 0.00979593\n",
      "Iteration 3079, loss = 0.00979190\n",
      "Iteration 3080, loss = 0.00978777\n",
      "Iteration 3081, loss = 0.00978338\n",
      "Iteration 3082, loss = 0.00977931\n",
      "Iteration 3083, loss = 0.00977523\n",
      "Iteration 3084, loss = 0.00977108\n",
      "Iteration 3085, loss = 0.00976685\n",
      "Iteration 3086, loss = 0.00976275\n",
      "Iteration 3087, loss = 0.00975836\n",
      "Iteration 3088, loss = 0.00975549\n",
      "Iteration 3089, loss = 0.00975151\n",
      "Iteration 3090, loss = 0.00974720\n",
      "Iteration 3091, loss = 0.00974318\n",
      "Iteration 3092, loss = 0.00973910\n",
      "Iteration 3093, loss = 0.00973538\n",
      "Iteration 3094, loss = 0.00973223\n",
      "Iteration 3095, loss = 0.00972743\n",
      "Iteration 3096, loss = 0.00972424\n",
      "Iteration 3097, loss = 0.00971929\n",
      "Iteration 3098, loss = 0.00971518\n",
      "Iteration 3099, loss = 0.00971092\n",
      "Iteration 3100, loss = 0.00970569\n",
      "Iteration 3101, loss = 0.00970155\n",
      "Iteration 3102, loss = 0.00969738\n",
      "Iteration 3103, loss = 0.00969377\n",
      "Iteration 3104, loss = 0.00968955\n",
      "Iteration 3105, loss = 0.00968513\n",
      "Iteration 3106, loss = 0.00968111\n",
      "Iteration 3107, loss = 0.00967691\n",
      "Iteration 3108, loss = 0.00967300\n",
      "Iteration 3109, loss = 0.00966870\n",
      "Iteration 3110, loss = 0.00966445\n",
      "Iteration 3111, loss = 0.00966069\n",
      "Iteration 3112, loss = 0.00965622\n",
      "Iteration 3113, loss = 0.00965233\n",
      "Iteration 3114, loss = 0.00964903\n",
      "Iteration 3115, loss = 0.00964436\n",
      "Iteration 3116, loss = 0.00964069\n",
      "Iteration 3117, loss = 0.00963662\n",
      "Iteration 3118, loss = 0.00963198\n",
      "Iteration 3119, loss = 0.00962814\n",
      "Iteration 3120, loss = 0.00962441\n",
      "Iteration 3121, loss = 0.00962066\n",
      "Iteration 3122, loss = 0.00961683\n",
      "Iteration 3123, loss = 0.00961294\n",
      "Iteration 3124, loss = 0.00960927\n",
      "Iteration 3125, loss = 0.00960484\n",
      "Iteration 3126, loss = 0.00960116\n",
      "Iteration 3127, loss = 0.00959729\n",
      "Iteration 3128, loss = 0.00959415\n",
      "Iteration 3129, loss = 0.00959003\n",
      "Iteration 3130, loss = 0.00958596\n",
      "Iteration 3131, loss = 0.00958208\n",
      "Iteration 3132, loss = 0.00957740\n",
      "Iteration 3133, loss = 0.00957376\n",
      "Iteration 3134, loss = 0.00956873\n",
      "Iteration 3135, loss = 0.00956568\n",
      "Iteration 3136, loss = 0.00956050\n",
      "Iteration 3137, loss = 0.00955677\n",
      "Iteration 3138, loss = 0.00955286\n",
      "Iteration 3139, loss = 0.00954892\n",
      "Iteration 3140, loss = 0.00954522\n",
      "Iteration 3141, loss = 0.00954183\n",
      "Iteration 3142, loss = 0.00953806\n",
      "Iteration 3143, loss = 0.00953437\n",
      "Iteration 3144, loss = 0.00953180\n",
      "Iteration 3145, loss = 0.00952806\n",
      "Iteration 3146, loss = 0.00952533\n",
      "Iteration 3147, loss = 0.00952127\n",
      "Iteration 3148, loss = 0.00951752\n",
      "Iteration 3149, loss = 0.00951326\n",
      "Iteration 3150, loss = 0.00950982\n",
      "Iteration 3151, loss = 0.00950619\n",
      "Iteration 3152, loss = 0.00950290\n",
      "Iteration 3153, loss = 0.00949926\n",
      "Iteration 3154, loss = 0.00949635\n",
      "Iteration 3155, loss = 0.00949273\n",
      "Iteration 3156, loss = 0.00948889\n",
      "Iteration 3157, loss = 0.00948432\n",
      "Iteration 3158, loss = 0.00947912\n",
      "Iteration 3159, loss = 0.00947524\n",
      "Iteration 3160, loss = 0.00947034\n",
      "Iteration 3161, loss = 0.00946599\n",
      "Iteration 3162, loss = 0.00946156\n",
      "Iteration 3163, loss = 0.00945738\n",
      "Iteration 3164, loss = 0.00945309\n",
      "Iteration 3165, loss = 0.00944905\n",
      "Iteration 3166, loss = 0.00944484\n",
      "Iteration 3167, loss = 0.00944080\n",
      "Iteration 3168, loss = 0.00943553\n",
      "Iteration 3169, loss = 0.00943120\n",
      "Iteration 3170, loss = 0.00942661\n",
      "Iteration 3171, loss = 0.00942292\n",
      "Iteration 3172, loss = 0.00941795\n",
      "Iteration 3173, loss = 0.00941397\n",
      "Iteration 3174, loss = 0.00941024\n",
      "Iteration 3175, loss = 0.00940597\n",
      "Iteration 3176, loss = 0.00940251\n",
      "Iteration 3177, loss = 0.00939846\n",
      "Iteration 3178, loss = 0.00939516\n",
      "Iteration 3179, loss = 0.00939146\n",
      "Iteration 3180, loss = 0.00938855\n",
      "Iteration 3181, loss = 0.00938403\n",
      "Iteration 3182, loss = 0.00938022\n",
      "Iteration 3183, loss = 0.00937587\n",
      "Iteration 3184, loss = 0.00937295\n",
      "Iteration 3185, loss = 0.00936831\n",
      "Iteration 3186, loss = 0.00936422\n",
      "Iteration 3187, loss = 0.00935986\n",
      "Iteration 3188, loss = 0.00935648\n",
      "Iteration 3189, loss = 0.00935230\n",
      "Iteration 3190, loss = 0.00934849\n",
      "Iteration 3191, loss = 0.00934475\n",
      "Iteration 3192, loss = 0.00934066\n",
      "Iteration 3193, loss = 0.00933629\n",
      "Iteration 3194, loss = 0.00933227\n",
      "Iteration 3195, loss = 0.00932828\n",
      "Iteration 3196, loss = 0.00932388\n",
      "Iteration 3197, loss = 0.00932081\n",
      "Iteration 3198, loss = 0.00931645\n",
      "Iteration 3199, loss = 0.00931272\n",
      "Iteration 3200, loss = 0.00930934\n",
      "Iteration 3201, loss = 0.00930545\n",
      "Iteration 3202, loss = 0.00930150\n",
      "Iteration 3203, loss = 0.00929829\n",
      "Iteration 3204, loss = 0.00929567\n",
      "Iteration 3205, loss = 0.00929134\n",
      "Iteration 3206, loss = 0.00928705\n",
      "Iteration 3207, loss = 0.00928283\n",
      "Iteration 3208, loss = 0.00927858\n",
      "Iteration 3209, loss = 0.00927440\n",
      "Iteration 3210, loss = 0.00926968\n",
      "Iteration 3211, loss = 0.00926633\n",
      "Iteration 3212, loss = 0.00926136\n",
      "Iteration 3213, loss = 0.00925806\n",
      "Iteration 3214, loss = 0.00925330\n",
      "Iteration 3215, loss = 0.00924933\n",
      "Iteration 3216, loss = 0.00924514\n",
      "Iteration 3217, loss = 0.00924176\n",
      "Iteration 3218, loss = 0.00923770\n",
      "Iteration 3219, loss = 0.00923338\n",
      "Iteration 3220, loss = 0.00922962\n",
      "Iteration 3221, loss = 0.00922617\n",
      "Iteration 3222, loss = 0.00922265\n",
      "Iteration 3223, loss = 0.00921927\n",
      "Iteration 3224, loss = 0.00921625\n",
      "Iteration 3225, loss = 0.00921238\n",
      "Iteration 3226, loss = 0.00920889\n",
      "Iteration 3227, loss = 0.00920563\n",
      "Iteration 3228, loss = 0.00920182\n",
      "Iteration 3229, loss = 0.00919908\n",
      "Iteration 3230, loss = 0.00919537\n",
      "Iteration 3231, loss = 0.00919175\n",
      "Iteration 3232, loss = 0.00918813\n",
      "Iteration 3233, loss = 0.00918543\n",
      "Iteration 3234, loss = 0.00918089\n",
      "Iteration 3235, loss = 0.00917758\n",
      "Iteration 3236, loss = 0.00917354\n",
      "Iteration 3237, loss = 0.00916995\n",
      "Iteration 3238, loss = 0.00916679\n",
      "Iteration 3239, loss = 0.00916340\n",
      "Iteration 3240, loss = 0.00916029\n",
      "Iteration 3241, loss = 0.00915699\n",
      "Iteration 3242, loss = 0.00915408\n",
      "Iteration 3243, loss = 0.00915127\n",
      "Iteration 3244, loss = 0.00914787\n",
      "Iteration 3245, loss = 0.00914360\n",
      "Iteration 3246, loss = 0.00913996\n",
      "Iteration 3247, loss = 0.00913578\n",
      "Iteration 3248, loss = 0.00913245\n",
      "Iteration 3249, loss = 0.00912819\n",
      "Iteration 3250, loss = 0.00912395\n",
      "Iteration 3251, loss = 0.00912071\n",
      "Iteration 3252, loss = 0.00911508\n",
      "Iteration 3253, loss = 0.00911055\n",
      "Iteration 3254, loss = 0.00910683\n",
      "Iteration 3255, loss = 0.00910159\n",
      "Iteration 3256, loss = 0.00909795\n",
      "Iteration 3257, loss = 0.00909489\n",
      "Iteration 3258, loss = 0.00908953\n",
      "Iteration 3259, loss = 0.00908618\n",
      "Iteration 3260, loss = 0.00908206\n",
      "Iteration 3261, loss = 0.00907875\n",
      "Iteration 3262, loss = 0.00907461\n",
      "Iteration 3263, loss = 0.00907120\n",
      "Iteration 3264, loss = 0.00906737\n",
      "Iteration 3265, loss = 0.00906385\n",
      "Iteration 3266, loss = 0.00906010\n",
      "Iteration 3267, loss = 0.00905695\n",
      "Iteration 3268, loss = 0.00905309\n",
      "Iteration 3269, loss = 0.00904946\n",
      "Iteration 3270, loss = 0.00904598\n",
      "Iteration 3271, loss = 0.00904293\n",
      "Iteration 3272, loss = 0.00903936\n",
      "Iteration 3273, loss = 0.00903634\n",
      "Iteration 3274, loss = 0.00903286\n",
      "Iteration 3275, loss = 0.00902908\n",
      "Iteration 3276, loss = 0.00902570\n",
      "Iteration 3277, loss = 0.00902237\n",
      "Iteration 3278, loss = 0.00901926\n",
      "Iteration 3279, loss = 0.00901561\n",
      "Iteration 3280, loss = 0.00901213\n",
      "Iteration 3281, loss = 0.00900894\n",
      "Iteration 3282, loss = 0.00900498\n",
      "Iteration 3283, loss = 0.00900108\n",
      "Iteration 3284, loss = 0.00899778\n",
      "Iteration 3285, loss = 0.00899315\n",
      "Iteration 3286, loss = 0.00899115\n",
      "Iteration 3287, loss = 0.00898579\n",
      "Iteration 3288, loss = 0.00898208\n",
      "Iteration 3289, loss = 0.00897895\n",
      "Iteration 3290, loss = 0.00897475\n",
      "Iteration 3291, loss = 0.00897166\n",
      "Iteration 3292, loss = 0.00896820\n",
      "Iteration 3293, loss = 0.00896337\n",
      "Iteration 3294, loss = 0.00896062\n",
      "Iteration 3295, loss = 0.00895612\n",
      "Iteration 3296, loss = 0.00895272\n",
      "Iteration 3297, loss = 0.00894897\n",
      "Iteration 3298, loss = 0.00894485\n",
      "Iteration 3299, loss = 0.00894180\n",
      "Iteration 3300, loss = 0.00893777\n",
      "Iteration 3301, loss = 0.00893240\n",
      "Iteration 3302, loss = 0.00892877\n",
      "Iteration 3303, loss = 0.00892437\n",
      "Iteration 3304, loss = 0.00892144\n",
      "Iteration 3305, loss = 0.00891636\n",
      "Iteration 3306, loss = 0.00891196\n",
      "Iteration 3307, loss = 0.00890843\n",
      "Iteration 3308, loss = 0.00890419\n",
      "Iteration 3309, loss = 0.00890066\n",
      "Iteration 3310, loss = 0.00889731\n",
      "Iteration 3311, loss = 0.00889315\n",
      "Iteration 3312, loss = 0.00888998\n",
      "Iteration 3313, loss = 0.00888585\n",
      "Iteration 3314, loss = 0.00888237\n",
      "Iteration 3315, loss = 0.00887851\n",
      "Iteration 3316, loss = 0.00887505\n",
      "Iteration 3317, loss = 0.00887107\n",
      "Iteration 3318, loss = 0.00886761\n",
      "Iteration 3319, loss = 0.00886387\n",
      "Iteration 3320, loss = 0.00886051\n",
      "Iteration 3321, loss = 0.00885744\n",
      "Iteration 3322, loss = 0.00885526\n",
      "Iteration 3323, loss = 0.00885115\n",
      "Iteration 3324, loss = 0.00884756\n",
      "Iteration 3325, loss = 0.00884439\n",
      "Iteration 3326, loss = 0.00884062\n",
      "Iteration 3327, loss = 0.00883735\n",
      "Iteration 3328, loss = 0.00883424\n",
      "Iteration 3329, loss = 0.00883071\n",
      "Iteration 3330, loss = 0.00882694\n",
      "Iteration 3331, loss = 0.00882346\n",
      "Iteration 3332, loss = 0.00881992\n",
      "Iteration 3333, loss = 0.00881674\n",
      "Iteration 3334, loss = 0.00881294\n",
      "Iteration 3335, loss = 0.00880938\n",
      "Iteration 3336, loss = 0.00880554\n",
      "Iteration 3337, loss = 0.00880189\n",
      "Iteration 3338, loss = 0.00879828\n",
      "Iteration 3339, loss = 0.00879476\n",
      "Iteration 3340, loss = 0.00879137\n",
      "Iteration 3341, loss = 0.00878835\n",
      "Iteration 3342, loss = 0.00878448\n",
      "Iteration 3343, loss = 0.00878123\n",
      "Iteration 3344, loss = 0.00877842\n",
      "Iteration 3345, loss = 0.00877499\n",
      "Iteration 3346, loss = 0.00877132\n",
      "Iteration 3347, loss = 0.00876832\n",
      "Iteration 3348, loss = 0.00876451\n",
      "Iteration 3349, loss = 0.00876104\n",
      "Iteration 3350, loss = 0.00875800\n",
      "Iteration 3351, loss = 0.00875483\n",
      "Iteration 3352, loss = 0.00875096\n",
      "Iteration 3353, loss = 0.00874762\n",
      "Iteration 3354, loss = 0.00874475\n",
      "Iteration 3355, loss = 0.00874074\n",
      "Iteration 3356, loss = 0.00873692\n",
      "Iteration 3357, loss = 0.00873385\n",
      "Iteration 3358, loss = 0.00872992\n",
      "Iteration 3359, loss = 0.00872642\n",
      "Iteration 3360, loss = 0.00872336\n",
      "Iteration 3361, loss = 0.00871983\n",
      "Iteration 3362, loss = 0.00871701\n",
      "Iteration 3363, loss = 0.00871207\n",
      "Iteration 3364, loss = 0.00870807\n",
      "Iteration 3365, loss = 0.00870397\n",
      "Iteration 3366, loss = 0.00870123\n",
      "Iteration 3367, loss = 0.00869816\n",
      "Iteration 3368, loss = 0.00869334\n",
      "Iteration 3369, loss = 0.00868981\n",
      "Iteration 3370, loss = 0.00868659\n",
      "Iteration 3371, loss = 0.00868307\n",
      "Iteration 3372, loss = 0.00867957\n",
      "Iteration 3373, loss = 0.00867683\n",
      "Iteration 3374, loss = 0.00867282\n",
      "Iteration 3375, loss = 0.00866950\n",
      "Iteration 3376, loss = 0.00866527\n",
      "Iteration 3377, loss = 0.00866142\n",
      "Iteration 3378, loss = 0.00865784\n",
      "Iteration 3379, loss = 0.00865442\n",
      "Iteration 3380, loss = 0.00864999\n",
      "Iteration 3381, loss = 0.00864640\n",
      "Iteration 3382, loss = 0.00864292\n",
      "Iteration 3383, loss = 0.00863884\n",
      "Iteration 3384, loss = 0.00863469\n",
      "Iteration 3385, loss = 0.00863186\n",
      "Iteration 3386, loss = 0.00862799\n",
      "Iteration 3387, loss = 0.00862413\n",
      "Iteration 3388, loss = 0.00862074\n",
      "Iteration 3389, loss = 0.00861674\n",
      "Iteration 3390, loss = 0.00861353\n",
      "Iteration 3391, loss = 0.00860985\n",
      "Iteration 3392, loss = 0.00860678\n",
      "Iteration 3393, loss = 0.00860339\n",
      "Iteration 3394, loss = 0.00859928\n",
      "Iteration 3395, loss = 0.00859578\n",
      "Iteration 3396, loss = 0.00859307\n",
      "Iteration 3397, loss = 0.00858909\n",
      "Iteration 3398, loss = 0.00858600\n",
      "Iteration 3399, loss = 0.00858218\n",
      "Iteration 3400, loss = 0.00857955\n",
      "Iteration 3401, loss = 0.00857551\n",
      "Iteration 3402, loss = 0.00857242\n",
      "Iteration 3403, loss = 0.00856846\n",
      "Iteration 3404, loss = 0.00856483\n",
      "Iteration 3405, loss = 0.00856167\n",
      "Iteration 3406, loss = 0.00855850\n",
      "Iteration 3407, loss = 0.00855513\n",
      "Iteration 3408, loss = 0.00855143\n",
      "Iteration 3409, loss = 0.00854814\n",
      "Iteration 3410, loss = 0.00854548\n",
      "Iteration 3411, loss = 0.00854168\n",
      "Iteration 3412, loss = 0.00853830\n",
      "Iteration 3413, loss = 0.00853519\n",
      "Iteration 3414, loss = 0.00853194\n",
      "Iteration 3415, loss = 0.00852880\n",
      "Iteration 3416, loss = 0.00852594\n",
      "Iteration 3417, loss = 0.00852249\n",
      "Iteration 3418, loss = 0.00851929\n",
      "Iteration 3419, loss = 0.00851597\n",
      "Iteration 3420, loss = 0.00851284\n",
      "Iteration 3421, loss = 0.00850983\n",
      "Iteration 3422, loss = 0.00850685\n",
      "Iteration 3423, loss = 0.00850355\n",
      "Iteration 3424, loss = 0.00850027\n",
      "Iteration 3425, loss = 0.00849747\n",
      "Iteration 3426, loss = 0.00849427\n",
      "Iteration 3427, loss = 0.00849150\n",
      "Iteration 3428, loss = 0.00848724\n",
      "Iteration 3429, loss = 0.00848467\n",
      "Iteration 3430, loss = 0.00848061\n",
      "Iteration 3431, loss = 0.00847734\n",
      "Iteration 3432, loss = 0.00847451\n",
      "Iteration 3433, loss = 0.00847168\n",
      "Iteration 3434, loss = 0.00846751\n",
      "Iteration 3435, loss = 0.00846410\n",
      "Iteration 3436, loss = 0.00846072\n",
      "Iteration 3437, loss = 0.00845809\n",
      "Iteration 3438, loss = 0.00845428\n",
      "Iteration 3439, loss = 0.00845113\n",
      "Iteration 3440, loss = 0.00844793\n",
      "Iteration 3441, loss = 0.00844486\n",
      "Iteration 3442, loss = 0.00844190\n",
      "Iteration 3443, loss = 0.00843889\n",
      "Iteration 3444, loss = 0.00843599\n",
      "Iteration 3445, loss = 0.00843228\n",
      "Iteration 3446, loss = 0.00842912\n",
      "Iteration 3447, loss = 0.00842589\n",
      "Iteration 3448, loss = 0.00842286\n",
      "Iteration 3449, loss = 0.00841970\n",
      "Iteration 3450, loss = 0.00841647\n",
      "Iteration 3451, loss = 0.00841537\n",
      "Iteration 3452, loss = 0.00841021\n",
      "Iteration 3453, loss = 0.00840674\n",
      "Iteration 3454, loss = 0.00840400\n",
      "Iteration 3455, loss = 0.00840033\n",
      "Iteration 3456, loss = 0.00839738\n",
      "Iteration 3457, loss = 0.00839360\n",
      "Iteration 3458, loss = 0.00839036\n",
      "Iteration 3459, loss = 0.00838696\n",
      "Iteration 3460, loss = 0.00838378\n",
      "Iteration 3461, loss = 0.00838069\n",
      "Iteration 3462, loss = 0.00837773\n",
      "Iteration 3463, loss = 0.00837461\n",
      "Iteration 3464, loss = 0.00837121\n",
      "Iteration 3465, loss = 0.00836843\n",
      "Iteration 3466, loss = 0.00836529\n",
      "Iteration 3467, loss = 0.00836215\n",
      "Iteration 3468, loss = 0.00835925\n",
      "Iteration 3469, loss = 0.00835608\n",
      "Iteration 3470, loss = 0.00835466\n",
      "Iteration 3471, loss = 0.00835040\n",
      "Iteration 3472, loss = 0.00834753\n",
      "Iteration 3473, loss = 0.00834344\n",
      "Iteration 3474, loss = 0.00833999\n",
      "Iteration 3475, loss = 0.00833635\n",
      "Iteration 3476, loss = 0.00833292\n",
      "Iteration 3477, loss = 0.00832954\n",
      "Iteration 3478, loss = 0.00832630\n",
      "Iteration 3479, loss = 0.00832219\n",
      "Iteration 3480, loss = 0.00831918\n",
      "Iteration 3481, loss = 0.00831557\n",
      "Iteration 3482, loss = 0.00831279\n",
      "Iteration 3483, loss = 0.00830944\n",
      "Iteration 3484, loss = 0.00830659\n",
      "Iteration 3485, loss = 0.00830341\n",
      "Iteration 3486, loss = 0.00830048\n",
      "Iteration 3487, loss = 0.00829757\n",
      "Iteration 3488, loss = 0.00829409\n",
      "Iteration 3489, loss = 0.00829188\n",
      "Iteration 3490, loss = 0.00828800\n",
      "Iteration 3491, loss = 0.00828455\n",
      "Iteration 3492, loss = 0.00828176\n",
      "Iteration 3493, loss = 0.00827803\n",
      "Iteration 3494, loss = 0.00827535\n",
      "Iteration 3495, loss = 0.00827216\n",
      "Iteration 3496, loss = 0.00826897\n",
      "Iteration 3497, loss = 0.00826606\n",
      "Iteration 3498, loss = 0.00826261\n",
      "Iteration 3499, loss = 0.00826010\n",
      "Iteration 3500, loss = 0.00825718\n",
      "Iteration 3501, loss = 0.00825338\n",
      "Iteration 3502, loss = 0.00825041\n",
      "Iteration 3503, loss = 0.00824711\n",
      "Iteration 3504, loss = 0.00824418\n",
      "Iteration 3505, loss = 0.00824087\n",
      "Iteration 3506, loss = 0.00823750\n",
      "Iteration 3507, loss = 0.00823646\n",
      "Iteration 3508, loss = 0.00823218\n",
      "Iteration 3509, loss = 0.00822913\n",
      "Iteration 3510, loss = 0.00822586\n",
      "Iteration 3511, loss = 0.00822242\n",
      "Iteration 3512, loss = 0.00822010\n",
      "Iteration 3513, loss = 0.00821674\n",
      "Iteration 3514, loss = 0.00821483\n",
      "Iteration 3515, loss = 0.00821097\n",
      "Iteration 3516, loss = 0.00820790\n",
      "Iteration 3517, loss = 0.00820589\n",
      "Iteration 3518, loss = 0.00820207\n",
      "Iteration 3519, loss = 0.00819914\n",
      "Iteration 3520, loss = 0.00819602\n",
      "Iteration 3521, loss = 0.00819282\n",
      "Iteration 3522, loss = 0.00818963\n",
      "Iteration 3523, loss = 0.00818665\n",
      "Iteration 3524, loss = 0.00818312\n",
      "Iteration 3525, loss = 0.00818024\n",
      "Iteration 3526, loss = 0.00817812\n",
      "Iteration 3527, loss = 0.00817362\n",
      "Iteration 3528, loss = 0.00817061\n",
      "Iteration 3529, loss = 0.00816688\n",
      "Iteration 3530, loss = 0.00816427\n",
      "Iteration 3531, loss = 0.00816097\n",
      "Iteration 3532, loss = 0.00815659\n",
      "Iteration 3533, loss = 0.00815360\n",
      "Iteration 3534, loss = 0.00814953\n",
      "Iteration 3535, loss = 0.00814674\n",
      "Iteration 3536, loss = 0.00814298\n",
      "Iteration 3537, loss = 0.00813930\n",
      "Iteration 3538, loss = 0.00813654\n",
      "Iteration 3539, loss = 0.00813430\n",
      "Iteration 3540, loss = 0.00813037\n",
      "Iteration 3541, loss = 0.00812697\n",
      "Iteration 3542, loss = 0.00812400\n",
      "Iteration 3543, loss = 0.00812129\n",
      "Iteration 3544, loss = 0.00811815\n",
      "Iteration 3545, loss = 0.00811507\n",
      "Iteration 3546, loss = 0.00811242\n",
      "Iteration 3547, loss = 0.00810957\n",
      "Iteration 3548, loss = 0.00810650\n",
      "Iteration 3549, loss = 0.00810363\n",
      "Iteration 3550, loss = 0.00810019\n",
      "Iteration 3551, loss = 0.00809715\n",
      "Iteration 3552, loss = 0.00809379\n",
      "Iteration 3553, loss = 0.00809062\n",
      "Iteration 3554, loss = 0.00808784\n",
      "Iteration 3555, loss = 0.00808443\n",
      "Iteration 3556, loss = 0.00808177\n",
      "Iteration 3557, loss = 0.00807834\n",
      "Iteration 3558, loss = 0.00807476\n",
      "Iteration 3559, loss = 0.00807209\n",
      "Iteration 3560, loss = 0.00806917\n",
      "Iteration 3561, loss = 0.00806623\n",
      "Iteration 3562, loss = 0.00806305\n",
      "Iteration 3563, loss = 0.00805991\n",
      "Iteration 3564, loss = 0.00805752\n",
      "Iteration 3565, loss = 0.00805443\n",
      "Iteration 3566, loss = 0.00805140\n",
      "Iteration 3567, loss = 0.00804867\n",
      "Iteration 3568, loss = 0.00804620\n",
      "Iteration 3569, loss = 0.00804418\n",
      "Iteration 3570, loss = 0.00803937\n",
      "Iteration 3571, loss = 0.00803662\n",
      "Iteration 3572, loss = 0.00803283\n",
      "Iteration 3573, loss = 0.00802941\n",
      "Iteration 3574, loss = 0.00802689\n",
      "Iteration 3575, loss = 0.00802292\n",
      "Iteration 3576, loss = 0.00801923\n",
      "Iteration 3577, loss = 0.00801570\n",
      "Iteration 3578, loss = 0.00801285\n",
      "Iteration 3579, loss = 0.00800949\n",
      "Iteration 3580, loss = 0.00800695\n",
      "Iteration 3581, loss = 0.00800366\n",
      "Iteration 3582, loss = 0.00800048\n",
      "Iteration 3583, loss = 0.00799758\n",
      "Iteration 3584, loss = 0.00799411\n",
      "Iteration 3585, loss = 0.00799132\n",
      "Iteration 3586, loss = 0.00798798\n",
      "Iteration 3587, loss = 0.00798508\n",
      "Iteration 3588, loss = 0.00798243\n",
      "Iteration 3589, loss = 0.00797961\n",
      "Iteration 3590, loss = 0.00797660\n",
      "Iteration 3591, loss = 0.00797401\n",
      "Iteration 3592, loss = 0.00797097\n",
      "Iteration 3593, loss = 0.00796823\n",
      "Iteration 3594, loss = 0.00796550\n",
      "Iteration 3595, loss = 0.00796162\n",
      "Iteration 3596, loss = 0.00795901\n",
      "Iteration 3597, loss = 0.00795637\n",
      "Iteration 3598, loss = 0.00795295\n",
      "Iteration 3599, loss = 0.00794977\n",
      "Iteration 3600, loss = 0.00794701\n",
      "Iteration 3601, loss = 0.00794397\n",
      "Iteration 3602, loss = 0.00794124\n",
      "Iteration 3603, loss = 0.00793803\n",
      "Iteration 3604, loss = 0.00793538\n",
      "Iteration 3605, loss = 0.00793279\n",
      "Iteration 3606, loss = 0.00792992\n",
      "Iteration 3607, loss = 0.00792656\n",
      "Iteration 3608, loss = 0.00792405\n",
      "Iteration 3609, loss = 0.00792074\n",
      "Iteration 3610, loss = 0.00791801\n",
      "Iteration 3611, loss = 0.00791563\n",
      "Iteration 3612, loss = 0.00791313\n",
      "Iteration 3613, loss = 0.00791043\n",
      "Iteration 3614, loss = 0.00790803\n",
      "Iteration 3615, loss = 0.00790632\n",
      "Iteration 3616, loss = 0.00790373\n",
      "Iteration 3617, loss = 0.00790164\n",
      "Iteration 3618, loss = 0.00789974\n",
      "Iteration 3619, loss = 0.00789700\n",
      "Iteration 3620, loss = 0.00789420\n",
      "Iteration 3621, loss = 0.00789180\n",
      "Iteration 3622, loss = 0.00788876\n",
      "Iteration 3623, loss = 0.00788578\n",
      "Iteration 3624, loss = 0.00788311\n",
      "Iteration 3625, loss = 0.00788047\n",
      "Iteration 3626, loss = 0.00787725\n",
      "Iteration 3627, loss = 0.00787512\n",
      "Iteration 3628, loss = 0.00787197\n",
      "Iteration 3629, loss = 0.00786945\n",
      "Iteration 3630, loss = 0.00786641\n",
      "Iteration 3631, loss = 0.00786345\n",
      "Iteration 3632, loss = 0.00786083\n",
      "Iteration 3633, loss = 0.00785819\n",
      "Iteration 3634, loss = 0.00785533\n",
      "Iteration 3635, loss = 0.00785283\n",
      "Iteration 3636, loss = 0.00785101\n",
      "Iteration 3637, loss = 0.00784791\n",
      "Iteration 3638, loss = 0.00784491\n",
      "Iteration 3639, loss = 0.00784378\n",
      "Iteration 3640, loss = 0.00783980\n",
      "Iteration 3641, loss = 0.00783610\n",
      "Iteration 3642, loss = 0.00783229\n",
      "Iteration 3643, loss = 0.00782902\n",
      "Iteration 3644, loss = 0.00782591\n",
      "Iteration 3645, loss = 0.00782289\n",
      "Iteration 3646, loss = 0.00782022\n",
      "Iteration 3647, loss = 0.00781616\n",
      "Iteration 3648, loss = 0.00781352\n",
      "Iteration 3649, loss = 0.00781065\n",
      "Iteration 3650, loss = 0.00780713\n",
      "Iteration 3651, loss = 0.00780471\n",
      "Iteration 3652, loss = 0.00780099\n",
      "Iteration 3653, loss = 0.00779767\n",
      "Iteration 3654, loss = 0.00779470\n",
      "Iteration 3655, loss = 0.00779170\n",
      "Iteration 3656, loss = 0.00778878\n",
      "Iteration 3657, loss = 0.00778620\n",
      "Iteration 3658, loss = 0.00778314\n",
      "Iteration 3659, loss = 0.00778017\n",
      "Iteration 3660, loss = 0.00777750\n",
      "Iteration 3661, loss = 0.00777418\n",
      "Iteration 3662, loss = 0.00777027\n",
      "Iteration 3663, loss = 0.00776823\n",
      "Iteration 3664, loss = 0.00776501\n",
      "Iteration 3665, loss = 0.00776148\n",
      "Iteration 3666, loss = 0.00775869\n",
      "Iteration 3667, loss = 0.00775548\n",
      "Iteration 3668, loss = 0.00775259\n",
      "Iteration 3669, loss = 0.00774991\n",
      "Iteration 3670, loss = 0.00774721\n",
      "Iteration 3671, loss = 0.00774441\n",
      "Iteration 3672, loss = 0.00774169\n",
      "Iteration 3673, loss = 0.00773958\n",
      "Iteration 3674, loss = 0.00773684\n",
      "Iteration 3675, loss = 0.00773397\n",
      "Iteration 3676, loss = 0.00773115\n",
      "Iteration 3677, loss = 0.00772804\n",
      "Iteration 3678, loss = 0.00772587\n",
      "Iteration 3679, loss = 0.00772288\n",
      "Iteration 3680, loss = 0.00772093\n",
      "Iteration 3681, loss = 0.00771823\n",
      "Iteration 3682, loss = 0.00771602\n",
      "Iteration 3683, loss = 0.00771498\n",
      "Iteration 3684, loss = 0.00771108\n",
      "Iteration 3685, loss = 0.00770800\n",
      "Iteration 3686, loss = 0.00770517\n",
      "Iteration 3687, loss = 0.00770261\n",
      "Iteration 3688, loss = 0.00769957\n",
      "Iteration 3689, loss = 0.00769731\n",
      "Iteration 3690, loss = 0.00769445\n",
      "Iteration 3691, loss = 0.00769181\n",
      "Iteration 3692, loss = 0.00768908\n",
      "Iteration 3693, loss = 0.00768689\n",
      "Iteration 3694, loss = 0.00768468\n",
      "Iteration 3695, loss = 0.00768220\n",
      "Iteration 3696, loss = 0.00767961\n",
      "Iteration 3697, loss = 0.00767734\n",
      "Iteration 3698, loss = 0.00767501\n",
      "Iteration 3699, loss = 0.00767182\n",
      "Iteration 3700, loss = 0.00766883\n",
      "Iteration 3701, loss = 0.00766685\n",
      "Iteration 3702, loss = 0.00766302\n",
      "Iteration 3703, loss = 0.00766016\n",
      "Iteration 3704, loss = 0.00765710\n",
      "Iteration 3705, loss = 0.00765396\n",
      "Iteration 3706, loss = 0.00765105\n",
      "Iteration 3707, loss = 0.00764792\n",
      "Iteration 3708, loss = 0.00764566\n",
      "Iteration 3709, loss = 0.00764275\n",
      "Iteration 3710, loss = 0.00764020\n",
      "Iteration 3711, loss = 0.00763736\n",
      "Iteration 3712, loss = 0.00763462\n",
      "Iteration 3713, loss = 0.00763218\n",
      "Iteration 3714, loss = 0.00763009\n",
      "Iteration 3715, loss = 0.00762727\n",
      "Iteration 3716, loss = 0.00762520\n",
      "Iteration 3717, loss = 0.00762292\n",
      "Iteration 3718, loss = 0.00762057\n",
      "Iteration 3719, loss = 0.00761748\n",
      "Iteration 3720, loss = 0.00761445\n",
      "Iteration 3721, loss = 0.00761108\n",
      "Iteration 3722, loss = 0.00760978\n",
      "Iteration 3723, loss = 0.00760671\n",
      "Iteration 3724, loss = 0.00760313\n",
      "Iteration 3725, loss = 0.00760119\n",
      "Iteration 3726, loss = 0.00759806\n",
      "Iteration 3727, loss = 0.00759565\n",
      "Iteration 3728, loss = 0.00759336\n",
      "Iteration 3729, loss = 0.00759169\n",
      "Iteration 3730, loss = 0.00758801\n",
      "Iteration 3731, loss = 0.00758494\n",
      "Iteration 3732, loss = 0.00758176\n",
      "Iteration 3733, loss = 0.00757904\n",
      "Iteration 3734, loss = 0.00757612\n",
      "Iteration 3735, loss = 0.00757279\n",
      "Iteration 3736, loss = 0.00757034\n",
      "Iteration 3737, loss = 0.00756768\n",
      "Iteration 3738, loss = 0.00756414\n",
      "Iteration 3739, loss = 0.00756055\n",
      "Iteration 3740, loss = 0.00755763\n",
      "Iteration 3741, loss = 0.00755529\n",
      "Iteration 3742, loss = 0.00755152\n",
      "Iteration 3743, loss = 0.00754889\n",
      "Iteration 3744, loss = 0.00754640\n",
      "Iteration 3745, loss = 0.00754257\n",
      "Iteration 3746, loss = 0.00754025\n",
      "Iteration 3747, loss = 0.00753737\n",
      "Iteration 3748, loss = 0.00753472\n",
      "Iteration 3749, loss = 0.00753226\n",
      "Iteration 3750, loss = 0.00752980\n",
      "Iteration 3751, loss = 0.00752792\n",
      "Iteration 3752, loss = 0.00752504\n",
      "Iteration 3753, loss = 0.00752351\n",
      "Iteration 3754, loss = 0.00752004\n",
      "Iteration 3755, loss = 0.00751723\n",
      "Iteration 3756, loss = 0.00751505\n",
      "Iteration 3757, loss = 0.00751198\n",
      "Iteration 3758, loss = 0.00750967\n",
      "Iteration 3759, loss = 0.00750669\n",
      "Iteration 3760, loss = 0.00750346\n",
      "Iteration 3761, loss = 0.00750043\n",
      "Iteration 3762, loss = 0.00749719\n",
      "Iteration 3763, loss = 0.00749478\n",
      "Iteration 3764, loss = 0.00749137\n",
      "Iteration 3765, loss = 0.00748881\n",
      "Iteration 3766, loss = 0.00748577\n",
      "Iteration 3767, loss = 0.00748310\n",
      "Iteration 3768, loss = 0.00748025\n",
      "Iteration 3769, loss = 0.00747746\n",
      "Iteration 3770, loss = 0.00747477\n",
      "Iteration 3771, loss = 0.00747236\n",
      "Iteration 3772, loss = 0.00747031\n",
      "Iteration 3773, loss = 0.00746722\n",
      "Iteration 3774, loss = 0.00746407\n",
      "Iteration 3775, loss = 0.00746161\n",
      "Iteration 3776, loss = 0.00745959\n",
      "Iteration 3777, loss = 0.00745668\n",
      "Iteration 3778, loss = 0.00745365\n",
      "Iteration 3779, loss = 0.00745107\n",
      "Iteration 3780, loss = 0.00744858\n",
      "Iteration 3781, loss = 0.00744601\n",
      "Iteration 3782, loss = 0.00744360\n",
      "Iteration 3783, loss = 0.00744098\n",
      "Iteration 3784, loss = 0.00743871\n",
      "Iteration 3785, loss = 0.00743645\n",
      "Iteration 3786, loss = 0.00743378\n",
      "Iteration 3787, loss = 0.00743160\n",
      "Iteration 3788, loss = 0.00742890\n",
      "Iteration 3789, loss = 0.00742700\n",
      "Iteration 3790, loss = 0.00742403\n",
      "Iteration 3791, loss = 0.00742140\n",
      "Iteration 3792, loss = 0.00741915\n",
      "Iteration 3793, loss = 0.00741686\n",
      "Iteration 3794, loss = 0.00741440\n",
      "Iteration 3795, loss = 0.00741227\n",
      "Iteration 3796, loss = 0.00741000\n",
      "Iteration 3797, loss = 0.00740793\n",
      "Iteration 3798, loss = 0.00740588\n",
      "Iteration 3799, loss = 0.00740342\n",
      "Iteration 3800, loss = 0.00740057\n",
      "Iteration 3801, loss = 0.00739790\n",
      "Iteration 3802, loss = 0.00739564\n",
      "Iteration 3803, loss = 0.00739303\n",
      "Iteration 3804, loss = 0.00739065\n",
      "Iteration 3805, loss = 0.00738769\n",
      "Iteration 3806, loss = 0.00738501\n",
      "Iteration 3807, loss = 0.00738237\n",
      "Iteration 3808, loss = 0.00738036\n",
      "Iteration 3809, loss = 0.00737729\n",
      "Iteration 3810, loss = 0.00737492\n",
      "Iteration 3811, loss = 0.00737252\n",
      "Iteration 3812, loss = 0.00737006\n",
      "Iteration 3813, loss = 0.00736724\n",
      "Iteration 3814, loss = 0.00736520\n",
      "Iteration 3815, loss = 0.00736237\n",
      "Iteration 3816, loss = 0.00735991\n",
      "Iteration 3817, loss = 0.00735820\n",
      "Iteration 3818, loss = 0.00735514\n",
      "Iteration 3819, loss = 0.00735296\n",
      "Iteration 3820, loss = 0.00735049\n",
      "Iteration 3821, loss = 0.00734835\n",
      "Iteration 3822, loss = 0.00734596\n",
      "Iteration 3823, loss = 0.00734344\n",
      "Iteration 3824, loss = 0.00734088\n",
      "Iteration 3825, loss = 0.00733901\n",
      "Iteration 3826, loss = 0.00733680\n",
      "Iteration 3827, loss = 0.00733472\n",
      "Iteration 3828, loss = 0.00733245\n",
      "Iteration 3829, loss = 0.00733045\n",
      "Iteration 3830, loss = 0.00732905\n",
      "Iteration 3831, loss = 0.00732672\n",
      "Iteration 3832, loss = 0.00732492\n",
      "Iteration 3833, loss = 0.00732292\n",
      "Iteration 3834, loss = 0.00732023\n",
      "Iteration 3835, loss = 0.00731822\n",
      "Iteration 3836, loss = 0.00731435\n",
      "Iteration 3837, loss = 0.00731165\n",
      "Iteration 3838, loss = 0.00730882\n",
      "Iteration 3839, loss = 0.00730708\n",
      "Iteration 3840, loss = 0.00730297\n",
      "Iteration 3841, loss = 0.00730049\n",
      "Iteration 3842, loss = 0.00729757\n",
      "Iteration 3843, loss = 0.00729522\n",
      "Iteration 3844, loss = 0.00729321\n",
      "Iteration 3845, loss = 0.00729033\n",
      "Iteration 3846, loss = 0.00728757\n",
      "Iteration 3847, loss = 0.00728542\n",
      "Iteration 3848, loss = 0.00728241\n",
      "Iteration 3849, loss = 0.00727994\n",
      "Iteration 3850, loss = 0.00727723\n",
      "Iteration 3851, loss = 0.00727518\n",
      "Iteration 3852, loss = 0.00727236\n",
      "Iteration 3853, loss = 0.00726980\n",
      "Iteration 3854, loss = 0.00726723\n",
      "Iteration 3855, loss = 0.00726444\n",
      "Iteration 3856, loss = 0.00726235\n",
      "Iteration 3857, loss = 0.00726053\n",
      "Iteration 3858, loss = 0.00725658\n",
      "Iteration 3859, loss = 0.00725493\n",
      "Iteration 3860, loss = 0.00725175\n",
      "Iteration 3861, loss = 0.00724902\n",
      "Iteration 3862, loss = 0.00724701\n",
      "Iteration 3863, loss = 0.00724462\n",
      "Iteration 3864, loss = 0.00724209\n",
      "Iteration 3865, loss = 0.00724011\n",
      "Iteration 3866, loss = 0.00723686\n",
      "Iteration 3867, loss = 0.00723413\n",
      "Iteration 3868, loss = 0.00723178\n",
      "Iteration 3869, loss = 0.00722904\n",
      "Iteration 3870, loss = 0.00722687\n",
      "Iteration 3871, loss = 0.00722449\n",
      "Iteration 3872, loss = 0.00722287\n",
      "Iteration 3873, loss = 0.00722024\n",
      "Iteration 3874, loss = 0.00721778\n",
      "Iteration 3875, loss = 0.00721533\n",
      "Iteration 3876, loss = 0.00721281\n",
      "Iteration 3877, loss = 0.00721020\n",
      "Iteration 3878, loss = 0.00720811\n",
      "Iteration 3879, loss = 0.00720545\n",
      "Iteration 3880, loss = 0.00720321\n",
      "Iteration 3881, loss = 0.00720108\n",
      "Iteration 3882, loss = 0.00719853\n",
      "Iteration 3883, loss = 0.00719569\n",
      "Iteration 3884, loss = 0.00719297\n",
      "Iteration 3885, loss = 0.00719017\n",
      "Iteration 3886, loss = 0.00718776\n",
      "Iteration 3887, loss = 0.00718505\n",
      "Iteration 3888, loss = 0.00718266\n",
      "Iteration 3889, loss = 0.00718040\n",
      "Iteration 3890, loss = 0.00717810\n",
      "Iteration 3891, loss = 0.00717562\n",
      "Iteration 3892, loss = 0.00717344\n",
      "Iteration 3893, loss = 0.00717125\n",
      "Iteration 3894, loss = 0.00716880\n",
      "Iteration 3895, loss = 0.00716640\n",
      "Iteration 3896, loss = 0.00716474\n",
      "Iteration 3897, loss = 0.00716180\n",
      "Iteration 3898, loss = 0.00715895\n",
      "Iteration 3899, loss = 0.00715628\n",
      "Iteration 3900, loss = 0.00715430\n",
      "Iteration 3901, loss = 0.00715124\n",
      "Iteration 3902, loss = 0.00714892\n",
      "Iteration 3903, loss = 0.00714708\n",
      "Iteration 3904, loss = 0.00714475\n",
      "Iteration 3905, loss = 0.00714229\n",
      "Iteration 3906, loss = 0.00714011\n",
      "Iteration 3907, loss = 0.00713790\n",
      "Iteration 3908, loss = 0.00713585\n",
      "Iteration 3909, loss = 0.00713367\n",
      "Iteration 3910, loss = 0.00713136\n",
      "Iteration 3911, loss = 0.00712899\n",
      "Iteration 3912, loss = 0.00712728\n",
      "Iteration 3913, loss = 0.00712428\n",
      "Iteration 3914, loss = 0.00712179\n",
      "Iteration 3915, loss = 0.00711896\n",
      "Iteration 3916, loss = 0.00711639\n",
      "Iteration 3917, loss = 0.00711218\n",
      "Iteration 3918, loss = 0.00711068\n",
      "Iteration 3919, loss = 0.00710665\n",
      "Iteration 3920, loss = 0.00710364\n",
      "Iteration 3921, loss = 0.00710084\n",
      "Iteration 3922, loss = 0.00709951\n",
      "Iteration 3923, loss = 0.00709610\n",
      "Iteration 3924, loss = 0.00709371\n",
      "Iteration 3925, loss = 0.00709042\n",
      "Iteration 3926, loss = 0.00708754\n",
      "Iteration 3927, loss = 0.00708409\n",
      "Iteration 3928, loss = 0.00708167\n",
      "Iteration 3929, loss = 0.00707822\n",
      "Iteration 3930, loss = 0.00707478\n",
      "Iteration 3931, loss = 0.00707119\n",
      "Iteration 3932, loss = 0.00706824\n",
      "Iteration 3933, loss = 0.00706786\n",
      "Iteration 3934, loss = 0.00706461\n",
      "Iteration 3935, loss = 0.00706086\n",
      "Iteration 3936, loss = 0.00705806\n",
      "Iteration 3937, loss = 0.00705551\n",
      "Iteration 3938, loss = 0.00705247\n",
      "Iteration 3939, loss = 0.00704953\n",
      "Iteration 3940, loss = 0.00704786\n",
      "Iteration 3941, loss = 0.00704468\n",
      "Iteration 3942, loss = 0.00704189\n",
      "Iteration 3943, loss = 0.00703881\n",
      "Iteration 3944, loss = 0.00703667\n",
      "Iteration 3945, loss = 0.00703458\n",
      "Iteration 3946, loss = 0.00703142\n",
      "Iteration 3947, loss = 0.00702879\n",
      "Iteration 3948, loss = 0.00702645\n",
      "Iteration 3949, loss = 0.00702399\n",
      "Iteration 3950, loss = 0.00702174\n",
      "Iteration 3951, loss = 0.00701934\n",
      "Iteration 3952, loss = 0.00701706\n",
      "Iteration 3953, loss = 0.00701458\n",
      "Iteration 3954, loss = 0.00701255\n",
      "Iteration 3955, loss = 0.00701008\n",
      "Iteration 3956, loss = 0.00700783\n",
      "Iteration 3957, loss = 0.00700577\n",
      "Iteration 3958, loss = 0.00700372\n",
      "Iteration 3959, loss = 0.00700132\n",
      "Iteration 3960, loss = 0.00699941\n",
      "Iteration 3961, loss = 0.00699714\n",
      "Iteration 3962, loss = 0.00699489\n",
      "Iteration 3963, loss = 0.00699255\n",
      "Iteration 3964, loss = 0.00698993\n",
      "Iteration 3965, loss = 0.00698804\n",
      "Iteration 3966, loss = 0.00698622\n",
      "Iteration 3967, loss = 0.00698337\n",
      "Iteration 3968, loss = 0.00698053\n",
      "Iteration 3969, loss = 0.00697801\n",
      "Iteration 3970, loss = 0.00697549\n",
      "Iteration 3971, loss = 0.00697311\n",
      "Iteration 3972, loss = 0.00697056\n",
      "Iteration 3973, loss = 0.00696800\n",
      "Iteration 3974, loss = 0.00696513\n",
      "Iteration 3975, loss = 0.00696281\n",
      "Iteration 3976, loss = 0.00696117\n",
      "Iteration 3977, loss = 0.00695810\n",
      "Iteration 3978, loss = 0.00695541\n",
      "Iteration 3979, loss = 0.00695381\n",
      "Iteration 3980, loss = 0.00695082\n",
      "Iteration 3981, loss = 0.00694891\n",
      "Iteration 3982, loss = 0.00694639\n",
      "Iteration 3983, loss = 0.00694568\n",
      "Iteration 3984, loss = 0.00694208\n",
      "Iteration 3985, loss = 0.00693965\n",
      "Iteration 3986, loss = 0.00693728\n",
      "Iteration 3987, loss = 0.00693503\n",
      "Iteration 3988, loss = 0.00693247\n",
      "Iteration 3989, loss = 0.00693017\n",
      "Iteration 3990, loss = 0.00692805\n",
      "Iteration 3991, loss = 0.00692521\n",
      "Iteration 3992, loss = 0.00692316\n",
      "Iteration 3993, loss = 0.00692031\n",
      "Iteration 3994, loss = 0.00691772\n",
      "Iteration 3995, loss = 0.00691637\n",
      "Iteration 3996, loss = 0.00691327\n",
      "Iteration 3997, loss = 0.00691091\n",
      "Iteration 3998, loss = 0.00690856\n",
      "Iteration 3999, loss = 0.00690624\n",
      "Iteration 4000, loss = 0.00690485\n",
      "Iteration 4001, loss = 0.00690161\n",
      "Iteration 4002, loss = 0.00689963\n",
      "Iteration 4003, loss = 0.00689716\n",
      "Iteration 4004, loss = 0.00689477\n",
      "Iteration 4005, loss = 0.00689241\n",
      "Iteration 4006, loss = 0.00688994\n",
      "Iteration 4007, loss = 0.00688791\n",
      "Iteration 4008, loss = 0.00688497\n",
      "Iteration 4009, loss = 0.00688250\n",
      "Iteration 4010, loss = 0.00688006\n",
      "Iteration 4011, loss = 0.00687733\n",
      "Iteration 4012, loss = 0.00687475\n",
      "Iteration 4013, loss = 0.00687263\n",
      "Iteration 4014, loss = 0.00686966\n",
      "Iteration 4015, loss = 0.00686757\n",
      "Iteration 4016, loss = 0.00686523\n",
      "Iteration 4017, loss = 0.00686237\n",
      "Iteration 4018, loss = 0.00686015\n",
      "Iteration 4019, loss = 0.00685766\n",
      "Iteration 4020, loss = 0.00685537\n",
      "Iteration 4021, loss = 0.00685296\n",
      "Iteration 4022, loss = 0.00685074\n",
      "Iteration 4023, loss = 0.00684904\n",
      "Iteration 4024, loss = 0.00684648\n",
      "Iteration 4025, loss = 0.00684429\n",
      "Iteration 4026, loss = 0.00684267\n",
      "Iteration 4027, loss = 0.00684068\n",
      "Iteration 4028, loss = 0.00683815\n",
      "Iteration 4029, loss = 0.00683592\n",
      "Iteration 4030, loss = 0.00683395\n",
      "Iteration 4031, loss = 0.00683162\n",
      "Iteration 4032, loss = 0.00682931\n",
      "Iteration 4033, loss = 0.00682761\n",
      "Iteration 4034, loss = 0.00682561\n",
      "Iteration 4035, loss = 0.00682306\n",
      "Iteration 4036, loss = 0.00682044\n",
      "Iteration 4037, loss = 0.00681779\n",
      "Iteration 4038, loss = 0.00681571\n",
      "Iteration 4039, loss = 0.00681398\n",
      "Iteration 4040, loss = 0.00681077\n",
      "Iteration 4041, loss = 0.00680830\n",
      "Iteration 4042, loss = 0.00680594\n",
      "Iteration 4043, loss = 0.00680404\n",
      "Iteration 4044, loss = 0.00680129\n",
      "Iteration 4045, loss = 0.00679874\n",
      "Iteration 4046, loss = 0.00679656\n",
      "Iteration 4047, loss = 0.00679448\n",
      "Iteration 4048, loss = 0.00679235\n",
      "Iteration 4049, loss = 0.00678991\n",
      "Iteration 4050, loss = 0.00678795\n",
      "Iteration 4051, loss = 0.00678551\n",
      "Iteration 4052, loss = 0.00678319\n",
      "Iteration 4053, loss = 0.00678099\n",
      "Iteration 4054, loss = 0.00677868\n",
      "Iteration 4055, loss = 0.00677615\n",
      "Iteration 4056, loss = 0.00677395\n",
      "Iteration 4057, loss = 0.00677156\n",
      "Iteration 4058, loss = 0.00676965\n",
      "Iteration 4059, loss = 0.00676836\n",
      "Iteration 4060, loss = 0.00676520\n",
      "Iteration 4061, loss = 0.00676330\n",
      "Iteration 4062, loss = 0.00676101\n",
      "Iteration 4063, loss = 0.00675889\n",
      "Iteration 4064, loss = 0.00675703\n",
      "Iteration 4065, loss = 0.00675384\n",
      "Iteration 4066, loss = 0.00675127\n",
      "Iteration 4067, loss = 0.00675013\n",
      "Iteration 4068, loss = 0.00674700\n",
      "Iteration 4069, loss = 0.00674441\n",
      "Iteration 4070, loss = 0.00674246\n",
      "Iteration 4071, loss = 0.00674035\n",
      "Iteration 4072, loss = 0.00673802\n",
      "Iteration 4073, loss = 0.00673578\n",
      "Iteration 4074, loss = 0.00673361\n",
      "Iteration 4075, loss = 0.00673153\n",
      "Iteration 4076, loss = 0.00672913\n",
      "Iteration 4077, loss = 0.00672682\n",
      "Iteration 4078, loss = 0.00672431\n",
      "Iteration 4079, loss = 0.00672229\n",
      "Iteration 4080, loss = 0.00671995\n",
      "Iteration 4081, loss = 0.00671761\n",
      "Iteration 4082, loss = 0.00671570\n",
      "Iteration 4083, loss = 0.00671373\n",
      "Iteration 4084, loss = 0.00671173\n",
      "Iteration 4085, loss = 0.00670971\n",
      "Iteration 4086, loss = 0.00670764\n",
      "Iteration 4087, loss = 0.00670542\n",
      "Iteration 4088, loss = 0.00670272\n",
      "Iteration 4089, loss = 0.00670088\n",
      "Iteration 4090, loss = 0.00669834\n",
      "Iteration 4091, loss = 0.00669632\n",
      "Iteration 4092, loss = 0.00669374\n",
      "Iteration 4093, loss = 0.00669211\n",
      "Iteration 4094, loss = 0.00669008\n",
      "Iteration 4095, loss = 0.00668791\n",
      "Iteration 4096, loss = 0.00668624\n",
      "Iteration 4097, loss = 0.00668520\n",
      "Iteration 4098, loss = 0.00668251\n",
      "Iteration 4099, loss = 0.00668048\n",
      "Iteration 4100, loss = 0.00667899\n",
      "Iteration 4101, loss = 0.00667688\n",
      "Iteration 4102, loss = 0.00667495\n",
      "Iteration 4103, loss = 0.00667286\n",
      "Iteration 4104, loss = 0.00667119\n",
      "Iteration 4105, loss = 0.00666916\n",
      "Iteration 4106, loss = 0.00666724\n",
      "Iteration 4107, loss = 0.00666574\n",
      "Iteration 4108, loss = 0.00666366\n",
      "Iteration 4109, loss = 0.00666154\n",
      "Iteration 4110, loss = 0.00665934\n",
      "Iteration 4111, loss = 0.00665716\n",
      "Iteration 4112, loss = 0.00665529\n",
      "Iteration 4113, loss = 0.00665327\n",
      "Iteration 4114, loss = 0.00665108\n",
      "Iteration 4115, loss = 0.00664875\n",
      "Iteration 4116, loss = 0.00664653\n",
      "Iteration 4117, loss = 0.00664438\n",
      "Iteration 4118, loss = 0.00664209\n",
      "Iteration 4119, loss = 0.00663989\n",
      "Iteration 4120, loss = 0.00663759\n",
      "Iteration 4121, loss = 0.00663550\n",
      "Iteration 4122, loss = 0.00663341\n",
      "Iteration 4123, loss = 0.00663133\n",
      "Iteration 4124, loss = 0.00662892\n",
      "Iteration 4125, loss = 0.00662670\n",
      "Iteration 4126, loss = 0.00662441\n",
      "Iteration 4127, loss = 0.00662229\n",
      "Iteration 4128, loss = 0.00662028\n",
      "Iteration 4129, loss = 0.00661799\n",
      "Iteration 4130, loss = 0.00661606\n",
      "Iteration 4131, loss = 0.00661400\n",
      "Iteration 4132, loss = 0.00661205\n",
      "Iteration 4133, loss = 0.00661050\n",
      "Iteration 4134, loss = 0.00660806\n",
      "Iteration 4135, loss = 0.00660605\n",
      "Iteration 4136, loss = 0.00660388\n",
      "Iteration 4137, loss = 0.00660162\n",
      "Iteration 4138, loss = 0.00659951\n",
      "Iteration 4139, loss = 0.00659819\n",
      "Iteration 4140, loss = 0.00659602\n",
      "Iteration 4141, loss = 0.00659464\n",
      "Iteration 4142, loss = 0.00659212\n",
      "Iteration 4143, loss = 0.00659043\n",
      "Iteration 4144, loss = 0.00658894\n",
      "Iteration 4145, loss = 0.00658661\n",
      "Iteration 4146, loss = 0.00658423\n",
      "Iteration 4147, loss = 0.00658179\n",
      "Iteration 4148, loss = 0.00657960\n",
      "Iteration 4149, loss = 0.00657722\n",
      "Iteration 4150, loss = 0.00657404\n",
      "Iteration 4151, loss = 0.00657131\n",
      "Iteration 4152, loss = 0.00656830\n",
      "Iteration 4153, loss = 0.00656521\n",
      "Iteration 4154, loss = 0.00656331\n",
      "Iteration 4155, loss = 0.00655990\n",
      "Iteration 4156, loss = 0.00655789\n",
      "Iteration 4157, loss = 0.00655547\n",
      "Iteration 4158, loss = 0.00655255\n",
      "Iteration 4159, loss = 0.00654995\n",
      "Iteration 4160, loss = 0.00654746\n",
      "Iteration 4161, loss = 0.00654545\n",
      "Iteration 4162, loss = 0.00654249\n",
      "Iteration 4163, loss = 0.00654002\n",
      "Iteration 4164, loss = 0.00653767\n",
      "Iteration 4165, loss = 0.00653509\n",
      "Iteration 4166, loss = 0.00653327\n",
      "Iteration 4167, loss = 0.00653113\n",
      "Iteration 4168, loss = 0.00652919\n",
      "Iteration 4169, loss = 0.00652633\n",
      "Iteration 4170, loss = 0.00652364\n",
      "Iteration 4171, loss = 0.00652172\n",
      "Iteration 4172, loss = 0.00651913\n",
      "Iteration 4173, loss = 0.00651715\n",
      "Iteration 4174, loss = 0.00651470\n",
      "Iteration 4175, loss = 0.00651260\n",
      "Iteration 4176, loss = 0.00651063\n",
      "Iteration 4177, loss = 0.00650815\n",
      "Iteration 4178, loss = 0.00650614\n",
      "Iteration 4179, loss = 0.00650378\n",
      "Iteration 4180, loss = 0.00650192\n",
      "Iteration 4181, loss = 0.00649971\n",
      "Iteration 4182, loss = 0.00649731\n",
      "Iteration 4183, loss = 0.00649532\n",
      "Iteration 4184, loss = 0.00649312\n",
      "Iteration 4185, loss = 0.00649192\n",
      "Iteration 4186, loss = 0.00648926\n",
      "Iteration 4187, loss = 0.00648682\n",
      "Iteration 4188, loss = 0.00648516\n",
      "Iteration 4189, loss = 0.00648317\n",
      "Iteration 4190, loss = 0.00648109\n",
      "Iteration 4191, loss = 0.00647940\n",
      "Iteration 4192, loss = 0.00647719\n",
      "Iteration 4193, loss = 0.00647522\n",
      "Iteration 4194, loss = 0.00647310\n",
      "Iteration 4195, loss = 0.00647109\n",
      "Iteration 4196, loss = 0.00646883\n",
      "Iteration 4197, loss = 0.00646631\n",
      "Iteration 4198, loss = 0.00646430\n",
      "Iteration 4199, loss = 0.00646216\n",
      "Iteration 4200, loss = 0.00645952\n",
      "Iteration 4201, loss = 0.00645766\n",
      "Iteration 4202, loss = 0.00645534\n",
      "Iteration 4203, loss = 0.00645328\n",
      "Iteration 4204, loss = 0.00645108\n",
      "Iteration 4205, loss = 0.00644898\n",
      "Iteration 4206, loss = 0.00644700\n",
      "Iteration 4207, loss = 0.00644505\n",
      "Iteration 4208, loss = 0.00644268\n",
      "Iteration 4209, loss = 0.00644058\n",
      "Iteration 4210, loss = 0.00643858\n",
      "Iteration 4211, loss = 0.00643708\n",
      "Iteration 4212, loss = 0.00643422\n",
      "Iteration 4213, loss = 0.00643248\n",
      "Iteration 4214, loss = 0.00643009\n",
      "Iteration 4215, loss = 0.00642860\n",
      "Iteration 4216, loss = 0.00642600\n",
      "Iteration 4217, loss = 0.00642392\n",
      "Iteration 4218, loss = 0.00642208\n",
      "Iteration 4219, loss = 0.00642012\n",
      "Iteration 4220, loss = 0.00641782\n",
      "Iteration 4221, loss = 0.00641580\n",
      "Iteration 4222, loss = 0.00641375\n",
      "Iteration 4223, loss = 0.00641225\n",
      "Iteration 4224, loss = 0.00640983\n",
      "Iteration 4225, loss = 0.00640778\n",
      "Iteration 4226, loss = 0.00640562\n",
      "Iteration 4227, loss = 0.00640399\n",
      "Iteration 4228, loss = 0.00640172\n",
      "Iteration 4229, loss = 0.00639990\n",
      "Iteration 4230, loss = 0.00639749\n",
      "Iteration 4231, loss = 0.00639545\n",
      "Iteration 4232, loss = 0.00639340\n",
      "Iteration 4233, loss = 0.00639181\n",
      "Iteration 4234, loss = 0.00638923\n",
      "Iteration 4235, loss = 0.00638754\n",
      "Iteration 4236, loss = 0.00638525\n",
      "Iteration 4237, loss = 0.00638301\n",
      "Iteration 4238, loss = 0.00638088\n",
      "Iteration 4239, loss = 0.00637910\n",
      "Iteration 4240, loss = 0.00637657\n",
      "Iteration 4241, loss = 0.00637453\n",
      "Iteration 4242, loss = 0.00637250\n",
      "Iteration 4243, loss = 0.00637032\n",
      "Iteration 4244, loss = 0.00636853\n",
      "Iteration 4245, loss = 0.00636628\n",
      "Iteration 4246, loss = 0.00636475\n",
      "Iteration 4247, loss = 0.00636225\n",
      "Iteration 4248, loss = 0.00636028\n",
      "Iteration 4249, loss = 0.00635874\n",
      "Iteration 4250, loss = 0.00635672\n",
      "Iteration 4251, loss = 0.00635466\n",
      "Iteration 4252, loss = 0.00635283\n",
      "Iteration 4253, loss = 0.00635100\n",
      "Iteration 4254, loss = 0.00634913\n",
      "Iteration 4255, loss = 0.00634775\n",
      "Iteration 4256, loss = 0.00634570\n",
      "Iteration 4257, loss = 0.00634406\n",
      "Iteration 4258, loss = 0.00634146\n",
      "Iteration 4259, loss = 0.00633993\n",
      "Iteration 4260, loss = 0.00633702\n",
      "Iteration 4261, loss = 0.00633511\n",
      "Iteration 4262, loss = 0.00633342\n",
      "Iteration 4263, loss = 0.00633130\n",
      "Iteration 4264, loss = 0.00632908\n",
      "Iteration 4265, loss = 0.00632706\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "multi_classifier=MLPClassifier(hidden_layer_sizes=(8,4), max_iter=8000, alpha=0.0001, solver='sgd', verbose=10,  random_state=21,tol=0.000000001)\n",
    "multi_classifier.fit(X_train,y_train)\n",
    "multi_accuracies=cross_val_score(estimator=multi_classifier,X=X_test,y=y_test,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "olympic-voluntary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies:\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Mean Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracies:\\n\",multi_accuracies)\n",
    "print(\"Mean Accuracy: \",multi_accuracies.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "applied-kansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_predicted= multi_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "pursuant-chancellor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,multi_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "secure-addition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix For MLPClassifier\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import matplotlib.pyplot as plt\\nimport pandas as pd\\nimport seaborn as sns'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import matplotlib.pyplot as plt\\nimport pandas as pd\\nimport seaborn as sns'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import matplotlib.pyplot as plt\\nimport pandas as pd\\nimport seaborn as sns'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Confusion Matrix For MLPClassifier\")\n",
    "cm=metrics.confusion_matrix(y_test,multi_predicted, labels=[0, 1])\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index = [i for i in [0,1]],\n",
    "                  columns = [i for i in [\"Predict 0\",\"Predict 1\"]])\n",
    "plt.figure(figsize = (7,5))\n",
    "sns.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiovascular-vienna",
   "metadata": {},
   "source": [
    "<h4>Printing each Algorithm and the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "literary-hollywood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: 0.9745454545454545\n",
      "Support Vector Machine (using kernel=linear): 0.9818181818181818\n",
      "Support Vector Machine (using kernel=rbf): 1.0\n",
      "RandomForestClassifier: 0.9963636363636363\n",
      "KNeighborsClassifier: 1.0\n",
      "MLPClassifier: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"LogisticRegression:\", accuracy_score(y_test,y_test_pred))\n",
    "print(\"Support Vector Machine (using kernel=linear):\", accuracy_score(y_test,svm_pred))\n",
    "print(\"Support Vector Machine (using kernel=rbf):\", accuracy_score(y_test,svm_rbf_pred))\n",
    "print(\"RandomForestClassifier:\", accuracy_score(y_test,rdf_pred))\n",
    "print(\"KNeighborsClassifier:\", accuracy_score(y_test,KNN_predicted))\n",
    "print(\"MLPClassifier:\", accuracy_score(y_test,multi_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-rates",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
